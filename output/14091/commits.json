[
  {
    "sha": "3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzozYmI2ZjM0ZjY2ZTBmNDM4ODFlZTE2NTFhYTE0Y2ZkZDUwYzE2ODE4",
    "commit": {
      "author": {
        "name": "Federico Tenga",
        "email": "31323835+fedsten@users.noreply.github.com",
        "date": "2018-08-28T10:32:09Z"
      },
      "committer": {
        "name": "Federico Tenga",
        "email": "federicotenga@gmail.com",
        "date": "2018-08-31T20:10:00Z"
      },
      "message": "Update fuzzing.md",
      "tree": {
        "sha": "4569614c31b3d8811077a0a37af33e6681272ced",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/4569614c31b3d8811077a0a37af33e6681272ced"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/comments",
    "author": {
      "login": "fedsten",
      "id": 31323835,
      "node_id": "MDQ6VXNlcjMxMzIzODM1",
      "avatar_url": "https://avatars.githubusercontent.com/u/31323835?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/fedsten",
      "html_url": "https://github.com/fedsten",
      "followers_url": "https://api.github.com/users/fedsten/followers",
      "following_url": "https://api.github.com/users/fedsten/following{/other_user}",
      "gists_url": "https://api.github.com/users/fedsten/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/fedsten/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/fedsten/subscriptions",
      "organizations_url": "https://api.github.com/users/fedsten/orgs",
      "repos_url": "https://api.github.com/users/fedsten/repos",
      "events_url": "https://api.github.com/users/fedsten/events{/privacy}",
      "received_events_url": "https://api.github.com/users/fedsten/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": null,
    "parents": [
      {
        "sha": "59ecacfc84af13e5a1608e7d970315d07dcb0269",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/59ecacfc84af13e5a1608e7d970315d07dcb0269",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/59ecacfc84af13e5a1608e7d970315d07dcb0269"
      }
    ],
    "stats": {
      "total": 82,
      "additions": 41,
      "deletions": 41
    },
    "files": [
      {
        "sha": "4948b01cbdebf8a1f2e53191d6242a7c945e00ff",
        "filename": "build-aux/m4/ax_pthread.m4",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/build-aux/m4/ax_pthread.m4",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/build-aux/m4/ax_pthread.m4",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/build-aux/m4/ax_pthread.m4?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -190,8 +190,8 @@ case $host_os in\n         # (non-functional) versions of the pthreads routines, so link-based\n         # tests will erroneously succeed. (N.B.: The stubs are missing\n         # pthread_cleanup_push, or rather a function called by this macro,\n-        # so we could check for that, but who knows whether they'll stub\n-        # that too in a future libc.)  So we'll check first for the\n+        # so we could check for that, but who knows whether they will stub\n+        # that too in a future libc.)  So we will check first for the\n         # standard Solaris way of linking pthreads (-mt -lpthread).\n \n         ax_pthread_flags=\"-mt,pthread pthread $ax_pthread_flags\""
      },
      {
        "sha": "6bf43c90a01a2c1fd5f6f6f6d1b86005bdbbf6d0",
        "filename": "configure.ac",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/configure.ac",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/configure.ac",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/configure.ac?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -1407,7 +1407,7 @@ AC_CONFIG_LINKS([test/util/rpcauth-test.py:test/util/rpcauth-test.py])\n \n dnl boost's m4 checks do something really nasty: they export these vars. As a\n dnl result, they leak into secp256k1's configure and crazy things happen.\n-dnl Until this is fixed upstream and we've synced, we'll just un-export them.\n+dnl Until this is fixed upstream and we've synced, we will just un-export them.\n CPPFLAGS_TEMP=\"$CPPFLAGS\"\n unset CPPFLAGS\n CPPFLAGS=\"$CPPFLAGS_TEMP\""
      },
      {
        "sha": "34029ccdd5314636fc13df542188255e036bae8c",
        "filename": "depends/config.sub",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/depends/config.sub",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/depends/config.sub",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/depends/config.sub?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -1539,7 +1539,7 @@ else\n # \"-sun\"), then you have to tell the case statement up towards the top\n # that MANUFACTURER isn't an operating system.  Otherwise, code above\n # will signal an error saying that MANUFACTURER isn't an operating\n-# system, and we'll never get to this point.\n+# system, and we will never get to this point.\n \n case $basic_machine in\n \tscore-*)"
      },
      {
        "sha": "e6f99f878d5ee8d3600aa590263f50397b9573a7",
        "filename": "doc/README_osx.md",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/doc/README_osx.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/doc/README_osx.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/README_osx.md?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -83,7 +83,7 @@ contrib/macdeploy/custom_dsstore.py.\n \n As of OS X 10.9 Mavericks, using an Apple-blessed key to sign binaries is a\n requirement in order to satisfy the new Gatekeeper requirements. Because this\n-private key cannot be shared, we'll have to be a bit creative in order for the\n+private key cannot be shared, we will have to be a bit creative in order for the\n build process to remain somewhat deterministic. Here's how it works:\n \n - Builders use Gitian to create an unsigned release. This outputs an unsigned"
      },
      {
        "sha": "b28ddde75ffc1e3210d035464b4b07fc599df07c",
        "filename": "doc/fuzzing.md",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/doc/fuzzing.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/doc/fuzzing.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/fuzzing.md?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -2,7 +2,7 @@ Fuzz-testing Bitcoin Core\n ==========================\n \n A special test harness `test_bitcoin_fuzzy` is provided to provide an easy\n-entry point for fuzzers and the like. In this document we'll describe how to\n+entry point for fuzzers and the like. In this document we will describe how to\n use it with AFL.\n \n Building AFL\n@@ -44,7 +44,7 @@ Preparing fuzzing\n \n AFL needs an input directory with examples, and an output directory where it\n will place examples that it found. These can be anywhere in the file system,\n-we'll define environment variables to make it easy to reference them.\n+we will define environment variables to make it easy to reference them.\n \n ```\n mkdir inputs"
      },
      {
        "sha": "fcb552548fdf33cdfa97cd193775849475b0fa91",
        "filename": "src/bloom.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/bloom.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/bloom.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/bloom.cpp?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -208,7 +208,7 @@ CRollingBloomFilter::CRollingBloomFilter(const unsigned int nElements, const dou\n     /* The optimal number of hash functions is log(fpRate) / log(0.5), but\n      * restrict it to the range 1-50. */\n     nHashFuncs = std::max(1, std::min((int)round(logFpRate / log(0.5)), 50));\n-    /* In this rolling bloom filter, we'll store between 2 and 3 generations of nElements / 2 entries. */\n+    /* In this rolling bloom filter, we will store between 2 and 3 generations of nElements / 2 entries. */\n     nEntriesPerGeneration = (nElements + 1) / 2;\n     uint32_t nMaxElements = nEntriesPerGeneration * 3;\n     /* The maximum fpRate = pow(1.0 - exp(-nHashFuncs * nMaxElements / nFilterBits), nHashFuncs)"
      },
      {
        "sha": "068f88ffd74cdb7ff189317c62c19d4dc5edf69b",
        "filename": "src/chainparams.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/chainparams.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/chainparams.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/chainparams.cpp?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -126,7 +126,7 @@ class CMainParams : public CChainParams {\n \n         // Note that of those which support the service bits prefix, most only support a subset of\n         // possible options.\n-        // This is fine at runtime as we'll fall back to using them as a oneshot if they don't support the\n+        // This is fine at runtime as we will fall back to using them as a oneshot if they don't support the\n         // service bits we want, but we should get them updated to support all service bits wanted by any\n         // release ASAP to avoid it where possible.\n         vSeeds.emplace_back(\"seed.bitcoin.sipa.be\"); // Pieter Wuille, only supports x1, x5, x9, and xd"
      },
      {
        "sha": "f8e87f23c883f362514f89d36c62e4fd66633821",
        "filename": "src/leveldb/db/db_test.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/leveldb/db/db_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/leveldb/db/db_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/db_test.cc?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -2067,7 +2067,7 @@ TEST(DBTest, Randomized) {\n       if ((step % 100) == 0) {\n         ASSERT_TRUE(CompareIterators(step, &model, db_, NULL, NULL));\n         ASSERT_TRUE(CompareIterators(step, &model, db_, model_snap, db_snap));\n-        // Save a snapshot from each DB this time that we'll use next\n+        // Save a snapshot from each DB this time that we will use next\n         // time we compare things, to make sure the current state is\n         // preserved with the snapshot\n         if (model_snap != NULL) model.ReleaseSnapshot(model_snap);"
      },
      {
        "sha": "126b4e7261a3ab72073d290bf6d354be1c2bbc64",
        "filename": "src/leveldb/table/table.cc",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/leveldb/table/table.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/leveldb/table/table.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/table.cc?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -69,7 +69,7 @@ Status Table::Open(const Options& options,\n   }\n \n   if (s.ok()) {\n-    // We've successfully read the footer and the index block: we're\n+    // We have successfully read the footer and the index block: we're\n     // ready to serve requests.\n     Rep* rep = new Table::Rep;\n     rep->options = options;\n@@ -268,7 +268,7 @@ uint64_t Table::ApproximateOffsetOf(const Slice& key) const {\n       result = handle.offset();\n     } else {\n       // Strange: we can't decode the block handle in the index block.\n-      // We'll just return the offset of the metaindex block, which is\n+      // We will just return the offset of the metaindex block, which is\n       // close to the whole file size for this case.\n       result = rep_->metaindex_handle.offset();\n     }"
      },
      {
        "sha": "8c86be30c61479dee198dfbce3b64ea33a3129a6",
        "filename": "src/net.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/net.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/net.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net.cpp?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -1871,7 +1871,7 @@ void CConnman::ThreadOpenConnections(const std::vector<std::string> connect)\n             if (nANow - addr.nLastTry < 600 && nTries < 30)\n                 continue;\n \n-            // for non-feelers, require all the services we'll want,\n+            // for non-feelers, require all the services we will want,\n             // for feelers, only require they be a full node (only because most\n             // SPV clients don't have a good address DB available)\n             if (!fFeeler && !HasAllDesirableServiceFlags(addr.nServices)) {"
      },
      {
        "sha": "7bcd37a129f61c024c3b5e220b9a08ab420a63b4",
        "filename": "src/net_processing.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/net_processing.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/net_processing.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.cpp?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -512,7 +512,7 @@ static void FindNextBlocksToDownload(NodeId nodeid, unsigned int count, std::vec\n     CNodeState *state = State(nodeid);\n     assert(state != nullptr);\n \n-    // Make sure pindexBestKnownBlock is up to date, we'll need it.\n+    // Make sure pindexBestKnownBlock is up to date, we will need it.\n     ProcessBlockAvailability(nodeid);\n \n     if (state->pindexBestKnownBlock == nullptr || state->pindexBestKnownBlock->nChainWork < chainActive.Tip()->nChainWork || state->pindexBestKnownBlock->nChainWork < nMinimumChainWork) {\n@@ -1400,7 +1400,7 @@ bool static ProcessHeadersMessage(CNode *pfrom, CConnman *connman, const std::ve\n             hashLastBlock = header.GetHash();\n         }\n \n-        // If we don't have the last header, then they'll have given us\n+        // If we don't have the last header, then they will have given us\n         // something new (if these headers are valid).\n         if (!LookupBlockIndex(hashLastBlock)) {\n             received_new_header = true;"
      },
      {
        "sha": "8cb2009e9c7bbfa78b2abd68c157790ba8c61df7",
        "filename": "src/policy/fees.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/policy/fees.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/policy/fees.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/policy/fees.cpp?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -261,7 +261,7 @@ double TxConfirmStats::EstimateMedianVal(int confTarget, double sufficientTxVal,\n     unsigned int startbucket = requireGreater ? maxbucketindex : 0;\n     int step = requireGreater ? -1 : 1;\n \n-    // We'll combine buckets until we have enough samples.\n+    // We will combine buckets until we have enough samples.\n     // The near and far variables will define the range we've combined\n     // The best variables are the last range we saw which still had a high\n     // enough confirmation rate to count as success.\n@@ -407,7 +407,7 @@ void TxConfirmStats::Read(CAutoFile& filein, int nFileVersion, size_t numBuckets\n {\n     // Read data file and do some very basic sanity checking\n     // buckets and bucketMap are not updated yet, so don't access them\n-    // If there is a read failure, we'll just discard this entire object anyway\n+    // If there is a read failure, we will just discard this entire object anyway\n     size_t maxConfirms, maxPeriods;\n \n     // The current version will store the decay with each individual TxConfirmStats and also keep a scale factor"
      },
      {
        "sha": "7ecd8f4d52a18e833157cd5773e8769ea76b26e2",
        "filename": "src/qt/paymentrequestplus.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/qt/paymentrequestplus.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/qt/paymentrequestplus.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/qt/paymentrequestplus.cpp?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -64,7 +64,7 @@ bool PaymentRequestPlus::getMerchant(X509_STORE* certStore, QString& merchant) c\n     if (!IsInitialized())\n         return false;\n \n-    // One day we'll support more PKI types, but just\n+    // One day we will support more PKI types, but just\n     // x509 for now:\n     const EVP_MD* digestAlgorithm = nullptr;\n     if (paymentRequest.pki_type() == \"x509+sha256\") {"
      },
      {
        "sha": "fb7ee95e955097edfde6931d6b4e9dbb2ff1a405",
        "filename": "src/secp256k1/src/group_impl.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/secp256k1/src/group_impl.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/secp256k1/src/group_impl.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/secp256k1/src/group_impl.h?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -32,7 +32,7 @@\n  *   P = (int(P.order()) / int(order)) * P\n  *   assert(P.order() == order)\n  *\n- * 3. Print the values. You'll need to use a vim macro or something to\n+ * 3. Print the values. You will need to use a vim macro or something to\n  *    split the hex output into 4-byte chunks.\n  *   print \"%x %x\" % P.xy()\n  */"
      },
      {
        "sha": "cf77e85cba2ad71cc3494596a5bfe1ec52246952",
        "filename": "src/support/lockedpool.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/support/lockedpool.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/support/lockedpool.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/support/lockedpool.cpp?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -342,7 +342,7 @@ bool LockedPool::new_arena(size_t size, size_t align)\n     // If this is the first arena, handle this specially: Cap the upper size\n     // by the process limit. This makes sure that the first arena will at least\n     // be locked. An exception to this is if the process limit is 0:\n-    // in this case no memory can be locked at all so we'll skip past this logic.\n+    // in this case no memory can be locked at all so we will skip past this logic.\n     if (arenas.empty()) {\n         size_t limit = allocator->GetLimit();\n         if (limit > 0) {"
      },
      {
        "sha": "928dc43b11e5b59c2c6be34a27ae6364daade577",
        "filename": "src/test/scheduler_tests.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/test/scheduler_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/test/scheduler_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/scheduler_tests.cpp?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -123,7 +123,7 @@ BOOST_AUTO_TEST_CASE(singlethreadedscheduler_ordered)\n     // create more threads than queues\n     // if the queues only permit execution of one task at once then\n     // the extra threads should effectively be doing nothing\n-    // if they don't we'll get out of order behaviour\n+    // if they don't we will get out of order behaviour\n     boost::thread_group threads;\n     for (int i = 0; i < 5; ++i) {\n         threads.create_thread(boost::bind(&CScheduler::serviceQueue, &scheduler));"
      },
      {
        "sha": "b684ab9da098850676b59d21a23adcd0913c13a4",
        "filename": "src/validation.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/validation.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/validation.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/validation.cpp?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -916,7 +916,7 @@ static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool\n         // flags to cache our script execution flags. This is, of course,\n         // useless if the next block has different script flags from the\n         // previous one, but because the cache tracks script flags for us it\n-        // will auto-invalidate and we'll just have a few blocks of extra\n+        // will auto-invalidate and we will just have a few blocks of extra\n         // misses on soft-fork activation.\n         //\n         // This is also useful in case of bugs in the standard flags that cause\n@@ -4195,7 +4195,7 @@ bool CChainState::RewindBlockIndex(const CChainParams& params)\n     }\n \n     // Reduce validity flag and have-data flags.\n-    // We do this after actual disconnecting, otherwise we'll end up writing the lack of data\n+    // We do this after actual disconnecting, otherwise we will end up writing the lack of data\n     // to disk before writing the chainstate, resulting in a failure to continue if interrupted.\n     for (const auto& entry : mapBlockIndex) {\n         CBlockIndex* pindexIter = entry.second;"
      },
      {
        "sha": "b3931cb080d9d663abe815e822536bc9996b2d84",
        "filename": "src/validation.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/validation.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/validation.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/validation.h?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -95,7 +95,7 @@ static const int MAX_CMPCTBLOCK_DEPTH = 5;\n static const int MAX_BLOCKTXN_DEPTH = 10;\n /** Size of the \"block download window\": how far ahead of our current height do we fetch?\n  *  Larger windows tolerate larger download speed differences between peer, but increase the potential\n- *  degree of disordering of blocks on disk (which make reindexing and pruning harder). We'll probably\n+ *  degree of disordering of blocks on disk (which make reindexing and pruning harder). We will probably\n  *  want to make this a per-peer adaptive value at some point. */\n static const unsigned int BLOCK_DOWNLOAD_WINDOW = 1024;\n /** Time to wait (in seconds) between writing blocks/block index to disk. */"
      },
      {
        "sha": "20b369fe24ae87c221d112db63d693e4ea79957e",
        "filename": "src/wallet/test/coinselector_tests.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/wallet/test/coinselector_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/wallet/test/coinselector_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/wallet/test/coinselector_tests.cpp?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -395,7 +395,7 @@ BOOST_AUTO_TEST_CASE(knapsack_solver_test)\n         add_coin(MIN_CHANGE * 5 / 10);\n \n         // try making 1 * MIN_CHANGE from the 1.5 * MIN_CHANGE\n-        // we'll get change smaller than MIN_CHANGE whatever happens, so can expect MIN_CHANGE exactly\n+        // we will get change smaller than MIN_CHANGE whatever happens, so can expect MIN_CHANGE exactly\n         BOOST_CHECK( testWallet.SelectCoinsMinConf(MIN_CHANGE, filter_confirmed, GroupCoins(vCoins), setCoinsRet, nValueRet, coin_selection_params, bnb_used));\n         BOOST_CHECK_EQUAL(nValueRet, MIN_CHANGE);\n "
      },
      {
        "sha": "e27d41a48de902bdd4d4486bb1d2bf217c5070b6",
        "filename": "src/wallet/wallet.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/wallet/wallet.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/src/wallet/wallet.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/wallet/wallet.cpp?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -3643,7 +3643,7 @@ void CWallet::GetKeyBirthTimes(std::map<CTxDestination, int64_t> &mapKeyBirth) c\n         }\n     }\n \n-    // map in which we'll infer heights of other keys\n+    // map in which we will infer heights of other keys\n     CBlockIndex *pindexMax = chainActive[std::max(0, chainActive.Height() - 144)]; // the tip can be reorganized; use a 144-block safety margin\n     std::map<CKeyID, CBlockIndex*> mapKeyFirstBlock;\n     for (const CKeyID &keyid : GetKeys()) {"
      },
      {
        "sha": "7a74c7927ed72e1c7c5f37112d5d8016ff5a37ec",
        "filename": "test/functional/feature_dbcrash.py",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_dbcrash.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_dbcrash.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_dbcrash.py?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -66,7 +66,7 @@ def set_test_params(self):\n     def setup_network(self):\n         self.add_nodes(self.num_nodes, extra_args=self.extra_args)\n         self.start_nodes()\n-        # Leave them unconnected, we'll use submitblock directly in this test\n+        # Leave them unconnected, we will use submitblock directly in this test\n \n     def restart_node(self, node_index, expected_tip):\n         \"\"\"Start up a given node id, wait for the tip to reach the given block hash, and calculate the utxo hash.\n@@ -129,7 +129,7 @@ def sync_node3blocks(self, block_hashes):\n         \"\"\"Use submitblock to sync node3's chain with the other nodes\n \n         If submitblock fails, restart the node and get the new utxo hash.\n-        If any nodes crash while updating, we'll compare utxo hashes to\n+        If any nodes crash while updating, we will compare utxo hashes to\n         ensure recovery was successful.\"\"\"\n \n         node3_utxo_hash = self.nodes[3].gettxoutsetinfo()['hash_serialized_2']"
      },
      {
        "sha": "3a084772e104ccbfafa344e519c21bf1280be1fa",
        "filename": "test/functional/feature_fee_estimation.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_fee_estimation.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_fee_estimation.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_fee_estimation.py?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -128,7 +128,7 @@ def set_test_params(self):\n \n     def setup_network(self):\n         \"\"\"\n-        We'll setup the network to have 3 nodes that all mine with different parameters.\n+        We will setup the network to have 3 nodes that all mine with different parameters.\n         But first we need to use one node to create a lot of outputs\n         which we will use to generate our transactions.\n         \"\"\""
      },
      {
        "sha": "d4f951ed2cf1e832ce9464852fc056d680388335",
        "filename": "test/functional/feature_maxuploadtarget.py",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_maxuploadtarget.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_maxuploadtarget.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_maxuploadtarget.py?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -61,7 +61,7 @@ def run_test(self):\n         # Now mine a big block\n         mine_large_block(self.nodes[0], self.utxo_cache)\n \n-        # Store the hash; we'll request this later\n+        # Store the hash; we will request this later\n         big_old_block = self.nodes[0].getbestblockhash()\n         old_block_size = self.nodes[0].getblock(big_old_block, True)['size']\n         big_old_block = int(big_old_block, 16)\n@@ -72,7 +72,7 @@ def run_test(self):\n         # Mine one more block, so that the prior block looks old\n         mine_large_block(self.nodes[0], self.utxo_cache)\n \n-        # We'll be requesting this new block too\n+        # We will be requesting this new block too\n         big_new_block = self.nodes[0].getbestblockhash()\n         big_new_block = int(big_new_block, 16)\n "
      },
      {
        "sha": "ef52498e4ac711d329f9735c8a7148fa4319ec0d",
        "filename": "test/functional/feature_pruning.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_pruning.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_pruning.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_pruning.py?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -364,7 +364,7 @@ def run_test(self):\n         # Extend this chain past the PruneAfterHeight\n         # N0=N1=N2 **...*(1020)\n \n-        self.log.info(\"Check that we'll exceed disk space target if we have a very high stale block rate\")\n+        self.log.info(\"Check that we will exceed disk space target if we have a very high stale block rate\")\n         self.create_chain_with_staleblocks()\n         # Disconnect N0\n         # And mine a 24 block chain on N1 and a separate 25 block chain on N0"
      },
      {
        "sha": "3cbf4ee4451668a54a85a6d19a437576fbbf85fd",
        "filename": "test/functional/feature_rbf.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_rbf.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_rbf.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_rbf.py?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -531,7 +531,7 @@ def test_prioritised_transactions(self):\n         tx2a_hex = txToHex(tx2a)\n         self.nodes[0].sendrawtransaction(tx2a_hex, True)\n \n-        # Lower fee, but we'll prioritise it\n+        # Lower fee, but we will prioritise it\n         tx2b = CTransaction()\n         tx2b.vin = [CTxIn(tx1_outpoint, nSequence=0)]\n         tx2b.vout = [CTxOut(int(1.01 * COIN), CScript([b'a' * 35]))]"
      },
      {
        "sha": "36666d65d64873d2bad1169028dc0bd3a06a6313",
        "filename": "test/functional/feature_versionbits_warning.py",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_versionbits_warning.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/feature_versionbits_warning.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_versionbits_warning.py?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -73,7 +73,7 @@ def run_test(self):\n         self.send_blocks_with_version(node.p2p, VB_THRESHOLD - 1, VB_UNKNOWN_VERSION)\n         node.generate(VB_PERIOD - VB_THRESHOLD + 1)\n \n-        # Check that we're not getting any versionbit-related errors in get*info()\n+        # Check that we are not getting any versionbit-related errors in get*info()\n         assert(not VB_PATTERN.match(node.getmininginfo()[\"warnings\"]))\n         assert(not VB_PATTERN.match(node.getnetworkinfo()[\"warnings\"]))\n \n@@ -94,7 +94,7 @@ def run_test(self):\n         # Stop-start the node. This is required because bitcoind will only warn once about unknown versions or unknown rules activating.\n         self.restart_node(0)\n \n-        # Generating one block guarantees that we'll get out of IBD\n+        # Generating one block guarantees that we will get out of IBD\n         node.generate(1)\n         wait_until(lambda: not node.getblockchaininfo()['initialblockdownload'], timeout=10, lock=mininode_lock)\n         # Generating one more block will be enough to generate an error."
      },
      {
        "sha": "e6880df9613d772a67d9d080abc21a86c5e8cac0",
        "filename": "test/functional/p2p_compactblocks.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/p2p_compactblocks.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/p2p_compactblocks.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_compactblocks.py?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -898,7 +898,7 @@ def run_test(self):\n         self.test_getblocktxn_handler(self.nodes[1], self.segwit_node, 2)\n         self.test_getblocktxn_handler(self.nodes[1], self.old_node, 1)\n \n-        # Test that if we submitblock to node1, we'll get a compact block\n+        # Test that if we submitblock to node1, we will get a compact block\n         # announcement to all peers.\n         # (Post-segwit activation, blocks won't propagate from node0 to node1\n         # automatically, so don't bother testing a block announced to node0.)"
      },
      {
        "sha": "12524b7a4e52f1d9dab3b9e068e68452dc7c4ed2",
        "filename": "test/functional/p2p_leak.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/p2p_leak.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/p2p_leak.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_leak.py?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -54,7 +54,7 @@ def on_cmpctblock(self, message): self.bad_message(message)\n     def on_getblocktxn(self, message): self.bad_message(message)\n     def on_blocktxn(self, message): self.bad_message(message)\n \n-# Node that never sends a version. We'll use this to send a bunch of messages\n+# Node that never sends a version. We will use this to send a bunch of messages\n # anyway, and eventually get disconnected.\n class CNodeNoVersionBan(CLazyNode):\n     # send a bunch of veracks without sending a message. This should get us disconnected."
      },
      {
        "sha": "4e1c6a062cd5956cbf7e5f437dbeb203c75c0a61",
        "filename": "test/functional/p2p_segwit.py",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/p2p_segwit.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/p2p_segwit.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_segwit.py?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -1534,7 +1534,7 @@ def test_uncompressed_pubkey(self):\n         self.update_witness_block_with_transactions(block, [tx])\n         test_witness_block(self.nodes[0], self.test_node, block, accepted=True)\n \n-        # Now try to spend it. Send it to a P2WSH output, which we'll\n+        # Now try to spend it. Send it to a P2WSH output, which we will\n         # use in the next test.\n         witness_program = CScript([pubkey, CScriptOp(OP_CHECKSIG)])\n         witness_hash = sha256(witness_program)\n@@ -1559,7 +1559,7 @@ def test_uncompressed_pubkey(self):\n \n         # Test 2: P2WSH\n         # Try to spend the P2WSH output created in last test.\n-        # Send it to a P2SH(P2WSH) output, which we'll use in the next test.\n+        # Send it to a P2SH(P2WSH) output, which we will use in the next test.\n         p2sh_witness_hash = hash160(script_wsh)\n         script_p2sh = CScript([OP_HASH160, p2sh_witness_hash, OP_EQUAL])\n         script_sig = CScript([script_wsh])"
      },
      {
        "sha": "7132934030674abf753a6a3c32acdb63bd26b798",
        "filename": "test/functional/rpc_txoutproof.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/rpc_txoutproof.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/rpc_txoutproof.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/rpc_txoutproof.py?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -79,7 +79,7 @@ def run_test(self):\n         # We can't get a proof if we specify transactions from different blocks\n         assert_raises_rpc_error(-5, \"Not all transactions found in specified or retrieved block\", self.nodes[2].gettxoutproof, [txid1, txid3])\n \n-        # Now we'll try tweaking a proof.\n+        # Now we will try tweaking a proof.\n         proof = self.nodes[3].gettxoutproof([txid1, txid2])\n         assert txid1 in self.nodes[0].verifytxoutproof(proof)\n         assert txid2 in self.nodes[1].verifytxoutproof(proof)"
      },
      {
        "sha": "d98271b50b6ee7b5c2618813b17ad2382232267e",
        "filename": "test/functional/test_framework/util.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/test_framework/util.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3bb6f34f66e0f43881ee1651aa14cfdd50c16818/test/functional/test_framework/util.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/test_framework/util.py?ref=3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "patch": "@@ -515,7 +515,7 @@ def gen_return_txouts():\n     script_pubkey = \"6a4d0200\"  # OP_RETURN OP_PUSH2 512 bytes\n     for i in range(512):\n         script_pubkey = script_pubkey + \"01\"\n-    # concatenate 128 txouts of above script_pubkey which we'll insert before the txout for change\n+    # concatenate 128 txouts of above script_pubkey which we will insert before the txout for change\n     txouts = \"81\"\n     for k in range(128):\n         # add txout value"
      }
    ]
  },
  {
    "sha": "ec49b56c58ebc5ea466bdce6c220667a292f370a",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzplYzQ5YjU2YzU4ZWJjNWVhNDY2YmRjZTZjMjIwNjY3YTI5MmYzNzBh",
    "commit": {
      "author": {
        "name": "Federico Tenga",
        "email": "federicotenga@gmail.com",
        "date": "2018-08-31T19:32:16Z"
      },
      "committer": {
        "name": "Federico Tenga",
        "email": "federicotenga@gmail.com",
        "date": "2018-08-31T20:10:00Z"
      },
      "message": "style enhancement in docs",
      "tree": {
        "sha": "e720707531fa4993a0fac57d097321c005bf76cf",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/e720707531fa4993a0fac57d097321c005bf76cf"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/ec49b56c58ebc5ea466bdce6c220667a292f370a",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/ec49b56c58ebc5ea466bdce6c220667a292f370a",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/ec49b56c58ebc5ea466bdce6c220667a292f370a",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/ec49b56c58ebc5ea466bdce6c220667a292f370a/comments",
    "author": null,
    "committer": null,
    "parents": [
      {
        "sha": "3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3bb6f34f66e0f43881ee1651aa14cfdd50c16818",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/3bb6f34f66e0f43881ee1651aa14cfdd50c16818"
      }
    ],
    "stats": {
      "total": 494,
      "additions": 247,
      "deletions": 247
    },
    "files": [
      {
        "sha": "59e1e8dbe4939290a0fe6ed8859fbb03ab31bc4a",
        "filename": "CONTRIBUTING.md",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/CONTRIBUTING.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/CONTRIBUTING.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/CONTRIBUTING.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -14,7 +14,7 @@ purposes. As such there are repository \"maintainers\" who are responsible for\n merging pull requests as well as a \"lead maintainer\" who is responsible for the\n release cycle, overall merging, moderation and appointment of maintainers.\n \n-If you're looking for somewhere to start contributing, check out the\n+If you are looking for somewhere to start contributing, check out the\n [good first issue](https://github.com/bitcoin/bitcoin/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n list.\n \n@@ -264,7 +264,7 @@ a worthwhile change based on the judgement of the maintainers.\n \n As most reviewers are themselves developers with their own projects, the review\n process can be quite lengthy, and some amount of patience is required. If you find\n-that you've been waiting for a pull request to be given attention for several\n+that you have been waiting for a pull request to be given attention for several\n months, there may be a number of reasons for this, some of which you can do something\n about:\n \n@@ -287,7 +287,7 @@ about:\n     find the person touching the code you are touching before you and see if you can find\n     them and give them a nudge. Don't be incessant about the nudging though.\n   - Finally, if all else fails, ask on IRC or elsewhere for someone to give your pull request\n-    a look. If you think you've been waiting an unreasonably long amount of time (month+) for\n+    a look. If you think you have been waiting an unreasonably long amount of time (month+) for\n     no particular reason (few lines changed, etc), this is totally fine. Try to return the favor\n     when someone else is asking for feedback on their code, and universe balances out.\n "
      },
      {
        "sha": "f4e36e3f108136a99683763fe33cf633dec34a6a",
        "filename": "contrib/devtools/README.md",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/devtools/README.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/devtools/README.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/devtools/README.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -109,7 +109,7 @@ check or whatever).\n * Ask you whether to push the result upstream.\n \n This means that there are no potential race conditions (where a\n-pullreq gets updated while you're reviewing it, but before you click\n+pullreq gets updated while you are reviewing it, but before you click\n merge), and when using GPG signatures, that even a compromised GitHub\n couldn't mess with the sources.\n "
      },
      {
        "sha": "4317f0cc1796d2925784d83f1ac9cb11a69048b8",
        "filename": "contrib/devtools/github-merge.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/devtools/github-merge.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/devtools/github-merge.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/devtools/github-merge.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -7,7 +7,7 @@\n # github repository, inspect it, sign it and optionally push it.\n \n # The following temporary branches are created/overwritten and deleted:\n-# * pull/$PULL/base (the current master we're merging onto)\n+# * pull/$PULL/base (the current master we are merging onto)\n # * pull/$PULL/head (the current state of the remote pull request)\n # * pull/$PULL/merge (github's merge)\n # * pull/$PULL/local-merge (our merge)"
      },
      {
        "sha": "5e6c526db4d60f3eda02349aca5d9c7110323432",
        "filename": "contrib/devtools/update-translations.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/devtools/update-translations.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/devtools/update-translations.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/devtools/update-translations.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -66,7 +66,7 @@ def split_format_specifiers(specifiers):\n         else:\n             other.append(s)\n \n-    # If both numeric format specifiers and \"others\" are used, assume we're dealing\n+    # If both numeric format specifiers and \"others\" are used, assume we are dealing\n     # with a Qt-formatted message. In the case of Qt formatting (see https://doc.qt.io/qt-5/qstring.html#arg)\n     # only numeric formats are replaced at all. This means \"(percentage: %1%)\" is valid, without needing\n     # any kind of escaping that would be necessary for strprintf. Without this, this function"
      },
      {
        "sha": "48cc88b5f497979d81b318d9eaa74eb35c1bbe7b",
        "filename": "contrib/install_db4.sh",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/install_db4.sh",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/install_db4.sh",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/install_db4.sh?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -9,7 +9,7 @@ if [ -z \"${1}\" ]; then\n   echo \"Usage: ./install_db4.sh <base-dir> [<extra-bdb-configure-flag> ...]\"\n   echo\n   echo \"Must specify a single argument: the directory in which db4 will be built.\"\n-  echo \"This is probably \\`pwd\\` if you're at the root of the bitcoin repository.\"\n+  echo \"This is probably \\`pwd\\` if you are at the root of the bitcoin repository.\"\n   exit 1\n fi\n "
      },
      {
        "sha": "fc2fb95139dd1e2f80f000a4c2508383f722e44a",
        "filename": "contrib/verify-commits/README.md",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/verify-commits/README.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/verify-commits/README.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/verify-commits/README.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -14,7 +14,7 @@ Remember that you can't use an untrusted script to verify itself. This means\n that checking out code, then running `verify-commits.py` against `HEAD` is\n _not_ safe, because the version of `verify-commits.py` that you just ran could\n be backdoored. Instead, you need to use a trusted version of verify-commits\n-prior to checkout to make sure you're checking out only code signed by trusted\n+prior to checkout to make sure you are checking out only code signed by trusted\n keys:\n \n     git fetch origin && \\"
      },
      {
        "sha": "e551ee604ab1f0b9dfc35f5c9df24a96dc74860c",
        "filename": "contrib/verify-commits/gpg.sh",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/verify-commits/gpg.sh",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/contrib/verify-commits/gpg.sh",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/verify-commits/gpg.sh?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -18,7 +18,7 @@ else\n \t# in fact because what's being signed is a commit object that's\n \t# semi-deterministically generated by untrusted input (the pull-req) in theory\n \t# an attacker could construct a pull-req that results in a commit object that\n-\t# they've created a collision for. Not the most likely attack, but preventing\n+\t# they have created a collision for. Not the most likely attack, but preventing\n \t# it is pretty easy so we do so as a \"belt-and-suspenders\" measure.\n \tGPG_RES=\"\"\n \tfor LINE in \"$(gpg --version)\"; do\n@@ -27,9 +27,9 @@ else\n \t\t\t\techo \"Please upgrade to at least gpg 2.1.10 to check for weak signatures\" > /dev/stderr\n \t\t\t\tGPG_RES=\"$(printf '%s\\n' \"$INPUT\" | gpg --trust-model always \"$@\" 2>/dev/null)\"\n \t\t\t\t;;\n-\t\t\t# We assume if you're running 2.1+, you're probably running 2.1.10+\n+\t\t\t# We assume if you are running 2.1+, you are probably running 2.1.10+\n \t\t\t# gpg will fail otherwise\n-\t\t\t# We assume if you're running 1.X, it is either 1.4.1X or 1.4.20+\n+\t\t\t# We assume if you are running 1.X, it is either 1.4.1X or 1.4.20+\n \t\t\t# gpg will fail otherwise\n \t\tesac\n \tdone"
      },
      {
        "sha": "5f421c97c669ae99764e06073e94d96fc0d52449",
        "filename": "depends/config.sub",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/depends/config.sub",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/depends/config.sub",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/depends/config.sub?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -1535,7 +1535,7 @@ else\n # The value should be what the vendor currently ships out the door with their\n # machine or put another way, the most popular os provided with the machine.\n \n-# Note that if you're going to try to match \"-MANUFACTURER\" here (say,\n+# Note that if you are going to try to match \"-MANUFACTURER\" here (say,\n # \"-sun\"), then you have to tell the case statement up towards the top\n # that MANUFACTURER isn't an operating system.  Otherwise, code above\n # will signal an error saying that MANUFACTURER isn't an operating"
      },
      {
        "sha": "a5d8ab0bb514730addfb59a6e447cd782d068959",
        "filename": "doc/README_osx.md",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/README_osx.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/README_osx.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/README_osx.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -48,7 +48,7 @@ Alternatively, you can use 7zip and SleuthKit to extract the files one by one.\n The script contrib/macdeploy/extract-osx-sdk.sh automates this. First ensure\n the dmg file is in the current directory, and then run the script. You may wish\n to delete the intermediate 5.hfs file and MacOSX10.11.sdk (the directory) when\n-you've confirmed the extraction succeeded.\n+you have confirmed the extraction succeeded.\n \n ```bash\n apt-get install p7zip-full sleuthkit"
      },
      {
        "sha": "5a29381b0a954c3e52ee29a3bcb6e354f5e4e4ea",
        "filename": "doc/developer-notes.md",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/developer-notes.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/developer-notes.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/developer-notes.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -41,7 +41,7 @@ Coding Style (General)\n ----------------------\n \n Various coding styles have been used during the history of the codebase,\n-and the result is not very consistent. However, we're now trying to converge to\n+and the result is not very consistent. However, we are now trying to converge to\n a single style, which is specified below. When writing patches, favor the new\n style over attempting to mimic the surrounding style, except for move-only\n commits."
      },
      {
        "sha": "bcc960b68489cd7facba035d184bb0afae130aae",
        "filename": "doc/psbt.md",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/psbt.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/psbt.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/psbt.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -42,7 +42,7 @@ from one to the next, until the Extractor can convert it to a real transaction.\n In order to permit parallel operation, **Combiners** can be employed which merge\n metadata from different PSBTs for the same unsigned transaction.\n \n-The names above in bold are the names of the roles defined in BIP174. They're\n+The names above in bold are the names of the roles defined in BIP174. They are\n useful in understanding the underlying steps, but in practice, software and\n hardware implementations will typically implement multiple roles simultaneously.\n \n@@ -81,7 +81,7 @@ hardware implementations will typically implement multiple roles simultaneously.\n \n #### Multisig with multiple Bitcoin Core instances\n \n-Alice, Bob, and Carol want to create a 2-of-3 multisig address. They're all using\n+Alice, Bob, and Carol want to create a 2-of-3 multisig address. They are all using\n Bitcoin Core. We assume their wallets only contain the multisig funds. In case\n they also have a personal wallet, this can be accomplished through the\n multiwallet feature - possibly resulting in a need to add `-rpcwallet=name` to"
      },
      {
        "sha": "6e135a4e6a4bbc7e5cc78c7e7f51e345763cfbd1",
        "filename": "doc/release-notes/release-notes-0.10.0.md",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-notes/release-notes-0.10.0.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-notes/release-notes-0.10.0.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/release-notes/release-notes-0.10.0.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -185,7 +185,7 @@ OpenSSL has code in their source repository for derandomization\n and reduction in timing leaks that we've eagerly wanted to use for a\n long time, but this functionality has still not made its\n way into a released version of OpenSSL. Libsecp256k1 achieves\n-significantly stronger protection: As far as we're aware this is\n+significantly stronger protection: As far as we are aware this is\n the only deployed implementation of constant time signing for\n the curve Bitcoin uses and we have reason to believe that\n libsecp256k1 is better tested and more thoroughly reviewed"
      },
      {
        "sha": "740015d47140bd080ecae7856dc1b829e17a47c3",
        "filename": "doc/release-notes/release-notes-0.12.0.md",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-notes/release-notes-0.12.0.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-notes/release-notes-0.12.0.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/release-notes/release-notes-0.12.0.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -295,7 +295,7 @@ To detect conflicts with historical transactions in the chain a one-time\n \n Unlike earlier versions, unconfirmed but non-conflicting transactions will never\n get a negative confirmation count. They are not treated as spendable unless\n-they're coming from ourself (change) and accepted into our local mempool,\n+they are coming from ourself (change) and accepted into our local mempool,\n however. The new \"trusted\" field in the `listtransactions` RPC output\n indicates whether outputs of an unconfirmed transaction are considered\n spendable.\n@@ -750,7 +750,7 @@ git merge commit are mentioned.\n - #7063 `6abf6eb` [Tests] Add prioritisetransaction RPC test (Suhas Daftuar)\n - #7137 `16f4a6e` Tests: Explicitly set chain limits in replace-by-fee test (Suhas Daftuar)\n - #7216 `9572e49` Removed offline testnet DNSSeed 'alexykot.me'. (tnull)\n-- #7209 `f3ad812` test: don't override BITCOIND and BITCOINCLI if they're set (Wladimir J. van der Laan)\n+- #7209 `f3ad812` test: don't override BITCOIND and BITCOINCLI if they are set (Wladimir J. van der Laan)\n - #7226 `301f16a` Tests: Add more tests to p2p-fullblocktest (Suhas Daftuar)\n - #7153 `9ef7c54` [Tests] Add mempool_limit.py test (Jonas Schnelli)\n - #7170 `453c567` tests: Disable Tor interaction (Wladimir J. van der Laan)"
      },
      {
        "sha": "5ea97b756f44c0dd76e817d927dc1ae4556b3dcf",
        "filename": "doc/release-notes/release-notes-0.13.1.md",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-notes/release-notes-0.13.1.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-notes/release-notes-0.13.1.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/release-notes/release-notes-0.13.1.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -155,7 +155,7 @@ another 2,016 blocks, segwit will activate.\n \n For more information about segwit, please see the [segwit FAQ][], the\n [segwit wallet developers guide][] or BIPs [141][BIP141], [143][BIP143],\n-[144][BIP144], and [145][BIP145].  If you're a miner or mining pool\n+[144][BIP144], and [145][BIP145].  If you are a miner or mining pool\n operator, please see the [versionbits FAQ][] for information about\n signaling support for a soft fork.\n "
      },
      {
        "sha": "1517620666805a429c0a56c09984d35315a98020",
        "filename": "doc/release-notes/release-notes-0.15.0.md",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-notes/release-notes-0.15.0.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-notes/release-notes-0.15.0.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/release-notes/release-notes-0.15.0.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -152,7 +152,7 @@ Bitcoin Core 0.15.0 contains the following changes to the RPC interface and `bit\n \n * When running Bitcoin Core with a single wallet, there are **no** changes to the RPC interface or `bitcoin-cli`. All RPC calls and `bitcoin-cli` commands continue to work as before.\n * When running Bitcoin Core with multi-wallet, all *node-level* RPC methods continue to work as before. HTTP RPC requests should be send to the normal `<RPC IP address>:<RPC port>` endpoint, and `bitcoin-cli` commands should be run as before. A *node-level* RPC method is any method which does not require access to the wallet.\n-* When running Bitcoin Core with multi-wallet, *wallet-level* RPC methods must specify the wallet for which they're intended in every request. HTTP RPC requests should be send to the `<RPC IP address>:<RPC port>/wallet/<wallet name>` endpoint, for example `127.0.0.1:8332/wallet/wallet1.dat`. `bitcoin-cli` commands should be run with a `-rpcwallet` option, for example `bitcoin-cli -rpcwallet=wallet1.dat getbalance`.\n+* When running Bitcoin Core with multi-wallet, *wallet-level* RPC methods must specify the wallet for which they are intended in every request. HTTP RPC requests should be send to the `<RPC IP address>:<RPC port>/wallet/<wallet name>` endpoint, for example `127.0.0.1:8332/wallet/wallet1.dat`. `bitcoin-cli` commands should be run with a `-rpcwallet` option, for example `bitcoin-cli -rpcwallet=wallet1.dat getbalance`.\n * A new *node-level* `listwallets` RPC method is added to display which wallets are currently loaded. The names returned by this method are the same as those used in the HTTP endpoint and for the `rpcwallet` argument.\n \n Note that while multi-wallet is now fully supported, the RPC multi-wallet interface should be considered unstable for version 0.15.0, and there may backwards-incompatible changes in future versions.\n@@ -205,7 +205,7 @@ Low-level RPC changes\n ---------------------\n \n - When using Bitcoin Core in multi-wallet mode, RPC requests for wallet methods must specify\n-  the wallet that they're intended for. See [Multi-wallet support](#multi-wallet-support) for full details.\n+  the wallet that they are intended for. See [Multi-wallet support](#multi-wallet-support) for full details.\n \n - The new database model no longer stores information about transaction\n   versions of unspent outputs (See [Performance improvements](#performance-improvements)). This means that:\n@@ -321,7 +321,7 @@ Low-level RPC changes\n - #10310 `f4b15e2` [doc] Add hint about getmempoolentry to getrawmempool help (kallewoof)\n - #8704 `96c850c` [RPC] Transaction details in getblock (achow101)\n - #8952 `9390845` Add query options to listunspent RPC call (pedrobranco)\n-- #10413 `08ac35a` Fix docs (there's no rpc command setpaytxfee) (RHavar)\n+- #10413 `08ac35a` Fix docs (there is no rpc command setpaytxfee) (RHavar)\n - #8384 `e317c0d` Add witness data output to TxInError messages (instagibbs)\n - #9571 `4677151` RPC: getblockchaininfo returns BIP signaling statistics  (pinheadmz)\n - #10450 `ef2d062` Fix bumpfee rpc \"errors\" return value (ryanofsky)"
      },
      {
        "sha": "5ea1f71c481d65d17718d5bee2c36a7cda58bbed",
        "filename": "doc/release-notes/release-notes-0.3.19.md",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-notes/release-notes-0.3.19.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-notes/release-notes-0.3.19.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/release-notes/release-notes-0.3.19.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -1,4 +1,4 @@\n-There's more work to do on DoS, but I'm doing a quick build of what I have so far in case it's needed, before venturing into more complex ideas.  The build for this is version 0.3.19.\n+There is more work to do on DoS, but I'm doing a quick build of what I have so far in case it's needed, before venturing into more complex ideas.  The build for this is version 0.3.19.\n \n - Added some DoS controls\n As Gavin and I have said clearly before, the software is not at all resistant to DoS attack.  This is one improvement, but there are still more ways to attack than I can count.  "
      },
      {
        "sha": "55993ccce4e1c6cb0594103f4f5139554f7e6da0",
        "filename": "doc/release-process.md",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-process.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/release-process.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/release-process.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -29,7 +29,7 @@ Before every major release:\n \n ### First time / New builders\n \n-If you're using the automated script (found in [contrib/gitian-build.py](/contrib/gitian-build.py)), then at this point you should run it with the \"--setup\" command. Otherwise ignore this.\n+If you are using the automated script (found in [contrib/gitian-build.py](/contrib/gitian-build.py)), then at this point you should run it with the \"--setup\" command. Otherwise ignore this.\n \n Check out the source code in the following directory hierarchy.\n \n@@ -58,7 +58,7 @@ Tag version (or release candidate) in git\n \n ### Setup and perform Gitian builds\n \n-If you're using the automated script (found in [contrib/gitian-build.py](/contrib/gitian-build.py)), then at this point you should run it with the \"--build\" command. Otherwise ignore this.\n+If you are using the automated script (found in [contrib/gitian-build.py](/contrib/gitian-build.py)), then at this point you should run it with the \"--build\" command. Otherwise ignore this.\n \n Setup Gitian descriptors:\n "
      },
      {
        "sha": "2b9f3df592199017736be2cbb9334db62d047941",
        "filename": "doc/tor.md",
        "status": "modified",
        "additions": 4,
        "deletions": 4,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/tor.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/doc/tor.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/tor.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -19,7 +19,7 @@ outgoing connections, but more is possible.\n \t                to explicitly disable access to hidden service.\n \n \t-listen         When using -proxy, listening is disabled by default. If you want\n-\t                to run a hidden service (see next section), you'll need to enable\n+\t                to run a hidden service (see next section), you will need to enable\n \t                it explicitly.\n \n \t-connect=X      When behind a Tor proxy, you can specify .onion addresses instead\n@@ -54,17 +54,17 @@ your bitcoind's P2P listen port (8333 by default).\n \t                Tor proxy typically runs), .onion addresses are given\n \t                preference for your node to advertise itself with.\n \n-\t-listen         You'll need to enable listening for incoming connections, as this\n+\t-listen         You will need to enable listening for incoming connections, as this\n \t                is off by default behind a proxy.\n \n \t-discover       When -externalip is specified, no attempt is made to discover local\n \t                IPv4 or IPv6 addresses. If you want to run a dual stack, reachable\n-\t                from both Tor and IPv4 (or IPv6), you'll need to either pass your\n+\t                from both Tor and IPv4 (or IPv6), you will need to either pass your\n \t                other addresses using -externalip, or explicitly enable -discover.\n \t                Note that both addresses of a dual-stack system may be easily\n \t                linkable using traffic analysis.\n \n-In a typical situation, where you're only reachable via Tor, this should suffice:\n+In a typical situation, where you are only reachable via Tor, this should suffice:\n \n \t./bitcoind -proxy=127.0.0.1:9050 -externalip=57qr3yd1nyntf5k.onion -listen\n "
      },
      {
        "sha": "f555627d2dff31a4a07cb47b2edeb8b860f80040",
        "filename": "share/examples/bitcoin.conf",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/share/examples/bitcoin.conf",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/share/examples/bitcoin.conf",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/share/examples/bitcoin.conf?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -29,13 +29,13 @@\n ##  connect will not do the above when you 'connect' to it. ##\n ##    It will *only* connect you to 4.2.2.4 and no one else.##\n ##                                                          ##\n-##  So if you're behind a firewall, or have other problems  ##\n+##  So if you are behind a firewall, or have other problems  ##\n ##  finding nodes, add some using 'addnode'.                ##\n ##                                                          ##\n ##  If you want to stay private, use 'connect' to only      ##\n ##  connect to \"trusted\" nodes.                             ##\n ##                                                          ##\n-##  If you run multiple nodes on a LAN, there's no need for ##\n+##  If you run multiple nodes on a LAN, there is no need for ##\n ##  all of them to open lots of connections.  Instead       ##\n ##  'connect' them all to one node that is port forwarded   ##\n ##  and has lots of connections.                            ##"
      },
      {
        "sha": "b59b548c3b77a5e38ad2b2159c22c7ba2468d65a",
        "filename": "src/base58.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/base58.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/base58.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/base58.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -8,7 +8,7 @@\n  * - Don't want 0OIl characters that look the same in some fonts and\n  *      could be used to create visually identical looking data.\n  * - A string with non-alphanumeric characters is not as easily accepted as input.\n- * - E-mail usually won't line-break if there's no punctuation to break at.\n+ * - E-mail usually won't line-break if there is no punctuation to break at.\n  * - Double-clicking selects the whole string as one word if it's all alphanumeric.\n  */\n #ifndef BITCOIN_BASE58_H"
      },
      {
        "sha": "90056e11ac379706d9d769ac67a2d118a1578a7a",
        "filename": "src/bitcoin-tx.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/bitcoin-tx.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/bitcoin-tx.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/bitcoin-tx.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -645,7 +645,7 @@ static void MutateTxSign(CMutableTransaction& tx, const std::string& flagStr)\n         const CAmount& amount = coin.out.nValue;\n \n         SignatureData sigdata = DataFromTransaction(mergedTx, i, coin.out);\n-        // Only sign SIGHASH_SINGLE if there's a corresponding output:\n+        // Only sign SIGHASH_SINGLE if there is a corresponding output:\n         if (!fHashSingle || (i < mergedTx.vout.size()))\n             ProduceSignature(keystore, MutableTransactionSignatureCreator(&mergedTx, i, amount, nHashType), prevPubKey, sigdata);\n "
      },
      {
        "sha": "239721021c21109eb236435dc55bd91e8e00915e",
        "filename": "src/consensus/merkle.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/consensus/merkle.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/consensus/merkle.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/consensus/merkle.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -6,7 +6,7 @@\n #include <hash.h>\n #include <utilstrencodings.h>\n \n-/*     WARNING! If you're reading this because you're learning about crypto\n+/*     WARNING! If you are reading this because you are learning about crypto\n        and/or designing a new system that will use merkle trees, keep in mind\n        that the following merkle tree algorithm has a serious flaw related to\n        duplicate txids, resulting in a vulnerability (CVE-2012-2459)."
      },
      {
        "sha": "625f095f0cce18b7105e3109fe92a082b6543a2b",
        "filename": "src/consensus/tx_verify.h",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/consensus/tx_verify.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/consensus/tx_verify.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/consensus/tx_verify.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -42,7 +42,7 @@ unsigned int GetLegacySigOpCount(const CTransaction& tx);\n /**\n  * Count ECDSA signature operations in pay-to-script-hash inputs.\n  *\n- * @param[in] mapInputs Map of previous transactions that have outputs we're spending\n+ * @param[in] mapInputs Map of previous transactions that have outputs we are spending\n  * @return maximum number of sigops required to validate this transaction's inputs\n  * @see CTransaction::FetchInputs\n  */\n@@ -51,7 +51,7 @@ unsigned int GetP2SHSigOpCount(const CTransaction& tx, const CCoinsViewCache& ma\n /**\n  * Compute total signature operation cost of a transaction.\n  * @param[in] tx     Transaction for which we are computing the cost\n- * @param[in] inputs Map of previous transactions that have outputs we're spending\n+ * @param[in] inputs Map of previous transactions that have outputs we are spending\n  * @param[out] flags Script verification flags\n  * @return Total signature operation cost of tx\n  */"
      },
      {
        "sha": "9194c1be273d3d39dc252d637bf1cff0ef725d7f",
        "filename": "src/crypto/aes.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/crypto/aes.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/crypto/aes.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crypto/aes.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -138,7 +138,7 @@ static int CBCDecrypt(const T& dec, const unsigned char iv[AES_BLOCKSIZE], const\n         unsigned char padsize = *--out;\n         fail = !padsize | (padsize > AES_BLOCKSIZE);\n \n-        // If not well-formed, treat it as though there's no padding.\n+        // If not well-formed, treat it as though there is no padding.\n         padsize *= !fail;\n \n         // All padding must equal the last byte otherwise it's not well-formed"
      },
      {
        "sha": "4e9c4c1f4a77e96b0566df4d1e2988bb22c9d672",
        "filename": "src/index/base.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/index/base.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/index/base.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/index/base.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -234,7 +234,7 @@ bool BaseIndex::BlockUntilSyncedToCurrentChain()\n     }\n \n     {\n-        // Skip the queue-draining stuff if we know we're caught up with\n+        // Skip the queue-draining stuff if we know we are caught up with\n         // chainActive.Tip().\n         LOCK(cs_main);\n         const CBlockIndex* chain_tip = chainActive.Tip();"
      },
      {
        "sha": "a7d300976b55b0d727eced2934a3111c980ee881",
        "filename": "src/init.cpp",
        "status": "modified",
        "additions": 7,
        "deletions": 7,
        "changes": 14,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/init.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/init.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/init.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -589,10 +589,10 @@ struct CImportingNow\n };\n \n \n-// If we're using -prune with -reindex, then delete block files that will be ignored by the\n+// If we are using -prune with -reindex, then delete block files that will be ignored by the\n // reindex.  Since reindexing works by starting at block file 0 and looping until a blockfile\n // is missing, do the same here to delete any later block files after a gap.  Also delete all\n-// rev files since they'll be rewritten by the reindex anyway.  This ensures that vinfoBlockFile\n+// rev files since they will be rewritten by the reindex anyway.  This ensures that vinfoBlockFile\n // is in sync with what's actually on disk by the time we start downloading, so that pruning\n // works correctly.\n static void CleanupBlockRevFiles()\n@@ -1457,7 +1457,7 @@ bool AppInitMain()\n \n                 if (fReset) {\n                     pblocktree->WriteReindexing(true);\n-                    //If we're reindexing in prune mode, wipe away unusable block files and all undo data files\n+                    //If we are reindexing in prune mode, wipe away unusable block files and all undo data files\n                     if (fPruneMode)\n                         CleanupBlockRevFiles();\n                 }\n@@ -1474,7 +1474,7 @@ bool AppInitMain()\n                 }\n \n                 // If the loaded chain has a wrong genesis, bail out immediately\n-                // (we're likely using a testnet datadir, or the other way around).\n+                // (we are likely using a testnet datadir, or the other way around).\n                 if (!mapBlockIndex.empty() && !LookupBlockIndex(chainparams.GetConsensus().hashGenesisBlock)) {\n                     return InitError(_(\"Incorrect or no genesis block found. Wrong datadir for network?\"));\n                 }\n@@ -1487,15 +1487,15 @@ bool AppInitMain()\n                 }\n \n                 // At this point blocktree args are consistent with what's on disk.\n-                // If we're not mid-reindex (based on disk + args), add a genesis block on disk\n+                // If we are not mid-reindex (based on disk + args), add a genesis block on disk\n                 // (otherwise we use the one already on disk).\n                 // This is called again in ThreadImport after the reindex completes.\n                 if (!fReindex && !LoadGenesisBlock(chainparams)) {\n                     strLoadError = _(\"Error initializing block database\");\n                     break;\n                 }\n \n-                // At this point we're either in reindex or we've loaded a useful\n+                // At this point we are either in reindex or we've loaded a useful\n                 // block tree into mapBlockIndex!\n \n                 pcoinsdbview.reset(new CCoinsViewDB(nCoinDBCache, false, fReset || fReindexChainState));\n@@ -1528,7 +1528,7 @@ bool AppInitMain()\n                 }\n \n                 if (!fReset) {\n-                    // Note that RewindBlockIndex MUST run even if we're about to -reindex-chainstate.\n+                    // Note that RewindBlockIndex MUST run even if we are about to -reindex-chainstate.\n                     // It both disconnects blocks based on chainActive, and drops block data in\n                     // mapBlockIndex based on lack of available witness data.\n                     uiInterface.InitMessage(_(\"Rewinding blocks...\"));"
      },
      {
        "sha": "424f9db0df8fd7b1c991d4d355a7b77cf5079f83",
        "filename": "src/keystore.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/keystore.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/keystore.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/keystore.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -19,7 +19,7 @@ void CBasicKeyStore::ImplicitlyLearnRelatedKeyScripts(const CPubKey& pubkey)\n     // P2SH-P2WPKH redeemscript to be present in the wallet in order to accept\n     // payment even to P2WPKH outputs.\n     // Also note that having superfluous scripts in the keystore never hurts.\n-    // They're only used to guide recursion in signing and IsMine logic - if\n+    // They are only used to guide recursion in signing and IsMine logic - if\n     // a script is present but we can't do anything with it, it has no effect.\n     // \"Implicitly\" refers to fact that scripts are derived automatically from\n     // existing keys, and are present in memory, even without being explicitly"
      },
      {
        "sha": "bd77bf8b75c8671e227589a92a924fa2e5a057ae",
        "filename": "src/leveldb/CONTRIBUTING.md",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/CONTRIBUTING.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/CONTRIBUTING.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/CONTRIBUTING.md?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -8,7 +8,7 @@ have to jump a couple of legal hurdles.\n Please fill out either the individual or corporate Contributor License\n Agreement as appropriate.\n \n-* If you are an individual writing original source code and you're sure you\n+* If you are an individual writing original source code and you are sure you\n own the intellectual property, then sign an [individual CLA](https://developers.google.com/open-source/cla/individual).\n * If you work for a company that wants to allow you to contribute your work,\n then sign a [corporate CLA](https://developers.google.com/open-source/cla/corporate)."
      },
      {
        "sha": "5446505eb4b33844d75bf7865b7944ee3eb0d536",
        "filename": "src/leveldb/Makefile",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/Makefile",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/Makefile",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/Makefile?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -14,7 +14,7 @@ OPT ?= -O2 -DNDEBUG\n # OPT ?= -O2 -g2 -DNDEBUG\n #-----------------------------------------------\n \n-# detect what platform we're building on\n+# detect what platform we are building on\n $(shell CC=\"$(CC)\" CXX=\"$(CXX)\" TARGET_OS=\"$(TARGET_OS)\" \\\n     ./build_detect_platform build_config.mk ./)\n # this file is generated by the previous line to set build flags and sources"
      },
      {
        "sha": "d3be6b22cf88669744be44dbb82f716c5af17c49",
        "filename": "src/leveldb/build_detect_platform",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/build_detect_platform",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/build_detect_platform",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/build_detect_platform?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -1,6 +1,6 @@\n #!/bin/sh\n #\n-# Detects OS we're compiling on and outputs a file specified by the first\n+# Detects OS we are compiling on and outputs a file specified by the first\n # argument, which in turn gets read while processing Makefile.\n #\n # The output will set the following variables:"
      },
      {
        "sha": "7da02080f56b09689973e1532a0819c90c72a631",
        "filename": "src/leveldb/db/db_impl.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/db/db_impl.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/db/db_impl.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/db_impl.cc?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -903,7 +903,7 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n     compact->smallest_snapshot = snapshots_.oldest()->number_;\n   }\n \n-  // Release mutex while we're actually doing the compaction work\n+  // Release mutex while we are actually doing the compaction work\n   mutex_.Unlock();\n \n   Iterator* input = versions_->MakeInputIterator(compact->compaction);"
      },
      {
        "sha": "cdd7b06e26b641f5598608e00af7b086ed9a2dac",
        "filename": "src/leveldb/db/log_reader.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/db/log_reader.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/db/log_reader.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/log_reader.cc?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -67,7 +67,7 @@ bool Reader::ReadRecord(Slice* record, std::string* scratch) {\n   scratch->clear();\n   record->clear();\n   bool in_fragmented_record = false;\n-  // Record offset of the logical record that we're reading\n+  // Record offset of the logical record that we are reading\n   // 0 is a dummy value to make compilers happy\n   uint64_t prospective_record_offset = 0;\n "
      },
      {
        "sha": "e99847b1f29c2efd68ee36f8ba5a7fab25f79fc5",
        "filename": "src/leveldb/db/version_set.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/db/version_set.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/db/version_set.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/version_set.cc?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -1489,7 +1489,7 @@ bool Compaction::IsBaseLevelForKey(const Slice& user_key) {\n     for (; level_ptrs_[lvl] < files.size(); ) {\n       FileMetaData* f = files[level_ptrs_[lvl]];\n       if (user_cmp->Compare(user_key, f->largest.user_key()) <= 0) {\n-        // We've advanced far enough\n+        // We have advanced far enough\n         if (user_cmp->Compare(user_key, f->smallest.user_key()) >= 0) {\n           // Key falls in this file's range, so definitely not base level\n           return false;"
      },
      {
        "sha": "8b2034f63b271841d53f18f3c3b0d6f153f533ec",
        "filename": "src/leveldb/doc/benchmark.html",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/doc/benchmark.html",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/doc/benchmark.html",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/doc/benchmark.html?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -413,7 +413,7 @@ <h4>Random Reads</h4>\n database.</p>\n \n <h3>B. No Compression Reads </h3>\n-<p>For this benchmark, we populated a database with 1 million entries consisting of 16 byte keys and 100 byte values. We compiled LevelDB and Kyoto Cabinet without compression support, so results that are read out from the database are already uncompressed. We've listed the SQLite3 baseline read performance as a point of comparison.</p>\n+<p>For this benchmark, we populated a database with 1 million entries consisting of 16 byte keys and 100 byte values. We compiled LevelDB and Kyoto Cabinet without compression support, so results that are read out from the database are already uncompressed. We have listed the SQLite3 baseline read performance as a point of comparison.</p>\n <h4>Sequential Reads</h4>\n <table class=\"bn\">\n <tr><td class=\"c1\">LevelDB</td>"
      },
      {
        "sha": "6576114d8cd8c9c5e6f2a5b24c297b57d9ac26c6",
        "filename": "src/leveldb/table/table.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/table/table.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/leveldb/table/table.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/table.cc?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -69,7 +69,7 @@ Status Table::Open(const Options& options,\n   }\n \n   if (s.ok()) {\n-    // We have successfully read the footer and the index block: we're\n+    // We have successfully read the footer and the index block: we are\n     // ready to serve requests.\n     Rep* rep = new Table::Rep;\n     rep->options = options;"
      },
      {
        "sha": "c2d3f0030293d5b30294a0232369506d42c3b954",
        "filename": "src/miner.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/miner.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/miner.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/miner.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -339,7 +339,7 @@ void BlockAssembler::addPackageTxs(int &nPackagesSelected, int &nDescendantsUpda\n \n         modtxscoreiter modit = mapModifiedTx.get<ancestor_score>().begin();\n         if (mi == mempool.mapTx.get<ancestor_score>().end()) {\n-            // We're out of entries in mapTx; use the entry from mapModifiedTx\n+            // We are out of entries in mapTx; use the entry from mapModifiedTx\n             iter = modit->iter;\n             fUsingModified = true;\n         } else {\n@@ -390,7 +390,7 @@ void BlockAssembler::addPackageTxs(int &nPackagesSelected, int &nDescendantsUpda\n \n             if (nConsecutiveFailed > MAX_CONSECUTIVE_FAILURES && nBlockWeight >\n                     nBlockMaxWeight - 4000) {\n-                // Give up if we're close to full and haven't succeeded in a while\n+                // Give up if we are close to full and haven't succeeded in a while\n                 break;\n             }\n             continue;"
      },
      {
        "sha": "3c8562ae44114d62dbbf2f58963f2a7bea27b98c",
        "filename": "src/miner.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/miner.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/miner.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/miner.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -179,7 +179,7 @@ class BlockAssembler\n     bool TestPackage(uint64_t packageSize, int64_t packageSigOpsCost) const;\n     /** Perform checks on each transaction in a package:\n       * locktime, premature-witness, serialized size (if necessary)\n-      * These checks should always succeed, and they're here\n+      * These checks should always succeed, and they are here\n       * only as an extra check in case of suboptimal node configuration */\n     bool TestPackageTransactions(const CTxMemPool::setEntries& package);\n     /** Return true if given transaction from mapTx has already been evaluated,"
      },
      {
        "sha": "32bcf09cec3cb737e474c6de15de67c8b735a9e0",
        "filename": "src/net.cpp",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/net.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/net.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -1726,7 +1726,7 @@ void CConnman::SetTryNewOutboundPeer(bool flag)\n // Exclude peers that are marked for disconnect, or are going to be\n // disconnected soon (eg one-shots and feelers)\n // Also exclude peers that haven't finished initial connection handshake yet\n-// (so that we don't decide we're over our desired connection limit, and then\n+// (so that we don't decide we are over our desired connection limit, and then\n // evict some peer that has finished the handshake)\n int CConnman::GetExtraOutboundCount()\n {\n@@ -1808,7 +1808,7 @@ void CConnman::ThreadOpenConnections(const std::vector<std::string> connect)\n                     // Netgroups for inbound and addnode peers are not excluded because our goal here\n                     // is to not use multiple of our limited outbound slots on a single netgroup\n                     // but inbound and addnode peers do not use our outbound slots.  Inbound peers\n-                    // also have the added issue that they're attacker controlled and could be used\n+                    // also have the added issue that they are attacker controlled and could be used\n                     // to prevent us from connecting to particular hosts if we used them here.\n                     setConnected.insert(pnode->addr.GetGroup());\n                     nOutbound++;\n@@ -2786,7 +2786,7 @@ void CNode::AskFor(const CInv& inv)\n     if (!setAskFor.insert(inv.hash).second)\n         return;\n \n-    // We're using mapAskFor as a priority queue,\n+    // We are using mapAskFor as a priority queue,\n     // the key is the earliest time the request can be sent\n     int64_t nRequestTime;\n     limitedmap<uint256, int64_t>::const_iterator it = mapAlreadyAskedFor.find(inv.hash);"
      },
      {
        "sha": "c7a568471c5213171dcc1b6c81bae7b9f353982c",
        "filename": "src/net.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/net.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/net.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -722,7 +722,7 @@ class CNode\n     std::atomic<int64_t> nLastTXTime;\n \n     // Ping time measurement:\n-    // The pong reply we're expecting, or 0 if no pong expected.\n+    // The pong reply we are expecting, or 0 if no pong expected.\n     std::atomic<uint64_t> nPingNonceSent;\n     // Time (in usec) the last ping was sent, or 0 if no ping was ever sent.\n     std::atomic<int64_t> nPingUsecStart;"
      },
      {
        "sha": "e9c8d5769083f281219e7c3643d02317e13fd265",
        "filename": "src/net_processing.cpp",
        "status": "modified",
        "additions": 24,
        "deletions": 24,
        "changes": 48,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/net_processing.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/net_processing.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -143,7 +143,7 @@ namespace {\n     /** Number of preferable block download peers. */\n     int nPreferredDownload GUARDED_BY(cs_main) = 0;\n \n-    /** Number of peers from which we're downloading blocks. */\n+    /** Number of peers from which we are downloading blocks. */\n     int nPeersWithValidatedDownloads GUARDED_BY(cs_main) = 0;\n \n     /** Number of outbound peers with m_chain_sync.m_protect. */\n@@ -185,7 +185,7 @@ struct CBlockReject {\n  * Maintain validation-specific state about nodes, protected by cs_main, instead\n  * by CNode's own locks. This simplifies asynchronous operation, where\n  * processing of incoming data is done after the ProcessMessage call returns,\n- * and we're no longer holding the node's locks.\n+ * and we are no longer holding the node's locks.\n  */\n struct CNodeState {\n     //! The peer's address\n@@ -214,7 +214,7 @@ struct CNodeState {\n     bool fSyncStarted;\n     //! When to potentially disconnect peer for stalling headers download\n     int64_t nHeadersSyncTimeout;\n-    //! Since when we're stalling block download progress (in microseconds), or 0.\n+    //! Since when we are stalling block download progress (in microseconds), or 0.\n     int64_t nStallingSince;\n     std::list<QueuedBlock> vBlocksInFlight;\n     //! When the first entry in vBlocksInFlight started downloading. Don't care when vBlocksInFlight is empty.\n@@ -389,7 +389,7 @@ static bool MarkBlockAsInFlight(NodeId nodeid, const uint256& hash, const CBlock\n     state->nBlocksInFlight++;\n     state->nBlocksInFlightValidHeaders += it->fValidatedHeaders;\n     if (state->nBlocksInFlight == 1) {\n-        // We're starting a block download (batch) from this peer.\n+        // We are starting a block download (batch) from this peer.\n         state->nDownloadingSince = GetTimeMicros();\n     }\n     if (state->nBlocksInFlightValidHeaders == 1 && pindex != nullptr) {\n@@ -1003,8 +1003,8 @@ void PeerLogicValidation::BlockChecked(const CBlock& block, const CValidationSta\n     }\n     // Check that:\n     // 1. The block is valid\n-    // 2. We're not in initial block download\n-    // 3. This is currently the best block we're aware of. We haven't updated\n+    // 2. We are not in initial block download\n+    // 3. This is currently the best block we are aware of. We haven't updated\n     //    the tip yet so we have no way to check this directly here. Instead we\n     //    just check that there are currently no other blocks in flight.\n     else if (state.IsValid() &&\n@@ -1227,7 +1227,7 @@ void static ProcessGetBlockData(CNode* pfrom, const CChainParams& chainparams, c\n             }\n             else if (inv.type == MSG_CMPCT_BLOCK)\n             {\n-                // If a peer is asking for old blocks, we're almost guaranteed\n+                // If a peer is asking for old blocks, we are almost guaranteed\n                 // they won't have a useful mempool to match against a compact block,\n                 // and we don't feel like constructing the object for them, so\n                 // instead we respond with the full, non-compact block.\n@@ -1499,8 +1499,8 @@ bool static ProcessHeadersMessage(CNode *pfrom, CConnman *connman, const std::ve\n                 }\n                 pindexWalk = pindexWalk->pprev;\n             }\n-            // If pindexWalk still isn't on our main chain, we're looking at a\n-            // very large reorg at a time we think we're close to caught up to\n+            // If pindexWalk still isn't on our main chain, we are looking at a\n+            // very large reorg at a time we think we are close to caught up to\n             // the main chain -- this shouldn't really happen.  Bail out on the\n             // direct fetch and rely on parallel download instead.\n             if (!chainActive.Contains(pindexWalk)) {\n@@ -1534,7 +1534,7 @@ bool static ProcessHeadersMessage(CNode *pfrom, CConnman *connman, const std::ve\n                 }\n             }\n         }\n-        // If we're in IBD, we want outbound peers that will serve us a useful\n+        // If we are in IBD, we want outbound peers that will serve us a useful\n         // chain. Disconnect peers that are on chains with insufficient work.\n         if (IsInitialBlockDownload() && nCount != MAX_HEADERS_RESULTS) {\n             // When nCount < MAX_HEADERS_RESULTS, we know we have no more\n@@ -2061,7 +2061,7 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n             pfrom->PushInventory(CInv(MSG_BLOCK, pindex->GetBlockHash()));\n             if (--nLimit <= 0)\n             {\n-                // When this block is requested, we'll send an inv that'll\n+                // When this block is requested, we will send an inv that'll\n                 // trigger the peer to getblocks the next batch of inventory.\n                 LogPrint(BCLog::NET, \"  getblocks stopping at limit %d %s\\n\", pindex->nHeight, pindex->GetBlockHash().ToString());\n                 pfrom->hashContinue = pindex->GetBlockHash();\n@@ -2108,7 +2108,7 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n             inv.type = State(pfrom->GetId())->fWantsCmpctWitness ? MSG_WITNESS_BLOCK : MSG_BLOCK;\n             inv.hash = req.blockhash;\n             pfrom->vRecvGetData.push_back(inv);\n-            // The message processing loop will go around again (without pausing) and we'll respond then (without cs_main)\n+            // The message processing loop will go around again (without pausing) and we will respond then (without cs_main)\n             return true;\n         }\n \n@@ -2459,7 +2459,7 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n             return true;\n         }\n \n-        // If we're not close to tip yet, give up and let parallel block fetch work its magic\n+        // If we are not close to tip yet, give up and let parallel block fetch work its magic\n         if (!fAlreadyInFlight && !CanDirectFetch(chainparams.GetConsensus()))\n             return true;\n \n@@ -2571,7 +2571,7 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n             // our anti-DoS protections in AcceptBlock, which filters\n             // unrequested blocks that might be trying to waste our resources\n             // (eg disk space). Because we only try to reconstruct blocks when\n-            // we're close to caught up (via the CanDirectFetch() requirement\n+            // we are close to caught up (via the CanDirectFetch() requirement\n             // above, combined with the behavior of not requesting blocks until\n             // we have a chain with at least nMinimumChainWork), and we ignore\n             // compact blocks with less work than our tip, it is safe to treat\n@@ -3100,7 +3100,7 @@ void PeerLogicValidation::ConsiderEviction(CNode *pto, int64_t time_in_seconds)\n                 state.m_chain_sync.m_sent_getheaders = false;\n             }\n         } else if (state.m_chain_sync.m_timeout == 0 || (state.m_chain_sync.m_work_header != nullptr && state.pindexBestKnownBlock != nullptr && state.pindexBestKnownBlock->nChainWork >= state.m_chain_sync.m_work_header->nChainWork)) {\n-            // Our best block known by this peer is behind our tip, and we're either noticing\n+            // Our best block known by this peer is behind our tip, and we are either noticing\n             // that for the first time, OR this peer was able to catch up to some earlier point\n             // where we checked against our tip.\n             // Either way, set a new timeout based on current tip.\n@@ -3112,7 +3112,7 @@ void PeerLogicValidation::ConsiderEviction(CNode *pto, int64_t time_in_seconds)\n             // of our tip, when we first detected it was behind. Send a single getheaders\n             // message to give the peer a chance to update us.\n             if (state.m_chain_sync.m_sent_getheaders) {\n-                // They've run out of time to catch up!\n+                // They have run out of time to catch up!\n                 LogPrintf(\"Disconnecting outbound peer %d for old chain, best known block = %s\\n\", pto->GetId(), state.pindexBestKnownBlock != nullptr ? state.pindexBestKnownBlock->GetBlockHash().ToString() : \"<none>\");\n                 pto->fDisconnect = true;\n             } else {\n@@ -3167,7 +3167,7 @@ void PeerLogicValidation::EvictExtraOutboundPeers(int64_t time_in_seconds)\n                 // Only disconnect a peer that has been connected to us for\n                 // some reasonable fraction of our check-frequency, to give\n                 // it time for new information to have arrived.\n-                // Also don't disconnect any peer we're trying to download a\n+                // Also don't disconnect any peer we are trying to download a\n                 // block from.\n                 CNodeState &state = *State(pnode->GetId());\n                 if (time_in_seconds - pnode->nTimeConnected > MINIMUM_CONNECT_TIME && state.nBlocksInFlight == 0) {\n@@ -3321,7 +3321,7 @@ bool PeerLogicValidation::SendMessages(CNode* pto)\n             pindexBestHeader = chainActive.Tip();\n         bool fFetch = state.fPreferredDownload || (nPreferredDownload == 0 && !pto->fClient && !pto->fOneShot); // Download if this is a nice peer, or we have no nice peers and this one might do.\n         if (!state.fSyncStarted && !pto->fClient && !fImporting && !fReindex) {\n-            // Only actively request headers from a single peer, unless we're close to today.\n+            // Only actively request headers from a single peer, unless we are close to today.\n             if ((nSyncStarted == 0 && fFetch) || pindexBestHeader->GetBlockTime() > GetAdjustedTime() - 24 * 60 * 60) {\n                 state.fSyncStarted = true;\n                 state.nHeadersSyncTimeout = GetTimeMicros() + HEADERS_DOWNLOAD_TIMEOUT_BASE + HEADERS_DOWNLOAD_TIMEOUT_PER_HEADER * (GetAdjustedTime() - pindexBestHeader->GetBlockTime())/(consensusParams.nPowTargetSpacing);\n@@ -3354,7 +3354,7 @@ bool PeerLogicValidation::SendMessages(CNode* pto)\n         //\n         {\n             // If we have less than MAX_BLOCKS_TO_ANNOUNCE in our\n-            // list of block hashes we're relaying, and our peer wants\n+            // list of block hashes we are relaying, and our peer wants\n             // headers announcements, then find the first header\n             // not yet known to our peer but would connect, and send.\n             // If no header would connect, or if we have too many\n@@ -3418,7 +3418,7 @@ bool PeerLogicValidation::SendMessages(CNode* pto)\n             if (!fRevertToInv && !vHeaders.empty()) {\n                 if (vHeaders.size() == 1 && state.fPreferHeaderAndIDs) {\n                     // We only send up to 1 block as header-and-ids, as otherwise\n-                    // probably means we're doing an initial-ish-sync or they're slow\n+                    // probably means we are doing an initial-ish-sync or they are slow\n                     LogPrint(BCLog::NET, \"%s sending header-and-ids %s to peer=%d\\n\", __func__,\n                             vHeaders.front().GetHash().ToString(), pto->GetId());\n \n@@ -3469,7 +3469,7 @@ bool PeerLogicValidation::SendMessages(CNode* pto)\n                     const CBlockIndex* pindex = LookupBlockIndex(hashToAnnounce);\n                     assert(pindex);\n \n-                    // Warn if we're announcing a block that is not on the main chain.\n+                    // Warn if we are announcing a block that is not on the main chain.\n                     // This should be very rare and could be optimized out.\n                     // Just log for now.\n                     if (chainActive[pindex->nHeight] != pindex) {\n@@ -3626,7 +3626,7 @@ bool PeerLogicValidation::SendMessages(CNode* pto)\n         if (!vInv.empty())\n             connman->PushMessage(pto, msgMaker.Make(NetMsgType::INV, vInv));\n \n-        // Detect whether we're stalling\n+        // Detect whether we are stalling\n         nNow = GetTimeMicros();\n         if (state.nStallingSince && state.nStallingSince < nNow - 1000000 * BLOCK_STALLING_TIMEOUT) {\n             // Stalling only triggers when the block download window cannot move. During normal steady state,\n@@ -3637,7 +3637,7 @@ bool PeerLogicValidation::SendMessages(CNode* pto)\n             return true;\n         }\n         // In case there is a block that has been in flight from this peer for 2 + 0.5 * N times the block interval\n-        // (with N the number of peers from which we're downloading validated blocks), disconnect due to timeout.\n+        // (with N the number of peers from which we are downloading validated blocks), disconnect due to timeout.\n         // We compensate for other peers to prevent killing off peers due to our own downstream link\n         // being saturated. We only count validated in-flight blocks so peers can't advertise non-existing block hashes\n         // to unreasonably increase our timeout.\n@@ -3726,7 +3726,7 @@ bool PeerLogicValidation::SendMessages(CNode* pto)\n                     vGetData.clear();\n                 }\n             } else {\n-                //If we're not going to ask, don't expect a response.\n+                //If we are not going to ask, don't expect a response.\n                 pto->setAskFor.erase(inv.hash);\n             }\n             pto->mapAskFor.erase(pto->mapAskFor.begin());"
      },
      {
        "sha": "630b68b59da51b374062390d404a6078c10151ab",
        "filename": "src/net_processing.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/net_processing.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/net_processing.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -60,7 +60,7 @@ class PeerLogicValidation final : public CValidationInterface, public NetEventsI\n     */\n     bool SendMessages(CNode* pto) override EXCLUSIVE_LOCKS_REQUIRED(pto->cs_sendProcessing);\n \n-    /** Consider evicting an outbound peer based on the amount of time they've been behind our tip */\n+    /** Consider evicting an outbound peer based on the amount of time they have been behind our tip */\n     void ConsiderEviction(CNode *pto, int64_t time_in_seconds) EXCLUSIVE_LOCKS_REQUIRED(cs_main);\n     /** Evict extra outbound peers. If we think our tip may be stale, connect to an extra outbound */\n     void CheckForStaleTipAndEvictPeers(const Consensus::Params &consensusParams);"
      },
      {
        "sha": "02256c2ea3ca01f5115f081899506241e3ab04a3",
        "filename": "src/policy/feerate.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/policy/feerate.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/policy/feerate.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/policy/feerate.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -26,7 +26,7 @@ class CFeeRate\n     CFeeRate() : nSatoshisPerK(0) { }\n     template<typename I>\n     CFeeRate(const I _nSatoshisPerK): nSatoshisPerK(_nSatoshisPerK) {\n-        // We've previously had bugs creep in from silent double->int conversion...\n+        // We have previously had bugs creep in from silent double->int conversion...\n         static_assert(std::is_integral<I>::value, \"CFeeRate should be used without floats\");\n     }\n     /** Constructor for a fee rate in satoshis per kB. The size in bytes must not exceed (2^63 - 1)*/"
      },
      {
        "sha": "a45983150a01350855bc165487cc7d8564727eff",
        "filename": "src/policy/fees.cpp",
        "status": "modified",
        "additions": 8,
        "deletions": 8,
        "changes": 16,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/policy/fees.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/policy/fees.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/policy/fees.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -158,7 +158,7 @@ class TxConfirmStats\n                              double minSuccess, bool requireGreater, unsigned int nBlockHeight,\n                              EstimationResult *result = nullptr) const;\n \n-    /** Return the max number of confirms we're tracking */\n+    /** Return the max number of confirms we are tracking */\n     unsigned int GetMaxConfirms() const { return scale * confAvg.size(); }\n \n     /** Write state of estimation data to a file*/\n@@ -265,7 +265,7 @@ double TxConfirmStats::EstimateMedianVal(int confTarget, double sufficientTxVal,\n     // The near and far variables will define the range we've combined\n     // The best variables are the last range we saw which still had a high\n     // enough confirmation rate to count as success.\n-    // The cur variables are the current range we're counting.\n+    // The cur variables are the current range we are counting.\n     unsigned int curNearBucket = startbucket;\n     unsigned int bestNearBucket = startbucket;\n     unsigned int curFarBucket = startbucket;\n@@ -352,7 +352,7 @@ double TxConfirmStats::EstimateMedianVal(int confTarget, double sufficientTxVal,\n         for (unsigned int j = minBucket; j <= maxBucket; j++) {\n             if (txCtAvg[j] < txSum)\n                 txSum -= txCtAvg[j];\n-            else { // we're in the right bucket\n+            else { // we are in the right bucket\n                 median = avg[j] / txCtAvg[j];\n                 break;\n             }\n@@ -559,14 +559,14 @@ void CBlockPolicyEstimator::processTransaction(const CTxMemPoolEntry& entry, boo\n \n     if (txHeight != nBestSeenHeight) {\n         // Ignore side chains and re-orgs; assuming they are random they don't\n-        // affect the estimate.  We'll potentially double count transactions in 1-block reorgs.\n+        // affect the estimate.  We will potentially double count transactions in 1-block reorgs.\n         // Ignore txs if BlockPolicyEstimator is not in sync with chainActive.Tip().\n         // It will be synced next time a block is processed.\n         return;\n     }\n \n     // Only want to be updating estimates when our blockchain is synced,\n-    // otherwise we'll miscalculate how many blocks its taking to get included.\n+    // otherwise we will miscalculate how many blocks its taking to get included.\n     if (!validFeeEstimate) {\n         untrackedTxs++;\n         return;\n@@ -620,7 +620,7 @@ void CBlockPolicyEstimator::processBlock(unsigned int nBlockHeight,\n         // Ignore side chains and re-orgs; assuming they are random\n         // they don't affect the estimate.\n         // And if an attacker can re-org the chain at will, then\n-        // you've got much bigger problems than \"attacker can influence\n+        // you have got much bigger problems than \"attacker can influence\n         // transaction fees.\"\n         return;\n     }\n@@ -694,7 +694,7 @@ CFeeRate CBlockPolicyEstimator::estimateRawFee(int confTarget, double successThr\n     }\n \n     LOCK(cs_feeEstimator);\n-    // Return failure if trying to analyze a target we're not tracking\n+    // Return failure if trying to analyze a target we are not tracking\n     if (confTarget <= 0 || (unsigned int)confTarget > stats->GetMaxConfirms())\n         return CFeeRate(0);\n     if (successThreshold > 1)\n@@ -829,7 +829,7 @@ CFeeRate CBlockPolicyEstimator::estimateSmartFee(int confTarget, FeeCalculation\n     double median = -1;\n     EstimationResult tempResult;\n \n-    // Return failure if trying to analyze a target we're not tracking\n+    // Return failure if trying to analyze a target we are not tracking\n     if (confTarget <= 0 || (unsigned int)confTarget > longStats->GetMaxConfirms()) {\n         return CFeeRate(0);  // error condition\n     }"
      },
      {
        "sha": "6a3f483eb473be2bc38a6d4985da30f99b916c66",
        "filename": "src/policy/policy.h",
        "status": "modified",
        "additions": 4,
        "deletions": 4,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/policy/policy.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/policy/policy.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/policy/policy.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -20,13 +20,13 @@ class CTxOut;\n static const unsigned int DEFAULT_BLOCK_MAX_WEIGHT = MAX_BLOCK_WEIGHT - 4000;\n /** Default for -blockmintxfee, which sets the minimum feerate for a transaction in blocks created by mining code **/\n static const unsigned int DEFAULT_BLOCK_MIN_TX_FEE = 1000;\n-/** The maximum weight for transactions we're willing to relay/mine */\n+/** The maximum weight for transactions we are willing to relay/mine */\n static const unsigned int MAX_STANDARD_TX_WEIGHT = 400000;\n-/** The minimum non-witness size for transactions we're willing to relay/mine (1 segwit input + 1 P2WPKH output = 82 bytes) */\n+/** The minimum non-witness size for transactions we are willing to relay/mine (1 segwit input + 1 P2WPKH output = 82 bytes) */\n static const unsigned int MIN_STANDARD_TX_NONWITNESS_SIZE = 82;\n /** Maximum number of signature check operations in an IsStandard() P2SH script */\n static const unsigned int MAX_P2SH_SIGOPS = 15;\n-/** The maximum number of sigops we're willing to relay/mine in a single tx */\n+/** The maximum number of sigops we are willing to relay/mine in a single tx */\n static const unsigned int MAX_STANDARD_TX_SIGOPS_COST = MAX_BLOCK_SIGOPS_COST/5;\n /** Default for -maxmempool, maximum megabytes of mempool memory usage */\n static const unsigned int DEFAULT_MAX_MEMPOOL_SIZE = 300;\n@@ -87,7 +87,7 @@ bool IsStandard(const CScript& scriptPubKey, txnouttype& whichType);\n bool IsStandardTx(const CTransaction& tx, std::string& reason);\n     /**\n      * Check for standard transaction types\n-     * @param[in] mapInputs    Map of previous transactions that have outputs we're spending\n+     * @param[in] mapInputs    Map of previous transactions that have outputs we are spending\n      * @return True if all inputs (scriptSigs) use only standard transaction forms\n      */\n bool AreInputsStandard(const CTransaction& tx, const CCoinsViewCache& mapInputs);"
      },
      {
        "sha": "cbf39044e371a812684f3fa1ed311c62cc0343b2",
        "filename": "src/qt/addresstablemodel.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/qt/addresstablemodel.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/qt/addresstablemodel.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/qt/addresstablemodel.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -272,7 +272,7 @@ bool AddressTableModel::setData(const QModelIndex &index, const QVariant &value,\n                 editStatus = DUPLICATE_ADDRESS;\n                 return false;\n             }\n-            // Double-check that we're not overwriting a receiving address\n+            // Double-check that we are not overwriting a receiving address\n             else if(rec->type == AddressTableEntry::Sending)\n             {\n                 // Remove old entry"
      },
      {
        "sha": "eefcd80eb7fc656422e558f68b22e161cbc46113",
        "filename": "src/rpc/mining.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/rpc/mining.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/rpc/mining.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/rpc/mining.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -71,7 +71,7 @@ static UniValue GetNetworkHashPS(int lookup, int height) {\n         maxTime = std::max(time, maxTime);\n     }\n \n-    // In case there's a situation where minTime == maxTime, we don't want a divide by zero exception.\n+    // In case there is a situation where minTime == maxTime, we don't want a divide by zero exception.\n     if (minTime == maxTime)\n         return 0;\n "
      },
      {
        "sha": "a8716d8548b68bf1fde3a3b4361e62f09a8b8154",
        "filename": "src/rpc/misc.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/rpc/misc.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/rpc/misc.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/rpc/misc.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -264,7 +264,7 @@ static UniValue setmocktime(const JSONRPCRequest& request)\n     if (!Params().MineBlocksOnDemand())\n         throw std::runtime_error(\"setmocktime for regression testing (-regtest mode) only\");\n \n-    // For now, don't change mocktime if we're in the middle of validation, as\n+    // For now, don't change mocktime if we are in the middle of validation, as\n     // this could have an effect on mempool time-based eviction, as well as\n     // IsCurrentForFeeEstimation() and IsInitialBlockDownload().\n     // TODO: figure out the right way to synchronize around mocktime, and"
      },
      {
        "sha": "b1a84861c0cbfb1fc2a19bde43c07ec0632eb6da",
        "filename": "src/rpc/net.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/rpc/net.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/rpc/net.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/rpc/net.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -98,7 +98,7 @@ static UniValue getpeerinfo(const JSONRPCRequest& request)\n             \"    \\\"synced_headers\\\": n,       (numeric) The last header we have in common with this peer\\n\"\n             \"    \\\"synced_blocks\\\": n,        (numeric) The last block we have in common with this peer\\n\"\n             \"    \\\"inflight\\\": [\\n\"\n-            \"       n,                        (numeric) The heights of blocks we're currently asking from this peer\\n\"\n+            \"       n,                        (numeric) The heights of blocks we are currently asking from this peer\\n\"\n             \"       ...\\n\"\n             \"    ],\\n\"\n             \"    \\\"whitelisted\\\": true|false, (boolean) Whether the peer is whitelisted\\n\"\n@@ -298,7 +298,7 @@ static UniValue getaddednodeinfo(const JSONRPCRequest& request)\n             \"    \\\"connected\\\" : true|false,          (boolean) If connected\\n\"\n             \"    \\\"addresses\\\" : [                    (list of objects) Only when connected = true\\n\"\n             \"       {\\n\"\n-            \"         \\\"address\\\" : \\\"192.168.0.201:8333\\\",  (string) The bitcoin server IP and port we're connected to\\n\"\n+            \"         \\\"address\\\" : \\\"192.168.0.201:8333\\\",  (string) The bitcoin server IP and port we are connected to\\n\"\n             \"         \\\"connected\\\" : \\\"outbound\\\"           (string) connection, inbound or outbound\\n\"\n             \"       }\\n\"\n             \"     ]\\n\""
      },
      {
        "sha": "e59d1cb3199b0de6588b1b4779ecec4dbd36d38a",
        "filename": "src/rpc/rawtransaction.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/rpc/rawtransaction.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/rpc/rawtransaction.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/rpc/rawtransaction.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -250,7 +250,7 @@ static UniValue gettxoutproof(const JSONRPCRequest& request)\n     } else {\n         LOCK(cs_main);\n \n-        // Loop through txids and try to find which block they're in. Exit loop once a block is found.\n+        // Loop through txids and try to find which block they are in. Exit loop once a block is found.\n         for (const auto& tx : setTxids) {\n             const Coin& coin = AccessByTxid(*pcoinsTip, tx);\n             if (!coin.IsSpent()) {\n@@ -865,7 +865,7 @@ UniValue SignTransaction(CMutableTransaction& mtx, const UniValue& prevTxsUnival\n         const CAmount& amount = coin.out.nValue;\n \n         SignatureData sigdata = DataFromTransaction(mtx, i, coin.out);\n-        // Only sign SIGHASH_SINGLE if there's a corresponding output:\n+        // Only sign SIGHASH_SINGLE if there is a corresponding output:\n         if (!fHashSingle || (i < mtx.vout.size())) {\n             ProduceSignature(*keystore, MutableTransactionSignatureCreator(&mtx, i, amount, nHashType), prevPubKey, sigdata);\n         }"
      },
      {
        "sha": "7e396145e91afbd2abe39429f68ff15985acbb18",
        "filename": "src/scheduler.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/scheduler.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/scheduler.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/scheduler.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -68,7 +68,7 @@ void CScheduler::serviceQueue()\n                     break; // Exit loop after timeout, it means we reached the time of the event\n             }\n #endif\n-            // If there are multiple threads, the queue can empty while we're waiting (another\n+            // If there are multiple threads, the queue can empty while we are waiting (another\n             // thread may service the task we were waiting on).\n             if (shouldStop() || taskQueue.empty())\n                 continue;"
      },
      {
        "sha": "d6083318a79c118e64715d19abc47166d7bd92b2",
        "filename": "src/scheduler.h",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/scheduler.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/scheduler.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/scheduler.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -61,8 +61,8 @@ class CScheduler\n     // and interrupted using boost::interrupt_thread\n     void serviceQueue();\n \n-    // Tell any threads running serviceQueue to stop as soon as they're\n-    // done servicing whatever task they're currently servicing (drain=false)\n+    // Tell any threads running serviceQueue to stop as soon as they are\n+    // done servicing whatever task they are currently servicing (drain=false)\n     // or when there is no work left to be done (drain=true)\n     void stop(bool drain=false);\n "
      },
      {
        "sha": "7f38b0d727dbb34edf8b01fec8c3f65e64bf3c05",
        "filename": "src/script/interpreter.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/script/interpreter.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/script/interpreter.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/script/interpreter.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -1344,7 +1344,7 @@ bool GenericTransactionSignatureChecker<T>::CheckLockTime(const CScriptNum& nLoc\n     ))\n         return false;\n \n-    // Now that we know we're comparing apples-to-apples, the\n+    // Now that we know we are comparing apples-to-apples, the\n     // comparison is a simple numeric one.\n     if (nLockTime > (int64_t)txTo->nLockTime)\n         return false;\n@@ -1404,7 +1404,7 @@ bool GenericTransactionSignatureChecker<T>::CheckSequence(const CScriptNum& nSeq\n         return false;\n     }\n \n-    // Now that we know we're comparing apples-to-apples, the\n+    // Now that we know we are comparing apples-to-apples, the\n     // comparison is a simple numeric one.\n     if (nSequenceMasked > txToSequenceMasked)\n         return false;"
      },
      {
        "sha": "c46fbfd8e098e82e07de6ded8b7e972ec5ec0c5f",
        "filename": "src/script/script.h",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/script/script.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/script/script.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/script/script.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -225,10 +225,10 @@ class CScriptNum\n             // number of bytes.\n             //\n             // If the most-significant-byte - excluding the sign bit - is zero\n-            // then we're not minimal. Note how this test also rejects the\n+            // then we are not minimal. Note how this test also rejects the\n             // negative-zero encoding, 0x80.\n             if ((vch.back() & 0x7f) == 0) {\n-                // One exception: if there's more than one byte and the most\n+                // One exception: if there is more than one byte and the most\n                 // significant bit of the second-most-significant-byte is set\n                 // it would conflict with the sign bit. An example of this case\n                 // is +-255, which encode to 0xff00 and 0xff80 respectively.\n@@ -482,7 +482,7 @@ class CScript : public CScriptBase\n     CScript& operator<<(const CScript& b)\n     {\n         // I'm not sure if this should push the script or concatenate scripts.\n-        // If there's ever a use for pushing a script onto a script, delete this member fn\n+        // If there is ever a use for pushing a script onto a script, delete this member fn\n         assert(!\"Warning: Pushing a CScript onto a CScript with << is probably not intended, use + to concatenate!\");\n         return *this;\n     }"
      },
      {
        "sha": "8ffddcf2c9f4510f5379f2479437b40765bba6d0",
        "filename": "src/script/sigcache.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/script/sigcache.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/script/sigcache.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/script/sigcache.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -20,7 +20,7 @@ static const int64_t MAX_MAX_SIG_CACHE_SIZE = 16384;\n class CPubKey;\n \n /**\n- * We're hashing a nonce into the entries themselves, so we don't need extra\n+ * We are hashing a nonce into the entries themselves, so we don't need extra\n  * blinding in the set hash computation.\n  *\n  * This may exhibit platform endian dependent behavior but because these are"
      },
      {
        "sha": "a9f94c73ed022b940c432651b93c2f372e99cdd7",
        "filename": "src/script/sign.cpp",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/script/sign.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/script/sign.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/script/sign.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -251,17 +251,17 @@ bool SignPSBTInput(const SigningProvider& provider, const CMutableTransaction& t\n     bool require_witness_sig = false;\n     CTxOut utxo;\n     if (input.non_witness_utxo) {\n-        // If we're taking our information from a non-witness UTXO, verify that it matches the prevout.\n+        // If we are taking our information from a non-witness UTXO, verify that it matches the prevout.\n         if (input.non_witness_utxo->GetHash() != tx.vin[index].prevout.hash) return false;\n         // If both witness and non-witness UTXO are provided, verify that they match. This check shouldn't\n         // matter, as the PSBT deserializer enforces only one of both is provided, and the only way both\n-        // can be present is when they're added simultaneously by FillPSBT (in which case they always match).\n+        // can be present is when they are added simultaneously by FillPSBT (in which case they always match).\n         // Still, check in order to not rely on callers to enforce this.\n         if (!input.witness_utxo.IsNull() && input.non_witness_utxo->vout[tx.vin[index].prevout.n] != input.witness_utxo) return false;\n         utxo = input.non_witness_utxo->vout[tx.vin[index].prevout.n];\n     } else if (!input.witness_utxo.IsNull()) {\n         utxo = input.witness_utxo;\n-        // When we're taking our information from a witness UTXO, we can't verify it is actually data from\n+        // When we are taking our information from a witness UTXO, we can't verify it is actually data from\n         // the output being spent. This is safe in case a witness signature is produced (which includes this\n         // information directly in the hash), but not for non-witness signatures. Remember that we require\n         // a witness signature in this situation."
      },
      {
        "sha": "c98050deb09cd3873cb784d38cfd1396e6430d33",
        "filename": "src/secp256k1/include/secp256k1.h",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/secp256k1/include/secp256k1.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/secp256k1/include/secp256k1.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/secp256k1/include/secp256k1.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -141,7 +141,7 @@ typedef int (*secp256k1_nonce_function)(\n #  define SECP256K1_ARG_NONNULL(_x)\n # endif\n \n-/** All flags' lower 8 bits indicate what they're for. Do not use directly. */\n+/** All flags' lower 8 bits indicate what they are for. Do not use directly. */\n #define SECP256K1_FLAGS_TYPE_MASK ((1 << 8) - 1)\n #define SECP256K1_FLAGS_TYPE_CONTEXT (1 << 0)\n #define SECP256K1_FLAGS_TYPE_COMPRESSION (1 << 1)\n@@ -394,7 +394,7 @@ SECP256K1_API SECP256K1_WARN_UNUSED_RESULT int secp256k1_ecdsa_verify(\n  *  Args: ctx:    a secp256k1 context object\n  *  Out:  sigout: a pointer to a signature to fill with the normalized form,\n  *                or copy if the input was already normalized. (can be NULL if\n- *                you're only interested in whether the input was already\n+ *                you are only interested in whether the input was already\n  *                normalized).\n  *  In:   sigin:  a pointer to a signature to check/normalize (cannot be NULL,\n  *                can be identical to sigout)"
      },
      {
        "sha": "07e612329eaa5beaf986aa501123c4d1dbb49238",
        "filename": "src/streams.h",
        "status": "modified",
        "additions": 5,
        "deletions": 5,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/streams.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/streams.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/streams.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -327,7 +327,7 @@ class CDataStream\n         assert(last - first > 0);\n         if (it == vch.begin() + nReadPos && (unsigned int)(last - first) <= nReadPos)\n         {\n-            // special case for inserting at the front when there's room\n+            // special case for inserting at the front when there is room\n             nReadPos -= (last - first);\n             memcpy(&vch[nReadPos], &first[0], last - first);\n         }\n@@ -341,7 +341,7 @@ class CDataStream\n         assert(last - first > 0);\n         if (it == vch.begin() + nReadPos && (unsigned int)(last - first) <= nReadPos)\n         {\n-            // special case for inserting at the front when there's room\n+            // special case for inserting at the front when there is room\n             nReadPos -= (last - first);\n             memcpy(&vch[nReadPos], &first[0], last - first);\n         }\n@@ -615,7 +615,7 @@ class BitStreamWriter\n /** Non-refcounted RAII wrapper for FILE*\n  *\n  * Will automatically close the file when it goes out of scope if not null.\n- * If you're returning the file pointer, return file.release().\n+ * If you are returning the file pointer, return file.release().\n  * If you need to close the file early, use file.fclose() instead of fclose(file).\n  */\n class CAutoFile\n@@ -736,7 +736,7 @@ class CBufferedFile\n     FILE *src;            // source file\n     uint64_t nSrcPos;     // how many bytes have been read from source\n     uint64_t nReadPos;    // how many bytes have been read from this\n-    uint64_t nReadLimit;  // up to which position we're allowed to read\n+    uint64_t nReadLimit;  // up to which position we are allowed to read\n     uint64_t nRewind;     // how many bytes we guarantee to rewind\n     std::vector<char> vchBuf; // the buffer\n \n@@ -786,7 +786,7 @@ class CBufferedFile\n         }\n     }\n \n-    // check whether we're at the end of the source file\n+    // check whether we are at the end of the source file\n     bool eof() const {\n         return nReadPos == nSrcPos && feof(src);\n     }"
      },
      {
        "sha": "563f9ad1b15829d2711422f4fa6e596ee1372e05",
        "filename": "src/support/cleanse.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/support/cleanse.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/support/cleanse.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/support/cleanse.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -33,7 +33,7 @@ void memory_cleanse(void *ptr, size_t len)\n     std::memset(ptr, 0, len);\n \n     /* As best as we can tell, this is sufficient to break any optimisations that\n-       might try to eliminate \"superfluous\" memsets. If there's an easy way to\n+       might try to eliminate \"superfluous\" memsets. If there is an easy way to\n        detect memset_s, it would be better to use that. */\n #if defined(_MSC_VER)\n     SecureZeroMemory(ptr, len);"
      },
      {
        "sha": "2e682719948ab295ab33cd1e4afbe7e66200bcd6",
        "filename": "src/sync.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/sync.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/sync.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/sync.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -174,7 +174,7 @@ void AssertLockNotHeldInternal(const char* pszName, const char* pszFile, int nLi\n void DeleteLock(void* cs)\n {\n     if (!lockdata.available) {\n-        // We're already shutting down.\n+        // We are already shutting down.\n         return;\n     }\n     std::lock_guard<std::mutex> lock(lockdata.dd_mutex);"
      },
      {
        "sha": "a9c0c5be65dd04254f590dead45dbc9534deaddd",
        "filename": "src/test/allocator_tests.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/allocator_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/allocator_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/allocator_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -191,7 +191,7 @@ BOOST_AUTO_TEST_CASE(lockedpool_tests_mock)\n     BOOST_CHECK(a4);\n     void *a5 = pool.alloc(LockedPool::ARENA_SIZE / 2);\n     BOOST_CHECK(a5);\n-    // We've passed a count of three arenas, so this allocation should fail\n+    // We have passed a count of three arenas, so this allocation should fail\n     void *a6 = pool.alloc(16);\n     BOOST_CHECK(!a6);\n "
      },
      {
        "sha": "27bdd04fafb7553e6ff0329ffb65cfb37d291b99",
        "filename": "src/test/coins_tests.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/coins_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/coins_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/coins_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -139,7 +139,7 @@ BOOST_AUTO_TEST_CASE(coins_cache_simulation_test)\n     for (unsigned int i = 0; i < NUM_SIMULATION_ITERATIONS; i++) {\n         // Do a random modification.\n         {\n-            uint256 txid = txids[InsecureRandRange(txids.size())]; // txid we're going to modify in this iteration.\n+            uint256 txid = txids[InsecureRandRange(txids.size())]; // txid we are going to modify in this iteration.\n             Coin& coin = result[COutPoint(txid, 0)];\n \n             // Determine whether to test HaveCoin before or after Access* (or both). As these functions"
      },
      {
        "sha": "2f471e2544b2b101222f55fcbd14c178abea2368",
        "filename": "src/test/dbwrapper_tests.cpp",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/dbwrapper_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/dbwrapper_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/dbwrapper_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -33,7 +33,7 @@ BOOST_AUTO_TEST_CASE(dbwrapper)\n         uint256 in = InsecureRand256();\n         uint256 res;\n \n-        // Ensure that we're doing real obfuscation when obfuscate=true\n+        // Ensure that we are doing real obfuscation when obfuscate=true\n         BOOST_CHECK(obfuscate != is_null_key(dbwrapper_private::GetObfuscateKey(dbw)));\n \n         BOOST_CHECK(dbw.Write(key, in));\n@@ -122,7 +122,7 @@ BOOST_AUTO_TEST_CASE(dbwrapper_iterator)\n // Test that we do not obfuscation if there is existing data.\n BOOST_AUTO_TEST_CASE(existing_data_no_obfuscate)\n {\n-    // We're going to share this fs::path between two wrappers\n+    // We are going to share this fs::path between two wrappers\n     fs::path ph = SetDataDir(\"existing_data_no_obfuscate\");\n     create_directories(ph);\n \n@@ -163,7 +163,7 @@ BOOST_AUTO_TEST_CASE(existing_data_no_obfuscate)\n // Ensure that we start obfuscating during a reindex.\n BOOST_AUTO_TEST_CASE(existing_data_reindex)\n {\n-    // We're going to share this fs::path between two wrappers\n+    // We are going to share this fs::path between two wrappers\n     fs::path ph = SetDataDir(\"existing_data_reindex\");\n     create_directories(ph);\n "
      },
      {
        "sha": "afad8d44d2a9b1648b73b8624ec18b043b6e2c94",
        "filename": "src/test/denialofservice_tests.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/denialofservice_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/denialofservice_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/denialofservice_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -160,7 +160,7 @@ BOOST_AUTO_TEST_CASE(stale_tip_peer_management)\n     }\n \n     // If we add one more peer, something should get marked for eviction\n-    // on the next check (since we're mocking the time to be in the future, the\n+    // on the next check (since we are mocking the time to be in the future, the\n     // required time connected check should be satisfied).\n     AddRandomOutboundPeer(vNodes, *peerLogic);\n "
      },
      {
        "sha": "01a7935d2dd432cae6fa0e3af8ae1326e4dfc172",
        "filename": "src/test/mempool_tests.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/mempool_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/mempool_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/mempool_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -525,7 +525,7 @@ BOOST_AUTO_TEST_CASE(MempoolSizeLimitTest)\n     pool.addUnchecked(entry.Fee(1100LL).FromTx(tx6));\n     pool.addUnchecked(entry.Fee(9000LL).FromTx(tx7));\n \n-    // we only require this to remove, at max, 2 txn, because it's not clear what we're really optimizing for aside from that\n+    // we only require this to remove, at max, 2 txn, because it's not clear what we are really optimizing for aside from that\n     pool.TrimToSize(pool.DynamicMemoryUsage() - 1);\n     BOOST_CHECK(pool.exists(tx4.GetHash()));\n     BOOST_CHECK(pool.exists(tx6.GetHash()));"
      },
      {
        "sha": "e7049d37dca21172b783f0a363c0ea647dd92125",
        "filename": "src/test/rpc_tests.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/rpc_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/rpc_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/rpc_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -70,7 +70,7 @@ BOOST_AUTO_TEST_CASE(rpc_rawparams)\n     BOOST_CHECK_NO_THROW(r = CallRPC(std::string(\"decoderawtransaction \")+rawtx+\" false\"));\n     BOOST_CHECK_THROW(r = CallRPC(std::string(\"decoderawtransaction \")+rawtx+\" false extra\"), std::runtime_error);\n \n-    // Only check failure cases for sendrawtransaction, there's no network to send to...\n+    // Only check failure cases for sendrawtransaction, there is no network to send to...\n     BOOST_CHECK_THROW(CallRPC(\"sendrawtransaction\"), std::runtime_error);\n     BOOST_CHECK_THROW(CallRPC(\"sendrawtransaction null\"), std::runtime_error);\n     BOOST_CHECK_THROW(CallRPC(\"sendrawtransaction DEADBEEF\"), std::runtime_error);"
      },
      {
        "sha": "4253a40e0a86edfe3aca8990f4ec8d7367a5c5eb",
        "filename": "src/test/script_p2sh_tests.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/script_p2sh_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/script_p2sh_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/script_p2sh_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -331,7 +331,7 @@ BOOST_AUTO_TEST_CASE(AreInputsStandard)\n     BOOST_CHECK(SignSignature(keystore, txFrom, txTo, 0, SIGHASH_ALL));\n     BOOST_CHECK(SignSignature(keystore, txFrom, txTo, 1, SIGHASH_ALL));\n     BOOST_CHECK(SignSignature(keystore, txFrom, txTo, 2, SIGHASH_ALL));\n-    // SignSignature doesn't know how to sign these. We're\n+    // SignSignature doesn't know how to sign these. We are\n     // not testing validating signatures, so just create\n     // dummy signatures that DO include the correct P2SH scripts:\n     txTo.vin[3].scriptSig << OP_11 << OP_11 << std::vector<unsigned char>(oneAndTwo.begin(), oneAndTwo.end());"
      },
      {
        "sha": "eaaa3baac5e3aad6919a1b323a6e037cbcf2a657",
        "filename": "src/test/scriptnum10.h",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/scriptnum10.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/scriptnum10.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/scriptnum10.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -45,10 +45,10 @@ class CScriptNum10\n             // number of bytes.\n             //\n             // If the most-significant-byte - excluding the sign bit - is zero\n-            // then we're not minimal. Note how this test also rejects the\n+            // then we are not minimal. Note how this test also rejects the\n             // negative-zero encoding, 0x80.\n             if ((vch.back() & 0x7f) == 0) {\n-                // One exception: if there's more than one byte and the most\n+                // One exception: if there is more than one byte and the most\n                 // significant bit of the second-most-significant-byte is set\n                 // it would conflict with the sign bit. An example of this case\n                 // is +-255, which encode to 0xff00 and 0xff80 respectively."
      },
      {
        "sha": "f2658d011d82ae61dedd52f8efde150db4b36dd7",
        "filename": "src/test/txvalidationcache_tests.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/txvalidationcache_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/txvalidationcache_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/txvalidationcache_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -201,7 +201,7 @@ BOOST_FIXTURE_TEST_CASE(checkinputs_test, TestChain100Setup)\n         BOOST_CHECK(!CheckInputs(spend_tx, state, pcoinsTip.get(), true, SCRIPT_VERIFY_P2SH | SCRIPT_VERIFY_DERSIG, true, true, ptd_spend_tx, nullptr));\n \n         // If we call again asking for scriptchecks (as happens in\n-        // ConnectBlock), we should add a script check object for this -- we're\n+        // ConnectBlock), we should add a script check object for this -- we are\n         // not caching invalidity (if that changes, delete this test case).\n         std::vector<CScriptCheck> scriptchecks;\n         BOOST_CHECK(CheckInputs(spend_tx, state, pcoinsTip.get(), true, SCRIPT_VERIFY_P2SH | SCRIPT_VERIFY_DERSIG, true, true, ptd_spend_tx, &scriptchecks));\n@@ -215,7 +215,7 @@ BOOST_FIXTURE_TEST_CASE(checkinputs_test, TestChain100Setup)\n     }\n \n     // And if we produce a block with this tx, it should be valid (DERSIG not\n-    // enabled yet), even though there's no cache entry.\n+    // enabled yet), even though there is no cache entry.\n     CBlock block;\n \n     block = CreateAndProcessBlock({spend_tx}, p2pk_scriptPubKey);"
      },
      {
        "sha": "2d2d63872cafe3e87282cb8778ff65db41804931",
        "filename": "src/test/util_tests.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/util_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/util_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/util_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -1155,7 +1155,7 @@ BOOST_AUTO_TEST_CASE(test_LockDirectory)\n     thr.join();\n     BOOST_CHECK_EQUAL(threadresult, true);\n #ifndef WIN32\n-    // Try to acquire lock in child process while we're holding it, this should fail.\n+    // Try to acquire lock in child process while we are holding it, this should fail.\n     char ch;\n     BOOST_CHECK_EQUAL(write(fd[1], &LockCommand, 1), 1);\n     BOOST_CHECK_EQUAL(read(fd[1], &ch, 1), 1);"
      },
      {
        "sha": "753ffb41fb43c943d2471e1477f9701885668a86",
        "filename": "src/test/versionbits_tests.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/versionbits_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/test/versionbits_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/versionbits_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -278,7 +278,7 @@ BOOST_AUTO_TEST_CASE(versionbits_computeblockversion)\n     for (int i=1; i<2012; i++) {\n         lastBlock = firstChain.Mine(2016+i, nTime, VERSIONBITS_LAST_OLD_BLOCK_VERSION).Tip();\n         // This works because VERSIONBITS_LAST_OLD_BLOCK_VERSION happens\n-        // to be 4, and the bit we're testing happens to be bit 28.\n+        // to be 4, and the bit we are testing happens to be bit 28.\n         BOOST_CHECK_EQUAL(ComputeBlockVersion(lastBlock, mainnetParams) & (1<<bit), 0);\n     }\n     // Now mine 5 more blocks at the start time -- MTP should not have passed yet, so"
      },
      {
        "sha": "9a6da1da7baadeb09c3787f5733cae6b1ba7c9cd",
        "filename": "src/tinyformat.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/tinyformat.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/tinyformat.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/tinyformat.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -704,7 +704,7 @@ inline const char* streamStateFromFormat(std::ostream& out, bool& spacePadPositi\n     while(*c == 'l' || *c == 'h' || *c == 'L' ||\n           *c == 'j' || *c == 'z' || *c == 't')\n         ++c;\n-    // 5) We're up to the conversion specifier character.\n+    // 5) We are up to the conversion specifier character.\n     // Set stream flags based on conversion specifier (thanks to the\n     // boost::format class for forging the way here).\n     bool intConversion = false;"
      },
      {
        "sha": "22c260c75b02ecbba81dc3b47a6698fbaa1f844a",
        "filename": "src/txmempool.cpp",
        "status": "modified",
        "additions": 6,
        "deletions": 6,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/txmempool.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/txmempool.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/txmempool.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -69,7 +69,7 @@ void CTxMemPool::UpdateForDescendants(txiter updateIt, cacheMap &cachedDescendan\n         for (txiter childEntry : setChildren) {\n             cacheMap::iterator cacheIt = cachedDescendants.find(childEntry);\n             if (cacheIt != cachedDescendants.end()) {\n-                // We've already calculated this one, just add the entries for this set\n+                // We have already calculated this one, just add the entries for this set\n                 // but don't traverse again.\n                 for (txiter cacheEntry : cacheIt->second) {\n                     setAllDescendants.insert(cacheEntry);\n@@ -166,7 +166,7 @@ bool CTxMemPool::CalculateMemPoolAncestors(const CTxMemPoolEntry &entry, setEntr\n             }\n         }\n     } else {\n-        // If we're not searching for parents, we require this to be an\n+        // If we are not searching for parents, we require this to be an\n         // entry in the mempool already.\n         txiter it = mapTx.iterator_to(entry);\n         parentHashes = GetMemPoolParents(it);\n@@ -251,11 +251,11 @@ void CTxMemPool::UpdateForRemoveFromMempool(const setEntries &entriesToRemove, b\n     // transaction\n     const uint64_t nNoLimit = std::numeric_limits<uint64_t>::max();\n     if (updateDescendants) {\n-        // updateDescendants should be true whenever we're not recursively\n+        // updateDescendants should be true whenever we are not recursively\n         // removing a tx and all its descendants, eg when a transaction is\n         // confirmed in a block.\n         // Here we only update statistics and not data in mapLinks (which\n-        // we need to preserve until we're finished with all operations that\n+        // we need to preserve until we are finished with all operations that\n         // need to traverse the mempool).\n         for (txiter removeIt : entriesToRemove) {\n             setEntries setDescendants;\n@@ -285,7 +285,7 @@ void CTxMemPool::UpdateForRemoveFromMempool(const setEntries &entriesToRemove, b\n         // has no children, and in the case of a reorg where that assumption is\n         // false, the in-mempool children aren't linked to the in-block tx's\n         // until UpdateTransactionsFromBlock() is called.\n-        // So if we're being called during a reorg, ie before\n+        // So if we are being called during a reorg, ie before\n         // UpdateTransactionsFromBlock() has been called, then mapLinks[] will\n         // differ from the set of mempool parents we'd calculate by searching,\n         // and it's important that we use the mapLinks[] notion of ancestor\n@@ -388,7 +388,7 @@ void CTxMemPool::addUnchecked(const CTxMemPoolEntry &entry, setEntries &setAnces\n     // children, because such children would be orphans.\n     // An exception to that is if a transaction enters that used to be in a block.\n     // In that case, our disconnect block logic will call UpdateTransactionsFromBlock\n-    // to clean up the mess we're leaving here.\n+    // to clean up the mess we are leaving here.\n \n     // Update ancestors with information about this tx\n     for (const uint256 &phash : setParentTransactions) {"
      },
      {
        "sha": "7d1474e3800efcac96de97cda5fb14f796053c3a",
        "filename": "src/txmempool.h",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/txmempool.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/txmempool.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/txmempool.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -222,7 +222,7 @@ class CompareTxMemPoolEntryByDescendantScore\n         return f1 < f2;\n     }\n \n-    // Return the fee/size we're using for sorting this entry.\n+    // Return the fee/size we are using for sorting this entry.\n     void GetModFeeAndSize(const CTxMemPoolEntry &a, double &mod_fee, double &size) const\n     {\n         // Compare feerate with descendants to feerate of the transaction, and\n@@ -295,7 +295,7 @@ class CompareTxMemPoolEntryByAncestorFee\n         return f1 > f2;\n     }\n \n-    // Return the fee/size we're using for sorting this entry.\n+    // Return the fee/size we are using for sorting this entry.\n     template <typename T>\n     void GetModFeeAndSize(const T &a, double &mod_fee, double &size) const\n     {\n@@ -420,7 +420,7 @@ class SaltedTxidHasher\n  * be descendant transactions of a tx coming from a disconnected block that are\n  * unreachable from just looking at transactions in the mempool (the linking\n  * transactions may also be in the disconnected block, waiting to be added).\n- * Because of this, there's not much benefit in trying to search for in-mempool\n+ * Because of this, there is not much benefit in trying to search for in-mempool\n  * children in addUnchecked().  Instead, in the special case of transactions\n  * being added from a disconnected block, we require the caller to clean up the\n  * state, to account for in-mempool, out-of-block descendants for all the"
      },
      {
        "sha": "02429467d15ca63d6487b7f93c21f0a69e1e1240",
        "filename": "src/univalue/lib/univalue_utffilter.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/univalue/lib/univalue_utffilter.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/univalue/lib/univalue_utffilter.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/univalue/lib/univalue_utffilter.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -69,7 +69,7 @@ class JSONUTF8StringFilter\n                 append_codepoint(codepoint_);\n         }\n     }\n-    // Check that we're in a state where the string can be ended\n+    // Check that we are in a state where the string can be ended\n     // No open sequences, no open surrogate pairs, etc\n     bool finalize()\n     {"
      },
      {
        "sha": "1f79dc06c11d1c2a7db70f8bd2f473fe05af7002",
        "filename": "src/util.cpp",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/util.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/util.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/util.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -160,7 +160,7 @@ bool LockDirectory(const fs::path& directory, const std::string lockfile_name, b\n         return error(\"Error while attempting to lock directory %s: %s\", directory.string(), lock->GetReason());\n     }\n     if (!probe_only) {\n-        // Lock successful and we're not just probing, put it into the map\n+        // Lock successful and we are not just probing, put it into the map\n         dir_locks.emplace(pathLockFile.string(), std::move(lock));\n     }\n     return true;\n@@ -374,7 +374,7 @@ void ArgsManager::WarnForSectionOnlyArgs()\n {\n     LOCK(cs_args);\n \n-    // if there's no section selected, don't worry\n+    // if there is no section selected, don't worry\n     if (m_network.empty()) return;\n \n     // if it's okay to use the default section for this network, don't worry\n@@ -387,7 +387,7 @@ void ArgsManager::WarnForSectionOnlyArgs()\n         found_result = ArgsManagerHelper::GetArgHelper(m_override_args, arg);\n         if (found_result.first) continue;\n \n-        // if there's a network-specific value for this option, it's fine\n+        // if there is a network-specific value for this option, it's fine\n         found_result = ArgsManagerHelper::GetArgHelper(m_config_args, ArgsManagerHelper::NetworkArg(*this, arg));\n         if (found_result.first) continue;\n "
      },
      {
        "sha": "3742c166916a951fb7b8f1a76a3f35b7e2e4b6f2",
        "filename": "src/validation.cpp",
        "status": "modified",
        "additions": 23,
        "deletions": 23,
        "changes": 46,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/validation.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/validation.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/validation.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -263,7 +263,7 @@ namespace {\n     int nLastBlockFile = 0;\n     /** Global flag to indicate we should check to see if there are\n      *  block/undo files that should be deleted.  Set on startup\n-     *  or if we allocate more file space when we're in prune mode\n+     *  or if we allocate more file space when we are in prune mode\n      */\n     bool fCheckForPruning = false;\n \n@@ -332,7 +332,7 @@ bool CheckFinalTx(const CTransaction &tx, int flags)\n     const int nBlockHeight = chainActive.Height() + 1;\n \n     // BIP113 requires that time-locked transactions have nLockTime set to\n-    // less than the median time of the previous block they're contained in.\n+    // less than the median time of the previous block they are contained in.\n     // When the next block is created its previous block will be the current\n     // chain tip, so we use that to calculate the median time passed to\n     // IsFinalTx() if LOCKTIME_MEDIAN_TIME_PAST is set.\n@@ -422,7 +422,7 @@ bool CheckSequenceLocks(const CTransaction &tx, int flags, LockPoints* lp, bool\n             // CheckSequenceLocks to indicate the LockPoints validity\n             int maxInputHeight = 0;\n             for (int height : prevheights) {\n-                // Can ignore mempool inputs since we'll fail if they had non-zero locks\n+                // Can ignore mempool inputs since we will fail if they had non-zero locks\n                 if (height != tip->nHeight+1) {\n                     maxInputHeight = std::max(maxInputHeight, height);\n                 }\n@@ -920,7 +920,7 @@ static bool AcceptToMemoryPoolWorker(const CChainParams& chainparams, CTxMemPool\n         // misses on soft-fork activation.\n         //\n         // This is also useful in case of bugs in the standard flags that cause\n-        // transactions to pass as valid when they're actually invalid. For\n+        // transactions to pass as valid when they are actually invalid. For\n         // instance the STRICTENC flag was incorrectly allowing certain\n         // CHECKSIG NOT scripts to pass, even though they were invalid.\n         //\n@@ -1826,7 +1826,7 @@ bool CChainState::ConnectBlock(const CBlock& block, CValidationState& state, CBl\n     if (!CheckBlock(block, state, chainparams.GetConsensus(), !fJustCheck, !fJustCheck)) {\n         if (state.CorruptionPossible()) {\n             // We don't write down blocks to disk if they may have been\n-            // corrupted, so this should be impossible unless we're having hardware\n+            // corrupted, so this should be impossible unless we are having hardware\n             // problems.\n             return AbortNode(state, \"Corrupt block found indicating potential hardware failure; shutting down\");\n         }\n@@ -1849,7 +1849,7 @@ bool CChainState::ConnectBlock(const CBlock& block, CValidationState& state, CBl\n \n     bool fScriptChecks = true;\n     if (!hashAssumeValid.IsNull()) {\n-        // We've been configured with the hash of a block which has been externally verified to have a valid history.\n+        // We have been configured with the hash of a block which has been externally verified to have a valid history.\n         // A suitable default value is included with the software and updated from time to time.  Because validity\n         //  relative to a piece of software is an objective fact these defaults can be easily reviewed.\n         // This setting doesn't force the selection of any particular chain but makes validating some faster by\n@@ -1896,7 +1896,7 @@ bool CChainState::ConnectBlock(const CBlock& block, CValidationState& state, CBl\n     // time BIP34 activated, in each of the existing pairs the duplicate coinbase had overwritten the first\n     // before the first had been spent.  Since those coinbases are sufficiently buried it's no longer possible to create further\n     // duplicate transactions descending from the known pairs either.\n-    // If we're on the known chain at height greater than where BIP34 activated, we can save the db accesses needed for the BIP30 check.\n+    // If we are on the known chain at height greater than where BIP34 activated, we can save the db accesses needed for the BIP30 check.\n \n     // BIP34 requires that a block at height X (block X) has its coinbase\n     // scriptSig start with a CScriptNum of X (indicated height X).  The above\n@@ -1949,7 +1949,7 @@ bool CChainState::ConnectBlock(const CBlock& block, CValidationState& state, CBl\n     // BIP30 checking again.\n     assert(pindex->pprev);\n     CBlockIndex *pindexBIP34height = pindex->pprev->GetAncestor(chainparams.GetConsensus().BIP34Height);\n-    //Only continue to enforce if we're below BIP34 activation height or the block hash at that height doesn't correspond.\n+    //Only continue to enforce if we are below BIP34 activation height or the block hash at that height doesn't correspond.\n     fEnforceBIP30 = fEnforceBIP30 && (!pindexBIP34height || !(pindexBIP34height->GetBlockHash() == chainparams.GetConsensus().BIP34Hash));\n \n     // TODO: Remove BIP30 checking from block height 1,983,702 on, once we have a\n@@ -2034,7 +2034,7 @@ bool CChainState::ConnectBlock(const CBlock& block, CValidationState& state, CBl\n         if (!tx.IsCoinBase())\n         {\n             std::vector<CScriptCheck> vChecks;\n-            bool fCacheResults = fJustCheck; /* Don't cache results if we're actually connecting blocks (still consult the cache, though) */\n+            bool fCacheResults = fJustCheck; /* Don't cache results if we are actually connecting blocks (still consult the cache, though) */\n             if (!CheckInputs(tx, state, view, fScriptChecks, flags, fCacheResults, fCacheResults, txdata[i], nScriptCheckThreads ? &vChecks : nullptr))\n                 return error(\"ConnectBlock(): CheckInputs on %s failed with %s\",\n                     tx.GetHash().ToString(), FormatStateMessage(state));\n@@ -2088,9 +2088,9 @@ bool CChainState::ConnectBlock(const CBlock& block, CValidationState& state, CBl\n \n /**\n  * Update the on-disk chain state.\n- * The caches and indexes are flushed depending on the mode we're called with\n- * if they're too large, if it's been a while since the last write,\n- * or always and in all cases if we're in prune mode and are deleting files.\n+ * The caches and indexes are flushed depending on the mode we are called with\n+ * if they are too large, if it's been a while since the last write,\n+ * or always and in all cases if we are in prune mode and are deleting files.\n  *\n  * If FlushStateMode::NONE is used, then FlushStateToDisk(...) won't do anything\n  * besides checking if we need to prune.\n@@ -2133,7 +2133,7 @@ bool static FlushStateToDisk(const CChainParams& chainparams, CValidationState &\n         int64_t nMempoolSizeMax = gArgs.GetArg(\"-maxmempool\", DEFAULT_MAX_MEMPOOL_SIZE) * 1000000;\n         int64_t cacheSize = pcoinsTip->DynamicMemoryUsage();\n         int64_t nTotalSpace = nCoinCacheUsage + std::max<int64_t>(nMempoolSizeMax - nMempoolUsage, 0);\n-        // The cache is large and we're within 10% and 10 MiB of the limit, but we have time now (not in the middle of a block processing).\n+        // The cache is large and we are within 10% and 10 MiB of the limit, but we have time now (not in the middle of a block processing).\n         bool fCacheLarge = mode == FlushStateMode::PERIODIC && cacheSize > std::max((9 * nTotalSpace) / 10, nTotalSpace - MAX_BLOCK_COINSDB_USAGE * 1024 * 1024);\n         // The cache is over the limit, we have to write now.\n         bool fCacheCritical = mode == FlushStateMode::IF_NEEDED && cacheSize > nTotalSpace;\n@@ -2516,7 +2516,7 @@ CBlockIndex* CChainState::FindMostWorkChain() {\n                     if (fFailedChain) {\n                         pindexFailed->nStatus |= BLOCK_FAILED_CHILD;\n                     } else if (fMissingData) {\n-                        // If we're missing data, then add back to mapBlocksUnlinked,\n+                        // If we are missing data, then add back to mapBlocksUnlinked,\n                         // so that if the block arrives in the future we can try adding\n                         // to setBlockIndexCandidates again.\n                         mapBlocksUnlinked.insert(std::make_pair(pindexFailed->pprev, pindexFailed));\n@@ -2543,7 +2543,7 @@ void CChainState::PruneBlockIndexCandidates() {\n     while (it != setBlockIndexCandidates.end() && setBlockIndexCandidates.value_comp()(*it, chainActive.Tip())) {\n         setBlockIndexCandidates.erase(it++);\n     }\n-    // Either the current tip or a successor of it we're working towards is left in setBlockIndexCandidates.\n+    // Either the current tip or a successor of it we are working towards is left in setBlockIndexCandidates.\n     assert(!setBlockIndexCandidates.empty());\n }\n \n@@ -2610,7 +2610,7 @@ bool CChainState::ActivateBestChainStep(CValidationState& state, const CChainPar\n             } else {\n                 PruneBlockIndexCandidates();\n                 if (!pindexOldTip || chainActive.Tip()->nChainWork > pindexOldTip->nChainWork) {\n-                    // We're in a better position than we were. Return temporarily to release the lock.\n+                    // We are in a better position than we were. Return temporarily to release the lock.\n                     fContinue = false;\n                     break;\n                 }\n@@ -2665,7 +2665,7 @@ static void NotifyHeaderTip() LOCKS_EXCLUDED(cs_main) {\n  * call may be quite long during reindexing or a substantial reorg.\n  */\n bool CChainState::ActivateBestChain(CValidationState &state, const CChainParams& chainparams, std::shared_ptr<const CBlock> pblock) {\n-    // Note that while we're often called here from ProcessNewBlock, this is\n+    // Note that while we are often called here from ProcessNewBlock, this is\n     // far from a guarantee. Things in the P2P/RPC will often end up calling\n     // us in the middle of ProcessNewBlock - do not assume pblock is set\n     // sanely for performance or correctness!\n@@ -4093,7 +4093,7 @@ bool CChainState::ReplayBlocks(const CChainParams& params, CCoinsView* view)\n     CCoinsViewCache cache(view);\n \n     std::vector<uint256> hashHeads = view->GetHeadBlocks();\n-    if (hashHeads.empty()) return true; // We're already in a consistent state.\n+    if (hashHeads.empty()) return true; // We are already in a consistent state.\n     if (hashHeads.size() != 2) return error(\"ReplayBlocks(): unknown inconsistent state\");\n \n     uiInterface.ShowProgress(_(\"Replaying blocks...\"), 0, false);\n@@ -4178,7 +4178,7 @@ bool CChainState::RewindBlockIndex(const CChainParams& params)\n     while (chainActive.Height() >= nHeight) {\n         if (fPruneMode && !(chainActive.Tip()->nStatus & BLOCK_HAVE_DATA)) {\n             // If pruning, don't try rewinding past the HAVE_DATA point;\n-            // since older blocks can't be served anyway, there's\n+            // since older blocks can't be served anyway, there is\n             // no need to walk further, and trying to DisconnectTip()\n             // will fail (and require a needless reindex/redownload\n             // of the blockchain).\n@@ -4253,7 +4253,7 @@ bool RewindBlockIndex(const CChainParams& params) {\n \n     if (chainActive.Tip() != nullptr) {\n         // FlushStateToDisk can possibly read chainActive. Be conservative\n-        // and skip it here, we're about to -reindex-chainstate anyway, so\n+        // and skip it here, we are about to -reindex-chainstate anyway, so\n         // it'll get called a bunch real soon.\n         CValidationState state;\n         if (!FlushStateToDisk(params, state, FlushStateMode::ALWAYS)) {\n@@ -4326,7 +4326,7 @@ bool CChainState::LoadGenesisBlock(const CChainParams& chainparams)\n {\n     LOCK(cs_main);\n \n-    // Check whether we're already initialized by checking for genesis in\n+    // Check whether we are already initialized by checking for genesis in\n     // mapBlockIndex. Note that we can't use chainActive here, since it is\n     // set based on the coins db, not the block index db, which is the only\n     // thing loaded at this point.\n@@ -4592,7 +4592,7 @@ void CChainState::CheckBlockIndex(const Consensus::Params& consensusParams)\n         if (!(pindex->nStatus & BLOCK_HAVE_DATA)) assert(!foundInUnlinked); // Can't be in mapBlocksUnlinked if we don't HAVE_DATA\n         if (pindexFirstMissing == nullptr) assert(!foundInUnlinked); // We aren't missing data for any parent -- cannot be in mapBlocksUnlinked.\n         if (pindex->pprev && (pindex->nStatus & BLOCK_HAVE_DATA) && pindexFirstNeverProcessed == nullptr && pindexFirstMissing != nullptr) {\n-            // We HAVE_DATA for this block, have received data for all parents at some point, but we're currently missing data for some parent.\n+            // We HAVE_DATA for this block, have received data for all parents at some point, but we are currently missing data for some parent.\n             assert(fHavePruned); // We must have pruned.\n             // This block may have entered mapBlocksUnlinked if:\n             //  - it has a descendant that at some point had more work than the\n@@ -4636,7 +4636,7 @@ void CChainState::CheckBlockIndex(const Consensus::Params& consensusParams)\n             // Find which child we just visited.\n             std::pair<std::multimap<CBlockIndex*,CBlockIndex*>::iterator,std::multimap<CBlockIndex*,CBlockIndex*>::iterator> rangePar = forward.equal_range(pindexPar);\n             while (rangePar.first->second != pindex) {\n-                assert(rangePar.first != rangePar.second); // Our parent must have at least the node we're coming from as child.\n+                assert(rangePar.first != rangePar.second); // Our parent must have at least the node we are coming from as child.\n                 rangePar.first++;\n             }\n             // Proceed to the next one."
      },
      {
        "sha": "10a0f63b6ef4bd78b4399b6746ea7f50fe9aeb99",
        "filename": "src/validation.h",
        "status": "modified",
        "additions": 5,
        "deletions": 5,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/validation.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/validation.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/validation.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -88,10 +88,10 @@ static const unsigned int BLOCK_STALLING_TIMEOUT = 2;\n /** Number of headers sent in one getheaders result. We rely on the assumption that if a peer sends\n  *  less than this number, we reached its tip. Changing this value is a protocol upgrade. */\n static const unsigned int MAX_HEADERS_RESULTS = 2000;\n-/** Maximum depth of blocks we're willing to serve as compact blocks to peers\n+/** Maximum depth of blocks we are willing to serve as compact blocks to peers\n  *  when requested. For older blocks, a regular BLOCK response will be sent. */\n static const int MAX_CMPCTBLOCK_DEPTH = 5;\n-/** Maximum depth of blocks we're willing to respond to GETBLOCKTXN requests for. */\n+/** Maximum depth of blocks we are willing to respond to GETBLOCKTXN requests for. */\n static const int MAX_BLOCKTXN_DEPTH = 10;\n /** Size of the \"block download window\": how far ahead of our current height do we fetch?\n  *  Larger windows tolerate larger download speed differences between peer, but increase the potential\n@@ -185,9 +185,9 @@ static const uint64_t nMinDiskSpace = 52428800;\n /** Pruning-related variables and constants */\n /** True if any block files have ever been pruned. */\n extern bool fHavePruned;\n-/** True if we're running in -prune mode. */\n+/** True if we are running in -prune mode. */\n extern bool fPruneMode;\n-/** Number of MiB of block files that we're trying to stay below. */\n+/** Number of MiB of block files that we are trying to stay below. */\n extern uint64_t nPruneTarget;\n /** Block files containing a block-height within MIN_BLOCKS_TO_KEEP of chainActive.Tip() will not be pruned. */\n static const unsigned int MIN_BLOCKS_TO_KEEP = 288;\n@@ -254,7 +254,7 @@ bool LoadExternalBlockFile(const CChainParams& chainparams, FILE* fileIn, CDiskB\n /** Ensures we have a genesis block in the block tree, possibly writing one to disk. */\n bool LoadGenesisBlock(const CChainParams& chainparams);\n /** Load the block tree and coins database from disk,\n- * initializing state if we're running with -reindex. */\n+ * initializing state if we are running with -reindex. */\n bool LoadBlockIndex(const CChainParams& chainparams) EXCLUSIVE_LOCKS_REQUIRED(cs_main);\n /** Update the chain tip based on database information. */\n bool LoadChainTip(const CChainParams& chainparams);"
      },
      {
        "sha": "5fabf8e32eaa0a46d47ff22dee4c22057a9dd5dd",
        "filename": "src/wallet/crypter.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/crypter.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/crypter.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/wallet/crypter.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -18,7 +18,7 @@ int CCrypter::BytesToKeySHA512AES(const std::vector<unsigned char>& chSalt, cons\n     // This mimics the behavior of openssl's EVP_BytesToKey with an aes256cbc\n     // cipher and sha512 message digest. Because sha512's output size (64b) is\n     // greater than the aes256 block size (16b) + aes256 key size (32b),\n-    // there's no need to process more than once (D_0).\n+    // there is no need to process more than once (D_0).\n \n     if(!count || !key || !iv)\n         return 0;"
      },
      {
        "sha": "741629d45c77a459dd0237a5c49de54a00492465",
        "filename": "src/wallet/rpcdump.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/rpcdump.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/rpcdump.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/wallet/rpcdump.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -1149,7 +1149,7 @@ UniValue importmulti(const JSONRPCRequest& mainRequest)\n             \"      \\\"pubkeys\\\": [\\\"<pubKey>\\\", ... ]                         , (array, optional) Array of strings giving pubkeys that must occur in the output or redeemscript\\n\"\n             \"      \\\"keys\\\": [\\\"<key>\\\", ... ]                               , (array, optional) Array of strings giving private keys whose corresponding public keys must occur in the output or redeemscript\\n\"\n             \"      \\\"internal\\\": <true>                                    , (boolean, optional, default: false) Stating whether matching outputs should be treated as not incoming payments\\n\"\n-            \"      \\\"watchonly\\\": <true>                                   , (boolean, optional, default: false) Stating whether matching outputs should be considered watched even when they're not spendable, only allowed if keys are empty\\n\"\n+            \"      \\\"watchonly\\\": <true>                                   , (boolean, optional, default: false) Stating whether matching outputs should be considered watched even when they are not spendable, only allowed if keys are empty\\n\"\n             \"      \\\"label\\\": <label>                                      , (string, optional, default: '') Label to assign to the address, only allowed with internal=false\\n\"\n             \"    }\\n\"\n             \"  ,...\\n\""
      },
      {
        "sha": "1406d8f6dd9040e4b462927e90914fe04e8a7938",
        "filename": "src/wallet/rpcwallet.cpp",
        "status": "modified",
        "additions": 6,
        "deletions": 6,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/rpcwallet.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/rpcwallet.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/wallet/rpcwallet.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -167,7 +167,7 @@ static UniValue getnewaddress(const JSONRPCRequest& request)\n \n     LOCK(pwallet->cs_wallet);\n \n-    // Parse the label first so we don't generate a key if there's an error\n+    // Parse the label first so we don't generate a key if there is an error\n     std::string label;\n     if (!request.params[0].isNull())\n         label = LabelFromValue(request.params[0]);\n@@ -351,7 +351,7 @@ static UniValue sendtoaddress(const JSONRPCRequest& request)\n             \"3. \\\"comment\\\"            (string, optional) A comment used to store what the transaction is for. \\n\"\n             \"                             This is not part of the transaction, just kept in your wallet.\\n\"\n             \"4. \\\"comment_to\\\"         (string, optional) A comment to store the name of the person or organization \\n\"\n-            \"                             to which you're sending the transaction. This is not part of the \\n\"\n+            \"                             to which you are sending the transaction. This is not part of the \\n\"\n             \"                             transaction, just kept in your wallet.\\n\"\n             \"5. subtractfeefromamount  (boolean, optional, default=false) The fee will be deducted from the amount being sent.\\n\"\n             \"                             The recipient will receive less bitcoins than you enter in the amount field.\\n\"\n@@ -1619,7 +1619,7 @@ static UniValue listsinceblock(const JSONRPCRequest& request)\n             \"    <structure is the same as \\\"transactions\\\" above, only present if include_removed=true>\\n\"\n             \"    Note: transactions that were re-added in the active chain will appear as-is in this array, and may thus have a positive confirmation count.\\n\"\n             \"  ],\\n\"\n-            \"  \\\"lastblock\\\": \\\"lastblockhash\\\"     (string) The hash of the block (target_confirmations-1) from the best block on the main chain. This is typically used to feed back into listsinceblock the next time you call it. So you would generally use a target_confirmations of say 6, so you will be continually re-notified of transactions until they've reached 6 confirmations plus any new ones\\n\"\n+            \"  \\\"lastblock\\\": \\\"lastblockhash\\\"     (string) The hash of the block (target_confirmations-1) from the best block on the main chain. This is typically used to feed back into listsinceblock the next time you call it. So you would generally use a target_confirmations of say 6, so you will be continually re-notified of transactions until they have reached 6 confirmations plus any new ones\\n\"\n             \"}\\n\"\n             \"\\nExamples:\\n\"\n             + HelpExampleCli(\"listsinceblock\", \"\")\n@@ -2514,7 +2514,7 @@ static UniValue loadwallet(const JSONRPCRequest& request)\n     if (fs::symlink_status(wallet_path).type() == fs::file_not_found) {\n         throw JSONRPCError(RPC_WALLET_NOT_FOUND, \"Wallet \" + wallet_file + \" not found.\");\n     } else if (fs::is_directory(wallet_path)) {\n-        // The given filename is a directory. Check that there's a wallet.dat file.\n+        // The given filename is a directory. Check that there is a wallet.dat file.\n         fs::path wallet_dat_file = wallet_path / \"wallet.dat\";\n         if (fs::symlink_status(wallet_dat_file).type() == fs::file_not_found) {\n             throw JSONRPCError(RPC_WALLET_NOT_FOUND, \"Directory \" + wallet_file + \" does not contain a wallet.dat file.\");\n@@ -2574,7 +2574,7 @@ static UniValue createwallet(const JSONRPCRequest& request)\n         throw JSONRPCError(RPC_WALLET_ERROR, \"Wallet \" + wallet_name + \" already exists.\");\n     }\n \n-    // Wallet::Verify will check if we're trying to create a wallet with a duplication name.\n+    // Wallet::Verify will check if we are trying to create a wallet with a duplication name.\n     if (!CWallet::Verify(wallet_name, false, error, warning)) {\n         throw JSONRPCError(RPC_WALLET_ERROR, \"Wallet file verification failed: \" + error);\n     }\n@@ -2636,7 +2636,7 @@ static UniValue unloadwallet(const JSONRPCRequest& request)\n     // The wallet will be destroyed once the last shared pointer is released.\n     wallet->NotifyUnload();\n \n-    // There's no point in waiting for the wallet to unload.\n+    // There is no point in waiting for the wallet to unload.\n     // At this point this method should never fail. The unloading could only\n     // fail due to an unexpected error which would cause a process termination.\n "
      },
      {
        "sha": "935ccc633541f7c1b02fcd93f521d523e5a1ea84",
        "filename": "src/wallet/test/coinselector_tests.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/test/coinselector_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/test/coinselector_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/wallet/test/coinselector_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -306,7 +306,7 @@ BOOST_AUTO_TEST_CASE(knapsack_solver_test)\n \n         // we can't make 38 cents only if we disallow new coins:\n         BOOST_CHECK(!testWallet.SelectCoinsMinConf(38 * CENT, filter_standard, GroupCoins(vCoins), setCoinsRet, nValueRet, coin_selection_params, bnb_used));\n-        // we can't even make 37 cents if we don't allow new coins even if they're from us\n+        // we can't even make 37 cents if we don't allow new coins even if they are from us\n         BOOST_CHECK(!testWallet.SelectCoinsMinConf(38 * CENT, filter_standard_extra, GroupCoins(vCoins), setCoinsRet, nValueRet, coin_selection_params, bnb_used));\n         // but we can make 37 cents if we accept new coins from ourself\n         BOOST_CHECK( testWallet.SelectCoinsMinConf(37 * CENT, filter_standard, GroupCoins(vCoins), setCoinsRet, nValueRet, coin_selection_params, bnb_used));\n@@ -424,7 +424,7 @@ BOOST_AUTO_TEST_CASE(knapsack_solver_test)\n         BOOST_CHECK_EQUAL(nValueRet, 500000 * COIN); // we should get the exact amount\n         BOOST_CHECK_EQUAL(setCoinsRet.size(), 10U); // in ten coins\n \n-        // if there's not enough in the smaller coins to make at least 1 * MIN_CHANGE change (0.5+0.6+0.7 < 1.0+1.0),\n+        // if there is not enough in the smaller coins to make at least 1 * MIN_CHANGE change (0.5+0.6+0.7 < 1.0+1.0),\n         // we need to try finding an exact subset anyway\n \n         // sometimes it will fail, and so we use the next biggest coin:"
      },
      {
        "sha": "1a529f66b6d5c26d02993763037a148c26e8e8a8",
        "filename": "src/wallet/test/wallet_tests.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/test/wallet_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/test/wallet_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/wallet/test/wallet_tests.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -235,7 +235,7 @@ BOOST_AUTO_TEST_CASE(ComputeTimeSmart)\n     // Test that updating existing transaction does not change smart time.\n     BOOST_CHECK_EQUAL(AddTx(m_wallet, 1, 200, 220), 100);\n \n-    // New transaction should use clock time if there's no block time.\n+    // New transaction should use clock time if there is no block time.\n     BOOST_CHECK_EQUAL(AddTx(m_wallet, 2, 300, 0), 300);\n \n     // New transaction should use block time if lower than clock time."
      },
      {
        "sha": "107a90b9d84963b006b01eacbe657d24436912bf",
        "filename": "src/wallet/wallet.cpp",
        "status": "modified",
        "additions": 8,
        "deletions": 8,
        "changes": 16,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/wallet.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/wallet.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/wallet/wallet.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -773,7 +773,7 @@ DBErrors CWallet::ReorderTransactions()\n             if (!nOrderPosOff)\n                 continue;\n \n-            // Since we're changing the order, write it back\n+            // Since we are changing the order, write it back\n             if (!batch.WriteTx(*pwtx))\n                 return DBErrors::LOAD_FAIL;\n         }\n@@ -815,7 +815,7 @@ bool CWallet::MarkReplaced(const uint256& originalHash, const uint256& newHash)\n \n     CWalletTx& wtx = (*mi).second;\n \n-    // Ensure for now that we're not overwriting data\n+    // Ensure for now that we are not overwriting data\n     assert(wtx.mapValue.count(\"replaced_by_txid\") == 0);\n \n     wtx.mapValue[\"replaced_by_txid\"] = newHash.ToString();\n@@ -1188,7 +1188,7 @@ void CWallet::BlockUntilSyncedToCurrentChain() {\n     AssertLockNotHeld(cs_wallet);\n \n     {\n-        // Skip the queue-draining stuff if we know we're caught up with\n+        // Skip the queue-draining stuff if we know we are caught up with\n         // chainActive.Tip()...\n         // We could also take cs_wallet here, and call m_last_block_processed\n         // protected by cs_wallet instead of cs_main, but as long as we need\n@@ -1989,7 +1989,7 @@ void CWallet::ResendWalletTransactions(int64_t nBestBlockTime, CConnman* connman\n     if (fFirst)\n         return;\n \n-    // Only do it if there's been a new block since last time\n+    // Only do it if there is been a new block since last time\n     if (nBestBlockTime < nLastResend)\n         return;\n     nLastResend = GetTime();\n@@ -2588,7 +2588,7 @@ bool CWallet::CreateTransaction(const std::vector<CRecipient>& vecSend, CTransac\n     //\n     // A simple way to think about this is from the wallet's point of view we\n     // always want the blockchain to move forward. By setting nLockTime this\n-    // way we're basically making the statement that we only want this\n+    // way we are basically making the statement that we only want this\n     // transaction to appear in the next block; we don't want to potentially\n     // encourage reorgs by allowing transactions to appear at lower heights\n     // than the next block in forks of the best chain.\n@@ -3651,7 +3651,7 @@ void CWallet::GetKeyBirthTimes(std::map<CTxDestination, int64_t> &mapKeyBirth) c\n             mapKeyFirstBlock[keyid] = pindexMax;\n     }\n \n-    // if there are no such keys, we're done\n+    // if there are no such keys, we are done\n     if (mapKeyFirstBlock.empty())\n         return;\n \n@@ -4177,7 +4177,7 @@ std::shared_ptr<CWallet> CWallet::CreateWalletFromFile(const std::string& name,\n \n     uiInterface.LoadWallet(walletInstance);\n \n-    // Register with the validation interface. It's ok to do this after rescan since we're still holding cs_main.\n+    // Register with the validation interface. It's ok to do this after rescan since we are still holding cs_main.\n     RegisterValidationInterface(walletInstance.get());\n \n     walletInstance->SetBroadcastTransactions(gArgs.GetBoolArg(\"-walletbroadcast\", DEFAULT_WALLETBROADCAST));\n@@ -4270,7 +4270,7 @@ bool CWalletTx::AcceptToMemoryPool(const CAmount& nAbsurdFee, CValidationState&\n     // entered-mempool callback, if we did not there would be a race where a\n     // user could call sendmoney in a loop and hit spurious out of funds errors\n     // because we think that this newly generated transaction's change is\n-    // unavailable as we're not yet aware that it is in the mempool.\n+    // unavailable as we are not yet aware that it is in the mempool.\n     bool ret = ::AcceptToMemoryPool(mempool, state, tx, nullptr /* pfMissingInputs */,\n                                 nullptr /* plTxnReplaced */, false /* bypass_limits */, nAbsurdFee);\n     fInMempool |= ret;"
      },
      {
        "sha": "d88725fe82812a1a385f3ed542ac83b26b847b7a",
        "filename": "src/wallet/wallet.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/wallet.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/wallet.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/wallet/wallet.h?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -993,7 +993,7 @@ class CWallet final : public CCryptoKeyStore, public CValidationInterface\n     //! signify that a particular wallet feature is now used. this may change nWalletVersion and nWalletMaxVersion if those are lower\n     void SetMinVersion(enum WalletFeature, WalletBatch* batch_in = nullptr, bool fExplicit = false);\n \n-    //! change which version we're allowed to upgrade to (note that this does not immediately imply upgrading to that format)\n+    //! change which version we are allowed to upgrade to (note that this does not immediately imply upgrading to that format)\n     bool SetMaxVersion(int nVersion);\n \n     //! get the current wallet format (the oldest client version guaranteed to understand this wallet)"
      },
      {
        "sha": "4283d23605c3f13ae2e439d1fa2ad583daa92896",
        "filename": "src/wallet/walletdb.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/walletdb.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/wallet/walletdb.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/wallet/walletdb.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -33,7 +33,7 @@ bool WalletBatch::WriteName(const std::string& strAddress, const std::string& st\n bool WalletBatch::EraseName(const std::string& strAddress)\n {\n     // This should only be used for sending addresses, never for receiving addresses,\n-    // receiving addresses must always have an address book entry if they're not change return.\n+    // receiving addresses must always have an address book entry if they are not change return.\n     return EraseIC(std::make_pair(std::string(\"name\"), strAddress));\n }\n "
      },
      {
        "sha": "17b750cadd30a927fde2ab5223bfc16d39a4ef1d",
        "filename": "src/zmq/zmqnotificationinterface.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/zmq/zmqnotificationinterface.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/src/zmq/zmqnotificationinterface.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/zmq/zmqnotificationinterface.cpp?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -155,7 +155,7 @@ void CZMQNotificationInterface::UpdatedBlockTip(const CBlockIndex *pindexNew, co\n \n void CZMQNotificationInterface::TransactionAddedToMempool(const CTransactionRef& ptx)\n {\n-    // Used by BlockConnected and BlockDisconnected as well, because they're\n+    // Used by BlockConnected and BlockDisconnected as well, because they are\n     // all the same external callback.\n     const CTransaction& tx = *ptx;\n "
      },
      {
        "sha": "86488511aef7952227666ac65c0a0859d73635c9",
        "filename": "test/functional/example_test.py",
        "status": "modified",
        "additions": 4,
        "deletions": 4,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/example_test.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/example_test.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/example_test.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -107,8 +107,8 @@ def setup_network(self):\n \n         self.setup_nodes()\n \n-        # In this test, we're not connecting node2 to node0 or node1. Calls to\n-        # sync_all() should not include node2, since we're not expecting it to\n+        # In this test, we are not connecting node2 to node0 or node1. Calls to\n+        # sync_all() should not include node2, since we are not expecting it to\n         # sync.\n         connect_nodes(self.nodes[0], 1)\n         self.sync_all([self.nodes[0:1]])\n@@ -121,7 +121,7 @@ def setup_network(self):\n     def custom_method(self):\n         \"\"\"Do some custom behaviour for this test\n \n-        Define it in a method here because you're going to use it repeatedly.\n+        Define it in a method here because you are going to use it repeatedly.\n         If you think it's useful in general, consider moving it to the base\n         BitcoinTestFramework class so other tests can use it.\"\"\"\n \n@@ -140,7 +140,7 @@ def run_test(self):\n         # Notice above how we called an RPC by calling a method with the same\n         # name on the node object. Notice also how we used a keyword argument\n         # to specify a named RPC argument. Neither of those are defined on the\n-        # node object. Instead there's some __getattr__() magic going on under\n+        # node object. Instead there is some __getattr__() magic going on under\n         # the covers to dispatch unrecognised attribute calls to the RPC\n         # interface.\n "
      },
      {
        "sha": "546999d21a40ebed622eab6b7b8d31cff4701687",
        "filename": "test/functional/feature_assumevalid.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_assumevalid.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_assumevalid.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_assumevalid.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -66,7 +66,7 @@ def setup_network(self):\n         self.start_node(0)\n \n     def send_blocks_until_disconnected(self, p2p_conn):\n-        \"\"\"Keep sending blocks to the node until we're disconnected.\"\"\"\n+        \"\"\"Keep sending blocks to the node until we are disconnected.\"\"\"\n         for i in range(len(self.blocks)):\n             if not p2p_conn.is_connected:\n                 break"
      },
      {
        "sha": "f31c44892514493cb06794889e28ebebbf9fe127",
        "filename": "test/functional/feature_bip68_sequence.py",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_bip68_sequence.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_bip68_sequence.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_bip68_sequence.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -155,8 +155,8 @@ def test_sequence_lock_confirmed_inputs(self):\n                         should_pass = False\n \n                     # Figure out what the median-time-past was for the confirmed input\n-                    # Note that if an input has N confirmations, we're going back N blocks\n-                    # from the tip so that we're looking up MTP of the block\n+                    # Note that if an input has N confirmations, we are going back N blocks\n+                    # from the tip so that we are looking up MTP of the block\n                     # PRIOR to the one the input appears in, as per the BIP68 spec.\n                     orig_time = self.get_median_time_past(utxos[j][\"confirmations\"])\n                     cur_time = self.get_median_time_past(0) # MTP of the tip"
      },
      {
        "sha": "e74525ee85e60cdafb6a5abd6ef1bf044c4f5f56",
        "filename": "test/functional/feature_block.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_block.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_block.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_block.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -525,7 +525,7 @@ def run_test(self):\n         #  -> b31 (8) -> b33 (9) -> b35 (10) -> b39 (11) -> b42 (12) -> b43 (13) -> b44 (14)\n         #                                                                                   \\-> ??? (15)\n \n-        # The next few blocks are going to be created \"by hand\" since they'll do funky things, such as having\n+        # The next few blocks are going to be created \"by hand\" since they will do funky things, such as having\n         # the first transaction be non-coinbase, etc.  The purpose of b44 is to make sure this works.\n         self.log.info(\"Build block 44 manually\")\n         height = self.block_heights[self.tip.sha256] + 1"
      },
      {
        "sha": "b7bcb216892b781a45a91c99e792252593dce6e1",
        "filename": "test/functional/feature_maxuploadtarget.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_maxuploadtarget.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_maxuploadtarget.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_maxuploadtarget.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -105,7 +105,7 @@ def run_test(self):\n \n         # Requesting the current block on p2p_conns[1] should succeed indefinitely,\n         # even when over the max upload target.\n-        # We'll try 800 times\n+        # We will try 800 times\n         getdata_request.inv = [CInv(2, big_new_block)]\n         for i in range(800):\n             p2p_conns[1].send_message(getdata_request)"
      },
      {
        "sha": "7de181b61c7350c5d74c4b0d278259e1cb4c314f",
        "filename": "test/functional/feature_minchainwork.py",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_minchainwork.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_minchainwork.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_minchainwork.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -35,7 +35,7 @@ def setup_network(self):\n         # This test relies on the chain setup being:\n         # node0 <- node1 <- node2\n         # Before leaving IBD, nodes prefer to download blocks from outbound\n-        # peers, so ensure that we're mining on an outbound peer and testing\n+        # peers, so ensure that we are mining on an outbound peer and testing\n         # block relay to inbound peers.\n         self.setup_nodes()\n         for i in range(self.num_nodes-1):\n@@ -58,7 +58,7 @@ def run_test(self):\n         # Sleep a few seconds and verify that node2 didn't get any new blocks\n         # or headers.  We sleep, rather than sync_blocks(node0, node1) because\n         # it's reasonable either way for node1 to get the blocks, or not get\n-        # them (since they're below node1's minchainwork).\n+        # them (since they are below node1's minchainwork).\n         time.sleep(3)\n \n         self.log.info(\"Verifying node 2 has no more blocks than before\")"
      },
      {
        "sha": "b2831bd3d6c6a6c02e48d8fc2760195c8d467752",
        "filename": "test/functional/feature_pruning.py",
        "status": "modified",
        "additions": 5,
        "deletions": 5,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_pruning.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_pruning.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_pruning.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -74,9 +74,9 @@ def test_height_min(self):\n         if not os.path.isfile(os.path.join(self.prunedir, \"blk00000.dat\")):\n             raise AssertionError(\"blk00000.dat is missing, pruning too early\")\n         self.log.info(\"Success\")\n-        self.log.info(\"Though we're already using more than 550MiB, current usage: %d\" % calc_usage(self.prunedir))\n+        self.log.info(\"Though we are already using more than 550MiB, current usage: %d\" % calc_usage(self.prunedir))\n         self.log.info(\"Mining 25 more blocks should cause the first block file to be pruned\")\n-        # Pruning doesn't run until we're allocating another chunk, 20 full blocks past the height cutoff will ensure this\n+        # Pruning doesn't run until we are allocating another chunk, 20 full blocks past the height cutoff will ensure this\n         for i in range(25):\n             mine_large_block(self.nodes[0], self.utxo_cache_0)\n \n@@ -136,8 +136,8 @@ def reorg_test(self):\n         self.log.info(\"Invalidating block %s at height %d\" % (badhash,invalidheight))\n         self.nodes[1].invalidateblock(badhash)\n \n-        # We've now switched to our previously mined-24 block fork on node 1, but that's not what we want\n-        # So invalidate that fork as well, until we're on the same chain as node 0/2 (but at an ancestor 288 blocks ago)\n+        # We have now switched to our previously mined-24 block fork on node 1, but that's not what we want\n+        # So invalidate that fork as well, until we are on the same chain as node 0/2 (but at an ancestor 288 blocks ago)\n         mainchainhash = self.nodes[0].getblockhash(invalidheight - 1)\n         curhash = self.nodes[1].getblockhash(invalidheight - 1)\n         while curhash != mainchainhash:\n@@ -359,7 +359,7 @@ def run_test(self):\n         self.stop_node(3)\n         self.stop_node(4)\n \n-        self.log.info(\"Check that we haven't started pruning yet because we're below PruneAfterHeight\")\n+        self.log.info(\"Check that we haven't started pruning yet because we are below PruneAfterHeight\")\n         self.test_height_min()\n         # Extend this chain past the PruneAfterHeight\n         # N0=N1=N2 **...*(1020)"
      },
      {
        "sha": "e4df6cdaaeb433908bb7ff4a388aec585f644451",
        "filename": "test/functional/feature_rbf.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_rbf.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/feature_rbf.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_rbf.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -319,7 +319,7 @@ def test_spends_of_conflicting_outputs(self):\n \n         tx1a_txid = int(tx1a_txid, 16)\n \n-        # Direct spend an output of the transaction we're replacing.\n+        # Direct spend an output of the transaction we are replacing.\n         tx2 = CTransaction()\n         tx2.vin = [CTxIn(utxo1, nSequence=0), CTxIn(utxo2, nSequence=0)]\n         tx2.vin.append(CTxIn(COutPoint(tx1a_txid, 0), nSequence=0))"
      },
      {
        "sha": "23f5bf4237eea08a03e2b6f98a41ff858bcf0d42",
        "filename": "test/functional/p2p_compactblocks.py",
        "status": "modified",
        "additions": 5,
        "deletions": 5,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/p2p_compactblocks.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/p2p_compactblocks.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_compactblocks.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -549,11 +549,11 @@ def test_incorrect_blocktxn_response(self, node, test_node, version):\n         assert_equal(absolute_indexes, [6, 7, 8, 9, 10])\n \n         # Now give an incorrect response.\n-        # Note that it's possible for bitcoind to be smart enough to know we're\n-        # lying, since it could check to see if the shortid matches what we're\n+        # Note that it's possible for bitcoind to be smart enough to know we are\n+        # lying, since it could check to see if the shortid matches what we are\n         # sending, and eg disconnect us for misbehavior.  If that behavior\n         # change was made, we could just modify this test by having a\n-        # different peer provide the block further down, so that we're still\n+        # different peer provide the block further down, so that we are still\n         # verifying that the block isn't marked bad permanently. This is good\n         # enough for now.\n         msg = msg_blocktxn()\n@@ -612,7 +612,7 @@ def test_getblocktxn_handler(self, node, test_node, version):\n                 test_node.last_message.pop(\"blocktxn\", None)\n             current_height -= 1\n \n-        # Next request should send a full block response, as we're past the\n+        # Next request should send a full block response, as we are past the\n         # allowed depth for a blocktxn response.\n         block_hash = node.getblockhash(current_height)\n         msg.block_txn_request = BlockTransactionsRequest(int(block_hash, 16), [0])\n@@ -713,7 +713,7 @@ def test_invalid_tx_in_compactblock(self, node, test_node, use_segwit):\n         del block.vtx[3]\n         block.hashMerkleRoot = block.calc_merkle_root()\n         if use_segwit:\n-            # If we're testing with segwit, also drop the coinbase witness,\n+            # If we are testing with segwit, also drop the coinbase witness,\n             # but include the witness commitment.\n             add_witness_commitment(block)\n             block.vtx[0].wit.vtxinwit = []"
      },
      {
        "sha": "095603a24ce892245369064b64cba69d3ac40009",
        "filename": "test/functional/p2p_segwit.py",
        "status": "modified",
        "additions": 7,
        "deletions": 7,
        "changes": 14,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/p2p_segwit.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/p2p_segwit.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_segwit.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -557,7 +557,7 @@ def test_getblocktemplate_before_lockin(self):\n         for node in [self.nodes[0], self.nodes[2]]:\n             gbt_results = node.getblocktemplate()\n             block_version = gbt_results['version']\n-            # If we're not indicating segwit support, we will still be\n+            # If we are not indicating segwit support, we will still be\n             # signalling for segwit activation.\n             assert_equal((block_version & (1 << VB_WITNESS_BIT) != 0), node == self.nodes[0])\n             # If we don't specify the segwit rule, then we won't get a default\n@@ -796,7 +796,7 @@ def test_p2sh_witness(self):\n         block = self.build_next_block()\n         self.update_witness_block_with_transactions(block, [spend_tx])\n \n-        # If we're after activation, then sending this with witnesses should be valid.\n+        # If we are after activation, then sending this with witnesses should be valid.\n         # This no longer works before activation, because SCRIPT_VERIFY_WITNESS\n         # is always set.\n         # TODO: rewrite this test to make clear that it only works after activation.\n@@ -1073,7 +1073,7 @@ def test_extra_witness_data(self):\n         # Extra witness data should not be allowed.\n         test_witness_block(self.nodes[0], self.test_node, block, accepted=False)\n \n-        # Try extra signature data.  Ok if we're not spending a witness output.\n+        # Try extra signature data.  Ok if we are not spending a witness output.\n         block.vtx[1].wit.vtxinwit = []\n         block.vtx[1].vin[0].scriptSig = CScript([OP_0])\n         block.vtx[1].rehash()\n@@ -1579,7 +1579,7 @@ def test_uncompressed_pubkey(self):\n \n         # Test 3: P2SH(P2WSH)\n         # Try to spend the P2SH output created in the last test.\n-        # Send it to a P2PKH output, which we'll use in the next test.\n+        # Send it to a P2PKH output, which we will use in the next test.\n         script_pubkey = get_p2pkh_script(pubkeyhash)\n         tx4 = CTransaction()\n         tx4.vin.append(CTxIn(COutPoint(tx3.sha256, 0), script_sig))\n@@ -1722,7 +1722,7 @@ def test_signature_version_1(self):\n \n             block.vtx.append(tx)\n \n-            # Test the block periodically, if we're close to maxblocksize\n+            # Test the block periodically, if we are close to maxblocksize\n             if (get_virtual_size(block) > MAX_BLOCK_BASE_SIZE - 1000):\n                 self.update_witness_block_with_transactions(block, [])\n                 test_witness_block(self.nodes[0], self.test_node, block, accepted=True)\n@@ -1812,7 +1812,7 @@ def test_non_standard_witness_blinding(self):\n         self.nodes[0].generate(1)\n         sync_blocks(self.nodes)\n \n-        # We'll add an unnecessary witness to this transaction that would cause\n+        # We will add an unnecessary witness to this transaction that would cause\n         # it to be non-standard, to test that violating policy with a witness\n         # doesn't blind a node to a transaction.  Transactions\n         # rejected for having a witness shouldn't be added\n@@ -1977,7 +1977,7 @@ def test_witness_sigops(self):\n         script_pubkey = CScript([OP_0, witness_hash])\n \n         sigops_per_script = 20 * 5 + 193 * 1\n-        # We'll produce 2 extra outputs, one with a program that would take us\n+        # We will produce 2 extra outputs, one with a program that would take us\n         # over max sig ops, and one with a program that would exactly reach max\n         # sig ops\n         outputs = (MAX_SIGOP_COST // sigops_per_script) + 2"
      },
      {
        "sha": "15a6f2a8891b5497025618c5d1f900baae4ffcfd",
        "filename": "test/functional/p2p_timeouts.py",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/p2p_timeouts.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/p2p_timeouts.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_timeouts.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -12,13 +12,13 @@\n \n - Start all three nodes\n - Wait 1 second\n-- Assert that we're connected\n+- Assert that we are connected\n - Send a ping to no_verack_node and no_version_node\n - Wait 30 seconds\n-- Assert that we're still connected\n+- Assert that we are still connected\n - Send a ping to no_verack_node and no_version_node\n - Wait 31 seconds\n-- Assert that we're no longer connected (timeout to receive version/verack is 60 seconds)\n+- Assert that we are no longer connected (timeout to receive version/verack is 60 seconds)\n \"\"\"\n \n from time import sleep"
      },
      {
        "sha": "f52b127ed42b2851a4be26def91f5a319ac6c949",
        "filename": "test/functional/p2p_unrequested_blocks.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/p2p_unrequested_blocks.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/p2p_unrequested_blocks.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_unrequested_blocks.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -292,7 +292,7 @@ def run_test(self):\n         assert_equal(self.nodes[0].getbestblockhash(), all_blocks[286].hash)\n         assert_equal(self.nodes[0].getblock(block_291.hash)[\"confirmations\"], -1)\n \n-        # Now send a new header on the invalid chain, indicating we're forked off, and expect to get disconnected\n+        # Now send a new header on the invalid chain, indicating we are forked off, and expect to get disconnected\n         block_293 = create_block(block_292.sha256, create_coinbase(293), block_292.nTime+1)\n         block_293.solve()\n         headers_message = msg_headers()"
      },
      {
        "sha": "d842fea10d1781c0acd2e3507749bceaaf61826b",
        "filename": "test/functional/test_framework/mininode.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/test_framework/mininode.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/test_framework/mininode.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/test_framework/mininode.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -518,7 +518,7 @@ def send_blocks_and_test(self, blocks, node, *, success=True, request_block=True\n             wait_until(lambda: self.reject_reason_received == reject_reason, lock=mininode_lock)\n \n     def send_txs_and_test(self, txs, node, *, success=True, expect_disconnect=False, reject_code=None, reject_reason=None):\n-        \"\"\"Send txs to test node and test whether they're accepted to the mempool.\n+        \"\"\"Send txs to test node and test whether they are accepted to the mempool.\n \n          - add all txs to our tx_store\n          - send tx messages for all txs"
      },
      {
        "sha": "c31179c3009de0d9869417c74cf4595ea6a2a2a6",
        "filename": "test/functional/test_framework/script.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/test_framework/script.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/test_framework/script.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/test_framework/script.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -387,7 +387,7 @@ class CScript(bytes):\n     \"\"\"Serialized script\n \n     A bytes subclass, so you can use this directly whenever bytes are accepted.\n-    Note that this means that indexing does *not* work - you'll get an index by\n+    Note that this means that indexing does *not* work - you will get an index by\n     byte rather than opcode. This format was chosen for efficiency so that the\n     general case would not require creating a lot of little CScriptOP objects.\n "
      },
      {
        "sha": "ecabe0279945bbb3dfffd4c6781be09d0586c09d",
        "filename": "test/functional/test_framework/util.py",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/test_framework/util.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/test_framework/util.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/test_framework/util.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -357,7 +357,7 @@ def disconnect_nodes(from_connection, node_num):\n         except JSONRPCException as e:\n             # If this node is disconnected between calculating the peer id\n             # and issuing the disconnect, don't worry about it.\n-            # This avoids a race condition if we're mass-disconnecting peers.\n+            # This avoids a race condition if we are mass-disconnecting peers.\n             if e.error['code'] != -29: # RPC_CLIENT_NODE_NOT_CONNECTED\n                 raise\n \n@@ -380,7 +380,7 @@ def sync_blocks(rpc_connections, *, wait=1, timeout=60):\n     Wait until everybody has the same tip.\n \n     sync_blocks needs to be called with an rpc_connections set that has least\n-    one node already synced to the latest, stable tip, otherwise there's a\n+    one node already synced to the latest, stable tip, otherwise there is a\n     chance it might return before all nodes are stably synced.\n     \"\"\"\n     stop_time = time.time() + timeout"
      },
      {
        "sha": "fda30efe6e1d3cd6f1ce322232ec0adbb1e37a92",
        "filename": "test/functional/wallet_basic.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/wallet_basic.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/wallet_basic.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/wallet_basic.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -43,7 +43,7 @@ def get_vsize(self, txn):\n         return self.nodes[0].decoderawtransaction(txn)['vsize']\n \n     def run_test(self):\n-        # Check that there's no UTXO on none of the nodes\n+        # Check that there is no UTXO on none of the nodes\n         assert_equal(len(self.nodes[0].listunspent()), 0)\n         assert_equal(len(self.nodes[1].listunspent()), 0)\n         assert_equal(len(self.nodes[2].listunspent()), 0)"
      },
      {
        "sha": "aa70e6f6b15d0b59eee76084c146c1287ba80f61",
        "filename": "test/functional/wallet_labels.py",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/wallet_labels.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/ec49b56c58ebc5ea466bdce6c220667a292f370a/test/functional/wallet_labels.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/wallet_labels.py?ref=ec49b56c58ebc5ea466bdce6c220667a292f370a",
        "patch": "@@ -20,7 +20,7 @@ def set_test_params(self):\n         self.num_nodes = 1\n \n     def run_test(self):\n-        # Check that there's no UTXO on the node\n+        # Check that there is no UTXO on the node\n         node = self.nodes[0]\n         assert_equal(len(node.listunspent()), 0)\n \n@@ -61,7 +61,7 @@ def run_test(self):\n         node.generate(1)\n \n         # we want to reset so that the \"\" label has what's expected.\n-        # otherwise we're off by exactly the fee amount as that's mined\n+        # otherwise we are off by exactly the fee amount as that's mined\n         # and matures in the next 100 blocks\n         amount_to_send = 1.0\n "
      }
    ]
  }
]