[
  {
    "sha": "91b0979d2d26c3ca694afbb0e2faf033320cbd41",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo5MWIwOTc5ZDJkMjZjM2NhNjk0YWZiYjBlMmZhZjAzMzMyMGNiZDQx",
    "commit": {
      "author": {
        "name": "John Newbery",
        "email": "john@johnnewbery.com",
        "date": "2017-06-02T18:30:36Z"
      },
      "committer": {
        "name": "John Newbery",
        "email": "john@johnnewbery.com",
        "date": "2017-07-02T21:05:45Z"
      },
      "message": "[tests] Introduce TestNode\n\nTestNode is a class responsible for all state related to a bitcoind node\nunder test. It stores local state, is responsible for tracking the\nbitcoind process and delegates unrecognised messages to the RPC\nconnection.\n\nThis commit changes start_nodes and stop_nodes to start and stop the\nbitcoind nodes in parallel, making test setup and teardown much faster.",
      "tree": {
        "sha": "b25678116d68d35d3481c986f982d1a0cd4ec210",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/b25678116d68d35d3481c986f982d1a0cd4ec210"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/91b0979d2d26c3ca694afbb0e2faf033320cbd41",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/91b0979d2d26c3ca694afbb0e2faf033320cbd41",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/91b0979d2d26c3ca694afbb0e2faf033320cbd41",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/91b0979d2d26c3ca694afbb0e2faf033320cbd41/comments",
    "author": {
      "login": "jnewbery",
      "id": 1063656,
      "node_id": "MDQ6VXNlcjEwNjM2NTY=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1063656?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jnewbery",
      "html_url": "https://github.com/jnewbery",
      "followers_url": "https://api.github.com/users/jnewbery/followers",
      "following_url": "https://api.github.com/users/jnewbery/following{/other_user}",
      "gists_url": "https://api.github.com/users/jnewbery/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jnewbery/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jnewbery/subscriptions",
      "organizations_url": "https://api.github.com/users/jnewbery/orgs",
      "repos_url": "https://api.github.com/users/jnewbery/repos",
      "events_url": "https://api.github.com/users/jnewbery/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jnewbery/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "jnewbery",
      "id": 1063656,
      "node_id": "MDQ6VXNlcjEwNjM2NTY=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1063656?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jnewbery",
      "html_url": "https://github.com/jnewbery",
      "followers_url": "https://api.github.com/users/jnewbery/followers",
      "following_url": "https://api.github.com/users/jnewbery/following{/other_user}",
      "gists_url": "https://api.github.com/users/jnewbery/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jnewbery/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jnewbery/subscriptions",
      "organizations_url": "https://api.github.com/users/jnewbery/orgs",
      "repos_url": "https://api.github.com/users/jnewbery/repos",
      "events_url": "https://api.github.com/users/jnewbery/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jnewbery/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "2935b469ae96a3203bb997a6eddc098903b336ce",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/2935b469ae96a3203bb997a6eddc098903b336ce",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/2935b469ae96a3203bb997a6eddc098903b336ce"
      }
    ],
    "stats": {
      "total": 274,
      "additions": 180,
      "deletions": 94
    },
    "files": [
      {
        "sha": "0812e1b0df90932d24a208f77621116523ff7bf7",
        "filename": "test/functional/blockchain.py",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/blockchain.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/blockchain.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/blockchain.py?ref=91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "patch": "@@ -139,13 +139,13 @@ def _test_stopatheight(self):\n         self.nodes[0].generate(6)\n         assert_equal(self.nodes[0].getblockcount(), 206)\n         self.log.debug('Node should not stop at this height')\n-        assert_raises(subprocess.TimeoutExpired, lambda: self.bitcoind_processes[0].wait(timeout=3))\n+        assert_raises(subprocess.TimeoutExpired, lambda: self.nodes[0].process.wait(timeout=3))\n         try:\n             self.nodes[0].generate(1)\n         except (ConnectionError, http.client.BadStatusLine):\n             pass  # The node already shut down before response\n         self.log.debug('Node should stop at this height...')\n-        self.bitcoind_processes[0].wait(timeout=BITCOIND_PROC_WAIT_TIMEOUT)\n+        self.nodes[0].process.wait(timeout=BITCOIND_PROC_WAIT_TIMEOUT)\n         self.nodes[0] = self.start_node(0, self.options.tmpdir)\n         assert_equal(self.nodes[0].getblockcount(), 207)\n "
      },
      {
        "sha": "3c488f609a3e0cdf8cf8b229206132dec1cb12b6",
        "filename": "test/functional/bumpfee.py",
        "status": "modified",
        "additions": 1,
        "deletions": 2,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/bumpfee.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/bumpfee.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/bumpfee.py?ref=91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "patch": "@@ -41,8 +41,7 @@ def setup_network(self, split=False):\n         self.nodes = self.start_nodes(self.num_nodes, self.options.tmpdir, extra_args)\n \n         # Encrypt wallet for test_locked_wallet_fails test\n-        self.nodes[1].encryptwallet(WALLET_PASSPHRASE)\n-        self.bitcoind_processes[1].wait()\n+        self.nodes[1].node_encrypt_wallet(WALLET_PASSPHRASE)\n         self.nodes[1] = self.start_node(1, self.options.tmpdir, extra_args[1])\n         self.nodes[1].walletpassphrase(WALLET_PASSPHRASE, WALLET_PASSPHRASE_TIMEOUT)\n "
      },
      {
        "sha": "85445c7815548c29aea8ccbb921f3fd48aa06c03",
        "filename": "test/functional/fundrawtransaction.py",
        "status": "modified",
        "additions": 1,
        "deletions": 2,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/fundrawtransaction.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/fundrawtransaction.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/fundrawtransaction.py?ref=91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "patch": "@@ -451,8 +451,7 @@ def run_test(self):\n         self.stop_node(0)\n         self.stop_node(2)\n         self.stop_node(3)\n-        self.nodes[1].encryptwallet(\"test\")\n-        self.bitcoind_processes[1].wait(timeout=BITCOIND_PROC_WAIT_TIMEOUT)\n+        self.nodes[1].node_encrypt_wallet(\"test\")\n \n         self.nodes = self.start_nodes(self.num_nodes, self.options.tmpdir)\n         # This test is not meant to test fee estimation and we'd like"
      },
      {
        "sha": "cca30e2688e4d8ad8ba551520bfafe6bafbdafb7",
        "filename": "test/functional/getblocktemplate_longpoll.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/getblocktemplate_longpoll.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/getblocktemplate_longpoll.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/getblocktemplate_longpoll.py?ref=91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "patch": "@@ -17,7 +17,7 @@ def __init__(self, node):\n         self.longpollid = templat['longpollid']\n         # create a new connection to the node, we can't use the same\n         # connection from two threads\n-        self.node = get_rpc_proxy(node.url, 1, timeout=600)\n+        self.node = get_rpc_proxy(node.url, 1, timeout=600, coveragedir=node.coverage_dir)\n \n     def run(self):\n         self.node.getblocktemplate({'longpollid':self.longpollid})"
      },
      {
        "sha": "3e7bb0ee072057f463d195847e066c387c4d12a0",
        "filename": "test/functional/keypool.py",
        "status": "modified",
        "additions": 1,
        "deletions": 2,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/keypool.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/keypool.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/keypool.py?ref=91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "patch": "@@ -17,8 +17,7 @@ def run_test(self):\n         assert(addr_before_encrypting_data['hdmasterkeyid'] == wallet_info_old['hdmasterkeyid'])\n         \n         # Encrypt wallet and wait to terminate\n-        nodes[0].encryptwallet('test')\n-        self.bitcoind_processes[0].wait()\n+        nodes[0].node_encrypt_wallet('test')\n         # Restart node 0\n         nodes[0] = self.start_node(0, self.options.tmpdir)\n         # Keep creating keys"
      },
      {
        "sha": "20808207b2bc80729f99d94872fdaa5da300c01a",
        "filename": "test/functional/rpcbind_test.py",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/rpcbind_test.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/rpcbind_test.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/rpcbind_test.py?ref=91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "patch": "@@ -37,7 +37,7 @@ def run_bind_test(self, allow_ips, connect_to, addresses, expected):\n             base_args += ['-rpcallowip=' + x for x in allow_ips]\n         binds = ['-rpcbind='+addr for addr in addresses]\n         self.nodes = self.start_nodes(self.num_nodes, self.options.tmpdir, [base_args + binds], connect_to)\n-        pid = self.bitcoind_processes[0].pid\n+        pid = self.nodes[0].process.pid\n         assert_equal(set(get_bind_addrs(pid)), set(expected))\n         self.stop_nodes()\n \n@@ -49,7 +49,7 @@ def run_allowip_test(self, allow_ips, rpchost, rpcport):\n         base_args = ['-disablewallet', '-nolisten'] + ['-rpcallowip='+x for x in allow_ips]\n         self.nodes = self.start_nodes(self.num_nodes, self.options.tmpdir, [base_args])\n         # connect to node through non-loopback interface\n-        node = get_rpc_proxy(rpc_url(get_datadir_path(self.options.tmpdir, 0), 0, \"%s:%d\" % (rpchost, rpcport)), 0)\n+        node = get_rpc_proxy(rpc_url(get_datadir_path(self.options.tmpdir, 0), 0, \"%s:%d\" % (rpchost, rpcport)), 0, coveragedir=self.options.coveragedir)\n         node.getnetworkinfo()\n         self.stop_nodes()\n "
      },
      {
        "sha": "641266507c556146ab605fd487706a23b8db4c4c",
        "filename": "test/functional/test_framework/test_framework.py",
        "status": "modified",
        "additions": 37,
        "deletions": 77,
        "changes": 114,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/test_framework/test_framework.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/test_framework/test_framework.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/test_framework/test_framework.py?ref=91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "patch": "@@ -5,34 +5,29 @@\n \"\"\"Base class for RPC testing.\"\"\"\n \n from collections import deque\n-import errno\n from enum import Enum\n-import http.client\n import logging\n import optparse\n import os\n import shutil\n-import subprocess\n import sys\n import tempfile\n import time\n import traceback\n \n from .authproxy import JSONRPCException\n from . import coverage\n+from .test_node import TestNode\n from .util import (\n     MAX_NODES,\n     PortSeed,\n     assert_equal,\n     check_json_precision,\n     connect_nodes_bi,\n     disconnect_nodes,\n-    get_rpc_proxy,\n     initialize_datadir,\n-    get_datadir_path,\n     log_filename,\n     p2p_port,\n-    rpc_url,\n     set_node_times,\n     sync_blocks,\n     sync_mempools,\n@@ -69,7 +64,6 @@ def __init__(self):\n         self.num_nodes = 4\n         self.setup_clean_chain = False\n         self.nodes = []\n-        self.bitcoind_processes = {}\n         self.mocktime = 0\n \n     def add_options(self, parser):\n@@ -203,67 +197,60 @@ def main(self):\n \n     # Public helper methods. These can be accessed by the subclass test scripts.\n \n-    def start_node(self, i, dirname, extra_args=None, rpchost=None, timewait=None, binary=None, stderr=None):\n+    def start_node(self, i, dirname, extra_args=[], rpchost=None, timewait=None, binary=None, stderr=None):\n         \"\"\"Start a bitcoind and return RPC connection to it\"\"\"\n \n-        datadir = os.path.join(dirname, \"node\" + str(i))\n         if binary is None:\n             binary = os.getenv(\"BITCOIND\", \"bitcoind\")\n-        args = [binary, \"-datadir=\" + datadir, \"-server\", \"-keypool=1\", \"-discover=0\", \"-rest\", \"-logtimemicros\", \"-debug\", \"-debugexclude=libevent\", \"-debugexclude=leveldb\", \"-mocktime=\" + str(self.mocktime), \"-uacomment=testnode%d\" % i]\n-        if extra_args is not None:\n-            args.extend(extra_args)\n-        self.bitcoind_processes[i] = subprocess.Popen(args, stderr=stderr)\n-        self.log.debug(\"initialize_chain: bitcoind started, waiting for RPC to come up\")\n-        self._wait_for_bitcoind_start(self.bitcoind_processes[i], datadir, i, rpchost)\n-        self.log.debug(\"initialize_chain: RPC successfully started\")\n-        proxy = get_rpc_proxy(rpc_url(datadir, i, rpchost), i, timeout=timewait)\n+        node = TestNode(i, dirname, extra_args, rpchost, timewait, binary, stderr, self.mocktime, coverage_dir=self.options.coveragedir)\n+        node.start()\n+        node.wait_for_rpc_connection()\n \n-        if self.options.coveragedir:\n-            coverage.write_all_rpc_commands(self.options.coveragedir, proxy)\n+        if self.options.coveragedir is not None:\n+            coverage.write_all_rpc_commands(self.options.coveragedir, node.rpc)\n \n-        return proxy\n+        return node\n \n     def start_nodes(self, num_nodes, dirname, extra_args=None, rpchost=None, timewait=None, binary=None):\n         \"\"\"Start multiple bitcoinds, return RPC connections to them\"\"\"\n \n         if extra_args is None:\n-            extra_args = [None] * num_nodes\n+            extra_args = [[]] * num_nodes\n         if binary is None:\n             binary = [None] * num_nodes\n         assert_equal(len(extra_args), num_nodes)\n         assert_equal(len(binary), num_nodes)\n-        rpcs = []\n+        nodes = []\n         try:\n             for i in range(num_nodes):\n-                rpcs.append(self.start_node(i, dirname, extra_args[i], rpchost, timewait=timewait, binary=binary[i]))\n+                nodes.append(TestNode(i, dirname, extra_args[i], rpchost, timewait=timewait, binary=binary[i], stderr=None, mocktime=self.mocktime, coverage_dir=self.options.coveragedir))\n+                nodes[i].start()\n+            for node in nodes:\n+                node.wait_for_rpc_connection()\n         except:\n             # If one node failed to start, stop the others\n-            # TODO: abusing self.nodes in this way is a little hacky.\n-            # Eventually we should do a better job of tracking nodes\n-            self.nodes.extend(rpcs)\n             self.stop_nodes()\n-            self.nodes = []\n             raise\n-        return rpcs\n+\n+        if self.options.coveragedir is not None:\n+            coverage.write_all_rpc_commands(self.options.coveragedir, node.rpc)\n+\n+        return nodes\n \n     def stop_node(self, i):\n         \"\"\"Stop a bitcoind test node\"\"\"\n-\n-        self.log.debug(\"Stopping node %d\" % i)\n-        try:\n-            self.nodes[i].stop()\n-        except http.client.CannotSendRequest as e:\n-            self.log.exception(\"Unable to stop node\")\n-        return_code = self.bitcoind_processes[i].wait(timeout=BITCOIND_PROC_WAIT_TIMEOUT)\n-        del self.bitcoind_processes[i]\n-        assert_equal(return_code, 0)\n+        self.nodes[i].stop_node()\n+        while not self.nodes[i].is_node_stopped():\n+            time.sleep(0.1)\n \n     def stop_nodes(self):\n         \"\"\"Stop multiple bitcoind test nodes\"\"\"\n-\n-        for i in range(len(self.nodes)):\n-            self.stop_node(i)\n-        assert not self.bitcoind_processes.values()  # All connections must be gone now\n+        for node in self.nodes:\n+            node.stop_node()\n+        # All connections must be gone now\n+        for node in self.nodes:\n+            while not node.is_node_stopped():\n+                time.sleep(0.1)\n \n     def assert_start_raises_init_error(self, i, dirname, extra_args=None, expected_msg=None):\n         with tempfile.SpooledTemporaryFile(max_size=2**16) as log_stderr:\n@@ -272,6 +259,8 @@ def assert_start_raises_init_error(self, i, dirname, extra_args=None, expected_m\n                 self.stop_node(i)\n             except Exception as e:\n                 assert 'bitcoind exited' in str(e)  # node must have shutdown\n+                self.nodes[i].running = False\n+                self.nodes[i].process = None\n                 if expected_msg is not None:\n                     log_stderr.seek(0)\n                     stderr = log_stderr.read().decode('utf-8')\n@@ -285,7 +274,7 @@ def assert_start_raises_init_error(self, i, dirname, extra_args=None, expected_m\n                 raise AssertionError(assert_msg)\n \n     def wait_for_node_exit(self, i, timeout):\n-        self.bitcoind_processes[i].wait(timeout)\n+        self.nodes[i].process.wait(timeout)\n \n     def split_network(self):\n         \"\"\"\n@@ -382,18 +371,13 @@ def _initialize_chain(self, test_dir, num_nodes, cachedir):\n                 args = [os.getenv(\"BITCOIND\", \"bitcoind\"), \"-server\", \"-keypool=1\", \"-datadir=\" + datadir, \"-discover=0\"]\n                 if i > 0:\n                     args.append(\"-connect=127.0.0.1:\" + str(p2p_port(0)))\n-                self.bitcoind_processes[i] = subprocess.Popen(args)\n-                self.log.debug(\"initialize_chain: bitcoind started, waiting for RPC to come up\")\n-                self._wait_for_bitcoind_start(self.bitcoind_processes[i], datadir, i)\n-                self.log.debug(\"initialize_chain: RPC successfully started\")\n+                self.nodes.append(TestNode(i, cachedir, extra_args=[], rpchost=None, timewait=None, binary=None, stderr=None, mocktime=self.mocktime, coverage_dir=None))\n+                self.nodes[i].args = args\n+                self.nodes[i].start()\n \n-            self.nodes = []\n-            for i in range(MAX_NODES):\n-                try:\n-                    self.nodes.append(get_rpc_proxy(rpc_url(get_datadir_path(cachedir, i), i), i))\n-                except:\n-                    self.log.exception(\"Error connecting to node %d\" % i)\n-                    sys.exit(1)\n+            # Wait for RPC connections to be ready\n+            for node in self.nodes:\n+                node.wait_for_rpc_connection()\n \n             # Create a 200-block-long chain; each of the 4 first nodes\n             # gets 25 mature blocks and 25 immature.\n@@ -437,30 +421,6 @@ def _initialize_chain_clean(self, test_dir, num_nodes):\n         for i in range(num_nodes):\n             initialize_datadir(test_dir, i)\n \n-    def _wait_for_bitcoind_start(self, process, datadir, i, rpchost=None):\n-        \"\"\"Wait for bitcoind to start.\n-\n-        This means that RPC is accessible and fully initialized.\n-        Raise an exception if bitcoind exits during initialization.\"\"\"\n-        while True:\n-            if process.poll() is not None:\n-                raise Exception('bitcoind exited with status %i during initialization' % process.returncode)\n-            try:\n-                # Check if .cookie file to be created\n-                rpc = get_rpc_proxy(rpc_url(datadir, i, rpchost), i, coveragedir=self.options.coveragedir)\n-                rpc.getblockcount()\n-                break  # break out of loop on success\n-            except IOError as e:\n-                if e.errno != errno.ECONNREFUSED:  # Port not yet open?\n-                    raise  # unknown IO error\n-            except JSONRPCException as e:  # Initialization phase\n-                if e.error['code'] != -28:  # RPC in warmup?\n-                    raise  # unknown JSON RPC exception\n-            except ValueError as e:  # cookie file not found and no rpcuser or rpcassword. bitcoind still starting\n-                if \"No RPC credentials\" not in str(e):\n-                    raise\n-            time.sleep(0.25)\n-\n class ComparisonTestFramework(BitcoinTestFramework):\n     \"\"\"Test framework for doing p2p comparison testing\n "
      },
      {
        "sha": "cd7ea88e7a21390ea36298bf4243f519f7dd9ac8",
        "filename": "test/functional/test_framework/test_node.py",
        "status": "added",
        "additions": 130,
        "deletions": 0,
        "changes": 130,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/test_framework/test_node.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/test_framework/test_node.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/test_framework/test_node.py?ref=91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "patch": "@@ -0,0 +1,130 @@\n+#!/usr/bin/env python3\n+# Copyright (c) 2017 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\"\"\"Class for bitcoind node under test\"\"\"\n+\n+import errno\n+import http.client\n+import logging\n+import os\n+import subprocess\n+import time\n+\n+from .util import (\n+    assert_equal,\n+    get_rpc_proxy,\n+    rpc_url,\n+)\n+from .authproxy import JSONRPCException\n+\n+class TestNode():\n+    \"\"\"A class for representing a bitcoind node under test.\n+\n+    This class contains:\n+\n+    - state about the node (whether it's running, etc)\n+    - a Python subprocess.Popen object representing the running process\n+    - an RPC connection to the node\n+\n+    To make things easier for the test writer, a bit of magic is happening under the covers.\n+    Any unrecognised messages will be dispatched to the RPC connection.\"\"\"\n+\n+    def __init__(self, i, dirname, extra_args, rpchost, timewait, binary, stderr, mocktime, coverage_dir):\n+        self.index = i\n+        self.datadir = os.path.join(dirname, \"node\" + str(i))\n+        self.rpchost = rpchost\n+        self.rpc_timeout = timewait\n+        if binary is None:\n+            self.binary = os.getenv(\"BITCOIND\", \"bitcoind\")\n+        else:\n+            self.binary = binary\n+        self.stderr = stderr\n+        self.coverage_dir = coverage_dir\n+        # Most callers will just need to add extra args to the standard list below. For those callers that need more flexibity, they can just set the args property directly.\n+        self.extra_args = extra_args\n+        self.args = [self.binary, \"-datadir=\" + self.datadir, \"-server\", \"-keypool=1\", \"-discover=0\", \"-rest\", \"-logtimemicros\", \"-debug\", \"-debugexclude=libevent\", \"-debugexclude=leveldb\", \"-mocktime=\" + str(mocktime), \"-uacomment=testnode%d\" % i]\n+\n+        self.running = False\n+        self.process = None\n+        self.rpc_connected = False\n+        self.rpc = None\n+        self.url = None\n+        self.log = logging.getLogger('TestFramework.node%d' % i)\n+\n+    def __getattr__(self, *args, **kwargs):\n+        \"\"\"Dispatches any unrecognised messages to the RPC connection.\"\"\"\n+        assert self.rpc_connected and self.rpc is not None, \"Error: no RPC connection\"\n+        return self.rpc.__getattr__(*args, **kwargs)\n+\n+    def start(self):\n+        \"\"\"Start the node.\"\"\"\n+        # import pdb; pdb.set_trace()\n+        self.process = subprocess.Popen(self.args + self.extra_args, stderr=self.stderr)\n+        self.running = True\n+        self.log.debug(\"bitcoind started, waiting for RPC to come up\")\n+\n+    def wait_for_rpc_connection(self):\n+        \"\"\"Sets up an RPC connection to the bitcoind process. Returns False if unable to connect.\"\"\"\n+\n+        attempts = 40\n+        while attempts > 0:\n+            assert not self.process.poll(), \"bitcoind exited with status %i during initialization\" % self.process.returncode\n+            try:\n+                self.rpc = get_rpc_proxy(rpc_url(self.datadir, self.index, self.rpchost), self.index)\n+                self.rpc.getblockcount()\n+                # If the call to getblockcount() succeeds then the RPC connection is up\n+                self.rpc_connected = True\n+                self.url = self.rpc.url\n+                self.log.debug(\"RPC successfully started\")\n+                return True\n+            except IOError as e:\n+                if e.errno != errno.ECONNREFUSED:  # Port not yet open?\n+                    raise  # unknown IO error\n+            except JSONRPCException as e:  # Initialization phase\n+                if e.error['code'] != -28:  # RPC in warmup?\n+                    raise  # unknown JSON RPC exception\n+            except ValueError as e:  # cookie file not found and no rpcuser or rpcassword. bitcoind still starting\n+                if \"No RPC credentials\" not in str(e):\n+                    raise\n+            time.sleep(0.25)\n+            attempts -= 1\n+        raise AssertionError(\"Unable to connect to bitcoind\")\n+\n+    def stop_node(self):\n+        \"\"\"Stop the node.\"\"\"\n+        if not self.running:\n+            return\n+        self.log.debug(\"Stopping node\")\n+        try:\n+            self.stop()\n+        except http.client.CannotSendRequest as e:\n+            self.log.exception(\"Unable to stop node.\")\n+\n+    def is_node_stopped(self):\n+        \"\"\"Checks whether the node has stopped.\n+\n+        Returns True if the node has stopped. False otherwise.\n+        This method is responsible for freeing resources (self.process).\"\"\"\n+        if not self.running:\n+            return True\n+        return_code = self.process.poll()\n+        if return_code is not None:\n+            # process has stopped. Assert that it didn't return an error code.\n+            assert_equal(return_code, 0)\n+            self.running = False\n+            self.process = None\n+            self.log.debug(\"Node stopped\")\n+            return True\n+        return False\n+\n+    def node_encrypt_wallet(self, passphrase):\n+        \"\"\"\"Encrypts the wallet.\n+\n+        This causes bitcoind to shutdown, so this method takes\n+        care of cleaning up resources.\"\"\"\n+        self.encryptwallet(passphrase)\n+        while not self.is_node_stopped():\n+            time.sleep(0.1)\n+        self.rpc = None\n+        self.rpc_connected = False"
      },
      {
        "sha": "50a2a6888a1c78085279cbe0fff824d824605993",
        "filename": "test/functional/test_framework/util.py",
        "status": "modified",
        "additions": 3,
        "deletions": 2,
        "changes": 5,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/test_framework/util.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/test_framework/util.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/test_framework/util.py?ref=91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "patch": "@@ -204,7 +204,7 @@ def rpc_port(n):\n     return PORT_MIN + PORT_RANGE + n + (MAX_NODES * PortSeed.n) % (PORT_RANGE - 1 - MAX_NODES)\n \n def rpc_url(datadir, i, rpchost=None):\n-    rpc_u, rpc_p = get_auth_cookie(datadir, i)\n+    rpc_u, rpc_p = get_auth_cookie(datadir)\n     host = '127.0.0.1'\n     port = rpc_port(i)\n     if rpchost:\n@@ -232,7 +232,7 @@ def initialize_datadir(dirname, n):\n def get_datadir_path(dirname, n):\n     return os.path.join(dirname, \"node\" + str(n))\n \n-def get_auth_cookie(datadir, n):\n+def get_auth_cookie(datadir):\n     user = None\n     password = None\n     if os.path.isfile(os.path.join(datadir, \"bitcoin.conf\")):\n@@ -244,6 +244,7 @@ def get_auth_cookie(datadir, n):\n                 if line.startswith(\"rpcpassword=\"):\n                     assert password is None  # Ensure that there is only one rpcpassword line\n                     password = line.split(\"=\")[1].strip(\"\\n\")\n+    # print(os.path.join(datadir, \"regtest\", \".cookie\"))\n     if os.path.isfile(os.path.join(datadir, \"regtest\", \".cookie\")):\n         with open(os.path.join(datadir, \"regtest\", \".cookie\"), 'r') as f:\n             userpass = f.read()"
      },
      {
        "sha": "61ad00330bd74225714c0b7f6e5384990679d2e9",
        "filename": "test/functional/wallet-dump.py",
        "status": "modified",
        "additions": 1,
        "deletions": 2,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/wallet-dump.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/wallet-dump.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/wallet-dump.py?ref=91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "patch": "@@ -94,8 +94,7 @@ def run_test (self):\n         assert_equal(found_addr_rsv, 90*2) # 90 keys plus 100% internal keys\n \n         #encrypt wallet, restart, unlock and dump\n-        self.nodes[0].encryptwallet('test')\n-        self.bitcoind_processes[0].wait()\n+        self.nodes[0].node_encrypt_wallet('test')\n         self.nodes[0] = self.start_node(0, self.options.tmpdir, self.extra_args[0])\n         self.nodes[0].walletpassphrase('test', 10)\n         # Should be a no-op:"
      },
      {
        "sha": "8fea4140db7591b32800de4e82471fcd44fe9228",
        "filename": "test/functional/wallet-encryption.py",
        "status": "modified",
        "additions": 1,
        "deletions": 2,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/wallet-encryption.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/91b0979d2d26c3ca694afbb0e2faf033320cbd41/test/functional/wallet-encryption.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/wallet-encryption.py?ref=91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "patch": "@@ -30,8 +30,7 @@ def run_test(self):\n         assert_equal(len(privkey), 52)\n \n         # Encrypt the wallet\n-        self.nodes[0].encryptwallet(passphrase)\n-        self.bitcoind_processes[0].wait(timeout=BITCOIND_PROC_WAIT_TIMEOUT)\n+        self.nodes[0].node_encrypt_wallet(passphrase)\n         self.nodes[0] = self.start_node(0, self.options.tmpdir)\n \n         # Test that the wallet is encrypted"
      }
    ]
  },
  {
    "sha": "806bf4839d4a9e5b4914faaf98a859b539f828b8",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo4MDZiZjQ4MzlkNGE5ZTViNDkxNGZhYWY5OGE4NTliNTM5ZjgyOGI4",
    "commit": {
      "author": {
        "name": "John Newbery",
        "email": "john@johnnewbery.com",
        "date": "2017-06-13T18:36:44Z"
      },
      "committer": {
        "name": "John Newbery",
        "email": "john@johnnewbery.com",
        "date": "2017-07-02T21:05:45Z"
      },
      "message": "[tests] make pruning test faster\n\nThis commit makes the pruning.py much faster.\n\nKey insights to do this:\n\n- pruning.py doesn't care what kind of transactions make up the big\nblocks that are pruned in the test. Instead of making blocks with\nseveral large, expensive to construct and validate transactions,\ninstead make the large blocks contain a single coinbase transaction with\na huge OP_RETURN txout.\n- avoid stop-starting nodes where possible.\n\nThis test could probably be made even faster by using the P2P interface\nfor submitting blocks instead of the submitblock RPC.",
      "tree": {
        "sha": "51c4f5ff6780445c20dc324bcbfdfe342814d06a",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/51c4f5ff6780445c20dc324bcbfdfe342814d06a"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/806bf4839d4a9e5b4914faaf98a859b539f828b8",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/806bf4839d4a9e5b4914faaf98a859b539f828b8",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/806bf4839d4a9e5b4914faaf98a859b539f828b8",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/806bf4839d4a9e5b4914faaf98a859b539f828b8/comments",
    "author": {
      "login": "jnewbery",
      "id": 1063656,
      "node_id": "MDQ6VXNlcjEwNjM2NTY=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1063656?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jnewbery",
      "html_url": "https://github.com/jnewbery",
      "followers_url": "https://api.github.com/users/jnewbery/followers",
      "following_url": "https://api.github.com/users/jnewbery/following{/other_user}",
      "gists_url": "https://api.github.com/users/jnewbery/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jnewbery/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jnewbery/subscriptions",
      "organizations_url": "https://api.github.com/users/jnewbery/orgs",
      "repos_url": "https://api.github.com/users/jnewbery/repos",
      "events_url": "https://api.github.com/users/jnewbery/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jnewbery/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "jnewbery",
      "id": 1063656,
      "node_id": "MDQ6VXNlcjEwNjM2NTY=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1063656?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jnewbery",
      "html_url": "https://github.com/jnewbery",
      "followers_url": "https://api.github.com/users/jnewbery/followers",
      "following_url": "https://api.github.com/users/jnewbery/following{/other_user}",
      "gists_url": "https://api.github.com/users/jnewbery/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jnewbery/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jnewbery/subscriptions",
      "organizations_url": "https://api.github.com/users/jnewbery/orgs",
      "repos_url": "https://api.github.com/users/jnewbery/repos",
      "events_url": "https://api.github.com/users/jnewbery/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jnewbery/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/91b0979d2d26c3ca694afbb0e2faf033320cbd41",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/91b0979d2d26c3ca694afbb0e2faf033320cbd41"
      }
    ],
    "stats": {
      "total": 129,
      "additions": 73,
      "deletions": 56
    },
    "files": [
      {
        "sha": "78685f3bd19c3b9cf9822f316e3fce6de5fce467",
        "filename": "test/functional/pruning.py",
        "status": "modified",
        "additions": 73,
        "deletions": 56,
        "changes": 129,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/806bf4839d4a9e5b4914faaf98a859b539f828b8/test/functional/pruning.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/806bf4839d4a9e5b4914faaf98a859b539f828b8/test/functional/pruning.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/pruning.py?ref=806bf4839d4a9e5b4914faaf98a859b539f828b8",
        "patch": "@@ -8,11 +8,15 @@\n This test uses 4GB of disk space.\n This test takes 30 mins or more (up to 2 hours)\n \"\"\"\n+from binascii import b2a_hex\n+import time\n+import os\n \n+from test_framework.blocktools import create_coinbase\n+from test_framework.mininode import CBlock\n+from test_framework.script import CScript, OP_RETURN, OP_NOP\n from test_framework.test_framework import BitcoinTestFramework\n from test_framework.util import *\n-import time\n-import os\n \n MIN_BLOCKS_TO_KEEP = 288\n \n@@ -21,6 +25,48 @@\n # compatible with pruning based on key creation time.\n TIMESTAMP_WINDOW = 2 * 60 * 60\n \n+def mine_large_blocks(node, n):\n+    # Make a large scriptsig for the coinbase transaction. This is OP_RETURN\n+    # followed by 950k of OP_NOP. This is a non-standard transaction but it\n+    # is consensus valid.\n+    # This could probably be made faster by submitting the block over P2P.\n+\n+    # Get the block parameters for the first block\n+    big_script = CScript([OP_RETURN] + [OP_NOP] * 950000)\n+    best_block = node.getblock(node.getbestblockhash())\n+    height = int(best_block[\"height\"]) + 1\n+    try:\n+        # Static variable ensures that time is monotonicly increasing and is therefore\n+        # different for each block created => blockhash is unique.\n+        mine_large_blocks.nTime = min(mine_large_blocks.nTime, int(best_block[\"time\"])) + 1\n+    except AttributeError:\n+        mine_large_blocks.nTime = int(best_block[\"time\"]) + 1\n+    previousblockhash = int(best_block[\"hash\"], 16)\n+\n+    for _ in range(n):\n+        # Build the coinbase transaction (with large scriptsig)\n+        coinbase_tx = create_coinbase(height)\n+        coinbase_tx.vin[0].nSequence = 2 ** 32 - 1\n+        coinbase_tx.vout[0].scriptPubKey = big_script\n+        coinbase_tx.rehash()\n+\n+        # Build the block\n+        block = CBlock()\n+        block.nVersion = best_block[\"version\"]\n+        block.hashPrevBlock = previousblockhash\n+        block.nTime = mine_large_blocks.nTime\n+        block.nBits = int('207fffff', 16)\n+        block.nNonce = 0\n+        block.vtx = [coinbase_tx]\n+        block.hashMerkleRoot = block.calc_merkle_root()\n+        block.solve()\n+        block_binary = (b2a_hex(block.serialize()).decode('ascii'))\n+\n+        node.submitblock(block_binary)\n+\n+        previousblockhash = block.sha256\n+        height += 1\n+        mine_large_blocks.nTime += 1\n \n def calc_usage(blockdir):\n     return sum(os.path.getsize(blockdir+f) for f in os.listdir(blockdir) if os.path.isfile(blockdir+f)) / (1024. * 1024.)\n@@ -61,9 +107,9 @@ def create_big_chain(self):\n         self.nodes[1].generate(200)\n         sync_blocks(self.nodes[0:2])\n         self.nodes[0].generate(150)\n+\n         # Then mine enough full blocks to create more than 550MiB of data\n-        for i in range(645):\n-            mine_large_block(self.nodes[0], self.utxo_cache_0)\n+        mine_large_blocks(self.nodes[0], 645)\n \n         sync_blocks(self.nodes[0:5])\n \n@@ -74,8 +120,7 @@ def test_height_min(self):\n         self.log.info(\"Though we're already using more than 550MiB, current usage: %d\" % calc_usage(self.prunedir))\n         self.log.info(\"Mining 25 more blocks should cause the first block file to be pruned\")\n         # Pruning doesn't run until we're allocating another chunk, 20 full blocks past the height cutoff will ensure this\n-        for i in range(25):\n-            mine_large_block(self.nodes[0], self.utxo_cache_0)\n+        mine_large_blocks(self.nodes[0], 25)\n \n         waitstart = time.time()\n         while os.path.isfile(self.prunedir+\"blk00000.dat\"):\n@@ -86,8 +131,7 @@ def test_height_min(self):\n         self.log.info(\"Success\")\n         usage = calc_usage(self.prunedir)\n         self.log.info(\"Usage should be below target: %d\" % usage)\n-        if (usage > 550):\n-            raise AssertionError(\"Pruning target not being met\")\n+        assert_greater_than(550, usage)\n \n     def create_chain_with_staleblocks(self):\n         # Create stale blocks in manageable sized chunks\n@@ -97,21 +141,14 @@ def create_chain_with_staleblocks(self):\n             # Disconnect node 0 so it can mine a longer reorg chain without knowing about node 1's soon-to-be-stale chain\n             # Node 2 stays connected, so it hears about the stale blocks and then reorg's when node0 reconnects\n             # Stopping node 0 also clears its mempool, so it doesn't have node1's transactions to accidentally mine\n-            self.stop_node(0)\n-            self.nodes[0]=self.start_node(0, self.options.tmpdir, self.full_node_default_args, timewait=900)\n+            disconnect_nodes(self.nodes[0], 1)\n+            disconnect_nodes(self.nodes[0], 2)\n+\n             # Mine 24 blocks in node 1\n-            for i in range(24):\n-                if j == 0:\n-                    mine_large_block(self.nodes[1], self.utxo_cache_1)\n-                else:\n-                    # Add node1's wallet transactions back to the mempool, to\n-                    # avoid the mined blocks from being too small.\n-                    self.nodes[1].resendwallettransactions()\n-                    self.nodes[1].generate(1) #tx's already in mempool from previous disconnects\n+            mine_large_blocks(self.nodes[1], 24)\n \n             # Reorg back with 25 block chain from node 0\n-            for i in range(25):\n-                mine_large_block(self.nodes[0], self.utxo_cache_0)\n+            mine_large_blocks(self.nodes[0], 25)\n \n             # Create connections in the order so both nodes can see the reorg at the same time\n             connect_nodes(self.nodes[1], 0)\n@@ -125,8 +162,6 @@ def reorg_test(self):\n         # This will cause Node 2 to do a reorg requiring 288 blocks of undo data to the reorg_test chain\n         # Reboot node 1 to clear its mempool (hopefully make the invalidate faster)\n         # Lower the block max size so we don't keep mining all our big mempool transactions (from disconnected blocks)\n-        self.stop_node(1)\n-        self.nodes[1] = self.start_node(1, self.options.tmpdir, [\"-maxreceivebuffer=20000\",\"-blockmaxsize=5000\", \"-checkblocks=5\", \"-disablesafemode\"], timewait=900)\n \n         height = self.nodes[1].getblockcount()\n         self.log.info(\"Current block height: %d\" % height)\n@@ -148,41 +183,31 @@ def reorg_test(self):\n         self.log.info(\"New best height: %d\" % self.nodes[1].getblockcount())\n \n         # Reboot node1 to clear those giant tx's from mempool\n-        self.stop_node(1)\n-        self.nodes[1] = self.start_node(1, self.options.tmpdir, [\"-maxreceivebuffer=20000\",\"-blockmaxsize=5000\", \"-checkblocks=5\", \"-disablesafemode\"], timewait=900)\n \n         self.log.info(\"Generating new longer chain of 300 more blocks\")\n         self.nodes[1].generate(300)\n \n-        self.log.info(\"Reconnect nodes\")\n-        connect_nodes(self.nodes[0], 1)\n-        connect_nodes(self.nodes[2], 1)\n-        sync_blocks(self.nodes[0:3], timeout=120)\n \n         self.log.info(\"Verify height on node 2: %d\" % self.nodes[2].getblockcount())\n-        self.log.info(\"Usage possibly still high bc of stale blocks in block files: %d\" % calc_usage(self.prunedir))\n+        self.log.info(\"Usage possibly still high because of stale blocks in block files: %d\" % calc_usage(self.prunedir))\n \n-        self.log.info(\"Mine 220 more blocks so we have requisite history (some blocks will be big and cause pruning of previous chain)\")\n+        self.log.info(\"Mine 220 more large blocks so we have requisite history\")\n \n         # Get node0's wallet transactions back in its mempool, to avoid the\n         # mined blocks from being too small.\n-        self.nodes[0].resendwallettransactions()\n+        # self.nodes[0].resendwallettransactions()\n \n-        for i in range(22):\n-            # This can be slow, so do this in multiple RPC calls to avoid\n-            # RPC timeouts.\n-            self.nodes[0].generate(10) #node 0 has many large tx's in its mempool from the disconnects\n-        sync_blocks(self.nodes[0:3], timeout=300)\n+        mine_large_blocks(self.nodes[0], 220)\n \n         usage = calc_usage(self.prunedir)\n         self.log.info(\"Usage should be below target: %d\" % usage)\n-        if (usage > 550):\n-            raise AssertionError(\"Pruning target not being met\")\n+        assert_greater_than(550, usage)\n \n-        return invalidheight,badhash\n+        return invalidheight, badhash\n \n     def reorg_back(self):\n         # Verify that a block on the old main chain fork has been pruned away\n+        # import ipdb; ipdb.set_trace()\n         assert_raises_jsonrpc(-1, \"Block not available (pruned data)\", self.nodes[2].getblock, self.forkhash)\n         self.log.info(\"Will need to redownload block %d\" % self.forkheight)\n \n@@ -272,38 +297,30 @@ def has_block(index):\n \n         # height=100 too low to prune first block file so this is a no-op\n         prune(100)\n-        if not has_block(0):\n-            raise AssertionError(\"blk00000.dat is missing when should still be there\")\n+        assert has_block(0), \"blk00000.dat is missing when should still be there\"\n \n         # Does nothing\n         node.pruneblockchain(height(0))\n-        if not has_block(0):\n-            raise AssertionError(\"blk00000.dat is missing when should still be there\")\n+        assert has_block(0), \"blk00000.dat is missing when should still be there\"\n \n         # height=500 should prune first file\n         prune(500)\n-        if has_block(0):\n-            raise AssertionError(\"blk00000.dat is still there, should be pruned by now\")\n-        if not has_block(1):\n-            raise AssertionError(\"blk00001.dat is missing when should still be there\")\n+        assert not has_block(0), \"blk00000.dat is still there, should be pruned by now\"\n+        assert has_block(1), \"blk00001.dat is missing when should still be there\"\n \n         # height=650 should prune second file\n         prune(650)\n-        if has_block(1):\n-            raise AssertionError(\"blk00001.dat is still there, should be pruned by now\")\n+        assert not has_block(1), \"blk00001.dat is still there, should be pruned by now\"\n \n         # height=1000 should not prune anything more, because tip-288 is in blk00002.dat.\n         prune(1000, 1001 - MIN_BLOCKS_TO_KEEP)\n-        if not has_block(2):\n-            raise AssertionError(\"blk00002.dat is still there, should be pruned by now\")\n+        assert has_block(2), \"blk00002.dat is still there, should be pruned by now\"\n \n         # advance the tip so blk00002.dat and blk00003.dat can be pruned (the last 288 blocks should now be in blk00004.dat)\n         node.generate(288)\n         prune(1000)\n-        if has_block(2):\n-            raise AssertionError(\"blk00002.dat is still there, should be pruned by now\")\n-        if has_block(3):\n-            raise AssertionError(\"blk00003.dat is still there, should be pruned by now\")\n+        assert not has_block(2), \"blk00002.dat is still there, should be pruned by now\"\n+        assert not has_block(3), \"blk00003.dat is still there, should be pruned by now\"\n \n         # stop node, start back up with auto-prune at 550MB, make sure still runs\n         self.stop_node(node_number)\n@@ -383,7 +400,7 @@ def run_test(self):\n         self.mainchainhash2 = self.nodes[2].getblockhash(self.mainchainheight)\n \n         self.log.info(\"Check that we can survive a 288 block reorg still\")\n-        (self.forkheight,self.forkhash) = self.reorg_test() #(1033, )\n+        self.forkheight, self.forkhash = self.reorg_test() #(1033, )\n         # Now create a 288 block reorg by mining a longer chain on N1\n         # First disconnect N1\n         # Then invalidate 1033 on main chain and 1032 on fork so height is 1032 on main chain"
      }
    ]
  }
]