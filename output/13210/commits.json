[
  {
    "sha": "0d31ef4762f5a1428a57439d26551a99f15ddc2e",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzowZDMxZWY0NzYyZjVhMTQyOGE1NzQzOWQyNjU1MWE5OWYxNWRkYzJl",
    "commit": {
      "author": {
        "name": "John Bampton",
        "email": "jbampton@users.noreply.github.com",
        "date": "2018-05-10T15:28:27Z"
      },
      "committer": {
        "name": "John Bampton",
        "email": "jbampton@users.noreply.github.com",
        "date": "2018-05-10T21:59:05Z"
      },
      "message": "Enable W191 and W291 flake8 checks.\nRemove trailing whitespace from Python files.\nConvert tabs to spaces.",
      "tree": {
        "sha": "b2943f8b56ffef8d12fdf8d79ed9d04cd8a8c62b",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/b2943f8b56ffef8d12fdf8d79ed9d04cd8a8c62b"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/0d31ef4762f5a1428a57439d26551a99f15ddc2e",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/0d31ef4762f5a1428a57439d26551a99f15ddc2e",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/0d31ef4762f5a1428a57439d26551a99f15ddc2e",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/0d31ef4762f5a1428a57439d26551a99f15ddc2e/comments",
    "author": {
      "login": "jbampton",
      "id": 418747,
      "node_id": "MDQ6VXNlcjQxODc0Nw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/418747?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jbampton",
      "html_url": "https://github.com/jbampton",
      "followers_url": "https://api.github.com/users/jbampton/followers",
      "following_url": "https://api.github.com/users/jbampton/following{/other_user}",
      "gists_url": "https://api.github.com/users/jbampton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jbampton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jbampton/subscriptions",
      "organizations_url": "https://api.github.com/users/jbampton/orgs",
      "repos_url": "https://api.github.com/users/jbampton/repos",
      "events_url": "https://api.github.com/users/jbampton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jbampton/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "jbampton",
      "id": 418747,
      "node_id": "MDQ6VXNlcjQxODc0Nw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/418747?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jbampton",
      "html_url": "https://github.com/jbampton",
      "followers_url": "https://api.github.com/users/jbampton/followers",
      "following_url": "https://api.github.com/users/jbampton/following{/other_user}",
      "gists_url": "https://api.github.com/users/jbampton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jbampton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jbampton/subscriptions",
      "organizations_url": "https://api.github.com/users/jbampton/orgs",
      "repos_url": "https://api.github.com/users/jbampton/repos",
      "events_url": "https://api.github.com/users/jbampton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jbampton/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "1c582503507b72306be1355738f1d853e499bd15",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/1c582503507b72306be1355738f1d853e499bd15",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/1c582503507b72306be1355738f1d853e499bd15"
      }
    ],
    "stats": {
      "total": 824,
      "additions": 413,
      "deletions": 411
    },
    "files": [
      {
        "sha": "82d3c196831afd6ccf2f2ebd0d3d14f258eff375",
        "filename": "contrib/devtools/copyright_header.py",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/devtools/copyright_header.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/devtools/copyright_header.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/devtools/copyright_header.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -506,7 +506,7 @@ def file_has_hashbang(file_lines):\n \n def insert_python_header(filename, file_lines, start_year, end_year):\n     if file_has_hashbang(file_lines):\n-        insert_idx = 1 \n+        insert_idx = 1\n     else:\n         insert_idx = 0\n     header_lines = get_python_header_lines_to_insert(start_year, end_year)\n@@ -571,7 +571,7 @@ def insert_cmd(argv):\n     if extension not in ['.h', '.cpp', '.cc', '.c', '.py']:\n         sys.exit(\"*** cannot insert for file extension %s\" % extension)\n \n-    if extension == '.py': \n+    if extension == '.py':\n         style = 'python'\n     else:\n         style = 'cpp'"
      },
      {
        "sha": "d0cd0a374ffc48724f28705d6f823b220eb0a957",
        "filename": "contrib/devtools/lint-python.sh",
        "status": "modified",
        "additions": 3,
        "deletions": 1,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/devtools/lint-python.sh",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/devtools/lint-python.sh",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/devtools/lint-python.sh?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -61,6 +61,8 @@\n # F823 local variable name \u2026 referenced before assignment\n # F831 duplicate argument name in function definition\n # F841 local variable 'foo' is assigned to but never used\n+# W191 indentation contains tabs\n+# W291 trailing whitespace\n # W292 no newline at end of file\n # W293 blank line contains whitespace\n # W504 line break after binary operator\n@@ -71,4 +73,4 @@\n # W605 invalid escape sequence \"x\"\n # W606 'async' and 'await' are reserved keywords starting with Python 3.7\n \n-flake8 --ignore=B,C,E,F,I,N,W --select=E112,E113,E115,E116,E125,E131,E133,E223,E224,E242,E266,E271,E272,E273,E274,E275,E304,E306,E401,E402,E502,E701,E702,E703,E714,E721,E741,E742,E743,F401,E901,E902,F402,F404,F406,F407,F601,F602,F621,F622,F631,F701,F702,F703,F704,F705,F706,F707,F811,F812,F821,F822,F823,F831,F841,W292,W293,W504,W601,W602,W603,W604,W605,W606 .\n+flake8 --ignore=B,C,E,F,I,N,W --select=E112,E113,E115,E116,E125,E131,E133,E223,E224,E242,E266,E271,E272,E273,E274,E275,E304,E306,E401,E402,E502,E701,E702,E703,E714,E721,E741,E742,E743,F401,E901,E902,F402,F404,F406,F407,F601,F602,F621,F622,F631,F701,F702,F703,F704,F705,F706,F707,F811,F812,F821,F822,F823,F831,F841,W191,W291,W292,W293,W504,W601,W602,W603,W604,W605,W606 ."
      },
      {
        "sha": "c9516ef83f901c29e2f0129ae2370a354a55414d",
        "filename": "contrib/devtools/security-check.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/devtools/security-check.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/devtools/security-check.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/devtools/security-check.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -150,7 +150,7 @@ def check_PE_DYNAMIC_BASE(executable):\n def check_PE_HIGH_ENTROPY_VA(executable):\n     '''PIE: DllCharacteristics bit 0x20 signifies high-entropy ASLR'''\n     (arch,bits) = get_PE_dll_characteristics(executable)\n-    if arch == 'i386:x86-64': \n+    if arch == 'i386:x86-64':\n         reqbits = IMAGE_DLL_CHARACTERISTICS_HIGH_ENTROPY_VA\n     else: # Unnecessary on 32-bit\n         assert(arch == 'i386')"
      },
      {
        "sha": "307e05773652529c6551829d41dac86ec88d4544",
        "filename": "contrib/devtools/test-security-check.py",
        "status": "modified",
        "additions": 8,
        "deletions": 8,
        "changes": 16,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/devtools/test-security-check.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/devtools/test-security-check.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/devtools/test-security-check.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -32,15 +32,15 @@ def test_ELF(self):\n         cc = 'gcc'\n         write_testcode(source)\n \n-        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,-zexecstack','-fno-stack-protector','-Wl,-znorelro']), \n+        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,-zexecstack','-fno-stack-protector','-Wl,-znorelro']),\n                 (1, executable+': failed PIE NX RELRO Canary'))\n-        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,-znoexecstack','-fno-stack-protector','-Wl,-znorelro']), \n+        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,-znoexecstack','-fno-stack-protector','-Wl,-znorelro']),\n                 (1, executable+': failed PIE RELRO Canary'))\n-        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,-znoexecstack','-fstack-protector-all','-Wl,-znorelro']), \n+        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,-znoexecstack','-fstack-protector-all','-Wl,-znorelro']),\n                 (1, executable+': failed PIE RELRO'))\n-        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,-znoexecstack','-fstack-protector-all','-Wl,-znorelro','-pie','-fPIE']), \n+        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,-znoexecstack','-fstack-protector-all','-Wl,-znorelro','-pie','-fPIE']),\n                 (1, executable+': failed RELRO'))\n-        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,-znoexecstack','-fstack-protector-all','-Wl,-zrelro','-Wl,-z,now','-pie','-fPIE']), \n+        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,-znoexecstack','-fstack-protector-all','-Wl,-zrelro','-Wl,-z,now','-pie','-fPIE']),\n                 (0, ''))\n \n     def test_32bit_PE(self):\n@@ -49,11 +49,11 @@ def test_32bit_PE(self):\n         cc = 'i686-w64-mingw32-gcc'\n         write_testcode(source)\n \n-        self.assertEqual(call_security_check(cc, source, executable, []), \n+        self.assertEqual(call_security_check(cc, source, executable, []),\n                 (1, executable+': failed DYNAMIC_BASE NX'))\n-        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,--nxcompat']), \n+        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,--nxcompat']),\n                 (1, executable+': failed DYNAMIC_BASE'))\n-        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,--nxcompat','-Wl,--dynamicbase']), \n+        self.assertEqual(call_security_check(cc, source, executable, ['-Wl,--nxcompat','-Wl,--dynamicbase']),\n                 (0, ''))\n     def test_64bit_PE(self):\n         source = 'test1.c'"
      },
      {
        "sha": "f8aea273427ab9046ee3221bb6bd657c5d312ab0",
        "filename": "contrib/linearize/linearize-data.py",
        "status": "modified",
        "additions": 266,
        "deletions": 266,
        "changes": 532,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/linearize/linearize-data.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/linearize/linearize-data.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/linearize/linearize-data.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -22,300 +22,300 @@\n settings = {}\n \n def hex_switchEndian(s):\n-\t\"\"\" Switches the endianness of a hex string (in pairs of hex chars) \"\"\"\n-\tpairList = [s[i:i+2].encode() for i in range(0, len(s), 2)]\n-\treturn b''.join(pairList[::-1]).decode()\n+    \"\"\" Switches the endianness of a hex string (in pairs of hex chars) \"\"\"\n+    pairList = [s[i:i+2].encode() for i in range(0, len(s), 2)]\n+    return b''.join(pairList[::-1]).decode()\n \n def uint32(x):\n-\treturn x & 0xffffffff\n+    return x & 0xffffffff\n \n def bytereverse(x):\n-\treturn uint32(( ((x) << 24) | (((x) << 8) & 0x00ff0000) |\n-\t\t       (((x) >> 8) & 0x0000ff00) | ((x) >> 24) ))\n+    return uint32(( ((x) << 24) | (((x) << 8) & 0x00ff0000) |\n+               (((x) >> 8) & 0x0000ff00) | ((x) >> 24) ))\n \n def bufreverse(in_buf):\n-\tout_words = []\n-\tfor i in range(0, len(in_buf), 4):\n-\t\tword = struct.unpack('@I', in_buf[i:i+4])[0]\n-\t\tout_words.append(struct.pack('@I', bytereverse(word)))\n-\treturn b''.join(out_words)\n+    out_words = []\n+    for i in range(0, len(in_buf), 4):\n+        word = struct.unpack('@I', in_buf[i:i+4])[0]\n+        out_words.append(struct.pack('@I', bytereverse(word)))\n+    return b''.join(out_words)\n \n def wordreverse(in_buf):\n-\tout_words = []\n-\tfor i in range(0, len(in_buf), 4):\n-\t\tout_words.append(in_buf[i:i+4])\n-\tout_words.reverse()\n-\treturn b''.join(out_words)\n+    out_words = []\n+    for i in range(0, len(in_buf), 4):\n+        out_words.append(in_buf[i:i+4])\n+    out_words.reverse()\n+    return b''.join(out_words)\n \n def calc_hdr_hash(blk_hdr):\n-\thash1 = hashlib.sha256()\n-\thash1.update(blk_hdr)\n-\thash1_o = hash1.digest()\n+    hash1 = hashlib.sha256()\n+    hash1.update(blk_hdr)\n+    hash1_o = hash1.digest()\n \n-\thash2 = hashlib.sha256()\n-\thash2.update(hash1_o)\n-\thash2_o = hash2.digest()\n+    hash2 = hashlib.sha256()\n+    hash2.update(hash1_o)\n+    hash2_o = hash2.digest()\n \n-\treturn hash2_o\n+    return hash2_o\n \n def calc_hash_str(blk_hdr):\n-\thash = calc_hdr_hash(blk_hdr)\n-\thash = bufreverse(hash)\n-\thash = wordreverse(hash)\n-\thash_str = hexlify(hash).decode('utf-8')\n-\treturn hash_str\n+    hash = calc_hdr_hash(blk_hdr)\n+    hash = bufreverse(hash)\n+    hash = wordreverse(hash)\n+    hash_str = hexlify(hash).decode('utf-8')\n+    return hash_str\n \n def get_blk_dt(blk_hdr):\n-\tmembers = struct.unpack(\"<I\", blk_hdr[68:68+4])\n-\tnTime = members[0]\n-\tdt = datetime.datetime.fromtimestamp(nTime)\n-\tdt_ym = datetime.datetime(dt.year, dt.month, 1)\n-\treturn (dt_ym, nTime)\n+    members = struct.unpack(\"<I\", blk_hdr[68:68+4])\n+    nTime = members[0]\n+    dt = datetime.datetime.fromtimestamp(nTime)\n+    dt_ym = datetime.datetime(dt.year, dt.month, 1)\n+    return (dt_ym, nTime)\n \n # When getting the list of block hashes, undo any byte reversals.\n def get_block_hashes(settings):\n-\tblkindex = []\n-\tf = open(settings['hashlist'], \"r\")\n-\tfor line in f:\n-\t\tline = line.rstrip()\n-\t\tif settings['rev_hash_bytes'] == 'true':\n-\t\t\tline = hex_switchEndian(line)\n-\t\tblkindex.append(line)\n+    blkindex = []\n+    f = open(settings['hashlist'], \"r\")\n+    for line in f:\n+        line = line.rstrip()\n+        if settings['rev_hash_bytes'] == 'true':\n+            line = hex_switchEndian(line)\n+        blkindex.append(line)\n \n-\tprint(\"Read \" + str(len(blkindex)) + \" hashes\")\n+    print(\"Read \" + str(len(blkindex)) + \" hashes\")\n \n-\treturn blkindex\n+    return blkindex\n \n # The block map shouldn't give or receive byte-reversed hashes.\n def mkblockmap(blkindex):\n-\tblkmap = {}\n-\tfor height,hash in enumerate(blkindex):\n-\t\tblkmap[hash] = height\n-\treturn blkmap\n+    blkmap = {}\n+    for height,hash in enumerate(blkindex):\n+        blkmap[hash] = height\n+    return blkmap\n \n # Block header and extent on disk\n BlockExtent = namedtuple('BlockExtent', ['fn', 'offset', 'inhdr', 'blkhdr', 'size'])\n \n class BlockDataCopier:\n-\tdef __init__(self, settings, blkindex, blkmap):\n-\t\tself.settings = settings\n-\t\tself.blkindex = blkindex\n-\t\tself.blkmap = blkmap\n-\n-\t\tself.inFn = 0\n-\t\tself.inF = None\n-\t\tself.outFn = 0\n-\t\tself.outsz = 0\n-\t\tself.outF = None\n-\t\tself.outFname = None\n-\t\tself.blkCountIn = 0\n-\t\tself.blkCountOut = 0\n-\n-\t\tself.lastDate = datetime.datetime(2000, 1, 1)\n-\t\tself.highTS = 1408893517 - 315360000\n-\t\tself.timestampSplit = False\n-\t\tself.fileOutput = True\n-\t\tself.setFileTime = False\n-\t\tself.maxOutSz = settings['max_out_sz']\n-\t\tif 'output' in settings:\n-\t\t\tself.fileOutput = False\n-\t\tif settings['file_timestamp'] != 0:\n-\t\t\tself.setFileTime = True\n-\t\tif settings['split_timestamp'] != 0:\n-\t\t\tself.timestampSplit = True\n-\t\t# Extents and cache for out-of-order blocks\n-\t\tself.blockExtents = {}\n-\t\tself.outOfOrderData = {}\n-\t\tself.outOfOrderSize = 0 # running total size for items in outOfOrderData\n-\n-\tdef writeBlock(self, inhdr, blk_hdr, rawblock):\n-\t\tblockSizeOnDisk = len(inhdr) + len(blk_hdr) + len(rawblock)\n-\t\tif not self.fileOutput and ((self.outsz + blockSizeOnDisk) > self.maxOutSz):\n-\t\t\tself.outF.close()\n-\t\t\tif self.setFileTime:\n-\t\t\t\tos.utime(self.outFname, (int(time.time()), self.highTS))\n-\t\t\tself.outF = None\n-\t\t\tself.outFname = None\n-\t\t\tself.outFn = self.outFn + 1\n-\t\t\tself.outsz = 0\n-\n-\t\t(blkDate, blkTS) = get_blk_dt(blk_hdr)\n-\t\tif self.timestampSplit and (blkDate > self.lastDate):\n-\t\t\tprint(\"New month \" + blkDate.strftime(\"%Y-%m\") + \" @ \" + self.hash_str)\n-\t\t\tself.lastDate = blkDate\n-\t\t\tif self.outF:\n-\t\t\t\tself.outF.close()\n-\t\t\t\tif self.setFileTime:\n-\t\t\t\t\tos.utime(self.outFname, (int(time.time()), self.highTS))\n-\t\t\t\tself.outF = None\n-\t\t\t\tself.outFname = None\n-\t\t\t\tself.outFn = self.outFn + 1\n-\t\t\t\tself.outsz = 0\n-\n-\t\tif not self.outF:\n-\t\t\tif self.fileOutput:\n-\t\t\t\tself.outFname = self.settings['output_file']\n-\t\t\telse:\n-\t\t\t\tself.outFname = os.path.join(self.settings['output'], \"blk%05d.dat\" % self.outFn)\n-\t\t\tprint(\"Output file \" + self.outFname)\n-\t\t\tself.outF = open(self.outFname, \"wb\")\n-\n-\t\tself.outF.write(inhdr)\n-\t\tself.outF.write(blk_hdr)\n-\t\tself.outF.write(rawblock)\n-\t\tself.outsz = self.outsz + len(inhdr) + len(blk_hdr) + len(rawblock)\n-\n-\t\tself.blkCountOut = self.blkCountOut + 1\n-\t\tif blkTS > self.highTS:\n-\t\t\tself.highTS = blkTS\n-\n-\t\tif (self.blkCountOut % 1000) == 0:\n-\t\t\tprint('%i blocks scanned, %i blocks written (of %i, %.1f%% complete)' % \n-\t\t\t\t\t(self.blkCountIn, self.blkCountOut, len(self.blkindex), 100.0 * self.blkCountOut / len(self.blkindex)))\n-\n-\tdef inFileName(self, fn):\n-\t\treturn os.path.join(self.settings['input'], \"blk%05d.dat\" % fn)\n-\n-\tdef fetchBlock(self, extent):\n-\t\t'''Fetch block contents from disk given extents'''\n-\t\twith open(self.inFileName(extent.fn), \"rb\") as f:\n-\t\t\tf.seek(extent.offset)\n-\t\t\treturn f.read(extent.size)\n-\n-\tdef copyOneBlock(self):\n-\t\t'''Find the next block to be written in the input, and copy it to the output.'''\n-\t\textent = self.blockExtents.pop(self.blkCountOut)\n-\t\tif self.blkCountOut in self.outOfOrderData:\n-\t\t\t# If the data is cached, use it from memory and remove from the cache\n-\t\t\trawblock = self.outOfOrderData.pop(self.blkCountOut)\n-\t\t\tself.outOfOrderSize -= len(rawblock)\n-\t\telse: # Otherwise look up data on disk\n-\t\t\trawblock = self.fetchBlock(extent)\n-\n-\t\tself.writeBlock(extent.inhdr, extent.blkhdr, rawblock)\n-\n-\tdef run(self):\n-\t\twhile self.blkCountOut < len(self.blkindex):\n-\t\t\tif not self.inF:\n-\t\t\t\tfname = self.inFileName(self.inFn)\n-\t\t\t\tprint(\"Input file \" + fname)\n-\t\t\t\ttry:\n-\t\t\t\t\tself.inF = open(fname, \"rb\")\n-\t\t\t\texcept IOError:\n-\t\t\t\t\tprint(\"Premature end of block data\")\n-\t\t\t\t\treturn\n-\n-\t\t\tinhdr = self.inF.read(8)\n-\t\t\tif (not inhdr or (inhdr[0] == \"\\0\")):\n-\t\t\t\tself.inF.close()\n-\t\t\t\tself.inF = None\n-\t\t\t\tself.inFn = self.inFn + 1\n-\t\t\t\tcontinue\n-\n-\t\t\tinMagic = inhdr[:4]\n-\t\t\tif (inMagic != self.settings['netmagic']):\n-\t\t\t\tprint(\"Invalid magic: \" + hexlify(inMagic).decode('utf-8'))\n-\t\t\t\treturn\n-\t\t\tinLenLE = inhdr[4:]\n-\t\t\tsu = struct.unpack(\"<I\", inLenLE)\n-\t\t\tinLen = su[0] - 80 # length without header\n-\t\t\tblk_hdr = self.inF.read(80)\n-\t\t\tinExtent = BlockExtent(self.inFn, self.inF.tell(), inhdr, blk_hdr, inLen)\n-\n-\t\t\tself.hash_str = calc_hash_str(blk_hdr)\n-\t\t\tif not self.hash_str in blkmap:\n-\t\t\t\t# Because blocks can be written to files out-of-order as of 0.10, the script\n-\t\t\t\t# may encounter blocks it doesn't know about. Treat as debug output.\n-\t\t\t\tif settings['debug_output'] == 'true':\n-\t\t\t\t\tprint(\"Skipping unknown block \" + self.hash_str)\n-\t\t\t\tself.inF.seek(inLen, os.SEEK_CUR)\n-\t\t\t\tcontinue\n-\n-\t\t\tblkHeight = self.blkmap[self.hash_str]\n-\t\t\tself.blkCountIn += 1\n-\n-\t\t\tif self.blkCountOut == blkHeight:\n-\t\t\t\t# If in-order block, just copy\n-\t\t\t\trawblock = self.inF.read(inLen)\n-\t\t\t\tself.writeBlock(inhdr, blk_hdr, rawblock)\n-\n-\t\t\t\t# See if we can catch up to prior out-of-order blocks\n-\t\t\t\twhile self.blkCountOut in self.blockExtents:\n-\t\t\t\t\tself.copyOneBlock()\n-\n-\t\t\telse: # If out-of-order, skip over block data for now\n-\t\t\t\tself.blockExtents[blkHeight] = inExtent\n-\t\t\t\tif self.outOfOrderSize < self.settings['out_of_order_cache_sz']:\n-\t\t\t\t\t# If there is space in the cache, read the data\n-\t\t\t\t\t# Reading the data in file sequence instead of seeking and fetching it later is preferred,\n-\t\t\t\t\t# but we don't want to fill up memory\n-\t\t\t\t\tself.outOfOrderData[blkHeight] = self.inF.read(inLen)\n-\t\t\t\t\tself.outOfOrderSize += inLen\n-\t\t\t\telse: # If no space in cache, seek forward\n-\t\t\t\t\tself.inF.seek(inLen, os.SEEK_CUR)\n-\n-\t\tprint(\"Done (%i blocks written)\" % (self.blkCountOut))\n+    def __init__(self, settings, blkindex, blkmap):\n+        self.settings = settings\n+        self.blkindex = blkindex\n+        self.blkmap = blkmap\n+\n+        self.inFn = 0\n+        self.inF = None\n+        self.outFn = 0\n+        self.outsz = 0\n+        self.outF = None\n+        self.outFname = None\n+        self.blkCountIn = 0\n+        self.blkCountOut = 0\n+\n+        self.lastDate = datetime.datetime(2000, 1, 1)\n+        self.highTS = 1408893517 - 315360000\n+        self.timestampSplit = False\n+        self.fileOutput = True\n+        self.setFileTime = False\n+        self.maxOutSz = settings['max_out_sz']\n+        if 'output' in settings:\n+            self.fileOutput = False\n+        if settings['file_timestamp'] != 0:\n+            self.setFileTime = True\n+        if settings['split_timestamp'] != 0:\n+            self.timestampSplit = True\n+        # Extents and cache for out-of-order blocks\n+        self.blockExtents = {}\n+        self.outOfOrderData = {}\n+        self.outOfOrderSize = 0 # running total size for items in outOfOrderData\n+\n+    def writeBlock(self, inhdr, blk_hdr, rawblock):\n+        blockSizeOnDisk = len(inhdr) + len(blk_hdr) + len(rawblock)\n+        if not self.fileOutput and ((self.outsz + blockSizeOnDisk) > self.maxOutSz):\n+            self.outF.close()\n+            if self.setFileTime:\n+                os.utime(self.outFname, (int(time.time()), self.highTS))\n+            self.outF = None\n+            self.outFname = None\n+            self.outFn = self.outFn + 1\n+            self.outsz = 0\n+\n+        (blkDate, blkTS) = get_blk_dt(blk_hdr)\n+        if self.timestampSplit and (blkDate > self.lastDate):\n+            print(\"New month \" + blkDate.strftime(\"%Y-%m\") + \" @ \" + self.hash_str)\n+            self.lastDate = blkDate\n+            if self.outF:\n+                self.outF.close()\n+                if self.setFileTime:\n+                    os.utime(self.outFname, (int(time.time()), self.highTS))\n+                self.outF = None\n+                self.outFname = None\n+                self.outFn = self.outFn + 1\n+                self.outsz = 0\n+\n+        if not self.outF:\n+            if self.fileOutput:\n+                self.outFname = self.settings['output_file']\n+            else:\n+                self.outFname = os.path.join(self.settings['output'], \"blk%05d.dat\" % self.outFn)\n+            print(\"Output file \" + self.outFname)\n+            self.outF = open(self.outFname, \"wb\")\n+\n+        self.outF.write(inhdr)\n+        self.outF.write(blk_hdr)\n+        self.outF.write(rawblock)\n+        self.outsz = self.outsz + len(inhdr) + len(blk_hdr) + len(rawblock)\n+\n+        self.blkCountOut = self.blkCountOut + 1\n+        if blkTS > self.highTS:\n+            self.highTS = blkTS\n+\n+        if (self.blkCountOut % 1000) == 0:\n+            print('%i blocks scanned, %i blocks written (of %i, %.1f%% complete)' %\n+                    (self.blkCountIn, self.blkCountOut, len(self.blkindex), 100.0 * self.blkCountOut / len(self.blkindex)))\n+\n+    def inFileName(self, fn):\n+        return os.path.join(self.settings['input'], \"blk%05d.dat\" % fn)\n+\n+    def fetchBlock(self, extent):\n+        '''Fetch block contents from disk given extents'''\n+        with open(self.inFileName(extent.fn), \"rb\") as f:\n+            f.seek(extent.offset)\n+            return f.read(extent.size)\n+\n+    def copyOneBlock(self):\n+        '''Find the next block to be written in the input, and copy it to the output.'''\n+        extent = self.blockExtents.pop(self.blkCountOut)\n+        if self.blkCountOut in self.outOfOrderData:\n+            # If the data is cached, use it from memory and remove from the cache\n+            rawblock = self.outOfOrderData.pop(self.blkCountOut)\n+            self.outOfOrderSize -= len(rawblock)\n+        else: # Otherwise look up data on disk\n+            rawblock = self.fetchBlock(extent)\n+\n+        self.writeBlock(extent.inhdr, extent.blkhdr, rawblock)\n+\n+    def run(self):\n+        while self.blkCountOut < len(self.blkindex):\n+            if not self.inF:\n+                fname = self.inFileName(self.inFn)\n+                print(\"Input file \" + fname)\n+                try:\n+                    self.inF = open(fname, \"rb\")\n+                except IOError:\n+                    print(\"Premature end of block data\")\n+                    return\n+\n+            inhdr = self.inF.read(8)\n+            if (not inhdr or (inhdr[0] == \"\\0\")):\n+                self.inF.close()\n+                self.inF = None\n+                self.inFn = self.inFn + 1\n+                continue\n+\n+            inMagic = inhdr[:4]\n+            if (inMagic != self.settings['netmagic']):\n+                print(\"Invalid magic: \" + hexlify(inMagic).decode('utf-8'))\n+                return\n+            inLenLE = inhdr[4:]\n+            su = struct.unpack(\"<I\", inLenLE)\n+            inLen = su[0] - 80 # length without header\n+            blk_hdr = self.inF.read(80)\n+            inExtent = BlockExtent(self.inFn, self.inF.tell(), inhdr, blk_hdr, inLen)\n+\n+            self.hash_str = calc_hash_str(blk_hdr)\n+            if not self.hash_str in blkmap:\n+                # Because blocks can be written to files out-of-order as of 0.10, the script\n+                # may encounter blocks it doesn't know about. Treat as debug output.\n+                if settings['debug_output'] == 'true':\n+                    print(\"Skipping unknown block \" + self.hash_str)\n+                self.inF.seek(inLen, os.SEEK_CUR)\n+                continue\n+\n+            blkHeight = self.blkmap[self.hash_str]\n+            self.blkCountIn += 1\n+\n+            if self.blkCountOut == blkHeight:\n+                # If in-order block, just copy\n+                rawblock = self.inF.read(inLen)\n+                self.writeBlock(inhdr, blk_hdr, rawblock)\n+\n+                # See if we can catch up to prior out-of-order blocks\n+                while self.blkCountOut in self.blockExtents:\n+                    self.copyOneBlock()\n+\n+            else: # If out-of-order, skip over block data for now\n+                self.blockExtents[blkHeight] = inExtent\n+                if self.outOfOrderSize < self.settings['out_of_order_cache_sz']:\n+                    # If there is space in the cache, read the data\n+                    # Reading the data in file sequence instead of seeking and fetching it later is preferred,\n+                    # but we don't want to fill up memory\n+                    self.outOfOrderData[blkHeight] = self.inF.read(inLen)\n+                    self.outOfOrderSize += inLen\n+                else: # If no space in cache, seek forward\n+                    self.inF.seek(inLen, os.SEEK_CUR)\n+\n+        print(\"Done (%i blocks written)\" % (self.blkCountOut))\n \n if __name__ == '__main__':\n-\tif len(sys.argv) != 2:\n-\t\tprint(\"Usage: linearize-data.py CONFIG-FILE\")\n-\t\tsys.exit(1)\n-\n-\tf = open(sys.argv[1])\n-\tfor line in f:\n-\t\t# skip comment lines\n-\t\tm = re.search('^\\s*#', line)\n-\t\tif m:\n-\t\t\tcontinue\n-\n-\t\t# parse key=value lines\n-\t\tm = re.search('^(\\w+)\\s*=\\s*(\\S.*)$', line)\n-\t\tif m is None:\n-\t\t\tcontinue\n-\t\tsettings[m.group(1)] = m.group(2)\n-\tf.close()\n-\n-\t# Force hash byte format setting to be lowercase to make comparisons easier.\n-\t# Also place upfront in case any settings need to know about it.\n-\tif 'rev_hash_bytes' not in settings:\n-\t\tsettings['rev_hash_bytes'] = 'false'\n-\tsettings['rev_hash_bytes'] = settings['rev_hash_bytes'].lower()\n-\n-\tif 'netmagic' not in settings:\n-\t\tsettings['netmagic'] = 'f9beb4d9'\n-\tif 'genesis' not in settings:\n-\t\tsettings['genesis'] = '000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f'\n-\tif 'input' not in settings:\n-\t\tsettings['input'] = 'input'\n-\tif 'hashlist' not in settings:\n-\t\tsettings['hashlist'] = 'hashlist.txt'\n-\tif 'file_timestamp' not in settings:\n-\t\tsettings['file_timestamp'] = 0\n-\tif 'split_timestamp' not in settings:\n-\t\tsettings['split_timestamp'] = 0\n-\tif 'max_out_sz' not in settings:\n-\t\tsettings['max_out_sz'] = 1000 * 1000 * 1000\n-\tif 'out_of_order_cache_sz' not in settings:\n-\t\tsettings['out_of_order_cache_sz'] = 100 * 1000 * 1000\n-\tif 'debug_output' not in settings:\n-\t\tsettings['debug_output'] = 'false'\n-\n-\tsettings['max_out_sz'] = int(settings['max_out_sz'])\n-\tsettings['split_timestamp'] = int(settings['split_timestamp'])\n-\tsettings['file_timestamp'] = int(settings['file_timestamp'])\n-\tsettings['netmagic'] = unhexlify(settings['netmagic'].encode('utf-8'))\n-\tsettings['out_of_order_cache_sz'] = int(settings['out_of_order_cache_sz'])\n-\tsettings['debug_output'] = settings['debug_output'].lower()\n-\n-\tif 'output_file' not in settings and 'output' not in settings:\n-\t\tprint(\"Missing output file / directory\")\n-\t\tsys.exit(1)\n-\n-\tblkindex = get_block_hashes(settings)\n-\tblkmap = mkblockmap(blkindex)\n-\n-\t# Block hash map won't be byte-reversed. Neither should the genesis hash.\n-\tif not settings['genesis'] in blkmap:\n-\t\tprint(\"Genesis block not found in hashlist\")\n-\telse:\n-\t\tBlockDataCopier(settings, blkindex, blkmap).run()\n+    if len(sys.argv) != 2:\n+        print(\"Usage: linearize-data.py CONFIG-FILE\")\n+        sys.exit(1)\n+\n+    f = open(sys.argv[1])\n+    for line in f:\n+        # skip comment lines\n+        m = re.search('^\\s*#', line)\n+        if m:\n+            continue\n+\n+        # parse key=value lines\n+        m = re.search('^(\\w+)\\s*=\\s*(\\S.*)$', line)\n+        if m is None:\n+            continue\n+        settings[m.group(1)] = m.group(2)\n+    f.close()\n+\n+    # Force hash byte format setting to be lowercase to make comparisons easier.\n+    # Also place upfront in case any settings need to know about it.\n+    if 'rev_hash_bytes' not in settings:\n+        settings['rev_hash_bytes'] = 'false'\n+    settings['rev_hash_bytes'] = settings['rev_hash_bytes'].lower()\n+\n+    if 'netmagic' not in settings:\n+        settings['netmagic'] = 'f9beb4d9'\n+    if 'genesis' not in settings:\n+        settings['genesis'] = '000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f'\n+    if 'input' not in settings:\n+        settings['input'] = 'input'\n+    if 'hashlist' not in settings:\n+        settings['hashlist'] = 'hashlist.txt'\n+    if 'file_timestamp' not in settings:\n+        settings['file_timestamp'] = 0\n+    if 'split_timestamp' not in settings:\n+        settings['split_timestamp'] = 0\n+    if 'max_out_sz' not in settings:\n+        settings['max_out_sz'] = 1000 * 1000 * 1000\n+    if 'out_of_order_cache_sz' not in settings:\n+        settings['out_of_order_cache_sz'] = 100 * 1000 * 1000\n+    if 'debug_output' not in settings:\n+        settings['debug_output'] = 'false'\n+\n+    settings['max_out_sz'] = int(settings['max_out_sz'])\n+    settings['split_timestamp'] = int(settings['split_timestamp'])\n+    settings['file_timestamp'] = int(settings['file_timestamp'])\n+    settings['netmagic'] = unhexlify(settings['netmagic'].encode('utf-8'))\n+    settings['out_of_order_cache_sz'] = int(settings['out_of_order_cache_sz'])\n+    settings['debug_output'] = settings['debug_output'].lower()\n+\n+    if 'output_file' not in settings and 'output' not in settings:\n+        print(\"Missing output file / directory\")\n+        sys.exit(1)\n+\n+    blkindex = get_block_hashes(settings)\n+    blkmap = mkblockmap(blkindex)\n+\n+    # Block hash map won't be byte-reversed. Neither should the genesis hash.\n+    if not settings['genesis'] in blkmap:\n+        print(\"Genesis block not found in hashlist\")\n+    else:\n+        BlockDataCopier(settings, blkindex, blkmap).run()"
      },
      {
        "sha": "8e1266ae0b466ec993786f7cbb3873f16c2c6c0c",
        "filename": "contrib/linearize/linearize-hashes.py",
        "status": "modified",
        "additions": 124,
        "deletions": 124,
        "changes": 248,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/linearize/linearize-hashes.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/linearize/linearize-hashes.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/linearize/linearize-hashes.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -22,135 +22,135 @@\n settings = {}\n \n def hex_switchEndian(s):\n-\t\"\"\" Switches the endianness of a hex string (in pairs of hex chars) \"\"\"\n-\tpairList = [s[i:i+2].encode() for i in range(0, len(s), 2)]\n-\treturn b''.join(pairList[::-1]).decode()\n+    \"\"\" Switches the endianness of a hex string (in pairs of hex chars) \"\"\"\n+    pairList = [s[i:i+2].encode() for i in range(0, len(s), 2)]\n+    return b''.join(pairList[::-1]).decode()\n \n class BitcoinRPC:\n-\tdef __init__(self, host, port, username, password):\n-\t\tauthpair = \"%s:%s\" % (username, password)\n-\t\tauthpair = authpair.encode('utf-8')\n-\t\tself.authhdr = b\"Basic \" + base64.b64encode(authpair)\n-\t\tself.conn = httplib.HTTPConnection(host, port=port, timeout=30)\n-\n-\tdef execute(self, obj):\n-\t\ttry:\n-\t\t\tself.conn.request('POST', '/', json.dumps(obj),\n-\t\t\t\t{ 'Authorization' : self.authhdr,\n-\t\t\t\t  'Content-type' : 'application/json' })\n-\t\texcept ConnectionRefusedError:\n-\t\t\tprint('RPC connection refused. Check RPC settings and the server status.',\n-\t\t\t      file=sys.stderr)\n-\t\t\treturn None\n-\n-\t\tresp = self.conn.getresponse()\n-\t\tif resp is None:\n-\t\t\tprint(\"JSON-RPC: no response\", file=sys.stderr)\n-\t\t\treturn None\n-\n-\t\tbody = resp.read().decode('utf-8')\n-\t\tresp_obj = json.loads(body)\n-\t\treturn resp_obj\n-\n-\t@staticmethod\n-\tdef build_request(idx, method, params):\n-\t\tobj = { 'version' : '1.1',\n-\t\t\t'method' : method,\n-\t\t\t'id' : idx }\n-\t\tif params is None:\n-\t\t\tobj['params'] = []\n-\t\telse:\n-\t\t\tobj['params'] = params\n-\t\treturn obj\n-\n-\t@staticmethod\n-\tdef response_is_error(resp_obj):\n-\t\treturn 'error' in resp_obj and resp_obj['error'] is not None\n+    def __init__(self, host, port, username, password):\n+        authpair = \"%s:%s\" % (username, password)\n+        authpair = authpair.encode('utf-8')\n+        self.authhdr = b\"Basic \" + base64.b64encode(authpair)\n+        self.conn = httplib.HTTPConnection(host, port=port, timeout=30)\n+\n+    def execute(self, obj):\n+        try:\n+            self.conn.request('POST', '/', json.dumps(obj),\n+                { 'Authorization' : self.authhdr,\n+                  'Content-type' : 'application/json' })\n+        except ConnectionRefusedError:\n+            print('RPC connection refused. Check RPC settings and the server status.',\n+                  file=sys.stderr)\n+            return None\n+\n+        resp = self.conn.getresponse()\n+        if resp is None:\n+            print(\"JSON-RPC: no response\", file=sys.stderr)\n+            return None\n+\n+        body = resp.read().decode('utf-8')\n+        resp_obj = json.loads(body)\n+        return resp_obj\n+\n+    @staticmethod\n+    def build_request(idx, method, params):\n+        obj = { 'version' : '1.1',\n+            'method' : method,\n+            'id' : idx }\n+        if params is None:\n+            obj['params'] = []\n+        else:\n+            obj['params'] = params\n+        return obj\n+\n+    @staticmethod\n+    def response_is_error(resp_obj):\n+        return 'error' in resp_obj and resp_obj['error'] is not None\n \n def get_block_hashes(settings, max_blocks_per_call=10000):\n-\trpc = BitcoinRPC(settings['host'], settings['port'],\n-\t\t\t settings['rpcuser'], settings['rpcpassword'])\n-\n-\theight = settings['min_height']\n-\twhile height < settings['max_height']+1:\n-\t\tnum_blocks = min(settings['max_height']+1-height, max_blocks_per_call)\n-\t\tbatch = []\n-\t\tfor x in range(num_blocks):\n-\t\t\tbatch.append(rpc.build_request(x, 'getblockhash', [height + x]))\n-\n-\t\treply = rpc.execute(batch)\n-\t\tif reply is None:\n-\t\t\tprint('Cannot continue. Program will halt.')\n-\t\t\treturn None\n-\n-\t\tfor x,resp_obj in enumerate(reply):\n-\t\t\tif rpc.response_is_error(resp_obj):\n-\t\t\t\tprint('JSON-RPC: error at height', height+x, ': ', resp_obj['error'], file=sys.stderr)\n-\t\t\t\tsys.exit(1)\n-\t\t\tassert(resp_obj['id'] == x) # assume replies are in-sequence\n-\t\t\tif settings['rev_hash_bytes'] == 'true':\n-\t\t\t\tresp_obj['result'] = hex_switchEndian(resp_obj['result'])\n-\t\t\tprint(resp_obj['result'])\n-\n-\t\theight += num_blocks\n+    rpc = BitcoinRPC(settings['host'], settings['port'],\n+             settings['rpcuser'], settings['rpcpassword'])\n+\n+    height = settings['min_height']\n+    while height < settings['max_height']+1:\n+        num_blocks = min(settings['max_height']+1-height, max_blocks_per_call)\n+        batch = []\n+        for x in range(num_blocks):\n+            batch.append(rpc.build_request(x, 'getblockhash', [height + x]))\n+\n+        reply = rpc.execute(batch)\n+        if reply is None:\n+            print('Cannot continue. Program will halt.')\n+            return None\n+\n+        for x,resp_obj in enumerate(reply):\n+            if rpc.response_is_error(resp_obj):\n+                print('JSON-RPC: error at height', height+x, ': ', resp_obj['error'], file=sys.stderr)\n+                sys.exit(1)\n+            assert(resp_obj['id'] == x) # assume replies are in-sequence\n+            if settings['rev_hash_bytes'] == 'true':\n+                resp_obj['result'] = hex_switchEndian(resp_obj['result'])\n+            print(resp_obj['result'])\n+\n+        height += num_blocks\n \n def get_rpc_cookie():\n-\t# Open the cookie file\n-\twith open(os.path.join(os.path.expanduser(settings['datadir']), '.cookie'), 'r') as f:\n-\t\tcombined = f.readline()\n-\t\tcombined_split = combined.split(\":\")\n-\t\tsettings['rpcuser'] = combined_split[0]\n-\t\tsettings['rpcpassword'] = combined_split[1]\n+    # Open the cookie file\n+    with open(os.path.join(os.path.expanduser(settings['datadir']), '.cookie'), 'r') as f:\n+        combined = f.readline()\n+        combined_split = combined.split(\":\")\n+        settings['rpcuser'] = combined_split[0]\n+        settings['rpcpassword'] = combined_split[1]\n \n if __name__ == '__main__':\n-\tif len(sys.argv) != 2:\n-\t\tprint(\"Usage: linearize-hashes.py CONFIG-FILE\")\n-\t\tsys.exit(1)\n-\n-\tf = open(sys.argv[1])\n-\tfor line in f:\n-\t\t# skip comment lines\n-\t\tm = re.search('^\\s*#', line)\n-\t\tif m:\n-\t\t\tcontinue\n-\n-\t\t# parse key=value lines\n-\t\tm = re.search('^(\\w+)\\s*=\\s*(\\S.*)$', line)\n-\t\tif m is None:\n-\t\t\tcontinue\n-\t\tsettings[m.group(1)] = m.group(2)\n-\tf.close()\n-\n-\tif 'host' not in settings:\n-\t\tsettings['host'] = '127.0.0.1'\n-\tif 'port' not in settings:\n-\t\tsettings['port'] = 8332\n-\tif 'min_height' not in settings:\n-\t\tsettings['min_height'] = 0\n-\tif 'max_height' not in settings:\n-\t\tsettings['max_height'] = 313000\n-\tif 'rev_hash_bytes' not in settings:\n-\t\tsettings['rev_hash_bytes'] = 'false'\n-\n-\tuse_userpass = True\n-\tuse_datadir = False\n-\tif 'rpcuser' not in settings or 'rpcpassword' not in settings:\n-\t\tuse_userpass = False\n-\tif 'datadir' in settings and not use_userpass:\n-\t\tuse_datadir = True\n-\tif not use_userpass and not use_datadir:\n-\t\tprint(\"Missing datadir or username and/or password in cfg file\", file=sys.stderr)\n-\t\tsys.exit(1)\n-\n-\tsettings['port'] = int(settings['port'])\n-\tsettings['min_height'] = int(settings['min_height'])\n-\tsettings['max_height'] = int(settings['max_height'])\n-\n-\t# Force hash byte format setting to be lowercase to make comparisons easier.\n-\tsettings['rev_hash_bytes'] = settings['rev_hash_bytes'].lower()\n-\n-\t# Get the rpc user and pass from the cookie if the datadir is set\n-\tif use_datadir:\n-\t\tget_rpc_cookie()\n-\n-\tget_block_hashes(settings)\n+    if len(sys.argv) != 2:\n+        print(\"Usage: linearize-hashes.py CONFIG-FILE\")\n+        sys.exit(1)\n+\n+    f = open(sys.argv[1])\n+    for line in f:\n+        # skip comment lines\n+        m = re.search('^\\s*#', line)\n+        if m:\n+            continue\n+\n+        # parse key=value lines\n+        m = re.search('^(\\w+)\\s*=\\s*(\\S.*)$', line)\n+        if m is None:\n+            continue\n+        settings[m.group(1)] = m.group(2)\n+    f.close()\n+\n+    if 'host' not in settings:\n+        settings['host'] = '127.0.0.1'\n+    if 'port' not in settings:\n+        settings['port'] = 8332\n+    if 'min_height' not in settings:\n+        settings['min_height'] = 0\n+    if 'max_height' not in settings:\n+        settings['max_height'] = 313000\n+    if 'rev_hash_bytes' not in settings:\n+        settings['rev_hash_bytes'] = 'false'\n+\n+    use_userpass = True\n+    use_datadir = False\n+    if 'rpcuser' not in settings or 'rpcpassword' not in settings:\n+        use_userpass = False\n+    if 'datadir' in settings and not use_userpass:\n+        use_datadir = True\n+    if not use_userpass and not use_datadir:\n+        print(\"Missing datadir or username and/or password in cfg file\", file=sys.stderr)\n+        sys.exit(1)\n+\n+    settings['port'] = int(settings['port'])\n+    settings['min_height'] = int(settings['min_height'])\n+    settings['max_height'] = int(settings['max_height'])\n+\n+    # Force hash byte format setting to be lowercase to make comparisons easier.\n+    settings['rev_hash_bytes'] = settings['rev_hash_bytes'].lower()\n+\n+    # Get the rpc user and pass from the cookie if the datadir is set\n+    if use_datadir:\n+        get_rpc_cookie()\n+\n+    get_block_hashes(settings)"
      },
      {
        "sha": "ace7d3534f78e664d9421121b27f0c27fb70d294",
        "filename": "contrib/seeds/generate-seeds.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/seeds/generate-seeds.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/contrib/seeds/generate-seeds.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/seeds/generate-seeds.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -11,7 +11,7 @@\n     nodes_main.txt\n     nodes_test.txt\n \n-These files must consist of lines in the format \n+These files must consist of lines in the format\n \n     <ip>\n     <ip>:<port>"
      },
      {
        "sha": "6d8d9843eb20a68a2bdae8545cd69d603e94d0db",
        "filename": "test/functional/feature_bip68_sequence.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/feature_bip68_sequence.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/feature_bip68_sequence.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_bip68_sequence.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -67,7 +67,7 @@ def test_disable_flag(self):\n         # If sequence locks were used, this would require 1 block for the\n         # input to mature.\n         sequence_value = SEQUENCE_LOCKTIME_DISABLE_FLAG | 1\n-        tx1.vin = [CTxIn(COutPoint(int(utxo[\"txid\"], 16), utxo[\"vout\"]), nSequence=sequence_value)] \n+        tx1.vin = [CTxIn(COutPoint(int(utxo[\"txid\"], 16), utxo[\"vout\"]), nSequence=sequence_value)]\n         tx1.vout = [CTxOut(value, CScript([b'a']))]\n \n         tx1_signed = self.nodes[0].signrawtransactionwithwallet(ToHex(tx1))[\"hex\"]"
      },
      {
        "sha": "0946f27b90ded98f1658fbb2992c376e9b14bcfd",
        "filename": "test/functional/feature_maxuploadtarget.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/feature_maxuploadtarget.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/feature_maxuploadtarget.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_maxuploadtarget.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -100,7 +100,7 @@ def run_test(self):\n             assert_equal(p2p_conns[0].block_receive_map[big_old_block], i+1)\n \n         assert_equal(len(self.nodes[0].getpeerinfo()), 3)\n-        # At most a couple more tries should succeed (depending on how long \n+        # At most a couple more tries should succeed (depending on how long\n         # the test has been running so far).\n         for i in range(3):\n             p2p_conns[0].send_message(getdata_request)"
      },
      {
        "sha": "2d10c547e2ab57aa49a117f0864e15a2b8b7601c",
        "filename": "test/functional/feature_proxy.py",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/feature_proxy.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/feature_proxy.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/feature_proxy.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -79,9 +79,9 @@ def setup_nodes(self):\n         # Note: proxies are not used to connect to local nodes\n         # this is because the proxy to use is based on CService.GetNetwork(), which return NET_UNROUTABLE for localhost\n         args = [\n-            ['-listen', '-proxy=%s:%i' % (self.conf1.addr),'-proxyrandomize=1'], \n-            ['-listen', '-proxy=%s:%i' % (self.conf1.addr),'-onion=%s:%i' % (self.conf2.addr),'-proxyrandomize=0'], \n-            ['-listen', '-proxy=%s:%i' % (self.conf2.addr),'-proxyrandomize=1'], \n+            ['-listen', '-proxy=%s:%i' % (self.conf1.addr),'-proxyrandomize=1'],\n+            ['-listen', '-proxy=%s:%i' % (self.conf1.addr),'-onion=%s:%i' % (self.conf2.addr),'-proxyrandomize=0'],\n+            ['-listen', '-proxy=%s:%i' % (self.conf2.addr),'-proxyrandomize=1'],\n             []\n             ]\n         if self.have_ipv6:"
      },
      {
        "sha": "c304bbba859ac12fcca84aaf7b17c57bf268c027",
        "filename": "test/functional/p2p_feefilter.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/p2p_feefilter.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/p2p_feefilter.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_feefilter.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -69,7 +69,7 @@ def run_test(self):\n         # Change tx fee rate to 10 sat/byte and test they are no longer received\n         node1.settxfee(Decimal(\"0.00010000\"))\n         [node1.sendtoaddress(node1.getnewaddress(), 1) for x in range(3)]\n-        sync_mempools(self.nodes) # must be sure node 0 has received all txs \n+        sync_mempools(self.nodes) # must be sure node 0 has received all txs\n \n         # Send one transaction from node0 that should be received, so that we\n         # we can sync the test on receipt (if node1's txs were relayed, they'd"
      },
      {
        "sha": "e56d2acfcf8058097b73a10c407a13bde0d6f943",
        "filename": "test/functional/p2p_segwit.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/p2p_segwit.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/p2p_segwit.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_segwit.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -1659,7 +1659,7 @@ def test_witness_sigops(self):\n             tx2.wit.vtxinwit.append(CTxInWitness())\n             tx2.wit.vtxinwit[-1].scriptWitness.stack = [ witness_program ]\n             total_value += tx.vout[i].nValue\n-        tx2.wit.vtxinwit[-1].scriptWitness.stack = [ witness_program_toomany ] \n+        tx2.wit.vtxinwit[-1].scriptWitness.stack = [ witness_program_toomany ]\n         tx2.vout.append(CTxOut(total_value, CScript([OP_TRUE])))\n         tx2.rehash()\n "
      },
      {
        "sha": "01d27dabe7364496b7c41d0450b4206399bd4725",
        "filename": "test/functional/wallet_dump.py",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/wallet_dump.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/0d31ef4762f5a1428a57439d26551a99f15ddc2e/test/functional/wallet_dump.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/wallet_dump.py?ref=0d31ef4762f5a1428a57439d26551a99f15ddc2e",
        "patch": "@@ -136,7 +136,7 @@ def run_test (self):\n         assert_equal(found_addr, test_addr_count)\n         assert_equal(found_script_addr, 2)\n         assert_equal(found_addr_chg, 90*2 + 50)  # old reserve keys are marked as change now\n-        assert_equal(found_addr_rsv, 90*2) \n+        assert_equal(found_addr_rsv, 90*2)\n         assert_equal(witness_addr_ret, witness_addr)\n \n         # Overwriting should fail"
      }
    ]
  }
]