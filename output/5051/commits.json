[
  {
    "sha": "aedc74dfa688306c5a139a88782da74f69ba6757",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzphZWRjNzRkZmE2ODgzMDZjNWExMzlhODg3ODJkYTc0ZjY5YmE2NzU3",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@gmail.com",
        "date": "2014-10-06T15:55:55Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@gmail.com",
        "date": "2014-10-06T16:30:12Z"
      },
      "message": "contrib: make linearize-data.py cope with out-of-order blocks\n\nMake it possible to read blocks in any order. This will be required\nafter headers-first (#4468), so should be merged before that.\n\n- Read block header. For expected blocks, continue, else skip.\n- For in-order blocks: copy block contents directly. Write prior\n  out-of-order blocks if this connects a consecutive span.\n- For out-of-order blocks, store extents of block data for later\n  retrieval. Cache out-of-order blocks in memory up to 100MB\n  (configurable).",
      "tree": {
        "sha": "9e7b2fd87c426010465298c3ab5d72ba54bad66d",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/9e7b2fd87c426010465298c3ab5d72ba54bad66d"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/aedc74dfa688306c5a139a88782da74f69ba6757",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/aedc74dfa688306c5a139a88782da74f69ba6757",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/aedc74dfa688306c5a139a88782da74f69ba6757",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/aedc74dfa688306c5a139a88782da74f69ba6757/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "5505a1b13f75af9f0f6421b42d97c06e079db345",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/5505a1b13f75af9f0f6421b42d97c06e079db345",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/5505a1b13f75af9f0f6421b42d97c06e079db345"
      }
    ],
    "stats": {
      "total": 260,
      "additions": 162,
      "deletions": 98
    },
    "files": [
      {
        "sha": "e0fef13886d92aa96b6172e8eab7116895fd09f7",
        "filename": "contrib/linearize/example-linearize.cfg",
        "status": "modified",
        "additions": 2,
        "deletions": 0,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/aedc74dfa688306c5a139a88782da74f69ba6757/contrib/linearize/example-linearize.cfg",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/aedc74dfa688306c5a139a88782da74f69ba6757/contrib/linearize/example-linearize.cfg",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/linearize/example-linearize.cfg?ref=aedc74dfa688306c5a139a88782da74f69ba6757",
        "patch": "@@ -15,3 +15,5 @@ output_file=/home/example/Downloads/bootstrap.dat\n hashlist=hashlist.txt\n split_year=1\n \n+# Maxmimum size in bytes of out-of-order blocks cache in memory\n+out_of_order_cache_sz = 100000000"
      },
      {
        "sha": "2dac3a614b03180b7d6804cd7d195e3e2a92e7c2",
        "filename": "contrib/linearize/linearize-data.py",
        "status": "modified",
        "additions": 160,
        "deletions": 98,
        "changes": 258,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/aedc74dfa688306c5a139a88782da74f69ba6757/contrib/linearize/linearize-data.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/aedc74dfa688306c5a139a88782da74f69ba6757/contrib/linearize/linearize-data.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/linearize/linearize-data.py?ref=aedc74dfa688306c5a139a88782da74f69ba6757",
        "patch": "@@ -2,11 +2,12 @@\n #\n # linearize-data.py: Construct a linear, no-fork version of the chain.\n #\n-# Copyright (c) 2013 The Bitcoin developers\n+# Copyright (c) 2013-2014 The Bitcoin developers\n # Distributed under the MIT/X11 software license, see the accompanying\n # file COPYING or http://www.opensource.org/licenses/mit-license.php.\n #\n \n+from __future__ import print_function, division\n import json\n import struct\n import re\n@@ -17,10 +18,10 @@\n import hashlib\n import datetime\n import time\n+from collections import namedtuple\n \n settings = {}\n \n-\n def uint32(x):\n \treturn x & 0xffffffffL\n \n@@ -78,116 +79,174 @@ def get_block_hashes(settings):\n \n \treturn blkindex\n \n-def mkblockset(blkindex):\n+def mkblockmap(blkindex):\n \tblkmap = {}\n-\tfor hash in blkindex:\n-\t\tblkmap[hash] = True\n+\tfor height,hash in enumerate(blkindex):\n+\t\tblkmap[hash] = height\n \treturn blkmap\n \n-def copydata(settings, blkindex, blkset):\n-\tinFn = 0\n-\tinF = None\n-\toutFn = 0\n-\toutsz = 0\n-\toutF = None\n-\toutFname = None\n-\tblkCount = 0\n-\n-\tlastDate = datetime.datetime(2000, 1, 1)\n-\thighTS = 1408893517 - 315360000\n-\ttimestampSplit = False\n-\tfileOutput = True\n-\tsetFileTime = False\n-\tmaxOutSz = settings['max_out_sz']\n-\tif 'output' in settings:\n-\t\tfileOutput = False\n-\tif settings['file_timestamp'] != 0:\n-\t\tsetFileTime = True\n-\tif settings['split_timestamp'] != 0:\n-\t\ttimestampSplit = True\n-\n-\twhile True:\n-\t\tif not inF:\n-\t\t\tfname = \"%s/blk%05d.dat\" % (settings['input'], inFn)\n-\t\t\tprint(\"Input file\" + fname)\n-\t\t\ttry:\n-\t\t\t\tinF = open(fname, \"rb\")\n-\t\t\texcept IOError:\n-\t\t\t\tprint \"Done\"\n-\t\t\t\treturn\n-\n-\t\tinhdr = inF.read(8)\n-\t\tif (not inhdr or (inhdr[0] == \"\\0\")):\n-\t\t\tinF.close()\n-\t\t\tinF = None\n-\t\t\tinFn = inFn + 1\n-\t\t\tcontinue\n-\n-\t\tinMagic = inhdr[:4]\n-\t\tif (inMagic != settings['netmagic']):\n-\t\t\tprint(\"Invalid magic:\" + inMagic)\n-\t\t\treturn\n-\t\tinLenLE = inhdr[4:]\n-\t\tsu = struct.unpack(\"<I\", inLenLE)\n-\t\tinLen = su[0]\n-\t\trawblock = inF.read(inLen)\n-\t\tblk_hdr = rawblock[:80]\n-\n-\t\thash_str = calc_hash_str(blk_hdr)\n-\t\tif not hash_str in blkset:\n-\t\t\tprint(\"Skipping unknown block \" + hash_str)\n-\t\t\tcontinue\n-\n-\t\tif blkindex[blkCount] != hash_str:\n-\t\t\tprint(\"Out of order block.\")\n-\t\t\tprint(\"Expected \" + blkindex[blkCount])\n-\t\t\tprint(\"Got \" + hash_str)\n-\t\t\tsys.exit(1)\n-\n-\t\tif not fileOutput and ((outsz + inLen) > maxOutSz):\n-\t\t\toutF.close()\n-\t\t\tif setFileTime:\n+# Block header and extent on disk\n+BlockExtent = namedtuple('BlockExtent', ['fn', 'offset', 'inhdr', 'blkhdr', 'size'])\n+\n+class BlockDataCopier:\n+\tdef __init__(self, settings, blkindex, blkmap):\n+\t\tself.settings = settings\n+\t\tself.blkindex = blkindex\n+\t\tself.blkmap = blkmap\n+\n+\t\tself.inFn = 0\n+\t\tself.inF = None\n+\t\tself.outFn = 0\n+\t\tself.outsz = 0\n+\t\tself.outF = None\n+\t\tself.outFname = None\n+\t\tself.blkCountIn = 0\n+\t\tself.blkCountOut = 0\n+\n+\t\tself.lastDate = datetime.datetime(2000, 1, 1)\n+\t\tself.highTS = 1408893517 - 315360000\n+\t\tself.timestampSplit = False\n+\t\tself.fileOutput = True\n+\t\tself.setFileTime = False\n+\t\tself.maxOutSz = settings['max_out_sz']\n+\t\tif 'output' in settings:\n+\t\t\tself.fileOutput = False\n+\t\tif settings['file_timestamp'] != 0:\n+\t\t\tself.setFileTime = True\n+\t\tif settings['split_timestamp'] != 0:\n+\t\t\tself.timestampSplit = True\n+        # Extents and cache for out-of-order blocks\n+\t\tself.blockExtents = {}\n+\t\tself.outOfOrderData = {}\n+\t\tself.outOfOrderSize = 0 # running total size for items in outOfOrderData\n+\n+\tdef writeBlock(self, inhdr, blk_hdr, rawblock):\n+\t\tif not self.fileOutput and ((self.outsz + self.inLen) > self.maxOutSz):\n+\t\t\tself.outF.close()\n+\t\t\tif self.setFileTime:\n \t\t\t\tos.utime(outFname, (int(time.time()), highTS))\n-\t\t\toutF = None\n-\t\t\toutFname = None\n-\t\t\toutFn = outFn + 1\n-\t\t\toutsz = 0\n+\t\t\tself.outF = None\n+\t\t\tself.outFname = None\n+\t\t\tself.outFn = outFn + 1\n+\t\t\tself.outsz = 0\n \n \t\t(blkDate, blkTS) = get_blk_dt(blk_hdr)\n-\t\tif timestampSplit and (blkDate > lastDate):\n+\t\tif self.timestampSplit and (blkDate > self.lastDate):\n \t\t\tprint(\"New month \" + blkDate.strftime(\"%Y-%m\") + \" @ \" + hash_str)\n \t\t\tlastDate = blkDate\n \t\t\tif outF:\n \t\t\t\toutF.close()\n \t\t\t\tif setFileTime:\n \t\t\t\t\tos.utime(outFname, (int(time.time()), highTS))\n-\t\t\t\toutF = None\n-\t\t\t\toutFname = None\n-\t\t\t\toutFn = outFn + 1\n-\t\t\t\toutsz = 0\n-\n-\t\tif not outF:\n-\t\t\tif fileOutput:\n-\t\t\t\toutFname = settings['output_file']\n+\t\t\t\tself.outF = None\n+\t\t\t\tself.outFname = None\n+\t\t\t\tself.outFn = self.outFn + 1\n+\t\t\t\tself.outsz = 0\n+\n+\t\tif not self.outF:\n+\t\t\tif self.fileOutput:\n+\t\t\t\toutFname = self.settings['output_file']\n \t\t\telse:\n-\t\t\t\toutFname = \"%s/blk%05d.dat\" % (settings['output'], outFn)\n+\t\t\t\toutFname = \"%s/blk%05d.dat\" % (self.settings['output'], outFn)\n \t\t\tprint(\"Output file\" + outFname)\n-\t\t\toutF = open(outFname, \"wb\")\n-\n-\t\toutF.write(inhdr)\n-\t\toutF.write(rawblock)\n-\t\toutsz = outsz + inLen + 8\n-\n-\t\tblkCount = blkCount + 1\n-\t\tif blkTS > highTS:\n-\t\t\thighTS = blkTS\n-\n-\t\tif (blkCount % 1000) == 0:\n-\t\t\tprint(\"Wrote \" + str(blkCount) + \" blocks\")\n+\t\t\tself.outF = open(outFname, \"wb\")\n+\n+\t\tself.outF.write(inhdr)\n+\t\tself.outF.write(blk_hdr)\n+\t\tself.outF.write(rawblock)\n+\t\tself.outsz = self.outsz + len(inhdr) + len(blk_hdr) + len(rawblock)\n+\n+\t\tself.blkCountOut = self.blkCountOut + 1\n+\t\tif blkTS > self.highTS:\n+\t\t\tself.highTS = blkTS\n+\n+\t\tif (self.blkCountOut % 1000) == 0:\n+\t\t\tprint('%i blocks scanned, %i blocks written (of %i, %.1f%% complete)' % \n+\t\t\t\t\t(self.blkCountIn, self.blkCountOut, len(self.blkindex), 100.0 * self.blkCountOut / len(self.blkindex)))\n+\n+\tdef inFileName(self, fn):\n+\t\treturn \"%s/blk%05d.dat\" % (self.settings['input'], fn)\n+\n+\tdef fetchBlock(self, extent):\n+\t\t'''Fetch block contents from disk given extents'''\n+\t\twith open(self.inFileName(extent.fn), \"rb\") as f:\n+\t\t\tf.seek(extent.offset)\n+\t\t\treturn f.read(extent.size)\n+\n+\tdef copyOneBlock(self):\n+\t\t'''Find the next block to be written in the input, and copy it to the output.'''\n+\t\textent = self.blockExtents.pop(self.blkCountOut)\n+\t\tif self.blkCountOut in self.outOfOrderData:\n+\t\t\t# If the data is cached, use it from memory and remove from the cache\n+\t\t\trawblock = self.outOfOrderData.pop(self.blkCountOut)\n+\t\t\tself.outOfOrderSize -= len(rawblock)\n+\t\telse: # Otherwise look up data on disk\n+\t\t\trawblock = self.fetchBlock(extent)\n+\n+\t\tself.writeBlock(extent.inhdr, extent.blkhdr, rawblock)\n+\n+\tdef run(self):\n+\t\twhile self.blkCountOut < len(self.blkindex):\n+\t\t\tif not self.inF:\n+\t\t\t\tfname = self.inFileName(self.inFn)\n+\t\t\t\tprint(\"Input file\" + fname)\n+\t\t\t\ttry:\n+\t\t\t\t\tself.inF = open(fname, \"rb\")\n+\t\t\t\texcept IOError:\n+\t\t\t\t\tprint(\"Premature end of block data\")\n+\t\t\t\t\treturn\n+\n+\t\t\tinhdr = self.inF.read(8)\n+\t\t\tif (not inhdr or (inhdr[0] == \"\\0\")):\n+\t\t\t\tself.inF.close()\n+\t\t\t\tself.inF = None\n+\t\t\t\tself.inFn = self.inFn + 1\n+\t\t\t\tcontinue\n+\n+\t\t\tinMagic = inhdr[:4]\n+\t\t\tif (inMagic != self.settings['netmagic']):\n+\t\t\t\tprint(\"Invalid magic:\" + inMagic)\n+\t\t\t\treturn\n+\t\t\tinLenLE = inhdr[4:]\n+\t\t\tsu = struct.unpack(\"<I\", inLenLE)\n+\t\t\tinLen = su[0] - 80 # length without header\n+\t\t\tblk_hdr = self.inF.read(80)\n+\t\t\tinExtent = BlockExtent(self.inFn, self.inF.tell(), inhdr, blk_hdr, inLen)\n+\n+\t\t\thash_str = calc_hash_str(blk_hdr)\n+\t\t\tif not hash_str in blkmap:\n+\t\t\t\tprint(\"Skipping unknown block \" + hash_str)\n+\t\t\t\tself.inF.seek(inLen, os.SEEK_CUR)\n+\t\t\t\tcontinue\n+\n+\t\t\tblkHeight = self.blkmap[hash_str]\n+\t\t\tself.blkCountIn += 1\n+\n+\t\t\tif self.blkCountOut == blkHeight:\n+\t\t\t\t# If in-order block, just copy\n+\t\t\t\trawblock = self.inF.read(inLen)\n+\t\t\t\tself.writeBlock(inhdr, blk_hdr, rawblock)\n+\n+\t\t\t\t# See if we can catch up to prior out-of-order blocks\n+\t\t\t\twhile self.blkCountOut in self.blockExtents:\n+\t\t\t\t\tself.copyOneBlock()\n+\n+\t\t\telse: # If out-of-order, skip over block data for now\n+\t\t\t\tself.blockExtents[blkHeight] = inExtent\n+\t\t\t\tif self.outOfOrderSize < self.settings['out_of_order_cache_sz']:\n+\t\t\t\t\t# If there is space in the cache, read the data\n+\t\t\t\t\t# Reading the data in file sequence instead of seeking and fetching it later is preferred,\n+\t\t\t\t\t# but we don't want to fill up memory\n+\t\t\t\t\tself.outOfOrderData[blkHeight] = self.inF.read(inLen)\n+\t\t\t\t\tself.outOfOrderSize += inLen\n+\t\t\t\telse: # If no space in cache, seek forward\n+\t\t\t\t\tself.inF.seek(inLen, os.SEEK_CUR)\n+\n+\t\tprint(\"Done (%i blocks written)\" % (self.blkCountOut))\n \n if __name__ == '__main__':\n \tif len(sys.argv) != 2:\n-\t\tprint \"Usage: linearize-data.py CONFIG-FILE\"\n+\t\tprint(\"Usage: linearize-data.py CONFIG-FILE\")\n \t\tsys.exit(1)\n \n \tf = open(sys.argv[1])\n@@ -216,22 +275,25 @@ def copydata(settings, blkindex, blkset):\n \t\tsettings['split_timestamp'] = 0\n \tif 'max_out_sz' not in settings:\n \t\tsettings['max_out_sz'] = 1000L * 1000 * 1000\n+\tif 'out_of_order_cache_sz' not in settings:\n+\t\tsettings['out_of_order_cache_sz'] = 100 * 1000 * 1000\n \n \tsettings['max_out_sz'] = long(settings['max_out_sz'])\n \tsettings['split_timestamp'] = int(settings['split_timestamp'])\n \tsettings['file_timestamp'] = int(settings['file_timestamp'])\n \tsettings['netmagic'] = settings['netmagic'].decode('hex')\n+\tsettings['out_of_order_cache_sz'] = int(settings['out_of_order_cache_sz'])\n \n \tif 'output_file' not in settings and 'output' not in settings:\n \t\tprint(\"Missing output file / directory\")\n \t\tsys.exit(1)\n \n \tblkindex = get_block_hashes(settings)\n-\tblkset = mkblockset(blkindex)\n+\tblkmap = mkblockmap(blkindex)\n \n-\tif not \"000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f\" in blkset:\n+\tif not \"000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f\" in blkmap:\n \t\tprint(\"not found\")\n \telse:\n-\t\tcopydata(settings, blkindex, blkset)\n+\t\tBlockDataCopier(settings, blkindex, blkmap).run()\n \n "
      }
    ]
  }
]