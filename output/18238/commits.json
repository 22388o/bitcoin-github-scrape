[
  {
    "sha": "a204d1586ca9e8f2d7b3951358fa5e63faa1810b",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzphMjA0ZDE1ODZjYTllOGYyZDdiMzk1MTM1OGZhNWU2M2ZhYTE4MTBi",
    "commit": {
      "author": {
        "name": "Anthony Towns",
        "email": "aj@erisian.com.au",
        "date": "2020-02-03T11:04:30Z"
      },
      "committer": {
        "name": "Anthony Towns",
        "email": "aj@erisian.com.au",
        "date": "2020-03-02T07:00:59Z"
      },
      "message": "net_processing: Retry notfounds with more urgency\n\nAnytime we see a NOTFOUND in response to a request for a tx, look through\neach of our peers for anyone else who announced the tx, find one who\ndoesn't already have its inflight tx count maxed out, and of those,\nmake the one who'd look at it first, look at it asap.",
      "tree": {
        "sha": "c5109a8682a21c5dc524c06ceb1b6714a99c1178",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/c5109a8682a21c5dc524c06ceb1b6714a99c1178"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/a204d1586ca9e8f2d7b3951358fa5e63faa1810b",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/a204d1586ca9e8f2d7b3951358fa5e63faa1810b",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/a204d1586ca9e8f2d7b3951358fa5e63faa1810b",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/a204d1586ca9e8f2d7b3951358fa5e63faa1810b/comments",
    "author": {
      "login": "ajtowns",
      "id": 127186,
      "node_id": "MDQ6VXNlcjEyNzE4Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ajtowns",
      "html_url": "https://github.com/ajtowns",
      "followers_url": "https://api.github.com/users/ajtowns/followers",
      "following_url": "https://api.github.com/users/ajtowns/following{/other_user}",
      "gists_url": "https://api.github.com/users/ajtowns/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ajtowns/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
      "organizations_url": "https://api.github.com/users/ajtowns/orgs",
      "repos_url": "https://api.github.com/users/ajtowns/repos",
      "events_url": "https://api.github.com/users/ajtowns/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ajtowns/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "ajtowns",
      "id": 127186,
      "node_id": "MDQ6VXNlcjEyNzE4Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/127186?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ajtowns",
      "html_url": "https://github.com/ajtowns",
      "followers_url": "https://api.github.com/users/ajtowns/followers",
      "following_url": "https://api.github.com/users/ajtowns/following{/other_user}",
      "gists_url": "https://api.github.com/users/ajtowns/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ajtowns/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ajtowns/subscriptions",
      "organizations_url": "https://api.github.com/users/ajtowns/orgs",
      "repos_url": "https://api.github.com/users/ajtowns/repos",
      "events_url": "https://api.github.com/users/ajtowns/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ajtowns/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "715dbbe9e8b64fd4b556a0b0720b44d68c3b5e32",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/715dbbe9e8b64fd4b556a0b0720b44d68c3b5e32",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/715dbbe9e8b64fd4b556a0b0720b44d68c3b5e32"
      }
    ],
    "stats": {
      "total": 45,
      "additions": 42,
      "deletions": 3
    },
    "files": [
      {
        "sha": "3373f7f5445758564eae3e61cda81d25611d5f2d",
        "filename": "src/net_processing.cpp",
        "status": "modified",
        "additions": 42,
        "deletions": 3,
        "changes": 45,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/a204d1586ca9e8f2d7b3951358fa5e63faa1810b/src/net_processing.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/a204d1586ca9e8f2d7b3951358fa5e63faa1810b/src/net_processing.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.cpp?ref=a204d1586ca9e8f2d7b3951358fa5e63faa1810b",
        "patch": "@@ -75,6 +75,8 @@ static constexpr std::chrono::microseconds INBOUND_PEER_TX_DELAY{std::chrono::se\n static constexpr std::chrono::microseconds GETDATA_TX_INTERVAL{std::chrono::seconds{60}};\n /** Maximum delay (in microseconds) for transaction requests to avoid biasing some peers over others. */\n static constexpr std::chrono::microseconds MAX_GETDATA_RANDOM_DELAY{std::chrono::seconds{2}};\n+/** Delay between receiving a NOTFOUND and trying the next peer. */\n+static constexpr std::chrono::microseconds MAX_NOTFOUND_RETRY_RANDOM_DELAY{std::chrono::seconds{2}};\n /** How long to wait (in microseconds) before expiring an in-flight getdata request to a peer */\n static constexpr std::chrono::microseconds TX_EXPIRY_INTERVAL{GETDATA_TX_INTERVAL * 10};\n static_assert(INBOUND_PEER_TX_DELAY >= MAX_GETDATA_RANDOM_DELAY,\n@@ -344,8 +346,10 @@ struct CNodeState {\n          */\n         std::multimap<std::chrono::microseconds, uint256> m_tx_process_time;\n \n-        //! Store all the transactions a peer has recently announced\n-        std::set<uint256> m_tx_announced;\n+        /* Store all the transactions a peer has recently announced,\n+         * along with their process time\n+         */\n+        std::map<uint256, std::chrono::microseconds> m_tx_announced;\n \n         //! Store transactions which were requested by us, with timestamp\n         std::map<uint256, std::chrono::microseconds> m_tx_in_flight;\n@@ -731,6 +735,37 @@ std::chrono::microseconds CalculateTxGetDataTime(const uint256& txid, std::chron\n     return process_time;\n }\n \n+static void RetryProcessTx(CConnman& connman, const uint256& txid, const std::chrono::microseconds current_time) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n+{\n+    CNodeState::TxDownloadState* best_d = nullptr;\n+    std::chrono::microseconds best;\n+\n+    for (auto& el : mapNodeState) {\n+         CNodeState::TxDownloadState* d = &el.second.m_tx_download;\n+         if (d->m_tx_in_flight.size() >= MAX_PEER_TX_IN_FLIGHT) continue;\n+         auto it = d->m_tx_announced.find(txid);\n+         if (it != d->m_tx_announced.end()) {\n+             if (best_d == nullptr || (it->second != std::chrono::microseconds::zero() && it->second < best)) {\n+                 best_d = d;\n+                 best = it->second;\n+             }\n+         }\n+    }\n+\n+    std::chrono::microseconds process_time = current_time + GetRandMicros(MAX_NOTFOUND_RETRY_RANDOM_DELAY);\n+    if (best_d != nullptr && process_time < best) {\n+        auto end = best_d->m_tx_process_time.end();\n+        for (auto it = best_d->m_tx_process_time.lower_bound(best); it != end && it->first == best; ++it) {\n+            if (it->second == txid) {\n+                best_d->m_tx_process_time.erase(it);\n+                best_d->m_tx_announced[txid] = process_time;\n+                best_d->m_tx_process_time.emplace(process_time, txid);\n+                break;\n+            }\n+        }\n+    }\n+}\n+\n void RequestTx(CNodeState* state, const uint256& txid, std::chrono::microseconds current_time) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n {\n     CNodeState::TxDownloadState& peer_download_state = state->m_tx_download;\n@@ -741,12 +776,12 @@ void RequestTx(CNodeState* state, const uint256& txid, std::chrono::microseconds\n         // this announcement\n         return;\n     }\n-    peer_download_state.m_tx_announced.insert(txid);\n \n     // Calculate the time to try requesting this transaction. Use\n     // fPreferredDownload as a proxy for outbound peers.\n     const auto process_time = CalculateTxGetDataTime(txid, current_time, !state->fPreferredDownload);\n \n+    peer_download_state.m_tx_announced.emplace(txid, process_time);\n     peer_download_state.m_tx_process_time.emplace(process_time, txid);\n }\n \n@@ -3222,6 +3257,7 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n         std::vector<CInv> vInv;\n         vRecv >> vInv;\n         if (vInv.size() <= MAX_PEER_TX_IN_FLIGHT + MAX_BLOCKS_IN_TRANSIT_PER_PEER) {\n+            const auto current_time = GetTime<std::chrono::microseconds>();\n             for (CInv &inv : vInv) {\n                 if (inv.type == MSG_TX || inv.type == MSG_WITNESS_TX) {\n                     // If we receive a NOTFOUND message for a txid we requested, erase\n@@ -3234,6 +3270,7 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n                     }\n                     state->m_tx_download.m_tx_in_flight.erase(in_flight_it);\n                     state->m_tx_download.m_tx_announced.erase(inv.hash);\n+                    RetryProcessTx(*connman, inv.hash, current_time);\n                 }\n             }\n         }\n@@ -4039,6 +4076,7 @@ bool PeerLogicValidation::SendMessages(CNode* pto)\n             // Erase this entry from tx_process_time (it may be added back for\n             // processing at a later time, see below)\n             tx_process_time.erase(tx_process_time.begin());\n+            state.m_tx_download.m_tx_announced[txid] = std::chrono::microseconds::zero();\n             CInv inv(MSG_TX | GetFetchFlags(pto), txid);\n             if (!AlreadyHave(inv)) {\n                 // If this transaction was last requested more than 1 minute ago,\n@@ -4060,6 +4098,7 @@ bool PeerLogicValidation::SendMessages(CNode* pto)\n                     // requests to outbound peers).\n                     const auto next_process_time = CalculateTxGetDataTime(txid, current_time, !state.fPreferredDownload);\n                     tx_process_time.emplace(next_process_time, txid);\n+                    state.m_tx_download.m_tx_announced[txid] = next_process_time;\n                 }\n             } else {\n                 // We have already seen this transaction, no need to download."
      }
    ]
  }
]