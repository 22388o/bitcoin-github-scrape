[
  {
    "sha": "c9e69fbf3915fe1187b4c2e77be5ae6b16121194",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzpjOWU2OWZiZjM5MTVmZTExODdiNGMyZTc3YmU1YWU2YjE2MTIxMTk0",
    "commit": {
      "author": {
        "name": "Jeremy Rubin",
        "email": "jeremy.l.rubin@gmail.com",
        "date": "2016-10-05T20:58:47Z"
      },
      "committer": {
        "name": "Jeremy Rubin",
        "email": "jeremy.l.rubin@gmail.com",
        "date": "2016-12-14T21:02:05Z"
      },
      "message": "Add CuckooCache implementation and replace the sigcache map_type with it\n\nSQUASHME: Change cuckoocache to only work for powers of two, to avoid mod operator\nSQUASHME: Update Documentation and simplify logarithm logic\nSQUASHME: OSX Build Errors\nSQUASHME: minor Feedback from sipa + bluematt\nSQUASHME: DOCONLY: Clarify a few comments.",
      "tree": {
        "sha": "44f74b2355ce7c2618be7c2ba60c4fecbbfd4776",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/44f74b2355ce7c2618be7c2ba60c4fecbbfd4776"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/c9e69fbf3915fe1187b4c2e77be5ae6b16121194",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/c9e69fbf3915fe1187b4c2e77be5ae6b16121194",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/c9e69fbf3915fe1187b4c2e77be5ae6b16121194",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/c9e69fbf3915fe1187b4c2e77be5ae6b16121194/comments",
    "author": {
      "login": "JeremyRubin",
      "id": 886523,
      "node_id": "MDQ6VXNlcjg4NjUyMw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/886523?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/JeremyRubin",
      "html_url": "https://github.com/JeremyRubin",
      "followers_url": "https://api.github.com/users/JeremyRubin/followers",
      "following_url": "https://api.github.com/users/JeremyRubin/following{/other_user}",
      "gists_url": "https://api.github.com/users/JeremyRubin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/JeremyRubin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/JeremyRubin/subscriptions",
      "organizations_url": "https://api.github.com/users/JeremyRubin/orgs",
      "repos_url": "https://api.github.com/users/JeremyRubin/repos",
      "events_url": "https://api.github.com/users/JeremyRubin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/JeremyRubin/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "JeremyRubin",
      "id": 886523,
      "node_id": "MDQ6VXNlcjg4NjUyMw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/886523?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/JeremyRubin",
      "html_url": "https://github.com/JeremyRubin",
      "followers_url": "https://api.github.com/users/JeremyRubin/followers",
      "following_url": "https://api.github.com/users/JeremyRubin/following{/other_user}",
      "gists_url": "https://api.github.com/users/JeremyRubin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/JeremyRubin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/JeremyRubin/subscriptions",
      "organizations_url": "https://api.github.com/users/JeremyRubin/orgs",
      "repos_url": "https://api.github.com/users/JeremyRubin/repos",
      "events_url": "https://api.github.com/users/JeremyRubin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/JeremyRubin/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "7942d31d5fa0c78136fc51d4746d6d61eeb587a7",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/7942d31d5fa0c78136fc51d4746d6d61eeb587a7",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/7942d31d5fa0c78136fc51d4746d6d61eeb587a7"
      }
    ],
    "stats": {
      "total": 547,
      "additions": 506,
      "deletions": 41
    },
    "files": [
      {
        "sha": "efd6a820b5ce0677d24f3d5515949a98ebea0528",
        "filename": "src/cuckoocache.h",
        "status": "added",
        "additions": 457,
        "deletions": 0,
        "changes": 457,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/c9e69fbf3915fe1187b4c2e77be5ae6b16121194/src/cuckoocache.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/c9e69fbf3915fe1187b4c2e77be5ae6b16121194/src/cuckoocache.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/cuckoocache.h?ref=c9e69fbf3915fe1187b4c2e77be5ae6b16121194",
        "patch": "@@ -0,0 +1,457 @@\n+// Copyright (c) 2016 Jeremy Rubin\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef _BITCOIN_CUCKOOCACHE_H_\n+#define _BITCOIN_CUCKOOCACHE_H_\n+\n+#include <array>\n+#include <algorithm>\n+#include <atomic>\n+#include <cstring>\n+#include <cmath>\n+#include <memory>\n+#include <vector>\n+\n+\n+/** namespace CuckooCache provides high performance cache primitives\n+ *\n+ * Summary:\n+ *\n+ * 1) bit_packed_atomic_flags is bit-packed atomic flags for garbage collection\n+ *\n+ * 2) cache is a cache which is performant in memory usage and lookup speed. It\n+ * is lockfree for erase operations. Elements are lazily erased on the next\n+ * insert.\n+ */\n+namespace CuckooCache\n+{\n+/** bit_packed_atomic_flags implements a container for garbage collection flags\n+ * that is only thread unsafe on calls to setup. This class bit-packs collection\n+ * flags for memory efficiency.\n+ *\n+ * All operations are std::memory_order_relaxed so external mechanisms must\n+ * ensure that writes and reads are properly synchronized.\n+ *\n+ * On setup(n), all bits up to n are marked as collected.\n+ *\n+ * Under the hood, because it is an 8-bit type, it makes sense to use a multiple\n+ * of 8 for setup, but it will be safe if that is not the case as well.\n+ *\n+ */\n+class bit_packed_atomic_flags\n+{\n+    std::unique_ptr<std::atomic<uint8_t>[]> mem;\n+\n+public:\n+    /** No default constructor as there must be some size */\n+    bit_packed_atomic_flags() = delete;\n+\n+    /**\n+     * bit_packed_atomic_flags constructor creates memory to sufficiently\n+     * keep track of garbage collection information for size entries.\n+     *\n+     * @param size the number of elements to allocate space for\n+     *\n+     * @post bit_set, bit_unset, and bit_is_set function properly forall x. x <\n+     * size\n+     * @post All calls to bit_is_set (without subsequent bit_unset) will return\n+     * true.\n+     */\n+    bit_packed_atomic_flags(uint32_t size)\n+    {\n+        // pad out the size if needed\n+        size = (size + 7) / 8;\n+        mem.reset(new std::atomic<uint8_t>[size]);\n+        for (uint32_t i = 0; i < size; ++i)\n+            mem[i].store(0xFF);\n+    };\n+\n+    /** setup marks all entries and ensures that bit_packed_atomic_flags can store\n+     * at least size entries\n+     *\n+     * @param b the number of elements to allocate space for\n+     * @post bit_set, bit_unset, and bit_is_set function properly forall x. x <\n+     * b\n+     * @post All calls to bit_is_set (without subsequent bit_unset) will return\n+     * true.\n+     */\n+    inline void setup(uint32_t b)\n+    {\n+        bit_packed_atomic_flags d(b);\n+        std::swap(mem, d.mem);\n+    }\n+\n+    /** bit_set sets an entry as discardable.\n+     *\n+     * @param s the index of the entry to bit_set.\n+     * @post immediately subsequent call (assuming proper external memory\n+     * ordering) to bit_is_set(s) == true.\n+     *\n+     */\n+    inline void bit_set(uint32_t s)\n+    {\n+        mem[s >> 3].fetch_or(1 << (s & 7), std::memory_order_relaxed);\n+    }\n+\n+    /**  bit_unset marks an entry as something that should not be overwritten\n+     *\n+     * @param s the index of the entry to bit_unset.\n+     * @post immediately subsequent call (assuming proper external memory\n+     * ordering) to bit_is_set(s) == false.\n+     */\n+    inline void bit_unset(uint32_t s)\n+    {\n+        mem[s >> 3].fetch_and(~(1 << (s & 7)), std::memory_order_relaxed);\n+    }\n+\n+    /** bit_is_set queries the table for discardability at s\n+     *\n+     * @param s the index of the entry to read.\n+     * @returns if the bit at index s was set.\n+     * */\n+    inline bool bit_is_set(uint32_t s) const\n+    {\n+        return (1 << (s & 7)) & mem[s >> 3].load(std::memory_order_relaxed);\n+    }\n+};\n+\n+/** cache implements a cache with properties similar to a cuckoo-set\n+ *\n+ *  The cache is able to hold up to (~(uint32_t)0) - 1 elements.\n+ *\n+ *  Read Operations:\n+ *      - contains(*, false)\n+ *\n+ *  Read+Erase Operations:\n+ *      - contains(*, true)\n+ *\n+ *  Erase Operations:\n+ *      - allow_erase()\n+ *\n+ *  Write Operations:\n+ *      - setup()\n+ *      - setup_bytes()\n+ *      - insert()\n+ *      - please_keep()\n+ *\n+ *  Synchronization Free Operations:\n+ *      - invalid()\n+ *      - compute_hashes()\n+ *\n+ * User Must Guarantee:\n+ *\n+ * 1) Write Requires synchronized access (e.g., a lock)\n+ * 2) Read Requires no concurrent Write, synchronized with the last insert.\n+ * 3) Erase requires no concurrent Write, synchronized with last insert.\n+ * 4) An Erase caller must release all memory before allowing a new Writer.\n+ *\n+ *\n+ * Note on function names:\n+ *   - The name \"allow_erase\" is used because the real discard happens later.\n+ *   - The name \"please_keep\" is used because elements may be erased anyways on insert.\n+ *\n+ * @tparam Element should be a movable and copyable type\n+ * @tparam Hash should be a function/callable which takes a template parameter\n+ * hash_select and an Element and extracts a hash from it. Should return\n+ * high-entropy hashes for `Hash h; h<0>(e) ... h<7>(e)`.\n+ */\n+template <typename Element, typename Hash>\n+class cache\n+{\n+private:\n+    /** table stores all the elements */\n+    std::vector<Element> table;\n+\n+    /** size stores the total available slots in the hash table */\n+    uint32_t size;\n+\n+    /** The bit_packed_atomic_flags array is marked mutable because we want\n+     * garbage collection to be allowed to occur from const methods */\n+    mutable bit_packed_atomic_flags collection_flags;\n+\n+    /** epoch_flags tracks how recently an element was inserted into\n+     * the cache. true denotes recent, false denotes not-recent. See insert()\n+     * method for full semantics.\n+     */\n+    mutable std::vector<bool> epoch_flags;\n+\n+    /** epoch_heuristic_counter is used to determine when a epoch might be aged\n+     * & an expensive scan should be done.  epoch_heuristic_counter is\n+     * decremented on insert and reset to the new number of inserts which would\n+     * cause the epoch to reach epoch_size when it reaches zero.\n+     */\n+    uint32_t epoch_heuristic_counter;\n+\n+    /** epoch_size is set to be the number of elements supposed to be in a\n+     * epoch. When the number of non-erased elements in a epoch\n+     * exceeds epoch_size, a new epoch should be started and all\n+     * current entries demoted. epoch_size is set to be 45% of size because\n+     * we want to keep load around 90%, and we support 3 epochs at once --\n+     * one \"dead\" which has been erased, one \"dying\" which has been marked to be\n+     * erased next, and one \"living\" which new inserts add to.\n+     */\n+    uint32_t epoch_size;\n+\n+    /** hash_mask should be set to appropriately mask out a hash such that every\n+     * masked hash is [0,size), eg, if floor(log2(size)) == 20, then hash_mask\n+     * should be (1<<20)-1\n+     */\n+    uint32_t hash_mask;\n+\n+    /** depth_limit determines how many elements insert should try to replace.\n+     * Should be set to log2(n)*/\n+    uint8_t depth_limit;\n+\n+    /** hash_function is a const instance of the hash function. It cannot be\n+     * static or initialized at call time as it may have internal state (such as\n+     * a nonce).\n+     * */\n+    const Hash hash_function;\n+\n+    /** compute_hashes is convenience for not having to write out this\n+     * expression everywhere we use the hash values of an Element.\n+     *\n+     * @param e the element whose hashes will be returned\n+     * @returns std::array<uint32_t, 8> of deterministic hashes derived from e\n+     */\n+    inline std::array<uint32_t, 8> compute_hashes(const Element& e) const\n+    {\n+        return {{hash_function.template operator()<0>(e) & hash_mask,\n+                 hash_function.template operator()<1>(e) & hash_mask,\n+                 hash_function.template operator()<2>(e) & hash_mask,\n+                 hash_function.template operator()<3>(e) & hash_mask,\n+                 hash_function.template operator()<4>(e) & hash_mask,\n+                 hash_function.template operator()<5>(e) & hash_mask,\n+                 hash_function.template operator()<6>(e) & hash_mask,\n+                 hash_function.template operator()<7>(e) & hash_mask}};\n+    }\n+\n+    /* end\n+     * @returns a constexpr index that can never be inserted to */\n+    constexpr uint32_t invalid() const\n+    {\n+        return ~(uint32_t)0;\n+    }\n+\n+    /** allow_erase marks the element at index n as discardable. Threadsafe\n+     * without any concurrent insert.\n+     * @param n the index to allow erasure of\n+     */\n+    inline void allow_erase(uint32_t n) const\n+    {\n+        collection_flags.bit_set(n);\n+    }\n+\n+    /** please_keep marks the element at index n as an entry that should be kept.\n+     * Threadsafe without any concurrent insert.\n+     * @param n the index to prioritize keeping\n+     */\n+    inline void please_keep(uint32_t n) const\n+    {\n+        collection_flags.bit_unset(n);\n+    }\n+\n+    /** epoch_check handles the changing of epochs for elements stored in the\n+     * cache. epoch_check should be run before every insert.\n+     *\n+     * First, epoch_check decrements and checks the cheap heuristic, and then does\n+     * a more expensive scan if the cheap heuristic runs out. If the expensive\n+     * scan suceeds, the epochs are aged and old elements are allow_erased. The\n+     * cheap heuristic is reset to retrigger after the worst case growth of the\n+     * current epoch's elements would exceed the epoch_size.\n+     */\n+    void epoch_check()\n+    {\n+        if (epoch_heuristic_counter != 0) {\n+            --epoch_heuristic_counter;\n+            return;\n+        }\n+        // count the number of elements from the latest epoch which\n+        // have not been erased.\n+        uint32_t epoch_unused_count = 0;\n+        for (uint32_t i = 0; i < size; ++i)\n+            epoch_unused_count += epoch_flags[i] &&\n+                                  !collection_flags.bit_is_set(i);\n+        // If there are more non-deleted entries in the current epoch than the\n+        // epoch size, then allow_erase on all elements in the old epoch (marked\n+        // false) and move all elements in the current epoch to the old epoch\n+        // but do not call allow_erase on their indices.\n+        if (epoch_unused_count >= epoch_size) {\n+            for (uint32_t i = 0; i < size; ++i)\n+                if (epoch_flags[i])\n+                    epoch_flags[i] = false;\n+                else\n+                    allow_erase(i);\n+            epoch_heuristic_counter = epoch_size;\n+        } else\n+            // reset the epoch_heuristic_counter to next do a scan when worst\n+            // case behavior (no intermittent erases) would exceed epoch size,\n+            // with a reasonable minimum scan size.\n+            // Ordinarily, we would have to sanity check std::min(epoch_size,\n+            // epoch_unused_count), but we already know that `epoch_unused_count\n+            // < epoch_size` in this branch\n+            epoch_heuristic_counter = std::max(1u, std::max(epoch_size / 16,\n+                        epoch_size - epoch_unused_count));\n+    }\n+\n+public:\n+    /** You must always construct a cache with some elements via a subsequent\n+     * call to setup or setup_bytes, otherwise operations may segfault.\n+     */\n+    cache() : table(), size(), collection_flags(0), epoch_flags(),\n+    epoch_heuristic_counter(), epoch_size(), depth_limit(0), hash_function()\n+    {\n+    }\n+\n+    /** setup initializes the container to store no more than new_size\n+     * elements. setup rounds down to a power of two size.\n+     *\n+     * setup should only be called once.\n+     *\n+     * @param new_size the desired number of elements to store\n+     * @returns the maximum number of elements storable\n+     **/\n+    uint32_t setup(uint32_t new_size)\n+    {\n+        // depth_limit must be at least one otherwise errors can occur.\n+        depth_limit = static_cast<uint8_t>(std::log2(static_cast<float>(std::max((uint32_t)2, new_size))));\n+        size = 1 << depth_limit;\n+        hash_mask = size-1;\n+        table.resize(size);\n+        collection_flags.setup(size);\n+        epoch_flags.resize(size);\n+        // Set to 45% as described above\n+        epoch_size = std::max((uint32_t)1, (45 * size) / 100);\n+        // Initially set to wait for a whole epoch\n+        epoch_heuristic_counter = epoch_size;\n+        return size;\n+    }\n+\n+    /** setup_bytes is a convenience function which accounts for internal memory\n+     * usage when deciding how many elements to store. It isn't perfect because\n+     * it doesn't account for any overhead (struct size, MallocUsage, collection\n+     * and epoch flags). This was done to simplify selecting a power of two\n+     * size. In the expected use case, an extra two bits per entry should be\n+     * negligible compared to the size of the elements.\n+     *\n+     * @param bytes the approximate number of bytes to use for this data\n+     * structure.\n+     * @returns the maximum number of elements storable (see setup()\n+     * documentation for more detail)\n+     */\n+    uint32_t setup_bytes(size_t bytes)\n+    {\n+        return setup(bytes/sizeof(Element));\n+    }\n+\n+    /** insert loops at most depth_limit times trying to insert a hash\n+     * at various locations in the table via a variant of the Cuckoo Algorithm\n+     * with eight hash locations.\n+     *\n+     * It drops the last tried element if it runs out of depth before\n+     * encountering an open slot.\n+     *\n+     * Thus\n+     *\n+     * insert(x);\n+     * return contains(x, false);\n+     *\n+     * is not guaranteed to return true.\n+     *\n+     * @param e the element to insert\n+     * @post one of the following: All previously inserted elements and e are\n+     * now in the table, one previously inserted element is evicted from the\n+     * table, the entry attempted to be inserted is evicted.\n+     *\n+     */\n+    inline void insert(Element e)\n+    {\n+        epoch_check();\n+        uint32_t last_loc = invalid();\n+        bool last_epoch = true;\n+        std::array<uint32_t, 8> locs = compute_hashes(e);\n+        // Make sure we have not already inserted this element\n+        // If we have, make sure that it does not get deleted\n+        for (uint32_t loc : locs)\n+            if (table[loc] == e) {\n+                please_keep(loc);\n+                epoch_flags[loc] = last_epoch;\n+                return;\n+            }\n+        for (uint8_t depth = 0; depth < depth_limit; ++depth) {\n+            // First try to insert to an empty slot, if one exists\n+            for (uint32_t loc : locs) {\n+                if (!collection_flags.bit_is_set(loc))\n+                    continue;\n+                table[loc] = std::move(e);\n+                please_keep(loc);\n+                epoch_flags[loc] = last_epoch;\n+                return;\n+            }\n+            /** Swap with the element at the location that was\n+            * not the last one looked at. Example:\n+            *\n+            * 1) On first iteration, last_loc == invalid(), find returns last, so\n+            *    last_loc defaults to locs[0].\n+            * 2) On further iterations, where last_loc == locs[k], last_loc will\n+            *    go to locs[k+1 % 8], i.e., next of the 8 indicies wrapping around\n+            *    to 0 if needed.\n+            *\n+            * This prevents moving the element we just put in.\n+            *\n+            * The swap is not a move -- we must switch onto the evicted element\n+            * for the next iteration.\n+            */\n+            last_loc = locs[(1 + (std::find(locs.begin(), locs.end(), last_loc) - locs.begin())) & 7];\n+            std::swap(table[last_loc], e);\n+            // Can't std::swap a std::vector<bool>::reference and a bool&.\n+            bool epoch = last_epoch;\n+            last_epoch = epoch_flags[last_loc];\n+            epoch_flags[last_loc] = epoch;\n+\n+            // Recompute the locs -- unfortunately happens one too many times!\n+            locs = compute_hashes(e);\n+        }\n+    }\n+\n+    /* contains iterates through the hash locations for a given element\n+     * and checks to see if it is present.\n+     *\n+     * contains does not check garbage collected state (in other words,\n+     * garbage is only collected when the space is needed), so:\n+     *\n+     * insert(x);\n+     * if (contains(x, true))\n+     *     return contains(x, false);\n+     * else\n+     *     return true;\n+     *\n+     * executed on a single thread will always return true!\n+     *\n+     * This is a great property for re-org performance for example.\n+     *\n+     * contains returns a bool set true if the element was found.\n+     *\n+     * @param e the element to check\n+     * @param erase\n+     *\n+     * @post if erase is true and the element is found, then the garbage collect\n+     * flag is set\n+     * @returns true if the element is found, false otherwise\n+     */\n+    inline bool contains(const Element& e, const bool erase) const\n+    {\n+        std::array<uint32_t, 8> locs = compute_hashes(e);\n+        for (uint32_t loc : locs)\n+            if (table[loc] == e) {\n+                if (erase)\n+                    allow_erase(loc);\n+                return true;\n+            }\n+        return false;\n+    }\n+};\n+} // namespace CuckooCache\n+\n+#endif"
      },
      {
        "sha": "1a500792a30eb9c11d1e345accc704ac111b07ab",
        "filename": "src/init.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 0,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/c9e69fbf3915fe1187b4c2e77be5ae6b16121194/src/init.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/c9e69fbf3915fe1187b4c2e77be5ae6b16121194/src/init.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/init.cpp?ref=c9e69fbf3915fe1187b4c2e77be5ae6b16121194",
        "patch": "@@ -1070,6 +1070,8 @@ bool AppInit2(boost::thread_group& threadGroup, CScheduler& scheduler)\n     LogPrintf(\"Using config file %s\\n\", GetConfigFile(GetArg(\"-conf\", BITCOIN_CONF_FILENAME)).string());\n     LogPrintf(\"Using at most %i connections (%i file descriptors available)\\n\", nMaxConnections, nFD);\n \n+    InitSignatureCache();\n+\n     LogPrintf(\"Using %u threads for script verification\\n\", nScriptCheckThreads);\n     if (nScriptCheckThreads) {\n         for (int i=0; i<nScriptCheckThreads-1; i++)"
      },
      {
        "sha": "b78d7b607ff97743e9ace8ec99c32cd6e551949c",
        "filename": "src/script/sigcache.cpp",
        "status": "modified",
        "additions": 39,
        "deletions": 38,
        "changes": 77,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/c9e69fbf3915fe1187b4c2e77be5ae6b16121194/src/script/sigcache.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/c9e69fbf3915fe1187b4c2e77be5ae6b16121194/src/script/sigcache.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/script/sigcache.cpp?ref=c9e69fbf3915fe1187b4c2e77be5ae6b16121194",
        "patch": "@@ -11,20 +11,29 @@\n #include \"uint256.h\"\n #include \"util.h\"\n \n+#include \"cuckoocache.h\"\n #include <boost/thread.hpp>\n-#include <boost/unordered_set.hpp>\n \n namespace {\n \n /**\n  * We're hashing a nonce into the entries themselves, so we don't need extra\n  * blinding in the set hash computation.\n+ *\n+ * This may exhibit platform endian dependent behavior but because these are\n+ * nonced hashes (random) and this state is only ever used locally it is safe.\n+ * All that matters is local consistency.\n  */\n-class CSignatureCacheHasher\n+class SignatureCacheHasher\n {\n public:\n-    size_t operator()(const uint256& key) const {\n-        return key.GetCheapHash();\n+    template <uint8_t hash_select>\n+    uint32_t operator()(const uint256& key) const\n+    {\n+        static_assert(hash_select <8, \"SignatureCacheHasher only has 8 hashes available.\");\n+        uint32_t u;\n+        std::memcpy(&u, key.begin()+4*hash_select, 4);\n+        return u;\n     }\n };\n \n@@ -38,11 +47,10 @@ class CSignatureCache\n private:\n      //! Entries are SHA256(nonce || signature hash || public key || signature):\n     uint256 nonce;\n-    typedef boost::unordered_set<uint256, CSignatureCacheHasher> map_type;\n+    typedef CuckooCache::cache<uint256, SignatureCacheHasher> map_type;\n     map_type setValid;\n     boost::shared_mutex cs_sigcache;\n \n-\n public:\n     CSignatureCache()\n     {\n@@ -56,58 +64,51 @@ class CSignatureCache\n     }\n \n     bool\n-    Get(const uint256& entry)\n+    Get(const uint256& entry, const bool erase)\n     {\n         boost::shared_lock<boost::shared_mutex> lock(cs_sigcache);\n-        return setValid.count(entry);\n+        return setValid.contains(entry, erase);\n     }\n \n-    void Erase(const uint256& entry)\n+    void Set(uint256& entry)\n     {\n         boost::unique_lock<boost::shared_mutex> lock(cs_sigcache);\n-        setValid.erase(entry);\n+        setValid.insert(entry);\n     }\n-\n-    void Set(const uint256& entry)\n+    uint32_t setup_bytes(size_t n)\n     {\n-        size_t nMaxCacheSize = GetArg(\"-maxsigcachesize\", DEFAULT_MAX_SIG_CACHE_SIZE) * ((size_t) 1 << 20);\n-        if (nMaxCacheSize <= 0) return;\n-\n-        boost::unique_lock<boost::shared_mutex> lock(cs_sigcache);\n-        while (memusage::DynamicUsage(setValid) > nMaxCacheSize)\n-        {\n-            map_type::size_type s = GetRand(setValid.bucket_count());\n-            map_type::local_iterator it = setValid.begin(s);\n-            if (it != setValid.end(s)) {\n-                setValid.erase(*it);\n-            }\n-        }\n-\n-        setValid.insert(entry);\n+        return setValid.setup_bytes(n);\n     }\n };\n \n+/* In previous versions of this code, signatureCache was a local static variable\n+ * in CachingTransactionSignatureChecker::VerifySignature.  We initialize\n+ * signatureCache outside of VerifySignature to avoid the atomic operation per\n+ * call overhead associated with local static variables even though\n+ * signatureCache could be made local to VerifySignature.\n+*/\n+static CSignatureCache signatureCache;\n }\n \n-bool CachingTransactionSignatureChecker::VerifySignature(const std::vector<unsigned char>& vchSig, const CPubKey& pubkey, const uint256& sighash) const\n+// To be called once in AppInit2/TestingSetup to initialize the signatureCache\n+void InitSignatureCache()\n {\n-    static CSignatureCache signatureCache;\n+    size_t nMaxCacheSize = GetArg(\"-maxsigcachesize\", DEFAULT_MAX_SIG_CACHE_SIZE) * ((size_t) 1 << 20);\n+    if (nMaxCacheSize <= 0) return;\n+    size_t nElems = signatureCache.setup_bytes(nMaxCacheSize);\n+    LogPrintf(\"Using %zu MiB out of %zu requested for signature cache, able to store %zu elements\\n\",\n+            (nElems*sizeof(uint256)) >>20, nMaxCacheSize>>20, nElems);\n+}\n \n+bool CachingTransactionSignatureChecker::VerifySignature(const std::vector<unsigned char>& vchSig, const CPubKey& pubkey, const uint256& sighash) const\n+{\n     uint256 entry;\n     signatureCache.ComputeEntry(entry, sighash, vchSig, pubkey);\n-\n-    if (signatureCache.Get(entry)) {\n-        if (!store) {\n-            signatureCache.Erase(entry);\n-        }\n+    if (signatureCache.Get(entry, !store))\n         return true;\n-    }\n-\n     if (!TransactionSignatureChecker::VerifySignature(vchSig, pubkey, sighash))\n         return false;\n-\n-    if (store) {\n+    if (store)\n         signatureCache.Set(entry);\n-    }\n     return true;\n }"
      },
      {
        "sha": "5243fc0a42be711825e29da4be9ec64ad38ef6b2",
        "filename": "src/script/sigcache.h",
        "status": "modified",
        "additions": 6,
        "deletions": 3,
        "changes": 9,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/c9e69fbf3915fe1187b4c2e77be5ae6b16121194/src/script/sigcache.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/c9e69fbf3915fe1187b4c2e77be5ae6b16121194/src/script/sigcache.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/script/sigcache.h?ref=c9e69fbf3915fe1187b4c2e77be5ae6b16121194",
        "patch": "@@ -10,9 +10,10 @@\n \n #include <vector>\n \n-// DoS prevention: limit cache size to less than 40MB (over 500000\n-// entries on 64-bit systems).\n-static const unsigned int DEFAULT_MAX_SIG_CACHE_SIZE = 40;\n+// DoS prevention: limit cache size to 32MB (over 1000000 entries on 64-bit\n+// systems). Due to how we count cache size, actual memory usage is slightly\n+// more (~32.25 MB)\n+static const unsigned int DEFAULT_MAX_SIG_CACHE_SIZE = 32;\n \n class CPubKey;\n \n@@ -27,4 +28,6 @@ class CachingTransactionSignatureChecker : public TransactionSignatureChecker\n     bool VerifySignature(const std::vector<unsigned char>& vchSig, const CPubKey& vchPubKey, const uint256& sighash) const;\n };\n \n+void InitSignatureCache();\n+\n #endif // BITCOIN_SCRIPT_SIGCACHE_H"
      },
      {
        "sha": "b7a2a854d39f4c7e4138c4b47ccd84e24b1ef87d",
        "filename": "src/test/test_bitcoin.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 0,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/c9e69fbf3915fe1187b4c2e77be5ae6b16121194/src/test/test_bitcoin.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/c9e69fbf3915fe1187b4c2e77be5ae6b16121194/src/test/test_bitcoin.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/test_bitcoin.cpp?ref=c9e69fbf3915fe1187b4c2e77be5ae6b16121194",
        "patch": "@@ -19,6 +19,7 @@\n #include \"ui_interface.h\"\n #include \"rpc/server.h\"\n #include \"rpc/register.h\"\n+#include \"script/sigcache.h\"\n \n #include \"test/testutil.h\"\n \n@@ -39,6 +40,7 @@ BasicTestingSetup::BasicTestingSetup(const std::string& chainName)\n         ECC_Start();\n         SetupEnvironment();\n         SetupNetworking();\n+        InitSignatureCache();\n         fPrintToDebugLog = false; // don't want to write to debug.log file\n         fCheckBlockIndex = true;\n         SelectParams(chainName);"
      }
    ]
  },
  {
    "sha": "67dac4e1937b9835d2c09402d35e0050467fbc6d",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo2N2RhYzRlMTkzN2I5ODM1ZDJjMDk0MDJkMzVlMDA1MDQ2N2ZiYzZk",
    "commit": {
      "author": {
        "name": "Jeremy Rubin",
        "email": "jeremy.l.rubin@gmail.com",
        "date": "2016-10-05T20:59:18Z"
      },
      "committer": {
        "name": "Jeremy Rubin",
        "email": "jeremy.l.rubin@gmail.com",
        "date": "2016-12-14T21:02:22Z"
      },
      "message": "Add unit tests for the CuckooCache\n\nSQUASHME: Update Tests for other SQUASHMEs",
      "tree": {
        "sha": "7bb00ce68b10a6e65c44516595df3861675125c5",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/7bb00ce68b10a6e65c44516595df3861675125c5"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/67dac4e1937b9835d2c09402d35e0050467fbc6d",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/67dac4e1937b9835d2c09402d35e0050467fbc6d",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/67dac4e1937b9835d2c09402d35e0050467fbc6d",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/67dac4e1937b9835d2c09402d35e0050467fbc6d/comments",
    "author": {
      "login": "JeremyRubin",
      "id": 886523,
      "node_id": "MDQ6VXNlcjg4NjUyMw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/886523?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/JeremyRubin",
      "html_url": "https://github.com/JeremyRubin",
      "followers_url": "https://api.github.com/users/JeremyRubin/followers",
      "following_url": "https://api.github.com/users/JeremyRubin/following{/other_user}",
      "gists_url": "https://api.github.com/users/JeremyRubin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/JeremyRubin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/JeremyRubin/subscriptions",
      "organizations_url": "https://api.github.com/users/JeremyRubin/orgs",
      "repos_url": "https://api.github.com/users/JeremyRubin/repos",
      "events_url": "https://api.github.com/users/JeremyRubin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/JeremyRubin/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "JeremyRubin",
      "id": 886523,
      "node_id": "MDQ6VXNlcjg4NjUyMw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/886523?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/JeremyRubin",
      "html_url": "https://github.com/JeremyRubin",
      "followers_url": "https://api.github.com/users/JeremyRubin/followers",
      "following_url": "https://api.github.com/users/JeremyRubin/following{/other_user}",
      "gists_url": "https://api.github.com/users/JeremyRubin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/JeremyRubin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/JeremyRubin/subscriptions",
      "organizations_url": "https://api.github.com/users/JeremyRubin/orgs",
      "repos_url": "https://api.github.com/users/JeremyRubin/repos",
      "events_url": "https://api.github.com/users/JeremyRubin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/JeremyRubin/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "c9e69fbf3915fe1187b4c2e77be5ae6b16121194",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/c9e69fbf3915fe1187b4c2e77be5ae6b16121194",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/c9e69fbf3915fe1187b4c2e77be5ae6b16121194"
      }
    ],
    "stats": {
      "total": 395,
      "additions": 395,
      "deletions": 0
    },
    "files": [
      {
        "sha": "8178fb742900735d6dbf7514e03d696a1c6bdae8",
        "filename": "src/Makefile.test.include",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/67dac4e1937b9835d2c09402d35e0050467fbc6d/src/Makefile.test.include",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/67dac4e1937b9835d2c09402d35e0050467fbc6d/src/Makefile.test.include",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/Makefile.test.include?ref=67dac4e1937b9835d2c09402d35e0050467fbc6d",
        "patch": "@@ -54,6 +54,7 @@ BITCOIN_TESTS =\\\n   test/coins_tests.cpp \\\n   test/compress_tests.cpp \\\n   test/crypto_tests.cpp \\\n+  test/cuckoocache_tests.cpp \\\n   test/DoS_tests.cpp \\\n   test/getarg_tests.cpp \\\n   test/hash_tests.cpp \\"
      },
      {
        "sha": "1bc50d5ea9002a2b5607351a6a9a005fe0b14559",
        "filename": "src/test/cuckoocache_tests.cpp",
        "status": "added",
        "additions": 394,
        "deletions": 0,
        "changes": 394,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/67dac4e1937b9835d2c09402d35e0050467fbc6d/src/test/cuckoocache_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/67dac4e1937b9835d2c09402d35e0050467fbc6d/src/test/cuckoocache_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/cuckoocache_tests.cpp?ref=67dac4e1937b9835d2c09402d35e0050467fbc6d",
        "patch": "@@ -0,0 +1,394 @@\n+// Copyright (c) 2012-2016 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+#include <boost/test/unit_test.hpp>\n+#include \"cuckoocache.h\"\n+#include \"test/test_bitcoin.h\"\n+#include \"random.h\"\n+#include <thread>\n+#include <boost/thread.hpp>\n+\n+\n+/** Test Suite for CuckooCache\n+ *\n+ *  1) All tests should have a deterministic result (using insecure rand\n+ *  with deterministic seeds)\n+ *  2) Some test methods are templated to allow for easier testing\n+ *  against new versions / comparing\n+ *  3) Results should be treated as a regression test, ie, did the behavior\n+ *  change significantly from what was expected. This can be OK, depending on\n+ *  the nature of the change, but requires updating the tests to reflect the new\n+ *  expected behavior. For example improving the hit rate may cause some tests\n+ *  using BOOST_CHECK_CLOSE to fail.\n+ *\n+ */\n+FastRandomContext insecure_rand(true);\n+\n+BOOST_AUTO_TEST_SUITE(cuckoocache_tests);\n+\n+\n+/** insecure_GetRandHash fills in a uint256 from insecure_rand\n+ */\n+void insecure_GetRandHash(uint256& t)\n+{\n+    uint32_t* ptr = (uint32_t*)t.begin();\n+    for (uint8_t j = 0; j < 8; ++j)\n+        *(ptr++) = insecure_rand.rand32();\n+}\n+\n+/** Definition copied from /src/script/sigcache.cpp\n+ */\n+class uint256Hasher\n+{\n+public:\n+    template <uint8_t hash_select>\n+    uint32_t operator()(const uint256& key) const\n+    {\n+        static_assert(hash_select <8, \"SignatureCacheHasher only has 8 hashes available.\");\n+        uint32_t u;\n+        std::memcpy(&u, key.begin() + 4 * hash_select, 4);\n+        return u;\n+    }\n+};\n+\n+\n+/* Test that no values not inserted into the cache are read out of it.\n+ *\n+ * There are no repeats in the first 200000 insecure_GetRandHash calls\n+ */\n+BOOST_AUTO_TEST_CASE(test_cuckoocache_no_fakes)\n+{\n+    insecure_rand = FastRandomContext(true);\n+    CuckooCache::cache<uint256, uint256Hasher> cc{};\n+    cc.setup_bytes(32 << 20);\n+    uint256 v;\n+    for (int x = 0; x < 100000; ++x) {\n+        insecure_GetRandHash(v);\n+        cc.insert(v);\n+    }\n+    for (int x = 0; x < 100000; ++x) {\n+        insecure_GetRandHash(v);\n+        BOOST_CHECK(!cc.contains(v, false));\n+    }\n+};\n+\n+/** This helper returns the hit rate when megabytes*load worth of entries are\n+ * inserted into a megabytes sized cache\n+ */\n+template <typename Cache>\n+double test_cache(size_t megabytes, double load)\n+{\n+    insecure_rand = FastRandomContext(true);\n+    std::vector<uint256> hashes;\n+    Cache set{};\n+    size_t bytes = megabytes * (1 << 20);\n+    set.setup_bytes(bytes);\n+    uint32_t n_insert = static_cast<uint32_t>(load * (bytes / sizeof(uint256)));\n+    hashes.resize(n_insert);\n+    for (uint32_t i = 0; i < n_insert; ++i) {\n+        uint32_t* ptr = (uint32_t*)hashes[i].begin();\n+        for (uint8_t j = 0; j < 8; ++j)\n+            *(ptr++) = insecure_rand.rand32();\n+    }\n+    /** We make a copy of the hashes because future optimizations of the\n+     * cuckoocache may overwrite the inserted element, so the test is\n+     * \"future proofed\".\n+     */\n+    std::vector<uint256> hashes_insert_copy = hashes;\n+    /** Do the insert */\n+    for (uint256& h : hashes_insert_copy)\n+        set.insert(h);\n+    /** Count the hits */\n+    uint32_t count = 0;\n+    for (uint256& h : hashes)\n+        count += set.contains(h, false);\n+    double hit_rate = ((double)count) / ((double)n_insert);\n+    return hit_rate;\n+}\n+\n+/** The normalized hit rate for a given load.\n+ *\n+ * The semantics are a little confusing, so please see the below\n+ * explanation.\n+ *\n+ * Examples:\n+ *\n+ * 1) at load 0.5, we expect a perfect hit rate, so we multiply by\n+ * 1.0\n+ * 2) at load 2.0, we expect to see half the entries, so a perfect hit rate\n+ * would be 0.5. Therefore, if we see a hit rate of 0.4, 0.4*2.0 = 0.8 is the\n+ * normalized hit rate.\n+ *\n+ * This is basically the right semantics, but has a bit of a glitch depending on\n+ * how you measure around load 1.0 as after load 1.0 your normalized hit rate\n+ * becomes effectively perfect, ignoring freshness.\n+ */\n+double normalize_hit_rate(double hits, double load)\n+{\n+    return hits * std::max(load, 1.0);\n+}\n+\n+/** Check the hit rate on loads ranging from 0.1 to 2.0 */\n+BOOST_AUTO_TEST_CASE(cuckoocache_hit_rate_ok)\n+{\n+    /** Arbitrarily selected Hit Rate threshold that happens to work for this test\n+     * as a lower bound on performance.\n+     */\n+    double HitRateThresh = 0.98;\n+    size_t megabytes = 32;\n+    for (double load = 0.1; load < 2; load *= 2) {\n+        double hits = test_cache<CuckooCache::cache<uint256, uint256Hasher>>(megabytes, load);\n+        BOOST_CHECK(normalize_hit_rate(hits, load) > HitRateThresh);\n+    }\n+}\n+\n+\n+/** This helper checks that erased elements are preferentially inserted onto and\n+ * that the hit rate of \"fresher\" keys is reasonable*/\n+template <typename Cache>\n+void test_cache_erase(size_t megabytes)\n+{\n+    double load = 1;\n+    insecure_rand = FastRandomContext(true);\n+    std::vector<uint256> hashes;\n+    Cache set{};\n+    size_t bytes = megabytes * (1 << 20);\n+    set.setup_bytes(bytes);\n+    uint32_t n_insert = static_cast<uint32_t>(load * (bytes / sizeof(uint256)));\n+    hashes.resize(n_insert);\n+    for (uint32_t i = 0; i < n_insert; ++i) {\n+        uint32_t* ptr = (uint32_t*)hashes[i].begin();\n+        for (uint8_t j = 0; j < 8; ++j)\n+            *(ptr++) = insecure_rand.rand32();\n+    }\n+    /** We make a copy of the hashes because future optimizations of the\n+     * cuckoocache may overwrite the inserted element, so the test is\n+     * \"future proofed\".\n+     */\n+    std::vector<uint256> hashes_insert_copy = hashes;\n+\n+    /** Insert the first half */\n+    for (uint32_t i = 0; i < (n_insert / 2); ++i)\n+        set.insert(hashes_insert_copy[i]);\n+    /** Erase the first quarter */\n+    for (uint32_t i = 0; i < (n_insert / 4); ++i)\n+        set.contains(hashes[i], true);\n+    /** Insert the second half */\n+    for (uint32_t i = (n_insert / 2); i < n_insert; ++i)\n+        set.insert(hashes_insert_copy[i]);\n+\n+    /** elements that we marked erased but that are still there */\n+    size_t count_erased_but_contained = 0;\n+    /** elements that we did not erase but are older */\n+    size_t count_stale = 0;\n+    /** elements that were most recently inserted */\n+    size_t count_fresh = 0;\n+\n+    for (uint32_t i = 0; i < (n_insert / 4); ++i)\n+        count_erased_but_contained += set.contains(hashes[i], false);\n+    for (uint32_t i = (n_insert / 4); i < (n_insert / 2); ++i)\n+        count_stale += set.contains(hashes[i], false);\n+    for (uint32_t i = (n_insert / 2); i < n_insert; ++i)\n+        count_fresh += set.contains(hashes[i], false);\n+\n+    double hit_rate_erased_but_contained = double(count_erased_but_contained) / (double(n_insert) / 4.0);\n+    double hit_rate_stale = double(count_stale) / (double(n_insert) / 4.0);\n+    double hit_rate_fresh = double(count_fresh) / (double(n_insert) / 2.0);\n+\n+    // Check that our hit_rate_fresh is perfect\n+    BOOST_CHECK_EQUAL(hit_rate_fresh, 1.0);\n+    // Check that we have a more than 2x better hit rate on stale elements than\n+    // erased elements.\n+    BOOST_CHECK(hit_rate_stale > 2 * hit_rate_erased_but_contained);\n+}\n+\n+BOOST_AUTO_TEST_CASE(cuckoocache_erase_ok)\n+{\n+    size_t megabytes = 32;\n+    test_cache_erase<CuckooCache::cache<uint256, uint256Hasher>>(megabytes);\n+}\n+\n+template <typename Cache>\n+void test_cache_erase_parallel(size_t megabytes)\n+{\n+    double load = 1;\n+    insecure_rand = FastRandomContext(true);\n+    std::vector<uint256> hashes;\n+    Cache set{};\n+    size_t bytes = megabytes * (1 << 20);\n+    set.setup_bytes(bytes);\n+    uint32_t n_insert = static_cast<uint32_t>(load * (bytes / sizeof(uint256)));\n+    hashes.resize(n_insert);\n+    for (uint32_t i = 0; i < n_insert; ++i) {\n+        uint32_t* ptr = (uint32_t*)hashes[i].begin();\n+        for (uint8_t j = 0; j < 8; ++j)\n+            *(ptr++) = insecure_rand.rand32();\n+    }\n+    /** We make a copy of the hashes because future optimizations of the\n+     * cuckoocache may overwrite the inserted element, so the test is\n+     * \"future proofed\".\n+     */\n+    std::vector<uint256> hashes_insert_copy = hashes;\n+    boost::shared_mutex mtx;\n+\n+    {\n+        /** Grab lock to make sure we release inserts */\n+        boost::unique_lock<boost::shared_mutex> l(mtx);\n+        /** Insert the first half */\n+        for (uint32_t i = 0; i < (n_insert / 2); ++i)\n+            set.insert(hashes_insert_copy[i]);\n+    }\n+\n+    /** Spin up 3 threads to run contains with erase.\n+     */\n+    std::vector<std::thread> threads;\n+    /** Erase the first quarter */\n+    for (uint32_t x = 0; x < 3; ++x)\n+        /** Each thread is emplaced with x copy-by-value\n+        */\n+        threads.emplace_back([&, x] {\n+            boost::shared_lock<boost::shared_mutex> l(mtx);\n+            size_t ntodo = (n_insert/4)/3;\n+            size_t start = ntodo*x;\n+            size_t end = ntodo*(x+1);\n+            for (uint32_t i = start; i < end; ++i)\n+                set.contains(hashes[i], true);\n+        });\n+\n+    /** Wait for all threads to finish\n+     */\n+    for (std::thread& t : threads)\n+        t.join();\n+    /** Grab lock to make sure we observe erases */\n+    boost::unique_lock<boost::shared_mutex> l(mtx);\n+    /** Insert the second half */\n+    for (uint32_t i = (n_insert / 2); i < n_insert; ++i)\n+        set.insert(hashes_insert_copy[i]);\n+\n+    /** elements that we marked erased but that are still there */\n+    size_t count_erased_but_contained = 0;\n+    /** elements that we did not erase but are older */\n+    size_t count_stale = 0;\n+    /** elements that were most recently inserted */\n+    size_t count_fresh = 0;\n+\n+    for (uint32_t i = 0; i < (n_insert / 4); ++i)\n+        count_erased_but_contained += set.contains(hashes[i], false);\n+    for (uint32_t i = (n_insert / 4); i < (n_insert / 2); ++i)\n+        count_stale += set.contains(hashes[i], false);\n+    for (uint32_t i = (n_insert / 2); i < n_insert; ++i)\n+        count_fresh += set.contains(hashes[i], false);\n+\n+    double hit_rate_erased_but_contained = double(count_erased_but_contained) / (double(n_insert) / 4.0);\n+    double hit_rate_stale = double(count_stale) / (double(n_insert) / 4.0);\n+    double hit_rate_fresh = double(count_fresh) / (double(n_insert) / 2.0);\n+\n+    // Check that our hit_rate_fresh is perfect\n+    BOOST_CHECK_EQUAL(hit_rate_fresh, 1.0);\n+    // Check that we have a more than 2x better hit rate on stale elements than\n+    // erased elements.\n+    BOOST_CHECK(hit_rate_stale > 2 * hit_rate_erased_but_contained);\n+}\n+BOOST_AUTO_TEST_CASE(cuckoocache_erase_parallel_ok)\n+{\n+    size_t megabytes = 32;\n+    test_cache_erase_parallel<CuckooCache::cache<uint256, uint256Hasher>>(megabytes);\n+}\n+\n+\n+template <typename Cache>\n+void test_cache_generations()\n+{\n+    // This test checks that for a simulation of network activity, the fresh hit\n+    // rate is never below 99%, and the number of times that it is worse than\n+    // 99.9% are less than 1% of the time.\n+    double min_hit_rate = 0.99;\n+    double tight_hit_rate = 0.999;\n+    double max_rate_less_than_tight_hit_rate = 0.01;\n+    // A cache that meets this specification is therefore shown to have a hit\n+    // rate of at least tight_hit_rate * (1 - max_rate_less_than_tight_hit_rate) +\n+    // min_hit_rate*max_rate_less_than_tight_hit_rate = 0.999*99%+0.99*1% == 99.89%\n+    // hit rate with low variance.\n+\n+    // We use deterministic values, but this test has also passed on many\n+    // iterations with non-deterministic values, so it isn't \"overfit\" to the\n+    // specific entropy in FastRandomContext(true) and implementation of the\n+    // cache.\n+    insecure_rand = FastRandomContext(true);\n+\n+    // block_activity models a chunk of network activity. n_insert elements are\n+    // adde to the cache. The first and last n/4 are stored for removal later\n+    // and the middle n/2 are not stored. This models a network which uses half\n+    // the signatures of recently (since the last block) added transactions\n+    // immediately and never uses the other half.\n+    struct block_activity {\n+        std::vector<uint256> reads;\n+        block_activity(uint32_t n_insert, Cache& c) : reads()\n+        {\n+            std::vector<uint256> inserts;\n+            inserts.resize(n_insert);\n+            reads.reserve(n_insert / 2);\n+            for (uint32_t i = 0; i < n_insert; ++i) {\n+                uint32_t* ptr = (uint32_t*)inserts[i].begin();\n+                for (uint8_t j = 0; j < 8; ++j)\n+                    *(ptr++) = insecure_rand.rand32();\n+            }\n+            for (uint32_t i = 0; i < n_insert / 4; ++i)\n+                reads.push_back(inserts[i]);\n+            for (uint32_t i = n_insert - (n_insert / 4); i < n_insert; ++i)\n+                reads.push_back(inserts[i]);\n+            for (auto h : inserts)\n+                c.insert(h);\n+        }\n+    };\n+\n+    const uint32_t BLOCK_SIZE = 10000;\n+    // We expect window size 60 to perform reasonably given that each epoch\n+    // stores 45% of the cache size (~472k).\n+    const uint32_t WINDOW_SIZE = 60;\n+    const uint32_t POP_AMOUNT = (BLOCK_SIZE / WINDOW_SIZE) / 2;\n+    const double load = 10;\n+    const size_t megabytes = 32;\n+    const size_t bytes = megabytes * (1 << 20);\n+    const uint32_t n_insert = static_cast<uint32_t>(load * (bytes / sizeof(uint256)));\n+\n+    std::vector<block_activity> hashes;\n+    Cache set{};\n+    set.setup_bytes(bytes);\n+    hashes.reserve(n_insert / BLOCK_SIZE);\n+    std::deque<block_activity> last_few;\n+    uint32_t out_of_tight_tolerance = 0;\n+    uint32_t total = n_insert / BLOCK_SIZE;\n+    // we use the deque last_few to model a sliding window of blocks. at each\n+    // step, each of the last WINDOW_SIZE block_activities checks the cache for\n+    // POP_AMOUNT of the hashes that they inserted, and marks these erased.\n+    for (uint32_t i = 0; i < total; ++i) {\n+        if (last_few.size() == WINDOW_SIZE)\n+            last_few.pop_front();\n+        last_few.emplace_back(BLOCK_SIZE, set);\n+        uint32_t count = 0;\n+        for (auto& act : last_few)\n+            for (uint32_t k = 0; k < POP_AMOUNT; ++k) {\n+                count += set.contains(act.reads.back(), true);\n+                act.reads.pop_back();\n+            }\n+        // We use last_few.size() rather than WINDOW_SIZE for the correct\n+        // behavior on the first WINDOW_SIZE iterations where the deque is not\n+        // full yet.\n+        double hit = (double(count)) / (last_few.size() * POP_AMOUNT);\n+        // Loose Check that hit rate is above min_hit_rate\n+        BOOST_CHECK(hit > min_hit_rate);\n+        // Tighter check, count number of times we are less than tight_hit_rate\n+        // (and implicityly, greater than min_hit_rate)\n+        out_of_tight_tolerance += hit < tight_hit_rate;\n+    }\n+    // Check that being out of tolerance happens less than\n+    // max_rate_less_than_tight_hit_rate of the time\n+    BOOST_CHECK(double(out_of_tight_tolerance) / double(total) < max_rate_less_than_tight_hit_rate);\n+}\n+BOOST_AUTO_TEST_CASE(cuckoocache_generations)\n+{\n+    test_cache_generations<CuckooCache::cache<uint256, uint256Hasher>>();\n+}\n+\n+BOOST_AUTO_TEST_SUITE_END();"
      }
    ]
  }
]