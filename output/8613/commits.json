[
  {
    "sha": "634ad517037b319147816f1d112b066528e1724a",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo2MzRhZDUxNzAzN2IzMTkxNDc4MTZmMWQxMTJiMDY2NTI4ZTE3MjRh",
    "commit": {
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter.wuille@gmail.com",
        "date": "2016-12-02T00:14:45Z"
      },
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter.wuille@gmail.com",
        "date": "2016-12-02T00:14:45Z"
      },
      "message": "Squashed 'src/leveldb/' changes from 20ca81f..a31c8aa\n\na31c8aa Add NewAppendableFile for win32 environment\n1913d71 Merge upstream LevelDB 1.19\n3080a45 Increase leveldb version to 1.19.\nfa6dc01 A zippy change broke test assumptions about the size of compressed output. Fix the tests by allowing more slop in zippy's behavior. ------------- Created by MOE: https://github.com/google/moe MOE_MIGRATED_REVID=123432472\n06a191b fix problems in LevelDB's caching code\na7bff69 Fix LevelDB build when asserts are enabled in release builds. (#367)\nea992b4 Change std::uint64_t to uint64_t (#354)\ne84b5bd This CL fixes a bug encountered when reading records from leveldb files that have been split, as in a [] input task split.\n3211343 Deleted redundant null ptr check prior to delete.\n7306ef8 Merge pull request #348 from randomascii/master\n6b18316 Fix signed/unsigned mismatch on VC++ builds\nadbe3eb Putting build artifacts in subdirectory.\n2d0320a Merge pull request #329 from ralphtheninja/travis-badge\ndd1c3c3 add travis build badge\n43fcf23 Merge pull request #328 from cmumford/master\n9fcae61 Added a Travis CI build file.\ndac40d2 Merge pull request #284 from ideawu/master\n8ec241a Merge pull request #317 from falvojr/patch-1\n5d36bed Merge pull request #272 from vapier/master\n4753c9b Added a contributors section to README.md\ne2446d0 Merge pull request #275 from paulirish/patch-1\n706b7f8 Resolve race when getting approximate-memory-usage property\n3c9ff3c Only compiling TrimSpace on linux.\nf8d205c Including atomic_pointer.h in port_posix\n889de31 Let LevelDB use xcrun to determine Xcode.app path instead of using a hardcoded path.\n528c2bc Add \"approximate-memory-usage\" property to leveldb::DB::GetProperty\n359b6bc Add leveldb::Cache::Prune\n50e77a8 Fix size_t/int comparison/conversion issues in leveldb.\n5208e79 Added leveldb::Status::IsInvalidArgument() method.\nce45404 Suppress error reporting after seeking but before a valid First or Full record is encountered.\nb9afa1f include <assert> -> <cassert>\nedf2939 Update README.md\n65190ac Will not reuse manifest if reuse_logs options is false.\nac1d69d LevelDB now attempts to reuse the preceding MANIFEST and log file when re-opened.\n76bba13 fix indent\n8fcceb2 log compaction output file's level along with number\n0e0f074 documentation. improved link\nc85addc readme: improved documentation link\nceff6f1 Fix Android/MIPS build.\n77948e7 Add benchmark that measures cost of repeatedly opening the database.\n34ad72e Move header guard below copyright banner.\na75d435 Clean up layering of storage/leveldb/...\nb234f65 Added a new fault injection test.\nc4c38f9 Add arm64 support to leveldb.\ncea9b10 Fixed incorrect comment wording for Iterator::Seek.\nc00c569 Deleted old README file.\n\ngit-subtree-dir: src/leveldb\ngit-subtree-split: a31c8aa408d5594830f7cb20ead1ef1dff51b79e",
      "tree": {
        "sha": "0088401632072effafed7c43d67a204467ffc460",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/0088401632072effafed7c43d67a204467ffc460"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/634ad517037b319147816f1d112b066528e1724a",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/634ad517037b319147816f1d112b066528e1724a",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/634ad517037b319147816f1d112b066528e1724a",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/634ad517037b319147816f1d112b066528e1724a/comments",
    "author": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "fb9857bfd68c13b52e14bc28dd981bc12501806a",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/fb9857bfd68c13b52e14bc28dd981bc12501806a",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/fb9857bfd68c13b52e14bc28dd981bc12501806a"
      }
    ],
    "stats": {
      "total": 2314,
      "additions": 1942,
      "deletions": 372
    },
    "files": [
      {
        "sha": "f5bd74c4541263e5df4e598158879d78edb51cda",
        "filename": ".travis.yml",
        "status": "added",
        "additions": 13,
        "deletions": 0,
        "changes": 13,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/.travis.yml",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/.travis.yml",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.travis.yml?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -0,0 +1,13 @@\n+language: cpp\n+compiler:\n+- clang\n+- gcc\n+os:\n+- linux\n+- osx\n+sudo: false\n+before_install:\n+- echo $LANG\n+- echo $LC_ALL\n+script:\n+- make -j 4 check"
      },
      {
        "sha": "07a5a1ead6fd8a3b6eb45f0ef5481c5787f3fd78",
        "filename": "Makefile",
        "status": "modified",
        "additions": 327,
        "deletions": 140,
        "changes": 467,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/Makefile",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/Makefile",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/Makefile?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -20,208 +20,395 @@ $(shell CC=\"$(CC)\" CXX=\"$(CXX)\" TARGET_OS=\"$(TARGET_OS)\" \\\n # this file is generated by the previous line to set build flags and sources\n include build_config.mk\n \n+TESTS = \\\n+\tdb/autocompact_test \\\n+\tdb/c_test \\\n+\tdb/corruption_test \\\n+\tdb/db_test \\\n+\tdb/dbformat_test \\\n+\tdb/fault_injection_test \\\n+\tdb/filename_test \\\n+\tdb/log_test \\\n+\tdb/recovery_test \\\n+\tdb/skiplist_test \\\n+\tdb/version_edit_test \\\n+\tdb/version_set_test \\\n+\tdb/write_batch_test \\\n+\thelpers/memenv/memenv_test \\\n+\tissues/issue178_test \\\n+\tissues/issue200_test \\\n+\ttable/filter_block_test \\\n+\ttable/table_test \\\n+\tutil/arena_test \\\n+\tutil/bloom_test \\\n+\tutil/cache_test \\\n+\tutil/coding_test \\\n+\tutil/crc32c_test \\\n+\tutil/env_test \\\n+\tutil/hash_test\n+\n+UTILS = \\\n+\tdb/db_bench \\\n+\tdb/leveldbutil\n+\n+# Put the object files in a subdirectory, but the application at the top of the object dir.\n+PROGNAMES := $(notdir $(TESTS) $(UTILS))\n+\n+# On Linux may need libkyotocabinet-dev for dependency.\n+BENCHMARKS = \\\n+\tdoc/bench/db_bench_sqlite3 \\\n+\tdoc/bench/db_bench_tree_db\n+\n CFLAGS += -I. -I./include $(PLATFORM_CCFLAGS) $(OPT)\n CXXFLAGS += -I. -I./include $(PLATFORM_CXXFLAGS) $(OPT)\n \n LDFLAGS += $(PLATFORM_LDFLAGS)\n LIBS += $(PLATFORM_LIBS)\n \n-LIBOBJECTS = $(SOURCES:.cc=.o)\n-MEMENVOBJECTS = $(MEMENV_SOURCES:.cc=.o)\n-\n-TESTUTIL = ./util/testutil.o\n-TESTHARNESS = ./util/testharness.o $(TESTUTIL)\n+SIMULATOR_OUTDIR=out-ios-x86\n+DEVICE_OUTDIR=out-ios-arm\n \n-# Note: iOS should probably be using libtool, not ar.\n ifeq ($(PLATFORM), IOS)\n+# Note: iOS should probably be using libtool, not ar.\n AR=xcrun ar\n+SIMULATORSDK=$(shell xcrun -sdk iphonesimulator --show-sdk-path)\n+DEVICESDK=$(shell xcrun -sdk iphoneos --show-sdk-path)\n+DEVICE_CFLAGS = -isysroot \"$(DEVICESDK)\" -arch armv6 -arch armv7 -arch armv7s -arch arm64\n+SIMULATOR_CFLAGS = -isysroot \"$(SIMULATORSDK)\" -arch i686 -arch x86_64\n+STATIC_OUTDIR=out-ios-universal\n+else\n+STATIC_OUTDIR=out-static\n+SHARED_OUTDIR=out-shared\n+STATIC_PROGRAMS := $(addprefix $(STATIC_OUTDIR)/, $(PROGNAMES))\n+SHARED_PROGRAMS := $(addprefix $(SHARED_OUTDIR)/, db_bench)\n endif\n \n-TESTS = \\\n-\tarena_test \\\n-\tautocompact_test \\\n-\tbloom_test \\\n-\tc_test \\\n-\tcache_test \\\n-\tcoding_test \\\n-\tcorruption_test \\\n-\tcrc32c_test \\\n-\tdb_test \\\n-\tdbformat_test \\\n-\tenv_test \\\n-\tfilename_test \\\n-\tfilter_block_test \\\n-\thash_test \\\n-\tissue178_test \\\n-\tissue200_test \\\n-\tlog_test \\\n-\tmemenv_test \\\n-\tskiplist_test \\\n-\ttable_test \\\n-\tversion_edit_test \\\n-\tversion_set_test \\\n-\twrite_batch_test\n-\n-PROGRAMS = db_bench leveldbutil $(TESTS)\n-BENCHMARKS = db_bench_sqlite3 db_bench_tree_db\n-\n-LIBRARY = libleveldb.a\n-MEMENVLIBRARY = libmemenv.a\n+STATIC_LIBOBJECTS := $(addprefix $(STATIC_OUTDIR)/, $(SOURCES:.cc=.o))\n+STATIC_MEMENVOBJECTS := $(addprefix $(STATIC_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n+\n+DEVICE_LIBOBJECTS := $(addprefix $(DEVICE_OUTDIR)/, $(SOURCES:.cc=.o))\n+DEVICE_MEMENVOBJECTS := $(addprefix $(DEVICE_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n+\n+SIMULATOR_LIBOBJECTS := $(addprefix $(SIMULATOR_OUTDIR)/, $(SOURCES:.cc=.o))\n+SIMULATOR_MEMENVOBJECTS := $(addprefix $(SIMULATOR_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n+\n+SHARED_LIBOBJECTS := $(addprefix $(SHARED_OUTDIR)/, $(SOURCES:.cc=.o))\n+SHARED_MEMENVOBJECTS := $(addprefix $(SHARED_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n+\n+TESTUTIL := $(STATIC_OUTDIR)/util/testutil.o\n+TESTHARNESS := $(STATIC_OUTDIR)/util/testharness.o $(TESTUTIL)\n+\n+STATIC_TESTOBJS := $(addprefix $(STATIC_OUTDIR)/, $(addsuffix .o, $(TESTS)))\n+STATIC_UTILOBJS := $(addprefix $(STATIC_OUTDIR)/, $(addsuffix .o, $(UTILS)))\n+STATIC_ALLOBJS := $(STATIC_LIBOBJECTS) $(STATIC_MEMENVOBJECTS) $(STATIC_TESTOBJS) $(STATIC_UTILOBJS) $(TESTHARNESS)\n+DEVICE_ALLOBJS := $(DEVICE_LIBOBJECTS) $(DEVICE_MEMENVOBJECTS)\n+SIMULATOR_ALLOBJS := $(SIMULATOR_LIBOBJECTS) $(SIMULATOR_MEMENVOBJECTS)\n \n default: all\n \n # Should we build shared libraries?\n ifneq ($(PLATFORM_SHARED_EXT),)\n \n+# Many leveldb test apps use non-exported API's. Only build a subset for testing.\n+SHARED_ALLOBJS := $(SHARED_LIBOBJECTS) $(SHARED_MEMENVOBJECTS) $(TESTHARNESS)\n+\n ifneq ($(PLATFORM_SHARED_VERSIONED),true)\n-SHARED1 = libleveldb.$(PLATFORM_SHARED_EXT)\n-SHARED2 = $(SHARED1)\n-SHARED3 = $(SHARED1)\n-SHARED = $(SHARED1)\n+SHARED_LIB1 = libleveldb.$(PLATFORM_SHARED_EXT)\n+SHARED_LIB2 = $(SHARED_LIB1)\n+SHARED_LIB3 = $(SHARED_LIB1)\n+SHARED_LIBS = $(SHARED_LIB1)\n+SHARED_MEMENVLIB = $(SHARED_OUTDIR)/libmemenv.a\n else\n # Update db.h if you change these.\n-SHARED_MAJOR = 1\n-SHARED_MINOR = 18\n-SHARED1 = libleveldb.$(PLATFORM_SHARED_EXT)\n-SHARED2 = $(SHARED1).$(SHARED_MAJOR)\n-SHARED3 = $(SHARED1).$(SHARED_MAJOR).$(SHARED_MINOR)\n-SHARED = $(SHARED1) $(SHARED2) $(SHARED3)\n-$(SHARED1): $(SHARED3)\n-\tln -fs $(SHARED3) $(SHARED1)\n-$(SHARED2): $(SHARED3)\n-\tln -fs $(SHARED3) $(SHARED2)\n+SHARED_VERSION_MAJOR = 1\n+SHARED_VERSION_MINOR = 19\n+SHARED_LIB1 = libleveldb.$(PLATFORM_SHARED_EXT)\n+SHARED_LIB2 = $(SHARED_LIB1).$(SHARED_VERSION_MAJOR)\n+SHARED_LIB3 = $(SHARED_LIB1).$(SHARED_VERSION_MAJOR).$(SHARED_VERSION_MINOR)\n+SHARED_LIBS = $(SHARED_OUTDIR)/$(SHARED_LIB1) $(SHARED_OUTDIR)/$(SHARED_LIB2) $(SHARED_OUTDIR)/$(SHARED_LIB3)\n+$(SHARED_OUTDIR)/$(SHARED_LIB1): $(SHARED_OUTDIR)/$(SHARED_LIB3)\n+\tln -fs $(SHARED_LIB3) $(SHARED_OUTDIR)/$(SHARED_LIB1)\n+$(SHARED_OUTDIR)/$(SHARED_LIB2): $(SHARED_OUTDIR)/$(SHARED_LIB3)\n+\tln -fs $(SHARED_LIB3) $(SHARED_OUTDIR)/$(SHARED_LIB2)\n+SHARED_MEMENVLIB = $(SHARED_OUTDIR)/libmemenv.a\n endif\n \n-$(SHARED3):\n-\t$(CXX) $(LDFLAGS) $(PLATFORM_SHARED_LDFLAGS)$(SHARED2) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) $(SOURCES) -o $(SHARED3) $(LIBS)\n+$(SHARED_OUTDIR)/$(SHARED_LIB3): $(SHARED_LIBOBJECTS)\n+\t$(CXX) $(LDFLAGS) $(PLATFORM_SHARED_LDFLAGS)$(SHARED_LIB2) $(SHARED_LIBOBJECTS) -o $(SHARED_OUTDIR)/$(SHARED_LIB3) $(LIBS)\n \n endif  # PLATFORM_SHARED_EXT\n \n-all: $(SHARED) $(LIBRARY)\n+all: $(SHARED_LIBS) $(SHARED_PROGRAMS) $(STATIC_OUTDIR)/libleveldb.a $(STATIC_OUTDIR)/libmemenv.a $(STATIC_PROGRAMS)\n \n-check: all $(PROGRAMS) $(TESTS)\n-\tfor t in $(TESTS); do echo \"***** Running $$t\"; ./$$t || exit 1; done\n+check: $(STATIC_PROGRAMS)\n+\tfor t in $(notdir $(TESTS)); do echo \"***** Running $$t\"; $(STATIC_OUTDIR)/$$t || exit 1; done\n \n clean:\n-\t-rm -f $(PROGRAMS) $(BENCHMARKS) $(LIBRARY) $(SHARED) $(MEMENVLIBRARY) */*.o */*/*.o ios-x86/*/*.o ios-arm/*/*.o build_config.mk\n-\t-rm -rf ios-x86/* ios-arm/*\n+\t-rm -rf out-static out-shared out-ios-x86 out-ios-arm out-ios-universal\n+\t-rm -f build_config.mk\n+\t-rm -rf ios-x86 ios-arm\n \n-$(LIBRARY): $(LIBOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(LIBOBJECTS)\n+$(STATIC_OUTDIR):\n+\tmkdir $@\n \n-db_bench: db/db_bench.o $(LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) db/db_bench.o $(LIBOBJECTS) $(TESTUTIL) -o $@ $(LIBS)\n+$(STATIC_OUTDIR)/db: | $(STATIC_OUTDIR)\n+\tmkdir $@\n \n-db_bench_sqlite3: doc/bench/db_bench_sqlite3.o $(LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) doc/bench/db_bench_sqlite3.o $(LIBOBJECTS) $(TESTUTIL) -o $@ -lsqlite3 $(LIBS)\n+$(STATIC_OUTDIR)/helpers/memenv: | $(STATIC_OUTDIR)\n+\tmkdir -p $@\n \n-db_bench_tree_db: doc/bench/db_bench_tree_db.o $(LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) doc/bench/db_bench_tree_db.o $(LIBOBJECTS) $(TESTUTIL) -o $@ -lkyotocabinet $(LIBS)\n+$(STATIC_OUTDIR)/port: | $(STATIC_OUTDIR)\n+\tmkdir $@\n \n-leveldbutil: db/leveldb_main.o $(LIBOBJECTS)\n-\t$(CXX) $(LDFLAGS) db/leveldb_main.o $(LIBOBJECTS) -o $@ $(LIBS)\n+$(STATIC_OUTDIR)/table: | $(STATIC_OUTDIR)\n+\tmkdir $@\n \n-arena_test: util/arena_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/arena_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(STATIC_OUTDIR)/util: | $(STATIC_OUTDIR)\n+\tmkdir $@\n \n-autocompact_test: db/autocompact_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/autocompact_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+.PHONY: STATIC_OBJDIRS\n+STATIC_OBJDIRS: \\\n+\t$(STATIC_OUTDIR)/db \\\n+\t$(STATIC_OUTDIR)/port \\\n+\t$(STATIC_OUTDIR)/table \\\n+\t$(STATIC_OUTDIR)/util \\\n+\t$(STATIC_OUTDIR)/helpers/memenv\n \n-bloom_test: util/bloom_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/bloom_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR):\n+\tmkdir $@\n \n-c_test: db/c_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/c_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR)/db: | $(SHARED_OUTDIR)\n+\tmkdir $@\n \n-cache_test: util/cache_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/cache_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR)/helpers/memenv: | $(SHARED_OUTDIR)\n+\tmkdir -p $@\n \n-coding_test: util/coding_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/coding_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR)/port: | $(SHARED_OUTDIR)\n+\tmkdir $@\n \n-corruption_test: db/corruption_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/corruption_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR)/table: | $(SHARED_OUTDIR)\n+\tmkdir $@\n \n-crc32c_test: util/crc32c_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/crc32c_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR)/util: | $(SHARED_OUTDIR)\n+\tmkdir $@\n \n-db_test: db/db_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/db_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+.PHONY: SHARED_OBJDIRS\n+SHARED_OBJDIRS: \\\n+\t$(SHARED_OUTDIR)/db \\\n+\t$(SHARED_OUTDIR)/port \\\n+\t$(SHARED_OUTDIR)/table \\\n+\t$(SHARED_OUTDIR)/util \\\n+\t$(SHARED_OUTDIR)/helpers/memenv\n \n-dbformat_test: db/dbformat_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/dbformat_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR):\n+\tmkdir $@\n \n-env_test: util/env_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/env_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR)/db: | $(DEVICE_OUTDIR)\n+\tmkdir $@\n \n-filename_test: db/filename_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/filename_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR)/helpers/memenv: | $(DEVICE_OUTDIR)\n+\tmkdir -p $@\n \n-filter_block_test: table/filter_block_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) table/filter_block_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR)/port: | $(DEVICE_OUTDIR)\n+\tmkdir $@\n \n-hash_test: util/hash_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/hash_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR)/table: | $(DEVICE_OUTDIR)\n+\tmkdir $@\n \n-issue178_test: issues/issue178_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) issues/issue178_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR)/util: | $(DEVICE_OUTDIR)\n+\tmkdir $@\n \n-issue200_test: issues/issue200_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) issues/issue200_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+.PHONY: DEVICE_OBJDIRS\n+DEVICE_OBJDIRS: \\\n+\t$(DEVICE_OUTDIR)/db \\\n+\t$(DEVICE_OUTDIR)/port \\\n+\t$(DEVICE_OUTDIR)/table \\\n+\t$(DEVICE_OUTDIR)/util \\\n+\t$(DEVICE_OUTDIR)/helpers/memenv\n \n-log_test: db/log_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/log_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR):\n+\tmkdir $@\n \n-table_test: table/table_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) table/table_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR)/db: | $(SIMULATOR_OUTDIR)\n+\tmkdir $@\n \n-skiplist_test: db/skiplist_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/skiplist_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR)/helpers/memenv: | $(SIMULATOR_OUTDIR)\n+\tmkdir -p $@\n \n-version_edit_test: db/version_edit_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/version_edit_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR)/port: | $(SIMULATOR_OUTDIR)\n+\tmkdir $@\n \n-version_set_test: db/version_set_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/version_set_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR)/table: | $(SIMULATOR_OUTDIR)\n+\tmkdir $@\n \n-write_batch_test: db/write_batch_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/write_batch_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR)/util: | $(SIMULATOR_OUTDIR)\n+\tmkdir $@\n \n-$(MEMENVLIBRARY) : $(MEMENVOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(MEMENVOBJECTS)\n+.PHONY: SIMULATOR_OBJDIRS\n+SIMULATOR_OBJDIRS: \\\n+\t$(SIMULATOR_OUTDIR)/db \\\n+\t$(SIMULATOR_OUTDIR)/port \\\n+\t$(SIMULATOR_OUTDIR)/table \\\n+\t$(SIMULATOR_OUTDIR)/util \\\n+\t$(SIMULATOR_OUTDIR)/helpers/memenv\n \n-memenv_test : helpers/memenv/memenv_test.o $(MEMENVLIBRARY) $(LIBRARY) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) helpers/memenv/memenv_test.o $(MEMENVLIBRARY) $(LIBRARY) $(TESTHARNESS) -o $@ $(LIBS)\n+$(STATIC_ALLOBJS): | STATIC_OBJDIRS\n+$(DEVICE_ALLOBJS): | DEVICE_OBJDIRS\n+$(SIMULATOR_ALLOBJS): | SIMULATOR_OBJDIRS\n+$(SHARED_ALLOBJS): | SHARED_OBJDIRS\n \n ifeq ($(PLATFORM), IOS)\n-# For iOS, create universal object files to be used on both the simulator and\n+$(DEVICE_OUTDIR)/libleveldb.a: $(DEVICE_LIBOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(DEVICE_LIBOBJECTS)\n+\n+$(SIMULATOR_OUTDIR)/libleveldb.a: $(SIMULATOR_LIBOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(SIMULATOR_LIBOBJECTS)\n+\n+$(DEVICE_OUTDIR)/libmemenv.a: $(DEVICE_MEMENVOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(DEVICE_MEMENVOBJECTS)\n+\n+$(SIMULATOR_OUTDIR)/libmemenv.a: $(SIMULATOR_MEMENVOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(SIMULATOR_MEMENVOBJECTS)\n+\n+# For iOS, create universal object libraries to be used on both the simulator and\n # a device.\n-PLATFORMSROOT=/Applications/Xcode.app/Contents/Developer/Platforms\n-SIMULATORROOT=$(PLATFORMSROOT)/iPhoneSimulator.platform/Developer\n-DEVICEROOT=$(PLATFORMSROOT)/iPhoneOS.platform/Developer\n-IOSVERSION=$(shell defaults read $(PLATFORMSROOT)/iPhoneOS.platform/version CFBundleShortVersionString)\n-IOSARCH=-arch armv6 -arch armv7 -arch armv7s -arch arm64\n-\n-.cc.o:\n-\tmkdir -p ios-x86/$(dir $@)\n-\txcrun -sdk iphonesimulator $(CXX) $(CXXFLAGS) -isysroot $(SIMULATORROOT)/SDKs/iPhoneSimulator$(IOSVERSION).sdk -arch i686 -arch x86_64 -c $< -o ios-x86/$@\n-\tmkdir -p ios-arm/$(dir $@)\n-\txcrun -sdk iphoneos $(CXX) $(CXXFLAGS) -isysroot $(DEVICEROOT)/SDKs/iPhoneOS$(IOSVERSION).sdk $(IOSARCH) -c $< -o ios-arm/$@\n-\txcrun lipo ios-x86/$@ ios-arm/$@ -create -output $@\n-\n-.c.o:\n-\tmkdir -p ios-x86/$(dir $@)\n-\txcrun -sdk iphonesimulator $(CC) $(CFLAGS) -isysroot $(SIMULATORROOT)/SDKs/iPhoneSimulator$(IOSVERSION).sdk -arch i686 -arch x86_64 -c $< -o ios-x86/$@\n-\tmkdir -p ios-arm/$(dir $@)\n-\txcrun -sdk iphoneos $(CC) $(CFLAGS) -isysroot $(DEVICEROOT)/SDKs/iPhoneOS$(IOSVERSION).sdk $(IOSARCH) -c $< -o ios-arm/$@\n-\txcrun lipo ios-x86/$@ ios-arm/$@ -create -output $@\n+$(STATIC_OUTDIR)/libleveldb.a: $(STATIC_OUTDIR) $(DEVICE_OUTDIR)/libleveldb.a $(SIMULATOR_OUTDIR)/libleveldb.a\n+\tlipo -create $(DEVICE_OUTDIR)/libleveldb.a $(SIMULATOR_OUTDIR)/libleveldb.a -output $@\n \n+$(STATIC_OUTDIR)/libmemenv.a: $(STATIC_OUTDIR) $(DEVICE_OUTDIR)/libmemenv.a $(SIMULATOR_OUTDIR)/libmemenv.a\n+\tlipo -create $(DEVICE_OUTDIR)/libmemenv.a $(SIMULATOR_OUTDIR)/libmemenv.a -output $@\n else\n-.cc.o:\n+$(STATIC_OUTDIR)/libleveldb.a:$(STATIC_LIBOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(STATIC_LIBOBJECTS)\n+\n+$(STATIC_OUTDIR)/libmemenv.a:$(STATIC_MEMENVOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(STATIC_MEMENVOBJECTS)\n+endif\n+\n+$(SHARED_MEMENVLIB):$(SHARED_MEMENVOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(SHARED_MEMENVOBJECTS)\n+\n+$(STATIC_OUTDIR)/db_bench:db/db_bench.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/db_bench.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/db_bench_sqlite3:doc/bench/db_bench_sqlite3.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) doc/bench/db_bench_sqlite3.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ -lsqlite3 $(LIBS)\n+\n+$(STATIC_OUTDIR)/db_bench_tree_db:doc/bench/db_bench_tree_db.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) doc/bench/db_bench_tree_db.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ -lkyotocabinet $(LIBS)\n+\n+$(STATIC_OUTDIR)/leveldbutil:db/leveldbutil.cc $(STATIC_LIBOBJECTS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/leveldbutil.cc $(STATIC_LIBOBJECTS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/arena_test:util/arena_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/arena_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/autocompact_test:db/autocompact_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/autocompact_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/bloom_test:util/bloom_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/bloom_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/c_test:$(STATIC_OUTDIR)/db/c_test.o $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(STATIC_OUTDIR)/db/c_test.o $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/cache_test:util/cache_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/cache_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/coding_test:util/coding_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/coding_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/corruption_test:db/corruption_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/corruption_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/crc32c_test:util/crc32c_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/crc32c_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/db_test:db/db_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/db_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/dbformat_test:db/dbformat_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/dbformat_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/env_test:util/env_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/env_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/fault_injection_test:db/fault_injection_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/fault_injection_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/filename_test:db/filename_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/filename_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/filter_block_test:table/filter_block_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) table/filter_block_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/hash_test:util/hash_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/hash_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/issue178_test:issues/issue178_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) issues/issue178_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/issue200_test:issues/issue200_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) issues/issue200_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/log_test:db/log_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/log_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/recovery_test:db/recovery_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/recovery_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/table_test:table/table_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) table/table_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/skiplist_test:db/skiplist_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/skiplist_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/version_edit_test:db/version_edit_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/version_edit_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/version_set_test:db/version_set_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/version_set_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/write_batch_test:db/write_batch_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/write_batch_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/memenv_test:$(STATIC_OUTDIR)/helpers/memenv/memenv_test.o $(STATIC_OUTDIR)/libmemenv.a $(STATIC_OUTDIR)/libleveldb.a $(TESTHARNESS)\n+\t$(XCRUN) $(CXX) $(LDFLAGS) $(STATIC_OUTDIR)/helpers/memenv/memenv_test.o $(STATIC_OUTDIR)/libmemenv.a $(STATIC_OUTDIR)/libleveldb.a $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(SHARED_OUTDIR)/db_bench:$(SHARED_OUTDIR)/db/db_bench.o $(SHARED_LIBS) $(TESTUTIL)\n+\t$(XCRUN) $(CXX) $(LDFLAGS) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) $(SHARED_OUTDIR)/db/db_bench.o $(TESTUTIL) $(SHARED_OUTDIR)/$(SHARED_LIB3) -o $@ $(LIBS)\n+\n+.PHONY: run-shared\n+run-shared: $(SHARED_OUTDIR)/db_bench\n+\tLD_LIBRARY_PATH=$(SHARED_OUTDIR) $(SHARED_OUTDIR)/db_bench\n+\n+$(SIMULATOR_OUTDIR)/%.o: %.cc\n+\txcrun -sdk iphonesimulator $(CXX) $(CXXFLAGS) $(SIMULATOR_CFLAGS) -c $< -o $@\n+\n+$(DEVICE_OUTDIR)/%.o: %.cc\n+\txcrun -sdk iphoneos $(CXX) $(CXXFLAGS) $(DEVICE_CFLAGS) -c $< -o $@\n+\n+$(SIMULATOR_OUTDIR)/%.o: %.c\n+\txcrun -sdk iphonesimulator $(CC) $(CFLAGS) $(SIMULATOR_CFLAGS) -c $< -o $@\n+\n+$(DEVICE_OUTDIR)/%.o: %.c\n+\txcrun -sdk iphoneos $(CC) $(CFLAGS) $(DEVICE_CFLAGS) -c $< -o $@\n+\n+$(STATIC_OUTDIR)/%.o: %.cc\n \t$(CXX) $(CXXFLAGS) -c $< -o $@\n \n-.c.o:\n+$(STATIC_OUTDIR)/%.o: %.c\n \t$(CC) $(CFLAGS) -c $< -o $@\n-endif\n+\n+$(SHARED_OUTDIR)/%.o: %.cc\n+\t$(CXX) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) -c $< -o $@\n+\n+$(SHARED_OUTDIR)/%.o: %.c\n+\t$(CC) $(CFLAGS) $(PLATFORM_SHARED_CFLAGS) -c $< -o $@"
      },
      {
        "sha": "3618adeeedbea04a14e00d5a1ef33dd4f0a7be06",
        "filename": "README",
        "status": "removed",
        "additions": 0,
        "deletions": 51,
        "changes": 51,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/fb9857bfd68c13b52e14bc28dd981bc12501806a/README",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/fb9857bfd68c13b52e14bc28dd981bc12501806a/README",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/README?ref=fb9857bfd68c13b52e14bc28dd981bc12501806a",
        "patch": "@@ -1,51 +0,0 @@\n-leveldb: A key-value store\n-Authors: Sanjay Ghemawat (sanjay@google.com) and Jeff Dean (jeff@google.com)\n-\n-The code under this directory implements a system for maintaining a\n-persistent key/value store.\n-\n-See doc/index.html for more explanation.\n-See doc/impl.html for a brief overview of the implementation.\n-\n-The public interface is in include/*.h.  Callers should not include or\n-rely on the details of any other header files in this package.  Those\n-internal APIs may be changed without warning.\n-\n-Guide to header files:\n-\n-include/db.h\n-    Main interface to the DB: Start here\n-\n-include/options.h\n-    Control over the behavior of an entire database, and also\n-    control over the behavior of individual reads and writes.\n-\n-include/comparator.h\n-    Abstraction for user-specified comparison function.  If you want\n-    just bytewise comparison of keys, you can use the default comparator,\n-    but clients can write their own comparator implementations if they\n-    want custom ordering (e.g. to handle different character\n-    encodings, etc.)\n-\n-include/iterator.h\n-    Interface for iterating over data. You can get an iterator\n-    from a DB object.\n-\n-include/write_batch.h\n-    Interface for atomically applying multiple updates to a database.\n-\n-include/slice.h\n-    A simple module for maintaining a pointer and a length into some\n-    other byte array.\n-\n-include/status.h\n-    Status is returned from many of the public interfaces and is used\n-    to report success and various kinds of errors.\n-\n-include/env.h\n-    Abstraction of the OS environment.  A posix implementation of\n-    this interface is in util/env_posix.cc\n-\n-include/table.h\n-include/table_builder.h\n-    Lower-level modules that most clients probably won't use directly"
      },
      {
        "sha": "c75b185e0e7466a3eba439b571d37cdb63b7e660",
        "filename": "README.md",
        "status": "modified",
        "additions": 37,
        "deletions": 2,
        "changes": 39,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/README.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/README.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/README.md?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -1,5 +1,7 @@\n **LevelDB is a fast key-value storage library written at Google that provides an ordered mapping from string keys to string values.**\n \n+[![Build Status](https://travis-ci.org/google/leveldb.svg?branch=master)](https://travis-ci.org/google/leveldb)\n+\n Authors: Sanjay Ghemawat (sanjay@google.com) and Jeff Dean (jeff@google.com)\n \n # Features\n@@ -10,16 +12,49 @@ Authors: Sanjay Ghemawat (sanjay@google.com) and Jeff Dean (jeff@google.com)\n   * Multiple changes can be made in one atomic batch.\n   * Users can create a transient snapshot to get a consistent view of data.\n   * Forward and backward iteration is supported over the data.\n-  * Data is automatically compressed using the [Snappy compression library](http://code.google.com/p/snappy).\n+  * Data is automatically compressed using the [Snappy compression library](http://google.github.io/snappy/).\n   * External activity (file system operations etc.) is relayed through a virtual interface so users can customize the operating system interactions.\n-  * [Detailed documentation](http://htmlpreview.github.io/?https://github.com/google/leveldb/blob/master/doc/index.html) about how to use the library is included with the source code.\n+\n+# Documentation\n+  [LevelDB library documentation](https://rawgit.com/google/leveldb/master/doc/index.html) is online and bundled with the source code.\n \n \n # Limitations\n   * This is not a SQL database.  It does not have a relational data model, it does not support SQL queries, and it has no support for indexes.\n   * Only a single process (possibly multi-threaded) can access a particular database at a time.\n   * There is no client-server support builtin to the library.  An application that needs such support will have to wrap their own server around the library.\n \n+# Contributing to the leveldb Project\n+The leveldb project welcomes contributions. leveldb's primary goal is to be\n+a reliable and fast key/value store. Changes that are in line with the\n+features/limitations outlined above, and meet the requirements below,\n+will be considered.\n+\n+Contribution requirements:\n+\n+1. **POSIX only**. We _generally_ will only accept changes that are both\n+   compiled, and tested on a POSIX platform - usually Linux. Very small\n+   changes will sometimes be accepted, but consider that more of an\n+   exception than the rule.\n+\n+2. **Stable API**. We strive very hard to maintain a stable API. Changes that\n+   require changes for projects using leveldb _might_ be rejected without\n+   sufficient benefit to the project.\n+\n+3. **Tests**: All changes must be accompanied by a new (or changed) test, or\n+   a sufficient explanation as to why a new (or changed) test is not required.\n+\n+## Submitting a Pull Request\n+Before any pull request will be accepted the author must first sign a\n+Contributor License Agreement (CLA) at https://cla.developers.google.com/.\n+\n+In order to keep the commit timeline linear\n+[squash](https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History#Squashing-Commits)\n+your changes down to a single commit and [rebase](https://git-scm.com/docs/git-rebase)\n+on google/leveldb/master. This keeps the commit timeline linear and more easily sync'ed\n+with the internal repository at Google. More information at GitHub's\n+[About Git rebase](https://help.github.com/articles/about-git-rebase/) page.\n+\n # Performance\n \n Here is a performance report (with explanations) from the run of the"
      },
      {
        "sha": "d7edab1d87bb50cb1b882db87ae2bae22959c9f7",
        "filename": "build_detect_platform",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/build_detect_platform",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/build_detect_platform",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/build_detect_platform?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -175,7 +175,7 @@ DIRS=\"$PREFIX/db $PREFIX/util $PREFIX/table\"\n set -f # temporarily disable globbing so that our patterns aren't expanded\n PRUNE_TEST=\"-name *test*.cc -prune\"\n PRUNE_BENCH=\"-name *_bench.cc -prune\"\n-PRUNE_TOOL=\"-name leveldb_main.cc -prune\"\n+PRUNE_TOOL=\"-name leveldbutil.cc -prune\"\n PORTABLE_FILES=`find $DIRS $PRUNE_TEST -o $PRUNE_BENCH -o $PRUNE_TOOL -o -name '*.cc' -print | sort | sed \"s,^$PREFIX/,,\" | tr \"\\n\" \" \"`\n \n set +f # re-enable globbing"
      },
      {
        "sha": "37a484d25fea2d401b6956ae246b9365e7b8aa8e",
        "filename": "db/corruption_test.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/corruption_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/corruption_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/corruption_test.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -36,7 +36,7 @@ class CorruptionTest {\n     tiny_cache_ = NewLRUCache(100);\n     options_.env = &env_;\n     options_.block_cache = tiny_cache_;\n-    dbname_ = test::TmpDir() + \"/db_test\";\n+    dbname_ = test::TmpDir() + \"/corruption_test\";\n     DestroyDB(dbname_, options_);\n \n     db_ = NULL;"
      },
      {
        "sha": "7a0f5e08cdd58672ee69527bcbef72ac869c9189",
        "filename": "db/db_bench.cc",
        "status": "modified",
        "additions": 23,
        "deletions": 1,
        "changes": 24,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/db_bench.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/db_bench.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/db_bench.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -33,6 +33,7 @@\n //      readmissing   -- read N missing keys in random order\n //      readhot       -- read N times in random order from 1% section of DB\n //      seekrandom    -- N random seeks\n+//      open          -- cost of opening a DB\n //      crc32c        -- repeated crc32c of 4K of data\n //      acquireload   -- load N*1000 times\n //   Meta operations:\n@@ -99,6 +100,9 @@ static int FLAGS_bloom_bits = -1;\n // benchmark will fail.\n static bool FLAGS_use_existing_db = false;\n \n+// If true, reuse existing log/MANIFEST files when re-opening a database.\n+static bool FLAGS_reuse_logs = false;\n+\n // Use the db with the following name.\n static const char* FLAGS_db = NULL;\n \n@@ -138,6 +142,7 @@ class RandomGenerator {\n   }\n };\n \n+#if defined(__linux)\n static Slice TrimSpace(Slice s) {\n   size_t start = 0;\n   while (start < s.size() && isspace(s[start])) {\n@@ -149,6 +154,7 @@ static Slice TrimSpace(Slice s) {\n   }\n   return Slice(s.data() + start, limit - start);\n }\n+#endif\n \n static void AppendWithSpace(std::string* str, Slice msg) {\n   if (msg.empty()) return;\n@@ -442,7 +448,11 @@ class Benchmark {\n       bool fresh_db = false;\n       int num_threads = FLAGS_threads;\n \n-      if (name == Slice(\"fillseq\")) {\n+      if (name == Slice(\"open\")) {\n+        method = &Benchmark::OpenBench;\n+        num_ /= 10000;\n+        if (num_ < 1) num_ = 1;\n+      } else if (name == Slice(\"fillseq\")) {\n         fresh_db = true;\n         method = &Benchmark::WriteSeq;\n       } else if (name == Slice(\"fillbatch\")) {\n@@ -695,13 +705,22 @@ class Benchmark {\n     options.write_buffer_size = FLAGS_write_buffer_size;\n     options.max_open_files = FLAGS_open_files;\n     options.filter_policy = filter_policy_;\n+    options.reuse_logs = FLAGS_reuse_logs;\n     Status s = DB::Open(options, FLAGS_db, &db_);\n     if (!s.ok()) {\n       fprintf(stderr, \"open error: %s\\n\", s.ToString().c_str());\n       exit(1);\n     }\n   }\n \n+  void OpenBench(ThreadState* thread) {\n+    for (int i = 0; i < num_; i++) {\n+      delete db_;\n+      Open();\n+      thread->stats.FinishedSingleOp();\n+    }\n+  }\n+\n   void WriteSeq(ThreadState* thread) {\n     DoWrite(thread, true);\n   }\n@@ -941,6 +960,9 @@ int main(int argc, char** argv) {\n     } else if (sscanf(argv[i], \"--use_existing_db=%d%c\", &n, &junk) == 1 &&\n                (n == 0 || n == 1)) {\n       FLAGS_use_existing_db = n;\n+    } else if (sscanf(argv[i], \"--reuse_logs=%d%c\", &n, &junk) == 1 &&\n+               (n == 0 || n == 1)) {\n+      FLAGS_reuse_logs = n;\n     } else if (sscanf(argv[i], \"--num=%d%c\", &n, &junk) == 1) {\n       FLAGS_num = n;\n     } else if (sscanf(argv[i], \"--reads=%d%c\", &n, &junk) == 1) {"
      },
      {
        "sha": "60f4e66e55796756eff2586ecb1f8a9f688b2783",
        "filename": "db/db_impl.cc",
        "status": "modified",
        "additions": 124,
        "deletions": 70,
        "changes": 194,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/db_impl.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/db_impl.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/db_impl.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -125,7 +125,7 @@ DBImpl::DBImpl(const Options& raw_options, const std::string& dbname)\n       db_lock_(NULL),\n       shutting_down_(NULL),\n       bg_cv_(&mutex_),\n-      mem_(new MemTable(internal_comparator_)),\n+      mem_(NULL),\n       imm_(NULL),\n       logfile_(NULL),\n       logfile_number_(0),\n@@ -134,7 +134,6 @@ DBImpl::DBImpl(const Options& raw_options, const std::string& dbname)\n       tmp_batch_(new WriteBatch),\n       bg_compaction_scheduled_(false),\n       manual_compaction_(NULL) {\n-  mem_->Ref();\n   has_imm_.Release_Store(NULL);\n \n   // Reserve ten files or so for other uses and give the rest to TableCache.\n@@ -271,7 +270,7 @@ void DBImpl::DeleteObsoleteFiles() {\n   }\n }\n \n-Status DBImpl::Recover(VersionEdit* edit) {\n+Status DBImpl::Recover(VersionEdit* edit, bool *save_manifest) {\n   mutex_.AssertHeld();\n \n   // Ignore error from CreateDir since the creation of the DB is\n@@ -301,66 +300,69 @@ Status DBImpl::Recover(VersionEdit* edit) {\n     }\n   }\n \n-  s = versions_->Recover();\n-  if (s.ok()) {\n-    SequenceNumber max_sequence(0);\n-\n-    // Recover from all newer log files than the ones named in the\n-    // descriptor (new log files may have been added by the previous\n-    // incarnation without registering them in the descriptor).\n-    //\n-    // Note that PrevLogNumber() is no longer used, but we pay\n-    // attention to it in case we are recovering a database\n-    // produced by an older version of leveldb.\n-    const uint64_t min_log = versions_->LogNumber();\n-    const uint64_t prev_log = versions_->PrevLogNumber();\n-    std::vector<std::string> filenames;\n-    s = env_->GetChildren(dbname_, &filenames);\n+  s = versions_->Recover(save_manifest);\n+  if (!s.ok()) {\n+    return s;\n+  }\n+  SequenceNumber max_sequence(0);\n+\n+  // Recover from all newer log files than the ones named in the\n+  // descriptor (new log files may have been added by the previous\n+  // incarnation without registering them in the descriptor).\n+  //\n+  // Note that PrevLogNumber() is no longer used, but we pay\n+  // attention to it in case we are recovering a database\n+  // produced by an older version of leveldb.\n+  const uint64_t min_log = versions_->LogNumber();\n+  const uint64_t prev_log = versions_->PrevLogNumber();\n+  std::vector<std::string> filenames;\n+  s = env_->GetChildren(dbname_, &filenames);\n+  if (!s.ok()) {\n+    return s;\n+  }\n+  std::set<uint64_t> expected;\n+  versions_->AddLiveFiles(&expected);\n+  uint64_t number;\n+  FileType type;\n+  std::vector<uint64_t> logs;\n+  for (size_t i = 0; i < filenames.size(); i++) {\n+    if (ParseFileName(filenames[i], &number, &type)) {\n+      expected.erase(number);\n+      if (type == kLogFile && ((number >= min_log) || (number == prev_log)))\n+        logs.push_back(number);\n+    }\n+  }\n+  if (!expected.empty()) {\n+    char buf[50];\n+    snprintf(buf, sizeof(buf), \"%d missing files; e.g.\",\n+             static_cast<int>(expected.size()));\n+    return Status::Corruption(buf, TableFileName(dbname_, *(expected.begin())));\n+  }\n+\n+  // Recover in the order in which the logs were generated\n+  std::sort(logs.begin(), logs.end());\n+  for (size_t i = 0; i < logs.size(); i++) {\n+    s = RecoverLogFile(logs[i], (i == logs.size() - 1), save_manifest, edit,\n+                       &max_sequence);\n     if (!s.ok()) {\n       return s;\n     }\n-    std::set<uint64_t> expected;\n-    versions_->AddLiveFiles(&expected);\n-    uint64_t number;\n-    FileType type;\n-    std::vector<uint64_t> logs;\n-    for (size_t i = 0; i < filenames.size(); i++) {\n-      if (ParseFileName(filenames[i], &number, &type)) {\n-        expected.erase(number);\n-        if (type == kLogFile && ((number >= min_log) || (number == prev_log)))\n-          logs.push_back(number);\n-      }\n-    }\n-    if (!expected.empty()) {\n-      char buf[50];\n-      snprintf(buf, sizeof(buf), \"%d missing files; e.g.\",\n-               static_cast<int>(expected.size()));\n-      return Status::Corruption(buf, TableFileName(dbname_, *(expected.begin())));\n-    }\n-\n-    // Recover in the order in which the logs were generated\n-    std::sort(logs.begin(), logs.end());\n-    for (size_t i = 0; i < logs.size(); i++) {\n-      s = RecoverLogFile(logs[i], edit, &max_sequence);\n \n-      // The previous incarnation may not have written any MANIFEST\n-      // records after allocating this log number.  So we manually\n-      // update the file number allocation counter in VersionSet.\n-      versions_->MarkFileNumberUsed(logs[i]);\n-    }\n+    // The previous incarnation may not have written any MANIFEST\n+    // records after allocating this log number.  So we manually\n+    // update the file number allocation counter in VersionSet.\n+    versions_->MarkFileNumberUsed(logs[i]);\n+  }\n \n-    if (s.ok()) {\n-      if (versions_->LastSequence() < max_sequence) {\n-        versions_->SetLastSequence(max_sequence);\n-      }\n-    }\n+  if (versions_->LastSequence() < max_sequence) {\n+    versions_->SetLastSequence(max_sequence);\n   }\n \n-  return s;\n+  return Status::OK();\n }\n \n-Status DBImpl::RecoverLogFile(uint64_t log_number,\n-                              VersionEdit* edit,\n+Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log,\n+                              bool* save_manifest, VersionEdit* edit,\n                               SequenceNumber* max_sequence) {\n   struct LogReporter : public log::Reader::Reporter {\n     Env* env;\n@@ -405,6 +407,7 @@ Status DBImpl::RecoverLogFile(uint64_t log_number,\n   std::string scratch;\n   Slice record;\n   WriteBatch batch;\n+  int compactions = 0;\n   MemTable* mem = NULL;\n   while (reader.ReadRecord(&record, &scratch) &&\n          status.ok()) {\n@@ -432,25 +435,52 @@ Status DBImpl::RecoverLogFile(uint64_t log_number,\n     }\n \n     if (mem->ApproximateMemoryUsage() > options_.write_buffer_size) {\n+      compactions++;\n+      *save_manifest = true;\n       status = WriteLevel0Table(mem, edit, NULL);\n+      mem->Unref();\n+      mem = NULL;\n       if (!status.ok()) {\n         // Reflect errors immediately so that conditions like full\n         // file-systems cause the DB::Open() to fail.\n         break;\n       }\n-      mem->Unref();\n-      mem = NULL;\n     }\n   }\n \n-  if (status.ok() && mem != NULL) {\n-    status = WriteLevel0Table(mem, edit, NULL);\n-    // Reflect errors immediately so that conditions like full\n-    // file-systems cause the DB::Open() to fail.\n+  delete file;\n+\n+  // See if we should keep reusing the last log file.\n+  if (status.ok() && options_.reuse_logs && last_log && compactions == 0) {\n+    assert(logfile_ == NULL);\n+    assert(log_ == NULL);\n+    assert(mem_ == NULL);\n+    uint64_t lfile_size;\n+    if (env_->GetFileSize(fname, &lfile_size).ok() &&\n+        env_->NewAppendableFile(fname, &logfile_).ok()) {\n+      Log(options_.info_log, \"Reusing old log %s \\n\", fname.c_str());\n+      log_ = new log::Writer(logfile_, lfile_size);\n+      logfile_number_ = log_number;\n+      if (mem != NULL) {\n+        mem_ = mem;\n+        mem = NULL;\n+      } else {\n+        // mem can be NULL if lognum exists but was empty.\n+        mem_ = new MemTable(internal_comparator_);\n+        mem_->Ref();\n+      }\n+    }\n+  }\n+\n+  if (mem != NULL) {\n+    // mem did not get reused; compact it.\n+    if (status.ok()) {\n+      *save_manifest = true;\n+      status = WriteLevel0Table(mem, edit, NULL);\n+    }\n+    mem->Unref();\n   }\n \n-  if (mem != NULL) mem->Unref();\n-  delete file;\n   return status;\n }\n \n@@ -821,8 +851,9 @@ Status DBImpl::FinishCompactionOutputFile(CompactionState* compact,\n     delete iter;\n     if (s.ok()) {\n       Log(options_.info_log,\n-          \"Generated table #%llu: %lld keys, %lld bytes\",\n+          \"Generated table #%llu@%d: %lld keys, %lld bytes\",\n           (unsigned long long) output_number,\n+          compact->compaction->level(),\n           (unsigned long long) current_entries,\n           (unsigned long long) current_bytes);\n     }\n@@ -1395,6 +1426,19 @@ bool DBImpl::GetProperty(const Slice& property, std::string* value) {\n   } else if (in == \"sstables\") {\n     *value = versions_->current()->DebugString();\n     return true;\n+  } else if (in == \"approximate-memory-usage\") {\n+    size_t total_usage = options_.block_cache->TotalCharge();\n+    if (mem_) {\n+      total_usage += mem_->ApproximateMemoryUsage();\n+    }\n+    if (imm_) {\n+      total_usage += imm_->ApproximateMemoryUsage();\n+    }\n+    char buf[50];\n+    snprintf(buf, sizeof(buf), \"%llu\",\n+             static_cast<unsigned long long>(total_usage));\n+    value->append(buf);\n+    return true;\n   }\n \n   return false;\n@@ -1449,8 +1493,11 @@ Status DB::Open(const Options& options, const std::string& dbname,\n   DBImpl* impl = new DBImpl(options, dbname);\n   impl->mutex_.Lock();\n   VersionEdit edit;\n-  Status s = impl->Recover(&edit); // Handles create_if_missing, error_if_exists\n-  if (s.ok()) {\n+  // Recover handles create_if_missing, error_if_exists\n+  bool save_manifest = false;\n+  Status s = impl->Recover(&edit, &save_manifest);\n+  if (s.ok() && impl->mem_ == NULL) {\n+    // Create new log and a corresponding memtable.\n     uint64_t new_log_number = impl->versions_->NewFileNumber();\n     WritableFile* lfile;\n     s = options.env->NewWritableFile(LogFileName(dbname, new_log_number),\n@@ -1460,15 +1507,22 @@ Status DB::Open(const Options& options, const std::string& dbname,\n       impl->logfile_ = lfile;\n       impl->logfile_number_ = new_log_number;\n       impl->log_ = new log::Writer(lfile);\n-      s = impl->versions_->LogAndApply(&edit, &impl->mutex_);\n-    }\n-    if (s.ok()) {\n-      impl->DeleteObsoleteFiles();\n-      impl->MaybeScheduleCompaction();\n+      impl->mem_ = new MemTable(impl->internal_comparator_);\n+      impl->mem_->Ref();\n     }\n   }\n+  if (s.ok() && save_manifest) {\n+    edit.SetPrevLogNumber(0);  // No older logs needed after recovery.\n+    edit.SetLogNumber(impl->logfile_number_);\n+    s = impl->versions_->LogAndApply(&edit, &impl->mutex_);\n+  }\n+  if (s.ok()) {\n+    impl->DeleteObsoleteFiles();\n+    impl->MaybeScheduleCompaction();\n+  }\n   impl->mutex_.Unlock();\n   if (s.ok()) {\n+    assert(impl->mem_ != NULL);\n     *dbptr = impl;\n   } else {\n     delete impl;"
      },
      {
        "sha": "8ff323e72879967a9ff27876155a21ffb2330d3d",
        "filename": "db/db_impl.h",
        "status": "modified",
        "additions": 4,
        "deletions": 4,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/db_impl.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/db_impl.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/db_impl.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -78,7 +78,8 @@ class DBImpl : public DB {\n   // Recover the descriptor from persistent storage.  May do a significant\n   // amount of work to recover recently logged updates.  Any changes to\n   // be made to the descriptor are added to *edit.\n-  Status Recover(VersionEdit* edit) EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n+  Status Recover(VersionEdit* edit, bool* save_manifest)\n+      EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n   void MaybeIgnoreError(Status* s) const;\n \n@@ -90,9 +91,8 @@ class DBImpl : public DB {\n   // Errors are recorded in bg_error_.\n   void CompactMemTable() EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n-  Status RecoverLogFile(uint64_t log_number,\n-                        VersionEdit* edit,\n-                        SequenceNumber* max_sequence)\n+  Status RecoverLogFile(uint64_t log_number, bool last_log, bool* save_manifest,\n+                        VersionEdit* edit, SequenceNumber* max_sequence)\n       EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n   Status WriteLevel0Table(MemTable* mem, VersionEdit* edit, Version* base)"
      },
      {
        "sha": "a0b08bc19c6510322dc65a94e135fa17ee922659",
        "filename": "db/db_test.cc",
        "status": "modified",
        "additions": 31,
        "deletions": 1,
        "changes": 32,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/db_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/db_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/db_test.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -193,6 +193,7 @@ class DBTest {\n   // Sequence of option configurations to try\n   enum OptionConfig {\n     kDefault,\n+    kReuse,\n     kFilter,\n     kUncompressed,\n     kEnd\n@@ -237,7 +238,11 @@ class DBTest {\n   // Return the current option configuration.\n   Options CurrentOptions() {\n     Options options;\n+    options.reuse_logs = false;\n     switch (option_config_) {\n+      case kReuse:\n+        options.reuse_logs = true;\n+        break;\n       case kFilter:\n         options.filter_policy = filter_policy_;\n         break;\n@@ -558,6 +563,17 @@ TEST(DBTest, GetFromVersions) {\n   } while (ChangeOptions());\n }\n \n+TEST(DBTest, GetMemUsage) {\n+  do {\n+    ASSERT_OK(Put(\"foo\", \"v1\"));\n+    std::string val;\n+    ASSERT_TRUE(db_->GetProperty(\"leveldb.approximate-memory-usage\", &val));\n+    int mem_usage = atoi(val.c_str());\n+    ASSERT_GT(mem_usage, 0);\n+    ASSERT_LT(mem_usage, 5*1024*1024);\n+  } while (ChangeOptions());\n+}\n+\n TEST(DBTest, GetSnapshot) {\n   do {\n     // Try with both a short key and a long key\n@@ -1080,6 +1096,14 @@ TEST(DBTest, ApproximateSizes) {\n     // 0 because GetApproximateSizes() does not account for memtable space\n     ASSERT_TRUE(Between(Size(\"\", Key(50)), 0, 0));\n \n+    if (options.reuse_logs) {\n+      // Recovery will reuse memtable, and GetApproximateSizes() does not\n+      // account for memtable usage;\n+      Reopen(&options);\n+      ASSERT_TRUE(Between(Size(\"\", Key(50)), 0, 0));\n+      continue;\n+    }\n+\n     // Check sizes across recovery by reopening a few times\n     for (int run = 0; run < 3; run++) {\n       Reopen(&options);\n@@ -1123,6 +1147,11 @@ TEST(DBTest, ApproximateSizes_MixOfSmallAndLarge) {\n     ASSERT_OK(Put(Key(6), RandomString(&rnd, 300000)));\n     ASSERT_OK(Put(Key(7), RandomString(&rnd, 10000)));\n \n+    if (options.reuse_logs) {\n+      // Need to force a memtable compaction since recovery does not do so.\n+      ASSERT_OK(dbfull()->TEST_CompactMemTable());\n+    }\n+\n     // Check sizes across recovery by reopening a few times\n     for (int run = 0; run < 3; run++) {\n       Reopen(&options);\n@@ -2084,7 +2113,8 @@ void BM_LogAndApply(int iters, int num_base_files) {\n   InternalKeyComparator cmp(BytewiseComparator());\n   Options options;\n   VersionSet vset(dbname, &options, NULL, &cmp);\n-  ASSERT_OK(vset.Recover());\n+  bool save_manifest;\n+  ASSERT_OK(vset.Recover(&save_manifest));\n   VersionEdit vbase;\n   uint64_t fnum = 1;\n   for (int i = 0; i < num_base_files; i++) {"
      },
      {
        "sha": "875dfe81eeab39656a57deade1589895a6d87cd7",
        "filename": "db/fault_injection_test.cc",
        "status": "added",
        "additions": 554,
        "deletions": 0,
        "changes": 554,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/fault_injection_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/fault_injection_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/fault_injection_test.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -0,0 +1,554 @@\n+// Copyright 2014 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+// This test uses a custom Env to keep track of the state of a filesystem as of\n+// the last \"sync\". It then checks for data loss errors by purposely dropping\n+// file data (or entire files) not protected by a \"sync\".\n+\n+#include \"leveldb/db.h\"\n+\n+#include <map>\n+#include <set>\n+#include \"db/db_impl.h\"\n+#include \"db/filename.h\"\n+#include \"db/log_format.h\"\n+#include \"db/version_set.h\"\n+#include \"leveldb/cache.h\"\n+#include \"leveldb/env.h\"\n+#include \"leveldb/table.h\"\n+#include \"leveldb/write_batch.h\"\n+#include \"util/logging.h\"\n+#include \"util/mutexlock.h\"\n+#include \"util/testharness.h\"\n+#include \"util/testutil.h\"\n+\n+namespace leveldb {\n+\n+static const int kValueSize = 1000;\n+static const int kMaxNumValues = 2000;\n+static const size_t kNumIterations = 3;\n+\n+class FaultInjectionTestEnv;\n+\n+namespace {\n+\n+// Assume a filename, and not a directory name like \"/foo/bar/\"\n+static std::string GetDirName(const std::string filename) {\n+  size_t found = filename.find_last_of(\"/\\\\\");\n+  if (found == std::string::npos) {\n+    return \"\";\n+  } else {\n+    return filename.substr(0, found);\n+  }\n+}\n+\n+Status SyncDir(const std::string& dir) {\n+  // As this is a test it isn't required to *actually* sync this directory.\n+  return Status::OK();\n+}\n+\n+// A basic file truncation function suitable for this test.\n+Status Truncate(const std::string& filename, uint64_t length) {\n+  leveldb::Env* env = leveldb::Env::Default();\n+\n+  SequentialFile* orig_file;\n+  Status s = env->NewSequentialFile(filename, &orig_file);\n+  if (!s.ok())\n+    return s;\n+\n+  char* scratch = new char[length];\n+  leveldb::Slice result;\n+  s = orig_file->Read(length, &result, scratch);\n+  delete orig_file;\n+  if (s.ok()) {\n+    std::string tmp_name = GetDirName(filename) + \"/truncate.tmp\";\n+    WritableFile* tmp_file;\n+    s = env->NewWritableFile(tmp_name, &tmp_file);\n+    if (s.ok()) {\n+      s = tmp_file->Append(result);\n+      delete tmp_file;\n+      if (s.ok()) {\n+        s = env->RenameFile(tmp_name, filename);\n+      } else {\n+        env->DeleteFile(tmp_name);\n+      }\n+    }\n+  }\n+\n+  delete[] scratch;\n+\n+  return s;\n+}\n+\n+struct FileState {\n+  std::string filename_;\n+  ssize_t pos_;\n+  ssize_t pos_at_last_sync_;\n+  ssize_t pos_at_last_flush_;\n+\n+  FileState(const std::string& filename)\n+      : filename_(filename),\n+        pos_(-1),\n+        pos_at_last_sync_(-1),\n+        pos_at_last_flush_(-1) { }\n+\n+  FileState() : pos_(-1), pos_at_last_sync_(-1), pos_at_last_flush_(-1) {}\n+\n+  bool IsFullySynced() const { return pos_ <= 0 || pos_ == pos_at_last_sync_; }\n+\n+  Status DropUnsyncedData() const;\n+};\n+\n+}  // anonymous namespace\n+\n+// A wrapper around WritableFile which informs another Env whenever this file\n+// is written to or sync'ed.\n+class TestWritableFile : public WritableFile {\n+ public:\n+  TestWritableFile(const FileState& state,\n+                   WritableFile* f,\n+                   FaultInjectionTestEnv* env);\n+  virtual ~TestWritableFile();\n+  virtual Status Append(const Slice& data);\n+  virtual Status Close();\n+  virtual Status Flush();\n+  virtual Status Sync();\n+\n+ private:\n+  FileState state_;\n+  WritableFile* target_;\n+  bool writable_file_opened_;\n+  FaultInjectionTestEnv* env_;\n+\n+  Status SyncParent();\n+};\n+\n+class FaultInjectionTestEnv : public EnvWrapper {\n+ public:\n+  FaultInjectionTestEnv() : EnvWrapper(Env::Default()), filesystem_active_(true) {}\n+  virtual ~FaultInjectionTestEnv() { }\n+  virtual Status NewWritableFile(const std::string& fname,\n+                                 WritableFile** result);\n+  virtual Status NewAppendableFile(const std::string& fname,\n+                                   WritableFile** result);\n+  virtual Status DeleteFile(const std::string& f);\n+  virtual Status RenameFile(const std::string& s, const std::string& t);\n+\n+  void WritableFileClosed(const FileState& state);\n+  Status DropUnsyncedFileData();\n+  Status DeleteFilesCreatedAfterLastDirSync();\n+  void DirWasSynced();\n+  bool IsFileCreatedSinceLastDirSync(const std::string& filename);\n+  void ResetState();\n+  void UntrackFile(const std::string& f);\n+  // Setting the filesystem to inactive is the test equivalent to simulating a\n+  // system reset. Setting to inactive will freeze our saved filesystem state so\n+  // that it will stop being recorded. It can then be reset back to the state at\n+  // the time of the reset.\n+  bool IsFilesystemActive() const { return filesystem_active_; }\n+  void SetFilesystemActive(bool active) { filesystem_active_ = active; }\n+\n+ private:\n+  port::Mutex mutex_;\n+  std::map<std::string, FileState> db_file_state_;\n+  std::set<std::string> new_files_since_last_dir_sync_;\n+  bool filesystem_active_;  // Record flushes, syncs, writes\n+};\n+\n+TestWritableFile::TestWritableFile(const FileState& state,\n+                                   WritableFile* f,\n+                                   FaultInjectionTestEnv* env)\n+    : state_(state),\n+      target_(f),\n+      writable_file_opened_(true),\n+      env_(env) {\n+  assert(f != NULL);\n+}\n+\n+TestWritableFile::~TestWritableFile() {\n+  if (writable_file_opened_) {\n+    Close();\n+  }\n+  delete target_;\n+}\n+\n+Status TestWritableFile::Append(const Slice& data) {\n+  Status s = target_->Append(data);\n+  if (s.ok() && env_->IsFilesystemActive()) {\n+    state_.pos_ += data.size();\n+  }\n+  return s;\n+}\n+\n+Status TestWritableFile::Close() {\n+  writable_file_opened_ = false;\n+  Status s = target_->Close();\n+  if (s.ok()) {\n+    env_->WritableFileClosed(state_);\n+  }\n+  return s;\n+}\n+\n+Status TestWritableFile::Flush() {\n+  Status s = target_->Flush();\n+  if (s.ok() && env_->IsFilesystemActive()) {\n+    state_.pos_at_last_flush_ = state_.pos_;\n+  }\n+  return s;\n+}\n+\n+Status TestWritableFile::SyncParent() {\n+  Status s = SyncDir(GetDirName(state_.filename_));\n+  if (s.ok()) {\n+    env_->DirWasSynced();\n+  }\n+  return s;\n+}\n+\n+Status TestWritableFile::Sync() {\n+  if (!env_->IsFilesystemActive()) {\n+    return Status::OK();\n+  }\n+  // Ensure new files referred to by the manifest are in the filesystem.\n+  Status s = target_->Sync();\n+  if (s.ok()) {\n+    state_.pos_at_last_sync_ = state_.pos_;\n+  }\n+  if (env_->IsFileCreatedSinceLastDirSync(state_.filename_)) {\n+    Status ps = SyncParent();\n+    if (s.ok() && !ps.ok()) {\n+      s = ps;\n+    }\n+  }\n+  return s;\n+}\n+\n+Status FaultInjectionTestEnv::NewWritableFile(const std::string& fname,\n+                                              WritableFile** result) {\n+  WritableFile* actual_writable_file;\n+  Status s = target()->NewWritableFile(fname, &actual_writable_file);\n+  if (s.ok()) {\n+    FileState state(fname);\n+    state.pos_ = 0;\n+    *result = new TestWritableFile(state, actual_writable_file, this);\n+    // NewWritableFile doesn't append to files, so if the same file is\n+    // opened again then it will be truncated - so forget our saved\n+    // state.\n+    UntrackFile(fname);\n+    MutexLock l(&mutex_);\n+    new_files_since_last_dir_sync_.insert(fname);\n+  }\n+  return s;\n+}\n+\n+Status FaultInjectionTestEnv::NewAppendableFile(const std::string& fname,\n+                                                WritableFile** result) {\n+  WritableFile* actual_writable_file;\n+  Status s = target()->NewAppendableFile(fname, &actual_writable_file);\n+  if (s.ok()) {\n+    FileState state(fname);\n+    state.pos_ = 0;\n+    {\n+      MutexLock l(&mutex_);\n+      if (db_file_state_.count(fname) == 0) {\n+        new_files_since_last_dir_sync_.insert(fname);\n+      } else {\n+        state = db_file_state_[fname];\n+      }\n+    }\n+    *result = new TestWritableFile(state, actual_writable_file, this);\n+  }\n+  return s;\n+}\n+\n+Status FaultInjectionTestEnv::DropUnsyncedFileData() {\n+  Status s;\n+  MutexLock l(&mutex_);\n+  for (std::map<std::string, FileState>::const_iterator it =\n+           db_file_state_.begin();\n+       s.ok() && it != db_file_state_.end(); ++it) {\n+    const FileState& state = it->second;\n+    if (!state.IsFullySynced()) {\n+      s = state.DropUnsyncedData();\n+    }\n+  }\n+  return s;\n+}\n+\n+void FaultInjectionTestEnv::DirWasSynced() {\n+  MutexLock l(&mutex_);\n+  new_files_since_last_dir_sync_.clear();\n+}\n+\n+bool FaultInjectionTestEnv::IsFileCreatedSinceLastDirSync(\n+    const std::string& filename) {\n+  MutexLock l(&mutex_);\n+  return new_files_since_last_dir_sync_.find(filename) !=\n+         new_files_since_last_dir_sync_.end();\n+}\n+\n+void FaultInjectionTestEnv::UntrackFile(const std::string& f) {\n+  MutexLock l(&mutex_);\n+  db_file_state_.erase(f);\n+  new_files_since_last_dir_sync_.erase(f);\n+}\n+\n+Status FaultInjectionTestEnv::DeleteFile(const std::string& f) {\n+  Status s = EnvWrapper::DeleteFile(f);\n+  ASSERT_OK(s);\n+  if (s.ok()) {\n+    UntrackFile(f);\n+  }\n+  return s;\n+}\n+\n+Status FaultInjectionTestEnv::RenameFile(const std::string& s,\n+                                         const std::string& t) {\n+  Status ret = EnvWrapper::RenameFile(s, t);\n+\n+  if (ret.ok()) {\n+    MutexLock l(&mutex_);\n+    if (db_file_state_.find(s) != db_file_state_.end()) {\n+      db_file_state_[t] = db_file_state_[s];\n+      db_file_state_.erase(s);\n+    }\n+\n+    if (new_files_since_last_dir_sync_.erase(s) != 0) {\n+      assert(new_files_since_last_dir_sync_.find(t) ==\n+             new_files_since_last_dir_sync_.end());\n+      new_files_since_last_dir_sync_.insert(t);\n+    }\n+  }\n+\n+  return ret;\n+}\n+\n+void FaultInjectionTestEnv::ResetState() {\n+  // Since we are not destroying the database, the existing files\n+  // should keep their recorded synced/flushed state. Therefore\n+  // we do not reset db_file_state_ and new_files_since_last_dir_sync_.\n+  MutexLock l(&mutex_);\n+  SetFilesystemActive(true);\n+}\n+\n+Status FaultInjectionTestEnv::DeleteFilesCreatedAfterLastDirSync() {\n+  // Because DeleteFile access this container make a copy to avoid deadlock\n+  mutex_.Lock();\n+  std::set<std::string> new_files(new_files_since_last_dir_sync_.begin(),\n+                                  new_files_since_last_dir_sync_.end());\n+  mutex_.Unlock();\n+  Status s;\n+  std::set<std::string>::const_iterator it;\n+  for (it = new_files.begin(); s.ok() && it != new_files.end(); ++it) {\n+    s = DeleteFile(*it);\n+  }\n+  return s;\n+}\n+\n+void FaultInjectionTestEnv::WritableFileClosed(const FileState& state) {\n+  MutexLock l(&mutex_);\n+  db_file_state_[state.filename_] = state;\n+}\n+\n+Status FileState::DropUnsyncedData() const {\n+  ssize_t sync_pos = pos_at_last_sync_ == -1 ? 0 : pos_at_last_sync_;\n+  return Truncate(filename_, sync_pos);\n+}\n+\n+class FaultInjectionTest {\n+ public:\n+  enum ExpectedVerifResult { VAL_EXPECT_NO_ERROR, VAL_EXPECT_ERROR };\n+  enum ResetMethod { RESET_DROP_UNSYNCED_DATA, RESET_DELETE_UNSYNCED_FILES };\n+\n+  FaultInjectionTestEnv* env_;\n+  std::string dbname_;\n+  Cache* tiny_cache_;\n+  Options options_;\n+  DB* db_;\n+\n+  FaultInjectionTest()\n+      : env_(new FaultInjectionTestEnv),\n+        tiny_cache_(NewLRUCache(100)),\n+        db_(NULL) {\n+    dbname_ = test::TmpDir() + \"/fault_test\";\n+    DestroyDB(dbname_, Options());  // Destroy any db from earlier run\n+    options_.reuse_logs = true;\n+    options_.env = env_;\n+    options_.paranoid_checks = true;\n+    options_.block_cache = tiny_cache_;\n+    options_.create_if_missing = true;\n+  }\n+\n+  ~FaultInjectionTest() {\n+    CloseDB();\n+    DestroyDB(dbname_, Options());\n+    delete tiny_cache_;\n+    delete env_;\n+  }\n+\n+  void ReuseLogs(bool reuse) {\n+    options_.reuse_logs = reuse;\n+  }\n+\n+  void Build(int start_idx, int num_vals) {\n+    std::string key_space, value_space;\n+    WriteBatch batch;\n+    for (int i = start_idx; i < start_idx + num_vals; i++) {\n+      Slice key = Key(i, &key_space);\n+      batch.Clear();\n+      batch.Put(key, Value(i, &value_space));\n+      WriteOptions options;\n+      ASSERT_OK(db_->Write(options, &batch));\n+    }\n+  }\n+\n+  Status ReadValue(int i, std::string* val) const {\n+    std::string key_space, value_space;\n+    Slice key = Key(i, &key_space);\n+    Value(i, &value_space);\n+    ReadOptions options;\n+    return db_->Get(options, key, val);\n+  }\n+\n+  Status Verify(int start_idx, int num_vals,\n+                ExpectedVerifResult expected) const {\n+    std::string val;\n+    std::string value_space;\n+    Status s;\n+    for (int i = start_idx; i < start_idx + num_vals && s.ok(); i++) {\n+      Value(i, &value_space);\n+      s = ReadValue(i, &val);\n+      if (expected == VAL_EXPECT_NO_ERROR) {\n+        if (s.ok()) {\n+          ASSERT_EQ(value_space, val);\n+        }\n+      } else if (s.ok()) {\n+        fprintf(stderr, \"Expected an error at %d, but was OK\\n\", i);\n+        s = Status::IOError(dbname_, \"Expected value error:\");\n+      } else {\n+        s = Status::OK();  // An expected error\n+      }\n+    }\n+    return s;\n+  }\n+\n+  // Return the ith key\n+  Slice Key(int i, std::string* storage) const {\n+    char buf[100];\n+    snprintf(buf, sizeof(buf), \"%016d\", i);\n+    storage->assign(buf, strlen(buf));\n+    return Slice(*storage);\n+  }\n+\n+  // Return the value to associate with the specified key\n+  Slice Value(int k, std::string* storage) const {\n+    Random r(k);\n+    return test::RandomString(&r, kValueSize, storage);\n+  }\n+\n+  Status OpenDB() {\n+    delete db_;\n+    db_ = NULL;\n+    env_->ResetState();\n+    return DB::Open(options_, dbname_, &db_);\n+  }\n+\n+  void CloseDB() {\n+    delete db_;\n+    db_ = NULL;\n+  }\n+\n+  void DeleteAllData() {\n+    Iterator* iter = db_->NewIterator(ReadOptions());\n+    WriteOptions options;\n+    for (iter->SeekToFirst(); iter->Valid(); iter->Next()) {\n+      ASSERT_OK(db_->Delete(WriteOptions(), iter->key()));\n+    }\n+\n+    delete iter;\n+  }\n+\n+  void ResetDBState(ResetMethod reset_method) {\n+    switch (reset_method) {\n+      case RESET_DROP_UNSYNCED_DATA:\n+        ASSERT_OK(env_->DropUnsyncedFileData());\n+        break;\n+      case RESET_DELETE_UNSYNCED_FILES:\n+        ASSERT_OK(env_->DeleteFilesCreatedAfterLastDirSync());\n+        break;\n+      default:\n+        assert(false);\n+    }\n+  }\n+\n+  void PartialCompactTestPreFault(int num_pre_sync, int num_post_sync) {\n+    DeleteAllData();\n+    Build(0, num_pre_sync);\n+    db_->CompactRange(NULL, NULL);\n+    Build(num_pre_sync, num_post_sync);\n+  }\n+\n+  void PartialCompactTestReopenWithFault(ResetMethod reset_method,\n+                                         int num_pre_sync,\n+                                         int num_post_sync) {\n+    env_->SetFilesystemActive(false);\n+    CloseDB();\n+    ResetDBState(reset_method);\n+    ASSERT_OK(OpenDB());\n+    ASSERT_OK(Verify(0, num_pre_sync, FaultInjectionTest::VAL_EXPECT_NO_ERROR));\n+    ASSERT_OK(Verify(num_pre_sync, num_post_sync, FaultInjectionTest::VAL_EXPECT_ERROR));\n+  }\n+\n+  void NoWriteTestPreFault() {\n+  }\n+\n+  void NoWriteTestReopenWithFault(ResetMethod reset_method) {\n+    CloseDB();\n+    ResetDBState(reset_method);\n+    ASSERT_OK(OpenDB());\n+  }\n+\n+  void DoTest() {\n+    Random rnd(0);\n+    ASSERT_OK(OpenDB());\n+    for (size_t idx = 0; idx < kNumIterations; idx++) {\n+      int num_pre_sync = rnd.Uniform(kMaxNumValues);\n+      int num_post_sync = rnd.Uniform(kMaxNumValues);\n+\n+      PartialCompactTestPreFault(num_pre_sync, num_post_sync);\n+      PartialCompactTestReopenWithFault(RESET_DROP_UNSYNCED_DATA,\n+                                        num_pre_sync,\n+                                        num_post_sync);\n+\n+      NoWriteTestPreFault();\n+      NoWriteTestReopenWithFault(RESET_DROP_UNSYNCED_DATA);\n+\n+      PartialCompactTestPreFault(num_pre_sync, num_post_sync);\n+      // No new files created so we expect all values since no files will be\n+      // dropped.\n+      PartialCompactTestReopenWithFault(RESET_DELETE_UNSYNCED_FILES,\n+                                        num_pre_sync + num_post_sync,\n+                                        0);\n+\n+      NoWriteTestPreFault();\n+      NoWriteTestReopenWithFault(RESET_DELETE_UNSYNCED_FILES);\n+    }\n+  }\n+};\n+\n+TEST(FaultInjectionTest, FaultTestNoLogReuse) {\n+  ReuseLogs(false);\n+  DoTest();\n+}\n+\n+TEST(FaultInjectionTest, FaultTestWithLogReuse) {\n+  ReuseLogs(true);\n+  DoTest();\n+}\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) {\n+  return leveldb::test::RunAllTests();\n+}"
      },
      {
        "sha": "9f4b7dd70c245302e9841e6a407e89659992284f",
        "filename": "db/leveldbutil.cc",
        "status": "renamed",
        "additions": 0,
        "deletions": 0,
        "changes": 0,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/leveldbutil.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/leveldbutil.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/leveldbutil.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "previous_filename": "db/leveldb_main.cc"
      },
      {
        "sha": "a6d304545d828e0f6dfb792e8f545888a2a8a9c0",
        "filename": "db/log_reader.cc",
        "status": "modified",
        "additions": 20,
        "deletions": 2,
        "changes": 22,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/log_reader.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/log_reader.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/log_reader.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -25,7 +25,8 @@ Reader::Reader(SequentialFile* file, Reporter* reporter, bool checksum,\n       eof_(false),\n       last_record_offset_(0),\n       end_of_buffer_offset_(0),\n-      initial_offset_(initial_offset) {\n+      initial_offset_(initial_offset),\n+      resyncing_(initial_offset > 0) {\n }\n \n Reader::~Reader() {\n@@ -72,8 +73,25 @@ bool Reader::ReadRecord(Slice* record, std::string* scratch) {\n \n   Slice fragment;\n   while (true) {\n-    uint64_t physical_record_offset = end_of_buffer_offset_ - buffer_.size();\n     const unsigned int record_type = ReadPhysicalRecord(&fragment);\n+\n+    // ReadPhysicalRecord may have only had an empty trailer remaining in its\n+    // internal buffer. Calculate the offset of the next physical record now\n+    // that it has returned, properly accounting for its header size.\n+    uint64_t physical_record_offset =\n+        end_of_buffer_offset_ - buffer_.size() - kHeaderSize - fragment.size();\n+\n+    if (resyncing_) {\n+      if (record_type == kMiddleType) {\n+        continue;\n+      } else if (record_type == kLastType) {\n+        resyncing_ = false;\n+        continue;\n+      } else {\n+        resyncing_ = false;\n+      }\n+    }\n+\n     switch (record_type) {\n       case kFullType:\n         if (in_fragmented_record) {"
      },
      {
        "sha": "8389d61f8f1dde45435840d972ec99ba6d793c15",
        "filename": "db/log_reader.h",
        "status": "modified",
        "additions": 5,
        "deletions": 0,
        "changes": 5,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/log_reader.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/log_reader.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/log_reader.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -73,6 +73,11 @@ class Reader {\n   // Offset at which to start looking for the first record to return\n   uint64_t const initial_offset_;\n \n+  // True if we are resynchronizing after a seek (initial_offset_ > 0). In\n+  // particular, a run of kMiddleType and kLastType records can be silently\n+  // skipped in this mode\n+  bool resyncing_;\n+\n   // Extend record types with the following special values\n   enum {\n     kEof = kMaxRecordType + 1,"
      },
      {
        "sha": "48a5928657e0f57fa2cc5c9477d3a755d216f149",
        "filename": "db/log_test.cc",
        "status": "modified",
        "additions": 81,
        "deletions": 20,
        "changes": 101,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/log_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/log_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/log_test.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -79,7 +79,7 @@ class LogTest {\n     virtual Status Skip(uint64_t n) {\n       if (n > contents_.size()) {\n         contents_.clear();\n-        return Status::NotFound(\"in-memory file skipepd past end\");\n+        return Status::NotFound(\"in-memory file skipped past end\");\n       }\n \n       contents_.remove_prefix(n);\n@@ -104,23 +104,34 @@ class LogTest {\n   StringSource source_;\n   ReportCollector report_;\n   bool reading_;\n-  Writer writer_;\n-  Reader reader_;\n+  Writer* writer_;\n+  Reader* reader_;\n \n   // Record metadata for testing initial offset functionality\n   static size_t initial_offset_record_sizes_[];\n   static uint64_t initial_offset_last_record_offsets_[];\n+  static int num_initial_offset_records_;\n \n  public:\n   LogTest() : reading_(false),\n-              writer_(&dest_),\n-              reader_(&source_, &report_, true/*checksum*/,\n-                      0/*initial_offset*/) {\n+              writer_(new Writer(&dest_)),\n+              reader_(new Reader(&source_, &report_, true/*checksum*/,\n+                      0/*initial_offset*/)) {\n+  }\n+\n+  ~LogTest() {\n+    delete writer_;\n+    delete reader_;\n+  }\n+\n+  void ReopenForAppend() {\n+    delete writer_;\n+    writer_ = new Writer(&dest_, dest_.contents_.size());\n   }\n \n   void Write(const std::string& msg) {\n     ASSERT_TRUE(!reading_) << \"Write() after starting to read\";\n-    writer_.AddRecord(Slice(msg));\n+    writer_->AddRecord(Slice(msg));\n   }\n \n   size_t WrittenBytes() const {\n@@ -134,7 +145,7 @@ class LogTest {\n     }\n     std::string scratch;\n     Slice record;\n-    if (reader_.ReadRecord(&record, &scratch)) {\n+    if (reader_->ReadRecord(&record, &scratch)) {\n       return record.ToString();\n     } else {\n       return \"EOF\";\n@@ -182,13 +193,18 @@ class LogTest {\n   }\n \n   void WriteInitialOffsetLog() {\n-    for (int i = 0; i < 4; i++) {\n+    for (int i = 0; i < num_initial_offset_records_; i++) {\n       std::string record(initial_offset_record_sizes_[i],\n                          static_cast<char>('a' + i));\n       Write(record);\n     }\n   }\n \n+  void StartReadingAt(uint64_t initial_offset) {\n+    delete reader_;\n+    reader_ = new Reader(&source_, &report_, true/*checksum*/, initial_offset);\n+  }\n+\n   void CheckOffsetPastEndReturnsNoRecords(uint64_t offset_past_end) {\n     WriteInitialOffsetLog();\n     reading_ = true;\n@@ -208,32 +224,48 @@ class LogTest {\n     source_.contents_ = Slice(dest_.contents_);\n     Reader* offset_reader = new Reader(&source_, &report_, true/*checksum*/,\n                                        initial_offset);\n-    Slice record;\n-    std::string scratch;\n-    ASSERT_TRUE(offset_reader->ReadRecord(&record, &scratch));\n-    ASSERT_EQ(initial_offset_record_sizes_[expected_record_offset],\n-              record.size());\n-    ASSERT_EQ(initial_offset_last_record_offsets_[expected_record_offset],\n-              offset_reader->LastRecordOffset());\n-    ASSERT_EQ((char)('a' + expected_record_offset), record.data()[0]);\n+\n+    // Read all records from expected_record_offset through the last one.\n+    ASSERT_LT(expected_record_offset, num_initial_offset_records_);\n+    for (; expected_record_offset < num_initial_offset_records_;\n+         ++expected_record_offset) {\n+      Slice record;\n+      std::string scratch;\n+      ASSERT_TRUE(offset_reader->ReadRecord(&record, &scratch));\n+      ASSERT_EQ(initial_offset_record_sizes_[expected_record_offset],\n+                record.size());\n+      ASSERT_EQ(initial_offset_last_record_offsets_[expected_record_offset],\n+                offset_reader->LastRecordOffset());\n+      ASSERT_EQ((char)('a' + expected_record_offset), record.data()[0]);\n+    }\n     delete offset_reader;\n   }\n-\n };\n \n size_t LogTest::initial_offset_record_sizes_[] =\n     {10000,  // Two sizable records in first block\n      10000,\n      2 * log::kBlockSize - 1000,  // Span three blocks\n-     1};\n+     1,\n+     13716,  // Consume all but two bytes of block 3.\n+     log::kBlockSize - kHeaderSize, // Consume the entirety of block 4.\n+    };\n \n uint64_t LogTest::initial_offset_last_record_offsets_[] =\n     {0,\n      kHeaderSize + 10000,\n      2 * (kHeaderSize + 10000),\n      2 * (kHeaderSize + 10000) +\n-         (2 * log::kBlockSize - 1000) + 3 * kHeaderSize};\n+         (2 * log::kBlockSize - 1000) + 3 * kHeaderSize,\n+     2 * (kHeaderSize + 10000) +\n+         (2 * log::kBlockSize - 1000) + 3 * kHeaderSize\n+         + kHeaderSize + 1,\n+     3 * log::kBlockSize,\n+    };\n \n+// LogTest::initial_offset_last_record_offsets_ must be defined before this.\n+int LogTest::num_initial_offset_records_ =\n+    sizeof(LogTest::initial_offset_last_record_offsets_)/sizeof(uint64_t);\n \n TEST(LogTest, Empty) {\n   ASSERT_EQ(\"EOF\", Read());\n@@ -318,6 +350,15 @@ TEST(LogTest, AlignedEof) {\n   ASSERT_EQ(\"EOF\", Read());\n }\n \n+TEST(LogTest, OpenForAppend) {\n+  Write(\"hello\");\n+  ReopenForAppend();\n+  Write(\"world\");\n+  ASSERT_EQ(\"hello\", Read());\n+  ASSERT_EQ(\"world\", Read());\n+  ASSERT_EQ(\"EOF\", Read());\n+}\n+\n TEST(LogTest, RandomRead) {\n   const int N = 500;\n   Random write_rnd(301);\n@@ -445,6 +486,22 @@ TEST(LogTest, PartialLastIsIgnored) {\n   ASSERT_EQ(0, DroppedBytes());\n }\n \n+TEST(LogTest, SkipIntoMultiRecord) {\n+  // Consider a fragmented record:\n+  //    first(R1), middle(R1), last(R1), first(R2)\n+  // If initial_offset points to a record after first(R1) but before first(R2)\n+  // incomplete fragment errors are not actual errors, and must be suppressed\n+  // until a new first or full record is encountered.\n+  Write(BigString(\"foo\", 3*kBlockSize));\n+  Write(\"correct\");\n+  StartReadingAt(kBlockSize);\n+\n+  ASSERT_EQ(\"correct\", Read());\n+  ASSERT_EQ(\"\", ReportMessage());\n+  ASSERT_EQ(0, DroppedBytes());\n+  ASSERT_EQ(\"EOF\", Read());\n+}\n+\n TEST(LogTest, ErrorJoinsRecords) {\n   // Consider two fragmented records:\n   //    first(R1) last(R1) first(R2) last(R2)\n@@ -514,6 +571,10 @@ TEST(LogTest, ReadFourthStart) {\n       3);\n }\n \n+TEST(LogTest, ReadInitialOffsetIntoBlockPadding) {\n+  CheckInitialOffsetRecord(3 * log::kBlockSize - 3, 5);\n+}\n+\n TEST(LogTest, ReadEnd) {\n   CheckOffsetPastEndReturnsNoRecords(0);\n }"
      },
      {
        "sha": "74a03270da8500188175a38c3a3fdab2e7b27b8e",
        "filename": "db/log_writer.cc",
        "status": "modified",
        "additions": 13,
        "deletions": 4,
        "changes": 17,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/log_writer.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/log_writer.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/log_writer.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -12,15 +12,24 @@\n namespace leveldb {\n namespace log {\n \n-Writer::Writer(WritableFile* dest)\n-    : dest_(dest),\n-      block_offset_(0) {\n+static void InitTypeCrc(uint32_t* type_crc) {\n   for (int i = 0; i <= kMaxRecordType; i++) {\n     char t = static_cast<char>(i);\n-    type_crc_[i] = crc32c::Value(&t, 1);\n+    type_crc[i] = crc32c::Value(&t, 1);\n   }\n }\n \n+Writer::Writer(WritableFile* dest)\n+    : dest_(dest),\n+      block_offset_(0) {\n+  InitTypeCrc(type_crc_);\n+}\n+\n+Writer::Writer(WritableFile* dest, uint64_t dest_length)\n+    : dest_(dest), block_offset_(dest_length % kBlockSize) {\n+  InitTypeCrc(type_crc_);\n+}\n+\n Writer::~Writer() {\n }\n "
      },
      {
        "sha": "9e7cc4705b0146b316dbe4e9e0b05f1146c4389b",
        "filename": "db/log_writer.h",
        "status": "modified",
        "additions": 6,
        "deletions": 0,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/log_writer.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/log_writer.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/log_writer.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -22,6 +22,12 @@ class Writer {\n   // \"*dest\" must be initially empty.\n   // \"*dest\" must remain live while this Writer is in use.\n   explicit Writer(WritableFile* dest);\n+\n+  // Create a writer that will append data to \"*dest\".\n+  // \"*dest\" must have initial length \"dest_length\".\n+  // \"*dest\" must remain live while this Writer is in use.\n+  Writer(WritableFile* dest, uint64_t dest_length);\n+\n   ~Writer();\n \n   Status AddRecord(const Slice& slice);"
      },
      {
        "sha": "9f41567cde23dfd645b19d290c6e4a4256804900",
        "filename": "db/memtable.h",
        "status": "modified",
        "additions": 1,
        "deletions": 4,
        "changes": 5,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/memtable.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/memtable.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/memtable.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -36,10 +36,7 @@ class MemTable {\n   }\n \n   // Returns an estimate of the number of bytes of data in use by this\n-  // data structure.\n-  //\n-  // REQUIRES: external synchronization to prevent simultaneous\n-  // operations on the same MemTable.\n+  // data structure. It is safe to call when MemTable is being modified.\n   size_t ApproximateMemoryUsage();\n \n   // Return an iterator that yields the contents of the memtable."
      },
      {
        "sha": "9596f4288a84e558835421f8e68c57189a1da765",
        "filename": "db/recovery_test.cc",
        "status": "added",
        "additions": 324,
        "deletions": 0,
        "changes": 324,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/recovery_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/recovery_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/recovery_test.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -0,0 +1,324 @@\n+// Copyright (c) 2014 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"db/db_impl.h\"\n+#include \"db/filename.h\"\n+#include \"db/version_set.h\"\n+#include \"db/write_batch_internal.h\"\n+#include \"leveldb/db.h\"\n+#include \"leveldb/env.h\"\n+#include \"leveldb/write_batch.h\"\n+#include \"util/logging.h\"\n+#include \"util/testharness.h\"\n+#include \"util/testutil.h\"\n+\n+namespace leveldb {\n+\n+class RecoveryTest {\n+ public:\n+  RecoveryTest() : env_(Env::Default()), db_(NULL) {\n+    dbname_ = test::TmpDir() + \"/recovery_test\";\n+    DestroyDB(dbname_, Options());\n+    Open();\n+  }\n+\n+  ~RecoveryTest() {\n+    Close();\n+    DestroyDB(dbname_, Options());\n+  }\n+\n+  DBImpl* dbfull() const { return reinterpret_cast<DBImpl*>(db_); }\n+  Env* env() const { return env_; }\n+\n+  bool CanAppend() {\n+    WritableFile* tmp;\n+    Status s = env_->NewAppendableFile(CurrentFileName(dbname_), &tmp);\n+    delete tmp;\n+    if (s.IsNotSupportedError()) {\n+      return false;\n+    } else {\n+      return true;\n+    }\n+  }\n+\n+  void Close() {\n+    delete db_;\n+    db_ = NULL;\n+  }\n+\n+  void Open(Options* options = NULL) {\n+    Close();\n+    Options opts;\n+    if (options != NULL) {\n+      opts = *options;\n+    } else {\n+      opts.reuse_logs = true;  // TODO(sanjay): test both ways\n+      opts.create_if_missing = true;\n+    }\n+    if (opts.env == NULL) {\n+      opts.env = env_;\n+    }\n+    ASSERT_OK(DB::Open(opts, dbname_, &db_));\n+    ASSERT_EQ(1, NumLogs());\n+  }\n+\n+  Status Put(const std::string& k, const std::string& v) {\n+    return db_->Put(WriteOptions(), k, v);\n+  }\n+\n+  std::string Get(const std::string& k, const Snapshot* snapshot = NULL) {\n+    std::string result;\n+    Status s = db_->Get(ReadOptions(), k, &result);\n+    if (s.IsNotFound()) {\n+      result = \"NOT_FOUND\";\n+    } else if (!s.ok()) {\n+      result = s.ToString();\n+    }\n+    return result;\n+  }\n+\n+  std::string ManifestFileName() {\n+    std::string current;\n+    ASSERT_OK(ReadFileToString(env_, CurrentFileName(dbname_), &current));\n+    size_t len = current.size();\n+    if (len > 0 && current[len-1] == '\\n') {\n+      current.resize(len - 1);\n+    }\n+    return dbname_ + \"/\" + current;\n+  }\n+\n+  std::string LogName(uint64_t number) {\n+    return LogFileName(dbname_, number);\n+  }\n+\n+  size_t DeleteLogFiles() {\n+    std::vector<uint64_t> logs = GetFiles(kLogFile);\n+    for (size_t i = 0; i < logs.size(); i++) {\n+      ASSERT_OK(env_->DeleteFile(LogName(logs[i]))) << LogName(logs[i]);\n+    }\n+    return logs.size();\n+  }\n+\n+  uint64_t FirstLogFile() {\n+    return GetFiles(kLogFile)[0];\n+  }\n+\n+  std::vector<uint64_t> GetFiles(FileType t) {\n+    std::vector<std::string> filenames;\n+    ASSERT_OK(env_->GetChildren(dbname_, &filenames));\n+    std::vector<uint64_t> result;\n+    for (size_t i = 0; i < filenames.size(); i++) {\n+      uint64_t number;\n+      FileType type;\n+      if (ParseFileName(filenames[i], &number, &type) && type == t) {\n+        result.push_back(number);\n+      }\n+    }\n+    return result;\n+  }\n+\n+  int NumLogs() {\n+    return GetFiles(kLogFile).size();\n+  }\n+\n+  int NumTables() {\n+    return GetFiles(kTableFile).size();\n+  }\n+\n+  uint64_t FileSize(const std::string& fname) {\n+    uint64_t result;\n+    ASSERT_OK(env_->GetFileSize(fname, &result)) << fname;\n+    return result;\n+  }\n+\n+  void CompactMemTable() {\n+    dbfull()->TEST_CompactMemTable();\n+  }\n+\n+  // Directly construct a log file that sets key to val.\n+  void MakeLogFile(uint64_t lognum, SequenceNumber seq, Slice key, Slice val) {\n+    std::string fname = LogFileName(dbname_, lognum);\n+    WritableFile* file;\n+    ASSERT_OK(env_->NewWritableFile(fname, &file));\n+    log::Writer writer(file);\n+    WriteBatch batch;\n+    batch.Put(key, val);\n+    WriteBatchInternal::SetSequence(&batch, seq);\n+    ASSERT_OK(writer.AddRecord(WriteBatchInternal::Contents(&batch)));\n+    ASSERT_OK(file->Flush());\n+    delete file;\n+  }\n+\n+ private:\n+  std::string dbname_;\n+  Env* env_;\n+  DB* db_;\n+};\n+\n+TEST(RecoveryTest, ManifestReused) {\n+  if (!CanAppend()) {\n+    fprintf(stderr, \"skipping test because env does not support appending\\n\");\n+    return;\n+  }\n+  ASSERT_OK(Put(\"foo\", \"bar\"));\n+  Close();\n+  std::string old_manifest = ManifestFileName();\n+  Open();\n+  ASSERT_EQ(old_manifest, ManifestFileName());\n+  ASSERT_EQ(\"bar\", Get(\"foo\"));\n+  Open();\n+  ASSERT_EQ(old_manifest, ManifestFileName());\n+  ASSERT_EQ(\"bar\", Get(\"foo\"));\n+}\n+\n+TEST(RecoveryTest, LargeManifestCompacted) {\n+  if (!CanAppend()) {\n+    fprintf(stderr, \"skipping test because env does not support appending\\n\");\n+    return;\n+  }\n+  ASSERT_OK(Put(\"foo\", \"bar\"));\n+  Close();\n+  std::string old_manifest = ManifestFileName();\n+\n+  // Pad with zeroes to make manifest file very big.\n+  {\n+    uint64_t len = FileSize(old_manifest);\n+    WritableFile* file;\n+    ASSERT_OK(env()->NewAppendableFile(old_manifest, &file));\n+    std::string zeroes(3*1048576 - static_cast<size_t>(len), 0);\n+    ASSERT_OK(file->Append(zeroes));\n+    ASSERT_OK(file->Flush());\n+    delete file;\n+  }\n+\n+  Open();\n+  std::string new_manifest = ManifestFileName();\n+  ASSERT_NE(old_manifest, new_manifest);\n+  ASSERT_GT(10000, FileSize(new_manifest));\n+  ASSERT_EQ(\"bar\", Get(\"foo\"));\n+\n+  Open();\n+  ASSERT_EQ(new_manifest, ManifestFileName());\n+  ASSERT_EQ(\"bar\", Get(\"foo\"));\n+}\n+\n+TEST(RecoveryTest, NoLogFiles) {\n+  ASSERT_OK(Put(\"foo\", \"bar\"));\n+  ASSERT_EQ(1, DeleteLogFiles());\n+  Open();\n+  ASSERT_EQ(\"NOT_FOUND\", Get(\"foo\"));\n+  Open();\n+  ASSERT_EQ(\"NOT_FOUND\", Get(\"foo\"));\n+}\n+\n+TEST(RecoveryTest, LogFileReuse) {\n+  if (!CanAppend()) {\n+    fprintf(stderr, \"skipping test because env does not support appending\\n\");\n+    return;\n+  }\n+  for (int i = 0; i < 2; i++) {\n+    ASSERT_OK(Put(\"foo\", \"bar\"));\n+    if (i == 0) {\n+      // Compact to ensure current log is empty\n+      CompactMemTable();\n+    }\n+    Close();\n+    ASSERT_EQ(1, NumLogs());\n+    uint64_t number = FirstLogFile();\n+    if (i == 0) {\n+      ASSERT_EQ(0, FileSize(LogName(number)));\n+    } else {\n+      ASSERT_LT(0, FileSize(LogName(number)));\n+    }\n+    Open();\n+    ASSERT_EQ(1, NumLogs());\n+    ASSERT_EQ(number, FirstLogFile()) << \"did not reuse log file\";\n+    ASSERT_EQ(\"bar\", Get(\"foo\"));\n+    Open();\n+    ASSERT_EQ(1, NumLogs());\n+    ASSERT_EQ(number, FirstLogFile()) << \"did not reuse log file\";\n+    ASSERT_EQ(\"bar\", Get(\"foo\"));\n+  }\n+}\n+\n+TEST(RecoveryTest, MultipleMemTables) {\n+  // Make a large log.\n+  const int kNum = 1000;\n+  for (int i = 0; i < kNum; i++) {\n+    char buf[100];\n+    snprintf(buf, sizeof(buf), \"%050d\", i);\n+    ASSERT_OK(Put(buf, buf));\n+  }\n+  ASSERT_EQ(0, NumTables());\n+  Close();\n+  ASSERT_EQ(0, NumTables());\n+  ASSERT_EQ(1, NumLogs());\n+  uint64_t old_log_file = FirstLogFile();\n+\n+  // Force creation of multiple memtables by reducing the write buffer size.\n+  Options opt;\n+  opt.reuse_logs = true;\n+  opt.write_buffer_size = (kNum*100) / 2;\n+  Open(&opt);\n+  ASSERT_LE(2, NumTables());\n+  ASSERT_EQ(1, NumLogs());\n+  ASSERT_NE(old_log_file, FirstLogFile()) << \"must not reuse log\";\n+  for (int i = 0; i < kNum; i++) {\n+    char buf[100];\n+    snprintf(buf, sizeof(buf), \"%050d\", i);\n+    ASSERT_EQ(buf, Get(buf));\n+  }\n+}\n+\n+TEST(RecoveryTest, MultipleLogFiles) {\n+  ASSERT_OK(Put(\"foo\", \"bar\"));\n+  Close();\n+  ASSERT_EQ(1, NumLogs());\n+\n+  // Make a bunch of uncompacted log files.\n+  uint64_t old_log = FirstLogFile();\n+  MakeLogFile(old_log+1, 1000, \"hello\", \"world\");\n+  MakeLogFile(old_log+2, 1001, \"hi\", \"there\");\n+  MakeLogFile(old_log+3, 1002, \"foo\", \"bar2\");\n+\n+  // Recover and check that all log files were processed.\n+  Open();\n+  ASSERT_LE(1, NumTables());\n+  ASSERT_EQ(1, NumLogs());\n+  uint64_t new_log = FirstLogFile();\n+  ASSERT_LE(old_log+3, new_log);\n+  ASSERT_EQ(\"bar2\", Get(\"foo\"));\n+  ASSERT_EQ(\"world\", Get(\"hello\"));\n+  ASSERT_EQ(\"there\", Get(\"hi\"));\n+\n+  // Test that previous recovery produced recoverable state.\n+  Open();\n+  ASSERT_LE(1, NumTables());\n+  ASSERT_EQ(1, NumLogs());\n+  if (CanAppend()) {\n+    ASSERT_EQ(new_log, FirstLogFile());\n+  }\n+  ASSERT_EQ(\"bar2\", Get(\"foo\"));\n+  ASSERT_EQ(\"world\", Get(\"hello\"));\n+  ASSERT_EQ(\"there\", Get(\"hi\"));\n+\n+  // Check that introducing an older log file does not cause it to be re-read.\n+  Close();\n+  MakeLogFile(old_log+1, 2000, \"hello\", \"stale write\");\n+  Open();\n+  ASSERT_LE(1, NumTables());\n+  ASSERT_EQ(1, NumLogs());\n+  if (CanAppend()) {\n+    ASSERT_EQ(new_log, FirstLogFile());\n+  }\n+  ASSERT_EQ(\"bar2\", Get(\"foo\"));\n+  ASSERT_EQ(\"world\", Get(\"hello\"));\n+  ASSERT_EQ(\"there\", Get(\"hi\"));\n+}\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) {\n+  return leveldb::test::RunAllTests();\n+}"
      },
      {
        "sha": "8bd77764d8fb37b9887dcf83edffa83b6e941c23",
        "filename": "db/skiplist.h",
        "status": "modified",
        "additions": 4,
        "deletions": 4,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/skiplist.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/skiplist.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/skiplist.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -1,10 +1,10 @@\n-#ifndef STORAGE_LEVELDB_DB_SKIPLIST_H_\n-#define STORAGE_LEVELDB_DB_SKIPLIST_H_\n-\n // Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n-//\n+\n+#ifndef STORAGE_LEVELDB_DB_SKIPLIST_H_\n+#define STORAGE_LEVELDB_DB_SKIPLIST_H_\n+\n // Thread safety\n // -------------\n //"
      },
      {
        "sha": "aee1461e1b256a527b8960da59a98fda7e345d4e",
        "filename": "db/skiplist_test.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/skiplist_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/skiplist_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/skiplist_test.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -250,7 +250,7 @@ class ConcurrentTest {\n         // Note that generation 0 is never inserted, so it is ok if\n         // <*,0,*> is missing.\n         ASSERT_TRUE((gen(pos) == 0) ||\n-                    (gen(pos) > initial_state.Get(key(pos)))\n+                    (gen(pos) > static_cast<Key>(initial_state.Get(key(pos))))\n                     ) << \"key: \" << key(pos)\n                       << \"; gen: \" << gen(pos)\n                       << \"; initgen: \""
      },
      {
        "sha": "6ed413c42d4f4a8d531fba2d53617605741046dc",
        "filename": "db/snapshot.h",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/snapshot.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/snapshot.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/snapshot.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -5,6 +5,7 @@\n #ifndef STORAGE_LEVELDB_DB_SNAPSHOT_H_\n #define STORAGE_LEVELDB_DB_SNAPSHOT_H_\n \n+#include \"db/dbformat.h\"\n #include \"leveldb/db.h\"\n \n namespace leveldb {"
      },
      {
        "sha": "a5e0f77a6a91312eaffe69352d79fd4416d764b3",
        "filename": "db/version_set.cc",
        "status": "modified",
        "additions": 39,
        "deletions": 1,
        "changes": 40,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/version_set.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/version_set.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/version_set.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -893,7 +893,7 @@ Status VersionSet::LogAndApply(VersionEdit* edit, port::Mutex* mu) {\n   return s;\n }\n \n-Status VersionSet::Recover() {\n+Status VersionSet::Recover(bool *save_manifest) {\n   struct LogReporter : public log::Reader::Reporter {\n     Status* status;\n     virtual void Corruption(size_t bytes, const Status& s) {\n@@ -1003,11 +1003,49 @@ Status VersionSet::Recover() {\n     last_sequence_ = last_sequence;\n     log_number_ = log_number;\n     prev_log_number_ = prev_log_number;\n+\n+    // See if we can reuse the existing MANIFEST file.\n+    if (ReuseManifest(dscname, current)) {\n+      // No need to save new manifest\n+    } else {\n+      *save_manifest = true;\n+    }\n   }\n \n   return s;\n }\n \n+bool VersionSet::ReuseManifest(const std::string& dscname,\n+                               const std::string& dscbase) {\n+  if (!options_->reuse_logs) {\n+    return false;\n+  }\n+  FileType manifest_type;\n+  uint64_t manifest_number;\n+  uint64_t manifest_size;\n+  if (!ParseFileName(dscbase, &manifest_number, &manifest_type) ||\n+      manifest_type != kDescriptorFile ||\n+      !env_->GetFileSize(dscname, &manifest_size).ok() ||\n+      // Make new compacted MANIFEST if old one is too big\n+      manifest_size >= kTargetFileSize) {\n+    return false;\n+  }\n+\n+  assert(descriptor_file_ == NULL);\n+  assert(descriptor_log_ == NULL);\n+  Status r = env_->NewAppendableFile(dscname, &descriptor_file_);\n+  if (!r.ok()) {\n+    Log(options_->info_log, \"Reuse MANIFEST: %s\\n\", r.ToString().c_str());\n+    assert(descriptor_file_ == NULL);\n+    return false;\n+  }\n+\n+  Log(options_->info_log, \"Reusing MANIFEST %s\\n\", dscname.c_str());\n+  descriptor_log_ = new log::Writer(descriptor_file_, manifest_size);\n+  manifest_file_number_ = manifest_number;\n+  return true;\n+}\n+\n void VersionSet::MarkFileNumberUsed(uint64_t number) {\n   if (next_file_number_ <= number) {\n     next_file_number_ = number + 1;"
      },
      {
        "sha": "1dec74567380915988f9dbb3beffa98a85c97cd2",
        "filename": "db/version_set.h",
        "status": "modified",
        "additions": 3,
        "deletions": 1,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/version_set.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/version_set.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/version_set.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -179,7 +179,7 @@ class VersionSet {\n       EXCLUSIVE_LOCKS_REQUIRED(mu);\n \n   // Recover the last saved descriptor from persistent storage.\n-  Status Recover();\n+  Status Recover(bool *save_manifest);\n \n   // Return the current version.\n   Version* current() const { return current_; }\n@@ -274,6 +274,8 @@ class VersionSet {\n   friend class Compaction;\n   friend class Version;\n \n+  bool ReuseManifest(const std::string& dscname, const std::string& dscbase);\n+\n   void Finalize(Version* v);\n \n   void GetRange(const std::vector<FileMetaData*>& inputs,"
      },
      {
        "sha": "9448ef7b21c3af42c570cf91391694bc6369972e",
        "filename": "db/write_batch_internal.h",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/db/write_batch_internal.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/db/write_batch_internal.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/write_batch_internal.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -5,6 +5,7 @@\n #ifndef STORAGE_LEVELDB_DB_WRITE_BATCH_INTERNAL_H_\n #define STORAGE_LEVELDB_DB_WRITE_BATCH_INTERNAL_H_\n \n+#include \"db/dbformat.h\"\n #include \"leveldb/write_batch.h\"\n \n namespace leveldb {"
      },
      {
        "sha": "2155192581e7b79784564f190a47138ae29461f0",
        "filename": "doc/index.html",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/doc/index.html",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/doc/index.html",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/index.html?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -22,7 +22,7 @@ <h1>Opening A Database</h1>\n creating it if necessary:\n <p>\n <pre>\n-  #include &lt;assert&gt;\n+  #include &lt;cassert&gt;\n   #include \"leveldb/db.h\"\n \n   leveldb::DB* db;"
      },
      {
        "sha": "9a98884daf8d40247a0c57ab5c559ae86010501d",
        "filename": "helpers/memenv/memenv.cc",
        "status": "modified",
        "additions": 13,
        "deletions": 0,
        "changes": 13,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/helpers/memenv/memenv.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/helpers/memenv/memenv.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/helpers/memenv/memenv.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -277,6 +277,19 @@ class InMemoryEnv : public EnvWrapper {\n     return Status::OK();\n   }\n \n+  virtual Status NewAppendableFile(const std::string& fname,\n+                                   WritableFile** result) {\n+    MutexLock lock(&mutex_);\n+    FileState** sptr = &file_map_[fname];\n+    FileState* file = *sptr;\n+    if (file == NULL) {\n+      file = new FileState();\n+      file->Ref();\n+    }\n+    *result = new WritableFileImpl(file);\n+    return Status::OK();\n+  }\n+\n   virtual bool FileExists(const std::string& fname) {\n     MutexLock lock(&mutex_);\n     return file_map_.find(fname) != file_map_.end();"
      },
      {
        "sha": "5cff77613f11df5eb6adcd8b2fd99310264edbd2",
        "filename": "helpers/memenv/memenv_test.cc",
        "status": "modified",
        "additions": 11,
        "deletions": 2,
        "changes": 13,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/helpers/memenv/memenv_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/helpers/memenv/memenv_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/helpers/memenv/memenv_test.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -40,6 +40,8 @@ TEST(MemEnvTest, Basics) {\n \n   // Create a file.\n   ASSERT_OK(env_->NewWritableFile(\"/dir/f\", &writable_file));\n+  ASSERT_OK(env_->GetFileSize(\"/dir/f\", &file_size));\n+  ASSERT_EQ(0, file_size);\n   delete writable_file;\n \n   // Check that the file exists.\n@@ -55,17 +57,24 @@ TEST(MemEnvTest, Basics) {\n   ASSERT_OK(writable_file->Append(\"abc\"));\n   delete writable_file;\n \n-  // Check for expected size.\n+  // Check that append works.\n+  ASSERT_OK(env_->NewAppendableFile(\"/dir/f\", &writable_file));\n   ASSERT_OK(env_->GetFileSize(\"/dir/f\", &file_size));\n   ASSERT_EQ(3, file_size);\n+  ASSERT_OK(writable_file->Append(\"hello\"));\n+  delete writable_file;\n+\n+  // Check for expected size.\n+  ASSERT_OK(env_->GetFileSize(\"/dir/f\", &file_size));\n+  ASSERT_EQ(8, file_size);\n \n   // Check that renaming works.\n   ASSERT_TRUE(!env_->RenameFile(\"/dir/non_existent\", \"/dir/g\").ok());\n   ASSERT_OK(env_->RenameFile(\"/dir/f\", \"/dir/g\"));\n   ASSERT_TRUE(!env_->FileExists(\"/dir/f\"));\n   ASSERT_TRUE(env_->FileExists(\"/dir/g\"));\n   ASSERT_OK(env_->GetFileSize(\"/dir/g\", &file_size));\n-  ASSERT_EQ(3, file_size);\n+  ASSERT_EQ(8, file_size);\n \n   // Check that opening non-existent file fails.\n   SequentialFile* seq_file;"
      },
      {
        "sha": "6819d5bc49f674d47cddf0b23ade8a19d316051c",
        "filename": "include/leveldb/cache.h",
        "status": "modified",
        "additions": 11,
        "deletions": 0,
        "changes": 11,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/include/leveldb/cache.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/include/leveldb/cache.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/cache.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -81,6 +81,17 @@ class Cache {\n   // its cache keys.\n   virtual uint64_t NewId() = 0;\n \n+  // Remove all cache entries that are not actively in use.  Memory-constrained\n+  // applications may wish to call this method to reduce memory usage.\n+  // Default implementation of Prune() does nothing.  Subclasses are strongly\n+  // encouraged to override the default implementation.  A future release of\n+  // leveldb may change Prune() to a pure abstract method.\n+  virtual void Prune() {}\n+\n+  // Return an estimate of the combined charges of all elements stored in the\n+  // cache.\n+  virtual size_t TotalCharge() const = 0;\n+\n  private:\n   void LRU_Remove(Handle* e);\n   void LRU_Append(Handle* e);"
      },
      {
        "sha": "9752cbad512de5ce11c9cdabb65fdb763f4da118",
        "filename": "include/leveldb/db.h",
        "status": "modified",
        "additions": 3,
        "deletions": 1,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/include/leveldb/db.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/include/leveldb/db.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/db.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -14,7 +14,7 @@ namespace leveldb {\n \n // Update Makefile if you change these\n static const int kMajorVersion = 1;\n-static const int kMinorVersion = 18;\n+static const int kMinorVersion = 19;\n \n struct Options;\n struct ReadOptions;\n@@ -115,6 +115,8 @@ class DB {\n   //     about the internal operation of the DB.\n   //  \"leveldb.sstables\" - returns a multi-line string that describes all\n   //     of the sstables that make up the db contents.\n+  //  \"leveldb.approximate-memory-usage\" - returns the approximate number of\n+  //     bytes of memory in use by the DB.\n   virtual bool GetProperty(const Slice& property, std::string* value) = 0;\n \n   // For each i in [0,n-1], store in \"sizes[i]\", the approximate"
      },
      {
        "sha": "99b6c21414b2e6c2d66b0b1a7674923e41b01976",
        "filename": "include/leveldb/env.h",
        "status": "modified",
        "additions": 18,
        "deletions": 0,
        "changes": 18,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/include/leveldb/env.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/include/leveldb/env.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/env.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -69,6 +69,21 @@ class Env {\n   virtual Status NewWritableFile(const std::string& fname,\n                                  WritableFile** result) = 0;\n \n+  // Create an object that either appends to an existing file, or\n+  // writes to a new file (if the file does not exist to begin with).\n+  // On success, stores a pointer to the new file in *result and\n+  // returns OK.  On failure stores NULL in *result and returns\n+  // non-OK.\n+  //\n+  // The returned file will only be accessed by one thread at a time.\n+  //\n+  // May return an IsNotSupportedError error if this Env does\n+  // not allow appending to an existing file.  Users of Env (including\n+  // the leveldb implementation) must be prepared to deal with\n+  // an Env that does not support appending.\n+  virtual Status NewAppendableFile(const std::string& fname,\n+                                   WritableFile** result);\n+\n   // Returns true iff the named file exists.\n   virtual bool FileExists(const std::string& fname) = 0;\n \n@@ -289,6 +304,9 @@ class EnvWrapper : public Env {\n   Status NewWritableFile(const std::string& f, WritableFile** r) {\n     return target_->NewWritableFile(f, r);\n   }\n+  Status NewAppendableFile(const std::string& f, WritableFile** r) {\n+    return target_->NewAppendableFile(f, r);\n+  }\n   bool FileExists(const std::string& f) { return target_->FileExists(f); }\n   Status GetChildren(const std::string& dir, std::vector<std::string>* r) {\n     return target_->GetChildren(dir, r);"
      },
      {
        "sha": "da631ed9d89bbc9cb764a624d8d5a26c34a626b7",
        "filename": "include/leveldb/iterator.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/include/leveldb/iterator.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/include/leveldb/iterator.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/iterator.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -37,7 +37,7 @@ class Iterator {\n   // Valid() after this call iff the source is not empty.\n   virtual void SeekToLast() = 0;\n \n-  // Position at the first key in the source that at or past target\n+  // Position at the first key in the source that is at or past target.\n   // The iterator is Valid() after this call iff the source contains\n   // an entry that comes at or past target.\n   virtual void Seek(const Slice& target) = 0;"
      },
      {
        "sha": "83a1ef39a4814d684006f5dd4980d4c01a2458ed",
        "filename": "include/leveldb/options.h",
        "status": "modified",
        "additions": 6,
        "deletions": 0,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/include/leveldb/options.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/include/leveldb/options.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/options.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -128,6 +128,12 @@ struct Options {\n   // efficiently detect that and will switch to uncompressed mode.\n   CompressionType compression;\n \n+  // EXPERIMENTAL: If true, append to existing MANIFEST and log files\n+  // when a database is opened.  This can significantly speed up open.\n+  //\n+  // Default: currently false, but may become true later.\n+  bool reuse_logs;\n+\n   // If non-NULL, use the specified filter policy to reduce disk reads.\n   // Many applications will benefit from passing the result of\n   // NewBloomFilterPolicy() here."
      },
      {
        "sha": "d9575f97532eb1e64451a9965a5076be99656610",
        "filename": "include/leveldb/status.h",
        "status": "modified",
        "additions": 6,
        "deletions": 0,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/include/leveldb/status.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/include/leveldb/status.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/status.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -60,6 +60,12 @@ class Status {\n   // Returns true iff the status indicates an IOError.\n   bool IsIOError() const { return code() == kIOError; }\n \n+  // Returns true iff the status indicates a NotSupportedError.\n+  bool IsNotSupportedError() const { return code() == kNotSupported; }\n+\n+  // Returns true iff the status indicates an InvalidArgument.\n+  bool IsInvalidArgument() const { return code() == kInvalidArgument; }\n+\n   // Return a string representation of this status suitable for printing.\n   // Returns the string \"OK\" for success.\n   std::string ToString() const;"
      },
      {
        "sha": "1c4c7aafc63eb86e11062ebda13d1038287d5dfc",
        "filename": "port/atomic_pointer.h",
        "status": "modified",
        "additions": 19,
        "deletions": 0,
        "changes": 19,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/port/atomic_pointer.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/port/atomic_pointer.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/atomic_pointer.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -35,8 +35,12 @@\n #define ARCH_CPU_X86_FAMILY 1\n #elif defined(__ARMEL__)\n #define ARCH_CPU_ARM_FAMILY 1\n+#elif defined(__aarch64__)\n+#define ARCH_CPU_ARM64_FAMILY 1\n #elif defined(__ppc__) || defined(__powerpc__) || defined(__powerpc64__)\n #define ARCH_CPU_PPC_FAMILY 1\n+#elif defined(__mips__)\n+#define ARCH_CPU_MIPS_FAMILY 1\n #endif\n \n namespace leveldb {\n@@ -92,6 +96,13 @@ inline void MemoryBarrier() {\n }\n #define LEVELDB_HAVE_MEMORY_BARRIER\n \n+// ARM64\n+#elif defined(ARCH_CPU_ARM64_FAMILY)\n+inline void MemoryBarrier() {\n+  asm volatile(\"dmb sy\" : : : \"memory\");\n+}\n+#define LEVELDB_HAVE_MEMORY_BARRIER\n+\n // PPC\n #elif defined(ARCH_CPU_PPC_FAMILY) && defined(__GNUC__)\n inline void MemoryBarrier() {\n@@ -101,6 +112,13 @@ inline void MemoryBarrier() {\n }\n #define LEVELDB_HAVE_MEMORY_BARRIER\n \n+// MIPS\n+#elif defined(ARCH_CPU_MIPS_FAMILY) && defined(__GNUC__)\n+inline void MemoryBarrier() {\n+  __asm__ __volatile__(\"sync\" : : : \"memory\");\n+}\n+#define LEVELDB_HAVE_MEMORY_BARRIER\n+\n #endif\n \n // AtomicPointer built using platform-specific MemoryBarrier()\n@@ -215,6 +233,7 @@ class AtomicPointer {\n #undef LEVELDB_HAVE_MEMORY_BARRIER\n #undef ARCH_CPU_X86_FAMILY\n #undef ARCH_CPU_ARM_FAMILY\n+#undef ARCH_CPU_ARM64_FAMILY\n #undef ARCH_CPU_PPC_FAMILY\n \n }  // namespace port"
      },
      {
        "sha": "30e8007ae3cf11e6b82c1f0cd71627525515f045",
        "filename": "port/port_posix.cc",
        "status": "modified",
        "additions": 0,
        "deletions": 1,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/port/port_posix.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/port/port_posix.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/port_posix.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -7,7 +7,6 @@\n #include <cstdlib>\n #include <stdio.h>\n #include <string.h>\n-#include \"util/logging.h\"\n \n namespace leveldb {\n namespace port {"
      },
      {
        "sha": "4e78b954f8d90c9c0aa0b4fd3ccff19ce8bdd62b",
        "filename": "table/filter_block.cc",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/table/filter_block.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/table/filter_block.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/filter_block.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -68,7 +68,7 @@ void FilterBlockBuilder::GenerateFilter() {\n \n   // Generate filter for current set of keys and append to result_.\n   filter_offsets_.push_back(result_.size());\n-  policy_->CreateFilter(&tmp_keys_[0], num_keys, &result_);\n+  policy_->CreateFilter(&tmp_keys_[0], static_cast<int>(num_keys), &result_);\n \n   tmp_keys_.clear();\n   keys_.clear();\n@@ -97,7 +97,7 @@ bool FilterBlockReader::KeyMayMatch(uint64_t block_offset, const Slice& key) {\n   if (index < num_) {\n     uint32_t start = DecodeFixed32(offset_ + index*4);\n     uint32_t limit = DecodeFixed32(offset_ + index*4 + 4);\n-    if (start <= limit && limit <= (offset_ - data_)) {\n+    if (start <= limit && limit <= static_cast<size_t>(offset_ - data_)) {\n       Slice filter = Slice(data_ + start, limit - start);\n       return policy_->KeyMayMatch(key, filter);\n     } else if (start == limit) {"
      },
      {
        "sha": "24e4e02445b8a01201e77a9697e2b0dd85255017",
        "filename": "table/format.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 2,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/table/format.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/table/format.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/format.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -30,15 +30,14 @@ Status BlockHandle::DecodeFrom(Slice* input) {\n }\n \n void Footer::EncodeTo(std::string* dst) const {\n-#ifndef NDEBUG\n   const size_t original_size = dst->size();\n-#endif\n   metaindex_handle_.EncodeTo(dst);\n   index_handle_.EncodeTo(dst);\n   dst->resize(2 * BlockHandle::kMaxEncodedLength);  // Padding\n   PutFixed32(dst, static_cast<uint32_t>(kTableMagicNumber & 0xffffffffu));\n   PutFixed32(dst, static_cast<uint32_t>(kTableMagicNumber >> 32));\n   assert(dst->size() == original_size + kEncodedLength);\n+  (void)original_size;  // Disable unused variable warning.\n }\n \n Status Footer::DecodeFrom(Slice* input) {"
      },
      {
        "sha": "f410c3fabe61048eee669454496be9b8c9ac1d17",
        "filename": "table/iterator_wrapper.h",
        "status": "modified",
        "additions": 3,
        "deletions": 0,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/table/iterator_wrapper.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/table/iterator_wrapper.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/iterator_wrapper.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -5,6 +5,9 @@\n #ifndef STORAGE_LEVELDB_TABLE_ITERATOR_WRAPPER_H_\n #define STORAGE_LEVELDB_TABLE_ITERATOR_WRAPPER_H_\n \n+#include \"leveldb/iterator.h\"\n+#include \"leveldb/slice.h\"\n+\n namespace leveldb {\n \n // A internal wrapper class with an interface similar to Iterator that"
      },
      {
        "sha": "decf8082cc1837802559886319cc40180fc7a5b8",
        "filename": "table/table.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/table/table.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/table/table.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/table.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -82,7 +82,7 @@ Status Table::Open(const Options& options,\n     *table = new Table(rep);\n     (*table)->ReadMeta(footer);\n   } else {\n-    if (index_block) delete index_block;\n+    delete index_block;\n   }\n \n   return s;"
      },
      {
        "sha": "abf6e246ff8e2751c4d8830b3a84b453f62f38e6",
        "filename": "table/table_test.cc",
        "status": "modified",
        "additions": 14,
        "deletions": 6,
        "changes": 20,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/table/table_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/table/table_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/table_test.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -853,12 +853,20 @@ TEST(TableTest, ApproximateOffsetOfCompressed) {\n   options.compression = kSnappyCompression;\n   c.Finish(options, &keys, &kvmap);\n \n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"abc\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k02\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k03\"),    2000,   3000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k04\"),    2000,   3000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"xyz\"),    4000,   6000));\n+  // Expected upper and lower bounds of space used by compressible strings.\n+  static const int kSlop = 1000;  // Compressor effectiveness varies.\n+  const int expected = 2500;  // 10000 * compression ratio (0.25)\n+  const int min_z = expected - kSlop;\n+  const int max_z = expected + kSlop;\n+\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"abc\"), 0, kSlop));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01\"), 0, kSlop));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k02\"), 0, kSlop));\n+  // Have now emitted a large compressible string, so adjust expected offset.\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k03\"), min_z, max_z));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k04\"), min_z, max_z));\n+  // Have now emitted two large compressible strings, so adjust expected offset.\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"xyz\"), 2 * min_z, 2 * max_z));\n }\n \n }  // namespace leveldb"
      },
      {
        "sha": "74078213eedac2069d5704e2aad7a444d0c4c2ea",
        "filename": "util/arena.cc",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/util/arena.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/util/arena.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/arena.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -9,8 +9,7 @@ namespace leveldb {\n \n static const int kBlockSize = 4096;\n \n-Arena::Arena() {\n-  blocks_memory_ = 0;\n+Arena::Arena() : memory_usage_(0) {\n   alloc_ptr_ = NULL;  // First allocation will allocate a block\n   alloc_bytes_remaining_ = 0;\n }\n@@ -60,8 +59,9 @@ char* Arena::AllocateAligned(size_t bytes) {\n \n char* Arena::AllocateNewBlock(size_t block_bytes) {\n   char* result = new char[block_bytes];\n-  blocks_memory_ += block_bytes;\n   blocks_.push_back(result);\n+  memory_usage_.NoBarrier_Store(\n+      reinterpret_cast<void*>(MemoryUsage() + block_bytes + sizeof(char*)));\n   return result;\n }\n "
      },
      {
        "sha": "48bab3374159543f1d261f60467d4563c9103a8a",
        "filename": "util/arena.h",
        "status": "modified",
        "additions": 5,
        "deletions": 5,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/util/arena.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/util/arena.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/arena.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -9,6 +9,7 @@\n #include <assert.h>\n #include <stddef.h>\n #include <stdint.h>\n+#include \"port/port.h\"\n \n namespace leveldb {\n \n@@ -24,10 +25,9 @@ class Arena {\n   char* AllocateAligned(size_t bytes);\n \n   // Returns an estimate of the total memory usage of data allocated\n-  // by the arena (including space allocated but not yet used for user\n-  // allocations).\n+  // by the arena.\n   size_t MemoryUsage() const {\n-    return blocks_memory_ + blocks_.capacity() * sizeof(char*);\n+    return reinterpret_cast<uintptr_t>(memory_usage_.NoBarrier_Load());\n   }\n \n  private:\n@@ -41,8 +41,8 @@ class Arena {\n   // Array of new[] allocated memory blocks\n   std::vector<char*> blocks_;\n \n-  // Bytes of memory in blocks allocated so far\n-  size_t blocks_memory_;\n+  // Total memory usage of the arena.\n+  port::AtomicPointer memory_usage_;\n \n   // No copying allowed\n   Arena(const Arena&);"
      },
      {
        "sha": "bf3e4ca6e93146b056fdff7eb5dfd5e397f52df7",
        "filename": "util/bloom.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/util/bloom.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/util/bloom.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/bloom.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -47,7 +47,7 @@ class BloomFilterPolicy : public FilterPolicy {\n     dst->resize(init_size + bytes, 0);\n     dst->push_back(static_cast<char>(k_));  // Remember # of probes in filter\n     char* array = &(*dst)[init_size];\n-    for (size_t i = 0; i < n; i++) {\n+    for (int i = 0; i < n; i++) {\n       // Use double-hashing to generate a sequence of hash values.\n       // See analysis in [Kirsch,Mitzenmacher 2006].\n       uint32_t h = BloomHash(keys[i]);"
      },
      {
        "sha": "1b87a2be3f540c673ee1749b0b855d396251f5aa",
        "filename": "util/bloom_test.cc",
        "status": "modified",
        "additions": 2,
        "deletions": 1,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/util/bloom_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/util/bloom_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/bloom_test.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -46,7 +46,8 @@ class BloomTest {\n       key_slices.push_back(Slice(keys_[i]));\n     }\n     filter_.clear();\n-    policy_->CreateFilter(&key_slices[0], key_slices.size(), &filter_);\n+    policy_->CreateFilter(&key_slices[0], static_cast<int>(key_slices.size()),\n+                          &filter_);\n     keys_.clear();\n     if (kVerbose >= 2) DumpFilter();\n   }"
      },
      {
        "sha": "ce46886171ad446e6b78340c800fbce3df903e3e",
        "filename": "util/cache.cc",
        "status": "modified",
        "additions": 108,
        "deletions": 28,
        "changes": 136,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/util/cache.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/util/cache.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/cache.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -19,6 +19,23 @@ Cache::~Cache() {\n namespace {\n \n // LRU cache implementation\n+//\n+// Cache entries have an \"in_cache\" boolean indicating whether the cache has a\n+// reference on the entry.  The only ways that this can become false without the\n+// entry being passed to its \"deleter\" are via Erase(), via Insert() when\n+// an element with a duplicate key is inserted, or on destruction of the cache.\n+//\n+// The cache keeps two linked lists of items in the cache.  All items in the\n+// cache are in one list or the other, and never both.  Items still referenced\n+// by clients but erased from the cache are in neither list.  The lists are:\n+// - in-use:  contains the items currently referenced by clients, in no\n+//   particular order.  (This list is used for invariant checking.  If we\n+//   removed the check, elements that would otherwise be on this list could be\n+//   left as disconnected singleton lists.)\n+// - LRU:  contains the items not currently referenced by clients, in LRU order\n+// Elements are moved between these lists by the Ref() and Unref() methods,\n+// when they detect an element in the cache acquiring or losing its only\n+// external reference.\n \n // An entry is a variable length heap-allocated structure.  Entries\n // are kept in a circular doubly linked list ordered by access time.\n@@ -30,7 +47,8 @@ struct LRUHandle {\n   LRUHandle* prev;\n   size_t charge;      // TODO(opt): Only allow uint32_t?\n   size_t key_length;\n-  uint32_t refs;\n+  bool in_cache;      // Whether entry is in the cache.\n+  uint32_t refs;      // References, including cache reference, if present.\n   uint32_t hash;      // Hash of key(); used for fast sharding and comparisons\n   char key_data[1];   // Beginning of key\n \n@@ -147,49 +165,77 @@ class LRUCache {\n   Cache::Handle* Lookup(const Slice& key, uint32_t hash);\n   void Release(Cache::Handle* handle);\n   void Erase(const Slice& key, uint32_t hash);\n+  void Prune();\n+  size_t TotalCharge() const {\n+    MutexLock l(&mutex_);\n+    return usage_;\n+  }\n \n  private:\n   void LRU_Remove(LRUHandle* e);\n-  void LRU_Append(LRUHandle* e);\n+  void LRU_Append(LRUHandle*list, LRUHandle* e);\n+  void Ref(LRUHandle* e);\n   void Unref(LRUHandle* e);\n+  bool FinishErase(LRUHandle* e);\n \n   // Initialized before use.\n   size_t capacity_;\n \n   // mutex_ protects the following state.\n-  port::Mutex mutex_;\n+  mutable port::Mutex mutex_;\n   size_t usage_;\n \n   // Dummy head of LRU list.\n   // lru.prev is newest entry, lru.next is oldest entry.\n+  // Entries have refs==1 and in_cache==true.\n   LRUHandle lru_;\n \n+  // Dummy head of in-use list.\n+  // Entries are in use by clients, and have refs >= 2 and in_cache==true.\n+  LRUHandle in_use_;\n+\n   HandleTable table_;\n };\n \n LRUCache::LRUCache()\n     : usage_(0) {\n-  // Make empty circular linked list\n+  // Make empty circular linked lists.\n   lru_.next = &lru_;\n   lru_.prev = &lru_;\n+  in_use_.next = &in_use_;\n+  in_use_.prev = &in_use_;\n }\n \n LRUCache::~LRUCache() {\n+  assert(in_use_.next == &in_use_);  // Error if caller has an unreleased handle\n   for (LRUHandle* e = lru_.next; e != &lru_; ) {\n     LRUHandle* next = e->next;\n-    assert(e->refs == 1);  // Error if caller has an unreleased handle\n+    assert(e->in_cache);\n+    e->in_cache = false;\n+    assert(e->refs == 1);  // Invariant of lru_ list.\n     Unref(e);\n     e = next;\n   }\n }\n \n+void LRUCache::Ref(LRUHandle* e) {\n+  if (e->refs == 1 && e->in_cache) {  // If on lru_ list, move to in_use_ list.\n+    LRU_Remove(e);\n+    LRU_Append(&in_use_, e);\n+  }\n+  e->refs++;\n+}\n+\n void LRUCache::Unref(LRUHandle* e) {\n   assert(e->refs > 0);\n   e->refs--;\n-  if (e->refs <= 0) {\n-    usage_ -= e->charge;\n+  if (e->refs == 0) { // Deallocate.\n+    assert(!e->in_cache);\n     (*e->deleter)(e->key(), e->value);\n     free(e);\n+  } else if (e->in_cache && e->refs == 1) {  // No longer in use; move to lru_ list.\n+    LRU_Remove(e);\n+    LRU_Append(&lru_, e);\n   }\n }\n \n@@ -198,10 +244,10 @@ void LRUCache::LRU_Remove(LRUHandle* e) {\n   e->prev->next = e->next;\n }\n \n-void LRUCache::LRU_Append(LRUHandle* e) {\n-  // Make \"e\" newest entry by inserting just before lru_\n-  e->next = &lru_;\n-  e->prev = lru_.prev;\n+void LRUCache::LRU_Append(LRUHandle* list, LRUHandle* e) {\n+  // Make \"e\" newest entry by inserting just before *list\n+  e->next = list;\n+  e->prev = list->prev;\n   e->prev->next = e;\n   e->next->prev = e;\n }\n@@ -210,9 +256,7 @@ Cache::Handle* LRUCache::Lookup(const Slice& key, uint32_t hash) {\n   MutexLock l(&mutex_);\n   LRUHandle* e = table_.Lookup(key, hash);\n   if (e != NULL) {\n-    e->refs++;\n-    LRU_Remove(e);\n-    LRU_Append(e);\n+    Ref(e);\n   }\n   return reinterpret_cast<Cache::Handle*>(e);\n }\n@@ -234,34 +278,58 @@ Cache::Handle* LRUCache::Insert(\n   e->charge = charge;\n   e->key_length = key.size();\n   e->hash = hash;\n-  e->refs = 2;  // One from LRUCache, one for the returned handle\n+  e->in_cache = false;\n+  e->refs = 1;  // for the returned handle.\n   memcpy(e->key_data, key.data(), key.size());\n-  LRU_Append(e);\n-  usage_ += charge;\n \n-  LRUHandle* old = table_.Insert(e);\n-  if (old != NULL) {\n-    LRU_Remove(old);\n-    Unref(old);\n-  }\n+  if (capacity_ > 0) {\n+    e->refs++;  // for the cache's reference.\n+    e->in_cache = true;\n+    LRU_Append(&in_use_, e);\n+    usage_ += charge;\n+    FinishErase(table_.Insert(e));\n+  } // else don't cache.  (Tests use capacity_==0 to turn off caching.)\n \n   while (usage_ > capacity_ && lru_.next != &lru_) {\n     LRUHandle* old = lru_.next;\n-    LRU_Remove(old);\n-    table_.Remove(old->key(), old->hash);\n-    Unref(old);\n+    assert(old->refs == 1);\n+    bool erased = FinishErase(table_.Remove(old->key(), old->hash));\n+    if (!erased) {  // to avoid unused variable when compiled NDEBUG\n+      assert(erased);\n+    }\n   }\n \n   return reinterpret_cast<Cache::Handle*>(e);\n }\n \n-void LRUCache::Erase(const Slice& key, uint32_t hash) {\n-  MutexLock l(&mutex_);\n-  LRUHandle* e = table_.Remove(key, hash);\n+// If e != NULL, finish removing *e from the cache; it has already been removed\n+// from the hash table.  Return whether e != NULL.  Requires mutex_ held.\n+bool LRUCache::FinishErase(LRUHandle* e) {\n   if (e != NULL) {\n+    assert(e->in_cache);\n     LRU_Remove(e);\n+    e->in_cache = false;\n+    usage_ -= e->charge;\n     Unref(e);\n   }\n+  return e != NULL;\n+}\n+\n+void LRUCache::Erase(const Slice& key, uint32_t hash) {\n+  MutexLock l(&mutex_);\n+  FinishErase(table_.Remove(key, hash));\n+}\n+\n+void LRUCache::Prune() {\n+  MutexLock l(&mutex_);\n+  while (lru_.next != &lru_) {\n+    LRUHandle* e = lru_.next;\n+    assert(e->refs == 1);\n+    bool erased = FinishErase(table_.Remove(e->key(), e->hash));\n+    if (!erased) {  // to avoid unused variable when compiled NDEBUG\n+      assert(erased);\n+    }\n+  }\n }\n \n static const int kNumShardBits = 4;\n@@ -314,6 +382,18 @@ class ShardedLRUCache : public Cache {\n     MutexLock l(&id_mutex_);\n     return ++(last_id_);\n   }\n+  virtual void Prune() {\n+    for (int s = 0; s < kNumShards; s++) {\n+      shard_[s].Prune();\n+    }\n+  }\n+  virtual size_t TotalCharge() const {\n+    size_t total = 0;\n+    for (int s = 0; s < kNumShards; s++) {\n+      total += shard_[s].TotalCharge();\n+    }\n+    return total;\n+  }\n };\n \n }  // end anonymous namespace"
      },
      {
        "sha": "468f7a6425bfa92ff05bb412202846ddc263f8f8",
        "filename": "util/cache_test.cc",
        "status": "modified",
        "additions": 41,
        "deletions": 1,
        "changes": 42,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/util/cache_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/util/cache_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/cache_test.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -59,6 +59,11 @@ class CacheTest {\n                                    &CacheTest::Deleter));\n   }\n \n+  Cache::Handle* InsertAndReturnHandle(int key, int value, int charge = 1) {\n+    return cache_->Insert(EncodeKey(key), EncodeValue(value), charge,\n+                          &CacheTest::Deleter);\n+  }\n+\n   void Erase(int key) {\n     cache_->Erase(EncodeKey(key));\n   }\n@@ -135,15 +140,37 @@ TEST(CacheTest, EntriesArePinned) {\n TEST(CacheTest, EvictionPolicy) {\n   Insert(100, 101);\n   Insert(200, 201);\n+  Insert(300, 301);\n+  Cache::Handle* h = cache_->Lookup(EncodeKey(300));\n \n-  // Frequently used entry must be kept around\n+  // Frequently used entry must be kept around,\n+  // as must things that are still in use.\n   for (int i = 0; i < kCacheSize + 100; i++) {\n     Insert(1000+i, 2000+i);\n     ASSERT_EQ(2000+i, Lookup(1000+i));\n     ASSERT_EQ(101, Lookup(100));\n   }\n   ASSERT_EQ(101, Lookup(100));\n   ASSERT_EQ(-1, Lookup(200));\n+  ASSERT_EQ(301, Lookup(300));\n+  cache_->Release(h);\n+}\n+\n+TEST(CacheTest, UseExceedsCacheSize) {\n+  // Overfill the cache, keeping handles on all inserted entries.\n+  std::vector<Cache::Handle*> h;\n+  for (int i = 0; i < kCacheSize + 100; i++) {\n+    h.push_back(InsertAndReturnHandle(1000+i, 2000+i));\n+  }\n+\n+  // Check that all the entries can be found in the cache.\n+  for (int i = 0; i < h.size(); i++) {\n+    ASSERT_EQ(2000+i, Lookup(1000+i));\n+  }\n+\n+  for (int i = 0; i < h.size(); i++) {\n+    cache_->Release(h[i]);\n+  }\n }\n \n TEST(CacheTest, HeavyEntries) {\n@@ -179,6 +206,19 @@ TEST(CacheTest, NewId) {\n   ASSERT_NE(a, b);\n }\n \n+TEST(CacheTest, Prune) {\n+  Insert(1, 100);\n+  Insert(2, 200);\n+\n+  Cache::Handle* handle = cache_->Lookup(EncodeKey(1));\n+  ASSERT_TRUE(handle);\n+  cache_->Prune();\n+  cache_->Release(handle);\n+\n+  ASSERT_EQ(100, Lookup(1));\n+  ASSERT_EQ(-1, Lookup(2));\n+}\n+\n }  // namespace leveldb\n \n int main(int argc, char** argv) {"
      },
      {
        "sha": "c58a0821ef7a3a8487d4449ce121ffdf9fcf87be",
        "filename": "util/env.cc",
        "status": "modified",
        "additions": 4,
        "deletions": 0,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/util/env.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/util/env.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/env.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -9,6 +9,10 @@ namespace leveldb {\n Env::~Env() {\n }\n \n+Status Env::NewAppendableFile(const std::string& fname, WritableFile** result) {\n+  return Status::NotSupported(\"NewAppendableFile\", fname);\n+}\n+\n SequentialFile::~SequentialFile() {\n }\n "
      },
      {
        "sha": "e0fca52f4632a2a141dad0f6030393678d11bb7f",
        "filename": "util/env_posix.cc",
        "status": "modified",
        "additions": 13,
        "deletions": 0,
        "changes": 13,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/util/env_posix.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/util/env_posix.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/env_posix.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -351,6 +351,19 @@ class PosixEnv : public Env {\n     return s;\n   }\n \n+  virtual Status NewAppendableFile(const std::string& fname,\n+                                   WritableFile** result) {\n+    Status s;\n+    FILE* f = fopen(fname.c_str(), \"a\");\n+    if (f == NULL) {\n+      *result = NULL;\n+      s = IOError(fname, errno);\n+    } else {\n+      *result = new PosixWritableFile(fname, f);\n+    }\n+    return s;\n+  }\n+\n   virtual bool FileExists(const std::string& fname) {\n     return access(fname.c_str(), F_OK) == 0;\n   }"
      },
      {
        "sha": "b074b7579ec2d377637112f4d5a9937f478637d6",
        "filename": "util/env_win.cc",
        "status": "modified",
        "additions": 30,
        "deletions": 7,
        "changes": 37,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/util/env_win.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/util/env_win.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/env_win.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -106,7 +106,7 @@ class Win32RandomAccessFile : public RandomAccessFile\n class Win32WritableFile : public WritableFile\n {\n public:\n-    Win32WritableFile(const std::string& fname);\n+    Win32WritableFile(const std::string& fname, bool append);\n     ~Win32WritableFile();\n \n     virtual Status Append(const Slice& data);\n@@ -158,6 +158,8 @@ class Win32Env : public Env\n         RandomAccessFile** result);\n     virtual Status NewWritableFile(const std::string& fname,\n         WritableFile** result);\n+    virtual Status NewAppendableFile(const std::string& fname,\n+        WritableFile** result);\n \n     virtual bool FileExists(const std::string& fname);\n \n@@ -423,17 +425,23 @@ void Win32RandomAccessFile::_CleanUp()\n     }\n }\n \n-Win32WritableFile::Win32WritableFile(const std::string& fname)\n+Win32WritableFile::Win32WritableFile(const std::string& fname, bool append)\n     : filename_(fname)\n {\n     std::wstring path;\n     ToWidePath(fname, path);\n-    DWORD Flag = PathFileExistsW(path.c_str()) ? OPEN_EXISTING : CREATE_ALWAYS;\n+    // NewAppendableFile: append to an existing file, or create a new one\n+    //     if none exists - this is OPEN_ALWAYS behavior, with\n+    //     FILE_APPEND_DATA to avoid having to manually position the file\n+    //     pointer at the end of the file.\n+    // NewWritableFile: create a new file, delete if it exists - this is\n+    //     CREATE_ALWAYS behavior. This file is used for writing only so\n+    //     use GENERIC_WRITE.\n     _hFile = CreateFileW(path.c_str(),\n-                         GENERIC_READ | GENERIC_WRITE,\n+                         append ? FILE_APPEND_DATA : GENERIC_WRITE,\n                          FILE_SHARE_READ|FILE_SHARE_DELETE|FILE_SHARE_WRITE,\n                          NULL,\n-                         Flag,\n+                         append ? OPEN_ALWAYS : CREATE_ALWAYS,\n                          FILE_ATTRIBUTE_NORMAL,\n                          NULL);\n     // CreateFileW returns INVALID_HANDLE_VALUE in case of error, always check isEnable() before use\n@@ -823,7 +831,9 @@ Status Win32Env::NewLogger( const std::string& fname, Logger** result )\n {\n     Status sRet;\n     std::string path = fname;\n-    Win32WritableFile* pMapFile = new Win32WritableFile(ModifyPath(path));\n+    // Logs are opened with write semantics, not with append semantics\n+    // (see PosixEnv::NewLogger)\n+    Win32WritableFile* pMapFile = new Win32WritableFile(ModifyPath(path), false);\n     if(!pMapFile->isEnable()){\n         delete pMapFile;\n         *result = NULL;\n@@ -837,7 +847,20 @@ Status Win32Env::NewWritableFile( const std::string& fname, WritableFile** resul\n {\n     Status sRet;\n     std::string path = fname;\n-    Win32WritableFile* pFile = new Win32WritableFile(ModifyPath(path));\n+    Win32WritableFile* pFile = new Win32WritableFile(ModifyPath(path), false);\n+    if(!pFile->isEnable()){\n+        *result = NULL;\n+        sRet = Status::IOError(fname,Win32::GetLastErrSz());\n+    }else\n+        *result = pFile;\n+    return sRet;\n+}\n+\n+Status Win32Env::NewAppendableFile( const std::string& fname, WritableFile** result )\n+{\n+    Status sRet;\n+    std::string path = fname;\n+    Win32WritableFile* pFile = new Win32WritableFile(ModifyPath(path), true);\n     if(!pFile->isEnable()){\n         *result = NULL;\n         sRet = Status::IOError(fname,Win32::GetLastErrSz());"
      },
      {
        "sha": "8b618fb1ae858d9af8484b81b1cd6c2f60bb018b",
        "filename": "util/options.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/util/options.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/util/options.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/options.cc?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -22,8 +22,8 @@ Options::Options()\n       block_size(4096),\n       block_restart_interval(16),\n       compression(kSnappyCompression),\n+      reuse_logs(false),\n       filter_policy(NULL) {\n }\n \n-\n }  // namespace leveldb"
      },
      {
        "sha": "d7e45837027db6d1d6235c43082bc20747c0571d",
        "filename": "util/testutil.h",
        "status": "modified",
        "additions": 10,
        "deletions": 0,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/634ad517037b319147816f1d112b066528e1724a/util/testutil.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/634ad517037b319147816f1d112b066528e1724a/util/testutil.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/testutil.h?ref=634ad517037b319147816f1d112b066528e1724a",
        "patch": "@@ -45,6 +45,16 @@ class ErrorEnv : public EnvWrapper {\n     }\n     return target()->NewWritableFile(fname, result);\n   }\n+\n+  virtual Status NewAppendableFile(const std::string& fname,\n+                                   WritableFile** result) {\n+    if (writable_file_error_) {\n+      ++num_writable_file_errors_;\n+      *result = NULL;\n+      return Status::IOError(fname, \"fake error\");\n+    }\n+    return target()->NewAppendableFile(fname, result);\n+  }\n };\n \n }  // namespace test"
      }
    ]
  },
  {
    "sha": "605d701471c3ee84682b0c149e41142d7cea95e7",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo2MDVkNzAxNDcxYzNlZTg0NjgyYjBjMTQ5ZTQxMTQyZDdjZWE5NWU3",
    "commit": {
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter.wuille@gmail.com",
        "date": "2016-12-02T00:14:45Z"
      },
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter.wuille@gmail.com",
        "date": "2016-12-02T00:14:45Z"
      },
      "message": "Merge in LevelDB 1.19 changes",
      "tree": {
        "sha": "7a6af0e78ee2202f510686e9a3561c28829b8a4b",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/7a6af0e78ee2202f510686e9a3561c28829b8a4b"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/605d701471c3ee84682b0c149e41142d7cea95e7",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/605d701471c3ee84682b0c149e41142d7cea95e7",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/605d701471c3ee84682b0c149e41142d7cea95e7",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/605d701471c3ee84682b0c149e41142d7cea95e7/comments",
    "author": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "dc6dee41f7cf2ba93fcd0fea7c157e4b2775d439",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/dc6dee41f7cf2ba93fcd0fea7c157e4b2775d439",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/dc6dee41f7cf2ba93fcd0fea7c157e4b2775d439"
      },
      {
        "sha": "634ad517037b319147816f1d112b066528e1724a",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/634ad517037b319147816f1d112b066528e1724a",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/634ad517037b319147816f1d112b066528e1724a"
      }
    ],
    "stats": {
      "total": 2314,
      "additions": 1942,
      "deletions": 372
    },
    "files": [
      {
        "sha": "f5bd74c4541263e5df4e598158879d78edb51cda",
        "filename": "src/leveldb/.travis.yml",
        "status": "added",
        "additions": 13,
        "deletions": 0,
        "changes": 13,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/.travis.yml",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/.travis.yml",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/.travis.yml?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -0,0 +1,13 @@\n+language: cpp\n+compiler:\n+- clang\n+- gcc\n+os:\n+- linux\n+- osx\n+sudo: false\n+before_install:\n+- echo $LANG\n+- echo $LC_ALL\n+script:\n+- make -j 4 check"
      },
      {
        "sha": "07a5a1ead6fd8a3b6eb45f0ef5481c5787f3fd78",
        "filename": "src/leveldb/Makefile",
        "status": "modified",
        "additions": 327,
        "deletions": 140,
        "changes": 467,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/Makefile",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/Makefile",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/Makefile?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -20,208 +20,395 @@ $(shell CC=\"$(CC)\" CXX=\"$(CXX)\" TARGET_OS=\"$(TARGET_OS)\" \\\n # this file is generated by the previous line to set build flags and sources\n include build_config.mk\n \n+TESTS = \\\n+\tdb/autocompact_test \\\n+\tdb/c_test \\\n+\tdb/corruption_test \\\n+\tdb/db_test \\\n+\tdb/dbformat_test \\\n+\tdb/fault_injection_test \\\n+\tdb/filename_test \\\n+\tdb/log_test \\\n+\tdb/recovery_test \\\n+\tdb/skiplist_test \\\n+\tdb/version_edit_test \\\n+\tdb/version_set_test \\\n+\tdb/write_batch_test \\\n+\thelpers/memenv/memenv_test \\\n+\tissues/issue178_test \\\n+\tissues/issue200_test \\\n+\ttable/filter_block_test \\\n+\ttable/table_test \\\n+\tutil/arena_test \\\n+\tutil/bloom_test \\\n+\tutil/cache_test \\\n+\tutil/coding_test \\\n+\tutil/crc32c_test \\\n+\tutil/env_test \\\n+\tutil/hash_test\n+\n+UTILS = \\\n+\tdb/db_bench \\\n+\tdb/leveldbutil\n+\n+# Put the object files in a subdirectory, but the application at the top of the object dir.\n+PROGNAMES := $(notdir $(TESTS) $(UTILS))\n+\n+# On Linux may need libkyotocabinet-dev for dependency.\n+BENCHMARKS = \\\n+\tdoc/bench/db_bench_sqlite3 \\\n+\tdoc/bench/db_bench_tree_db\n+\n CFLAGS += -I. -I./include $(PLATFORM_CCFLAGS) $(OPT)\n CXXFLAGS += -I. -I./include $(PLATFORM_CXXFLAGS) $(OPT)\n \n LDFLAGS += $(PLATFORM_LDFLAGS)\n LIBS += $(PLATFORM_LIBS)\n \n-LIBOBJECTS = $(SOURCES:.cc=.o)\n-MEMENVOBJECTS = $(MEMENV_SOURCES:.cc=.o)\n-\n-TESTUTIL = ./util/testutil.o\n-TESTHARNESS = ./util/testharness.o $(TESTUTIL)\n+SIMULATOR_OUTDIR=out-ios-x86\n+DEVICE_OUTDIR=out-ios-arm\n \n-# Note: iOS should probably be using libtool, not ar.\n ifeq ($(PLATFORM), IOS)\n+# Note: iOS should probably be using libtool, not ar.\n AR=xcrun ar\n+SIMULATORSDK=$(shell xcrun -sdk iphonesimulator --show-sdk-path)\n+DEVICESDK=$(shell xcrun -sdk iphoneos --show-sdk-path)\n+DEVICE_CFLAGS = -isysroot \"$(DEVICESDK)\" -arch armv6 -arch armv7 -arch armv7s -arch arm64\n+SIMULATOR_CFLAGS = -isysroot \"$(SIMULATORSDK)\" -arch i686 -arch x86_64\n+STATIC_OUTDIR=out-ios-universal\n+else\n+STATIC_OUTDIR=out-static\n+SHARED_OUTDIR=out-shared\n+STATIC_PROGRAMS := $(addprefix $(STATIC_OUTDIR)/, $(PROGNAMES))\n+SHARED_PROGRAMS := $(addprefix $(SHARED_OUTDIR)/, db_bench)\n endif\n \n-TESTS = \\\n-\tarena_test \\\n-\tautocompact_test \\\n-\tbloom_test \\\n-\tc_test \\\n-\tcache_test \\\n-\tcoding_test \\\n-\tcorruption_test \\\n-\tcrc32c_test \\\n-\tdb_test \\\n-\tdbformat_test \\\n-\tenv_test \\\n-\tfilename_test \\\n-\tfilter_block_test \\\n-\thash_test \\\n-\tissue178_test \\\n-\tissue200_test \\\n-\tlog_test \\\n-\tmemenv_test \\\n-\tskiplist_test \\\n-\ttable_test \\\n-\tversion_edit_test \\\n-\tversion_set_test \\\n-\twrite_batch_test\n-\n-PROGRAMS = db_bench leveldbutil $(TESTS)\n-BENCHMARKS = db_bench_sqlite3 db_bench_tree_db\n-\n-LIBRARY = libleveldb.a\n-MEMENVLIBRARY = libmemenv.a\n+STATIC_LIBOBJECTS := $(addprefix $(STATIC_OUTDIR)/, $(SOURCES:.cc=.o))\n+STATIC_MEMENVOBJECTS := $(addprefix $(STATIC_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n+\n+DEVICE_LIBOBJECTS := $(addprefix $(DEVICE_OUTDIR)/, $(SOURCES:.cc=.o))\n+DEVICE_MEMENVOBJECTS := $(addprefix $(DEVICE_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n+\n+SIMULATOR_LIBOBJECTS := $(addprefix $(SIMULATOR_OUTDIR)/, $(SOURCES:.cc=.o))\n+SIMULATOR_MEMENVOBJECTS := $(addprefix $(SIMULATOR_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n+\n+SHARED_LIBOBJECTS := $(addprefix $(SHARED_OUTDIR)/, $(SOURCES:.cc=.o))\n+SHARED_MEMENVOBJECTS := $(addprefix $(SHARED_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n+\n+TESTUTIL := $(STATIC_OUTDIR)/util/testutil.o\n+TESTHARNESS := $(STATIC_OUTDIR)/util/testharness.o $(TESTUTIL)\n+\n+STATIC_TESTOBJS := $(addprefix $(STATIC_OUTDIR)/, $(addsuffix .o, $(TESTS)))\n+STATIC_UTILOBJS := $(addprefix $(STATIC_OUTDIR)/, $(addsuffix .o, $(UTILS)))\n+STATIC_ALLOBJS := $(STATIC_LIBOBJECTS) $(STATIC_MEMENVOBJECTS) $(STATIC_TESTOBJS) $(STATIC_UTILOBJS) $(TESTHARNESS)\n+DEVICE_ALLOBJS := $(DEVICE_LIBOBJECTS) $(DEVICE_MEMENVOBJECTS)\n+SIMULATOR_ALLOBJS := $(SIMULATOR_LIBOBJECTS) $(SIMULATOR_MEMENVOBJECTS)\n \n default: all\n \n # Should we build shared libraries?\n ifneq ($(PLATFORM_SHARED_EXT),)\n \n+# Many leveldb test apps use non-exported API's. Only build a subset for testing.\n+SHARED_ALLOBJS := $(SHARED_LIBOBJECTS) $(SHARED_MEMENVOBJECTS) $(TESTHARNESS)\n+\n ifneq ($(PLATFORM_SHARED_VERSIONED),true)\n-SHARED1 = libleveldb.$(PLATFORM_SHARED_EXT)\n-SHARED2 = $(SHARED1)\n-SHARED3 = $(SHARED1)\n-SHARED = $(SHARED1)\n+SHARED_LIB1 = libleveldb.$(PLATFORM_SHARED_EXT)\n+SHARED_LIB2 = $(SHARED_LIB1)\n+SHARED_LIB3 = $(SHARED_LIB1)\n+SHARED_LIBS = $(SHARED_LIB1)\n+SHARED_MEMENVLIB = $(SHARED_OUTDIR)/libmemenv.a\n else\n # Update db.h if you change these.\n-SHARED_MAJOR = 1\n-SHARED_MINOR = 18\n-SHARED1 = libleveldb.$(PLATFORM_SHARED_EXT)\n-SHARED2 = $(SHARED1).$(SHARED_MAJOR)\n-SHARED3 = $(SHARED1).$(SHARED_MAJOR).$(SHARED_MINOR)\n-SHARED = $(SHARED1) $(SHARED2) $(SHARED3)\n-$(SHARED1): $(SHARED3)\n-\tln -fs $(SHARED3) $(SHARED1)\n-$(SHARED2): $(SHARED3)\n-\tln -fs $(SHARED3) $(SHARED2)\n+SHARED_VERSION_MAJOR = 1\n+SHARED_VERSION_MINOR = 19\n+SHARED_LIB1 = libleveldb.$(PLATFORM_SHARED_EXT)\n+SHARED_LIB2 = $(SHARED_LIB1).$(SHARED_VERSION_MAJOR)\n+SHARED_LIB3 = $(SHARED_LIB1).$(SHARED_VERSION_MAJOR).$(SHARED_VERSION_MINOR)\n+SHARED_LIBS = $(SHARED_OUTDIR)/$(SHARED_LIB1) $(SHARED_OUTDIR)/$(SHARED_LIB2) $(SHARED_OUTDIR)/$(SHARED_LIB3)\n+$(SHARED_OUTDIR)/$(SHARED_LIB1): $(SHARED_OUTDIR)/$(SHARED_LIB3)\n+\tln -fs $(SHARED_LIB3) $(SHARED_OUTDIR)/$(SHARED_LIB1)\n+$(SHARED_OUTDIR)/$(SHARED_LIB2): $(SHARED_OUTDIR)/$(SHARED_LIB3)\n+\tln -fs $(SHARED_LIB3) $(SHARED_OUTDIR)/$(SHARED_LIB2)\n+SHARED_MEMENVLIB = $(SHARED_OUTDIR)/libmemenv.a\n endif\n \n-$(SHARED3):\n-\t$(CXX) $(LDFLAGS) $(PLATFORM_SHARED_LDFLAGS)$(SHARED2) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) $(SOURCES) -o $(SHARED3) $(LIBS)\n+$(SHARED_OUTDIR)/$(SHARED_LIB3): $(SHARED_LIBOBJECTS)\n+\t$(CXX) $(LDFLAGS) $(PLATFORM_SHARED_LDFLAGS)$(SHARED_LIB2) $(SHARED_LIBOBJECTS) -o $(SHARED_OUTDIR)/$(SHARED_LIB3) $(LIBS)\n \n endif  # PLATFORM_SHARED_EXT\n \n-all: $(SHARED) $(LIBRARY)\n+all: $(SHARED_LIBS) $(SHARED_PROGRAMS) $(STATIC_OUTDIR)/libleveldb.a $(STATIC_OUTDIR)/libmemenv.a $(STATIC_PROGRAMS)\n \n-check: all $(PROGRAMS) $(TESTS)\n-\tfor t in $(TESTS); do echo \"***** Running $$t\"; ./$$t || exit 1; done\n+check: $(STATIC_PROGRAMS)\n+\tfor t in $(notdir $(TESTS)); do echo \"***** Running $$t\"; $(STATIC_OUTDIR)/$$t || exit 1; done\n \n clean:\n-\t-rm -f $(PROGRAMS) $(BENCHMARKS) $(LIBRARY) $(SHARED) $(MEMENVLIBRARY) */*.o */*/*.o ios-x86/*/*.o ios-arm/*/*.o build_config.mk\n-\t-rm -rf ios-x86/* ios-arm/*\n+\t-rm -rf out-static out-shared out-ios-x86 out-ios-arm out-ios-universal\n+\t-rm -f build_config.mk\n+\t-rm -rf ios-x86 ios-arm\n \n-$(LIBRARY): $(LIBOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(LIBOBJECTS)\n+$(STATIC_OUTDIR):\n+\tmkdir $@\n \n-db_bench: db/db_bench.o $(LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) db/db_bench.o $(LIBOBJECTS) $(TESTUTIL) -o $@ $(LIBS)\n+$(STATIC_OUTDIR)/db: | $(STATIC_OUTDIR)\n+\tmkdir $@\n \n-db_bench_sqlite3: doc/bench/db_bench_sqlite3.o $(LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) doc/bench/db_bench_sqlite3.o $(LIBOBJECTS) $(TESTUTIL) -o $@ -lsqlite3 $(LIBS)\n+$(STATIC_OUTDIR)/helpers/memenv: | $(STATIC_OUTDIR)\n+\tmkdir -p $@\n \n-db_bench_tree_db: doc/bench/db_bench_tree_db.o $(LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) doc/bench/db_bench_tree_db.o $(LIBOBJECTS) $(TESTUTIL) -o $@ -lkyotocabinet $(LIBS)\n+$(STATIC_OUTDIR)/port: | $(STATIC_OUTDIR)\n+\tmkdir $@\n \n-leveldbutil: db/leveldb_main.o $(LIBOBJECTS)\n-\t$(CXX) $(LDFLAGS) db/leveldb_main.o $(LIBOBJECTS) -o $@ $(LIBS)\n+$(STATIC_OUTDIR)/table: | $(STATIC_OUTDIR)\n+\tmkdir $@\n \n-arena_test: util/arena_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/arena_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(STATIC_OUTDIR)/util: | $(STATIC_OUTDIR)\n+\tmkdir $@\n \n-autocompact_test: db/autocompact_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/autocompact_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+.PHONY: STATIC_OBJDIRS\n+STATIC_OBJDIRS: \\\n+\t$(STATIC_OUTDIR)/db \\\n+\t$(STATIC_OUTDIR)/port \\\n+\t$(STATIC_OUTDIR)/table \\\n+\t$(STATIC_OUTDIR)/util \\\n+\t$(STATIC_OUTDIR)/helpers/memenv\n \n-bloom_test: util/bloom_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/bloom_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR):\n+\tmkdir $@\n \n-c_test: db/c_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/c_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR)/db: | $(SHARED_OUTDIR)\n+\tmkdir $@\n \n-cache_test: util/cache_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/cache_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR)/helpers/memenv: | $(SHARED_OUTDIR)\n+\tmkdir -p $@\n \n-coding_test: util/coding_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/coding_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR)/port: | $(SHARED_OUTDIR)\n+\tmkdir $@\n \n-corruption_test: db/corruption_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/corruption_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR)/table: | $(SHARED_OUTDIR)\n+\tmkdir $@\n \n-crc32c_test: util/crc32c_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/crc32c_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SHARED_OUTDIR)/util: | $(SHARED_OUTDIR)\n+\tmkdir $@\n \n-db_test: db/db_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/db_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+.PHONY: SHARED_OBJDIRS\n+SHARED_OBJDIRS: \\\n+\t$(SHARED_OUTDIR)/db \\\n+\t$(SHARED_OUTDIR)/port \\\n+\t$(SHARED_OUTDIR)/table \\\n+\t$(SHARED_OUTDIR)/util \\\n+\t$(SHARED_OUTDIR)/helpers/memenv\n \n-dbformat_test: db/dbformat_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/dbformat_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR):\n+\tmkdir $@\n \n-env_test: util/env_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/env_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR)/db: | $(DEVICE_OUTDIR)\n+\tmkdir $@\n \n-filename_test: db/filename_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/filename_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR)/helpers/memenv: | $(DEVICE_OUTDIR)\n+\tmkdir -p $@\n \n-filter_block_test: table/filter_block_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) table/filter_block_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR)/port: | $(DEVICE_OUTDIR)\n+\tmkdir $@\n \n-hash_test: util/hash_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) util/hash_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR)/table: | $(DEVICE_OUTDIR)\n+\tmkdir $@\n \n-issue178_test: issues/issue178_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) issues/issue178_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(DEVICE_OUTDIR)/util: | $(DEVICE_OUTDIR)\n+\tmkdir $@\n \n-issue200_test: issues/issue200_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) issues/issue200_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+.PHONY: DEVICE_OBJDIRS\n+DEVICE_OBJDIRS: \\\n+\t$(DEVICE_OUTDIR)/db \\\n+\t$(DEVICE_OUTDIR)/port \\\n+\t$(DEVICE_OUTDIR)/table \\\n+\t$(DEVICE_OUTDIR)/util \\\n+\t$(DEVICE_OUTDIR)/helpers/memenv\n \n-log_test: db/log_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/log_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR):\n+\tmkdir $@\n \n-table_test: table/table_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) table/table_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR)/db: | $(SIMULATOR_OUTDIR)\n+\tmkdir $@\n \n-skiplist_test: db/skiplist_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/skiplist_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR)/helpers/memenv: | $(SIMULATOR_OUTDIR)\n+\tmkdir -p $@\n \n-version_edit_test: db/version_edit_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/version_edit_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR)/port: | $(SIMULATOR_OUTDIR)\n+\tmkdir $@\n \n-version_set_test: db/version_set_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/version_set_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR)/table: | $(SIMULATOR_OUTDIR)\n+\tmkdir $@\n \n-write_batch_test: db/write_batch_test.o $(LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) db/write_batch_test.o $(LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+$(SIMULATOR_OUTDIR)/util: | $(SIMULATOR_OUTDIR)\n+\tmkdir $@\n \n-$(MEMENVLIBRARY) : $(MEMENVOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(MEMENVOBJECTS)\n+.PHONY: SIMULATOR_OBJDIRS\n+SIMULATOR_OBJDIRS: \\\n+\t$(SIMULATOR_OUTDIR)/db \\\n+\t$(SIMULATOR_OUTDIR)/port \\\n+\t$(SIMULATOR_OUTDIR)/table \\\n+\t$(SIMULATOR_OUTDIR)/util \\\n+\t$(SIMULATOR_OUTDIR)/helpers/memenv\n \n-memenv_test : helpers/memenv/memenv_test.o $(MEMENVLIBRARY) $(LIBRARY) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) helpers/memenv/memenv_test.o $(MEMENVLIBRARY) $(LIBRARY) $(TESTHARNESS) -o $@ $(LIBS)\n+$(STATIC_ALLOBJS): | STATIC_OBJDIRS\n+$(DEVICE_ALLOBJS): | DEVICE_OBJDIRS\n+$(SIMULATOR_ALLOBJS): | SIMULATOR_OBJDIRS\n+$(SHARED_ALLOBJS): | SHARED_OBJDIRS\n \n ifeq ($(PLATFORM), IOS)\n-# For iOS, create universal object files to be used on both the simulator and\n+$(DEVICE_OUTDIR)/libleveldb.a: $(DEVICE_LIBOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(DEVICE_LIBOBJECTS)\n+\n+$(SIMULATOR_OUTDIR)/libleveldb.a: $(SIMULATOR_LIBOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(SIMULATOR_LIBOBJECTS)\n+\n+$(DEVICE_OUTDIR)/libmemenv.a: $(DEVICE_MEMENVOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(DEVICE_MEMENVOBJECTS)\n+\n+$(SIMULATOR_OUTDIR)/libmemenv.a: $(SIMULATOR_MEMENVOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(SIMULATOR_MEMENVOBJECTS)\n+\n+# For iOS, create universal object libraries to be used on both the simulator and\n # a device.\n-PLATFORMSROOT=/Applications/Xcode.app/Contents/Developer/Platforms\n-SIMULATORROOT=$(PLATFORMSROOT)/iPhoneSimulator.platform/Developer\n-DEVICEROOT=$(PLATFORMSROOT)/iPhoneOS.platform/Developer\n-IOSVERSION=$(shell defaults read $(PLATFORMSROOT)/iPhoneOS.platform/version CFBundleShortVersionString)\n-IOSARCH=-arch armv6 -arch armv7 -arch armv7s -arch arm64\n-\n-.cc.o:\n-\tmkdir -p ios-x86/$(dir $@)\n-\txcrun -sdk iphonesimulator $(CXX) $(CXXFLAGS) -isysroot $(SIMULATORROOT)/SDKs/iPhoneSimulator$(IOSVERSION).sdk -arch i686 -arch x86_64 -c $< -o ios-x86/$@\n-\tmkdir -p ios-arm/$(dir $@)\n-\txcrun -sdk iphoneos $(CXX) $(CXXFLAGS) -isysroot $(DEVICEROOT)/SDKs/iPhoneOS$(IOSVERSION).sdk $(IOSARCH) -c $< -o ios-arm/$@\n-\txcrun lipo ios-x86/$@ ios-arm/$@ -create -output $@\n-\n-.c.o:\n-\tmkdir -p ios-x86/$(dir $@)\n-\txcrun -sdk iphonesimulator $(CC) $(CFLAGS) -isysroot $(SIMULATORROOT)/SDKs/iPhoneSimulator$(IOSVERSION).sdk -arch i686 -arch x86_64 -c $< -o ios-x86/$@\n-\tmkdir -p ios-arm/$(dir $@)\n-\txcrun -sdk iphoneos $(CC) $(CFLAGS) -isysroot $(DEVICEROOT)/SDKs/iPhoneOS$(IOSVERSION).sdk $(IOSARCH) -c $< -o ios-arm/$@\n-\txcrun lipo ios-x86/$@ ios-arm/$@ -create -output $@\n+$(STATIC_OUTDIR)/libleveldb.a: $(STATIC_OUTDIR) $(DEVICE_OUTDIR)/libleveldb.a $(SIMULATOR_OUTDIR)/libleveldb.a\n+\tlipo -create $(DEVICE_OUTDIR)/libleveldb.a $(SIMULATOR_OUTDIR)/libleveldb.a -output $@\n \n+$(STATIC_OUTDIR)/libmemenv.a: $(STATIC_OUTDIR) $(DEVICE_OUTDIR)/libmemenv.a $(SIMULATOR_OUTDIR)/libmemenv.a\n+\tlipo -create $(DEVICE_OUTDIR)/libmemenv.a $(SIMULATOR_OUTDIR)/libmemenv.a -output $@\n else\n-.cc.o:\n+$(STATIC_OUTDIR)/libleveldb.a:$(STATIC_LIBOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(STATIC_LIBOBJECTS)\n+\n+$(STATIC_OUTDIR)/libmemenv.a:$(STATIC_MEMENVOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(STATIC_MEMENVOBJECTS)\n+endif\n+\n+$(SHARED_MEMENVLIB):$(SHARED_MEMENVOBJECTS)\n+\trm -f $@\n+\t$(AR) -rs $@ $(SHARED_MEMENVOBJECTS)\n+\n+$(STATIC_OUTDIR)/db_bench:db/db_bench.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/db_bench.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/db_bench_sqlite3:doc/bench/db_bench_sqlite3.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) doc/bench/db_bench_sqlite3.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ -lsqlite3 $(LIBS)\n+\n+$(STATIC_OUTDIR)/db_bench_tree_db:doc/bench/db_bench_tree_db.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) doc/bench/db_bench_tree_db.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ -lkyotocabinet $(LIBS)\n+\n+$(STATIC_OUTDIR)/leveldbutil:db/leveldbutil.cc $(STATIC_LIBOBJECTS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/leveldbutil.cc $(STATIC_LIBOBJECTS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/arena_test:util/arena_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/arena_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/autocompact_test:db/autocompact_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/autocompact_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/bloom_test:util/bloom_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/bloom_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/c_test:$(STATIC_OUTDIR)/db/c_test.o $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(STATIC_OUTDIR)/db/c_test.o $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/cache_test:util/cache_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/cache_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/coding_test:util/coding_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/coding_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/corruption_test:db/corruption_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/corruption_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/crc32c_test:util/crc32c_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/crc32c_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/db_test:db/db_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/db_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/dbformat_test:db/dbformat_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/dbformat_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/env_test:util/env_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/env_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/fault_injection_test:db/fault_injection_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/fault_injection_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/filename_test:db/filename_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/filename_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/filter_block_test:table/filter_block_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) table/filter_block_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/hash_test:util/hash_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/hash_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/issue178_test:issues/issue178_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) issues/issue178_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/issue200_test:issues/issue200_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) issues/issue200_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/log_test:db/log_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/log_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/recovery_test:db/recovery_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/recovery_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/table_test:table/table_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) table/table_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/skiplist_test:db/skiplist_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/skiplist_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/version_edit_test:db/version_edit_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/version_edit_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/version_set_test:db/version_set_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/version_set_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/write_batch_test:db/write_batch_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n+\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/write_batch_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(STATIC_OUTDIR)/memenv_test:$(STATIC_OUTDIR)/helpers/memenv/memenv_test.o $(STATIC_OUTDIR)/libmemenv.a $(STATIC_OUTDIR)/libleveldb.a $(TESTHARNESS)\n+\t$(XCRUN) $(CXX) $(LDFLAGS) $(STATIC_OUTDIR)/helpers/memenv/memenv_test.o $(STATIC_OUTDIR)/libmemenv.a $(STATIC_OUTDIR)/libleveldb.a $(TESTHARNESS) -o $@ $(LIBS)\n+\n+$(SHARED_OUTDIR)/db_bench:$(SHARED_OUTDIR)/db/db_bench.o $(SHARED_LIBS) $(TESTUTIL)\n+\t$(XCRUN) $(CXX) $(LDFLAGS) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) $(SHARED_OUTDIR)/db/db_bench.o $(TESTUTIL) $(SHARED_OUTDIR)/$(SHARED_LIB3) -o $@ $(LIBS)\n+\n+.PHONY: run-shared\n+run-shared: $(SHARED_OUTDIR)/db_bench\n+\tLD_LIBRARY_PATH=$(SHARED_OUTDIR) $(SHARED_OUTDIR)/db_bench\n+\n+$(SIMULATOR_OUTDIR)/%.o: %.cc\n+\txcrun -sdk iphonesimulator $(CXX) $(CXXFLAGS) $(SIMULATOR_CFLAGS) -c $< -o $@\n+\n+$(DEVICE_OUTDIR)/%.o: %.cc\n+\txcrun -sdk iphoneos $(CXX) $(CXXFLAGS) $(DEVICE_CFLAGS) -c $< -o $@\n+\n+$(SIMULATOR_OUTDIR)/%.o: %.c\n+\txcrun -sdk iphonesimulator $(CC) $(CFLAGS) $(SIMULATOR_CFLAGS) -c $< -o $@\n+\n+$(DEVICE_OUTDIR)/%.o: %.c\n+\txcrun -sdk iphoneos $(CC) $(CFLAGS) $(DEVICE_CFLAGS) -c $< -o $@\n+\n+$(STATIC_OUTDIR)/%.o: %.cc\n \t$(CXX) $(CXXFLAGS) -c $< -o $@\n \n-.c.o:\n+$(STATIC_OUTDIR)/%.o: %.c\n \t$(CC) $(CFLAGS) -c $< -o $@\n-endif\n+\n+$(SHARED_OUTDIR)/%.o: %.cc\n+\t$(CXX) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) -c $< -o $@\n+\n+$(SHARED_OUTDIR)/%.o: %.c\n+\t$(CC) $(CFLAGS) $(PLATFORM_SHARED_CFLAGS) -c $< -o $@"
      },
      {
        "sha": "3618adeeedbea04a14e00d5a1ef33dd4f0a7be06",
        "filename": "src/leveldb/README",
        "status": "removed",
        "additions": 0,
        "deletions": 51,
        "changes": 51,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/dc6dee41f7cf2ba93fcd0fea7c157e4b2775d439/src/leveldb/README",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/dc6dee41f7cf2ba93fcd0fea7c157e4b2775d439/src/leveldb/README",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/README?ref=dc6dee41f7cf2ba93fcd0fea7c157e4b2775d439",
        "patch": "@@ -1,51 +0,0 @@\n-leveldb: A key-value store\n-Authors: Sanjay Ghemawat (sanjay@google.com) and Jeff Dean (jeff@google.com)\n-\n-The code under this directory implements a system for maintaining a\n-persistent key/value store.\n-\n-See doc/index.html for more explanation.\n-See doc/impl.html for a brief overview of the implementation.\n-\n-The public interface is in include/*.h.  Callers should not include or\n-rely on the details of any other header files in this package.  Those\n-internal APIs may be changed without warning.\n-\n-Guide to header files:\n-\n-include/db.h\n-    Main interface to the DB: Start here\n-\n-include/options.h\n-    Control over the behavior of an entire database, and also\n-    control over the behavior of individual reads and writes.\n-\n-include/comparator.h\n-    Abstraction for user-specified comparison function.  If you want\n-    just bytewise comparison of keys, you can use the default comparator,\n-    but clients can write their own comparator implementations if they\n-    want custom ordering (e.g. to handle different character\n-    encodings, etc.)\n-\n-include/iterator.h\n-    Interface for iterating over data. You can get an iterator\n-    from a DB object.\n-\n-include/write_batch.h\n-    Interface for atomically applying multiple updates to a database.\n-\n-include/slice.h\n-    A simple module for maintaining a pointer and a length into some\n-    other byte array.\n-\n-include/status.h\n-    Status is returned from many of the public interfaces and is used\n-    to report success and various kinds of errors.\n-\n-include/env.h\n-    Abstraction of the OS environment.  A posix implementation of\n-    this interface is in util/env_posix.cc\n-\n-include/table.h\n-include/table_builder.h\n-    Lower-level modules that most clients probably won't use directly"
      },
      {
        "sha": "c75b185e0e7466a3eba439b571d37cdb63b7e660",
        "filename": "src/leveldb/README.md",
        "status": "modified",
        "additions": 37,
        "deletions": 2,
        "changes": 39,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/README.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/README.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/README.md?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -1,5 +1,7 @@\n **LevelDB is a fast key-value storage library written at Google that provides an ordered mapping from string keys to string values.**\n \n+[![Build Status](https://travis-ci.org/google/leveldb.svg?branch=master)](https://travis-ci.org/google/leveldb)\n+\n Authors: Sanjay Ghemawat (sanjay@google.com) and Jeff Dean (jeff@google.com)\n \n # Features\n@@ -10,16 +12,49 @@ Authors: Sanjay Ghemawat (sanjay@google.com) and Jeff Dean (jeff@google.com)\n   * Multiple changes can be made in one atomic batch.\n   * Users can create a transient snapshot to get a consistent view of data.\n   * Forward and backward iteration is supported over the data.\n-  * Data is automatically compressed using the [Snappy compression library](http://code.google.com/p/snappy).\n+  * Data is automatically compressed using the [Snappy compression library](http://google.github.io/snappy/).\n   * External activity (file system operations etc.) is relayed through a virtual interface so users can customize the operating system interactions.\n-  * [Detailed documentation](http://htmlpreview.github.io/?https://github.com/google/leveldb/blob/master/doc/index.html) about how to use the library is included with the source code.\n+\n+# Documentation\n+  [LevelDB library documentation](https://rawgit.com/google/leveldb/master/doc/index.html) is online and bundled with the source code.\n \n \n # Limitations\n   * This is not a SQL database.  It does not have a relational data model, it does not support SQL queries, and it has no support for indexes.\n   * Only a single process (possibly multi-threaded) can access a particular database at a time.\n   * There is no client-server support builtin to the library.  An application that needs such support will have to wrap their own server around the library.\n \n+# Contributing to the leveldb Project\n+The leveldb project welcomes contributions. leveldb's primary goal is to be\n+a reliable and fast key/value store. Changes that are in line with the\n+features/limitations outlined above, and meet the requirements below,\n+will be considered.\n+\n+Contribution requirements:\n+\n+1. **POSIX only**. We _generally_ will only accept changes that are both\n+   compiled, and tested on a POSIX platform - usually Linux. Very small\n+   changes will sometimes be accepted, but consider that more of an\n+   exception than the rule.\n+\n+2. **Stable API**. We strive very hard to maintain a stable API. Changes that\n+   require changes for projects using leveldb _might_ be rejected without\n+   sufficient benefit to the project.\n+\n+3. **Tests**: All changes must be accompanied by a new (or changed) test, or\n+   a sufficient explanation as to why a new (or changed) test is not required.\n+\n+## Submitting a Pull Request\n+Before any pull request will be accepted the author must first sign a\n+Contributor License Agreement (CLA) at https://cla.developers.google.com/.\n+\n+In order to keep the commit timeline linear\n+[squash](https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History#Squashing-Commits)\n+your changes down to a single commit and [rebase](https://git-scm.com/docs/git-rebase)\n+on google/leveldb/master. This keeps the commit timeline linear and more easily sync'ed\n+with the internal repository at Google. More information at GitHub's\n+[About Git rebase](https://help.github.com/articles/about-git-rebase/) page.\n+\n # Performance\n \n Here is a performance report (with explanations) from the run of the"
      },
      {
        "sha": "d7edab1d87bb50cb1b882db87ae2bae22959c9f7",
        "filename": "src/leveldb/build_detect_platform",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/build_detect_platform",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/build_detect_platform",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/build_detect_platform?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -175,7 +175,7 @@ DIRS=\"$PREFIX/db $PREFIX/util $PREFIX/table\"\n set -f # temporarily disable globbing so that our patterns aren't expanded\n PRUNE_TEST=\"-name *test*.cc -prune\"\n PRUNE_BENCH=\"-name *_bench.cc -prune\"\n-PRUNE_TOOL=\"-name leveldb_main.cc -prune\"\n+PRUNE_TOOL=\"-name leveldbutil.cc -prune\"\n PORTABLE_FILES=`find $DIRS $PRUNE_TEST -o $PRUNE_BENCH -o $PRUNE_TOOL -o -name '*.cc' -print | sort | sed \"s,^$PREFIX/,,\" | tr \"\\n\" \" \"`\n \n set +f # re-enable globbing"
      },
      {
        "sha": "37a484d25fea2d401b6956ae246b9365e7b8aa8e",
        "filename": "src/leveldb/db/corruption_test.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/corruption_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/corruption_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/corruption_test.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -36,7 +36,7 @@ class CorruptionTest {\n     tiny_cache_ = NewLRUCache(100);\n     options_.env = &env_;\n     options_.block_cache = tiny_cache_;\n-    dbname_ = test::TmpDir() + \"/db_test\";\n+    dbname_ = test::TmpDir() + \"/corruption_test\";\n     DestroyDB(dbname_, options_);\n \n     db_ = NULL;"
      },
      {
        "sha": "7a0f5e08cdd58672ee69527bcbef72ac869c9189",
        "filename": "src/leveldb/db/db_bench.cc",
        "status": "modified",
        "additions": 23,
        "deletions": 1,
        "changes": 24,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/db_bench.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/db_bench.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/db_bench.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -33,6 +33,7 @@\n //      readmissing   -- read N missing keys in random order\n //      readhot       -- read N times in random order from 1% section of DB\n //      seekrandom    -- N random seeks\n+//      open          -- cost of opening a DB\n //      crc32c        -- repeated crc32c of 4K of data\n //      acquireload   -- load N*1000 times\n //   Meta operations:\n@@ -99,6 +100,9 @@ static int FLAGS_bloom_bits = -1;\n // benchmark will fail.\n static bool FLAGS_use_existing_db = false;\n \n+// If true, reuse existing log/MANIFEST files when re-opening a database.\n+static bool FLAGS_reuse_logs = false;\n+\n // Use the db with the following name.\n static const char* FLAGS_db = NULL;\n \n@@ -138,6 +142,7 @@ class RandomGenerator {\n   }\n };\n \n+#if defined(__linux)\n static Slice TrimSpace(Slice s) {\n   size_t start = 0;\n   while (start < s.size() && isspace(s[start])) {\n@@ -149,6 +154,7 @@ static Slice TrimSpace(Slice s) {\n   }\n   return Slice(s.data() + start, limit - start);\n }\n+#endif\n \n static void AppendWithSpace(std::string* str, Slice msg) {\n   if (msg.empty()) return;\n@@ -442,7 +448,11 @@ class Benchmark {\n       bool fresh_db = false;\n       int num_threads = FLAGS_threads;\n \n-      if (name == Slice(\"fillseq\")) {\n+      if (name == Slice(\"open\")) {\n+        method = &Benchmark::OpenBench;\n+        num_ /= 10000;\n+        if (num_ < 1) num_ = 1;\n+      } else if (name == Slice(\"fillseq\")) {\n         fresh_db = true;\n         method = &Benchmark::WriteSeq;\n       } else if (name == Slice(\"fillbatch\")) {\n@@ -695,13 +705,22 @@ class Benchmark {\n     options.write_buffer_size = FLAGS_write_buffer_size;\n     options.max_open_files = FLAGS_open_files;\n     options.filter_policy = filter_policy_;\n+    options.reuse_logs = FLAGS_reuse_logs;\n     Status s = DB::Open(options, FLAGS_db, &db_);\n     if (!s.ok()) {\n       fprintf(stderr, \"open error: %s\\n\", s.ToString().c_str());\n       exit(1);\n     }\n   }\n \n+  void OpenBench(ThreadState* thread) {\n+    for (int i = 0; i < num_; i++) {\n+      delete db_;\n+      Open();\n+      thread->stats.FinishedSingleOp();\n+    }\n+  }\n+\n   void WriteSeq(ThreadState* thread) {\n     DoWrite(thread, true);\n   }\n@@ -941,6 +960,9 @@ int main(int argc, char** argv) {\n     } else if (sscanf(argv[i], \"--use_existing_db=%d%c\", &n, &junk) == 1 &&\n                (n == 0 || n == 1)) {\n       FLAGS_use_existing_db = n;\n+    } else if (sscanf(argv[i], \"--reuse_logs=%d%c\", &n, &junk) == 1 &&\n+               (n == 0 || n == 1)) {\n+      FLAGS_reuse_logs = n;\n     } else if (sscanf(argv[i], \"--num=%d%c\", &n, &junk) == 1) {\n       FLAGS_num = n;\n     } else if (sscanf(argv[i], \"--reads=%d%c\", &n, &junk) == 1) {"
      },
      {
        "sha": "60f4e66e55796756eff2586ecb1f8a9f688b2783",
        "filename": "src/leveldb/db/db_impl.cc",
        "status": "modified",
        "additions": 124,
        "deletions": 70,
        "changes": 194,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/db_impl.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/db_impl.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/db_impl.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -125,7 +125,7 @@ DBImpl::DBImpl(const Options& raw_options, const std::string& dbname)\n       db_lock_(NULL),\n       shutting_down_(NULL),\n       bg_cv_(&mutex_),\n-      mem_(new MemTable(internal_comparator_)),\n+      mem_(NULL),\n       imm_(NULL),\n       logfile_(NULL),\n       logfile_number_(0),\n@@ -134,7 +134,6 @@ DBImpl::DBImpl(const Options& raw_options, const std::string& dbname)\n       tmp_batch_(new WriteBatch),\n       bg_compaction_scheduled_(false),\n       manual_compaction_(NULL) {\n-  mem_->Ref();\n   has_imm_.Release_Store(NULL);\n \n   // Reserve ten files or so for other uses and give the rest to TableCache.\n@@ -271,7 +270,7 @@ void DBImpl::DeleteObsoleteFiles() {\n   }\n }\n \n-Status DBImpl::Recover(VersionEdit* edit) {\n+Status DBImpl::Recover(VersionEdit* edit, bool *save_manifest) {\n   mutex_.AssertHeld();\n \n   // Ignore error from CreateDir since the creation of the DB is\n@@ -301,66 +300,69 @@ Status DBImpl::Recover(VersionEdit* edit) {\n     }\n   }\n \n-  s = versions_->Recover();\n-  if (s.ok()) {\n-    SequenceNumber max_sequence(0);\n-\n-    // Recover from all newer log files than the ones named in the\n-    // descriptor (new log files may have been added by the previous\n-    // incarnation without registering them in the descriptor).\n-    //\n-    // Note that PrevLogNumber() is no longer used, but we pay\n-    // attention to it in case we are recovering a database\n-    // produced by an older version of leveldb.\n-    const uint64_t min_log = versions_->LogNumber();\n-    const uint64_t prev_log = versions_->PrevLogNumber();\n-    std::vector<std::string> filenames;\n-    s = env_->GetChildren(dbname_, &filenames);\n+  s = versions_->Recover(save_manifest);\n+  if (!s.ok()) {\n+    return s;\n+  }\n+  SequenceNumber max_sequence(0);\n+\n+  // Recover from all newer log files than the ones named in the\n+  // descriptor (new log files may have been added by the previous\n+  // incarnation without registering them in the descriptor).\n+  //\n+  // Note that PrevLogNumber() is no longer used, but we pay\n+  // attention to it in case we are recovering a database\n+  // produced by an older version of leveldb.\n+  const uint64_t min_log = versions_->LogNumber();\n+  const uint64_t prev_log = versions_->PrevLogNumber();\n+  std::vector<std::string> filenames;\n+  s = env_->GetChildren(dbname_, &filenames);\n+  if (!s.ok()) {\n+    return s;\n+  }\n+  std::set<uint64_t> expected;\n+  versions_->AddLiveFiles(&expected);\n+  uint64_t number;\n+  FileType type;\n+  std::vector<uint64_t> logs;\n+  for (size_t i = 0; i < filenames.size(); i++) {\n+    if (ParseFileName(filenames[i], &number, &type)) {\n+      expected.erase(number);\n+      if (type == kLogFile && ((number >= min_log) || (number == prev_log)))\n+        logs.push_back(number);\n+    }\n+  }\n+  if (!expected.empty()) {\n+    char buf[50];\n+    snprintf(buf, sizeof(buf), \"%d missing files; e.g.\",\n+             static_cast<int>(expected.size()));\n+    return Status::Corruption(buf, TableFileName(dbname_, *(expected.begin())));\n+  }\n+\n+  // Recover in the order in which the logs were generated\n+  std::sort(logs.begin(), logs.end());\n+  for (size_t i = 0; i < logs.size(); i++) {\n+    s = RecoverLogFile(logs[i], (i == logs.size() - 1), save_manifest, edit,\n+                       &max_sequence);\n     if (!s.ok()) {\n       return s;\n     }\n-    std::set<uint64_t> expected;\n-    versions_->AddLiveFiles(&expected);\n-    uint64_t number;\n-    FileType type;\n-    std::vector<uint64_t> logs;\n-    for (size_t i = 0; i < filenames.size(); i++) {\n-      if (ParseFileName(filenames[i], &number, &type)) {\n-        expected.erase(number);\n-        if (type == kLogFile && ((number >= min_log) || (number == prev_log)))\n-          logs.push_back(number);\n-      }\n-    }\n-    if (!expected.empty()) {\n-      char buf[50];\n-      snprintf(buf, sizeof(buf), \"%d missing files; e.g.\",\n-               static_cast<int>(expected.size()));\n-      return Status::Corruption(buf, TableFileName(dbname_, *(expected.begin())));\n-    }\n-\n-    // Recover in the order in which the logs were generated\n-    std::sort(logs.begin(), logs.end());\n-    for (size_t i = 0; i < logs.size(); i++) {\n-      s = RecoverLogFile(logs[i], edit, &max_sequence);\n \n-      // The previous incarnation may not have written any MANIFEST\n-      // records after allocating this log number.  So we manually\n-      // update the file number allocation counter in VersionSet.\n-      versions_->MarkFileNumberUsed(logs[i]);\n-    }\n+    // The previous incarnation may not have written any MANIFEST\n+    // records after allocating this log number.  So we manually\n+    // update the file number allocation counter in VersionSet.\n+    versions_->MarkFileNumberUsed(logs[i]);\n+  }\n \n-    if (s.ok()) {\n-      if (versions_->LastSequence() < max_sequence) {\n-        versions_->SetLastSequence(max_sequence);\n-      }\n-    }\n+  if (versions_->LastSequence() < max_sequence) {\n+    versions_->SetLastSequence(max_sequence);\n   }\n \n-  return s;\n+  return Status::OK();\n }\n \n-Status DBImpl::RecoverLogFile(uint64_t log_number,\n-                              VersionEdit* edit,\n+Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log,\n+                              bool* save_manifest, VersionEdit* edit,\n                               SequenceNumber* max_sequence) {\n   struct LogReporter : public log::Reader::Reporter {\n     Env* env;\n@@ -405,6 +407,7 @@ Status DBImpl::RecoverLogFile(uint64_t log_number,\n   std::string scratch;\n   Slice record;\n   WriteBatch batch;\n+  int compactions = 0;\n   MemTable* mem = NULL;\n   while (reader.ReadRecord(&record, &scratch) &&\n          status.ok()) {\n@@ -432,25 +435,52 @@ Status DBImpl::RecoverLogFile(uint64_t log_number,\n     }\n \n     if (mem->ApproximateMemoryUsage() > options_.write_buffer_size) {\n+      compactions++;\n+      *save_manifest = true;\n       status = WriteLevel0Table(mem, edit, NULL);\n+      mem->Unref();\n+      mem = NULL;\n       if (!status.ok()) {\n         // Reflect errors immediately so that conditions like full\n         // file-systems cause the DB::Open() to fail.\n         break;\n       }\n-      mem->Unref();\n-      mem = NULL;\n     }\n   }\n \n-  if (status.ok() && mem != NULL) {\n-    status = WriteLevel0Table(mem, edit, NULL);\n-    // Reflect errors immediately so that conditions like full\n-    // file-systems cause the DB::Open() to fail.\n+  delete file;\n+\n+  // See if we should keep reusing the last log file.\n+  if (status.ok() && options_.reuse_logs && last_log && compactions == 0) {\n+    assert(logfile_ == NULL);\n+    assert(log_ == NULL);\n+    assert(mem_ == NULL);\n+    uint64_t lfile_size;\n+    if (env_->GetFileSize(fname, &lfile_size).ok() &&\n+        env_->NewAppendableFile(fname, &logfile_).ok()) {\n+      Log(options_.info_log, \"Reusing old log %s \\n\", fname.c_str());\n+      log_ = new log::Writer(logfile_, lfile_size);\n+      logfile_number_ = log_number;\n+      if (mem != NULL) {\n+        mem_ = mem;\n+        mem = NULL;\n+      } else {\n+        // mem can be NULL if lognum exists but was empty.\n+        mem_ = new MemTable(internal_comparator_);\n+        mem_->Ref();\n+      }\n+    }\n+  }\n+\n+  if (mem != NULL) {\n+    // mem did not get reused; compact it.\n+    if (status.ok()) {\n+      *save_manifest = true;\n+      status = WriteLevel0Table(mem, edit, NULL);\n+    }\n+    mem->Unref();\n   }\n \n-  if (mem != NULL) mem->Unref();\n-  delete file;\n   return status;\n }\n \n@@ -821,8 +851,9 @@ Status DBImpl::FinishCompactionOutputFile(CompactionState* compact,\n     delete iter;\n     if (s.ok()) {\n       Log(options_.info_log,\n-          \"Generated table #%llu: %lld keys, %lld bytes\",\n+          \"Generated table #%llu@%d: %lld keys, %lld bytes\",\n           (unsigned long long) output_number,\n+          compact->compaction->level(),\n           (unsigned long long) current_entries,\n           (unsigned long long) current_bytes);\n     }\n@@ -1395,6 +1426,19 @@ bool DBImpl::GetProperty(const Slice& property, std::string* value) {\n   } else if (in == \"sstables\") {\n     *value = versions_->current()->DebugString();\n     return true;\n+  } else if (in == \"approximate-memory-usage\") {\n+    size_t total_usage = options_.block_cache->TotalCharge();\n+    if (mem_) {\n+      total_usage += mem_->ApproximateMemoryUsage();\n+    }\n+    if (imm_) {\n+      total_usage += imm_->ApproximateMemoryUsage();\n+    }\n+    char buf[50];\n+    snprintf(buf, sizeof(buf), \"%llu\",\n+             static_cast<unsigned long long>(total_usage));\n+    value->append(buf);\n+    return true;\n   }\n \n   return false;\n@@ -1449,8 +1493,11 @@ Status DB::Open(const Options& options, const std::string& dbname,\n   DBImpl* impl = new DBImpl(options, dbname);\n   impl->mutex_.Lock();\n   VersionEdit edit;\n-  Status s = impl->Recover(&edit); // Handles create_if_missing, error_if_exists\n-  if (s.ok()) {\n+  // Recover handles create_if_missing, error_if_exists\n+  bool save_manifest = false;\n+  Status s = impl->Recover(&edit, &save_manifest);\n+  if (s.ok() && impl->mem_ == NULL) {\n+    // Create new log and a corresponding memtable.\n     uint64_t new_log_number = impl->versions_->NewFileNumber();\n     WritableFile* lfile;\n     s = options.env->NewWritableFile(LogFileName(dbname, new_log_number),\n@@ -1460,15 +1507,22 @@ Status DB::Open(const Options& options, const std::string& dbname,\n       impl->logfile_ = lfile;\n       impl->logfile_number_ = new_log_number;\n       impl->log_ = new log::Writer(lfile);\n-      s = impl->versions_->LogAndApply(&edit, &impl->mutex_);\n-    }\n-    if (s.ok()) {\n-      impl->DeleteObsoleteFiles();\n-      impl->MaybeScheduleCompaction();\n+      impl->mem_ = new MemTable(impl->internal_comparator_);\n+      impl->mem_->Ref();\n     }\n   }\n+  if (s.ok() && save_manifest) {\n+    edit.SetPrevLogNumber(0);  // No older logs needed after recovery.\n+    edit.SetLogNumber(impl->logfile_number_);\n+    s = impl->versions_->LogAndApply(&edit, &impl->mutex_);\n+  }\n+  if (s.ok()) {\n+    impl->DeleteObsoleteFiles();\n+    impl->MaybeScheduleCompaction();\n+  }\n   impl->mutex_.Unlock();\n   if (s.ok()) {\n+    assert(impl->mem_ != NULL);\n     *dbptr = impl;\n   } else {\n     delete impl;"
      },
      {
        "sha": "8ff323e72879967a9ff27876155a21ffb2330d3d",
        "filename": "src/leveldb/db/db_impl.h",
        "status": "modified",
        "additions": 4,
        "deletions": 4,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/db_impl.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/db_impl.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/db_impl.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -78,7 +78,8 @@ class DBImpl : public DB {\n   // Recover the descriptor from persistent storage.  May do a significant\n   // amount of work to recover recently logged updates.  Any changes to\n   // be made to the descriptor are added to *edit.\n-  Status Recover(VersionEdit* edit) EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n+  Status Recover(VersionEdit* edit, bool* save_manifest)\n+      EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n   void MaybeIgnoreError(Status* s) const;\n \n@@ -90,9 +91,8 @@ class DBImpl : public DB {\n   // Errors are recorded in bg_error_.\n   void CompactMemTable() EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n-  Status RecoverLogFile(uint64_t log_number,\n-                        VersionEdit* edit,\n-                        SequenceNumber* max_sequence)\n+  Status RecoverLogFile(uint64_t log_number, bool last_log, bool* save_manifest,\n+                        VersionEdit* edit, SequenceNumber* max_sequence)\n       EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n   Status WriteLevel0Table(MemTable* mem, VersionEdit* edit, Version* base)"
      },
      {
        "sha": "a0b08bc19c6510322dc65a94e135fa17ee922659",
        "filename": "src/leveldb/db/db_test.cc",
        "status": "modified",
        "additions": 31,
        "deletions": 1,
        "changes": 32,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/db_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/db_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/db_test.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -193,6 +193,7 @@ class DBTest {\n   // Sequence of option configurations to try\n   enum OptionConfig {\n     kDefault,\n+    kReuse,\n     kFilter,\n     kUncompressed,\n     kEnd\n@@ -237,7 +238,11 @@ class DBTest {\n   // Return the current option configuration.\n   Options CurrentOptions() {\n     Options options;\n+    options.reuse_logs = false;\n     switch (option_config_) {\n+      case kReuse:\n+        options.reuse_logs = true;\n+        break;\n       case kFilter:\n         options.filter_policy = filter_policy_;\n         break;\n@@ -558,6 +563,17 @@ TEST(DBTest, GetFromVersions) {\n   } while (ChangeOptions());\n }\n \n+TEST(DBTest, GetMemUsage) {\n+  do {\n+    ASSERT_OK(Put(\"foo\", \"v1\"));\n+    std::string val;\n+    ASSERT_TRUE(db_->GetProperty(\"leveldb.approximate-memory-usage\", &val));\n+    int mem_usage = atoi(val.c_str());\n+    ASSERT_GT(mem_usage, 0);\n+    ASSERT_LT(mem_usage, 5*1024*1024);\n+  } while (ChangeOptions());\n+}\n+\n TEST(DBTest, GetSnapshot) {\n   do {\n     // Try with both a short key and a long key\n@@ -1080,6 +1096,14 @@ TEST(DBTest, ApproximateSizes) {\n     // 0 because GetApproximateSizes() does not account for memtable space\n     ASSERT_TRUE(Between(Size(\"\", Key(50)), 0, 0));\n \n+    if (options.reuse_logs) {\n+      // Recovery will reuse memtable, and GetApproximateSizes() does not\n+      // account for memtable usage;\n+      Reopen(&options);\n+      ASSERT_TRUE(Between(Size(\"\", Key(50)), 0, 0));\n+      continue;\n+    }\n+\n     // Check sizes across recovery by reopening a few times\n     for (int run = 0; run < 3; run++) {\n       Reopen(&options);\n@@ -1123,6 +1147,11 @@ TEST(DBTest, ApproximateSizes_MixOfSmallAndLarge) {\n     ASSERT_OK(Put(Key(6), RandomString(&rnd, 300000)));\n     ASSERT_OK(Put(Key(7), RandomString(&rnd, 10000)));\n \n+    if (options.reuse_logs) {\n+      // Need to force a memtable compaction since recovery does not do so.\n+      ASSERT_OK(dbfull()->TEST_CompactMemTable());\n+    }\n+\n     // Check sizes across recovery by reopening a few times\n     for (int run = 0; run < 3; run++) {\n       Reopen(&options);\n@@ -2084,7 +2113,8 @@ void BM_LogAndApply(int iters, int num_base_files) {\n   InternalKeyComparator cmp(BytewiseComparator());\n   Options options;\n   VersionSet vset(dbname, &options, NULL, &cmp);\n-  ASSERT_OK(vset.Recover());\n+  bool save_manifest;\n+  ASSERT_OK(vset.Recover(&save_manifest));\n   VersionEdit vbase;\n   uint64_t fnum = 1;\n   for (int i = 0; i < num_base_files; i++) {"
      },
      {
        "sha": "875dfe81eeab39656a57deade1589895a6d87cd7",
        "filename": "src/leveldb/db/fault_injection_test.cc",
        "status": "added",
        "additions": 554,
        "deletions": 0,
        "changes": 554,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/fault_injection_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/fault_injection_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/fault_injection_test.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -0,0 +1,554 @@\n+// Copyright 2014 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+// This test uses a custom Env to keep track of the state of a filesystem as of\n+// the last \"sync\". It then checks for data loss errors by purposely dropping\n+// file data (or entire files) not protected by a \"sync\".\n+\n+#include \"leveldb/db.h\"\n+\n+#include <map>\n+#include <set>\n+#include \"db/db_impl.h\"\n+#include \"db/filename.h\"\n+#include \"db/log_format.h\"\n+#include \"db/version_set.h\"\n+#include \"leveldb/cache.h\"\n+#include \"leveldb/env.h\"\n+#include \"leveldb/table.h\"\n+#include \"leveldb/write_batch.h\"\n+#include \"util/logging.h\"\n+#include \"util/mutexlock.h\"\n+#include \"util/testharness.h\"\n+#include \"util/testutil.h\"\n+\n+namespace leveldb {\n+\n+static const int kValueSize = 1000;\n+static const int kMaxNumValues = 2000;\n+static const size_t kNumIterations = 3;\n+\n+class FaultInjectionTestEnv;\n+\n+namespace {\n+\n+// Assume a filename, and not a directory name like \"/foo/bar/\"\n+static std::string GetDirName(const std::string filename) {\n+  size_t found = filename.find_last_of(\"/\\\\\");\n+  if (found == std::string::npos) {\n+    return \"\";\n+  } else {\n+    return filename.substr(0, found);\n+  }\n+}\n+\n+Status SyncDir(const std::string& dir) {\n+  // As this is a test it isn't required to *actually* sync this directory.\n+  return Status::OK();\n+}\n+\n+// A basic file truncation function suitable for this test.\n+Status Truncate(const std::string& filename, uint64_t length) {\n+  leveldb::Env* env = leveldb::Env::Default();\n+\n+  SequentialFile* orig_file;\n+  Status s = env->NewSequentialFile(filename, &orig_file);\n+  if (!s.ok())\n+    return s;\n+\n+  char* scratch = new char[length];\n+  leveldb::Slice result;\n+  s = orig_file->Read(length, &result, scratch);\n+  delete orig_file;\n+  if (s.ok()) {\n+    std::string tmp_name = GetDirName(filename) + \"/truncate.tmp\";\n+    WritableFile* tmp_file;\n+    s = env->NewWritableFile(tmp_name, &tmp_file);\n+    if (s.ok()) {\n+      s = tmp_file->Append(result);\n+      delete tmp_file;\n+      if (s.ok()) {\n+        s = env->RenameFile(tmp_name, filename);\n+      } else {\n+        env->DeleteFile(tmp_name);\n+      }\n+    }\n+  }\n+\n+  delete[] scratch;\n+\n+  return s;\n+}\n+\n+struct FileState {\n+  std::string filename_;\n+  ssize_t pos_;\n+  ssize_t pos_at_last_sync_;\n+  ssize_t pos_at_last_flush_;\n+\n+  FileState(const std::string& filename)\n+      : filename_(filename),\n+        pos_(-1),\n+        pos_at_last_sync_(-1),\n+        pos_at_last_flush_(-1) { }\n+\n+  FileState() : pos_(-1), pos_at_last_sync_(-1), pos_at_last_flush_(-1) {}\n+\n+  bool IsFullySynced() const { return pos_ <= 0 || pos_ == pos_at_last_sync_; }\n+\n+  Status DropUnsyncedData() const;\n+};\n+\n+}  // anonymous namespace\n+\n+// A wrapper around WritableFile which informs another Env whenever this file\n+// is written to or sync'ed.\n+class TestWritableFile : public WritableFile {\n+ public:\n+  TestWritableFile(const FileState& state,\n+                   WritableFile* f,\n+                   FaultInjectionTestEnv* env);\n+  virtual ~TestWritableFile();\n+  virtual Status Append(const Slice& data);\n+  virtual Status Close();\n+  virtual Status Flush();\n+  virtual Status Sync();\n+\n+ private:\n+  FileState state_;\n+  WritableFile* target_;\n+  bool writable_file_opened_;\n+  FaultInjectionTestEnv* env_;\n+\n+  Status SyncParent();\n+};\n+\n+class FaultInjectionTestEnv : public EnvWrapper {\n+ public:\n+  FaultInjectionTestEnv() : EnvWrapper(Env::Default()), filesystem_active_(true) {}\n+  virtual ~FaultInjectionTestEnv() { }\n+  virtual Status NewWritableFile(const std::string& fname,\n+                                 WritableFile** result);\n+  virtual Status NewAppendableFile(const std::string& fname,\n+                                   WritableFile** result);\n+  virtual Status DeleteFile(const std::string& f);\n+  virtual Status RenameFile(const std::string& s, const std::string& t);\n+\n+  void WritableFileClosed(const FileState& state);\n+  Status DropUnsyncedFileData();\n+  Status DeleteFilesCreatedAfterLastDirSync();\n+  void DirWasSynced();\n+  bool IsFileCreatedSinceLastDirSync(const std::string& filename);\n+  void ResetState();\n+  void UntrackFile(const std::string& f);\n+  // Setting the filesystem to inactive is the test equivalent to simulating a\n+  // system reset. Setting to inactive will freeze our saved filesystem state so\n+  // that it will stop being recorded. It can then be reset back to the state at\n+  // the time of the reset.\n+  bool IsFilesystemActive() const { return filesystem_active_; }\n+  void SetFilesystemActive(bool active) { filesystem_active_ = active; }\n+\n+ private:\n+  port::Mutex mutex_;\n+  std::map<std::string, FileState> db_file_state_;\n+  std::set<std::string> new_files_since_last_dir_sync_;\n+  bool filesystem_active_;  // Record flushes, syncs, writes\n+};\n+\n+TestWritableFile::TestWritableFile(const FileState& state,\n+                                   WritableFile* f,\n+                                   FaultInjectionTestEnv* env)\n+    : state_(state),\n+      target_(f),\n+      writable_file_opened_(true),\n+      env_(env) {\n+  assert(f != NULL);\n+}\n+\n+TestWritableFile::~TestWritableFile() {\n+  if (writable_file_opened_) {\n+    Close();\n+  }\n+  delete target_;\n+}\n+\n+Status TestWritableFile::Append(const Slice& data) {\n+  Status s = target_->Append(data);\n+  if (s.ok() && env_->IsFilesystemActive()) {\n+    state_.pos_ += data.size();\n+  }\n+  return s;\n+}\n+\n+Status TestWritableFile::Close() {\n+  writable_file_opened_ = false;\n+  Status s = target_->Close();\n+  if (s.ok()) {\n+    env_->WritableFileClosed(state_);\n+  }\n+  return s;\n+}\n+\n+Status TestWritableFile::Flush() {\n+  Status s = target_->Flush();\n+  if (s.ok() && env_->IsFilesystemActive()) {\n+    state_.pos_at_last_flush_ = state_.pos_;\n+  }\n+  return s;\n+}\n+\n+Status TestWritableFile::SyncParent() {\n+  Status s = SyncDir(GetDirName(state_.filename_));\n+  if (s.ok()) {\n+    env_->DirWasSynced();\n+  }\n+  return s;\n+}\n+\n+Status TestWritableFile::Sync() {\n+  if (!env_->IsFilesystemActive()) {\n+    return Status::OK();\n+  }\n+  // Ensure new files referred to by the manifest are in the filesystem.\n+  Status s = target_->Sync();\n+  if (s.ok()) {\n+    state_.pos_at_last_sync_ = state_.pos_;\n+  }\n+  if (env_->IsFileCreatedSinceLastDirSync(state_.filename_)) {\n+    Status ps = SyncParent();\n+    if (s.ok() && !ps.ok()) {\n+      s = ps;\n+    }\n+  }\n+  return s;\n+}\n+\n+Status FaultInjectionTestEnv::NewWritableFile(const std::string& fname,\n+                                              WritableFile** result) {\n+  WritableFile* actual_writable_file;\n+  Status s = target()->NewWritableFile(fname, &actual_writable_file);\n+  if (s.ok()) {\n+    FileState state(fname);\n+    state.pos_ = 0;\n+    *result = new TestWritableFile(state, actual_writable_file, this);\n+    // NewWritableFile doesn't append to files, so if the same file is\n+    // opened again then it will be truncated - so forget our saved\n+    // state.\n+    UntrackFile(fname);\n+    MutexLock l(&mutex_);\n+    new_files_since_last_dir_sync_.insert(fname);\n+  }\n+  return s;\n+}\n+\n+Status FaultInjectionTestEnv::NewAppendableFile(const std::string& fname,\n+                                                WritableFile** result) {\n+  WritableFile* actual_writable_file;\n+  Status s = target()->NewAppendableFile(fname, &actual_writable_file);\n+  if (s.ok()) {\n+    FileState state(fname);\n+    state.pos_ = 0;\n+    {\n+      MutexLock l(&mutex_);\n+      if (db_file_state_.count(fname) == 0) {\n+        new_files_since_last_dir_sync_.insert(fname);\n+      } else {\n+        state = db_file_state_[fname];\n+      }\n+    }\n+    *result = new TestWritableFile(state, actual_writable_file, this);\n+  }\n+  return s;\n+}\n+\n+Status FaultInjectionTestEnv::DropUnsyncedFileData() {\n+  Status s;\n+  MutexLock l(&mutex_);\n+  for (std::map<std::string, FileState>::const_iterator it =\n+           db_file_state_.begin();\n+       s.ok() && it != db_file_state_.end(); ++it) {\n+    const FileState& state = it->second;\n+    if (!state.IsFullySynced()) {\n+      s = state.DropUnsyncedData();\n+    }\n+  }\n+  return s;\n+}\n+\n+void FaultInjectionTestEnv::DirWasSynced() {\n+  MutexLock l(&mutex_);\n+  new_files_since_last_dir_sync_.clear();\n+}\n+\n+bool FaultInjectionTestEnv::IsFileCreatedSinceLastDirSync(\n+    const std::string& filename) {\n+  MutexLock l(&mutex_);\n+  return new_files_since_last_dir_sync_.find(filename) !=\n+         new_files_since_last_dir_sync_.end();\n+}\n+\n+void FaultInjectionTestEnv::UntrackFile(const std::string& f) {\n+  MutexLock l(&mutex_);\n+  db_file_state_.erase(f);\n+  new_files_since_last_dir_sync_.erase(f);\n+}\n+\n+Status FaultInjectionTestEnv::DeleteFile(const std::string& f) {\n+  Status s = EnvWrapper::DeleteFile(f);\n+  ASSERT_OK(s);\n+  if (s.ok()) {\n+    UntrackFile(f);\n+  }\n+  return s;\n+}\n+\n+Status FaultInjectionTestEnv::RenameFile(const std::string& s,\n+                                         const std::string& t) {\n+  Status ret = EnvWrapper::RenameFile(s, t);\n+\n+  if (ret.ok()) {\n+    MutexLock l(&mutex_);\n+    if (db_file_state_.find(s) != db_file_state_.end()) {\n+      db_file_state_[t] = db_file_state_[s];\n+      db_file_state_.erase(s);\n+    }\n+\n+    if (new_files_since_last_dir_sync_.erase(s) != 0) {\n+      assert(new_files_since_last_dir_sync_.find(t) ==\n+             new_files_since_last_dir_sync_.end());\n+      new_files_since_last_dir_sync_.insert(t);\n+    }\n+  }\n+\n+  return ret;\n+}\n+\n+void FaultInjectionTestEnv::ResetState() {\n+  // Since we are not destroying the database, the existing files\n+  // should keep their recorded synced/flushed state. Therefore\n+  // we do not reset db_file_state_ and new_files_since_last_dir_sync_.\n+  MutexLock l(&mutex_);\n+  SetFilesystemActive(true);\n+}\n+\n+Status FaultInjectionTestEnv::DeleteFilesCreatedAfterLastDirSync() {\n+  // Because DeleteFile access this container make a copy to avoid deadlock\n+  mutex_.Lock();\n+  std::set<std::string> new_files(new_files_since_last_dir_sync_.begin(),\n+                                  new_files_since_last_dir_sync_.end());\n+  mutex_.Unlock();\n+  Status s;\n+  std::set<std::string>::const_iterator it;\n+  for (it = new_files.begin(); s.ok() && it != new_files.end(); ++it) {\n+    s = DeleteFile(*it);\n+  }\n+  return s;\n+}\n+\n+void FaultInjectionTestEnv::WritableFileClosed(const FileState& state) {\n+  MutexLock l(&mutex_);\n+  db_file_state_[state.filename_] = state;\n+}\n+\n+Status FileState::DropUnsyncedData() const {\n+  ssize_t sync_pos = pos_at_last_sync_ == -1 ? 0 : pos_at_last_sync_;\n+  return Truncate(filename_, sync_pos);\n+}\n+\n+class FaultInjectionTest {\n+ public:\n+  enum ExpectedVerifResult { VAL_EXPECT_NO_ERROR, VAL_EXPECT_ERROR };\n+  enum ResetMethod { RESET_DROP_UNSYNCED_DATA, RESET_DELETE_UNSYNCED_FILES };\n+\n+  FaultInjectionTestEnv* env_;\n+  std::string dbname_;\n+  Cache* tiny_cache_;\n+  Options options_;\n+  DB* db_;\n+\n+  FaultInjectionTest()\n+      : env_(new FaultInjectionTestEnv),\n+        tiny_cache_(NewLRUCache(100)),\n+        db_(NULL) {\n+    dbname_ = test::TmpDir() + \"/fault_test\";\n+    DestroyDB(dbname_, Options());  // Destroy any db from earlier run\n+    options_.reuse_logs = true;\n+    options_.env = env_;\n+    options_.paranoid_checks = true;\n+    options_.block_cache = tiny_cache_;\n+    options_.create_if_missing = true;\n+  }\n+\n+  ~FaultInjectionTest() {\n+    CloseDB();\n+    DestroyDB(dbname_, Options());\n+    delete tiny_cache_;\n+    delete env_;\n+  }\n+\n+  void ReuseLogs(bool reuse) {\n+    options_.reuse_logs = reuse;\n+  }\n+\n+  void Build(int start_idx, int num_vals) {\n+    std::string key_space, value_space;\n+    WriteBatch batch;\n+    for (int i = start_idx; i < start_idx + num_vals; i++) {\n+      Slice key = Key(i, &key_space);\n+      batch.Clear();\n+      batch.Put(key, Value(i, &value_space));\n+      WriteOptions options;\n+      ASSERT_OK(db_->Write(options, &batch));\n+    }\n+  }\n+\n+  Status ReadValue(int i, std::string* val) const {\n+    std::string key_space, value_space;\n+    Slice key = Key(i, &key_space);\n+    Value(i, &value_space);\n+    ReadOptions options;\n+    return db_->Get(options, key, val);\n+  }\n+\n+  Status Verify(int start_idx, int num_vals,\n+                ExpectedVerifResult expected) const {\n+    std::string val;\n+    std::string value_space;\n+    Status s;\n+    for (int i = start_idx; i < start_idx + num_vals && s.ok(); i++) {\n+      Value(i, &value_space);\n+      s = ReadValue(i, &val);\n+      if (expected == VAL_EXPECT_NO_ERROR) {\n+        if (s.ok()) {\n+          ASSERT_EQ(value_space, val);\n+        }\n+      } else if (s.ok()) {\n+        fprintf(stderr, \"Expected an error at %d, but was OK\\n\", i);\n+        s = Status::IOError(dbname_, \"Expected value error:\");\n+      } else {\n+        s = Status::OK();  // An expected error\n+      }\n+    }\n+    return s;\n+  }\n+\n+  // Return the ith key\n+  Slice Key(int i, std::string* storage) const {\n+    char buf[100];\n+    snprintf(buf, sizeof(buf), \"%016d\", i);\n+    storage->assign(buf, strlen(buf));\n+    return Slice(*storage);\n+  }\n+\n+  // Return the value to associate with the specified key\n+  Slice Value(int k, std::string* storage) const {\n+    Random r(k);\n+    return test::RandomString(&r, kValueSize, storage);\n+  }\n+\n+  Status OpenDB() {\n+    delete db_;\n+    db_ = NULL;\n+    env_->ResetState();\n+    return DB::Open(options_, dbname_, &db_);\n+  }\n+\n+  void CloseDB() {\n+    delete db_;\n+    db_ = NULL;\n+  }\n+\n+  void DeleteAllData() {\n+    Iterator* iter = db_->NewIterator(ReadOptions());\n+    WriteOptions options;\n+    for (iter->SeekToFirst(); iter->Valid(); iter->Next()) {\n+      ASSERT_OK(db_->Delete(WriteOptions(), iter->key()));\n+    }\n+\n+    delete iter;\n+  }\n+\n+  void ResetDBState(ResetMethod reset_method) {\n+    switch (reset_method) {\n+      case RESET_DROP_UNSYNCED_DATA:\n+        ASSERT_OK(env_->DropUnsyncedFileData());\n+        break;\n+      case RESET_DELETE_UNSYNCED_FILES:\n+        ASSERT_OK(env_->DeleteFilesCreatedAfterLastDirSync());\n+        break;\n+      default:\n+        assert(false);\n+    }\n+  }\n+\n+  void PartialCompactTestPreFault(int num_pre_sync, int num_post_sync) {\n+    DeleteAllData();\n+    Build(0, num_pre_sync);\n+    db_->CompactRange(NULL, NULL);\n+    Build(num_pre_sync, num_post_sync);\n+  }\n+\n+  void PartialCompactTestReopenWithFault(ResetMethod reset_method,\n+                                         int num_pre_sync,\n+                                         int num_post_sync) {\n+    env_->SetFilesystemActive(false);\n+    CloseDB();\n+    ResetDBState(reset_method);\n+    ASSERT_OK(OpenDB());\n+    ASSERT_OK(Verify(0, num_pre_sync, FaultInjectionTest::VAL_EXPECT_NO_ERROR));\n+    ASSERT_OK(Verify(num_pre_sync, num_post_sync, FaultInjectionTest::VAL_EXPECT_ERROR));\n+  }\n+\n+  void NoWriteTestPreFault() {\n+  }\n+\n+  void NoWriteTestReopenWithFault(ResetMethod reset_method) {\n+    CloseDB();\n+    ResetDBState(reset_method);\n+    ASSERT_OK(OpenDB());\n+  }\n+\n+  void DoTest() {\n+    Random rnd(0);\n+    ASSERT_OK(OpenDB());\n+    for (size_t idx = 0; idx < kNumIterations; idx++) {\n+      int num_pre_sync = rnd.Uniform(kMaxNumValues);\n+      int num_post_sync = rnd.Uniform(kMaxNumValues);\n+\n+      PartialCompactTestPreFault(num_pre_sync, num_post_sync);\n+      PartialCompactTestReopenWithFault(RESET_DROP_UNSYNCED_DATA,\n+                                        num_pre_sync,\n+                                        num_post_sync);\n+\n+      NoWriteTestPreFault();\n+      NoWriteTestReopenWithFault(RESET_DROP_UNSYNCED_DATA);\n+\n+      PartialCompactTestPreFault(num_pre_sync, num_post_sync);\n+      // No new files created so we expect all values since no files will be\n+      // dropped.\n+      PartialCompactTestReopenWithFault(RESET_DELETE_UNSYNCED_FILES,\n+                                        num_pre_sync + num_post_sync,\n+                                        0);\n+\n+      NoWriteTestPreFault();\n+      NoWriteTestReopenWithFault(RESET_DELETE_UNSYNCED_FILES);\n+    }\n+  }\n+};\n+\n+TEST(FaultInjectionTest, FaultTestNoLogReuse) {\n+  ReuseLogs(false);\n+  DoTest();\n+}\n+\n+TEST(FaultInjectionTest, FaultTestWithLogReuse) {\n+  ReuseLogs(true);\n+  DoTest();\n+}\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) {\n+  return leveldb::test::RunAllTests();\n+}"
      },
      {
        "sha": "9f4b7dd70c245302e9841e6a407e89659992284f",
        "filename": "src/leveldb/db/leveldbutil.cc",
        "status": "renamed",
        "additions": 0,
        "deletions": 0,
        "changes": 0,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/leveldbutil.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/leveldbutil.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/leveldbutil.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "previous_filename": "src/leveldb/db/leveldb_main.cc"
      },
      {
        "sha": "a6d304545d828e0f6dfb792e8f545888a2a8a9c0",
        "filename": "src/leveldb/db/log_reader.cc",
        "status": "modified",
        "additions": 20,
        "deletions": 2,
        "changes": 22,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/log_reader.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/log_reader.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/log_reader.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -25,7 +25,8 @@ Reader::Reader(SequentialFile* file, Reporter* reporter, bool checksum,\n       eof_(false),\n       last_record_offset_(0),\n       end_of_buffer_offset_(0),\n-      initial_offset_(initial_offset) {\n+      initial_offset_(initial_offset),\n+      resyncing_(initial_offset > 0) {\n }\n \n Reader::~Reader() {\n@@ -72,8 +73,25 @@ bool Reader::ReadRecord(Slice* record, std::string* scratch) {\n \n   Slice fragment;\n   while (true) {\n-    uint64_t physical_record_offset = end_of_buffer_offset_ - buffer_.size();\n     const unsigned int record_type = ReadPhysicalRecord(&fragment);\n+\n+    // ReadPhysicalRecord may have only had an empty trailer remaining in its\n+    // internal buffer. Calculate the offset of the next physical record now\n+    // that it has returned, properly accounting for its header size.\n+    uint64_t physical_record_offset =\n+        end_of_buffer_offset_ - buffer_.size() - kHeaderSize - fragment.size();\n+\n+    if (resyncing_) {\n+      if (record_type == kMiddleType) {\n+        continue;\n+      } else if (record_type == kLastType) {\n+        resyncing_ = false;\n+        continue;\n+      } else {\n+        resyncing_ = false;\n+      }\n+    }\n+\n     switch (record_type) {\n       case kFullType:\n         if (in_fragmented_record) {"
      },
      {
        "sha": "8389d61f8f1dde45435840d972ec99ba6d793c15",
        "filename": "src/leveldb/db/log_reader.h",
        "status": "modified",
        "additions": 5,
        "deletions": 0,
        "changes": 5,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/log_reader.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/log_reader.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/log_reader.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -73,6 +73,11 @@ class Reader {\n   // Offset at which to start looking for the first record to return\n   uint64_t const initial_offset_;\n \n+  // True if we are resynchronizing after a seek (initial_offset_ > 0). In\n+  // particular, a run of kMiddleType and kLastType records can be silently\n+  // skipped in this mode\n+  bool resyncing_;\n+\n   // Extend record types with the following special values\n   enum {\n     kEof = kMaxRecordType + 1,"
      },
      {
        "sha": "48a5928657e0f57fa2cc5c9477d3a755d216f149",
        "filename": "src/leveldb/db/log_test.cc",
        "status": "modified",
        "additions": 81,
        "deletions": 20,
        "changes": 101,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/log_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/log_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/log_test.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -79,7 +79,7 @@ class LogTest {\n     virtual Status Skip(uint64_t n) {\n       if (n > contents_.size()) {\n         contents_.clear();\n-        return Status::NotFound(\"in-memory file skipepd past end\");\n+        return Status::NotFound(\"in-memory file skipped past end\");\n       }\n \n       contents_.remove_prefix(n);\n@@ -104,23 +104,34 @@ class LogTest {\n   StringSource source_;\n   ReportCollector report_;\n   bool reading_;\n-  Writer writer_;\n-  Reader reader_;\n+  Writer* writer_;\n+  Reader* reader_;\n \n   // Record metadata for testing initial offset functionality\n   static size_t initial_offset_record_sizes_[];\n   static uint64_t initial_offset_last_record_offsets_[];\n+  static int num_initial_offset_records_;\n \n  public:\n   LogTest() : reading_(false),\n-              writer_(&dest_),\n-              reader_(&source_, &report_, true/*checksum*/,\n-                      0/*initial_offset*/) {\n+              writer_(new Writer(&dest_)),\n+              reader_(new Reader(&source_, &report_, true/*checksum*/,\n+                      0/*initial_offset*/)) {\n+  }\n+\n+  ~LogTest() {\n+    delete writer_;\n+    delete reader_;\n+  }\n+\n+  void ReopenForAppend() {\n+    delete writer_;\n+    writer_ = new Writer(&dest_, dest_.contents_.size());\n   }\n \n   void Write(const std::string& msg) {\n     ASSERT_TRUE(!reading_) << \"Write() after starting to read\";\n-    writer_.AddRecord(Slice(msg));\n+    writer_->AddRecord(Slice(msg));\n   }\n \n   size_t WrittenBytes() const {\n@@ -134,7 +145,7 @@ class LogTest {\n     }\n     std::string scratch;\n     Slice record;\n-    if (reader_.ReadRecord(&record, &scratch)) {\n+    if (reader_->ReadRecord(&record, &scratch)) {\n       return record.ToString();\n     } else {\n       return \"EOF\";\n@@ -182,13 +193,18 @@ class LogTest {\n   }\n \n   void WriteInitialOffsetLog() {\n-    for (int i = 0; i < 4; i++) {\n+    for (int i = 0; i < num_initial_offset_records_; i++) {\n       std::string record(initial_offset_record_sizes_[i],\n                          static_cast<char>('a' + i));\n       Write(record);\n     }\n   }\n \n+  void StartReadingAt(uint64_t initial_offset) {\n+    delete reader_;\n+    reader_ = new Reader(&source_, &report_, true/*checksum*/, initial_offset);\n+  }\n+\n   void CheckOffsetPastEndReturnsNoRecords(uint64_t offset_past_end) {\n     WriteInitialOffsetLog();\n     reading_ = true;\n@@ -208,32 +224,48 @@ class LogTest {\n     source_.contents_ = Slice(dest_.contents_);\n     Reader* offset_reader = new Reader(&source_, &report_, true/*checksum*/,\n                                        initial_offset);\n-    Slice record;\n-    std::string scratch;\n-    ASSERT_TRUE(offset_reader->ReadRecord(&record, &scratch));\n-    ASSERT_EQ(initial_offset_record_sizes_[expected_record_offset],\n-              record.size());\n-    ASSERT_EQ(initial_offset_last_record_offsets_[expected_record_offset],\n-              offset_reader->LastRecordOffset());\n-    ASSERT_EQ((char)('a' + expected_record_offset), record.data()[0]);\n+\n+    // Read all records from expected_record_offset through the last one.\n+    ASSERT_LT(expected_record_offset, num_initial_offset_records_);\n+    for (; expected_record_offset < num_initial_offset_records_;\n+         ++expected_record_offset) {\n+      Slice record;\n+      std::string scratch;\n+      ASSERT_TRUE(offset_reader->ReadRecord(&record, &scratch));\n+      ASSERT_EQ(initial_offset_record_sizes_[expected_record_offset],\n+                record.size());\n+      ASSERT_EQ(initial_offset_last_record_offsets_[expected_record_offset],\n+                offset_reader->LastRecordOffset());\n+      ASSERT_EQ((char)('a' + expected_record_offset), record.data()[0]);\n+    }\n     delete offset_reader;\n   }\n-\n };\n \n size_t LogTest::initial_offset_record_sizes_[] =\n     {10000,  // Two sizable records in first block\n      10000,\n      2 * log::kBlockSize - 1000,  // Span three blocks\n-     1};\n+     1,\n+     13716,  // Consume all but two bytes of block 3.\n+     log::kBlockSize - kHeaderSize, // Consume the entirety of block 4.\n+    };\n \n uint64_t LogTest::initial_offset_last_record_offsets_[] =\n     {0,\n      kHeaderSize + 10000,\n      2 * (kHeaderSize + 10000),\n      2 * (kHeaderSize + 10000) +\n-         (2 * log::kBlockSize - 1000) + 3 * kHeaderSize};\n+         (2 * log::kBlockSize - 1000) + 3 * kHeaderSize,\n+     2 * (kHeaderSize + 10000) +\n+         (2 * log::kBlockSize - 1000) + 3 * kHeaderSize\n+         + kHeaderSize + 1,\n+     3 * log::kBlockSize,\n+    };\n \n+// LogTest::initial_offset_last_record_offsets_ must be defined before this.\n+int LogTest::num_initial_offset_records_ =\n+    sizeof(LogTest::initial_offset_last_record_offsets_)/sizeof(uint64_t);\n \n TEST(LogTest, Empty) {\n   ASSERT_EQ(\"EOF\", Read());\n@@ -318,6 +350,15 @@ TEST(LogTest, AlignedEof) {\n   ASSERT_EQ(\"EOF\", Read());\n }\n \n+TEST(LogTest, OpenForAppend) {\n+  Write(\"hello\");\n+  ReopenForAppend();\n+  Write(\"world\");\n+  ASSERT_EQ(\"hello\", Read());\n+  ASSERT_EQ(\"world\", Read());\n+  ASSERT_EQ(\"EOF\", Read());\n+}\n+\n TEST(LogTest, RandomRead) {\n   const int N = 500;\n   Random write_rnd(301);\n@@ -445,6 +486,22 @@ TEST(LogTest, PartialLastIsIgnored) {\n   ASSERT_EQ(0, DroppedBytes());\n }\n \n+TEST(LogTest, SkipIntoMultiRecord) {\n+  // Consider a fragmented record:\n+  //    first(R1), middle(R1), last(R1), first(R2)\n+  // If initial_offset points to a record after first(R1) but before first(R2)\n+  // incomplete fragment errors are not actual errors, and must be suppressed\n+  // until a new first or full record is encountered.\n+  Write(BigString(\"foo\", 3*kBlockSize));\n+  Write(\"correct\");\n+  StartReadingAt(kBlockSize);\n+\n+  ASSERT_EQ(\"correct\", Read());\n+  ASSERT_EQ(\"\", ReportMessage());\n+  ASSERT_EQ(0, DroppedBytes());\n+  ASSERT_EQ(\"EOF\", Read());\n+}\n+\n TEST(LogTest, ErrorJoinsRecords) {\n   // Consider two fragmented records:\n   //    first(R1) last(R1) first(R2) last(R2)\n@@ -514,6 +571,10 @@ TEST(LogTest, ReadFourthStart) {\n       3);\n }\n \n+TEST(LogTest, ReadInitialOffsetIntoBlockPadding) {\n+  CheckInitialOffsetRecord(3 * log::kBlockSize - 3, 5);\n+}\n+\n TEST(LogTest, ReadEnd) {\n   CheckOffsetPastEndReturnsNoRecords(0);\n }"
      },
      {
        "sha": "74a03270da8500188175a38c3a3fdab2e7b27b8e",
        "filename": "src/leveldb/db/log_writer.cc",
        "status": "modified",
        "additions": 13,
        "deletions": 4,
        "changes": 17,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/log_writer.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/log_writer.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/log_writer.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -12,15 +12,24 @@\n namespace leveldb {\n namespace log {\n \n-Writer::Writer(WritableFile* dest)\n-    : dest_(dest),\n-      block_offset_(0) {\n+static void InitTypeCrc(uint32_t* type_crc) {\n   for (int i = 0; i <= kMaxRecordType; i++) {\n     char t = static_cast<char>(i);\n-    type_crc_[i] = crc32c::Value(&t, 1);\n+    type_crc[i] = crc32c::Value(&t, 1);\n   }\n }\n \n+Writer::Writer(WritableFile* dest)\n+    : dest_(dest),\n+      block_offset_(0) {\n+  InitTypeCrc(type_crc_);\n+}\n+\n+Writer::Writer(WritableFile* dest, uint64_t dest_length)\n+    : dest_(dest), block_offset_(dest_length % kBlockSize) {\n+  InitTypeCrc(type_crc_);\n+}\n+\n Writer::~Writer() {\n }\n "
      },
      {
        "sha": "9e7cc4705b0146b316dbe4e9e0b05f1146c4389b",
        "filename": "src/leveldb/db/log_writer.h",
        "status": "modified",
        "additions": 6,
        "deletions": 0,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/log_writer.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/log_writer.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/log_writer.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -22,6 +22,12 @@ class Writer {\n   // \"*dest\" must be initially empty.\n   // \"*dest\" must remain live while this Writer is in use.\n   explicit Writer(WritableFile* dest);\n+\n+  // Create a writer that will append data to \"*dest\".\n+  // \"*dest\" must have initial length \"dest_length\".\n+  // \"*dest\" must remain live while this Writer is in use.\n+  Writer(WritableFile* dest, uint64_t dest_length);\n+\n   ~Writer();\n \n   Status AddRecord(const Slice& slice);"
      },
      {
        "sha": "9f41567cde23dfd645b19d290c6e4a4256804900",
        "filename": "src/leveldb/db/memtable.h",
        "status": "modified",
        "additions": 1,
        "deletions": 4,
        "changes": 5,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/memtable.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/memtable.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/memtable.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -36,10 +36,7 @@ class MemTable {\n   }\n \n   // Returns an estimate of the number of bytes of data in use by this\n-  // data structure.\n-  //\n-  // REQUIRES: external synchronization to prevent simultaneous\n-  // operations on the same MemTable.\n+  // data structure. It is safe to call when MemTable is being modified.\n   size_t ApproximateMemoryUsage();\n \n   // Return an iterator that yields the contents of the memtable."
      },
      {
        "sha": "9596f4288a84e558835421f8e68c57189a1da765",
        "filename": "src/leveldb/db/recovery_test.cc",
        "status": "added",
        "additions": 324,
        "deletions": 0,
        "changes": 324,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/recovery_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/recovery_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/recovery_test.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -0,0 +1,324 @@\n+// Copyright (c) 2014 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"db/db_impl.h\"\n+#include \"db/filename.h\"\n+#include \"db/version_set.h\"\n+#include \"db/write_batch_internal.h\"\n+#include \"leveldb/db.h\"\n+#include \"leveldb/env.h\"\n+#include \"leveldb/write_batch.h\"\n+#include \"util/logging.h\"\n+#include \"util/testharness.h\"\n+#include \"util/testutil.h\"\n+\n+namespace leveldb {\n+\n+class RecoveryTest {\n+ public:\n+  RecoveryTest() : env_(Env::Default()), db_(NULL) {\n+    dbname_ = test::TmpDir() + \"/recovery_test\";\n+    DestroyDB(dbname_, Options());\n+    Open();\n+  }\n+\n+  ~RecoveryTest() {\n+    Close();\n+    DestroyDB(dbname_, Options());\n+  }\n+\n+  DBImpl* dbfull() const { return reinterpret_cast<DBImpl*>(db_); }\n+  Env* env() const { return env_; }\n+\n+  bool CanAppend() {\n+    WritableFile* tmp;\n+    Status s = env_->NewAppendableFile(CurrentFileName(dbname_), &tmp);\n+    delete tmp;\n+    if (s.IsNotSupportedError()) {\n+      return false;\n+    } else {\n+      return true;\n+    }\n+  }\n+\n+  void Close() {\n+    delete db_;\n+    db_ = NULL;\n+  }\n+\n+  void Open(Options* options = NULL) {\n+    Close();\n+    Options opts;\n+    if (options != NULL) {\n+      opts = *options;\n+    } else {\n+      opts.reuse_logs = true;  // TODO(sanjay): test both ways\n+      opts.create_if_missing = true;\n+    }\n+    if (opts.env == NULL) {\n+      opts.env = env_;\n+    }\n+    ASSERT_OK(DB::Open(opts, dbname_, &db_));\n+    ASSERT_EQ(1, NumLogs());\n+  }\n+\n+  Status Put(const std::string& k, const std::string& v) {\n+    return db_->Put(WriteOptions(), k, v);\n+  }\n+\n+  std::string Get(const std::string& k, const Snapshot* snapshot = NULL) {\n+    std::string result;\n+    Status s = db_->Get(ReadOptions(), k, &result);\n+    if (s.IsNotFound()) {\n+      result = \"NOT_FOUND\";\n+    } else if (!s.ok()) {\n+      result = s.ToString();\n+    }\n+    return result;\n+  }\n+\n+  std::string ManifestFileName() {\n+    std::string current;\n+    ASSERT_OK(ReadFileToString(env_, CurrentFileName(dbname_), &current));\n+    size_t len = current.size();\n+    if (len > 0 && current[len-1] == '\\n') {\n+      current.resize(len - 1);\n+    }\n+    return dbname_ + \"/\" + current;\n+  }\n+\n+  std::string LogName(uint64_t number) {\n+    return LogFileName(dbname_, number);\n+  }\n+\n+  size_t DeleteLogFiles() {\n+    std::vector<uint64_t> logs = GetFiles(kLogFile);\n+    for (size_t i = 0; i < logs.size(); i++) {\n+      ASSERT_OK(env_->DeleteFile(LogName(logs[i]))) << LogName(logs[i]);\n+    }\n+    return logs.size();\n+  }\n+\n+  uint64_t FirstLogFile() {\n+    return GetFiles(kLogFile)[0];\n+  }\n+\n+  std::vector<uint64_t> GetFiles(FileType t) {\n+    std::vector<std::string> filenames;\n+    ASSERT_OK(env_->GetChildren(dbname_, &filenames));\n+    std::vector<uint64_t> result;\n+    for (size_t i = 0; i < filenames.size(); i++) {\n+      uint64_t number;\n+      FileType type;\n+      if (ParseFileName(filenames[i], &number, &type) && type == t) {\n+        result.push_back(number);\n+      }\n+    }\n+    return result;\n+  }\n+\n+  int NumLogs() {\n+    return GetFiles(kLogFile).size();\n+  }\n+\n+  int NumTables() {\n+    return GetFiles(kTableFile).size();\n+  }\n+\n+  uint64_t FileSize(const std::string& fname) {\n+    uint64_t result;\n+    ASSERT_OK(env_->GetFileSize(fname, &result)) << fname;\n+    return result;\n+  }\n+\n+  void CompactMemTable() {\n+    dbfull()->TEST_CompactMemTable();\n+  }\n+\n+  // Directly construct a log file that sets key to val.\n+  void MakeLogFile(uint64_t lognum, SequenceNumber seq, Slice key, Slice val) {\n+    std::string fname = LogFileName(dbname_, lognum);\n+    WritableFile* file;\n+    ASSERT_OK(env_->NewWritableFile(fname, &file));\n+    log::Writer writer(file);\n+    WriteBatch batch;\n+    batch.Put(key, val);\n+    WriteBatchInternal::SetSequence(&batch, seq);\n+    ASSERT_OK(writer.AddRecord(WriteBatchInternal::Contents(&batch)));\n+    ASSERT_OK(file->Flush());\n+    delete file;\n+  }\n+\n+ private:\n+  std::string dbname_;\n+  Env* env_;\n+  DB* db_;\n+};\n+\n+TEST(RecoveryTest, ManifestReused) {\n+  if (!CanAppend()) {\n+    fprintf(stderr, \"skipping test because env does not support appending\\n\");\n+    return;\n+  }\n+  ASSERT_OK(Put(\"foo\", \"bar\"));\n+  Close();\n+  std::string old_manifest = ManifestFileName();\n+  Open();\n+  ASSERT_EQ(old_manifest, ManifestFileName());\n+  ASSERT_EQ(\"bar\", Get(\"foo\"));\n+  Open();\n+  ASSERT_EQ(old_manifest, ManifestFileName());\n+  ASSERT_EQ(\"bar\", Get(\"foo\"));\n+}\n+\n+TEST(RecoveryTest, LargeManifestCompacted) {\n+  if (!CanAppend()) {\n+    fprintf(stderr, \"skipping test because env does not support appending\\n\");\n+    return;\n+  }\n+  ASSERT_OK(Put(\"foo\", \"bar\"));\n+  Close();\n+  std::string old_manifest = ManifestFileName();\n+\n+  // Pad with zeroes to make manifest file very big.\n+  {\n+    uint64_t len = FileSize(old_manifest);\n+    WritableFile* file;\n+    ASSERT_OK(env()->NewAppendableFile(old_manifest, &file));\n+    std::string zeroes(3*1048576 - static_cast<size_t>(len), 0);\n+    ASSERT_OK(file->Append(zeroes));\n+    ASSERT_OK(file->Flush());\n+    delete file;\n+  }\n+\n+  Open();\n+  std::string new_manifest = ManifestFileName();\n+  ASSERT_NE(old_manifest, new_manifest);\n+  ASSERT_GT(10000, FileSize(new_manifest));\n+  ASSERT_EQ(\"bar\", Get(\"foo\"));\n+\n+  Open();\n+  ASSERT_EQ(new_manifest, ManifestFileName());\n+  ASSERT_EQ(\"bar\", Get(\"foo\"));\n+}\n+\n+TEST(RecoveryTest, NoLogFiles) {\n+  ASSERT_OK(Put(\"foo\", \"bar\"));\n+  ASSERT_EQ(1, DeleteLogFiles());\n+  Open();\n+  ASSERT_EQ(\"NOT_FOUND\", Get(\"foo\"));\n+  Open();\n+  ASSERT_EQ(\"NOT_FOUND\", Get(\"foo\"));\n+}\n+\n+TEST(RecoveryTest, LogFileReuse) {\n+  if (!CanAppend()) {\n+    fprintf(stderr, \"skipping test because env does not support appending\\n\");\n+    return;\n+  }\n+  for (int i = 0; i < 2; i++) {\n+    ASSERT_OK(Put(\"foo\", \"bar\"));\n+    if (i == 0) {\n+      // Compact to ensure current log is empty\n+      CompactMemTable();\n+    }\n+    Close();\n+    ASSERT_EQ(1, NumLogs());\n+    uint64_t number = FirstLogFile();\n+    if (i == 0) {\n+      ASSERT_EQ(0, FileSize(LogName(number)));\n+    } else {\n+      ASSERT_LT(0, FileSize(LogName(number)));\n+    }\n+    Open();\n+    ASSERT_EQ(1, NumLogs());\n+    ASSERT_EQ(number, FirstLogFile()) << \"did not reuse log file\";\n+    ASSERT_EQ(\"bar\", Get(\"foo\"));\n+    Open();\n+    ASSERT_EQ(1, NumLogs());\n+    ASSERT_EQ(number, FirstLogFile()) << \"did not reuse log file\";\n+    ASSERT_EQ(\"bar\", Get(\"foo\"));\n+  }\n+}\n+\n+TEST(RecoveryTest, MultipleMemTables) {\n+  // Make a large log.\n+  const int kNum = 1000;\n+  for (int i = 0; i < kNum; i++) {\n+    char buf[100];\n+    snprintf(buf, sizeof(buf), \"%050d\", i);\n+    ASSERT_OK(Put(buf, buf));\n+  }\n+  ASSERT_EQ(0, NumTables());\n+  Close();\n+  ASSERT_EQ(0, NumTables());\n+  ASSERT_EQ(1, NumLogs());\n+  uint64_t old_log_file = FirstLogFile();\n+\n+  // Force creation of multiple memtables by reducing the write buffer size.\n+  Options opt;\n+  opt.reuse_logs = true;\n+  opt.write_buffer_size = (kNum*100) / 2;\n+  Open(&opt);\n+  ASSERT_LE(2, NumTables());\n+  ASSERT_EQ(1, NumLogs());\n+  ASSERT_NE(old_log_file, FirstLogFile()) << \"must not reuse log\";\n+  for (int i = 0; i < kNum; i++) {\n+    char buf[100];\n+    snprintf(buf, sizeof(buf), \"%050d\", i);\n+    ASSERT_EQ(buf, Get(buf));\n+  }\n+}\n+\n+TEST(RecoveryTest, MultipleLogFiles) {\n+  ASSERT_OK(Put(\"foo\", \"bar\"));\n+  Close();\n+  ASSERT_EQ(1, NumLogs());\n+\n+  // Make a bunch of uncompacted log files.\n+  uint64_t old_log = FirstLogFile();\n+  MakeLogFile(old_log+1, 1000, \"hello\", \"world\");\n+  MakeLogFile(old_log+2, 1001, \"hi\", \"there\");\n+  MakeLogFile(old_log+3, 1002, \"foo\", \"bar2\");\n+\n+  // Recover and check that all log files were processed.\n+  Open();\n+  ASSERT_LE(1, NumTables());\n+  ASSERT_EQ(1, NumLogs());\n+  uint64_t new_log = FirstLogFile();\n+  ASSERT_LE(old_log+3, new_log);\n+  ASSERT_EQ(\"bar2\", Get(\"foo\"));\n+  ASSERT_EQ(\"world\", Get(\"hello\"));\n+  ASSERT_EQ(\"there\", Get(\"hi\"));\n+\n+  // Test that previous recovery produced recoverable state.\n+  Open();\n+  ASSERT_LE(1, NumTables());\n+  ASSERT_EQ(1, NumLogs());\n+  if (CanAppend()) {\n+    ASSERT_EQ(new_log, FirstLogFile());\n+  }\n+  ASSERT_EQ(\"bar2\", Get(\"foo\"));\n+  ASSERT_EQ(\"world\", Get(\"hello\"));\n+  ASSERT_EQ(\"there\", Get(\"hi\"));\n+\n+  // Check that introducing an older log file does not cause it to be re-read.\n+  Close();\n+  MakeLogFile(old_log+1, 2000, \"hello\", \"stale write\");\n+  Open();\n+  ASSERT_LE(1, NumTables());\n+  ASSERT_EQ(1, NumLogs());\n+  if (CanAppend()) {\n+    ASSERT_EQ(new_log, FirstLogFile());\n+  }\n+  ASSERT_EQ(\"bar2\", Get(\"foo\"));\n+  ASSERT_EQ(\"world\", Get(\"hello\"));\n+  ASSERT_EQ(\"there\", Get(\"hi\"));\n+}\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) {\n+  return leveldb::test::RunAllTests();\n+}"
      },
      {
        "sha": "8bd77764d8fb37b9887dcf83edffa83b6e941c23",
        "filename": "src/leveldb/db/skiplist.h",
        "status": "modified",
        "additions": 4,
        "deletions": 4,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/skiplist.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/skiplist.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/skiplist.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -1,10 +1,10 @@\n-#ifndef STORAGE_LEVELDB_DB_SKIPLIST_H_\n-#define STORAGE_LEVELDB_DB_SKIPLIST_H_\n-\n // Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n-//\n+\n+#ifndef STORAGE_LEVELDB_DB_SKIPLIST_H_\n+#define STORAGE_LEVELDB_DB_SKIPLIST_H_\n+\n // Thread safety\n // -------------\n //"
      },
      {
        "sha": "aee1461e1b256a527b8960da59a98fda7e345d4e",
        "filename": "src/leveldb/db/skiplist_test.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/skiplist_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/skiplist_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/skiplist_test.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -250,7 +250,7 @@ class ConcurrentTest {\n         // Note that generation 0 is never inserted, so it is ok if\n         // <*,0,*> is missing.\n         ASSERT_TRUE((gen(pos) == 0) ||\n-                    (gen(pos) > initial_state.Get(key(pos)))\n+                    (gen(pos) > static_cast<Key>(initial_state.Get(key(pos))))\n                     ) << \"key: \" << key(pos)\n                       << \"; gen: \" << gen(pos)\n                       << \"; initgen: \""
      },
      {
        "sha": "6ed413c42d4f4a8d531fba2d53617605741046dc",
        "filename": "src/leveldb/db/snapshot.h",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/snapshot.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/snapshot.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/snapshot.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -5,6 +5,7 @@\n #ifndef STORAGE_LEVELDB_DB_SNAPSHOT_H_\n #define STORAGE_LEVELDB_DB_SNAPSHOT_H_\n \n+#include \"db/dbformat.h\"\n #include \"leveldb/db.h\"\n \n namespace leveldb {"
      },
      {
        "sha": "a5e0f77a6a91312eaffe69352d79fd4416d764b3",
        "filename": "src/leveldb/db/version_set.cc",
        "status": "modified",
        "additions": 39,
        "deletions": 1,
        "changes": 40,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/version_set.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/version_set.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/version_set.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -893,7 +893,7 @@ Status VersionSet::LogAndApply(VersionEdit* edit, port::Mutex* mu) {\n   return s;\n }\n \n-Status VersionSet::Recover() {\n+Status VersionSet::Recover(bool *save_manifest) {\n   struct LogReporter : public log::Reader::Reporter {\n     Status* status;\n     virtual void Corruption(size_t bytes, const Status& s) {\n@@ -1003,11 +1003,49 @@ Status VersionSet::Recover() {\n     last_sequence_ = last_sequence;\n     log_number_ = log_number;\n     prev_log_number_ = prev_log_number;\n+\n+    // See if we can reuse the existing MANIFEST file.\n+    if (ReuseManifest(dscname, current)) {\n+      // No need to save new manifest\n+    } else {\n+      *save_manifest = true;\n+    }\n   }\n \n   return s;\n }\n \n+bool VersionSet::ReuseManifest(const std::string& dscname,\n+                               const std::string& dscbase) {\n+  if (!options_->reuse_logs) {\n+    return false;\n+  }\n+  FileType manifest_type;\n+  uint64_t manifest_number;\n+  uint64_t manifest_size;\n+  if (!ParseFileName(dscbase, &manifest_number, &manifest_type) ||\n+      manifest_type != kDescriptorFile ||\n+      !env_->GetFileSize(dscname, &manifest_size).ok() ||\n+      // Make new compacted MANIFEST if old one is too big\n+      manifest_size >= kTargetFileSize) {\n+    return false;\n+  }\n+\n+  assert(descriptor_file_ == NULL);\n+  assert(descriptor_log_ == NULL);\n+  Status r = env_->NewAppendableFile(dscname, &descriptor_file_);\n+  if (!r.ok()) {\n+    Log(options_->info_log, \"Reuse MANIFEST: %s\\n\", r.ToString().c_str());\n+    assert(descriptor_file_ == NULL);\n+    return false;\n+  }\n+\n+  Log(options_->info_log, \"Reusing MANIFEST %s\\n\", dscname.c_str());\n+  descriptor_log_ = new log::Writer(descriptor_file_, manifest_size);\n+  manifest_file_number_ = manifest_number;\n+  return true;\n+}\n+\n void VersionSet::MarkFileNumberUsed(uint64_t number) {\n   if (next_file_number_ <= number) {\n     next_file_number_ = number + 1;"
      },
      {
        "sha": "1dec74567380915988f9dbb3beffa98a85c97cd2",
        "filename": "src/leveldb/db/version_set.h",
        "status": "modified",
        "additions": 3,
        "deletions": 1,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/version_set.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/version_set.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/version_set.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -179,7 +179,7 @@ class VersionSet {\n       EXCLUSIVE_LOCKS_REQUIRED(mu);\n \n   // Recover the last saved descriptor from persistent storage.\n-  Status Recover();\n+  Status Recover(bool *save_manifest);\n \n   // Return the current version.\n   Version* current() const { return current_; }\n@@ -274,6 +274,8 @@ class VersionSet {\n   friend class Compaction;\n   friend class Version;\n \n+  bool ReuseManifest(const std::string& dscname, const std::string& dscbase);\n+\n   void Finalize(Version* v);\n \n   void GetRange(const std::vector<FileMetaData*>& inputs,"
      },
      {
        "sha": "9448ef7b21c3af42c570cf91391694bc6369972e",
        "filename": "src/leveldb/db/write_batch_internal.h",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/write_batch_internal.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/db/write_batch_internal.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/write_batch_internal.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -5,6 +5,7 @@\n #ifndef STORAGE_LEVELDB_DB_WRITE_BATCH_INTERNAL_H_\n #define STORAGE_LEVELDB_DB_WRITE_BATCH_INTERNAL_H_\n \n+#include \"db/dbformat.h\"\n #include \"leveldb/write_batch.h\"\n \n namespace leveldb {"
      },
      {
        "sha": "2155192581e7b79784564f190a47138ae29461f0",
        "filename": "src/leveldb/doc/index.html",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/doc/index.html",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/doc/index.html",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/doc/index.html?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -22,7 +22,7 @@ <h1>Opening A Database</h1>\n creating it if necessary:\n <p>\n <pre>\n-  #include &lt;assert&gt;\n+  #include &lt;cassert&gt;\n   #include \"leveldb/db.h\"\n \n   leveldb::DB* db;"
      },
      {
        "sha": "9a98884daf8d40247a0c57ab5c559ae86010501d",
        "filename": "src/leveldb/helpers/memenv/memenv.cc",
        "status": "modified",
        "additions": 13,
        "deletions": 0,
        "changes": 13,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/helpers/memenv/memenv.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/helpers/memenv/memenv.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/helpers/memenv/memenv.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -277,6 +277,19 @@ class InMemoryEnv : public EnvWrapper {\n     return Status::OK();\n   }\n \n+  virtual Status NewAppendableFile(const std::string& fname,\n+                                   WritableFile** result) {\n+    MutexLock lock(&mutex_);\n+    FileState** sptr = &file_map_[fname];\n+    FileState* file = *sptr;\n+    if (file == NULL) {\n+      file = new FileState();\n+      file->Ref();\n+    }\n+    *result = new WritableFileImpl(file);\n+    return Status::OK();\n+  }\n+\n   virtual bool FileExists(const std::string& fname) {\n     MutexLock lock(&mutex_);\n     return file_map_.find(fname) != file_map_.end();"
      },
      {
        "sha": "5cff77613f11df5eb6adcd8b2fd99310264edbd2",
        "filename": "src/leveldb/helpers/memenv/memenv_test.cc",
        "status": "modified",
        "additions": 11,
        "deletions": 2,
        "changes": 13,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/helpers/memenv/memenv_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/helpers/memenv/memenv_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/helpers/memenv/memenv_test.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -40,6 +40,8 @@ TEST(MemEnvTest, Basics) {\n \n   // Create a file.\n   ASSERT_OK(env_->NewWritableFile(\"/dir/f\", &writable_file));\n+  ASSERT_OK(env_->GetFileSize(\"/dir/f\", &file_size));\n+  ASSERT_EQ(0, file_size);\n   delete writable_file;\n \n   // Check that the file exists.\n@@ -55,17 +57,24 @@ TEST(MemEnvTest, Basics) {\n   ASSERT_OK(writable_file->Append(\"abc\"));\n   delete writable_file;\n \n-  // Check for expected size.\n+  // Check that append works.\n+  ASSERT_OK(env_->NewAppendableFile(\"/dir/f\", &writable_file));\n   ASSERT_OK(env_->GetFileSize(\"/dir/f\", &file_size));\n   ASSERT_EQ(3, file_size);\n+  ASSERT_OK(writable_file->Append(\"hello\"));\n+  delete writable_file;\n+\n+  // Check for expected size.\n+  ASSERT_OK(env_->GetFileSize(\"/dir/f\", &file_size));\n+  ASSERT_EQ(8, file_size);\n \n   // Check that renaming works.\n   ASSERT_TRUE(!env_->RenameFile(\"/dir/non_existent\", \"/dir/g\").ok());\n   ASSERT_OK(env_->RenameFile(\"/dir/f\", \"/dir/g\"));\n   ASSERT_TRUE(!env_->FileExists(\"/dir/f\"));\n   ASSERT_TRUE(env_->FileExists(\"/dir/g\"));\n   ASSERT_OK(env_->GetFileSize(\"/dir/g\", &file_size));\n-  ASSERT_EQ(3, file_size);\n+  ASSERT_EQ(8, file_size);\n \n   // Check that opening non-existent file fails.\n   SequentialFile* seq_file;"
      },
      {
        "sha": "6819d5bc49f674d47cddf0b23ade8a19d316051c",
        "filename": "src/leveldb/include/leveldb/cache.h",
        "status": "modified",
        "additions": 11,
        "deletions": 0,
        "changes": 11,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/cache.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/cache.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/cache.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -81,6 +81,17 @@ class Cache {\n   // its cache keys.\n   virtual uint64_t NewId() = 0;\n \n+  // Remove all cache entries that are not actively in use.  Memory-constrained\n+  // applications may wish to call this method to reduce memory usage.\n+  // Default implementation of Prune() does nothing.  Subclasses are strongly\n+  // encouraged to override the default implementation.  A future release of\n+  // leveldb may change Prune() to a pure abstract method.\n+  virtual void Prune() {}\n+\n+  // Return an estimate of the combined charges of all elements stored in the\n+  // cache.\n+  virtual size_t TotalCharge() const = 0;\n+\n  private:\n   void LRU_Remove(Handle* e);\n   void LRU_Append(Handle* e);"
      },
      {
        "sha": "9752cbad512de5ce11c9cdabb65fdb763f4da118",
        "filename": "src/leveldb/include/leveldb/db.h",
        "status": "modified",
        "additions": 3,
        "deletions": 1,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/db.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/db.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/db.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -14,7 +14,7 @@ namespace leveldb {\n \n // Update Makefile if you change these\n static const int kMajorVersion = 1;\n-static const int kMinorVersion = 18;\n+static const int kMinorVersion = 19;\n \n struct Options;\n struct ReadOptions;\n@@ -115,6 +115,8 @@ class DB {\n   //     about the internal operation of the DB.\n   //  \"leveldb.sstables\" - returns a multi-line string that describes all\n   //     of the sstables that make up the db contents.\n+  //  \"leveldb.approximate-memory-usage\" - returns the approximate number of\n+  //     bytes of memory in use by the DB.\n   virtual bool GetProperty(const Slice& property, std::string* value) = 0;\n \n   // For each i in [0,n-1], store in \"sizes[i]\", the approximate"
      },
      {
        "sha": "99b6c21414b2e6c2d66b0b1a7674923e41b01976",
        "filename": "src/leveldb/include/leveldb/env.h",
        "status": "modified",
        "additions": 18,
        "deletions": 0,
        "changes": 18,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/env.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/env.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/env.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -69,6 +69,21 @@ class Env {\n   virtual Status NewWritableFile(const std::string& fname,\n                                  WritableFile** result) = 0;\n \n+  // Create an object that either appends to an existing file, or\n+  // writes to a new file (if the file does not exist to begin with).\n+  // On success, stores a pointer to the new file in *result and\n+  // returns OK.  On failure stores NULL in *result and returns\n+  // non-OK.\n+  //\n+  // The returned file will only be accessed by one thread at a time.\n+  //\n+  // May return an IsNotSupportedError error if this Env does\n+  // not allow appending to an existing file.  Users of Env (including\n+  // the leveldb implementation) must be prepared to deal with\n+  // an Env that does not support appending.\n+  virtual Status NewAppendableFile(const std::string& fname,\n+                                   WritableFile** result);\n+\n   // Returns true iff the named file exists.\n   virtual bool FileExists(const std::string& fname) = 0;\n \n@@ -289,6 +304,9 @@ class EnvWrapper : public Env {\n   Status NewWritableFile(const std::string& f, WritableFile** r) {\n     return target_->NewWritableFile(f, r);\n   }\n+  Status NewAppendableFile(const std::string& f, WritableFile** r) {\n+    return target_->NewAppendableFile(f, r);\n+  }\n   bool FileExists(const std::string& f) { return target_->FileExists(f); }\n   Status GetChildren(const std::string& dir, std::vector<std::string>* r) {\n     return target_->GetChildren(dir, r);"
      },
      {
        "sha": "da631ed9d89bbc9cb764a624d8d5a26c34a626b7",
        "filename": "src/leveldb/include/leveldb/iterator.h",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/iterator.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/iterator.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/iterator.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -37,7 +37,7 @@ class Iterator {\n   // Valid() after this call iff the source is not empty.\n   virtual void SeekToLast() = 0;\n \n-  // Position at the first key in the source that at or past target\n+  // Position at the first key in the source that is at or past target.\n   // The iterator is Valid() after this call iff the source contains\n   // an entry that comes at or past target.\n   virtual void Seek(const Slice& target) = 0;"
      },
      {
        "sha": "83a1ef39a4814d684006f5dd4980d4c01a2458ed",
        "filename": "src/leveldb/include/leveldb/options.h",
        "status": "modified",
        "additions": 6,
        "deletions": 0,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/options.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/options.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/options.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -128,6 +128,12 @@ struct Options {\n   // efficiently detect that and will switch to uncompressed mode.\n   CompressionType compression;\n \n+  // EXPERIMENTAL: If true, append to existing MANIFEST and log files\n+  // when a database is opened.  This can significantly speed up open.\n+  //\n+  // Default: currently false, but may become true later.\n+  bool reuse_logs;\n+\n   // If non-NULL, use the specified filter policy to reduce disk reads.\n   // Many applications will benefit from passing the result of\n   // NewBloomFilterPolicy() here."
      },
      {
        "sha": "d9575f97532eb1e64451a9965a5076be99656610",
        "filename": "src/leveldb/include/leveldb/status.h",
        "status": "modified",
        "additions": 6,
        "deletions": 0,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/status.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/include/leveldb/status.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/status.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -60,6 +60,12 @@ class Status {\n   // Returns true iff the status indicates an IOError.\n   bool IsIOError() const { return code() == kIOError; }\n \n+  // Returns true iff the status indicates a NotSupportedError.\n+  bool IsNotSupportedError() const { return code() == kNotSupported; }\n+\n+  // Returns true iff the status indicates an InvalidArgument.\n+  bool IsInvalidArgument() const { return code() == kInvalidArgument; }\n+\n   // Return a string representation of this status suitable for printing.\n   // Returns the string \"OK\" for success.\n   std::string ToString() const;"
      },
      {
        "sha": "1c4c7aafc63eb86e11062ebda13d1038287d5dfc",
        "filename": "src/leveldb/port/atomic_pointer.h",
        "status": "modified",
        "additions": 19,
        "deletions": 0,
        "changes": 19,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/port/atomic_pointer.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/port/atomic_pointer.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/atomic_pointer.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -35,8 +35,12 @@\n #define ARCH_CPU_X86_FAMILY 1\n #elif defined(__ARMEL__)\n #define ARCH_CPU_ARM_FAMILY 1\n+#elif defined(__aarch64__)\n+#define ARCH_CPU_ARM64_FAMILY 1\n #elif defined(__ppc__) || defined(__powerpc__) || defined(__powerpc64__)\n #define ARCH_CPU_PPC_FAMILY 1\n+#elif defined(__mips__)\n+#define ARCH_CPU_MIPS_FAMILY 1\n #endif\n \n namespace leveldb {\n@@ -92,6 +96,13 @@ inline void MemoryBarrier() {\n }\n #define LEVELDB_HAVE_MEMORY_BARRIER\n \n+// ARM64\n+#elif defined(ARCH_CPU_ARM64_FAMILY)\n+inline void MemoryBarrier() {\n+  asm volatile(\"dmb sy\" : : : \"memory\");\n+}\n+#define LEVELDB_HAVE_MEMORY_BARRIER\n+\n // PPC\n #elif defined(ARCH_CPU_PPC_FAMILY) && defined(__GNUC__)\n inline void MemoryBarrier() {\n@@ -101,6 +112,13 @@ inline void MemoryBarrier() {\n }\n #define LEVELDB_HAVE_MEMORY_BARRIER\n \n+// MIPS\n+#elif defined(ARCH_CPU_MIPS_FAMILY) && defined(__GNUC__)\n+inline void MemoryBarrier() {\n+  __asm__ __volatile__(\"sync\" : : : \"memory\");\n+}\n+#define LEVELDB_HAVE_MEMORY_BARRIER\n+\n #endif\n \n // AtomicPointer built using platform-specific MemoryBarrier()\n@@ -215,6 +233,7 @@ class AtomicPointer {\n #undef LEVELDB_HAVE_MEMORY_BARRIER\n #undef ARCH_CPU_X86_FAMILY\n #undef ARCH_CPU_ARM_FAMILY\n+#undef ARCH_CPU_ARM64_FAMILY\n #undef ARCH_CPU_PPC_FAMILY\n \n }  // namespace port"
      },
      {
        "sha": "30e8007ae3cf11e6b82c1f0cd71627525515f045",
        "filename": "src/leveldb/port/port_posix.cc",
        "status": "modified",
        "additions": 0,
        "deletions": 1,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/port/port_posix.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/port/port_posix.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/port_posix.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -7,7 +7,6 @@\n #include <cstdlib>\n #include <stdio.h>\n #include <string.h>\n-#include \"util/logging.h\"\n \n namespace leveldb {\n namespace port {"
      },
      {
        "sha": "4e78b954f8d90c9c0aa0b4fd3ccff19ce8bdd62b",
        "filename": "src/leveldb/table/filter_block.cc",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/table/filter_block.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/table/filter_block.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/filter_block.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -68,7 +68,7 @@ void FilterBlockBuilder::GenerateFilter() {\n \n   // Generate filter for current set of keys and append to result_.\n   filter_offsets_.push_back(result_.size());\n-  policy_->CreateFilter(&tmp_keys_[0], num_keys, &result_);\n+  policy_->CreateFilter(&tmp_keys_[0], static_cast<int>(num_keys), &result_);\n \n   tmp_keys_.clear();\n   keys_.clear();\n@@ -97,7 +97,7 @@ bool FilterBlockReader::KeyMayMatch(uint64_t block_offset, const Slice& key) {\n   if (index < num_) {\n     uint32_t start = DecodeFixed32(offset_ + index*4);\n     uint32_t limit = DecodeFixed32(offset_ + index*4 + 4);\n-    if (start <= limit && limit <= (offset_ - data_)) {\n+    if (start <= limit && limit <= static_cast<size_t>(offset_ - data_)) {\n       Slice filter = Slice(data_ + start, limit - start);\n       return policy_->KeyMayMatch(key, filter);\n     } else if (start == limit) {"
      },
      {
        "sha": "24e4e02445b8a01201e77a9697e2b0dd85255017",
        "filename": "src/leveldb/table/format.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 2,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/table/format.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/table/format.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/format.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -30,15 +30,14 @@ Status BlockHandle::DecodeFrom(Slice* input) {\n }\n \n void Footer::EncodeTo(std::string* dst) const {\n-#ifndef NDEBUG\n   const size_t original_size = dst->size();\n-#endif\n   metaindex_handle_.EncodeTo(dst);\n   index_handle_.EncodeTo(dst);\n   dst->resize(2 * BlockHandle::kMaxEncodedLength);  // Padding\n   PutFixed32(dst, static_cast<uint32_t>(kTableMagicNumber & 0xffffffffu));\n   PutFixed32(dst, static_cast<uint32_t>(kTableMagicNumber >> 32));\n   assert(dst->size() == original_size + kEncodedLength);\n+  (void)original_size;  // Disable unused variable warning.\n }\n \n Status Footer::DecodeFrom(Slice* input) {"
      },
      {
        "sha": "f410c3fabe61048eee669454496be9b8c9ac1d17",
        "filename": "src/leveldb/table/iterator_wrapper.h",
        "status": "modified",
        "additions": 3,
        "deletions": 0,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/table/iterator_wrapper.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/table/iterator_wrapper.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/iterator_wrapper.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -5,6 +5,9 @@\n #ifndef STORAGE_LEVELDB_TABLE_ITERATOR_WRAPPER_H_\n #define STORAGE_LEVELDB_TABLE_ITERATOR_WRAPPER_H_\n \n+#include \"leveldb/iterator.h\"\n+#include \"leveldb/slice.h\"\n+\n namespace leveldb {\n \n // A internal wrapper class with an interface similar to Iterator that"
      },
      {
        "sha": "decf8082cc1837802559886319cc40180fc7a5b8",
        "filename": "src/leveldb/table/table.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/table/table.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/table/table.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/table.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -82,7 +82,7 @@ Status Table::Open(const Options& options,\n     *table = new Table(rep);\n     (*table)->ReadMeta(footer);\n   } else {\n-    if (index_block) delete index_block;\n+    delete index_block;\n   }\n \n   return s;"
      },
      {
        "sha": "abf6e246ff8e2751c4d8830b3a84b453f62f38e6",
        "filename": "src/leveldb/table/table_test.cc",
        "status": "modified",
        "additions": 14,
        "deletions": 6,
        "changes": 20,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/table/table_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/table/table_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/table_test.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -853,12 +853,20 @@ TEST(TableTest, ApproximateOffsetOfCompressed) {\n   options.compression = kSnappyCompression;\n   c.Finish(options, &keys, &kvmap);\n \n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"abc\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k02\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k03\"),    2000,   3000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k04\"),    2000,   3000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"xyz\"),    4000,   6000));\n+  // Expected upper and lower bounds of space used by compressible strings.\n+  static const int kSlop = 1000;  // Compressor effectiveness varies.\n+  const int expected = 2500;  // 10000 * compression ratio (0.25)\n+  const int min_z = expected - kSlop;\n+  const int max_z = expected + kSlop;\n+\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"abc\"), 0, kSlop));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01\"), 0, kSlop));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k02\"), 0, kSlop));\n+  // Have now emitted a large compressible string, so adjust expected offset.\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k03\"), min_z, max_z));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k04\"), min_z, max_z));\n+  // Have now emitted two large compressible strings, so adjust expected offset.\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"xyz\"), 2 * min_z, 2 * max_z));\n }\n \n }  // namespace leveldb"
      },
      {
        "sha": "74078213eedac2069d5704e2aad7a444d0c4c2ea",
        "filename": "src/leveldb/util/arena.cc",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/arena.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/arena.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/arena.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -9,8 +9,7 @@ namespace leveldb {\n \n static const int kBlockSize = 4096;\n \n-Arena::Arena() {\n-  blocks_memory_ = 0;\n+Arena::Arena() : memory_usage_(0) {\n   alloc_ptr_ = NULL;  // First allocation will allocate a block\n   alloc_bytes_remaining_ = 0;\n }\n@@ -60,8 +59,9 @@ char* Arena::AllocateAligned(size_t bytes) {\n \n char* Arena::AllocateNewBlock(size_t block_bytes) {\n   char* result = new char[block_bytes];\n-  blocks_memory_ += block_bytes;\n   blocks_.push_back(result);\n+  memory_usage_.NoBarrier_Store(\n+      reinterpret_cast<void*>(MemoryUsage() + block_bytes + sizeof(char*)));\n   return result;\n }\n "
      },
      {
        "sha": "48bab3374159543f1d261f60467d4563c9103a8a",
        "filename": "src/leveldb/util/arena.h",
        "status": "modified",
        "additions": 5,
        "deletions": 5,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/arena.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/arena.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/arena.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -9,6 +9,7 @@\n #include <assert.h>\n #include <stddef.h>\n #include <stdint.h>\n+#include \"port/port.h\"\n \n namespace leveldb {\n \n@@ -24,10 +25,9 @@ class Arena {\n   char* AllocateAligned(size_t bytes);\n \n   // Returns an estimate of the total memory usage of data allocated\n-  // by the arena (including space allocated but not yet used for user\n-  // allocations).\n+  // by the arena.\n   size_t MemoryUsage() const {\n-    return blocks_memory_ + blocks_.capacity() * sizeof(char*);\n+    return reinterpret_cast<uintptr_t>(memory_usage_.NoBarrier_Load());\n   }\n \n  private:\n@@ -41,8 +41,8 @@ class Arena {\n   // Array of new[] allocated memory blocks\n   std::vector<char*> blocks_;\n \n-  // Bytes of memory in blocks allocated so far\n-  size_t blocks_memory_;\n+  // Total memory usage of the arena.\n+  port::AtomicPointer memory_usage_;\n \n   // No copying allowed\n   Arena(const Arena&);"
      },
      {
        "sha": "bf3e4ca6e93146b056fdff7eb5dfd5e397f52df7",
        "filename": "src/leveldb/util/bloom.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/bloom.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/bloom.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/bloom.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -47,7 +47,7 @@ class BloomFilterPolicy : public FilterPolicy {\n     dst->resize(init_size + bytes, 0);\n     dst->push_back(static_cast<char>(k_));  // Remember # of probes in filter\n     char* array = &(*dst)[init_size];\n-    for (size_t i = 0; i < n; i++) {\n+    for (int i = 0; i < n; i++) {\n       // Use double-hashing to generate a sequence of hash values.\n       // See analysis in [Kirsch,Mitzenmacher 2006].\n       uint32_t h = BloomHash(keys[i]);"
      },
      {
        "sha": "1b87a2be3f540c673ee1749b0b855d396251f5aa",
        "filename": "src/leveldb/util/bloom_test.cc",
        "status": "modified",
        "additions": 2,
        "deletions": 1,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/bloom_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/bloom_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/bloom_test.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -46,7 +46,8 @@ class BloomTest {\n       key_slices.push_back(Slice(keys_[i]));\n     }\n     filter_.clear();\n-    policy_->CreateFilter(&key_slices[0], key_slices.size(), &filter_);\n+    policy_->CreateFilter(&key_slices[0], static_cast<int>(key_slices.size()),\n+                          &filter_);\n     keys_.clear();\n     if (kVerbose >= 2) DumpFilter();\n   }"
      },
      {
        "sha": "ce46886171ad446e6b78340c800fbce3df903e3e",
        "filename": "src/leveldb/util/cache.cc",
        "status": "modified",
        "additions": 108,
        "deletions": 28,
        "changes": 136,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/cache.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/cache.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/cache.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -19,6 +19,23 @@ Cache::~Cache() {\n namespace {\n \n // LRU cache implementation\n+//\n+// Cache entries have an \"in_cache\" boolean indicating whether the cache has a\n+// reference on the entry.  The only ways that this can become false without the\n+// entry being passed to its \"deleter\" are via Erase(), via Insert() when\n+// an element with a duplicate key is inserted, or on destruction of the cache.\n+//\n+// The cache keeps two linked lists of items in the cache.  All items in the\n+// cache are in one list or the other, and never both.  Items still referenced\n+// by clients but erased from the cache are in neither list.  The lists are:\n+// - in-use:  contains the items currently referenced by clients, in no\n+//   particular order.  (This list is used for invariant checking.  If we\n+//   removed the check, elements that would otherwise be on this list could be\n+//   left as disconnected singleton lists.)\n+// - LRU:  contains the items not currently referenced by clients, in LRU order\n+// Elements are moved between these lists by the Ref() and Unref() methods,\n+// when they detect an element in the cache acquiring or losing its only\n+// external reference.\n \n // An entry is a variable length heap-allocated structure.  Entries\n // are kept in a circular doubly linked list ordered by access time.\n@@ -30,7 +47,8 @@ struct LRUHandle {\n   LRUHandle* prev;\n   size_t charge;      // TODO(opt): Only allow uint32_t?\n   size_t key_length;\n-  uint32_t refs;\n+  bool in_cache;      // Whether entry is in the cache.\n+  uint32_t refs;      // References, including cache reference, if present.\n   uint32_t hash;      // Hash of key(); used for fast sharding and comparisons\n   char key_data[1];   // Beginning of key\n \n@@ -147,49 +165,77 @@ class LRUCache {\n   Cache::Handle* Lookup(const Slice& key, uint32_t hash);\n   void Release(Cache::Handle* handle);\n   void Erase(const Slice& key, uint32_t hash);\n+  void Prune();\n+  size_t TotalCharge() const {\n+    MutexLock l(&mutex_);\n+    return usage_;\n+  }\n \n  private:\n   void LRU_Remove(LRUHandle* e);\n-  void LRU_Append(LRUHandle* e);\n+  void LRU_Append(LRUHandle*list, LRUHandle* e);\n+  void Ref(LRUHandle* e);\n   void Unref(LRUHandle* e);\n+  bool FinishErase(LRUHandle* e);\n \n   // Initialized before use.\n   size_t capacity_;\n \n   // mutex_ protects the following state.\n-  port::Mutex mutex_;\n+  mutable port::Mutex mutex_;\n   size_t usage_;\n \n   // Dummy head of LRU list.\n   // lru.prev is newest entry, lru.next is oldest entry.\n+  // Entries have refs==1 and in_cache==true.\n   LRUHandle lru_;\n \n+  // Dummy head of in-use list.\n+  // Entries are in use by clients, and have refs >= 2 and in_cache==true.\n+  LRUHandle in_use_;\n+\n   HandleTable table_;\n };\n \n LRUCache::LRUCache()\n     : usage_(0) {\n-  // Make empty circular linked list\n+  // Make empty circular linked lists.\n   lru_.next = &lru_;\n   lru_.prev = &lru_;\n+  in_use_.next = &in_use_;\n+  in_use_.prev = &in_use_;\n }\n \n LRUCache::~LRUCache() {\n+  assert(in_use_.next == &in_use_);  // Error if caller has an unreleased handle\n   for (LRUHandle* e = lru_.next; e != &lru_; ) {\n     LRUHandle* next = e->next;\n-    assert(e->refs == 1);  // Error if caller has an unreleased handle\n+    assert(e->in_cache);\n+    e->in_cache = false;\n+    assert(e->refs == 1);  // Invariant of lru_ list.\n     Unref(e);\n     e = next;\n   }\n }\n \n+void LRUCache::Ref(LRUHandle* e) {\n+  if (e->refs == 1 && e->in_cache) {  // If on lru_ list, move to in_use_ list.\n+    LRU_Remove(e);\n+    LRU_Append(&in_use_, e);\n+  }\n+  e->refs++;\n+}\n+\n void LRUCache::Unref(LRUHandle* e) {\n   assert(e->refs > 0);\n   e->refs--;\n-  if (e->refs <= 0) {\n-    usage_ -= e->charge;\n+  if (e->refs == 0) { // Deallocate.\n+    assert(!e->in_cache);\n     (*e->deleter)(e->key(), e->value);\n     free(e);\n+  } else if (e->in_cache && e->refs == 1) {  // No longer in use; move to lru_ list.\n+    LRU_Remove(e);\n+    LRU_Append(&lru_, e);\n   }\n }\n \n@@ -198,10 +244,10 @@ void LRUCache::LRU_Remove(LRUHandle* e) {\n   e->prev->next = e->next;\n }\n \n-void LRUCache::LRU_Append(LRUHandle* e) {\n-  // Make \"e\" newest entry by inserting just before lru_\n-  e->next = &lru_;\n-  e->prev = lru_.prev;\n+void LRUCache::LRU_Append(LRUHandle* list, LRUHandle* e) {\n+  // Make \"e\" newest entry by inserting just before *list\n+  e->next = list;\n+  e->prev = list->prev;\n   e->prev->next = e;\n   e->next->prev = e;\n }\n@@ -210,9 +256,7 @@ Cache::Handle* LRUCache::Lookup(const Slice& key, uint32_t hash) {\n   MutexLock l(&mutex_);\n   LRUHandle* e = table_.Lookup(key, hash);\n   if (e != NULL) {\n-    e->refs++;\n-    LRU_Remove(e);\n-    LRU_Append(e);\n+    Ref(e);\n   }\n   return reinterpret_cast<Cache::Handle*>(e);\n }\n@@ -234,34 +278,58 @@ Cache::Handle* LRUCache::Insert(\n   e->charge = charge;\n   e->key_length = key.size();\n   e->hash = hash;\n-  e->refs = 2;  // One from LRUCache, one for the returned handle\n+  e->in_cache = false;\n+  e->refs = 1;  // for the returned handle.\n   memcpy(e->key_data, key.data(), key.size());\n-  LRU_Append(e);\n-  usage_ += charge;\n \n-  LRUHandle* old = table_.Insert(e);\n-  if (old != NULL) {\n-    LRU_Remove(old);\n-    Unref(old);\n-  }\n+  if (capacity_ > 0) {\n+    e->refs++;  // for the cache's reference.\n+    e->in_cache = true;\n+    LRU_Append(&in_use_, e);\n+    usage_ += charge;\n+    FinishErase(table_.Insert(e));\n+  } // else don't cache.  (Tests use capacity_==0 to turn off caching.)\n \n   while (usage_ > capacity_ && lru_.next != &lru_) {\n     LRUHandle* old = lru_.next;\n-    LRU_Remove(old);\n-    table_.Remove(old->key(), old->hash);\n-    Unref(old);\n+    assert(old->refs == 1);\n+    bool erased = FinishErase(table_.Remove(old->key(), old->hash));\n+    if (!erased) {  // to avoid unused variable when compiled NDEBUG\n+      assert(erased);\n+    }\n   }\n \n   return reinterpret_cast<Cache::Handle*>(e);\n }\n \n-void LRUCache::Erase(const Slice& key, uint32_t hash) {\n-  MutexLock l(&mutex_);\n-  LRUHandle* e = table_.Remove(key, hash);\n+// If e != NULL, finish removing *e from the cache; it has already been removed\n+// from the hash table.  Return whether e != NULL.  Requires mutex_ held.\n+bool LRUCache::FinishErase(LRUHandle* e) {\n   if (e != NULL) {\n+    assert(e->in_cache);\n     LRU_Remove(e);\n+    e->in_cache = false;\n+    usage_ -= e->charge;\n     Unref(e);\n   }\n+  return e != NULL;\n+}\n+\n+void LRUCache::Erase(const Slice& key, uint32_t hash) {\n+  MutexLock l(&mutex_);\n+  FinishErase(table_.Remove(key, hash));\n+}\n+\n+void LRUCache::Prune() {\n+  MutexLock l(&mutex_);\n+  while (lru_.next != &lru_) {\n+    LRUHandle* e = lru_.next;\n+    assert(e->refs == 1);\n+    bool erased = FinishErase(table_.Remove(e->key(), e->hash));\n+    if (!erased) {  // to avoid unused variable when compiled NDEBUG\n+      assert(erased);\n+    }\n+  }\n }\n \n static const int kNumShardBits = 4;\n@@ -314,6 +382,18 @@ class ShardedLRUCache : public Cache {\n     MutexLock l(&id_mutex_);\n     return ++(last_id_);\n   }\n+  virtual void Prune() {\n+    for (int s = 0; s < kNumShards; s++) {\n+      shard_[s].Prune();\n+    }\n+  }\n+  virtual size_t TotalCharge() const {\n+    size_t total = 0;\n+    for (int s = 0; s < kNumShards; s++) {\n+      total += shard_[s].TotalCharge();\n+    }\n+    return total;\n+  }\n };\n \n }  // end anonymous namespace"
      },
      {
        "sha": "468f7a6425bfa92ff05bb412202846ddc263f8f8",
        "filename": "src/leveldb/util/cache_test.cc",
        "status": "modified",
        "additions": 41,
        "deletions": 1,
        "changes": 42,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/cache_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/cache_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/cache_test.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -59,6 +59,11 @@ class CacheTest {\n                                    &CacheTest::Deleter));\n   }\n \n+  Cache::Handle* InsertAndReturnHandle(int key, int value, int charge = 1) {\n+    return cache_->Insert(EncodeKey(key), EncodeValue(value), charge,\n+                          &CacheTest::Deleter);\n+  }\n+\n   void Erase(int key) {\n     cache_->Erase(EncodeKey(key));\n   }\n@@ -135,15 +140,37 @@ TEST(CacheTest, EntriesArePinned) {\n TEST(CacheTest, EvictionPolicy) {\n   Insert(100, 101);\n   Insert(200, 201);\n+  Insert(300, 301);\n+  Cache::Handle* h = cache_->Lookup(EncodeKey(300));\n \n-  // Frequently used entry must be kept around\n+  // Frequently used entry must be kept around,\n+  // as must things that are still in use.\n   for (int i = 0; i < kCacheSize + 100; i++) {\n     Insert(1000+i, 2000+i);\n     ASSERT_EQ(2000+i, Lookup(1000+i));\n     ASSERT_EQ(101, Lookup(100));\n   }\n   ASSERT_EQ(101, Lookup(100));\n   ASSERT_EQ(-1, Lookup(200));\n+  ASSERT_EQ(301, Lookup(300));\n+  cache_->Release(h);\n+}\n+\n+TEST(CacheTest, UseExceedsCacheSize) {\n+  // Overfill the cache, keeping handles on all inserted entries.\n+  std::vector<Cache::Handle*> h;\n+  for (int i = 0; i < kCacheSize + 100; i++) {\n+    h.push_back(InsertAndReturnHandle(1000+i, 2000+i));\n+  }\n+\n+  // Check that all the entries can be found in the cache.\n+  for (int i = 0; i < h.size(); i++) {\n+    ASSERT_EQ(2000+i, Lookup(1000+i));\n+  }\n+\n+  for (int i = 0; i < h.size(); i++) {\n+    cache_->Release(h[i]);\n+  }\n }\n \n TEST(CacheTest, HeavyEntries) {\n@@ -179,6 +206,19 @@ TEST(CacheTest, NewId) {\n   ASSERT_NE(a, b);\n }\n \n+TEST(CacheTest, Prune) {\n+  Insert(1, 100);\n+  Insert(2, 200);\n+\n+  Cache::Handle* handle = cache_->Lookup(EncodeKey(1));\n+  ASSERT_TRUE(handle);\n+  cache_->Prune();\n+  cache_->Release(handle);\n+\n+  ASSERT_EQ(100, Lookup(1));\n+  ASSERT_EQ(-1, Lookup(2));\n+}\n+\n }  // namespace leveldb\n \n int main(int argc, char** argv) {"
      },
      {
        "sha": "c58a0821ef7a3a8487d4449ce121ffdf9fcf87be",
        "filename": "src/leveldb/util/env.cc",
        "status": "modified",
        "additions": 4,
        "deletions": 0,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/env.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/env.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/env.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -9,6 +9,10 @@ namespace leveldb {\n Env::~Env() {\n }\n \n+Status Env::NewAppendableFile(const std::string& fname, WritableFile** result) {\n+  return Status::NotSupported(\"NewAppendableFile\", fname);\n+}\n+\n SequentialFile::~SequentialFile() {\n }\n "
      },
      {
        "sha": "e0fca52f4632a2a141dad0f6030393678d11bb7f",
        "filename": "src/leveldb/util/env_posix.cc",
        "status": "modified",
        "additions": 13,
        "deletions": 0,
        "changes": 13,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/env_posix.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/env_posix.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/env_posix.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -351,6 +351,19 @@ class PosixEnv : public Env {\n     return s;\n   }\n \n+  virtual Status NewAppendableFile(const std::string& fname,\n+                                   WritableFile** result) {\n+    Status s;\n+    FILE* f = fopen(fname.c_str(), \"a\");\n+    if (f == NULL) {\n+      *result = NULL;\n+      s = IOError(fname, errno);\n+    } else {\n+      *result = new PosixWritableFile(fname, f);\n+    }\n+    return s;\n+  }\n+\n   virtual bool FileExists(const std::string& fname) {\n     return access(fname.c_str(), F_OK) == 0;\n   }"
      },
      {
        "sha": "b074b7579ec2d377637112f4d5a9937f478637d6",
        "filename": "src/leveldb/util/env_win.cc",
        "status": "modified",
        "additions": 30,
        "deletions": 7,
        "changes": 37,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/env_win.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/env_win.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/env_win.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -106,7 +106,7 @@ class Win32RandomAccessFile : public RandomAccessFile\n class Win32WritableFile : public WritableFile\n {\n public:\n-    Win32WritableFile(const std::string& fname);\n+    Win32WritableFile(const std::string& fname, bool append);\n     ~Win32WritableFile();\n \n     virtual Status Append(const Slice& data);\n@@ -158,6 +158,8 @@ class Win32Env : public Env\n         RandomAccessFile** result);\n     virtual Status NewWritableFile(const std::string& fname,\n         WritableFile** result);\n+    virtual Status NewAppendableFile(const std::string& fname,\n+        WritableFile** result);\n \n     virtual bool FileExists(const std::string& fname);\n \n@@ -423,17 +425,23 @@ void Win32RandomAccessFile::_CleanUp()\n     }\n }\n \n-Win32WritableFile::Win32WritableFile(const std::string& fname)\n+Win32WritableFile::Win32WritableFile(const std::string& fname, bool append)\n     : filename_(fname)\n {\n     std::wstring path;\n     ToWidePath(fname, path);\n-    DWORD Flag = PathFileExistsW(path.c_str()) ? OPEN_EXISTING : CREATE_ALWAYS;\n+    // NewAppendableFile: append to an existing file, or create a new one\n+    //     if none exists - this is OPEN_ALWAYS behavior, with\n+    //     FILE_APPEND_DATA to avoid having to manually position the file\n+    //     pointer at the end of the file.\n+    // NewWritableFile: create a new file, delete if it exists - this is\n+    //     CREATE_ALWAYS behavior. This file is used for writing only so\n+    //     use GENERIC_WRITE.\n     _hFile = CreateFileW(path.c_str(),\n-                         GENERIC_READ | GENERIC_WRITE,\n+                         append ? FILE_APPEND_DATA : GENERIC_WRITE,\n                          FILE_SHARE_READ|FILE_SHARE_DELETE|FILE_SHARE_WRITE,\n                          NULL,\n-                         Flag,\n+                         append ? OPEN_ALWAYS : CREATE_ALWAYS,\n                          FILE_ATTRIBUTE_NORMAL,\n                          NULL);\n     // CreateFileW returns INVALID_HANDLE_VALUE in case of error, always check isEnable() before use\n@@ -823,7 +831,9 @@ Status Win32Env::NewLogger( const std::string& fname, Logger** result )\n {\n     Status sRet;\n     std::string path = fname;\n-    Win32WritableFile* pMapFile = new Win32WritableFile(ModifyPath(path));\n+    // Logs are opened with write semantics, not with append semantics\n+    // (see PosixEnv::NewLogger)\n+    Win32WritableFile* pMapFile = new Win32WritableFile(ModifyPath(path), false);\n     if(!pMapFile->isEnable()){\n         delete pMapFile;\n         *result = NULL;\n@@ -837,7 +847,20 @@ Status Win32Env::NewWritableFile( const std::string& fname, WritableFile** resul\n {\n     Status sRet;\n     std::string path = fname;\n-    Win32WritableFile* pFile = new Win32WritableFile(ModifyPath(path));\n+    Win32WritableFile* pFile = new Win32WritableFile(ModifyPath(path), false);\n+    if(!pFile->isEnable()){\n+        *result = NULL;\n+        sRet = Status::IOError(fname,Win32::GetLastErrSz());\n+    }else\n+        *result = pFile;\n+    return sRet;\n+}\n+\n+Status Win32Env::NewAppendableFile( const std::string& fname, WritableFile** result )\n+{\n+    Status sRet;\n+    std::string path = fname;\n+    Win32WritableFile* pFile = new Win32WritableFile(ModifyPath(path), true);\n     if(!pFile->isEnable()){\n         *result = NULL;\n         sRet = Status::IOError(fname,Win32::GetLastErrSz());"
      },
      {
        "sha": "8b618fb1ae858d9af8484b81b1cd6c2f60bb018b",
        "filename": "src/leveldb/util/options.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/options.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/options.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/options.cc?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -22,8 +22,8 @@ Options::Options()\n       block_size(4096),\n       block_restart_interval(16),\n       compression(kSnappyCompression),\n+      reuse_logs(false),\n       filter_policy(NULL) {\n }\n \n-\n }  // namespace leveldb"
      },
      {
        "sha": "d7e45837027db6d1d6235c43082bc20747c0571d",
        "filename": "src/leveldb/util/testutil.h",
        "status": "modified",
        "additions": 10,
        "deletions": 0,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/testutil.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/605d701471c3ee84682b0c149e41142d7cea95e7/src/leveldb/util/testutil.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/testutil.h?ref=605d701471c3ee84682b0c149e41142d7cea95e7",
        "patch": "@@ -45,6 +45,16 @@ class ErrorEnv : public EnvWrapper {\n     }\n     return target()->NewWritableFile(fname, result);\n   }\n+\n+  virtual Status NewAppendableFile(const std::string& fname,\n+                                   WritableFile** result) {\n+    if (writable_file_error_) {\n+      ++num_writable_file_errors_;\n+      *result = NULL;\n+      return Status::IOError(fname, \"fake error\");\n+    }\n+    return target()->NewAppendableFile(fname, result);\n+  }\n };\n \n }  // namespace test"
      }
    ]
  }
]