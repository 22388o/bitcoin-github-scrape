[
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/442751314",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#issuecomment-442751314",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/14837",
    "id": 442751314,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0Mjc1MTMxNA==",
    "user": {
      "login": "gmaxwell",
      "id": 858454,
      "node_id": "MDQ6VXNlcjg1ODQ1NA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/858454?u=63e5c438c242094837a9deeda775d77988b508bf&v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gmaxwell",
      "html_url": "https://github.com/gmaxwell",
      "followers_url": "https://api.github.com/users/gmaxwell/followers",
      "following_url": "https://api.github.com/users/gmaxwell/following{/other_user}",
      "gists_url": "https://api.github.com/users/gmaxwell/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gmaxwell/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gmaxwell/subscriptions",
      "organizations_url": "https://api.github.com/users/gmaxwell/orgs",
      "repos_url": "https://api.github.com/users/gmaxwell/repos",
      "events_url": "https://api.github.com/users/gmaxwell/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gmaxwell/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-29T08:42:27Z",
    "updated_at": "2018-11-29T08:42:27Z",
    "author_association": "CONTRIBUTOR",
    "body": " The argument that the CVE fix was a performance regression is based on a misunderstand of the system's current operation: Block validation is only very rarely on the critical path for block propagation.  This wasn't the case when the duplicate checking skipping was added, but it is the case now. I can't imagine that the PR to skip the \"redundant\" duplicate check would have gone through if it wasn't on the block propagation critical path then, so I can't see a change that is 10x+ more complicated being adopted now that its off the critical path.\r\n\r\nThis adds hundreds of lines of code and a homebrew cryptographic hash that AFAICT isn't particularly cryptographic but if broken turns into a DOS attack (and no, XORing a seed is does not obviously produce pairwise independence, which some approximation of is required to achieve the claimed property that a bad input for one user would be okay for others),  -- and it looks like doesn't actually result in an observable benefit except on microbenchmarks.  \r\n\r\nNAK.",
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/442751314/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/442757835",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#issuecomment-442757835",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/14837",
    "id": 442757835,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0Mjc1NzgzNQ==",
    "user": {
      "login": "JeremyRubin",
      "id": 886523,
      "node_id": "MDQ6VXNlcjg4NjUyMw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/886523?u=8cdd8653982252593843d7369ecfebe432b89768&v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/JeremyRubin",
      "html_url": "https://github.com/JeremyRubin",
      "followers_url": "https://api.github.com/users/JeremyRubin/followers",
      "following_url": "https://api.github.com/users/JeremyRubin/following{/other_user}",
      "gists_url": "https://api.github.com/users/JeremyRubin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/JeremyRubin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/JeremyRubin/subscriptions",
      "organizations_url": "https://api.github.com/users/JeremyRubin/orgs",
      "repos_url": "https://api.github.com/users/JeremyRubin/repos",
      "events_url": "https://api.github.com/users/JeremyRubin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/JeremyRubin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-29T09:05:01Z",
    "updated_at": "2018-11-29T09:05:01Z",
    "author_association": "CONTRIBUTOR",
    "body": "The main benefit I'm emphasizing here is that it checks more strict properties.\r\n\r\nAs noted. the stricter check need not introduce a 'DoS attack' -- it can revert to the existing runtime easily. In any case, our goal isn't really to validate a maliciously created block quickly, it is to validate an honestly created block as quickly as possible and a maliciously created block in tolerable time -- I figured that they O(N / log(N)) speedup to switch back to the set algorithm upon collision wasn't worth the added complexity there, but it can certainly be done.  \r\n\r\nThe PCG I am using is not homebrew (except in implementation). If you prefer, we could add a dependency to the standard PCG library which contains a similar function. Thus the unstudied portion is mostly limited to the inputs to the function. My understanding of PCG is such that the xor'd seed should produce pairwise independence, although I grant you that it may be better to use two different seeds k1_1 and k1_2.  Perhaps there are other efficiently computable prfs which have pairwise independence that would be suited for this purpose -- I previously used SIPHASH for this.",
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/442757835/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/442766164",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#issuecomment-442766164",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/14837",
    "id": 442766164,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0Mjc2NjE2NA==",
    "user": {
      "login": "DrahtBot",
      "id": 39886733,
      "node_id": "MDQ6VXNlcjM5ODg2NzMz",
      "avatar_url": "https://avatars.githubusercontent.com/u/39886733?u=3c1e73d828cf5a5850dfc25c8397c1cf751db5ac&v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/DrahtBot",
      "html_url": "https://github.com/DrahtBot",
      "followers_url": "https://api.github.com/users/DrahtBot/followers",
      "following_url": "https://api.github.com/users/DrahtBot/following{/other_user}",
      "gists_url": "https://api.github.com/users/DrahtBot/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/DrahtBot/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
      "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
      "repos_url": "https://api.github.com/users/DrahtBot/repos",
      "events_url": "https://api.github.com/users/DrahtBot/events{/privacy}",
      "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-29T09:31:58Z",
    "updated_at": "2019-04-10T04:53:10Z",
    "author_association": "CONTRIBUTOR",
    "body": "<!--e57a25ab6845829454e8d69fc972939a-->\n\nThe following sections might be updated with supplementary metadata relevant to reviewers and maintainers.\n\n<!--174a7506f384e20aa4161008e828411d-->\n### Conflicts\nReviewers, this pull request conflicts with the following ones:\n\n* [#15773](https://drahtbot.github.io/bitcoin_core_issue_redirect/r/15773.html) (test: Add BitcoinTestFramework::sync_* methods by MarcoFalke)\n* [#15639](https://drahtbot.github.io/bitcoin_core_issue_redirect/r/15639.html) (bitcoin-wallet tool: Drop libbitcoin_server.a dependency by ryanofsky)\n* [#15638](https://drahtbot.github.io/bitcoin_core_issue_redirect/r/15638.html) (Move-only: Pull wallet code out of libbitcoin_server by ryanofsky)\n* [#15141](https://drahtbot.github.io/bitcoin_core_issue_redirect/r/15141.html) (Rewrite DoS interface between validation and net_processing by sdaftuar)\n* [#14696](https://drahtbot.github.io/bitcoin_core_issue_redirect/r/14696.html) (qa: Add explicit references to related CVE's in p2p_invalid_block test. by lucash-dev)\n\nIf you consider this pull request important, please also help to review the conflicting pull requests. Ideally, start with the one that should be merged first.",
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/442766164/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/442881137",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#issuecomment-442881137",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/14837",
    "id": 442881137,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0Mjg4MTEzNw==",
    "user": {
      "login": "ryanofsky",
      "id": 7133040,
      "node_id": "MDQ6VXNlcjcxMzMwNDA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7133040?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ryanofsky",
      "html_url": "https://github.com/ryanofsky",
      "followers_url": "https://api.github.com/users/ryanofsky/followers",
      "following_url": "https://api.github.com/users/ryanofsky/following{/other_user}",
      "gists_url": "https://api.github.com/users/ryanofsky/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ryanofsky/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ryanofsky/subscriptions",
      "organizations_url": "https://api.github.com/users/ryanofsky/orgs",
      "repos_url": "https://api.github.com/users/ryanofsky/repos",
      "events_url": "https://api.github.com/users/ryanofsky/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ryanofsky/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-29T15:44:24Z",
    "updated_at": "2018-11-29T15:44:24Z",
    "author_association": "CONTRIBUTOR",
    "body": "> Stricter Invariants This PR checks stricter properties. Before this PR, a block might pass checkblock with duplicate inputs spent across transactions and invalid longchain order.\r\n\r\n> The main benefit I'm emphasizing here is that it checks more strict properties.\r\n\r\nWhat's the list of properties that this PR checks for? \"Invalid longchain order\" seems to mean that \"outputs being created by this transaction being have not been spent by an earlier transaction.\" Are there other checks, too?\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/442881137/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/442898663",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#issuecomment-442898663",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/14837",
    "id": 442898663,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0Mjg5ODY2Mw==",
    "user": {
      "login": "ryanofsky",
      "id": 7133040,
      "node_id": "MDQ6VXNlcjcxMzMwNDA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7133040?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ryanofsky",
      "html_url": "https://github.com/ryanofsky",
      "followers_url": "https://api.github.com/users/ryanofsky/followers",
      "following_url": "https://api.github.com/users/ryanofsky/following{/other_user}",
      "gists_url": "https://api.github.com/users/ryanofsky/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ryanofsky/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ryanofsky/subscriptions",
      "organizations_url": "https://api.github.com/users/ryanofsky/orgs",
      "repos_url": "https://api.github.com/users/ryanofsky/repos",
      "events_url": "https://api.github.com/users/ryanofsky/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ryanofsky/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-29T16:27:22Z",
    "updated_at": "2018-11-29T16:27:22Z",
    "author_association": "CONTRIBUTOR",
    "body": "> What's the list of properties that this PR checks for?\r\n\r\nFound the list here:\r\n\r\nhttps://github.com/JeremyRubin/bitcoin/blob/0425c6409000aeb3270ba8f9c30d2746c5c5b784/src/validation.cpp#L3078-L3086\r\n\r\nThe actual implementation of this is change is short, clean and not hard to understand. This change doesn't add \"hundreds of lines of code\", though it does add a lot of comments and analysis.\r\n\r\nIf it's true that \"Block validation is only very rarely on the critical path for block propagation\" then making this change by itself try to help with performance and complexity is probably not worth the risks. But I am curious about:\r\n\r\n> Enforcing stricter invariants in CheckBlock helps us guard against potential errors in later sections of the code and opens up the door to new optimizations, parallelizations, or simplifications in the application of transactions in a block. For instance, we could create all new UTXOS in parallel and then spend all inputs in parallel.\r\n\r\nThis is an interesting idea, even though it seems like it would require a lock-free CCoinsViewCache to improve performance. It does seem conceptually like adding an \"Invalid longchain order\" invariant could make future optimizations possible, so maybe this is worth thinking about more.",
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/442898663/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/443231239",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#issuecomment-443231239",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/14837",
    "id": 443231239,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MzIzMTIzOQ==",
    "user": {
      "login": "sdaftuar",
      "id": 7463573,
      "node_id": "MDQ6VXNlcjc0NjM1NzM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sdaftuar",
      "html_url": "https://github.com/sdaftuar",
      "followers_url": "https://api.github.com/users/sdaftuar/followers",
      "following_url": "https://api.github.com/users/sdaftuar/following{/other_user}",
      "gists_url": "https://api.github.com/users/sdaftuar/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
      "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
      "repos_url": "https://api.github.com/users/sdaftuar/repos",
      "events_url": "https://api.github.com/users/sdaftuar/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-30T15:05:57Z",
    "updated_at": "2018-11-30T15:05:57Z",
    "author_association": "MEMBER",
    "body": "I agree with @gmaxwell.  Adding complexity to the consensus code (or, as I often argue, changing it at all) should be something we do for only very good reasons, both because of the high review burden consensus code changes incur on the project, and because of the maintenance burden and cognitive load we put on future developers as well. \r\n\r\nI really don't think we should consider making consensus code changes that are designed to have no effect but prep the way for unspecified future code changes (which is why I often chime in with a Concept NACK on consensus refactoring PRs).  These incur all the review and testing costs of a consensus change, but by design have no benefit to the network.  This project is way too busy for this to be a good use of developer effort IMO.\r\n\r\nIn my view, if we're going to make changes to the consensus code for performance reasons, then (a) those performance numbers should be demonstrably and meaningfully better for the network, and (b) we should generally discuss all the designs that might achieve the same performance benefit, and have a very good reason for not choosing the simplest such design.  In the case of this change, the performance benefits could likely be realized by far simpler changes, as has been pointed out in the review comments on other versions of this PR.\r\n\r\nI do think that it would be a useful discussion to figure out exactly what would be the simplest code design for where the duplicate inputs check should live -- I've had some offline conversations and in my view it's not obvious whether it should naturally be considered a context-free check we perform on transactions, or whether the check should reside instead at the utxo database layer.  If we care to improve the underlying issue here, I think we would best served by engaging in that design discussion to come up with the simplest way of reasoning about things in the future.\r\n\r\nFinally -- I think we should remember that we're not just writing code for ourselves, but for hopefully a much larger set of future engineers.  If we are going to burden people with complicated reasoning about a consensus topic, it should be because it's really important.",
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/443231239/reactions",
      "total_count": 3,
      "+1": 3,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/443301640",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#issuecomment-443301640",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/14837",
    "id": 443301640,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0MzMwMTY0MA==",
    "user": {
      "login": "gmaxwell",
      "id": 858454,
      "node_id": "MDQ6VXNlcjg1ODQ1NA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/858454?u=63e5c438c242094837a9deeda775d77988b508bf&v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gmaxwell",
      "html_url": "https://github.com/gmaxwell",
      "followers_url": "https://api.github.com/users/gmaxwell/followers",
      "following_url": "https://api.github.com/users/gmaxwell/following{/other_user}",
      "gists_url": "https://api.github.com/users/gmaxwell/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gmaxwell/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gmaxwell/subscriptions",
      "organizations_url": "https://api.github.com/users/gmaxwell/orgs",
      "repos_url": "https://api.github.com/users/gmaxwell/repos",
      "events_url": "https://api.github.com/users/gmaxwell/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gmaxwell/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-11-30T18:50:12Z",
    "updated_at": "2018-11-30T18:50:12Z",
    "author_association": "CONTRIBUTOR",
    "body": "If there were a PR with some massive validation speedup that needed the new behaviour this provides, then it might be worth considering on the basis of that improvement.  But as conjectural prepatory work I just don't see the gain.\r\n\r\nTo the extent that there is an argument that belt-and-suspendering the consistent check would make the code safer holds -- I'm not sure about that, but I think it's at least plausible-- that could be accomplished with a simpler and clearer check.",
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/443301640/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/444749879",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#issuecomment-444749879",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/14837",
    "id": 444749879,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NDc0OTg3OQ==",
    "user": {
      "login": "JeremyRubin",
      "id": 886523,
      "node_id": "MDQ6VXNlcjg4NjUyMw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/886523?u=8cdd8653982252593843d7369ecfebe432b89768&v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/JeremyRubin",
      "html_url": "https://github.com/JeremyRubin",
      "followers_url": "https://api.github.com/users/JeremyRubin/followers",
      "following_url": "https://api.github.com/users/JeremyRubin/following{/other_user}",
      "gists_url": "https://api.github.com/users/JeremyRubin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/JeremyRubin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/JeremyRubin/subscriptions",
      "organizations_url": "https://api.github.com/users/JeremyRubin/orgs",
      "repos_url": "https://api.github.com/users/JeremyRubin/repos",
      "events_url": "https://api.github.com/users/JeremyRubin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/JeremyRubin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-06T05:07:18Z",
    "updated_at": "2018-12-06T05:07:18Z",
    "author_association": "CONTRIBUTOR",
    "body": "@sdaftuar Thanks for the review and feedback.\r\n\r\n1. Understood. It's often times hard to tell the borderline between small-steps that are easy to reason about and sweeping changes which change lots of code. I tend to err on the side of small steps with easy to reason about changes because when things are larger I perceive there's more of a rejection for review simply because of large amount of changes required, even if it is decomposed into small steps. I also tend to prefer to do small steps so as not to invest to much effort on an approach that will not be acceptable early on.\r\n1. I can clarify the types of changes I'm excited about that this opens up the door to in a bit. I do have drafts of them, but I'm still thinking about how to best structure them to make the project benefit maximally. I'm happy to give you a preview.\r\n1. The differences between this approach and a simpler version (I also have an implementation of it which checks both duplicate inputs and longchain order) is somewhat substantial. But perhaps that difference would be less clear once the broader architecture changes are done -- happy to explore this as well. Also the simpler approaches mentioned in the other iteration do not have the same property that this one does (longchain checking) and cannot be augmented easily to support it (it becomes a separate check).\r\n1. This sounds like a good conversation. I have some opinions on this, but am not strongly attached. I don't have a horse in the race on weather they are contextual or non contextual checks -- either is somewhat fine to me, but I do feel strongly that duplicate input checks are not a per-transaction check (they are block wide). I also _believe_ from a performance perspective, they are best performed in ConnectBlock after the first Control.add and before Control.wait. From a code fragility perspective, I would prefer this check to happen before the UTXO database or caching hierarchy is written to *at all*. These two goals are slightly at odds, but there might be a way to make them work nicely together.\r\n1. I do believe this code is actually *much simpler* than the current state of affairs. Currently, where are duplicate inputs checked?  They are checked in two places -- per txn in check block, and then across transactions but not within transactions in ConnectBlock. That's what lead to the CVE. Changing the code to only perform the check in once place explicitly is dramatically simpler.  Reasoning about this is simpler. Now, the hashtable implementation, I agree, is more complicated, which is why I wrote a detailed comment. If performance is sacrificable a bit here as it's no longer in the hot path at all, I would prefer the slightly less performant version as it doesn't need as much convincing for the reader. When working on the broader change which can follow this PR, I will base it on that simpler version.\r\n1. I've always heard the project was scratch your own itch ;) \r\n\r\n\r\n\r\n\r\n@gmaxwell, will let you know when I have something ready. I do think that the belt-and-suspendering the check holds merit; I will include the simplest version possible in that version, to the extent it isn't worse than master.\r\n\r\nDo you have a falsifiable framework for testing this sort of change? I'd like to produce a testable change where I can demonstrate a change in an environment that you're happy with. Would it be -reindex-chainstate with assumevalid set to one month prior? Is there something simpler that would work and be convincing & permit more rapid iteration?",
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/444749879/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/445544371",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#issuecomment-445544371",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/14837",
    "id": 445544371,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NTU0NDM3MQ==",
    "user": {
      "login": "gmaxwell",
      "id": 858454,
      "node_id": "MDQ6VXNlcjg1ODQ1NA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/858454?u=63e5c438c242094837a9deeda775d77988b508bf&v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gmaxwell",
      "html_url": "https://github.com/gmaxwell",
      "followers_url": "https://api.github.com/users/gmaxwell/followers",
      "following_url": "https://api.github.com/users/gmaxwell/following{/other_user}",
      "gists_url": "https://api.github.com/users/gmaxwell/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gmaxwell/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gmaxwell/subscriptions",
      "organizations_url": "https://api.github.com/users/gmaxwell/orgs",
      "repos_url": "https://api.github.com/users/gmaxwell/repos",
      "events_url": "https://api.github.com/users/gmaxwell/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gmaxwell/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-09T14:55:20Z",
    "updated_at": "2018-12-09T14:55:20Z",
    "author_association": "CONTRIBUTOR",
    "body": "A reindex (-chainstate is fine) would be the standard benchmark, you could set assumevalid to whatever you think will highlight the improvement the most-- both extremes of AV setting fairly characterize different but important aspects of sync performance (the performance on older vs more recent history).  Similarly, default dbcache or maximized dbcache are both defensible benchmarking configurations (the performance on standard vs high performance hosts). ",
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/445544371/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/481711492",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#issuecomment-481711492",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/14837",
    "id": 481711492,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ4MTcxMTQ5Mg==",
    "user": {
      "login": "DrahtBot",
      "id": 39886733,
      "node_id": "MDQ6VXNlcjM5ODg2NzMz",
      "avatar_url": "https://avatars.githubusercontent.com/u/39886733?u=3c1e73d828cf5a5850dfc25c8397c1cf751db5ac&v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/DrahtBot",
      "html_url": "https://github.com/DrahtBot",
      "followers_url": "https://api.github.com/users/DrahtBot/followers",
      "following_url": "https://api.github.com/users/DrahtBot/following{/other_user}",
      "gists_url": "https://api.github.com/users/DrahtBot/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/DrahtBot/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/DrahtBot/subscriptions",
      "organizations_url": "https://api.github.com/users/DrahtBot/orgs",
      "repos_url": "https://api.github.com/users/DrahtBot/repos",
      "events_url": "https://api.github.com/users/DrahtBot/events{/privacy}",
      "received_events_url": "https://api.github.com/users/DrahtBot/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-04-10T14:21:20Z",
    "updated_at": "2019-04-10T14:21:20Z",
    "author_association": "CONTRIBUTOR",
    "body": "<!--cf906140f33d8803c4a75a2196329ecb-->Needs rebase",
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/481711492/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/484965751",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#issuecomment-484965751",
    "issue_url": "https://api.github.com/repos/bitcoin/bitcoin/issues/14837",
    "id": 484965751,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ4NDk2NTc1MQ==",
    "user": {
      "login": "MarcoFalke",
      "id": 6399679,
      "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6399679?u=0691974eedcc2ab5366cc1080fb1c030e87244c2&v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/MarcoFalke",
      "html_url": "https://github.com/MarcoFalke",
      "followers_url": "https://api.github.com/users/MarcoFalke/followers",
      "following_url": "https://api.github.com/users/MarcoFalke/following{/other_user}",
      "gists_url": "https://api.github.com/users/MarcoFalke/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/MarcoFalke/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
      "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
      "repos_url": "https://api.github.com/users/MarcoFalke/repos",
      "events_url": "https://api.github.com/users/MarcoFalke/events{/privacy}",
      "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-04-19T17:33:11Z",
    "updated_at": "2019-04-19T17:33:11Z",
    "author_association": "MEMBER",
    "body": "There hasn't been much activity lately and the patch still needs rebase, so I am closing this for now. Please let me know when you want to continue working on this, so the pull request can be re-opened.",
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/issues/comments/484965751/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237787620",
    "pull_request_review_id": 180171703,
    "id": 237787620,
    "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNzc4NzYyMA==",
    "diff_hunk": "@@ -3075,6 +3075,232 @@ static bool CheckBlockHeader(const CBlockHeader& block, CValidationState& state,\n     return true;\n }\n \n+/* CheckInputInvariants checks for three criticial invariants for the inputs in a block:\n+ * 1) No Duplicate Inputs\n+ * 2) Only one Coinbase (implied by 1)\n+ * 3) No Null Inputs other than coinbase (implied by 1 and 5)\n+ * 4) All long-chains are in order\n+ *\n+ * It does not check\n+ * 5) First txn is coinbase\n+ */\n+static bool CheckInputInvariants(const CBlock& block, CValidationState& state)\n+{\n+    /* This duplication checking algorithm uses a probabilistic filter to check\n+     * for collisions efficiently.  This is faster than the naive construction,\n+     * using a set, which requires more allocation and comparisons of uint256s.\n+     *\n+     * First we create a bitset table with 1<<21 elements. This is around 300\n+     * KB, so we construct it on the heap. We also create 8 pseudo-random\n+     * functions based on PCG. Each PCG function considers looks at 64 bits of\n+     * the prevout's hash, and the increment is xor'd with the index. Although\n+     * each hash is not dependent on the entire hash, a single 64-bit collision\n+     * would be expected with 4-billion UTXOS, and even then that would not\n+     * trigger a collision in this algorithm directly as there are 3 other\n+     * 64-bit hashes to collide.\n+     *\n+     *\n+     * Then, we iterate through the inputs one by one in order, hashing them using\n+     * our PCG hash functions.\n+     *\n+     * We then check if all 8 hashes are set in the table yet. If they are, we\n+     * do a linear scan through the inputs to see if it was a true collision,\n+     * and reject the txn.\n+     *\n+     * Otherwise, we set the 8 bits corresponding to the hashes and continue.\n+     *\n+     * ------------------------------------------------------------------------\n+     * Analysis\n+     * ------------------------------------------------------------------------\n+     * From the perspective of the N+1st prevout, assuming the transaction does\n+     * not double spend:\n+     *\n+     * Up to N*8 hashes have been set in the table already (potentially fewer if\n+     * collisions)\n+     *\n+     * For each of the 8 hashes h_1...h_8, P(bit set in table for h_i) =\n+     * (N*8)/1<<21\n+     *\n+     * Each of these probabilities is independent\n+     *\n+     * Therefore the total probability of a false collision on all bits is:\n+     * ((N*8)/2**21)**8\n+     *\n+     * The cost of a false collision is to do N comparisons.\n+     *\n+     * Therefore, the expression for the expected number of comparisons is:\n+     *\n+     * Sum[i*( i*8 / 2**21)**8, {i, 0, M}]\n+     *\n+     * Based on an input being at least 41 bytes, and a block being 1M bytes\n+     * max, there are a maximum of 24390 inputs, so M = 24390\n+     *\n+     * The total expected number of direct comparisons for M=24930 is therefore\n+     * 0.33 with this algorithm.\n+     *\n+     * The worst case for this algorithm from a denial of service perspective\n+     * with an invalid block would be to do a transaction where the last two\n+     * elements are a collision. In this case, the scan would require to scan all\n+     * N elements to find the conflict.\n+     *\n+     * ------------------------------------------------------------------------\n+     *  Extensions\n+     * ------------------------------------------------------------------------\n+     *\n+     * - Single Coinbase / Null Input Check\n+     *     Note that the first element checked is the coinbase transaction,\n+     *     whose input is null. Therefore, any subsequent null input would be a\n+     *     collision with that null, enabling us to not null check every\n+     *     subsequent entry. This has 0 overhead.\n+     * - Long Chain Check\n+     *     We also scan for the presence of the outputs of a transaction in the\n+     *     table as we go (without insertion), which detects an out-of-order\n+     *     spend in a long-chain within a block.\n+     *\n+     *     The worst case behavior for a block under this additional scan is for\n+     *     all inputs to be spent and then all outputs to be created. Any other\n+     *     pattern of inputs and outputs would be strictly less work. A minimal\n+     *     output is 9 bytes -- there are at most 1e6/9 outputs. Thus, we can\n+     *     model it as:\n+     *\n+     *     Max[((1-x)*1e6/9)(x*1e6/41)*(8*x*(1e6/41) / 2**21)**8 +\n+     *         Sum[ i*( i*8 / 2**21)**8, {i, 0, x*1e6/41}], {x, 0, 1}]\n+     *\n+     *     That is:\n+     *       The most amount of work for a given fraction x of block space devoted to\n+     *       inputs, which is the expected amount of work for checking a table with\n+     *       x*1e6/41 entries (1-x)*1e6/9 additional times plus the expected  work\n+     *       for deduplicating just the inputs.\n+     *\n+     *     This expression is at most ~0.7 expected comparisons worst case, which is\n+     *     still perfectly acceptable.\n+     */\n+\n+\n+    const auto pcg = [](uint64_t start, uint64_t inc) {\n+        uint64_t nxt = (inc | 1) + (start * 6364136223846793005ULL);\n+        uint32_t x = (nxt ^ (nxt >> 18)) >> 27;\n+        uint32_t r = nxt >> 59;\n+        return (x >> r) | (x << (31 & (-r)));\n+\n+    };\n+    const uint64_t k1 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k2 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k3 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k4 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k5 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k6 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k7 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k8 = GetRand(std::numeric_limits<uint64_t>::max());\n+    struct pos {\n+        uint32_t a : 21;\n+        uint32_t b : 21;\n+        uint32_t c : 21;\n+        bool empty_1 : 1;\n+        uint32_t d : 21;\n+        uint32_t e : 21;\n+        uint32_t f : 21;\n+        bool empty_2 : 1;\n+        uint32_t g : 21;\n+        uint32_t h : 21;\n+        uint32_t unused : 22;\n+    };\n+    auto hasher = [k1, k2, k3, k4, k5, k6, k7, k8, pcg](const COutPoint& out) {\n+        return pos{\n+            pcg(out.hash.GetUint64(0) ^ k1, 1 | ((((uint64_t)out.n) << 1) ^ k1)),\n+            pcg(out.hash.GetUint64(0) ^ k2, 1 | ((((uint64_t)out.n) << 1) ^ k2)),\n+            pcg(out.hash.GetUint64(1) ^ k3, 1 | ((((uint64_t)out.n) << 1) ^ k3)),\n+            false,\n+            pcg(out.hash.GetUint64(1) ^ k4, 1 | ((((uint64_t)out.n) << 1) ^ k4)),\n+            pcg(out.hash.GetUint64(2) ^ k5, 1 | ((((uint64_t)out.n) << 1) ^ k5)),\n+            pcg(out.hash.GetUint64(2) ^ k6, 1 | ((((uint64_t)out.n) << 1) ^ k6)),\n+            false,\n+            pcg(out.hash.GetUint64(3) ^ k7, 1 | ((((uint64_t)out.n) << 1) ^ k7)),\n+            pcg(out.hash.GetUint64(3) ^ k8, 1 | ((((uint64_t)out.n) << 1) ^ k8)),\n+            0,\n+        };\n+    };\n+\n+    std::unique_ptr<std::bitset<1 << 21>> pTable = MakeUnique<std::bitset<1 << 21>>();\n+    auto& table = *pTable.get();",
    "path": "src/validation.cpp",
    "position": 151,
    "original_position": 151,
    "commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "original_commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "user": {
      "login": "practicalswift",
      "id": 7826565,
      "node_id": "MDQ6VXNlcjc4MjY1NjU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/practicalswift",
      "html_url": "https://github.com/practicalswift",
      "followers_url": "https://api.github.com/users/practicalswift/followers",
      "following_url": "https://api.github.com/users/practicalswift/following{/other_user}",
      "gists_url": "https://api.github.com/users/practicalswift/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/practicalswift/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
      "organizations_url": "https://api.github.com/users/practicalswift/orgs",
      "repos_url": "https://api.github.com/users/practicalswift/repos",
      "events_url": "https://api.github.com/users/practicalswift/events{/privacy}",
      "received_events_url": "https://api.github.com/users/practicalswift/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "This `.get()` is redundant, right?",
    "created_at": "2018-11-30T09:05:14Z",
    "updated_at": "2018-11-30T09:05:14Z",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r237787620",
    "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237787620"
      },
      "html": {
        "href": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r237787620"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837"
      }
    },
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237787620/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "start_line": null,
    "original_start_line": null,
    "start_side": null,
    "line": 3225,
    "original_line": 3225,
    "side": "RIGHT"
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237788322",
    "pull_request_review_id": 180172622,
    "id": 237788322,
    "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNzc4ODMyMg==",
    "diff_hunk": "@@ -3075,6 +3075,232 @@ static bool CheckBlockHeader(const CBlockHeader& block, CValidationState& state,\n     return true;\n }\n \n+/* CheckInputInvariants checks for three criticial invariants for the inputs in a block:\n+ * 1) No Duplicate Inputs\n+ * 2) Only one Coinbase (implied by 1)\n+ * 3) No Null Inputs other than coinbase (implied by 1 and 5)\n+ * 4) All long-chains are in order\n+ *\n+ * It does not check\n+ * 5) First txn is coinbase\n+ */\n+static bool CheckInputInvariants(const CBlock& block, CValidationState& state)\n+{\n+    /* This duplication checking algorithm uses a probabilistic filter to check\n+     * for collisions efficiently.  This is faster than the naive construction,\n+     * using a set, which requires more allocation and comparisons of uint256s.\n+     *\n+     * First we create a bitset table with 1<<21 elements. This is around 300\n+     * KB, so we construct it on the heap. We also create 8 pseudo-random\n+     * functions based on PCG. Each PCG function considers looks at 64 bits of\n+     * the prevout's hash, and the increment is xor'd with the index. Although\n+     * each hash is not dependent on the entire hash, a single 64-bit collision\n+     * would be expected with 4-billion UTXOS, and even then that would not\n+     * trigger a collision in this algorithm directly as there are 3 other\n+     * 64-bit hashes to collide.\n+     *\n+     *\n+     * Then, we iterate through the inputs one by one in order, hashing them using\n+     * our PCG hash functions.\n+     *\n+     * We then check if all 8 hashes are set in the table yet. If they are, we\n+     * do a linear scan through the inputs to see if it was a true collision,\n+     * and reject the txn.\n+     *\n+     * Otherwise, we set the 8 bits corresponding to the hashes and continue.\n+     *\n+     * ------------------------------------------------------------------------\n+     * Analysis\n+     * ------------------------------------------------------------------------\n+     * From the perspective of the N+1st prevout, assuming the transaction does\n+     * not double spend:\n+     *\n+     * Up to N*8 hashes have been set in the table already (potentially fewer if\n+     * collisions)\n+     *\n+     * For each of the 8 hashes h_1...h_8, P(bit set in table for h_i) =\n+     * (N*8)/1<<21\n+     *\n+     * Each of these probabilities is independent\n+     *\n+     * Therefore the total probability of a false collision on all bits is:\n+     * ((N*8)/2**21)**8\n+     *\n+     * The cost of a false collision is to do N comparisons.\n+     *\n+     * Therefore, the expression for the expected number of comparisons is:\n+     *\n+     * Sum[i*( i*8 / 2**21)**8, {i, 0, M}]\n+     *\n+     * Based on an input being at least 41 bytes, and a block being 1M bytes\n+     * max, there are a maximum of 24390 inputs, so M = 24390\n+     *\n+     * The total expected number of direct comparisons for M=24930 is therefore\n+     * 0.33 with this algorithm.\n+     *\n+     * The worst case for this algorithm from a denial of service perspective\n+     * with an invalid block would be to do a transaction where the last two\n+     * elements are a collision. In this case, the scan would require to scan all\n+     * N elements to find the conflict.\n+     *\n+     * ------------------------------------------------------------------------\n+     *  Extensions\n+     * ------------------------------------------------------------------------\n+     *\n+     * - Single Coinbase / Null Input Check\n+     *     Note that the first element checked is the coinbase transaction,\n+     *     whose input is null. Therefore, any subsequent null input would be a\n+     *     collision with that null, enabling us to not null check every\n+     *     subsequent entry. This has 0 overhead.\n+     * - Long Chain Check\n+     *     We also scan for the presence of the outputs of a transaction in the\n+     *     table as we go (without insertion), which detects an out-of-order\n+     *     spend in a long-chain within a block.\n+     *\n+     *     The worst case behavior for a block under this additional scan is for\n+     *     all inputs to be spent and then all outputs to be created. Any other\n+     *     pattern of inputs and outputs would be strictly less work. A minimal\n+     *     output is 9 bytes -- there are at most 1e6/9 outputs. Thus, we can\n+     *     model it as:\n+     *\n+     *     Max[((1-x)*1e6/9)(x*1e6/41)*(8*x*(1e6/41) / 2**21)**8 +\n+     *         Sum[ i*( i*8 / 2**21)**8, {i, 0, x*1e6/41}], {x, 0, 1}]\n+     *\n+     *     That is:\n+     *       The most amount of work for a given fraction x of block space devoted to\n+     *       inputs, which is the expected amount of work for checking a table with\n+     *       x*1e6/41 entries (1-x)*1e6/9 additional times plus the expected  work\n+     *       for deduplicating just the inputs.\n+     *\n+     *     This expression is at most ~0.7 expected comparisons worst case, which is\n+     *     still perfectly acceptable.\n+     */\n+\n+\n+    const auto pcg = [](uint64_t start, uint64_t inc) {\n+        uint64_t nxt = (inc | 1) + (start * 6364136223846793005ULL);",
    "path": "src/validation.cpp",
    "position": 107,
    "original_position": 107,
    "commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "original_commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "user": {
      "login": "practicalswift",
      "id": 7826565,
      "node_id": "MDQ6VXNlcjc4MjY1NjU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/practicalswift",
      "html_url": "https://github.com/practicalswift",
      "followers_url": "https://api.github.com/users/practicalswift/followers",
      "following_url": "https://api.github.com/users/practicalswift/following{/other_user}",
      "gists_url": "https://api.github.com/users/practicalswift/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/practicalswift/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
      "organizations_url": "https://api.github.com/users/practicalswift/orgs",
      "repos_url": "https://api.github.com/users/practicalswift/repos",
      "events_url": "https://api.github.com/users/practicalswift/events{/privacy}",
      "received_events_url": "https://api.github.com/users/practicalswift/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "Make it explicit that the unsigned integer wraparound that will take place here at run-time is intentional? Or alternatively rewrite so that no integer wraparound takes place at run-time? Verify with `-fsanitize=integer`.",
    "created_at": "2018-11-30T09:07:20Z",
    "updated_at": "2018-11-30T09:10:03Z",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r237788322",
    "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237788322"
      },
      "html": {
        "href": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r237788322"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837"
      }
    },
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237788322/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "start_line": null,
    "original_start_line": null,
    "start_side": null,
    "line": 3181,
    "original_line": 3181,
    "side": "RIGHT"
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237789039",
    "pull_request_review_id": 180173483,
    "id": 237789039,
    "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNzc4OTAzOQ==",
    "diff_hunk": "@@ -3075,6 +3075,232 @@ static bool CheckBlockHeader(const CBlockHeader& block, CValidationState& state,\n     return true;\n }\n \n+/* CheckInputInvariants checks for three criticial invariants for the inputs in a block:\n+ * 1) No Duplicate Inputs\n+ * 2) Only one Coinbase (implied by 1)\n+ * 3) No Null Inputs other than coinbase (implied by 1 and 5)\n+ * 4) All long-chains are in order\n+ *\n+ * It does not check\n+ * 5) First txn is coinbase\n+ */\n+static bool CheckInputInvariants(const CBlock& block, CValidationState& state)\n+{\n+    /* This duplication checking algorithm uses a probabilistic filter to check\n+     * for collisions efficiently.  This is faster than the naive construction,\n+     * using a set, which requires more allocation and comparisons of uint256s.\n+     *\n+     * First we create a bitset table with 1<<21 elements. This is around 300\n+     * KB, so we construct it on the heap. We also create 8 pseudo-random\n+     * functions based on PCG. Each PCG function considers looks at 64 bits of\n+     * the prevout's hash, and the increment is xor'd with the index. Although\n+     * each hash is not dependent on the entire hash, a single 64-bit collision\n+     * would be expected with 4-billion UTXOS, and even then that would not\n+     * trigger a collision in this algorithm directly as there are 3 other\n+     * 64-bit hashes to collide.\n+     *\n+     *\n+     * Then, we iterate through the inputs one by one in order, hashing them using\n+     * our PCG hash functions.\n+     *\n+     * We then check if all 8 hashes are set in the table yet. If they are, we\n+     * do a linear scan through the inputs to see if it was a true collision,\n+     * and reject the txn.\n+     *\n+     * Otherwise, we set the 8 bits corresponding to the hashes and continue.\n+     *\n+     * ------------------------------------------------------------------------\n+     * Analysis\n+     * ------------------------------------------------------------------------\n+     * From the perspective of the N+1st prevout, assuming the transaction does\n+     * not double spend:\n+     *\n+     * Up to N*8 hashes have been set in the table already (potentially fewer if\n+     * collisions)\n+     *\n+     * For each of the 8 hashes h_1...h_8, P(bit set in table for h_i) =\n+     * (N*8)/1<<21\n+     *\n+     * Each of these probabilities is independent\n+     *\n+     * Therefore the total probability of a false collision on all bits is:\n+     * ((N*8)/2**21)**8\n+     *\n+     * The cost of a false collision is to do N comparisons.\n+     *\n+     * Therefore, the expression for the expected number of comparisons is:\n+     *\n+     * Sum[i*( i*8 / 2**21)**8, {i, 0, M}]\n+     *\n+     * Based on an input being at least 41 bytes, and a block being 1M bytes\n+     * max, there are a maximum of 24390 inputs, so M = 24390\n+     *\n+     * The total expected number of direct comparisons for M=24930 is therefore\n+     * 0.33 with this algorithm.\n+     *\n+     * The worst case for this algorithm from a denial of service perspective\n+     * with an invalid block would be to do a transaction where the last two\n+     * elements are a collision. In this case, the scan would require to scan all\n+     * N elements to find the conflict.\n+     *\n+     * ------------------------------------------------------------------------\n+     *  Extensions\n+     * ------------------------------------------------------------------------\n+     *\n+     * - Single Coinbase / Null Input Check\n+     *     Note that the first element checked is the coinbase transaction,\n+     *     whose input is null. Therefore, any subsequent null input would be a\n+     *     collision with that null, enabling us to not null check every\n+     *     subsequent entry. This has 0 overhead.\n+     * - Long Chain Check\n+     *     We also scan for the presence of the outputs of a transaction in the\n+     *     table as we go (without insertion), which detects an out-of-order\n+     *     spend in a long-chain within a block.\n+     *\n+     *     The worst case behavior for a block under this additional scan is for\n+     *     all inputs to be spent and then all outputs to be created. Any other\n+     *     pattern of inputs and outputs would be strictly less work. A minimal\n+     *     output is 9 bytes -- there are at most 1e6/9 outputs. Thus, we can\n+     *     model it as:\n+     *\n+     *     Max[((1-x)*1e6/9)(x*1e6/41)*(8*x*(1e6/41) / 2**21)**8 +\n+     *         Sum[ i*( i*8 / 2**21)**8, {i, 0, x*1e6/41}], {x, 0, 1}]\n+     *\n+     *     That is:\n+     *       The most amount of work for a given fraction x of block space devoted to\n+     *       inputs, which is the expected amount of work for checking a table with\n+     *       x*1e6/41 entries (1-x)*1e6/9 additional times plus the expected  work\n+     *       for deduplicating just the inputs.\n+     *\n+     *     This expression is at most ~0.7 expected comparisons worst case, which is\n+     *     still perfectly acceptable.\n+     */\n+\n+\n+    const auto pcg = [](uint64_t start, uint64_t inc) {\n+        uint64_t nxt = (inc | 1) + (start * 6364136223846793005ULL);\n+        uint32_t x = (nxt ^ (nxt >> 18)) >> 27;\n+        uint32_t r = nxt >> 59;\n+        return (x >> r) | (x << (31 & (-r)));",
    "path": "src/validation.cpp",
    "position": 110,
    "original_position": 110,
    "commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "original_commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "user": {
      "login": "practicalswift",
      "id": 7826565,
      "node_id": "MDQ6VXNlcjc4MjY1NjU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/practicalswift",
      "html_url": "https://github.com/practicalswift",
      "followers_url": "https://api.github.com/users/practicalswift/followers",
      "following_url": "https://api.github.com/users/practicalswift/following{/other_user}",
      "gists_url": "https://api.github.com/users/practicalswift/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/practicalswift/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
      "organizations_url": "https://api.github.com/users/practicalswift/orgs",
      "repos_url": "https://api.github.com/users/practicalswift/repos",
      "events_url": "https://api.github.com/users/practicalswift/events{/privacy}",
      "received_events_url": "https://api.github.com/users/practicalswift/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "Make it explicit that the unsigned integer wraparound that will take place here at run-time is intentional? Or alternatively rewrite so that no integer wraparound takes place at run-time? Verify with `-fsanitize=integer`.",
    "created_at": "2018-11-30T09:09:22Z",
    "updated_at": "2018-11-30T09:10:08Z",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r237789039",
    "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237789039"
      },
      "html": {
        "href": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r237789039"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837"
      }
    },
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237789039/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "start_line": null,
    "original_start_line": null,
    "start_side": null,
    "line": 3184,
    "original_line": 3184,
    "side": "RIGHT"
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237789510",
    "pull_request_review_id": 180174058,
    "id": 237789510,
    "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNzc4OTUxMA==",
    "diff_hunk": "@@ -3075,6 +3075,232 @@ static bool CheckBlockHeader(const CBlockHeader& block, CValidationState& state,\n     return true;\n }\n \n+/* CheckInputInvariants checks for three criticial invariants for the inputs in a block:",
    "path": "src/validation.cpp",
    "position": 4,
    "original_position": 4,
    "commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "original_commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "user": {
      "login": "practicalswift",
      "id": 7826565,
      "node_id": "MDQ6VXNlcjc4MjY1NjU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/practicalswift",
      "html_url": "https://github.com/practicalswift",
      "followers_url": "https://api.github.com/users/practicalswift/followers",
      "following_url": "https://api.github.com/users/practicalswift/following{/other_user}",
      "gists_url": "https://api.github.com/users/practicalswift/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/practicalswift/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
      "organizations_url": "https://api.github.com/users/practicalswift/orgs",
      "repos_url": "https://api.github.com/users/practicalswift/repos",
      "events_url": "https://api.github.com/users/practicalswift/events{/privacy}",
      "received_events_url": "https://api.github.com/users/practicalswift/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "Critical :-)",
    "created_at": "2018-11-30T09:10:33Z",
    "updated_at": "2018-11-30T09:10:33Z",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r237789510",
    "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237789510"
      },
      "html": {
        "href": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r237789510"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837"
      }
    },
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237789510/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "start_line": null,
    "original_start_line": null,
    "start_side": null,
    "line": 3078,
    "original_line": 3078,
    "side": "RIGHT"
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237850750",
    "pull_request_review_id": 180252878,
    "id": 237850750,
    "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzNzg1MDc1MA==",
    "diff_hunk": "@@ -3075,6 +3075,232 @@ static bool CheckBlockHeader(const CBlockHeader& block, CValidationState& state,\n     return true;\n }\n \n+/* CheckInputInvariants checks for three criticial invariants for the inputs in a block:\n+ * 1) No Duplicate Inputs\n+ * 2) Only one Coinbase (implied by 1)\n+ * 3) No Null Inputs other than coinbase (implied by 1 and 5)\n+ * 4) All long-chains are in order\n+ *\n+ * It does not check\n+ * 5) First txn is coinbase\n+ */\n+static bool CheckInputInvariants(const CBlock& block, CValidationState& state)\n+{\n+    /* This duplication checking algorithm uses a probabilistic filter to check\n+     * for collisions efficiently.  This is faster than the naive construction,\n+     * using a set, which requires more allocation and comparisons of uint256s.\n+     *\n+     * First we create a bitset table with 1<<21 elements. This is around 300\n+     * KB, so we construct it on the heap. We also create 8 pseudo-random\n+     * functions based on PCG. Each PCG function considers looks at 64 bits of\n+     * the prevout's hash, and the increment is xor'd with the index. Although\n+     * each hash is not dependent on the entire hash, a single 64-bit collision\n+     * would be expected with 4-billion UTXOS, and even then that would not\n+     * trigger a collision in this algorithm directly as there are 3 other\n+     * 64-bit hashes to collide.\n+     *\n+     *\n+     * Then, we iterate through the inputs one by one in order, hashing them using\n+     * our PCG hash functions.\n+     *\n+     * We then check if all 8 hashes are set in the table yet. If they are, we\n+     * do a linear scan through the inputs to see if it was a true collision,\n+     * and reject the txn.\n+     *\n+     * Otherwise, we set the 8 bits corresponding to the hashes and continue.\n+     *\n+     * ------------------------------------------------------------------------\n+     * Analysis\n+     * ------------------------------------------------------------------------\n+     * From the perspective of the N+1st prevout, assuming the transaction does\n+     * not double spend:\n+     *\n+     * Up to N*8 hashes have been set in the table already (potentially fewer if\n+     * collisions)\n+     *\n+     * For each of the 8 hashes h_1...h_8, P(bit set in table for h_i) =\n+     * (N*8)/1<<21\n+     *\n+     * Each of these probabilities is independent\n+     *\n+     * Therefore the total probability of a false collision on all bits is:\n+     * ((N*8)/2**21)**8\n+     *\n+     * The cost of a false collision is to do N comparisons.\n+     *\n+     * Therefore, the expression for the expected number of comparisons is:\n+     *\n+     * Sum[i*( i*8 / 2**21)**8, {i, 0, M}]\n+     *\n+     * Based on an input being at least 41 bytes, and a block being 1M bytes\n+     * max, there are a maximum of 24390 inputs, so M = 24390\n+     *\n+     * The total expected number of direct comparisons for M=24930 is therefore\n+     * 0.33 with this algorithm.\n+     *\n+     * The worst case for this algorithm from a denial of service perspective\n+     * with an invalid block would be to do a transaction where the last two\n+     * elements are a collision. In this case, the scan would require to scan all\n+     * N elements to find the conflict.\n+     *\n+     * ------------------------------------------------------------------------\n+     *  Extensions\n+     * ------------------------------------------------------------------------\n+     *\n+     * - Single Coinbase / Null Input Check\n+     *     Note that the first element checked is the coinbase transaction,\n+     *     whose input is null. Therefore, any subsequent null input would be a\n+     *     collision with that null, enabling us to not null check every\n+     *     subsequent entry. This has 0 overhead.\n+     * - Long Chain Check\n+     *     We also scan for the presence of the outputs of a transaction in the\n+     *     table as we go (without insertion), which detects an out-of-order\n+     *     spend in a long-chain within a block.\n+     *\n+     *     The worst case behavior for a block under this additional scan is for\n+     *     all inputs to be spent and then all outputs to be created. Any other\n+     *     pattern of inputs and outputs would be strictly less work. A minimal\n+     *     output is 9 bytes -- there are at most 1e6/9 outputs. Thus, we can\n+     *     model it as:\n+     *\n+     *     Max[((1-x)*1e6/9)(x*1e6/41)*(8*x*(1e6/41) / 2**21)**8 +\n+     *         Sum[ i*( i*8 / 2**21)**8, {i, 0, x*1e6/41}], {x, 0, 1}]\n+     *\n+     *     That is:\n+     *       The most amount of work for a given fraction x of block space devoted to\n+     *       inputs, which is the expected amount of work for checking a table with\n+     *       x*1e6/41 entries (1-x)*1e6/9 additional times plus the expected  work\n+     *       for deduplicating just the inputs.\n+     *\n+     *     This expression is at most ~0.7 expected comparisons worst case, which is\n+     *     still perfectly acceptable.\n+     */\n+\n+\n+    const auto pcg = [](uint64_t start, uint64_t inc) {\n+        uint64_t nxt = (inc | 1) + (start * 6364136223846793005ULL);\n+        uint32_t x = (nxt ^ (nxt >> 18)) >> 27;\n+        uint32_t r = nxt >> 59;\n+        return (x >> r) | (x << (31 & (-r)));\n+\n+    };\n+    const uint64_t k1 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k2 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k3 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k4 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k5 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k6 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k7 = GetRand(std::numeric_limits<uint64_t>::max());\n+    const uint64_t k8 = GetRand(std::numeric_limits<uint64_t>::max());\n+    struct pos {\n+        uint32_t a : 21;\n+        uint32_t b : 21;\n+        uint32_t c : 21;\n+        bool empty_1 : 1;\n+        uint32_t d : 21;\n+        uint32_t e : 21;\n+        uint32_t f : 21;\n+        bool empty_2 : 1;\n+        uint32_t g : 21;\n+        uint32_t h : 21;\n+        uint32_t unused : 22;\n+    };\n+    auto hasher = [k1, k2, k3, k4, k5, k6, k7, k8, pcg](const COutPoint& out) {\n+        return pos{\n+            pcg(out.hash.GetUint64(0) ^ k1, 1 | ((((uint64_t)out.n) << 1) ^ k1)),\n+            pcg(out.hash.GetUint64(0) ^ k2, 1 | ((((uint64_t)out.n) << 1) ^ k2)),\n+            pcg(out.hash.GetUint64(1) ^ k3, 1 | ((((uint64_t)out.n) << 1) ^ k3)),\n+            false,\n+            pcg(out.hash.GetUint64(1) ^ k4, 1 | ((((uint64_t)out.n) << 1) ^ k4)),\n+            pcg(out.hash.GetUint64(2) ^ k5, 1 | ((((uint64_t)out.n) << 1) ^ k5)),\n+            pcg(out.hash.GetUint64(2) ^ k6, 1 | ((((uint64_t)out.n) << 1) ^ k6)),\n+            false,\n+            pcg(out.hash.GetUint64(3) ^ k7, 1 | ((((uint64_t)out.n) << 1) ^ k7)),\n+            pcg(out.hash.GetUint64(3) ^ k8, 1 | ((((uint64_t)out.n) << 1) ^ k8)),\n+            0,\n+        };\n+    };\n+\n+    std::unique_ptr<std::bitset<1 << 21>> pTable = MakeUnique<std::bitset<1 << 21>>();",
    "path": "src/validation.cpp",
    "position": 150,
    "original_position": 150,
    "commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "original_commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "user": {
      "login": "ken2812221",
      "id": 11154118,
      "node_id": "MDQ6VXNlcjExMTU0MTE4",
      "avatar_url": "https://avatars.githubusercontent.com/u/11154118?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ken2812221",
      "html_url": "https://github.com/ken2812221",
      "followers_url": "https://api.github.com/users/ken2812221/followers",
      "following_url": "https://api.github.com/users/ken2812221/following{/other_user}",
      "gists_url": "https://api.github.com/users/ken2812221/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ken2812221/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ken2812221/subscriptions",
      "organizations_url": "https://api.github.com/users/ken2812221/orgs",
      "repos_url": "https://api.github.com/users/ken2812221/repos",
      "events_url": "https://api.github.com/users/ken2812221/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ken2812221/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "`#include <bitset>` to make appveyor happy.",
    "created_at": "2018-11-30T12:55:11Z",
    "updated_at": "2018-11-30T12:55:11Z",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r237850750",
    "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237850750"
      },
      "html": {
        "href": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r237850750"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837"
      }
    },
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/237850750/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "start_line": null,
    "original_start_line": null,
    "start_side": null,
    "line": 3224,
    "original_line": 3224,
    "side": "RIGHT"
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/238024768",
    "pull_request_review_id": 180478180,
    "id": 238024768,
    "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzODAyNDc2OA==",
    "diff_hunk": "@@ -3075,6 +3075,232 @@ static bool CheckBlockHeader(const CBlockHeader& block, CValidationState& state,\n     return true;\n }\n \n+/* CheckInputInvariants checks for three criticial invariants for the inputs in a block:\n+ * 1) No Duplicate Inputs\n+ * 2) Only one Coinbase (implied by 1)\n+ * 3) No Null Inputs other than coinbase (implied by 1 and 5)\n+ * 4) All long-chains are in order\n+ *\n+ * It does not check\n+ * 5) First txn is coinbase\n+ */\n+static bool CheckInputInvariants(const CBlock& block, CValidationState& state)\n+{\n+    /* This duplication checking algorithm uses a probabilistic filter to check\n+     * for collisions efficiently.  This is faster than the naive construction,\n+     * using a set, which requires more allocation and comparisons of uint256s.\n+     *\n+     * First we create a bitset table with 1<<21 elements. This is around 300\n+     * KB, so we construct it on the heap. We also create 8 pseudo-random\n+     * functions based on PCG. Each PCG function considers looks at 64 bits of\n+     * the prevout's hash, and the increment is xor'd with the index. Although\n+     * each hash is not dependent on the entire hash, a single 64-bit collision\n+     * would be expected with 4-billion UTXOS, and even then that would not\n+     * trigger a collision in this algorithm directly as there are 3 other\n+     * 64-bit hashes to collide.\n+     *\n+     *\n+     * Then, we iterate through the inputs one by one in order, hashing them using\n+     * our PCG hash functions.\n+     *\n+     * We then check if all 8 hashes are set in the table yet. If they are, we\n+     * do a linear scan through the inputs to see if it was a true collision,\n+     * and reject the txn.\n+     *\n+     * Otherwise, we set the 8 bits corresponding to the hashes and continue.\n+     *\n+     * ------------------------------------------------------------------------\n+     * Analysis\n+     * ------------------------------------------------------------------------\n+     * From the perspective of the N+1st prevout, assuming the transaction does\n+     * not double spend:\n+     *\n+     * Up to N*8 hashes have been set in the table already (potentially fewer if\n+     * collisions)\n+     *\n+     * For each of the 8 hashes h_1...h_8, P(bit set in table for h_i) =\n+     * (N*8)/1<<21\n+     *\n+     * Each of these probabilities is independent\n+     *\n+     * Therefore the total probability of a false collision on all bits is:\n+     * ((N*8)/2**21)**8\n+     *\n+     * The cost of a false collision is to do N comparisons.\n+     *\n+     * Therefore, the expression for the expected number of comparisons is:\n+     *\n+     * Sum[i*( i*8 / 2**21)**8, {i, 0, M}]\n+     *\n+     * Based on an input being at least 41 bytes, and a block being 1M bytes\n+     * max, there are a maximum of 24390 inputs, so M = 24390\n+     *\n+     * The total expected number of direct comparisons for M=24930 is therefore\n+     * 0.33 with this algorithm.\n+     *\n+     * The worst case for this algorithm from a denial of service perspective\n+     * with an invalid block would be to do a transaction where the last two\n+     * elements are a collision. In this case, the scan would require to scan all\n+     * N elements to find the conflict.\n+     *\n+     * ------------------------------------------------------------------------\n+     *  Extensions\n+     * ------------------------------------------------------------------------\n+     *\n+     * - Single Coinbase / Null Input Check\n+     *     Note that the first element checked is the coinbase transaction,\n+     *     whose input is null. Therefore, any subsequent null input would be a\n+     *     collision with that null, enabling us to not null check every\n+     *     subsequent entry. This has 0 overhead.\n+     * - Long Chain Check\n+     *     We also scan for the presence of the outputs of a transaction in the\n+     *     table as we go (without insertion), which detects an out-of-order\n+     *     spend in a long-chain within a block.\n+     *\n+     *     The worst case behavior for a block under this additional scan is for\n+     *     all inputs to be spent and then all outputs to be created. Any other\n+     *     pattern of inputs and outputs would be strictly less work. A minimal\n+     *     output is 9 bytes -- there are at most 1e6/9 outputs. Thus, we can\n+     *     model it as:\n+     *\n+     *     Max[((1-x)*1e6/9)(x*1e6/41)*(8*x*(1e6/41) / 2**21)**8 +\n+     *         Sum[ i*( i*8 / 2**21)**8, {i, 0, x*1e6/41}], {x, 0, 1}]\n+     *\n+     *     That is:\n+     *       The most amount of work for a given fraction x of block space devoted to\n+     *       inputs, which is the expected amount of work for checking a table with\n+     *       x*1e6/41 entries (1-x)*1e6/9 additional times plus the expected  work\n+     *       for deduplicating just the inputs.\n+     *\n+     *     This expression is at most ~0.7 expected comparisons worst case, which is\n+     *     still perfectly acceptable.\n+     */\n+\n+\n+    const auto pcg = [](uint64_t start, uint64_t inc) {\n+        uint64_t nxt = (inc | 1) + (start * 6364136223846793005ULL);",
    "path": "src/validation.cpp",
    "position": 107,
    "original_position": 107,
    "commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "original_commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "user": {
      "login": "JeremyRubin",
      "id": 886523,
      "node_id": "MDQ6VXNlcjg4NjUyMw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/886523?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/JeremyRubin",
      "html_url": "https://github.com/JeremyRubin",
      "followers_url": "https://api.github.com/users/JeremyRubin/followers",
      "following_url": "https://api.github.com/users/JeremyRubin/following{/other_user}",
      "gists_url": "https://api.github.com/users/JeremyRubin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/JeremyRubin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/JeremyRubin/subscriptions",
      "organizations_url": "https://api.github.com/users/JeremyRubin/orgs",
      "repos_url": "https://api.github.com/users/JeremyRubin/repos",
      "events_url": "https://api.github.com/users/JeremyRubin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/JeremyRubin/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "How do I make the wraparound explicit?",
    "created_at": "2018-11-30T22:41:00Z",
    "updated_at": "2018-11-30T22:41:00Z",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r238024768",
    "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/238024768"
      },
      "html": {
        "href": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r238024768"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837"
      }
    },
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/238024768/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "start_line": null,
    "original_start_line": null,
    "start_side": null,
    "line": 3181,
    "original_line": 3181,
    "side": "RIGHT",
    "in_reply_to_id": 237788322
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/238833478",
    "pull_request_review_id": 181473252,
    "id": 238833478,
    "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzODgzMzQ3OA==",
    "diff_hunk": "@@ -3075,6 +3075,232 @@ static bool CheckBlockHeader(const CBlockHeader& block, CValidationState& state,\n     return true;\n }\n \n+/* CheckInputInvariants checks for three criticial invariants for the inputs in a block:\n+ * 1) No Duplicate Inputs\n+ * 2) Only one Coinbase (implied by 1)\n+ * 3) No Null Inputs other than coinbase (implied by 1 and 5)\n+ * 4) All long-chains are in order\n+ *\n+ * It does not check\n+ * 5) First txn is coinbase\n+ */\n+static bool CheckInputInvariants(const CBlock& block, CValidationState& state)\n+{\n+    /* This duplication checking algorithm uses a probabilistic filter to check\n+     * for collisions efficiently.  This is faster than the naive construction,\n+     * using a set, which requires more allocation and comparisons of uint256s.\n+     *\n+     * First we create a bitset table with 1<<21 elements. This is around 300\n+     * KB, so we construct it on the heap. We also create 8 pseudo-random\n+     * functions based on PCG. Each PCG function considers looks at 64 bits of\n+     * the prevout's hash, and the increment is xor'd with the index. Although\n+     * each hash is not dependent on the entire hash, a single 64-bit collision\n+     * would be expected with 4-billion UTXOS, and even then that would not\n+     * trigger a collision in this algorithm directly as there are 3 other\n+     * 64-bit hashes to collide.\n+     *\n+     *\n+     * Then, we iterate through the inputs one by one in order, hashing them using\n+     * our PCG hash functions.\n+     *\n+     * We then check if all 8 hashes are set in the table yet. If they are, we\n+     * do a linear scan through the inputs to see if it was a true collision,\n+     * and reject the txn.\n+     *\n+     * Otherwise, we set the 8 bits corresponding to the hashes and continue.\n+     *\n+     * ------------------------------------------------------------------------\n+     * Analysis\n+     * ------------------------------------------------------------------------\n+     * From the perspective of the N+1st prevout, assuming the transaction does\n+     * not double spend:\n+     *\n+     * Up to N*8 hashes have been set in the table already (potentially fewer if\n+     * collisions)\n+     *\n+     * For each of the 8 hashes h_1...h_8, P(bit set in table for h_i) =\n+     * (N*8)/1<<21\n+     *\n+     * Each of these probabilities is independent\n+     *\n+     * Therefore the total probability of a false collision on all bits is:\n+     * ((N*8)/2**21)**8\n+     *\n+     * The cost of a false collision is to do N comparisons.\n+     *\n+     * Therefore, the expression for the expected number of comparisons is:\n+     *\n+     * Sum[i*( i*8 / 2**21)**8, {i, 0, M}]\n+     *\n+     * Based on an input being at least 41 bytes, and a block being 1M bytes\n+     * max, there are a maximum of 24390 inputs, so M = 24390\n+     *\n+     * The total expected number of direct comparisons for M=24930 is therefore\n+     * 0.33 with this algorithm.\n+     *\n+     * The worst case for this algorithm from a denial of service perspective\n+     * with an invalid block would be to do a transaction where the last two\n+     * elements are a collision. In this case, the scan would require to scan all\n+     * N elements to find the conflict.\n+     *\n+     * ------------------------------------------------------------------------\n+     *  Extensions\n+     * ------------------------------------------------------------------------\n+     *\n+     * - Single Coinbase / Null Input Check\n+     *     Note that the first element checked is the coinbase transaction,\n+     *     whose input is null. Therefore, any subsequent null input would be a\n+     *     collision with that null, enabling us to not null check every\n+     *     subsequent entry. This has 0 overhead.\n+     * - Long Chain Check\n+     *     We also scan for the presence of the outputs of a transaction in the\n+     *     table as we go (without insertion), which detects an out-of-order\n+     *     spend in a long-chain within a block.\n+     *\n+     *     The worst case behavior for a block under this additional scan is for\n+     *     all inputs to be spent and then all outputs to be created. Any other\n+     *     pattern of inputs and outputs would be strictly less work. A minimal\n+     *     output is 9 bytes -- there are at most 1e6/9 outputs. Thus, we can\n+     *     model it as:\n+     *\n+     *     Max[((1-x)*1e6/9)(x*1e6/41)*(8*x*(1e6/41) / 2**21)**8 +\n+     *         Sum[ i*( i*8 / 2**21)**8, {i, 0, x*1e6/41}], {x, 0, 1}]\n+     *\n+     *     That is:\n+     *       The most amount of work for a given fraction x of block space devoted to\n+     *       inputs, which is the expected amount of work for checking a table with\n+     *       x*1e6/41 entries (1-x)*1e6/9 additional times plus the expected  work\n+     *       for deduplicating just the inputs.\n+     *\n+     *     This expression is at most ~0.7 expected comparisons worst case, which is\n+     *     still perfectly acceptable.\n+     */\n+\n+\n+    const auto pcg = [](uint64_t start, uint64_t inc) {\n+        uint64_t nxt = (inc | 1) + (start * 6364136223846793005ULL);",
    "path": "src/validation.cpp",
    "position": 107,
    "original_position": 107,
    "commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "original_commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "user": {
      "login": "practicalswift",
      "id": 7826565,
      "node_id": "MDQ6VXNlcjc4MjY1NjU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/practicalswift",
      "html_url": "https://github.com/practicalswift",
      "followers_url": "https://api.github.com/users/practicalswift/followers",
      "following_url": "https://api.github.com/users/practicalswift/following{/other_user}",
      "gists_url": "https://api.github.com/users/practicalswift/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/practicalswift/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
      "organizations_url": "https://api.github.com/users/practicalswift/orgs",
      "repos_url": "https://api.github.com/users/practicalswift/repos",
      "events_url": "https://api.github.com/users/practicalswift/events{/privacy}",
      "received_events_url": "https://api.github.com/users/practicalswift/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "You could use the method I used in PR #14224: \r\n\r\nhttps://github.com/practicalswift/bitcoin/blob/0373038cedc07e3d775a1055c0da45f4e8fda2b7/src/attributes.h#L9-L15\r\n",
    "created_at": "2018-12-04T20:52:05Z",
    "updated_at": "2018-12-04T20:52:06Z",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r238833478",
    "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/238833478"
      },
      "html": {
        "href": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r238833478"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837"
      }
    },
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/238833478/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "start_line": null,
    "original_start_line": null,
    "start_side": null,
    "line": 3181,
    "original_line": 3181,
    "side": "RIGHT",
    "in_reply_to_id": 237788322
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/238873171",
    "pull_request_review_id": 181522638,
    "id": 238873171,
    "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzODg3MzE3MQ==",
    "diff_hunk": "@@ -3075,6 +3075,232 @@ static bool CheckBlockHeader(const CBlockHeader& block, CValidationState& state,\n     return true;\n }\n \n+/* CheckInputInvariants checks for three criticial invariants for the inputs in a block:\n+ * 1) No Duplicate Inputs\n+ * 2) Only one Coinbase (implied by 1)\n+ * 3) No Null Inputs other than coinbase (implied by 1 and 5)\n+ * 4) All long-chains are in order\n+ *\n+ * It does not check\n+ * 5) First txn is coinbase\n+ */\n+static bool CheckInputInvariants(const CBlock& block, CValidationState& state)\n+{\n+    /* This duplication checking algorithm uses a probabilistic filter to check\n+     * for collisions efficiently.  This is faster than the naive construction,\n+     * using a set, which requires more allocation and comparisons of uint256s.\n+     *\n+     * First we create a bitset table with 1<<21 elements. This is around 300\n+     * KB, so we construct it on the heap. We also create 8 pseudo-random\n+     * functions based on PCG. Each PCG function considers looks at 64 bits of\n+     * the prevout's hash, and the increment is xor'd with the index. Although\n+     * each hash is not dependent on the entire hash, a single 64-bit collision\n+     * would be expected with 4-billion UTXOS, and even then that would not\n+     * trigger a collision in this algorithm directly as there are 3 other\n+     * 64-bit hashes to collide.\n+     *\n+     *\n+     * Then, we iterate through the inputs one by one in order, hashing them using\n+     * our PCG hash functions.\n+     *\n+     * We then check if all 8 hashes are set in the table yet. If they are, we\n+     * do a linear scan through the inputs to see if it was a true collision,\n+     * and reject the txn.\n+     *\n+     * Otherwise, we set the 8 bits corresponding to the hashes and continue.\n+     *\n+     * ------------------------------------------------------------------------\n+     * Analysis\n+     * ------------------------------------------------------------------------\n+     * From the perspective of the N+1st prevout, assuming the transaction does\n+     * not double spend:\n+     *\n+     * Up to N*8 hashes have been set in the table already (potentially fewer if\n+     * collisions)\n+     *\n+     * For each of the 8 hashes h_1...h_8, P(bit set in table for h_i) =\n+     * (N*8)/1<<21\n+     *\n+     * Each of these probabilities is independent\n+     *\n+     * Therefore the total probability of a false collision on all bits is:\n+     * ((N*8)/2**21)**8\n+     *\n+     * The cost of a false collision is to do N comparisons.\n+     *\n+     * Therefore, the expression for the expected number of comparisons is:\n+     *\n+     * Sum[i*( i*8 / 2**21)**8, {i, 0, M}]\n+     *\n+     * Based on an input being at least 41 bytes, and a block being 1M bytes\n+     * max, there are a maximum of 24390 inputs, so M = 24390\n+     *\n+     * The total expected number of direct comparisons for M=24930 is therefore\n+     * 0.33 with this algorithm.\n+     *\n+     * The worst case for this algorithm from a denial of service perspective\n+     * with an invalid block would be to do a transaction where the last two\n+     * elements are a collision. In this case, the scan would require to scan all\n+     * N elements to find the conflict.\n+     *\n+     * ------------------------------------------------------------------------\n+     *  Extensions\n+     * ------------------------------------------------------------------------\n+     *\n+     * - Single Coinbase / Null Input Check\n+     *     Note that the first element checked is the coinbase transaction,\n+     *     whose input is null. Therefore, any subsequent null input would be a\n+     *     collision with that null, enabling us to not null check every\n+     *     subsequent entry. This has 0 overhead.\n+     * - Long Chain Check\n+     *     We also scan for the presence of the outputs of a transaction in the\n+     *     table as we go (without insertion), which detects an out-of-order\n+     *     spend in a long-chain within a block.\n+     *\n+     *     The worst case behavior for a block under this additional scan is for\n+     *     all inputs to be spent and then all outputs to be created. Any other\n+     *     pattern of inputs and outputs would be strictly less work. A minimal\n+     *     output is 9 bytes -- there are at most 1e6/9 outputs. Thus, we can\n+     *     model it as:\n+     *\n+     *     Max[((1-x)*1e6/9)(x*1e6/41)*(8*x*(1e6/41) / 2**21)**8 +\n+     *         Sum[ i*( i*8 / 2**21)**8, {i, 0, x*1e6/41}], {x, 0, 1}]\n+     *\n+     *     That is:\n+     *       The most amount of work for a given fraction x of block space devoted to\n+     *       inputs, which is the expected amount of work for checking a table with\n+     *       x*1e6/41 entries (1-x)*1e6/9 additional times plus the expected  work\n+     *       for deduplicating just the inputs.\n+     *\n+     *     This expression is at most ~0.7 expected comparisons worst case, which is\n+     *     still perfectly acceptable.\n+     */\n+\n+\n+    const auto pcg = [](uint64_t start, uint64_t inc) {\n+        uint64_t nxt = (inc | 1) + (start * 6364136223846793005ULL);",
    "path": "src/validation.cpp",
    "position": 107,
    "original_position": 107,
    "commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "original_commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "user": {
      "login": "MarcoFalke",
      "id": 6399679,
      "node_id": "MDQ6VXNlcjYzOTk2Nzk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6399679?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/MarcoFalke",
      "html_url": "https://github.com/MarcoFalke",
      "followers_url": "https://api.github.com/users/MarcoFalke/followers",
      "following_url": "https://api.github.com/users/MarcoFalke/following{/other_user}",
      "gists_url": "https://api.github.com/users/MarcoFalke/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/MarcoFalke/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/MarcoFalke/subscriptions",
      "organizations_url": "https://api.github.com/users/MarcoFalke/orgs",
      "repos_url": "https://api.github.com/users/MarcoFalke/repos",
      "events_url": "https://api.github.com/users/MarcoFalke/events{/privacy}",
      "received_events_url": "https://api.github.com/users/MarcoFalke/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "Why would that be preferable to the sanitizer suppressions in `./test/`?",
    "created_at": "2018-12-04T23:00:00Z",
    "updated_at": "2018-12-04T23:00:00Z",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r238873171",
    "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837",
    "author_association": "MEMBER",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/238873171"
      },
      "html": {
        "href": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r238873171"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837"
      }
    },
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/238873171/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "start_line": null,
    "original_start_line": null,
    "start_side": null,
    "line": 3181,
    "original_line": 3181,
    "side": "RIGHT",
    "in_reply_to_id": 237788322
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/239325118",
    "pull_request_review_id": 182080105,
    "id": 239325118,
    "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzOTMyNTExOA==",
    "diff_hunk": "@@ -3075,6 +3075,232 @@ static bool CheckBlockHeader(const CBlockHeader& block, CValidationState& state,\n     return true;\n }\n \n+/* CheckInputInvariants checks for three criticial invariants for the inputs in a block:\n+ * 1) No Duplicate Inputs\n+ * 2) Only one Coinbase (implied by 1)\n+ * 3) No Null Inputs other than coinbase (implied by 1 and 5)\n+ * 4) All long-chains are in order\n+ *\n+ * It does not check\n+ * 5) First txn is coinbase\n+ */\n+static bool CheckInputInvariants(const CBlock& block, CValidationState& state)\n+{\n+    /* This duplication checking algorithm uses a probabilistic filter to check\n+     * for collisions efficiently.  This is faster than the naive construction,\n+     * using a set, which requires more allocation and comparisons of uint256s.\n+     *\n+     * First we create a bitset table with 1<<21 elements. This is around 300\n+     * KB, so we construct it on the heap. We also create 8 pseudo-random\n+     * functions based on PCG. Each PCG function considers looks at 64 bits of\n+     * the prevout's hash, and the increment is xor'd with the index. Although\n+     * each hash is not dependent on the entire hash, a single 64-bit collision\n+     * would be expected with 4-billion UTXOS, and even then that would not\n+     * trigger a collision in this algorithm directly as there are 3 other\n+     * 64-bit hashes to collide.\n+     *\n+     *\n+     * Then, we iterate through the inputs one by one in order, hashing them using\n+     * our PCG hash functions.\n+     *\n+     * We then check if all 8 hashes are set in the table yet. If they are, we\n+     * do a linear scan through the inputs to see if it was a true collision,\n+     * and reject the txn.\n+     *\n+     * Otherwise, we set the 8 bits corresponding to the hashes and continue.\n+     *\n+     * ------------------------------------------------------------------------\n+     * Analysis\n+     * ------------------------------------------------------------------------\n+     * From the perspective of the N+1st prevout, assuming the transaction does\n+     * not double spend:\n+     *\n+     * Up to N*8 hashes have been set in the table already (potentially fewer if\n+     * collisions)\n+     *\n+     * For each of the 8 hashes h_1...h_8, P(bit set in table for h_i) =\n+     * (N*8)/1<<21\n+     *\n+     * Each of these probabilities is independent\n+     *\n+     * Therefore the total probability of a false collision on all bits is:\n+     * ((N*8)/2**21)**8\n+     *\n+     * The cost of a false collision is to do N comparisons.\n+     *\n+     * Therefore, the expression for the expected number of comparisons is:\n+     *\n+     * Sum[i*( i*8 / 2**21)**8, {i, 0, M}]\n+     *\n+     * Based on an input being at least 41 bytes, and a block being 1M bytes\n+     * max, there are a maximum of 24390 inputs, so M = 24390\n+     *\n+     * The total expected number of direct comparisons for M=24930 is therefore\n+     * 0.33 with this algorithm.\n+     *\n+     * The worst case for this algorithm from a denial of service perspective\n+     * with an invalid block would be to do a transaction where the last two\n+     * elements are a collision. In this case, the scan would require to scan all\n+     * N elements to find the conflict.\n+     *\n+     * ------------------------------------------------------------------------\n+     *  Extensions\n+     * ------------------------------------------------------------------------\n+     *\n+     * - Single Coinbase / Null Input Check\n+     *     Note that the first element checked is the coinbase transaction,\n+     *     whose input is null. Therefore, any subsequent null input would be a\n+     *     collision with that null, enabling us to not null check every\n+     *     subsequent entry. This has 0 overhead.\n+     * - Long Chain Check\n+     *     We also scan for the presence of the outputs of a transaction in the\n+     *     table as we go (without insertion), which detects an out-of-order\n+     *     spend in a long-chain within a block.\n+     *\n+     *     The worst case behavior for a block under this additional scan is for\n+     *     all inputs to be spent and then all outputs to be created. Any other\n+     *     pattern of inputs and outputs would be strictly less work. A minimal\n+     *     output is 9 bytes -- there are at most 1e6/9 outputs. Thus, we can\n+     *     model it as:\n+     *\n+     *     Max[((1-x)*1e6/9)(x*1e6/41)*(8*x*(1e6/41) / 2**21)**8 +\n+     *         Sum[ i*( i*8 / 2**21)**8, {i, 0, x*1e6/41}], {x, 0, 1}]\n+     *\n+     *     That is:\n+     *       The most amount of work for a given fraction x of block space devoted to\n+     *       inputs, which is the expected amount of work for checking a table with\n+     *       x*1e6/41 entries (1-x)*1e6/9 additional times plus the expected  work\n+     *       for deduplicating just the inputs.\n+     *\n+     *     This expression is at most ~0.7 expected comparisons worst case, which is\n+     *     still perfectly acceptable.\n+     */\n+\n+\n+    const auto pcg = [](uint64_t start, uint64_t inc) {\n+        uint64_t nxt = (inc | 1) + (start * 6364136223846793005ULL);",
    "path": "src/validation.cpp",
    "position": 107,
    "original_position": 107,
    "commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "original_commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "user": {
      "login": "JeremyRubin",
      "id": 886523,
      "node_id": "MDQ6VXNlcjg4NjUyMw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/886523?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/JeremyRubin",
      "html_url": "https://github.com/JeremyRubin",
      "followers_url": "https://api.github.com/users/JeremyRubin/followers",
      "following_url": "https://api.github.com/users/JeremyRubin/following{/other_user}",
      "gists_url": "https://api.github.com/users/JeremyRubin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/JeremyRubin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/JeremyRubin/subscriptions",
      "organizations_url": "https://api.github.com/users/JeremyRubin/orgs",
      "repos_url": "https://api.github.com/users/JeremyRubin/repos",
      "events_url": "https://api.github.com/users/JeremyRubin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/JeremyRubin/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "Yeah I'm not sure about it. Unsigned integer overflow isn't a bug, it's a feature... I would also like a suppression that operates at the statement level (e.g., like rust's wrapping_mul) rather than marking the entire function with an attribute. What if there is an unsigned wraparound issue elsewhere in the code?",
    "created_at": "2018-12-06T04:29:54Z",
    "updated_at": "2018-12-06T04:29:54Z",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r239325118",
    "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/239325118"
      },
      "html": {
        "href": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r239325118"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837"
      }
    },
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/239325118/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "start_line": null,
    "original_start_line": null,
    "start_side": null,
    "line": 3181,
    "original_line": 3181,
    "side": "RIGHT",
    "in_reply_to_id": 237788322
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/239331146",
    "pull_request_review_id": 182087264,
    "id": 239331146,
    "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzOTMzMTE0Ng==",
    "diff_hunk": "@@ -3075,6 +3075,232 @@ static bool CheckBlockHeader(const CBlockHeader& block, CValidationState& state,\n     return true;\n }\n \n+/* CheckInputInvariants checks for three criticial invariants for the inputs in a block:\n+ * 1) No Duplicate Inputs\n+ * 2) Only one Coinbase (implied by 1)\n+ * 3) No Null Inputs other than coinbase (implied by 1 and 5)\n+ * 4) All long-chains are in order\n+ *\n+ * It does not check\n+ * 5) First txn is coinbase\n+ */\n+static bool CheckInputInvariants(const CBlock& block, CValidationState& state)\n+{\n+    /* This duplication checking algorithm uses a probabilistic filter to check\n+     * for collisions efficiently.  This is faster than the naive construction,\n+     * using a set, which requires more allocation and comparisons of uint256s.\n+     *\n+     * First we create a bitset table with 1<<21 elements. This is around 300\n+     * KB, so we construct it on the heap. We also create 8 pseudo-random\n+     * functions based on PCG. Each PCG function considers looks at 64 bits of\n+     * the prevout's hash, and the increment is xor'd with the index. Although\n+     * each hash is not dependent on the entire hash, a single 64-bit collision\n+     * would be expected with 4-billion UTXOS, and even then that would not\n+     * trigger a collision in this algorithm directly as there are 3 other\n+     * 64-bit hashes to collide.\n+     *\n+     *\n+     * Then, we iterate through the inputs one by one in order, hashing them using\n+     * our PCG hash functions.\n+     *\n+     * We then check if all 8 hashes are set in the table yet. If they are, we\n+     * do a linear scan through the inputs to see if it was a true collision,\n+     * and reject the txn.\n+     *\n+     * Otherwise, we set the 8 bits corresponding to the hashes and continue.\n+     *\n+     * ------------------------------------------------------------------------\n+     * Analysis\n+     * ------------------------------------------------------------------------\n+     * From the perspective of the N+1st prevout, assuming the transaction does\n+     * not double spend:\n+     *\n+     * Up to N*8 hashes have been set in the table already (potentially fewer if\n+     * collisions)\n+     *\n+     * For each of the 8 hashes h_1...h_8, P(bit set in table for h_i) =\n+     * (N*8)/1<<21\n+     *\n+     * Each of these probabilities is independent\n+     *\n+     * Therefore the total probability of a false collision on all bits is:\n+     * ((N*8)/2**21)**8\n+     *\n+     * The cost of a false collision is to do N comparisons.\n+     *\n+     * Therefore, the expression for the expected number of comparisons is:\n+     *\n+     * Sum[i*( i*8 / 2**21)**8, {i, 0, M}]\n+     *\n+     * Based on an input being at least 41 bytes, and a block being 1M bytes\n+     * max, there are a maximum of 24390 inputs, so M = 24390\n+     *\n+     * The total expected number of direct comparisons for M=24930 is therefore\n+     * 0.33 with this algorithm.\n+     *\n+     * The worst case for this algorithm from a denial of service perspective\n+     * with an invalid block would be to do a transaction where the last two\n+     * elements are a collision. In this case, the scan would require to scan all\n+     * N elements to find the conflict.\n+     *\n+     * ------------------------------------------------------------------------\n+     *  Extensions\n+     * ------------------------------------------------------------------------\n+     *\n+     * - Single Coinbase / Null Input Check\n+     *     Note that the first element checked is the coinbase transaction,\n+     *     whose input is null. Therefore, any subsequent null input would be a\n+     *     collision with that null, enabling us to not null check every\n+     *     subsequent entry. This has 0 overhead.\n+     * - Long Chain Check\n+     *     We also scan for the presence of the outputs of a transaction in the\n+     *     table as we go (without insertion), which detects an out-of-order\n+     *     spend in a long-chain within a block.\n+     *\n+     *     The worst case behavior for a block under this additional scan is for\n+     *     all inputs to be spent and then all outputs to be created. Any other\n+     *     pattern of inputs and outputs would be strictly less work. A minimal\n+     *     output is 9 bytes -- there are at most 1e6/9 outputs. Thus, we can\n+     *     model it as:\n+     *\n+     *     Max[((1-x)*1e6/9)(x*1e6/41)*(8*x*(1e6/41) / 2**21)**8 +\n+     *         Sum[ i*( i*8 / 2**21)**8, {i, 0, x*1e6/41}], {x, 0, 1}]\n+     *\n+     *     That is:\n+     *       The most amount of work for a given fraction x of block space devoted to\n+     *       inputs, which is the expected amount of work for checking a table with\n+     *       x*1e6/41 entries (1-x)*1e6/9 additional times plus the expected  work\n+     *       for deduplicating just the inputs.\n+     *\n+     *     This expression is at most ~0.7 expected comparisons worst case, which is\n+     *     still perfectly acceptable.\n+     */\n+\n+\n+    const auto pcg = [](uint64_t start, uint64_t inc) {\n+        uint64_t nxt = (inc | 1) + (start * 6364136223846793005ULL);",
    "path": "src/validation.cpp",
    "position": 107,
    "original_position": 107,
    "commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "original_commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "user": {
      "login": "practicalswift",
      "id": 7826565,
      "node_id": "MDQ6VXNlcjc4MjY1NjU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/practicalswift",
      "html_url": "https://github.com/practicalswift",
      "followers_url": "https://api.github.com/users/practicalswift/followers",
      "following_url": "https://api.github.com/users/practicalswift/following{/other_user}",
      "gists_url": "https://api.github.com/users/practicalswift/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/practicalswift/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
      "organizations_url": "https://api.github.com/users/practicalswift/orgs",
      "repos_url": "https://api.github.com/users/practicalswift/repos",
      "events_url": "https://api.github.com/users/practicalswift/events{/privacy}",
      "received_events_url": "https://api.github.com/users/practicalswift/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "@MarcoFalke In contrast to the sanitizer suppressions it documents if the wraparound is intentional or not.\r\n\r\nWhat do you think about using say `INTENTIONAL_WRAPAROUND` for the intentional wraparounds and the file based sanitizer suppressions to cover the unintentional wraparounds?",
    "created_at": "2018-12-06T05:21:29Z",
    "updated_at": "2018-12-06T05:30:00Z",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r239331146",
    "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/239331146"
      },
      "html": {
        "href": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r239331146"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837"
      }
    },
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/239331146/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "start_line": null,
    "original_start_line": null,
    "start_side": null,
    "line": 3181,
    "original_line": 3181,
    "side": "RIGHT",
    "in_reply_to_id": 237788322
  },
  {
    "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/239331523",
    "pull_request_review_id": 182087754,
    "id": 239331523,
    "node_id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDIzOTMzMTUyMw==",
    "diff_hunk": "@@ -3075,6 +3075,232 @@ static bool CheckBlockHeader(const CBlockHeader& block, CValidationState& state,\n     return true;\n }\n \n+/* CheckInputInvariants checks for three criticial invariants for the inputs in a block:\n+ * 1) No Duplicate Inputs\n+ * 2) Only one Coinbase (implied by 1)\n+ * 3) No Null Inputs other than coinbase (implied by 1 and 5)\n+ * 4) All long-chains are in order\n+ *\n+ * It does not check\n+ * 5) First txn is coinbase\n+ */\n+static bool CheckInputInvariants(const CBlock& block, CValidationState& state)\n+{\n+    /* This duplication checking algorithm uses a probabilistic filter to check\n+     * for collisions efficiently.  This is faster than the naive construction,\n+     * using a set, which requires more allocation and comparisons of uint256s.\n+     *\n+     * First we create a bitset table with 1<<21 elements. This is around 300\n+     * KB, so we construct it on the heap. We also create 8 pseudo-random\n+     * functions based on PCG. Each PCG function considers looks at 64 bits of\n+     * the prevout's hash, and the increment is xor'd with the index. Although\n+     * each hash is not dependent on the entire hash, a single 64-bit collision\n+     * would be expected with 4-billion UTXOS, and even then that would not\n+     * trigger a collision in this algorithm directly as there are 3 other\n+     * 64-bit hashes to collide.\n+     *\n+     *\n+     * Then, we iterate through the inputs one by one in order, hashing them using\n+     * our PCG hash functions.\n+     *\n+     * We then check if all 8 hashes are set in the table yet. If they are, we\n+     * do a linear scan through the inputs to see if it was a true collision,\n+     * and reject the txn.\n+     *\n+     * Otherwise, we set the 8 bits corresponding to the hashes and continue.\n+     *\n+     * ------------------------------------------------------------------------\n+     * Analysis\n+     * ------------------------------------------------------------------------\n+     * From the perspective of the N+1st prevout, assuming the transaction does\n+     * not double spend:\n+     *\n+     * Up to N*8 hashes have been set in the table already (potentially fewer if\n+     * collisions)\n+     *\n+     * For each of the 8 hashes h_1...h_8, P(bit set in table for h_i) =\n+     * (N*8)/1<<21\n+     *\n+     * Each of these probabilities is independent\n+     *\n+     * Therefore the total probability of a false collision on all bits is:\n+     * ((N*8)/2**21)**8\n+     *\n+     * The cost of a false collision is to do N comparisons.\n+     *\n+     * Therefore, the expression for the expected number of comparisons is:\n+     *\n+     * Sum[i*( i*8 / 2**21)**8, {i, 0, M}]\n+     *\n+     * Based on an input being at least 41 bytes, and a block being 1M bytes\n+     * max, there are a maximum of 24390 inputs, so M = 24390\n+     *\n+     * The total expected number of direct comparisons for M=24930 is therefore\n+     * 0.33 with this algorithm.\n+     *\n+     * The worst case for this algorithm from a denial of service perspective\n+     * with an invalid block would be to do a transaction where the last two\n+     * elements are a collision. In this case, the scan would require to scan all\n+     * N elements to find the conflict.\n+     *\n+     * ------------------------------------------------------------------------\n+     *  Extensions\n+     * ------------------------------------------------------------------------\n+     *\n+     * - Single Coinbase / Null Input Check\n+     *     Note that the first element checked is the coinbase transaction,\n+     *     whose input is null. Therefore, any subsequent null input would be a\n+     *     collision with that null, enabling us to not null check every\n+     *     subsequent entry. This has 0 overhead.\n+     * - Long Chain Check\n+     *     We also scan for the presence of the outputs of a transaction in the\n+     *     table as we go (without insertion), which detects an out-of-order\n+     *     spend in a long-chain within a block.\n+     *\n+     *     The worst case behavior for a block under this additional scan is for\n+     *     all inputs to be spent and then all outputs to be created. Any other\n+     *     pattern of inputs and outputs would be strictly less work. A minimal\n+     *     output is 9 bytes -- there are at most 1e6/9 outputs. Thus, we can\n+     *     model it as:\n+     *\n+     *     Max[((1-x)*1e6/9)(x*1e6/41)*(8*x*(1e6/41) / 2**21)**8 +\n+     *         Sum[ i*( i*8 / 2**21)**8, {i, 0, x*1e6/41}], {x, 0, 1}]\n+     *\n+     *     That is:\n+     *       The most amount of work for a given fraction x of block space devoted to\n+     *       inputs, which is the expected amount of work for checking a table with\n+     *       x*1e6/41 entries (1-x)*1e6/9 additional times plus the expected  work\n+     *       for deduplicating just the inputs.\n+     *\n+     *     This expression is at most ~0.7 expected comparisons worst case, which is\n+     *     still perfectly acceptable.\n+     */\n+\n+\n+    const auto pcg = [](uint64_t start, uint64_t inc) {\n+        uint64_t nxt = (inc | 1) + (start * 6364136223846793005ULL);",
    "path": "src/validation.cpp",
    "position": 107,
    "original_position": 107,
    "commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "original_commit_id": "0425c6409000aeb3270ba8f9c30d2746c5c5b784",
    "user": {
      "login": "practicalswift",
      "id": 7826565,
      "node_id": "MDQ6VXNlcjc4MjY1NjU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7826565?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/practicalswift",
      "html_url": "https://github.com/practicalswift",
      "followers_url": "https://api.github.com/users/practicalswift/followers",
      "following_url": "https://api.github.com/users/practicalswift/following{/other_user}",
      "gists_url": "https://api.github.com/users/practicalswift/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/practicalswift/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/practicalswift/subscriptions",
      "organizations_url": "https://api.github.com/users/practicalswift/orgs",
      "repos_url": "https://api.github.com/users/practicalswift/repos",
      "events_url": "https://api.github.com/users/practicalswift/events{/privacy}",
      "received_events_url": "https://api.github.com/users/practicalswift/received_events",
      "type": "User",
      "site_admin": false
    },
    "body": "@JeremyRubin I assume you're talking about intentional wraparounds as features? The problem isn't intentional wraparounds \u2013 they are totally fine by definition. The problem is unintentional wraparounds. \r\n\r\nI share your wish for suppressions that operated at the statement level, but they don't exist yet AFAIK :-)",
    "created_at": "2018-12-06T05:24:40Z",
    "updated_at": "2018-12-06T05:27:41Z",
    "html_url": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r239331523",
    "pull_request_url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837",
    "author_association": "CONTRIBUTOR",
    "_links": {
      "self": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/239331523"
      },
      "html": {
        "href": "https://github.com/bitcoin/bitcoin/pull/14837#discussion_r239331523"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/bitcoin/bitcoin/pulls/14837"
      }
    },
    "reactions": {
      "url": "https://api.github.com/repos/bitcoin/bitcoin/pulls/comments/239331523/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "start_line": null,
    "original_start_line": null,
    "start_side": null,
    "line": 3181,
    "original_line": 3181,
    "side": "RIGHT",
    "in_reply_to_id": 237788322
  }
]