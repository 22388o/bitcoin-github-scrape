[
  {
    "sha": "66480821b36c839ab7615cb9309850015bceadb0",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo2NjQ4MDgyMWIzNmM4MzlhYjc2MTVjYjkzMDk4NTAwMTViY2VhZGIw",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T15:59:07Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T15:59:07Z"
      },
      "message": "Squashed 'src/leveldb/' changes from f545dfabff4c2e9836efed094dba99a34fbc6b88..f8ae182c1e5176d12e816fb2217ae33a5472fdd7\n\nf8ae182c1e5176d12e816fb2217ae33a5472fdd7 Adds unicode support to Windows environment.\n92ae82c78f225de84040c51e07fd0b4a61caed99 Increase maximum read-only mmap()s used from 1000 to 4096 on 64-bit systems\nd42e63d49d9df05b12cd00af4ffc5f2b3edf7e21 Do not crash if filesystem can't fsync\nbf2c2090b7ee12c5d85b85f08649b6e685f8715f Add filename to corruption errors\n0c40829872a9f00f38e11dc370ff8adb3e19f25b Remove redundant PROJECT_SOURCE_DIR usage from CMake config.\n5abdf4c019e51fce59d34c21b13bf4e0a948828a Fix installed target definition.\ncf4d9ab23de7ec36b8e00536b7450f02c639cd87 Test CMake installation on Travis.\n95d0ba1cb046bfd76619b8b80e14ee1b2897d219 Renamed local variable in DBImpl::Write.\n657ba514298a726c7533f3106d3778062b59d75f Added return in Version::Get::State::Match to quiet warning.\n370d532a00581ca79c87af7d7811e56de0ca52a8 Using CMake's check_cxx_compiler_flag to check support for -Wthread-safety.\n45ee61579c1eb3accd6c88c922ec468dd61beea8 Update Travis CI configuration.\n60db170a43a373d734c5b9f19693d36c75251c39 Fix tsan problem in env_test.\n21304d41f77990b8edabbdab33b222bd5ceb5f18 Merge pull request #698 from neal-zhu:master\n5e921896eedf87b0fb06bc8a1fd0991b9ac64131 drop fileds in State that are duplicates of fileds in Saver and fix typo\n53e280b56866ac4c90a9f5fcfe02ebdfd4a19832 Simplify unlocking in DeleteObsoleteFiles.\n046216a7ca6fb17a40cf8aa5598d90c825212a3d Add \"leveldb\" subdirectory to public include paths.\n9ee91ac747ddf26f484d54f9aa474ccc4a2e0359 Ending sentences with periods in README.md.\ne0d5f83a4f80060fe5b5d80025f0ad049bca430e Align EnvPosix and EnvWindows.\n69061b464ab1da287da9b7ffec1ed911b754403b Disable exceptions and RTTI in CMake configuration.\n107a75b62c19cce901ce10619b63c4b7acc9a0be cache Saver in State object\n76ca1162768e5c89f1a49946a1f286c702ae27ae fix bug(uninitialized options pointer in State)\nf668239bb262609146496b854e1ec3cea9cd1a83 remove TODO in Version::ForEachOverlapping\n177cd08629883c409f7a01f90f7084bc5518f1ef format\n8fa7a937ee8f38d8869357b0f27f120c5c58f4c9 fix bug\n6a90bb91ee72642241fdbeefa673f88370c7b245 use ForEachOverlapping to impl Get\n4cb80b7ddce6ff6089b15d8cfebf746fc1572477 Merge pull request #386 from ivanabc:master\n72a38ff7f206b3924ac009a12a1838d6a0bdab03 Replace \"> >\" with \">>\"\n863f185970eff21e826e5fe1164a6215a515c23b unsigned char -> uint8_t\na3b71c1ff65e30ced00e85ebbca9ae5786af6626 Use GCC 9 on Travis CI\nae49533210e96bdee9c9479a7fa547f375a39c8b Add explicit typecasts to avoid compiler warning.\n63d5315e1c224e52da8ec68d118c5b73ba2a63fc Merge branch 'master' into master\nc00e177f3613068eda4bff4abfbd3bd4165a86e8 Guard DBImpl::versions_ by mutex_.\n1d0b101165ddd34f26cc5c62b76f2a2e0d622483 Converted two for-loops to while-loops.\n28e6d238be73e743c963fc0a26395b783a7565e2 Switch to using C++ 11 override specifier.\n85cd40d108d8f8d91f58fd263c0f8428d11c34d5 Added unit test for InternalKey::DecodeFrom with empty string.\n1aae5c9f29ea43ceca745efae012c4aa731e9374 Merge pull request #411 from proller:assert1\nb7b86baec9ce47569affc5db54a20a6cc520e0f0 Using std::ostringstream in key DebugString.\n3e6c000e18519cb22e0a44d0dea45b34daee4ee1 Merge pull request #457 from jellor:patch-2\n1d94fe2f4d1dfdf1a6312bf4b36efcbe0c1bf576 Merge branch 'master' into patch-2\n27dc99fb2642cadc87c9aaec82c54a2c725ee0d6 Fix EnvPosix tests on Travis CI.\n9521545b062841409cf66eff0655feff09d9fd82 Formatting changes for prior O_CLOEXEC fix.\n900f7d37eb3224059dd37afc6614d3158ddaeb8d Merge pull request #624 from adam-azarchs:master\na7528a5d2bd29126b60a277b528ed606b67c1771 Clean up util/coding.{h,cc}.\n142035edd4b1ab431c0ecbd547d4a77f1eca0667 Initialize Stats::start_ before first use in Stats::Start().\ne22b1cec6e1e0e2dec4c93b658acbfc56fb692c0 Merge pull request #365 from allangj:c-strict-prototypes\ncd1ec032cd276409ba403cab4d0b2548dd26b890 Add argument definition for void c functions.\n4bd052d7e8b0469b2b87664388e2a99cb212ecdb Consolidate benchmark code to benchmarks/.\n506b1722ef1a58d87325575d9bbcd3c8869381c7 Convert missed virtual -> override in db_test.cc.\n24424a1ef2c284f4ec30544a3458023362cbeacd Style cleanup.\n9a56c49ed415df1b72ba1c84c8e7ed00de497f68 Merge pull request #679 from smartxworks:optimize-readseq\nabf441b657c7e75091e2bd59449df6849358b812 Merge pull request #278 from wankai:master\n78b39d68c15ba020c0d60a3906fb66dbf1697595 Bump the version number from 1.21 to 1.22.\n9bd23c767601a2420478eec158927882b879bada Correct class/structure declaration order.\nc784d63b931d07895833fb80185b10d44ad63cce Moved port/README to port/README.md.\n297e66afc1dda3f3d7a7cc2022030164c302cb7a Format all files IAW the Google C++ Style Guide.\n3724030179716fd8d95cf79339884c49afade8f9 Update Travis CI configuration.\nd3d1c8a0f40a7eaa12a5bb702fa01786b7c3a646 don't check current key in DBIter::Next()\n3dc9202f78a3eb30ee8c0267e4e4be2e3f986e45 [leveldb] Specifically export the WriteBatch::Handler inner class for Windows link\n2ccb45c33aecd8b15000c0c622f45eb119b6b478 Check for possibly invalid offset in test.\n7b1174519044339f07a023dc445b0d36425bd6db Changed Windows specific highlighting from bash to cmd.\n2f008ac19ec783e4d0ba2161320241c99e9897e1 Initialize class members to default values in constructors.\nffabb1ae86cc4eb4516a7c0824c878c3b2d19e5d Merge pull request #665 from cheng-chang:coding\n7da571cf2b954a107fa060698bfbfbba8e8318f8 Merge pull request #669 from pavel-pimenov:fix-readme-windows-mkdir\ndf4a323aafbf65996fec23de8b2dbb9d7e27ae11 Merge pull request #472 from zhoudayang:patch-1\n5a2a472741f36ecf5b994439da5a64c6ab90c47f Fixed missing std namespaces and make_unique.\n08e771901f454ac32643bd8e8cb2bcfa08026c0c Simplify issue320_test.\n65e86f75ea30e44bc65327f92a16328684269acb Fix formatting of recent snapshot compaction fix.\n7711e76766231bf93e0487c4530b2655e8c4c0b1 Merge pull request #339 from richcole-at-amazon:master\n71ed7c401ec1b1e38d6f7cb9eb2fcff93c24d1f1 Fixed typo in comment in version_set.h.\n09fa8868dbe0cb2701f0560c59ebb63cc17f1271 Align version/soversion CMake setup closer with other repositories.\n20fb601aa9f68ff0aa147df22524b7d01758552b Fix snapshot compaction bug\n37300aa54b8256dd2edfd504942eb2bd20823647 Restore soname versioning with CMake build\n952be04df6edb936b8f7d0f652861100a7f61e97 Fix mkdir (windows)\n56178ddaf4d3ba6c8d1cfb218610b1be3f5aa710 Update the version to 1.21 in preparation for a new release.\n35619d248d909b197f68226c7d0a9ff947b82e8a Project import generated by Copybara.\n416344de2fdffb3f17c565b984885d0122bfa1e9 leveldb: Register in copybara whitelist.\nda94ac67e91679842a56a876f0b19b429d72de25 leveldb: Minor cleanup in ports.\nbd24b963060861518c6648925f9708178562c992 leveldb: Silence unused argument warnings in MSVC.\n6188a54ce95b47cc6bd398d7f2eb45d061857e45 leveldb: Add tests for empty keys and values.\ncf1b5f473259e46c667f3fb5a28bcd884ee3a102 Remove unnecessary bit operation.\n7035af5fc36657447054617759854a726d31dbe0 Two small fixes for the Windows implementation (#661)\n6571279d6de21fe33caa31b2ea4170d34b15b10e fix a typo in the comment of skiplist_test.cc (#664)\n15e227896621d01ebad4c5d4b3cc82a7a9b5b30b Use override consistently in leveldb::test::ErrorEnv.\nea49b27d062c4bc998616cef7944f7f9088a327d Switch corruption_test to use InMemEnv.\nce399ac28af7023b1aff0ede4986cb6d89b3c0b5 Always copy bytes to scratch buffer when reading w/MemEnv.\n201f77d137f30ea46e789a2ad60e9119b6f990fc Inline defaults in options.\n9ce30510d482f5b2fa2965201453f0fc914f700c Deleted dangling reference to deleted atomic_pointer.h.\n7d8e41e49b8fddda66a2c5f0a6a47f1a916e8d26 leveldb: Replace AtomicPointer with std::atomic.\ndd906262fd364c08a652dfa914f9995f6b7608a9 Make InMemoryEnv more consistent with filesystem based Env's.\ncf1d1ab255de2a741695aec53d83e4f808f9e819 leveldb: Remove unused file port/win/stdint.h.\na20508dc6a18a34e05a6fc476a8d587fa9bb6608 Fix typo (#565)\n04470825ac96cab0d9d16e4ed410349d082fbf82 Add AppVeyor (Windows CI) badge to README.\ned76289b259d42d0a57c147e791e2c235ed28805 Align windows_logger with posix_logger.\n808e59ec6a160244960cda64b393968ffbdae72c Improve CI configuration.\nc69d33b0ec3dad2a8063ad66da9d51a1d6309f4e Added native support for Windows.\n75fceae7003e217e16b04433831da7528ae56881 Add O_CLOEXEC to open calls.\nfe4494804f5e3a2e25485d32aeb0eb7d2f25732e leveldb: Make WriteBatch::ApproximateSize() const.\n296de8d5b8e4e57bd1e46c981114dfbe58a8c4fa leveldb: Fix PosixWritableFile::Sync() on Apple systems.\nb70493ca8586285b49e9888e2b528f71806bdc6e Fix fdatasync() feature detection in opensource build.\naf7abf06ea061222c2c34d98e1995c5a901f374f Add back space to POSIX Logger.\n58d70545af9ec7f30821f973b604f8e2a2f9ebdb Update Travis CI configuration.\n1cb384088184be9840bd59b4040503a9fa9aee66 Clean up env_posix.cc.\na7dc502e9f11c2e5c911ba45b999676c43eaa51f Rework once initialization in env_posix.cc.\nc43565dd398b2233db8eb49ba05234d62fb42e03 C++11 cleanup for util/mutexlock.h.\n0145a94ab6bec48e596df499e8f6103e138a74ab Update .gitignore.\n73d5834eceee8efa9a8ccfec77dc096a9e8ba18a Rework threading in env_posix.cc.\n05709fb43eea34936c9f535edcb74d5e91a0b495 Remove InitOnce from the port API.\nbb88f25115d20a6d73dfb6b16cc298db2f66948b Clean up PosixWritableFile in env_posix.cc.\n7b945f200339aa47c24788d3ee9910c09c513843 Clean up posix_logger.h.\n89af27bde59fbbb3025653812b45fec10a655cb7 Remove ssize_t from code that is not POSIX-specific.\n03064cbbb2c00c3e6e41a78e8111d14a020f7d6f Simplify Limiter in env_posix.cc.\n9b44da73d9b1d839c437e3fdaaa14ea08260dce4 Clarify comments for leveldb::Env file reading methods.\n0ef2310f67f0c0b4ba3e6ad86d8138440af30d67 Remove GCC on OSX from the Travis CI matrix.\n16a2b8bb3af5b1f54676256e55a5d3f0ec02da42 Expose WriteBatch::Append in the C API.\nf7b0e1d901da26ac5ce6ad7f0a9806ce1440197e Expose WriteBatch::Append().\n6caf73ad9dae0ee91873bcb39554537b85163770 Clean up Iterator.\n6a6bdafcf10f5d4bef1ca52697c38d10c28b1a8b Corrected typo in docs: \"cache\" to \"block_cache\".\n18683981505dc374ce29211c80a9552f8f2f4571 Clean up SnapshotImpl.\ne7840de9f3db1a5eddedfecbbbc1ff72a4c2631a Fix documentation for log file growth.\nbc23e00f955eadb9e26f8ce07c1c664e7b985ff0 Update default log file size in doc.\n4de9594f6fbfd69043239a5705b5f32065f02d34 Add move constructor to Status.\nd177a0263cce4344d05188521ad53459c369b940 Replace port_posix with port_stdcxx.\n14cce848e7b8a040a8f457d5a796722a55e19597 Fix sign mismatch warnings in GCC.\n8046a51b21114d3575421bfc78b1d98b1678720a Add forgotten <limits> header to util/logging.cc.\na0008deb679480fd30e845d7e52421af72160c2c Reimplement ConsumeDecimalNumber.\n1f7dd5d5f6822f2b0b9f9e4c7d87d4535c122c0e Add tests for ConsumeDecimalNumber.\n1cc8b10b8232e174d5bd1313959825727e03faa7 Document the building process.\n09217fd0677a4fd9713c7a4d774c494a7d3c1f15 Replace NULL with nullptr in C++ files.\n6a3b915166fce75aaf9ac209114a3ad9caa34171 Remove PLATFORM_IS_LITTLE_ENDIAN from port/posix.h.\n260655b4c294991fe03bf6ab8b6d722ccfc41d32 Define LEVELDB_HAS_PORT_CONFIG_H for old compilers.\n6fa45666703add49f77652b2eadd874d49aedaf6 Rename CMake project / targets from Leveldb to leveldb.\n0db30413a4cfa8c980e675ba5cb96717d688af92 leveldb: Add more thread safety annotations.\n04f39105c5a418905da8b7657ca244d672c99d3b Take <atomic> for granted in port/atomic_pointer.h.\n74f032ff6f2465160366d865b1bb89a45dc2046b leveldb: Require C++11.\n8e75db8623703cdc25ec3cd06f82129296672489 Remove build configuration for make.\ndf9a841a4fc9a04c7713542d75f50e749fb64b7b Add export.h to CMakeLists.txt\n50fbc87e8c62a816d6afd4740e0652a13ac6dc3e Replace SIZE_MAX with std::numeric_limits.\n739c25100e46576cdcdfff2d6f43f9f7008103c7 Add CMake build support.\n0fa5a4f7b1ad9dc16b705bcad1f3ca913f187325 Extend thread safety annotations.\n8143c12f3fc483b1ba61cdce11f9c1faf6d01bea Fix includes in util/testharness.h.\naece2068d7375f987685b8b145288c5557f9ce50 Remove extern from function declarations.\nddab751002588fe58955357d68d12b062e038d0d Add tests for {Old}InfoLogFileName().\n7fd7c0072159abbca2660d91fc0667d5c17c4d16 Remove unused function ExtractValueType.\n594cc987af2e0af6417c4ac2b947ee8cdad59e5e Bypass OSMemoryBarrier() warning on Mac.\n49f35d3fc940a1e2d599d6ee3306eeb31a205e4b leveldb: Update Travis CI configuration for open source build.\n623d014a54f8cf9b74ad6aaba9181ca1e65c43a1 Expose Env::GetTempDirectory() for use in C test.\n8c8024ea33d8efc8c415597fb7fa1745002961d6 Switch HAVE_ library detection macros to 0/1.\n41172a24016bc29fc795ed504737392587f54e3d Enable thread safety annotations in open source version.\n47cb9e2a211e1d7157078ba7bab536beb29e56dc Add leveldb_options_set_max_file_size to the C API.\nb5d4a22e64c7a6615b412f464026c808b58b1d34 Fixed style guide link in CONTRIBUTING.md\n3da4d8b9899257386aeb5ffa345a6477c62ff7bf Deleted unused assignments in Reader.\n0509414f858ae7c7225e29f3659a709afb324355 leveldb::DestroyDB will now delete empty directories.\n23162ca1c6d891a9c5fe0e0fab1193cd54ed1b4f Fix typo (forgotten reference operator) in test.\n5c39524f3639e6bf6ab49215152d24273e662986 Replace SSE-optimized CRC32C in POSIX port with external library.\nca216e493f32278f50a823811ab95f64cf0f839b leveldb: Rename SNAPPY to HAVE_SNAPPY.\n25767d066ca995c055f04b78a31a6e518087e667 leveldb: Remove *_unlocked feature detection from POSIX port.\n4a7e7f50dcf661cfffe71737650b0fb18e195d18 Add LEVELDB_EXPORT macro to export public symbols.\n542590d2a8eee3838f40b01405baa6d2f6f8c700 leveldb: Include <algorithm> in util/env_test.cc.\n8ae7998aabae4f208d77afcb930dafabade1b28d Fix FD leak in POSIX Env.\nd9a9e02edf2b8187aa481416b36c49710026ab37 leveldb: Add tests for CL 170769101.\n4447f9caced2bd09585c90f1b203c3aa8f4bbc40 Remove handling for unused LRUHandle representation special case.\n2372ac574fdeb1235e70cdd86a2681d1ce05cf65 Fix file writing bug in CL 170738066.\n1c75e88055e06da2939f9f4bd294625b76792815 Fix use of uninitialized value in LRUHandle.\n7e12c00ecf1bb725e212618e7026e4d34d6cd3bb Fix issue 474: a race between the f*_unlocked() STDIO calls in env_posix.cc and concurrent application calls to fflush(NULL).\nbcd9a8ea4a8aad23a3e101a23c61615bab2a093f Use portable CRC32C from google/crc32c.\nea0a7586b8615fd39c6b8f5a8a21a1f242129c2f Remove confusing and unnecessary if.\n141e7671359d5e6c65ff70460774b53b94371df1 Simplify Table::Open() flow and remove a delete call.\n09a3c8e7417547829b94bcdaa62cdf9e896f29a9 Switched variable type from int to uint64_t in ConsumeDecimalNumber.\n2964b803b857932ff7499d7bebb61dc5514dab7c leveldb: Fix alignment code in SSE4.2-optimized CRC32C.\n02f43c0fcde39823830493503e8a3f72fed43d24 Remove dead code.\n0b402e96a76b19cd98e82402de636449a2613228 Use __APPLE__ instead of OS_MACOS. The former is compiler-provided.\n8415f00eeedd96934d3578572d3802900e61a556 leveldb: Report missing CURRENT manifest file as database corruption.\n69e2bd224b7f11e021527cb95bab18f1ee6e1b3b LevelDB: Add WriteBatch::ApproximateSize().\n471f0b84ec3420c7565511eb6e2fee8e0a0550e8 fix comment\n5b817400a0a5afe3badbb8859706a571882ababc fix comment\n7d060117fa0d5cab7cb15b0cf127533bea9ffbc7 broken db: fix assertion in leveldb::InternalKey::Encode, mark base as corrupt\n2883fcd849ca7b479d8a2f4fc929f0b6c7b9e372 set const property\ne5f0a51fa44115fb083c1e71d5ddcd07a7aba719 reduce lock's range in DeleteObsoleteFiles\ndd598676cd655dc2a2aaef47715ce18175d4a550 block_builder header file dependency fixed\nREVERT: f545dfabff4c2e9836efed094dba99a34fbc6b88 Merge #18: Use utf-8 to decode filename\nREVERT: f8e797a058b7a3993314e985dfdff8124214ba99 Use utf-8 to decode filename\nREVERT: 2fc114812a04e6b88852fa37eedc556a464241f7 Merge #14: Fixes to allow building with msvc.\nREVERT: 524b7e36a8e3bce6fcbcd1b5df09024283f325ba Merge #19: Increase maximum read-only mmap()s used from 1000 to 4096 on 64-bit systems\nREVERT: 4874cb8d3e1dc7b9026b9faf51b9282c91f8ef40 Increase maximum number of read-only mmap()s used from 1000 to 4096 on 64 bit systems.\nREVERT: 64052c76c567cff3dad32d1db0ef969d97b5882f Merge #15: Add filename to corruption errors\nREVERT: 135ed0fb4e5d6440b174c4b80c147e915dd58969 Add filename to corruption errors\nREVERT: d6eab93138884ee6c466fad5dadf2a1bfeb7cffd Fixes to allow building with msvc.\nREVERT: c521b3ac654cfbe009c575eacf7e5a6e189bb5bb Merge #11: fixup define checks. Cleans up some oopses from #5.\nREVERT: 8b1cd3753b184341e837b30383832645135d3d73 fixup define checks. Cleans up some oopses from #5.\nREVERT: 6b1508d6d58caabf76cec2688b3428c9070b7bc9 Merge #6: Fixes typo\nREVERT: fceb805426c66c8b79e2d75b83b4a35c57ad3a6e Merge #10: Clean up compile-time warnings (gcc 7.1)\nREVERT: 0ec2a343f3be66ef6e25f9b9badc0256ac0911b7 Clean up compile-time warnings (gcc 7.1)\nREVERT: d4c268a3571a66b3712ad24dfaf4b9f9671bcdf2 Merge #5: Move helper functions out of sse4.2 object\nREVERT: 8d4eb0847041a26377dc99b1c4fb5c22d4841d5e Add HasAcceleratedCRC32C to port_win.h\nREVERT: 77cfbfd250a690978a3b81d364054039467ed549 crc32: move helper functions out of port_posix_sse.cc\nREVERT: 4c1e9e01688864a32217e541102fa8d2df9a3d59 silence compiler warnings about uninitialized variables\nREVERT: 4953164851d1bc2fc653f60a98df5aa5c1dfcebd Merge #2: Prefer std::atomic over MemoryBarrier\nREVERT: 2953978ef8cd8f0babcac86a52f5c688a5ad8fa8 Fixes typo\nREVERT: f134284a1ce6e8e3ccc375a0a44300d9a87c51ab Merge #1: Merge upstream LevelDB 1.20\nREVERT: 196962ff01c39b4705d8117df5c3f8c205349950 Add AcceleratedCRC32C to port_win.h\nREVERT: ba8a445fdaa7cf3cb888a151e055330483b946f6 Prefer std::atomic over MemoryBarrier\nREVERT: 1bdf1c34c5d903e466673a15103124568d995db4 Merge upstream LevelDB v1.20\nREVERT: d31721eb0a115ac55506bb6735034bf915adc914 Merge #17: Fixed file sharing errors\nREVERT: fecd449021504dc647c1a1226d72ab0d5efb84ad Fixed file sharing error in Win32Env::GetFileSize(), Win32SequentialFile::_Init(), Win32RandomAccessFile::_Init() Fixed error checking in Win32SequentialFile::_Init()\nREVERT: 5b7510f1b79d9af1c5fe272a4587517a2579d3b7 Merge #14: Merge upstream LevelDB 1.19\nREVERT: 0d969fd5708c9fd559d63be28664e1e840beb8ca Merge #16: [LevelDB] Do no crash if filesystem can't fsync\nREVERT: c8c029b5b5793d3c9afef34afa53d10a910adf4e [LevelDB] Do no crash if filesystem can't fsync\nREVERT: a31c8aa408d5594830f7cb20ead1ef1dff51b79e Add NewAppendableFile for win32 environment\nREVERT: d40bc3fa5aaa5438d4d8f55ee83e6b3cd161ce02 Merge #13: Typo\nREVERT: ebbd772d33d8596e5765a4d1251308d732d61355 Typo\nREVERT: 1913d718ef8b07288229a75553862fcb343bf3ab Merge upstream LevelDB 1.19\nREVERT: 20ca81f08fb7fa108923a091668e447dcf5c6b9d Merge pull request #9\nREVERT: 7aa105e1a34e6e52b1e0de16d9d659a2af26fa0a leveldb: Win32WritableFile without memory mapping\nREVERT: 7d41e6f89ff04ce9e6a742932924796f69c6e23d Merge upstream LevelDB 1.18\nREVERT: 42dcc7edfc98c50038e4604fa630c626db17bf42 Merge upstream LevelDB 1.17.\nREVERT: e991315d7fe4ca84a98902578106cbffa3dcccfd Merge upstream LevelDB 1.15.\nREVERT: 02ac9f170b1c47e2c613cd47b8d7da45743af575 Merge upstream LevelDB 1.14.\nREVERT: 936b4613ea4551992e6096b1e05eeefc09a20e3b Merge upstream LevelDB 1.13.\nREVERT: be1b0ff1fcd6ad820a7fd111ac671fb51cc68001 On Mac OS X fsync does not guarantee write to disk. Use fcntl F_FULLFSYNC instead.\nREVERT: a02ddf9b14d145e88185ee209ab8b01d8826663a Added GNU/kFreeBSD kernel name (TARGET_OS)\nREVERT: 848746862caf337254a8a3e3a6bd3fa355db4fc8 CondVar::SignalAll was broken, leading to deadlocks on Windows builds. http://code.google.com/p/leveldb/issues/detail?id=149\nREVERT: f6d84d1baf74a15ee8a0f73a81c647058bf816e9 Allow files to be opened for reading multiple times\nREVERT: cb8e3f7adfaa48e09fb7a467086d69e4b6f948bd Checking whether closing succeeds\nREVERT: d5317e8eda06d8dbbf04f08866c92323ccdbb43f Print actual Win32 error that occurred on file creation failure.\nREVERT: 907f3084998fa4ce96b7abc6d9b12c7aa7b81c8c Port leveldb to MinGW32\nREVERT: 9def2bfbf18dfbc0c3c95e90c91f043a6de3c1cb Mingw support for Windows LevelDB port\nREVERT: 0a7b0748c71e64fd920eed94c26d69bc9ae77870 Pre-Vista leveldb::port::InitOnce implementation\nREVERT: 31a2b09985842c833fbbd81e17f207c377217754 Native Windows LevelDB port\nREVERT: 058a0357cd9650b214a199f81669a07d3eb4a298 Remove Snappy support\n\ngit-subtree-dir: src/leveldb\ngit-subtree-split: f8ae182c1e5176d12e816fb2217ae33a5472fdd7",
      "tree": {
        "sha": "52dde68beb13b70f6d5f2b1935c783db89087fc9",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/52dde68beb13b70f6d5f2b1935c783db89087fc9"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/66480821b36c839ab7615cb9309850015bceadb0",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/66480821b36c839ab7615cb9309850015bceadb0",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/66480821b36c839ab7615cb9309850015bceadb0",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/66480821b36c839ab7615cb9309850015bceadb0/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/4f2e6c8b881b7ccda36233332dfd1bd231389a8e"
      }
    ],
    "stats": {
      "total": 16432,
      "additions": 8569,
      "deletions": 7863
    },
    "files": [
      {
        "sha": "c24b17e8050882e621cb06eca956c38b1edc1121",
        "filename": ".appveyor.yml",
        "status": "added",
        "additions": 35,
        "deletions": 0,
        "changes": 35,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/.appveyor.yml",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/.appveyor.yml",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.appveyor.yml?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -0,0 +1,35 @@\n+# Build matrix / environment variables are explained on:\n+# https://www.appveyor.com/docs/appveyor-yml/\n+# This file can be validated on: https://ci.appveyor.com/tools/validate-yaml\n+\n+version: \"{build}\"\n+\n+environment:\n+  matrix:\n+    # AppVeyor currently has no custom job name feature.\n+    # http://help.appveyor.com/discussions/questions/1623-can-i-provide-a-friendly-name-for-jobs\n+    - JOB: Visual Studio 2017\n+      APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2017\n+      CMAKE_GENERATOR: Visual Studio 15 2017\n+\n+platform:\n+  - x86\n+  - x64\n+\n+configuration:\n+  - RelWithDebInfo\n+  - Debug\n+\n+build_script:\n+  - git submodule update --init --recursive\n+  - mkdir build\n+  - cd build\n+  - if \"%platform%\"==\"x64\" set CMAKE_GENERATOR=%CMAKE_GENERATOR% Win64\n+  - cmake --version\n+  - cmake .. -G \"%CMAKE_GENERATOR%\"\n+      -DCMAKE_CONFIGURATION_TYPES=\"%CONFIGURATION%\"\n+  - cmake --build . --config \"%CONFIGURATION%\"\n+  - cd ..\n+\n+test_script:\n+  - cd build && ctest --verbose --build-config \"%CONFIGURATION%\" && cd .."
      },
      {
        "sha": "f493f75382cc0dd27eb40571eb62f6c3b2d65aaf",
        "filename": ".clang-format",
        "status": "added",
        "additions": 18,
        "deletions": 0,
        "changes": 18,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/.clang-format",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/.clang-format",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.clang-format?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -0,0 +1,18 @@\n+# Run manually to reformat a file:\n+# clang-format -i --style=file <file>\n+# find . -iname '*.cc' -o -iname '*.h' -o -iname '*.h.in' | xargs clang-format -i --style=file\n+BasedOnStyle: Google\n+DerivePointerAlignment: false\n+\n+# Public headers are in a different location in the internal Google repository.\n+# Order them so that when imported to the authoritative repository they will be\n+# in correct alphabetical order.\n+IncludeCategories:\n+  - Regex:           '^(<|\"(benchmarks|db|helpers)/)'\n+    Priority:        1\n+  - Regex:           '^\"(leveldb)/'\n+    Priority:        2\n+  - Regex:           '^(<|\"(issues|port|table|third_party|util)/)'\n+    Priority:        3\n+  - Regex:           '.*'\n+    Priority:        4"
      },
      {
        "sha": "c4b242534fb45faa8e608f4d5234469439dd1460",
        "filename": ".gitignore",
        "status": "modified",
        "additions": 8,
        "deletions": 13,
        "changes": 21,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/.gitignore",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/.gitignore",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.gitignore?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -1,13 +1,8 @@\n-build_config.mk\n-*.a\n-*.o\n-*.dylib*\n-*.so\n-*.so.*\n-*_test\n-db_bench\n-leveldbutil\n-Release\n-Debug\n-Benchmark\n-vs2010.*\n+# Editors.\n+*.sw*\n+.vscode\n+.DS_Store\n+\n+# Build directory.\n+build/\n+out/"
      },
      {
        "sha": "42cbe64fd0ed5c25ad16c2ce9d4ca7522cebcfdd",
        "filename": ".travis.yml",
        "status": "modified",
        "additions": 75,
        "deletions": 6,
        "changes": 81,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/.travis.yml",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/.travis.yml",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.travis.yml?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -1,13 +1,82 @@\n+# Build matrix / environment variables are explained on:\n+# http://about.travis-ci.org/docs/user/build-configuration/\n+# This file can be validated on: http://lint.travis-ci.org/\n+\n language: cpp\n+dist: bionic\n+osx_image: xcode10.3\n+\n compiler:\n-- clang\n - gcc\n+- clang\n os:\n - linux\n - osx\n-sudo: false\n-before_install:\n-- echo $LANG\n-- echo $LC_ALL\n+\n+env:\n+- BUILD_TYPE=Debug\n+- BUILD_TYPE=RelWithDebInfo\n+\n+addons:\n+  apt:\n+    sources:\n+    - sourceline: 'deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-9 main'\n+      key_url: 'https://apt.llvm.org/llvm-snapshot.gpg.key'\n+    - sourceline: 'ppa:ubuntu-toolchain-r/test'\n+    packages:\n+    - clang-9\n+    - cmake\n+    - gcc-9\n+    - g++-9\n+    - libgoogle-perftools-dev\n+    - libkyotocabinet-dev\n+    - libsnappy-dev\n+    - libsqlite3-dev\n+    - ninja-build\n+  homebrew:\n+    packages:\n+    - cmake\n+    - crc32c\n+    - gcc@9\n+    - gperftools\n+    - kyoto-cabinet\n+    - llvm@9\n+    - ninja\n+    - snappy\n+    - sqlite3\n+    update: true\n+\n+install:\n+# The following Homebrew packages aren't linked by default, and need to be\n+# prepended to the path explicitly.\n+- if [ \"$TRAVIS_OS_NAME\" = \"osx\" ]; then\n+    export PATH=\"$(brew --prefix llvm)/bin:$PATH\";\n+  fi\n+# /usr/bin/gcc points to an older compiler on both Linux and macOS.\n+- if [ \"$CXX\" = \"g++\" ]; then export CXX=\"g++-9\" CC=\"gcc-9\"; fi\n+# /usr/bin/clang points to an older compiler on both Linux and macOS.\n+#\n+# Homebrew's llvm package doesn't ship a versioned clang++ binary, so the values\n+# below don't work on macOS. Fortunately, the path change above makes the\n+# default values (clang and clang++) resolve to the correct compiler on macOS.\n+- if [ \"$TRAVIS_OS_NAME\" = \"linux\" ]; then\n+    if [ \"$CXX\" = \"clang++\" ]; then export CXX=\"clang++-9\" CC=\"clang-9\"; fi;\n+  fi\n+- echo ${CC}\n+- echo ${CXX}\n+- ${CXX} --version\n+- cmake --version\n+\n+before_script:\n+- mkdir -p build && cd build\n+- cmake .. -G Ninja -DCMAKE_BUILD_TYPE=$BUILD_TYPE\n+    -DCMAKE_INSTALL_PREFIX=$HOME/.local\n+- cmake --build .\n+- cd ..\n+\n script:\n-- make -j 4 check\n+- cd build && ctest --verbose && cd ..\n+- \"if [ -f build/db_bench ] ; then build/db_bench ; fi\"\n+- \"if [ -f build/db_bench_sqlite3 ] ; then build/db_bench_sqlite3 ; fi\"\n+- \"if [ -f build/db_bench_tree_db ] ; then build/db_bench_tree_db ; fi\"\n+- cd build && cmake --build . --target install"
      },
      {
        "sha": "1cb46256c294349c7aaf8c88519fcec1d660b9af",
        "filename": "CMakeLists.txt",
        "status": "added",
        "additions": 465,
        "deletions": 0,
        "changes": 465,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/CMakeLists.txt",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/CMakeLists.txt",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/CMakeLists.txt?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -0,0 +1,465 @@\n+# Copyright 2017 The LevelDB Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+cmake_minimum_required(VERSION 3.9)\n+# Keep the version below in sync with the one in db.h\n+project(leveldb VERSION 1.22.0 LANGUAGES C CXX)\n+\n+# This project can use C11, but will gracefully decay down to C89.\n+set(CMAKE_C_STANDARD 11)\n+set(CMAKE_C_STANDARD_REQUIRED OFF)\n+set(CMAKE_C_EXTENSIONS OFF)\n+\n+# This project requires C++11.\n+set(CMAKE_CXX_STANDARD 11)\n+set(CMAKE_CXX_STANDARD_REQUIRED ON)\n+set(CMAKE_CXX_EXTENSIONS OFF)\n+\n+if (WIN32)\n+  set(LEVELDB_PLATFORM_NAME LEVELDB_PLATFORM_WINDOWS)\n+  # TODO(cmumford): Make UNICODE configurable for Windows.\n+  add_definitions(-D_UNICODE -DUNICODE)\n+else (WIN32)\n+  set(LEVELDB_PLATFORM_NAME LEVELDB_PLATFORM_POSIX)\n+endif (WIN32)\n+\n+option(LEVELDB_BUILD_TESTS \"Build LevelDB's unit tests\" ON)\n+option(LEVELDB_BUILD_BENCHMARKS \"Build LevelDB's benchmarks\" ON)\n+option(LEVELDB_INSTALL \"Install LevelDB's header and library\" ON)\n+\n+include(TestBigEndian)\n+test_big_endian(LEVELDB_IS_BIG_ENDIAN)\n+\n+include(CheckIncludeFile)\n+check_include_file(\"unistd.h\" HAVE_UNISTD_H)\n+\n+include(CheckLibraryExists)\n+check_library_exists(crc32c crc32c_value \"\" HAVE_CRC32C)\n+check_library_exists(snappy snappy_compress \"\" HAVE_SNAPPY)\n+check_library_exists(tcmalloc malloc \"\" HAVE_TCMALLOC)\n+\n+include(CheckCXXSymbolExists)\n+# Using check_cxx_symbol_exists() instead of check_c_symbol_exists() because\n+# we're including the header from C++, and feature detection should use the same\n+# compiler language that the project will use later. Principles aside, some\n+# versions of do not expose fdatasync() in <unistd.h> in standard C mode\n+# (-std=c11), but do expose the function in standard C++ mode (-std=c++11).\n+check_cxx_symbol_exists(fdatasync \"unistd.h\" HAVE_FDATASYNC)\n+check_cxx_symbol_exists(F_FULLFSYNC \"fcntl.h\" HAVE_FULLFSYNC)\n+check_cxx_symbol_exists(O_CLOEXEC \"fcntl.h\" HAVE_O_CLOEXEC)\n+\n+if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  # Disable C++ exceptions.\n+  string(REGEX REPLACE \"/EH[a-z]+\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /EHs-c-\")\n+  add_definitions(-D_HAS_EXCEPTIONS=0)\n+\n+  # Disable RTTI.\n+  string(REGEX REPLACE \"/GR\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /GR-\")\n+else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  # Enable strict prototype warnings for C code in clang and gcc.\n+  if(NOT CMAKE_C_FLAGS MATCHES \"-Wstrict-prototypes\")\n+    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -Wstrict-prototypes\")\n+  endif(NOT CMAKE_C_FLAGS MATCHES \"-Wstrict-prototypes\")\n+\n+  # Disable C++ exceptions.\n+  string(REGEX REPLACE \"-fexceptions\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fno-exceptions\")\n+\n+  # Disable RTTI.\n+  string(REGEX REPLACE \"-frtti\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fno-rtti\")\n+endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+\n+# Test whether -Wthread-safety is available. See\n+# https://clang.llvm.org/docs/ThreadSafetyAnalysis.html\n+include(CheckCXXCompilerFlag)\n+check_cxx_compiler_flag(-Wthread-safety HAVE_CLANG_THREAD_SAFETY)\n+\n+include(CheckCXXSourceCompiles)\n+\n+# Test whether C++17 __has_include is available.\n+check_cxx_source_compiles(\"\n+#if defined(__has_include) &&  __has_include(<string>)\n+#include <string>\n+#endif\n+int main() { std::string str; return 0; }\n+\" HAVE_CXX17_HAS_INCLUDE)\n+\n+set(LEVELDB_PUBLIC_INCLUDE_DIR \"include/leveldb\")\n+set(LEVELDB_PORT_CONFIG_DIR \"include/port\")\n+\n+configure_file(\n+  \"port/port_config.h.in\"\n+  \"${PROJECT_BINARY_DIR}/${LEVELDB_PORT_CONFIG_DIR}/port_config.h\"\n+)\n+\n+include_directories(\n+  \"${PROJECT_BINARY_DIR}/include\"\n+  \".\"\n+)\n+\n+if(BUILD_SHARED_LIBS)\n+  # Only export LEVELDB_EXPORT symbols from the shared library.\n+  add_compile_options(-fvisibility=hidden)\n+endif(BUILD_SHARED_LIBS)\n+\n+# Must be included before CMAKE_INSTALL_INCLUDEDIR is used.\n+include(GNUInstallDirs)\n+\n+add_library(leveldb \"\")\n+target_sources(leveldb\n+  PRIVATE\n+    \"${PROJECT_BINARY_DIR}/${LEVELDB_PORT_CONFIG_DIR}/port_config.h\"\n+    \"db/builder.cc\"\n+    \"db/builder.h\"\n+    \"db/c.cc\"\n+    \"db/db_impl.cc\"\n+    \"db/db_impl.h\"\n+    \"db/db_iter.cc\"\n+    \"db/db_iter.h\"\n+    \"db/dbformat.cc\"\n+    \"db/dbformat.h\"\n+    \"db/dumpfile.cc\"\n+    \"db/filename.cc\"\n+    \"db/filename.h\"\n+    \"db/log_format.h\"\n+    \"db/log_reader.cc\"\n+    \"db/log_reader.h\"\n+    \"db/log_writer.cc\"\n+    \"db/log_writer.h\"\n+    \"db/memtable.cc\"\n+    \"db/memtable.h\"\n+    \"db/repair.cc\"\n+    \"db/skiplist.h\"\n+    \"db/snapshot.h\"\n+    \"db/table_cache.cc\"\n+    \"db/table_cache.h\"\n+    \"db/version_edit.cc\"\n+    \"db/version_edit.h\"\n+    \"db/version_set.cc\"\n+    \"db/version_set.h\"\n+    \"db/write_batch_internal.h\"\n+    \"db/write_batch.cc\"\n+    \"port/port_stdcxx.h\"\n+    \"port/port.h\"\n+    \"port/thread_annotations.h\"\n+    \"table/block_builder.cc\"\n+    \"table/block_builder.h\"\n+    \"table/block.cc\"\n+    \"table/block.h\"\n+    \"table/filter_block.cc\"\n+    \"table/filter_block.h\"\n+    \"table/format.cc\"\n+    \"table/format.h\"\n+    \"table/iterator_wrapper.h\"\n+    \"table/iterator.cc\"\n+    \"table/merger.cc\"\n+    \"table/merger.h\"\n+    \"table/table_builder.cc\"\n+    \"table/table.cc\"\n+    \"table/two_level_iterator.cc\"\n+    \"table/two_level_iterator.h\"\n+    \"util/arena.cc\"\n+    \"util/arena.h\"\n+    \"util/bloom.cc\"\n+    \"util/cache.cc\"\n+    \"util/coding.cc\"\n+    \"util/coding.h\"\n+    \"util/comparator.cc\"\n+    \"util/crc32c.cc\"\n+    \"util/crc32c.h\"\n+    \"util/env.cc\"\n+    \"util/filter_policy.cc\"\n+    \"util/hash.cc\"\n+    \"util/hash.h\"\n+    \"util/logging.cc\"\n+    \"util/logging.h\"\n+    \"util/mutexlock.h\"\n+    \"util/no_destructor.h\"\n+    \"util/options.cc\"\n+    \"util/random.h\"\n+    \"util/status.cc\"\n+\n+  # Only CMake 3.3+ supports PUBLIC sources in targets exported by \"install\".\n+  $<$<VERSION_GREATER:CMAKE_VERSION,3.2>:PUBLIC>\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/c.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/cache.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/comparator.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/db.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/dumpfile.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/env.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/export.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/filter_policy.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/iterator.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/options.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/slice.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/status.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/table_builder.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/table.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/write_batch.h\"\n+)\n+\n+if (WIN32)\n+  target_sources(leveldb\n+    PRIVATE\n+      \"util/env_windows.cc\"\n+      \"util/windows_logger.h\"\n+  )\n+else (WIN32)\n+  target_sources(leveldb\n+    PRIVATE\n+      \"util/env_posix.cc\"\n+      \"util/posix_logger.h\"\n+  )\n+endif (WIN32)\n+\n+# MemEnv is not part of the interface and could be pulled to a separate library.\n+target_sources(leveldb\n+  PRIVATE\n+    \"helpers/memenv/memenv.cc\"\n+    \"helpers/memenv/memenv.h\"\n+)\n+\n+target_include_directories(leveldb\n+  PUBLIC\n+    $<BUILD_INTERFACE:${PROJECT_SOURCE_DIR}/include>\n+    $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>\n+)\n+\n+set_target_properties(leveldb\n+  PROPERTIES VERSION ${PROJECT_VERSION} SOVERSION ${PROJECT_VERSION_MAJOR})\n+\n+target_compile_definitions(leveldb\n+  PRIVATE\n+    # Used by include/export.h when building shared libraries.\n+    LEVELDB_COMPILE_LIBRARY\n+    # Used by port/port.h.\n+    ${LEVELDB_PLATFORM_NAME}=1\n+)\n+if (NOT HAVE_CXX17_HAS_INCLUDE)\n+  target_compile_definitions(leveldb\n+    PRIVATE\n+      LEVELDB_HAS_PORT_CONFIG_H=1\n+  )\n+endif(NOT HAVE_CXX17_HAS_INCLUDE)\n+\n+if(BUILD_SHARED_LIBS)\n+  target_compile_definitions(leveldb\n+    PUBLIC\n+      # Used by include/export.h.\n+      LEVELDB_SHARED_LIBRARY\n+  )\n+endif(BUILD_SHARED_LIBS)\n+\n+if(HAVE_CLANG_THREAD_SAFETY)\n+  target_compile_options(leveldb\n+    PUBLIC\n+      -Werror -Wthread-safety)\n+endif(HAVE_CLANG_THREAD_SAFETY)\n+\n+if(HAVE_CRC32C)\n+  target_link_libraries(leveldb crc32c)\n+endif(HAVE_CRC32C)\n+if(HAVE_SNAPPY)\n+  target_link_libraries(leveldb snappy)\n+endif(HAVE_SNAPPY)\n+if(HAVE_TCMALLOC)\n+  target_link_libraries(leveldb tcmalloc)\n+endif(HAVE_TCMALLOC)\n+\n+# Needed by port_stdcxx.h\n+find_package(Threads REQUIRED)\n+target_link_libraries(leveldb Threads::Threads)\n+\n+add_executable(leveldbutil\n+  \"db/leveldbutil.cc\"\n+)\n+target_link_libraries(leveldbutil leveldb)\n+\n+if(LEVELDB_BUILD_TESTS)\n+  enable_testing()\n+\n+  function(leveldb_test test_file)\n+    get_filename_component(test_target_name \"${test_file}\" NAME_WE)\n+\n+    add_executable(\"${test_target_name}\" \"\")\n+    target_sources(\"${test_target_name}\"\n+      PRIVATE\n+        \"${PROJECT_BINARY_DIR}/${LEVELDB_PORT_CONFIG_DIR}/port_config.h\"\n+        \"util/testharness.cc\"\n+        \"util/testharness.h\"\n+        \"util/testutil.cc\"\n+        \"util/testutil.h\"\n+\n+        \"${test_file}\"\n+    )\n+    target_link_libraries(\"${test_target_name}\" leveldb)\n+    target_compile_definitions(\"${test_target_name}\"\n+      PRIVATE\n+        ${LEVELDB_PLATFORM_NAME}=1\n+    )\n+    if (NOT HAVE_CXX17_HAS_INCLUDE)\n+      target_compile_definitions(\"${test_target_name}\"\n+        PRIVATE\n+          LEVELDB_HAS_PORT_CONFIG_H=1\n+      )\n+    endif(NOT HAVE_CXX17_HAS_INCLUDE)\n+\n+    add_test(NAME \"${test_target_name}\" COMMAND \"${test_target_name}\")\n+  endfunction(leveldb_test)\n+\n+  leveldb_test(\"db/c_test.c\")\n+  leveldb_test(\"db/fault_injection_test.cc\")\n+\n+  leveldb_test(\"issues/issue178_test.cc\")\n+  leveldb_test(\"issues/issue200_test.cc\")\n+  leveldb_test(\"issues/issue320_test.cc\")\n+\n+  leveldb_test(\"util/env_test.cc\")\n+  leveldb_test(\"util/status_test.cc\")\n+  leveldb_test(\"util/no_destructor_test.cc\")\n+\n+  if(NOT BUILD_SHARED_LIBS)\n+    leveldb_test(\"db/autocompact_test.cc\")\n+    leveldb_test(\"db/corruption_test.cc\")\n+    leveldb_test(\"db/db_test.cc\")\n+    leveldb_test(\"db/dbformat_test.cc\")\n+    leveldb_test(\"db/filename_test.cc\")\n+    leveldb_test(\"db/log_test.cc\")\n+    leveldb_test(\"db/recovery_test.cc\")\n+    leveldb_test(\"db/skiplist_test.cc\")\n+    leveldb_test(\"db/version_edit_test.cc\")\n+    leveldb_test(\"db/version_set_test.cc\")\n+    leveldb_test(\"db/write_batch_test.cc\")\n+\n+    leveldb_test(\"helpers/memenv/memenv_test.cc\")\n+\n+    leveldb_test(\"table/filter_block_test.cc\")\n+    leveldb_test(\"table/table_test.cc\")\n+\n+    leveldb_test(\"util/arena_test.cc\")\n+    leveldb_test(\"util/bloom_test.cc\")\n+    leveldb_test(\"util/cache_test.cc\")\n+    leveldb_test(\"util/coding_test.cc\")\n+    leveldb_test(\"util/crc32c_test.cc\")\n+    leveldb_test(\"util/hash_test.cc\")\n+    leveldb_test(\"util/logging_test.cc\")\n+\n+    # TODO(costan): This test also uses\n+    #               \"util/env_{posix|windows}_test_helper.h\"\n+    if (WIN32)\n+      leveldb_test(\"util/env_windows_test.cc\")\n+    else (WIN32)\n+      leveldb_test(\"util/env_posix_test.cc\")\n+    endif (WIN32)\n+  endif(NOT BUILD_SHARED_LIBS)\n+endif(LEVELDB_BUILD_TESTS)\n+\n+if(LEVELDB_BUILD_BENCHMARKS)\n+  function(leveldb_benchmark bench_file)\n+    get_filename_component(bench_target_name \"${bench_file}\" NAME_WE)\n+\n+    add_executable(\"${bench_target_name}\" \"\")\n+    target_sources(\"${bench_target_name}\"\n+      PRIVATE\n+        \"${PROJECT_BINARY_DIR}/${LEVELDB_PORT_CONFIG_DIR}/port_config.h\"\n+        \"util/histogram.cc\"\n+        \"util/histogram.h\"\n+        \"util/testharness.cc\"\n+        \"util/testharness.h\"\n+        \"util/testutil.cc\"\n+        \"util/testutil.h\"\n+\n+        \"${bench_file}\"\n+    )\n+    target_link_libraries(\"${bench_target_name}\" leveldb)\n+    target_compile_definitions(\"${bench_target_name}\"\n+      PRIVATE\n+        ${LEVELDB_PLATFORM_NAME}=1\n+    )\n+    if (NOT HAVE_CXX17_HAS_INCLUDE)\n+      target_compile_definitions(\"${bench_target_name}\"\n+        PRIVATE\n+          LEVELDB_HAS_PORT_CONFIG_H=1\n+      )\n+    endif(NOT HAVE_CXX17_HAS_INCLUDE)\n+  endfunction(leveldb_benchmark)\n+\n+  if(NOT BUILD_SHARED_LIBS)\n+    leveldb_benchmark(\"benchmarks/db_bench.cc\")\n+  endif(NOT BUILD_SHARED_LIBS)\n+\n+  check_library_exists(sqlite3 sqlite3_open \"\" HAVE_SQLITE3)\n+  if(HAVE_SQLITE3)\n+    leveldb_benchmark(\"benchmarks/db_bench_sqlite3.cc\")\n+    target_link_libraries(db_bench_sqlite3 sqlite3)\n+  endif(HAVE_SQLITE3)\n+\n+  # check_library_exists is insufficient here because the library names have\n+  # different manglings when compiled with clang or gcc, at least when installed\n+  # with Homebrew on Mac.\n+  set(OLD_CMAKE_REQURED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES})\n+  list(APPEND CMAKE_REQUIRED_LIBRARIES kyotocabinet)\n+  check_cxx_source_compiles(\"\n+#include <kcpolydb.h>\n+\n+int main() {\n+  kyotocabinet::TreeDB* db = new kyotocabinet::TreeDB();\n+  delete db;\n+  return 0;\n+}\n+  \"  HAVE_KYOTOCABINET)\n+  set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQURED_LIBRARIES})\n+  if(HAVE_KYOTOCABINET)\n+    leveldb_benchmark(\"benchmarks/db_bench_tree_db.cc\")\n+    target_link_libraries(db_bench_tree_db kyotocabinet)\n+  endif(HAVE_KYOTOCABINET)\n+endif(LEVELDB_BUILD_BENCHMARKS)\n+\n+if(LEVELDB_INSTALL)\n+  install(TARGETS leveldb\n+    EXPORT leveldbTargets\n+    RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR}\n+    LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n+    ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}\n+  )\n+  install(\n+    FILES\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/c.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/cache.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/comparator.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/db.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/dumpfile.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/env.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/export.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/filter_policy.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/iterator.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/options.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/slice.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/status.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/table_builder.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/table.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/write_batch.h\"\n+    DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/leveldb\n+  )\n+\n+  include(CMakePackageConfigHelpers)\n+  write_basic_package_version_file(\n+      \"${PROJECT_BINARY_DIR}/leveldbConfigVersion.cmake\"\n+      COMPATIBILITY SameMajorVersion\n+  )\n+  install(\n+    EXPORT leveldbTargets\n+    NAMESPACE leveldb::\n+    DESTINATION \"${CMAKE_INSTALL_LIBDIR}/cmake/leveldb\"\n+  )\n+  install(\n+    FILES\n+      \"cmake/leveldbConfig.cmake\"\n+      \"${PROJECT_BINARY_DIR}/leveldbConfigVersion.cmake\"\n+    DESTINATION \"${CMAKE_INSTALL_LIBDIR}/cmake/leveldb\"\n+  )\n+endif(LEVELDB_INSTALL)"
      },
      {
        "sha": "a74572a596396761830c62b38ebddcb836298e03",
        "filename": "CONTRIBUTING.md",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/CONTRIBUTING.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/CONTRIBUTING.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/CONTRIBUTING.md?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -31,6 +31,6 @@ the CLA.\n \n ## Writing Code ##\n \n-If your contribution contains code, please make sure that it follows \n-[the style guide](http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml).\n+If your contribution contains code, please make sure that it follows\n+[the style guide](http://google.github.io/styleguide/cppguide.html).\n Otherwise we will have to ask you to make changes, and that's no fun for anyone."
      },
      {
        "sha": "f7cc7d736c4f20d6cab6e760d43b76e880b80e95",
        "filename": "Makefile",
        "status": "removed",
        "additions": 0,
        "deletions": 424,
        "changes": 424,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/Makefile",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/Makefile",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/Makefile?ref=4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "patch": "@@ -1,424 +0,0 @@\n-# Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-# Use of this source code is governed by a BSD-style license that can be\n-# found in the LICENSE file. See the AUTHORS file for names of contributors.\n-\n-#-----------------------------------------------\n-# Uncomment exactly one of the lines labelled (A), (B), and (C) below\n-# to switch between compilation modes.\n-\n-# (A) Production use (optimized mode)\n-OPT ?= -O2 -DNDEBUG\n-# (B) Debug mode, w/ full line-level debugging symbols\n-# OPT ?= -g2\n-# (C) Profiling mode: opt, but w/debugging symbols\n-# OPT ?= -O2 -g2 -DNDEBUG\n-#-----------------------------------------------\n-\n-# detect what platform we're building on\n-$(shell CC=\"$(CC)\" CXX=\"$(CXX)\" TARGET_OS=\"$(TARGET_OS)\" \\\n-    ./build_detect_platform build_config.mk ./)\n-# this file is generated by the previous line to set build flags and sources\n-include build_config.mk\n-\n-TESTS = \\\n-\tdb/autocompact_test \\\n-\tdb/c_test \\\n-\tdb/corruption_test \\\n-\tdb/db_test \\\n-\tdb/dbformat_test \\\n-\tdb/fault_injection_test \\\n-\tdb/filename_test \\\n-\tdb/log_test \\\n-\tdb/recovery_test \\\n-\tdb/skiplist_test \\\n-\tdb/version_edit_test \\\n-\tdb/version_set_test \\\n-\tdb/write_batch_test \\\n-\thelpers/memenv/memenv_test \\\n-\tissues/issue178_test \\\n-\tissues/issue200_test \\\n-\ttable/filter_block_test \\\n-\ttable/table_test \\\n-\tutil/arena_test \\\n-\tutil/bloom_test \\\n-\tutil/cache_test \\\n-\tutil/coding_test \\\n-\tutil/crc32c_test \\\n-\tutil/env_posix_test \\\n-\tutil/env_test \\\n-\tutil/hash_test\n-\n-UTILS = \\\n-\tdb/db_bench \\\n-\tdb/leveldbutil\n-\n-# Put the object files in a subdirectory, but the application at the top of the object dir.\n-PROGNAMES := $(notdir $(TESTS) $(UTILS))\n-\n-# On Linux may need libkyotocabinet-dev for dependency.\n-BENCHMARKS = \\\n-\tdoc/bench/db_bench_sqlite3 \\\n-\tdoc/bench/db_bench_tree_db\n-\n-CFLAGS += -I. -I./include $(PLATFORM_CCFLAGS) $(OPT)\n-CXXFLAGS += -I. -I./include $(PLATFORM_CXXFLAGS) $(OPT)\n-\n-LDFLAGS += $(PLATFORM_LDFLAGS)\n-LIBS += $(PLATFORM_LIBS)\n-\n-SIMULATOR_OUTDIR=out-ios-x86\n-DEVICE_OUTDIR=out-ios-arm\n-\n-ifeq ($(PLATFORM), IOS)\n-# Note: iOS should probably be using libtool, not ar.\n-AR=xcrun ar\n-SIMULATORSDK=$(shell xcrun -sdk iphonesimulator --show-sdk-path)\n-DEVICESDK=$(shell xcrun -sdk iphoneos --show-sdk-path)\n-DEVICE_CFLAGS = -isysroot \"$(DEVICESDK)\" -arch armv6 -arch armv7 -arch armv7s -arch arm64\n-SIMULATOR_CFLAGS = -isysroot \"$(SIMULATORSDK)\" -arch i686 -arch x86_64\n-STATIC_OUTDIR=out-ios-universal\n-else\n-STATIC_OUTDIR=out-static\n-SHARED_OUTDIR=out-shared\n-STATIC_PROGRAMS := $(addprefix $(STATIC_OUTDIR)/, $(PROGNAMES))\n-SHARED_PROGRAMS := $(addprefix $(SHARED_OUTDIR)/, db_bench)\n-endif\n-\n-STATIC_LIBOBJECTS := $(addprefix $(STATIC_OUTDIR)/, $(SOURCES:.cc=.o))\n-STATIC_MEMENVOBJECTS := $(addprefix $(STATIC_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n-\n-DEVICE_LIBOBJECTS := $(addprefix $(DEVICE_OUTDIR)/, $(SOURCES:.cc=.o))\n-DEVICE_MEMENVOBJECTS := $(addprefix $(DEVICE_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n-\n-SIMULATOR_LIBOBJECTS := $(addprefix $(SIMULATOR_OUTDIR)/, $(SOURCES:.cc=.o))\n-SIMULATOR_MEMENVOBJECTS := $(addprefix $(SIMULATOR_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n-\n-SHARED_LIBOBJECTS := $(addprefix $(SHARED_OUTDIR)/, $(SOURCES:.cc=.o))\n-SHARED_MEMENVOBJECTS := $(addprefix $(SHARED_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n-\n-TESTUTIL := $(STATIC_OUTDIR)/util/testutil.o\n-TESTHARNESS := $(STATIC_OUTDIR)/util/testharness.o $(TESTUTIL)\n-\n-STATIC_TESTOBJS := $(addprefix $(STATIC_OUTDIR)/, $(addsuffix .o, $(TESTS)))\n-STATIC_UTILOBJS := $(addprefix $(STATIC_OUTDIR)/, $(addsuffix .o, $(UTILS)))\n-STATIC_ALLOBJS := $(STATIC_LIBOBJECTS) $(STATIC_MEMENVOBJECTS) $(STATIC_TESTOBJS) $(STATIC_UTILOBJS) $(TESTHARNESS)\n-DEVICE_ALLOBJS := $(DEVICE_LIBOBJECTS) $(DEVICE_MEMENVOBJECTS)\n-SIMULATOR_ALLOBJS := $(SIMULATOR_LIBOBJECTS) $(SIMULATOR_MEMENVOBJECTS)\n-\n-default: all\n-\n-# Should we build shared libraries?\n-ifneq ($(PLATFORM_SHARED_EXT),)\n-\n-# Many leveldb test apps use non-exported API's. Only build a subset for testing.\n-SHARED_ALLOBJS := $(SHARED_LIBOBJECTS) $(SHARED_MEMENVOBJECTS) $(TESTHARNESS)\n-\n-ifneq ($(PLATFORM_SHARED_VERSIONED),true)\n-SHARED_LIB1 = libleveldb.$(PLATFORM_SHARED_EXT)\n-SHARED_LIB2 = $(SHARED_LIB1)\n-SHARED_LIB3 = $(SHARED_LIB1)\n-SHARED_LIBS = $(SHARED_LIB1)\n-SHARED_MEMENVLIB = $(SHARED_OUTDIR)/libmemenv.a\n-else\n-# Update db.h if you change these.\n-SHARED_VERSION_MAJOR = 1\n-SHARED_VERSION_MINOR = 20\n-SHARED_LIB1 = libleveldb.$(PLATFORM_SHARED_EXT)\n-SHARED_LIB2 = $(SHARED_LIB1).$(SHARED_VERSION_MAJOR)\n-SHARED_LIB3 = $(SHARED_LIB1).$(SHARED_VERSION_MAJOR).$(SHARED_VERSION_MINOR)\n-SHARED_LIBS = $(SHARED_OUTDIR)/$(SHARED_LIB1) $(SHARED_OUTDIR)/$(SHARED_LIB2) $(SHARED_OUTDIR)/$(SHARED_LIB3)\n-$(SHARED_OUTDIR)/$(SHARED_LIB1): $(SHARED_OUTDIR)/$(SHARED_LIB3)\n-\tln -fs $(SHARED_LIB3) $(SHARED_OUTDIR)/$(SHARED_LIB1)\n-$(SHARED_OUTDIR)/$(SHARED_LIB2): $(SHARED_OUTDIR)/$(SHARED_LIB3)\n-\tln -fs $(SHARED_LIB3) $(SHARED_OUTDIR)/$(SHARED_LIB2)\n-SHARED_MEMENVLIB = $(SHARED_OUTDIR)/libmemenv.a\n-endif\n-\n-$(SHARED_OUTDIR)/$(SHARED_LIB3): $(SHARED_LIBOBJECTS)\n-\t$(CXX) $(LDFLAGS) $(PLATFORM_SHARED_LDFLAGS)$(SHARED_LIB2) $(SHARED_LIBOBJECTS) -o $(SHARED_OUTDIR)/$(SHARED_LIB3) $(LIBS)\n-\n-endif  # PLATFORM_SHARED_EXT\n-\n-all: $(SHARED_LIBS) $(SHARED_PROGRAMS) $(STATIC_OUTDIR)/libleveldb.a $(STATIC_OUTDIR)/libmemenv.a $(STATIC_PROGRAMS)\n-\n-check: $(STATIC_PROGRAMS)\n-\tfor t in $(notdir $(TESTS)); do echo \"***** Running $$t\"; $(STATIC_OUTDIR)/$$t || exit 1; done\n-\n-clean:\n-\t-rm -rf out-static out-shared out-ios-x86 out-ios-arm out-ios-universal\n-\t-rm -f build_config.mk\n-\t-rm -rf ios-x86 ios-arm\n-\n-$(STATIC_OUTDIR):\n-\tmkdir $@\n-\n-$(STATIC_OUTDIR)/db: | $(STATIC_OUTDIR)\n-\tmkdir $@\n-\n-$(STATIC_OUTDIR)/helpers/memenv: | $(STATIC_OUTDIR)\n-\tmkdir -p $@\n-\n-$(STATIC_OUTDIR)/port: | $(STATIC_OUTDIR)\n-\tmkdir $@\n-\n-$(STATIC_OUTDIR)/table: | $(STATIC_OUTDIR)\n-\tmkdir $@\n-\n-$(STATIC_OUTDIR)/util: | $(STATIC_OUTDIR)\n-\tmkdir $@\n-\n-.PHONY: STATIC_OBJDIRS\n-STATIC_OBJDIRS: \\\n-\t$(STATIC_OUTDIR)/db \\\n-\t$(STATIC_OUTDIR)/port \\\n-\t$(STATIC_OUTDIR)/table \\\n-\t$(STATIC_OUTDIR)/util \\\n-\t$(STATIC_OUTDIR)/helpers/memenv\n-\n-$(SHARED_OUTDIR):\n-\tmkdir $@\n-\n-$(SHARED_OUTDIR)/db: | $(SHARED_OUTDIR)\n-\tmkdir $@\n-\n-$(SHARED_OUTDIR)/helpers/memenv: | $(SHARED_OUTDIR)\n-\tmkdir -p $@\n-\n-$(SHARED_OUTDIR)/port: | $(SHARED_OUTDIR)\n-\tmkdir $@\n-\n-$(SHARED_OUTDIR)/table: | $(SHARED_OUTDIR)\n-\tmkdir $@\n-\n-$(SHARED_OUTDIR)/util: | $(SHARED_OUTDIR)\n-\tmkdir $@\n-\n-.PHONY: SHARED_OBJDIRS\n-SHARED_OBJDIRS: \\\n-\t$(SHARED_OUTDIR)/db \\\n-\t$(SHARED_OUTDIR)/port \\\n-\t$(SHARED_OUTDIR)/table \\\n-\t$(SHARED_OUTDIR)/util \\\n-\t$(SHARED_OUTDIR)/helpers/memenv\n-\n-$(DEVICE_OUTDIR):\n-\tmkdir $@\n-\n-$(DEVICE_OUTDIR)/db: | $(DEVICE_OUTDIR)\n-\tmkdir $@\n-\n-$(DEVICE_OUTDIR)/helpers/memenv: | $(DEVICE_OUTDIR)\n-\tmkdir -p $@\n-\n-$(DEVICE_OUTDIR)/port: | $(DEVICE_OUTDIR)\n-\tmkdir $@\n-\n-$(DEVICE_OUTDIR)/table: | $(DEVICE_OUTDIR)\n-\tmkdir $@\n-\n-$(DEVICE_OUTDIR)/util: | $(DEVICE_OUTDIR)\n-\tmkdir $@\n-\n-.PHONY: DEVICE_OBJDIRS\n-DEVICE_OBJDIRS: \\\n-\t$(DEVICE_OUTDIR)/db \\\n-\t$(DEVICE_OUTDIR)/port \\\n-\t$(DEVICE_OUTDIR)/table \\\n-\t$(DEVICE_OUTDIR)/util \\\n-\t$(DEVICE_OUTDIR)/helpers/memenv\n-\n-$(SIMULATOR_OUTDIR):\n-\tmkdir $@\n-\n-$(SIMULATOR_OUTDIR)/db: | $(SIMULATOR_OUTDIR)\n-\tmkdir $@\n-\n-$(SIMULATOR_OUTDIR)/helpers/memenv: | $(SIMULATOR_OUTDIR)\n-\tmkdir -p $@\n-\n-$(SIMULATOR_OUTDIR)/port: | $(SIMULATOR_OUTDIR)\n-\tmkdir $@\n-\n-$(SIMULATOR_OUTDIR)/table: | $(SIMULATOR_OUTDIR)\n-\tmkdir $@\n-\n-$(SIMULATOR_OUTDIR)/util: | $(SIMULATOR_OUTDIR)\n-\tmkdir $@\n-\n-.PHONY: SIMULATOR_OBJDIRS\n-SIMULATOR_OBJDIRS: \\\n-\t$(SIMULATOR_OUTDIR)/db \\\n-\t$(SIMULATOR_OUTDIR)/port \\\n-\t$(SIMULATOR_OUTDIR)/table \\\n-\t$(SIMULATOR_OUTDIR)/util \\\n-\t$(SIMULATOR_OUTDIR)/helpers/memenv\n-\n-$(STATIC_ALLOBJS): | STATIC_OBJDIRS\n-$(DEVICE_ALLOBJS): | DEVICE_OBJDIRS\n-$(SIMULATOR_ALLOBJS): | SIMULATOR_OBJDIRS\n-$(SHARED_ALLOBJS): | SHARED_OBJDIRS\n-\n-ifeq ($(PLATFORM), IOS)\n-$(DEVICE_OUTDIR)/libleveldb.a: $(DEVICE_LIBOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(DEVICE_LIBOBJECTS)\n-\n-$(SIMULATOR_OUTDIR)/libleveldb.a: $(SIMULATOR_LIBOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(SIMULATOR_LIBOBJECTS)\n-\n-$(DEVICE_OUTDIR)/libmemenv.a: $(DEVICE_MEMENVOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(DEVICE_MEMENVOBJECTS)\n-\n-$(SIMULATOR_OUTDIR)/libmemenv.a: $(SIMULATOR_MEMENVOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(SIMULATOR_MEMENVOBJECTS)\n-\n-# For iOS, create universal object libraries to be used on both the simulator and\n-# a device.\n-$(STATIC_OUTDIR)/libleveldb.a: $(STATIC_OUTDIR) $(DEVICE_OUTDIR)/libleveldb.a $(SIMULATOR_OUTDIR)/libleveldb.a\n-\tlipo -create $(DEVICE_OUTDIR)/libleveldb.a $(SIMULATOR_OUTDIR)/libleveldb.a -output $@\n-\n-$(STATIC_OUTDIR)/libmemenv.a: $(STATIC_OUTDIR) $(DEVICE_OUTDIR)/libmemenv.a $(SIMULATOR_OUTDIR)/libmemenv.a\n-\tlipo -create $(DEVICE_OUTDIR)/libmemenv.a $(SIMULATOR_OUTDIR)/libmemenv.a -output $@\n-else\n-$(STATIC_OUTDIR)/libleveldb.a:$(STATIC_LIBOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(STATIC_LIBOBJECTS)\n-\n-$(STATIC_OUTDIR)/libmemenv.a:$(STATIC_MEMENVOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(STATIC_MEMENVOBJECTS)\n-endif\n-\n-$(SHARED_MEMENVLIB):$(SHARED_MEMENVOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(SHARED_MEMENVOBJECTS)\n-\n-$(STATIC_OUTDIR)/db_bench:db/db_bench.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/db_bench.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/db_bench_sqlite3:doc/bench/db_bench_sqlite3.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) doc/bench/db_bench_sqlite3.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ -lsqlite3 $(LIBS)\n-\n-$(STATIC_OUTDIR)/db_bench_tree_db:doc/bench/db_bench_tree_db.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) doc/bench/db_bench_tree_db.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ -lkyotocabinet $(LIBS)\n-\n-$(STATIC_OUTDIR)/leveldbutil:db/leveldbutil.cc $(STATIC_LIBOBJECTS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/leveldbutil.cc $(STATIC_LIBOBJECTS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/arena_test:util/arena_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/arena_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/autocompact_test:db/autocompact_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/autocompact_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/bloom_test:util/bloom_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/bloom_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/c_test:$(STATIC_OUTDIR)/db/c_test.o $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(STATIC_OUTDIR)/db/c_test.o $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/cache_test:util/cache_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/cache_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/coding_test:util/coding_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/coding_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/corruption_test:db/corruption_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/corruption_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/crc32c_test:util/crc32c_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/crc32c_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/db_test:db/db_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/db_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/dbformat_test:db/dbformat_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/dbformat_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/env_posix_test:util/env_posix_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/env_posix_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/env_test:util/env_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/env_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/fault_injection_test:db/fault_injection_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/fault_injection_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/filename_test:db/filename_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/filename_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/filter_block_test:table/filter_block_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) table/filter_block_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/hash_test:util/hash_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/hash_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/issue178_test:issues/issue178_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) issues/issue178_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/issue200_test:issues/issue200_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) issues/issue200_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/log_test:db/log_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/log_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/recovery_test:db/recovery_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/recovery_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/table_test:table/table_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) table/table_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/skiplist_test:db/skiplist_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/skiplist_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/version_edit_test:db/version_edit_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/version_edit_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/version_set_test:db/version_set_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/version_set_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/write_batch_test:db/write_batch_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/write_batch_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/memenv_test:$(STATIC_OUTDIR)/helpers/memenv/memenv_test.o $(STATIC_OUTDIR)/libmemenv.a $(STATIC_OUTDIR)/libleveldb.a $(TESTHARNESS)\n-\t$(XCRUN) $(CXX) $(LDFLAGS) $(STATIC_OUTDIR)/helpers/memenv/memenv_test.o $(STATIC_OUTDIR)/libmemenv.a $(STATIC_OUTDIR)/libleveldb.a $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(SHARED_OUTDIR)/db_bench:$(SHARED_OUTDIR)/db/db_bench.o $(SHARED_LIBS) $(TESTUTIL)\n-\t$(XCRUN) $(CXX) $(LDFLAGS) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) $(SHARED_OUTDIR)/db/db_bench.o $(TESTUTIL) $(SHARED_OUTDIR)/$(SHARED_LIB3) -o $@ $(LIBS)\n-\n-.PHONY: run-shared\n-run-shared: $(SHARED_OUTDIR)/db_bench\n-\tLD_LIBRARY_PATH=$(SHARED_OUTDIR) $(SHARED_OUTDIR)/db_bench\n-\n-$(SIMULATOR_OUTDIR)/%.o: %.cc\n-\txcrun -sdk iphonesimulator $(CXX) $(CXXFLAGS) $(SIMULATOR_CFLAGS) -c $< -o $@\n-\n-$(DEVICE_OUTDIR)/%.o: %.cc\n-\txcrun -sdk iphoneos $(CXX) $(CXXFLAGS) $(DEVICE_CFLAGS) -c $< -o $@\n-\n-$(SIMULATOR_OUTDIR)/%.o: %.c\n-\txcrun -sdk iphonesimulator $(CC) $(CFLAGS) $(SIMULATOR_CFLAGS) -c $< -o $@\n-\n-$(DEVICE_OUTDIR)/%.o: %.c\n-\txcrun -sdk iphoneos $(CC) $(CFLAGS) $(DEVICE_CFLAGS) -c $< -o $@\n-\n-$(STATIC_OUTDIR)/%.o: %.cc\n-\t$(CXX) $(CXXFLAGS) -c $< -o $@\n-\n-$(STATIC_OUTDIR)/%.o: %.c\n-\t$(CC) $(CFLAGS) -c $< -o $@\n-\n-$(SHARED_OUTDIR)/%.o: %.cc\n-\t$(CXX) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) -c $< -o $@\n-\n-$(SHARED_OUTDIR)/%.o: %.c\n-\t$(CC) $(CFLAGS) $(PLATFORM_SHARED_CFLAGS) -c $< -o $@\n-\n-$(STATIC_OUTDIR)/port/port_posix_sse.o: port/port_posix_sse.cc\n-\t$(CXX) $(CXXFLAGS) $(PLATFORM_SSEFLAGS) -c $< -o $@\n-\n-$(SHARED_OUTDIR)/port/port_posix_sse.o: port/port_posix_sse.cc\n-\t$(CXX) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) $(PLATFORM_SSEFLAGS) -c $< -o $@"
      },
      {
        "sha": "dadfd5693ead7ad7656426fadbf2294c0189a040",
        "filename": "README.md",
        "status": "modified",
        "additions": 69,
        "deletions": 18,
        "changes": 87,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/README.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/README.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/README.md?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -1,10 +1,12 @@\n **LevelDB is a fast key-value storage library written at Google that provides an ordered mapping from string keys to string values.**\n \n [![Build Status](https://travis-ci.org/google/leveldb.svg?branch=master)](https://travis-ci.org/google/leveldb)\n+[![Build status](https://ci.appveyor.com/api/projects/status/g2j5j4rfkda6eyw5/branch/master?svg=true)](https://ci.appveyor.com/project/pwnall/leveldb)\n \n Authors: Sanjay Ghemawat (sanjay@google.com) and Jeff Dean (jeff@google.com)\n \n # Features\n+\n   * Keys and values are arbitrary byte arrays.\n   * Data is stored sorted by key.\n   * Callers can provide a custom comparison function to override the sort order.\n@@ -16,26 +18,66 @@ Authors: Sanjay Ghemawat (sanjay@google.com) and Jeff Dean (jeff@google.com)\n   * External activity (file system operations etc.) is relayed through a virtual interface so users can customize the operating system interactions.\n \n # Documentation\n-  [LevelDB library documentation](https://github.com/google/leveldb/blob/master/doc/index.md) is online and bundled with the source code.\n \n+  [LevelDB library documentation](https://github.com/google/leveldb/blob/master/doc/index.md) is online and bundled with the source code.\n \n # Limitations\n+\n   * This is not a SQL database.  It does not have a relational data model, it does not support SQL queries, and it has no support for indexes.\n   * Only a single process (possibly multi-threaded) can access a particular database at a time.\n   * There is no client-server support builtin to the library.  An application that needs such support will have to wrap their own server around the library.\n \n+# Building\n+\n+This project supports [CMake](https://cmake.org/) out of the box.\n+\n+### Build for POSIX\n+\n+Quick start:\n+\n+```bash\n+mkdir -p build && cd build\n+cmake -DCMAKE_BUILD_TYPE=Release .. && cmake --build .\n+```\n+\n+### Building for Windows\n+\n+First generate the Visual Studio 2017 project/solution files:\n+\n+```cmd\n+mkdir build\n+cd build\n+cmake -G \"Visual Studio 15\" ..\n+```\n+The default default will build for x86. For 64-bit run:\n+\n+```cmd\n+cmake -G \"Visual Studio 15 Win64\" ..\n+```\n+\n+To compile the Windows solution from the command-line:\n+\n+```cmd\n+devenv /build Debug leveldb.sln\n+```\n+\n+or open leveldb.sln in Visual Studio and build from within.\n+\n+Please see the CMake documentation and `CMakeLists.txt` for more advanced usage.\n+\n # Contributing to the leveldb Project\n+\n The leveldb project welcomes contributions. leveldb's primary goal is to be\n a reliable and fast key/value store. Changes that are in line with the\n features/limitations outlined above, and meet the requirements below,\n will be considered.\n \n Contribution requirements:\n \n-1. **POSIX only**. We _generally_ will only accept changes that are both\n-   compiled, and tested on a POSIX platform - usually Linux. Very small\n-   changes will sometimes be accepted, but consider that more of an\n-   exception than the rule.\n+1. **Tested platforms only**. We _generally_ will only accept changes for\n+   platforms that are compiled and tested. This means POSIX (for Linux and\n+   macOS) or Windows. Very small changes will sometimes be accepted, but\n+   consider that more of an exception than the rule.\n \n 2. **Stable API**. We strive very hard to maintain a stable API. Changes that\n    require changes for projects using leveldb _might_ be rejected without\n@@ -44,7 +86,16 @@ Contribution requirements:\n 3. **Tests**: All changes must be accompanied by a new (or changed) test, or\n    a sufficient explanation as to why a new (or changed) test is not required.\n \n+4. **Consistent Style**: This project conforms to the\n+   [Google C++ Style Guide](https://google.github.io/styleguide/cppguide.html).\n+   To ensure your changes are properly formatted please run:\n+\n+   ```\n+   clang-format -i --style=file <file>\n+   ```\n+\n ## Submitting a Pull Request\n+\n Before any pull request will be accepted the author must first sign a\n Contributor License Agreement (CLA) at https://cla.developers.google.com/.\n \n@@ -138,37 +189,37 @@ uncompressed blocks in memory, the read performance improves again:\n See [doc/index.md](doc/index.md) for more explanation. See\n [doc/impl.md](doc/impl.md) for a brief overview of the implementation.\n \n-The public interface is in include/*.h.  Callers should not include or\n+The public interface is in include/leveldb/*.h.  Callers should not include or\n rely on the details of any other header files in this package.  Those\n internal APIs may be changed without warning.\n \n Guide to header files:\n \n-* **include/db.h**: Main interface to the DB: Start here\n+* **include/leveldb/db.h**: Main interface to the DB: Start here.\n \n-* **include/options.h**: Control over the behavior of an entire database,\n+* **include/leveldb/options.h**: Control over the behavior of an entire database,\n and also control over the behavior of individual reads and writes.\n \n-* **include/comparator.h**: Abstraction for user-specified comparison function.\n+* **include/leveldb/comparator.h**: Abstraction for user-specified comparison function.\n If you want just bytewise comparison of keys, you can use the default\n comparator, but clients can write their own comparator implementations if they\n-want custom ordering (e.g. to handle different character encodings, etc.)\n+want custom ordering (e.g. to handle different character encodings, etc.).\n \n-* **include/iterator.h**: Interface for iterating over data. You can get\n+* **include/leveldb/iterator.h**: Interface for iterating over data. You can get\n an iterator from a DB object.\n \n-* **include/write_batch.h**: Interface for atomically applying multiple\n+* **include/leveldb/write_batch.h**: Interface for atomically applying multiple\n updates to a database.\n \n-* **include/slice.h**: A simple module for maintaining a pointer and a\n+* **include/leveldb/slice.h**: A simple module for maintaining a pointer and a\n length into some other byte array.\n \n-* **include/status.h**: Status is returned from many of the public interfaces\n+* **include/leveldb/status.h**: Status is returned from many of the public interfaces\n and is used to report success and various kinds of errors.\n \n-* **include/env.h**:\n+* **include/leveldb/env.h**:\n Abstraction of the OS environment.  A posix implementation of this interface is\n-in util/env_posix.cc\n+in util/env_posix.cc.\n \n-* **include/table.h, include/table_builder.h**: Lower-level modules that most\n-clients probably won't use directly\n+* **include/leveldb/table.h, include/leveldb/table_builder.h**: Lower-level modules that most\n+clients probably won't use directly."
      },
      {
        "sha": "5b76c2448fe1e475b97d12235bdff53b857557cf",
        "filename": "WINDOWS.md",
        "status": "removed",
        "additions": 0,
        "deletions": 39,
        "changes": 39,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/WINDOWS.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/WINDOWS.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/WINDOWS.md?ref=4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "patch": "@@ -1,39 +0,0 @@\n-# Building LevelDB On Windows\n-\n-## Prereqs \n-\n-Install the [Windows Software Development Kit version 7.1](http://www.microsoft.com/downloads/dlx/en-us/listdetailsview.aspx?FamilyID=6b6c21d2-2006-4afa-9702-529fa782d63b).\n-\n-Download and extract the [Snappy source distribution](http://snappy.googlecode.com/files/snappy-1.0.5.tar.gz)\n-\n-1. Open the \"Windows SDK 7.1 Command Prompt\" :\n-   Start Menu -> \"Microsoft Windows SDK v7.1\" > \"Windows SDK 7.1 Command Prompt\"\n-2. Change the directory to the leveldb project\n-\n-## Building the Static lib \n-\n-* 32 bit Version \n-\n-        setenv /x86\n-        msbuild.exe /p:Configuration=Release /p:Platform=Win32 /p:Snappy=..\\snappy-1.0.5\n-\n-* 64 bit Version \n-\n-        setenv /x64\n-        msbuild.exe /p:Configuration=Release /p:Platform=x64 /p:Snappy=..\\snappy-1.0.5\n-\n-\n-## Building and Running the Benchmark app\n-\n-* 32 bit Version \n-\n-\t    setenv /x86\n-\t    msbuild.exe /p:Configuration=Benchmark /p:Platform=Win32 /p:Snappy=..\\snappy-1.0.5\n-\t\tBenchmark\\leveldb.exe\n-\n-* 64 bit Version \n-\n-\t    setenv /x64\n-\t    msbuild.exe /p:Configuration=Benchmark /p:Platform=x64 /p:Snappy=..\\snappy-1.0.5\n-\t    x64\\Benchmark\\leveldb.exe\n-"
      },
      {
        "sha": "3696023b702f68c81b6d121e1769a39281cdc7d8",
        "filename": "benchmarks/db_bench.cc",
        "status": "renamed",
        "additions": 82,
        "deletions": 121,
        "changes": 203,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/benchmarks/db_bench.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/benchmarks/db_bench.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/benchmarks/db_bench.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -2,14 +2,14 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include <sys/types.h>\n #include <stdio.h>\n #include <stdlib.h>\n-#include \"db/db_impl.h\"\n-#include \"db/version_set.h\"\n+#include <sys/types.h>\n+\n #include \"leveldb/cache.h\"\n #include \"leveldb/db.h\"\n #include \"leveldb/env.h\"\n+#include \"leveldb/filter_policy.h\"\n #include \"leveldb/write_batch.h\"\n #include \"port/port.h\"\n #include \"util/crc32c.h\"\n@@ -35,7 +35,6 @@\n //      seekrandom    -- N random seeks\n //      open          -- cost of opening a DB\n //      crc32c        -- repeated crc32c of 4K of data\n-//      acquireload   -- load N*1000 times\n //   Meta operations:\n //      compact     -- Compact the entire DB\n //      stats       -- Print DB stats\n@@ -57,9 +56,7 @@ static const char* FLAGS_benchmarks =\n     \"fill100K,\"\n     \"crc32c,\"\n     \"snappycomp,\"\n-    \"snappyuncomp,\"\n-    \"acquireload,\"\n-    ;\n+    \"snappyuncomp,\";\n \n // Number of key/values to place in database\n static int FLAGS_num = 1000000;\n@@ -112,12 +109,12 @@ static bool FLAGS_use_existing_db = false;\n static bool FLAGS_reuse_logs = false;\n \n // Use the db with the following name.\n-static const char* FLAGS_db = NULL;\n+static const char* FLAGS_db = nullptr;\n \n namespace leveldb {\n \n namespace {\n-leveldb::Env* g_env = NULL;\n+leveldb::Env* g_env = nullptr;\n \n // Helper for quickly generating random data.\n class RandomGenerator {\n@@ -158,7 +155,7 @@ static Slice TrimSpace(Slice s) {\n     start++;\n   }\n   size_t limit = s.size();\n-  while (limit > start && isspace(s[limit-1])) {\n+  while (limit > start && isspace(s[limit - 1])) {\n     limit--;\n   }\n   return Slice(s.data() + start, limit - start);\n@@ -190,14 +187,12 @@ class Stats {\n \n   void Start() {\n     next_report_ = 100;\n-    last_op_finish_ = start_;\n     hist_.Clear();\n     done_ = 0;\n     bytes_ = 0;\n     seconds_ = 0;\n-    start_ = g_env->NowMicros();\n-    finish_ = start_;\n     message_.clear();\n+    start_ = finish_ = last_op_finish_ = g_env->NowMicros();\n   }\n \n   void Merge(const Stats& other) {\n@@ -217,9 +212,7 @@ class Stats {\n     seconds_ = (finish_ - start_) * 1e-6;\n   }\n \n-  void AddMessage(Slice msg) {\n-    AppendWithSpace(&message_, msg);\n-  }\n+  void AddMessage(Slice msg) { AppendWithSpace(&message_, msg); }\n \n   void FinishedSingleOp() {\n     if (FLAGS_histogram) {\n@@ -235,21 +228,26 @@ class Stats {\n \n     done_++;\n     if (done_ >= next_report_) {\n-      if      (next_report_ < 1000)   next_report_ += 100;\n-      else if (next_report_ < 5000)   next_report_ += 500;\n-      else if (next_report_ < 10000)  next_report_ += 1000;\n-      else if (next_report_ < 50000)  next_report_ += 5000;\n-      else if (next_report_ < 100000) next_report_ += 10000;\n-      else if (next_report_ < 500000) next_report_ += 50000;\n-      else                            next_report_ += 100000;\n+      if (next_report_ < 1000)\n+        next_report_ += 100;\n+      else if (next_report_ < 5000)\n+        next_report_ += 500;\n+      else if (next_report_ < 10000)\n+        next_report_ += 1000;\n+      else if (next_report_ < 50000)\n+        next_report_ += 5000;\n+      else if (next_report_ < 100000)\n+        next_report_ += 10000;\n+      else if (next_report_ < 500000)\n+        next_report_ += 50000;\n+      else\n+        next_report_ += 100000;\n       fprintf(stderr, \"... finished %d ops%30s\\r\", done_, \"\");\n       fflush(stderr);\n     }\n   }\n \n-  void AddBytes(int64_t n) {\n-    bytes_ += n;\n-  }\n+  void AddBytes(int64_t n) { bytes_ += n; }\n \n   void Report(const Slice& name) {\n     // Pretend at least one op was done in case we are running a benchmark\n@@ -268,11 +266,8 @@ class Stats {\n     }\n     AppendWithSpace(&extra, message_);\n \n-    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\",\n-            name.ToString().c_str(),\n-            seconds_ * 1e6 / done_,\n-            (extra.empty() ? \"\" : \" \"),\n-            extra.c_str());\n+    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\", name.ToString().c_str(),\n+            seconds_ * 1e6 / done_, (extra.empty() ? \"\" : \" \"), extra.c_str());\n     if (FLAGS_histogram) {\n       fprintf(stdout, \"Microseconds per op:\\n%s\\n\", hist_.ToString().c_str());\n     }\n@@ -283,33 +278,31 @@ class Stats {\n // State shared by all concurrent executions of the same benchmark.\n struct SharedState {\n   port::Mutex mu;\n-  port::CondVar cv;\n-  int total;\n+  port::CondVar cv GUARDED_BY(mu);\n+  int total GUARDED_BY(mu);\n \n   // Each thread goes through the following states:\n   //    (1) initializing\n   //    (2) waiting for others to be initialized\n   //    (3) running\n   //    (4) done\n \n-  int num_initialized;\n-  int num_done;\n-  bool start;\n+  int num_initialized GUARDED_BY(mu);\n+  int num_done GUARDED_BY(mu);\n+  bool start GUARDED_BY(mu);\n \n-  SharedState() : cv(&mu) { }\n+  SharedState(int total)\n+      : cv(&mu), total(total), num_initialized(0), num_done(0), start(false) {}\n };\n \n // Per-thread state for concurrent executions of the same benchmark.\n struct ThreadState {\n-  int tid;             // 0..n-1 when running in n threads\n-  Random rand;         // Has different seeds for different threads\n+  int tid;      // 0..n-1 when running in n threads\n+  Random rand;  // Has different seeds for different threads\n   Stats stats;\n   SharedState* shared;\n \n-  ThreadState(int index)\n-      : tid(index),\n-        rand(1000 + index) {\n-  }\n+  ThreadState(int index) : tid(index), rand(1000 + index), shared(nullptr) {}\n };\n \n }  // namespace\n@@ -335,20 +328,20 @@ class Benchmark {\n             static_cast<int>(FLAGS_value_size * FLAGS_compression_ratio + 0.5));\n     fprintf(stdout, \"Entries:    %d\\n\", num_);\n     fprintf(stdout, \"RawSize:    %.1f MB (estimated)\\n\",\n-            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_)\n-             / 1048576.0));\n+            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_) /\n+             1048576.0));\n     fprintf(stdout, \"FileSize:   %.1f MB (estimated)\\n\",\n-            (((kKeySize + FLAGS_value_size * FLAGS_compression_ratio) * num_)\n-             / 1048576.0));\n+            (((kKeySize + FLAGS_value_size * FLAGS_compression_ratio) * num_) /\n+             1048576.0));\n     PrintWarnings();\n     fprintf(stdout, \"------------------------------------------------\\n\");\n   }\n \n   void PrintWarnings() {\n #if defined(__GNUC__) && !defined(__OPTIMIZE__)\n-    fprintf(stdout,\n-            \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\"\n-            );\n+    fprintf(\n+        stdout,\n+        \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\");\n #endif\n #ifndef NDEBUG\n     fprintf(stdout,\n@@ -366,22 +359,22 @@ class Benchmark {\n   }\n \n   void PrintEnvironment() {\n-    fprintf(stderr, \"LevelDB:    version %d.%d\\n\",\n-            kMajorVersion, kMinorVersion);\n+    fprintf(stderr, \"LevelDB:    version %d.%d\\n\", kMajorVersion,\n+            kMinorVersion);\n \n #if defined(__linux)\n-    time_t now = time(NULL);\n+    time_t now = time(nullptr);\n     fprintf(stderr, \"Date:       %s\", ctime(&now));  // ctime() adds newline\n \n     FILE* cpuinfo = fopen(\"/proc/cpuinfo\", \"r\");\n-    if (cpuinfo != NULL) {\n+    if (cpuinfo != nullptr) {\n       char line[1000];\n       int num_cpus = 0;\n       std::string cpu_type;\n       std::string cache_size;\n-      while (fgets(line, sizeof(line), cpuinfo) != NULL) {\n+      while (fgets(line, sizeof(line), cpuinfo) != nullptr) {\n         const char* sep = strchr(line, ':');\n-        if (sep == NULL) {\n+        if (sep == nullptr) {\n           continue;\n         }\n         Slice key = TrimSpace(Slice(line, sep - 1 - line));\n@@ -402,16 +395,16 @@ class Benchmark {\n \n  public:\n   Benchmark()\n-  : cache_(FLAGS_cache_size >= 0 ? NewLRUCache(FLAGS_cache_size) : NULL),\n-    filter_policy_(FLAGS_bloom_bits >= 0\n-                   ? NewBloomFilterPolicy(FLAGS_bloom_bits)\n-                   : NULL),\n-    db_(NULL),\n-    num_(FLAGS_num),\n-    value_size_(FLAGS_value_size),\n-    entries_per_batch_(1),\n-    reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n-    heap_counter_(0) {\n+      : cache_(FLAGS_cache_size >= 0 ? NewLRUCache(FLAGS_cache_size) : nullptr),\n+        filter_policy_(FLAGS_bloom_bits >= 0\n+                           ? NewBloomFilterPolicy(FLAGS_bloom_bits)\n+                           : nullptr),\n+        db_(nullptr),\n+        num_(FLAGS_num),\n+        value_size_(FLAGS_value_size),\n+        entries_per_batch_(1),\n+        reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n+        heap_counter_(0) {\n     std::vector<std::string> files;\n     g_env->GetChildren(FLAGS_db, &files);\n     for (size_t i = 0; i < files.size(); i++) {\n@@ -435,12 +428,12 @@ class Benchmark {\n     Open();\n \n     const char* benchmarks = FLAGS_benchmarks;\n-    while (benchmarks != NULL) {\n+    while (benchmarks != nullptr) {\n       const char* sep = strchr(benchmarks, ',');\n       Slice name;\n-      if (sep == NULL) {\n+      if (sep == nullptr) {\n         name = benchmarks;\n-        benchmarks = NULL;\n+        benchmarks = nullptr;\n       } else {\n         name = Slice(benchmarks, sep - benchmarks);\n         benchmarks = sep + 1;\n@@ -453,7 +446,7 @@ class Benchmark {\n       entries_per_batch_ = 1;\n       write_options_ = WriteOptions();\n \n-      void (Benchmark::*method)(ThreadState*) = NULL;\n+      void (Benchmark::*method)(ThreadState*) = nullptr;\n       bool fresh_db = false;\n       int num_threads = FLAGS_threads;\n \n@@ -510,8 +503,6 @@ class Benchmark {\n         method = &Benchmark::Compact;\n       } else if (name == Slice(\"crc32c\")) {\n         method = &Benchmark::Crc32c;\n-      } else if (name == Slice(\"acquireload\")) {\n-        method = &Benchmark::AcquireLoad;\n       } else if (name == Slice(\"snappycomp\")) {\n         method = &Benchmark::SnappyCompress;\n       } else if (name == Slice(\"snappyuncomp\")) {\n@@ -523,7 +514,7 @@ class Benchmark {\n       } else if (name == Slice(\"sstables\")) {\n         PrintStats(\"leveldb.sstables\");\n       } else {\n-        if (name != Slice()) {  // No error message for empty name\n+        if (!name.empty()) {  // No error message for empty name\n           fprintf(stderr, \"unknown benchmark '%s'\\n\", name.ToString().c_str());\n         }\n       }\n@@ -532,16 +523,16 @@ class Benchmark {\n         if (FLAGS_use_existing_db) {\n           fprintf(stdout, \"%-12s : skipped (--use_existing_db is true)\\n\",\n                   name.ToString().c_str());\n-          method = NULL;\n+          method = nullptr;\n         } else {\n           delete db_;\n-          db_ = NULL;\n+          db_ = nullptr;\n           DestroyDB(FLAGS_db, Options());\n           Open();\n         }\n       }\n \n-      if (method != NULL) {\n+      if (method != nullptr) {\n         RunBenchmark(num_threads, name, method);\n       }\n     }\n@@ -585,11 +576,7 @@ class Benchmark {\n \n   void RunBenchmark(int n, Slice name,\n                     void (Benchmark::*method)(ThreadState*)) {\n-    SharedState shared;\n-    shared.total = n;\n-    shared.num_initialized = 0;\n-    shared.num_done = 0;\n-    shared.start = false;\n+    SharedState shared(n);\n \n     ThreadArg* arg = new ThreadArg[n];\n     for (int i = 0; i < n; i++) {\n@@ -643,22 +630,6 @@ class Benchmark {\n     thread->stats.AddMessage(label);\n   }\n \n-  void AcquireLoad(ThreadState* thread) {\n-    int dummy;\n-    port::AtomicPointer ap(&dummy);\n-    int count = 0;\n-    void *ptr = NULL;\n-    thread->stats.AddMessage(\"(each op is 1000 loads)\");\n-    while (count < 100000) {\n-      for (int i = 0; i < 1000; i++) {\n-        ptr = ap.Acquire_Load();\n-      }\n-      count++;\n-      thread->stats.FinishedSingleOp();\n-    }\n-    if (ptr == NULL) exit(1); // Disable unused variable warning.\n-  }\n-\n   void SnappyCompress(ThreadState* thread) {\n     RandomGenerator gen;\n     Slice input = gen.Generate(Options().block_size);\n@@ -692,8 +663,8 @@ class Benchmark {\n     int64_t bytes = 0;\n     char* uncompressed = new char[input.size()];\n     while (ok && bytes < 1024 * 1048576) {  // Compress 1G\n-      ok =  port::Snappy_Uncompress(compressed.data(), compressed.size(),\n-                                    uncompressed);\n+      ok = port::Snappy_Uncompress(compressed.data(), compressed.size(),\n+                                   uncompressed);\n       bytes += input.size();\n       thread->stats.FinishedSingleOp();\n     }\n@@ -707,7 +678,7 @@ class Benchmark {\n   }\n \n   void Open() {\n-    assert(db_ == NULL);\n+    assert(db_ == nullptr);\n     Options options;\n     options.env = g_env;\n     options.create_if_missing = !FLAGS_use_existing_db;\n@@ -733,13 +704,9 @@ class Benchmark {\n     }\n   }\n \n-  void WriteSeq(ThreadState* thread) {\n-    DoWrite(thread, true);\n-  }\n+  void WriteSeq(ThreadState* thread) { DoWrite(thread, true); }\n \n-  void WriteRandom(ThreadState* thread) {\n-    DoWrite(thread, false);\n-  }\n+  void WriteRandom(ThreadState* thread) { DoWrite(thread, false); }\n \n   void DoWrite(ThreadState* thread, bool seq) {\n     if (num_ != FLAGS_num) {\n@@ -755,7 +722,7 @@ class Benchmark {\n     for (int i = 0; i < num_; i += entries_per_batch_) {\n       batch.Clear();\n       for (int j = 0; j < entries_per_batch_; j++) {\n-        const int k = seq ? i+j : (thread->rand.Next() % FLAGS_num);\n+        const int k = seq ? i + j : (thread->rand.Next() % FLAGS_num);\n         char key[100];\n         snprintf(key, sizeof(key), \"%016d\", k);\n         batch.Put(key, gen.Generate(value_size_));\n@@ -865,7 +832,7 @@ class Benchmark {\n     for (int i = 0; i < num_; i += entries_per_batch_) {\n       batch.Clear();\n       for (int j = 0; j < entries_per_batch_; j++) {\n-        const int k = seq ? i+j : (thread->rand.Next() % FLAGS_num);\n+        const int k = seq ? i + j : (thread->rand.Next() % FLAGS_num);\n         char key[100];\n         snprintf(key, sizeof(key), \"%016d\", k);\n         batch.Delete(key);\n@@ -879,13 +846,9 @@ class Benchmark {\n     }\n   }\n \n-  void DeleteSeq(ThreadState* thread) {\n-    DoDelete(thread, true);\n-  }\n+  void DeleteSeq(ThreadState* thread) { DoDelete(thread, true); }\n \n-  void DeleteRandom(ThreadState* thread) {\n-    DoDelete(thread, false);\n-  }\n+  void DeleteRandom(ThreadState* thread) { DoDelete(thread, false); }\n \n   void ReadWhileWriting(ThreadState* thread) {\n     if (thread->tid > 0) {\n@@ -917,9 +880,7 @@ class Benchmark {\n     }\n   }\n \n-  void Compact(ThreadState* thread) {\n-    db_->CompactRange(NULL, NULL);\n-  }\n+  void Compact(ThreadState* thread) { db_->CompactRange(nullptr, nullptr); }\n \n   void PrintStats(const char* key) {\n     std::string stats;\n@@ -1008,10 +969,10 @@ int main(int argc, char** argv) {\n   leveldb::g_env = leveldb::Env::Default();\n \n   // Choose a location for the test database if none given with --db=<path>\n-  if (FLAGS_db == NULL) {\n-      leveldb::g_env->GetTestDirectory(&default_db_path);\n-      default_db_path += \"/dbbench\";\n-      FLAGS_db = default_db_path.c_str();\n+  if (FLAGS_db == nullptr) {\n+    leveldb::g_env->GetTestDirectory(&default_db_path);\n+    default_db_path += \"/dbbench\";\n+    FLAGS_db = default_db_path.c_str();\n   }\n \n   leveldb::Benchmark benchmark;",
        "previous_filename": "db/db_bench.cc"
      },
      {
        "sha": "f183f4fcfdf480186207efc0cee062f86ba5ced8",
        "filename": "benchmarks/db_bench_sqlite3.cc",
        "status": "renamed",
        "additions": 90,
        "deletions": 94,
        "changes": 184,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/benchmarks/db_bench_sqlite3.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/benchmarks/db_bench_sqlite3.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/benchmarks/db_bench_sqlite3.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -2,9 +2,10 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n+#include <sqlite3.h>\n #include <stdio.h>\n #include <stdlib.h>\n-#include <sqlite3.h>\n+\n #include \"util/histogram.h\"\n #include \"util/random.h\"\n #include \"util/testutil.h\"\n@@ -38,8 +39,7 @@ static const char* FLAGS_benchmarks =\n     \"fillrand100K,\"\n     \"fillseq100K,\"\n     \"readseq,\"\n-    \"readrand100K,\"\n-    ;\n+    \"readrand100K,\";\n \n // Number of key/values to place in database\n static int FLAGS_num = 1000000;\n@@ -76,38 +76,35 @@ static bool FLAGS_transaction = true;\n static bool FLAGS_WAL_enabled = true;\n \n // Use the db with the following name.\n-static const char* FLAGS_db = NULL;\n+static const char* FLAGS_db = nullptr;\n \n-inline\n-static void ExecErrorCheck(int status, char *err_msg) {\n+inline static void ExecErrorCheck(int status, char* err_msg) {\n   if (status != SQLITE_OK) {\n     fprintf(stderr, \"SQL error: %s\\n\", err_msg);\n     sqlite3_free(err_msg);\n     exit(1);\n   }\n }\n \n-inline\n-static void StepErrorCheck(int status) {\n+inline static void StepErrorCheck(int status) {\n   if (status != SQLITE_DONE) {\n     fprintf(stderr, \"SQL step error: status = %d\\n\", status);\n     exit(1);\n   }\n }\n \n-inline\n-static void ErrorCheck(int status) {\n+inline static void ErrorCheck(int status) {\n   if (status != SQLITE_OK) {\n     fprintf(stderr, \"sqlite3 error: status = %d\\n\", status);\n     exit(1);\n   }\n }\n \n-inline\n-static void WalCheckpoint(sqlite3* db_) {\n+inline static void WalCheckpoint(sqlite3* db_) {\n   // Flush all writes to disk\n   if (FLAGS_WAL_enabled) {\n-    sqlite3_wal_checkpoint_v2(db_, NULL, SQLITE_CHECKPOINT_FULL, NULL, NULL);\n+    sqlite3_wal_checkpoint_v2(db_, nullptr, SQLITE_CHECKPOINT_FULL, nullptr,\n+                              nullptr);\n   }\n }\n \n@@ -152,7 +149,7 @@ static Slice TrimSpace(Slice s) {\n     start++;\n   }\n   int limit = s.size();\n-  while (limit > start && isspace(s[limit-1])) {\n+  while (limit > start && isspace(s[limit - 1])) {\n     limit--;\n   }\n   return Slice(s.data() + start, limit - start);\n@@ -176,7 +173,7 @@ class Benchmark {\n \n   // State kept for progress messages\n   int done_;\n-  int next_report_;     // When to report next\n+  int next_report_;  // When to report next\n \n   void PrintHeader() {\n     const int kKeySize = 16;\n@@ -185,17 +182,17 @@ class Benchmark {\n     fprintf(stdout, \"Values:     %d bytes each\\n\", FLAGS_value_size);\n     fprintf(stdout, \"Entries:    %d\\n\", num_);\n     fprintf(stdout, \"RawSize:    %.1f MB (estimated)\\n\",\n-            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_)\n-             / 1048576.0));\n+            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_) /\n+             1048576.0));\n     PrintWarnings();\n     fprintf(stdout, \"------------------------------------------------\\n\");\n   }\n \n   void PrintWarnings() {\n #if defined(__GNUC__) && !defined(__OPTIMIZE__)\n-    fprintf(stdout,\n-            \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\"\n-            );\n+    fprintf(\n+        stdout,\n+        \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\");\n #endif\n #ifndef NDEBUG\n     fprintf(stdout,\n@@ -207,18 +204,18 @@ class Benchmark {\n     fprintf(stderr, \"SQLite:     version %s\\n\", SQLITE_VERSION);\n \n #if defined(__linux)\n-    time_t now = time(NULL);\n+    time_t now = time(nullptr);\n     fprintf(stderr, \"Date:       %s\", ctime(&now));  // ctime() adds newline\n \n     FILE* cpuinfo = fopen(\"/proc/cpuinfo\", \"r\");\n-    if (cpuinfo != NULL) {\n+    if (cpuinfo != nullptr) {\n       char line[1000];\n       int num_cpus = 0;\n       std::string cpu_type;\n       std::string cache_size;\n-      while (fgets(line, sizeof(line), cpuinfo) != NULL) {\n+      while (fgets(line, sizeof(line), cpuinfo) != nullptr) {\n         const char* sep = strchr(line, ':');\n-        if (sep == NULL) {\n+        if (sep == nullptr) {\n           continue;\n         }\n         Slice key = TrimSpace(Slice(line, sep - 1 - line));\n@@ -261,13 +258,20 @@ class Benchmark {\n \n     done_++;\n     if (done_ >= next_report_) {\n-      if      (next_report_ < 1000)   next_report_ += 100;\n-      else if (next_report_ < 5000)   next_report_ += 500;\n-      else if (next_report_ < 10000)  next_report_ += 1000;\n-      else if (next_report_ < 50000)  next_report_ += 5000;\n-      else if (next_report_ < 100000) next_report_ += 10000;\n-      else if (next_report_ < 500000) next_report_ += 50000;\n-      else                            next_report_ += 100000;\n+      if (next_report_ < 1000)\n+        next_report_ += 100;\n+      else if (next_report_ < 5000)\n+        next_report_ += 500;\n+      else if (next_report_ < 10000)\n+        next_report_ += 1000;\n+      else if (next_report_ < 50000)\n+        next_report_ += 5000;\n+      else if (next_report_ < 100000)\n+        next_report_ += 10000;\n+      else if (next_report_ < 500000)\n+        next_report_ += 50000;\n+      else\n+        next_report_ += 100000;\n       fprintf(stderr, \"... finished %d ops%30s\\r\", done_, \"\");\n       fflush(stderr);\n     }\n@@ -285,16 +289,14 @@ class Benchmark {\n       snprintf(rate, sizeof(rate), \"%6.1f MB/s\",\n                (bytes_ / 1048576.0) / (finish - start_));\n       if (!message_.empty()) {\n-        message_  = std::string(rate) + \" \" + message_;\n+        message_ = std::string(rate) + \" \" + message_;\n       } else {\n         message_ = rate;\n       }\n     }\n \n-    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\",\n-            name.ToString().c_str(),\n-            (finish - start_) * 1e6 / done_,\n-            (message_.empty() ? \"\" : \" \"),\n+    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\", name.ToString().c_str(),\n+            (finish - start_) * 1e6 / done_, (message_.empty() ? \"\" : \" \"),\n             message_.c_str());\n     if (FLAGS_histogram) {\n       fprintf(stdout, \"Microseconds per op:\\n%s\\n\", hist_.ToString().c_str());\n@@ -303,22 +305,16 @@ class Benchmark {\n   }\n \n  public:\n-  enum Order {\n-    SEQUENTIAL,\n-    RANDOM\n-  };\n-  enum DBState {\n-    FRESH,\n-    EXISTING\n-  };\n+  enum Order { SEQUENTIAL, RANDOM };\n+  enum DBState { FRESH, EXISTING };\n \n   Benchmark()\n-  : db_(NULL),\n-    db_num_(0),\n-    num_(FLAGS_num),\n-    reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n-    bytes_(0),\n-    rand_(301) {\n+      : db_(nullptr),\n+        db_num_(0),\n+        num_(FLAGS_num),\n+        reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n+        bytes_(0),\n+        rand_(301) {\n     std::vector<std::string> files;\n     std::string test_dir;\n     Env::Default()->GetTestDirectory(&test_dir);\n@@ -345,12 +341,12 @@ class Benchmark {\n     Open();\n \n     const char* benchmarks = FLAGS_benchmarks;\n-    while (benchmarks != NULL) {\n+    while (benchmarks != nullptr) {\n       const char* sep = strchr(benchmarks, ',');\n       Slice name;\n-      if (sep == NULL) {\n+      if (sep == nullptr) {\n         name = benchmarks;\n-        benchmarks = NULL;\n+        benchmarks = nullptr;\n       } else {\n         name = Slice(benchmarks, sep - benchmarks);\n         benchmarks = sep + 1;\n@@ -415,20 +411,18 @@ class Benchmark {\n   }\n \n   void Open() {\n-    assert(db_ == NULL);\n+    assert(db_ == nullptr);\n \n     int status;\n     char file_name[100];\n-    char* err_msg = NULL;\n+    char* err_msg = nullptr;\n     db_num_++;\n \n     // Open database\n     std::string tmp_dir;\n     Env::Default()->GetTestDirectory(&tmp_dir);\n-    snprintf(file_name, sizeof(file_name),\n-             \"%s/dbbench_sqlite3-%d.db\",\n-             tmp_dir.c_str(),\n-             db_num_);\n+    snprintf(file_name, sizeof(file_name), \"%s/dbbench_sqlite3-%d.db\",\n+             tmp_dir.c_str(), db_num_);\n     status = sqlite3_open(file_name, &db_);\n     if (status) {\n       fprintf(stderr, \"open error: %s\\n\", sqlite3_errmsg(db_));\n@@ -439,15 +433,15 @@ class Benchmark {\n     char cache_size[100];\n     snprintf(cache_size, sizeof(cache_size), \"PRAGMA cache_size = %d\",\n              FLAGS_num_pages);\n-    status = sqlite3_exec(db_, cache_size, NULL, NULL, &err_msg);\n+    status = sqlite3_exec(db_, cache_size, nullptr, nullptr, &err_msg);\n     ExecErrorCheck(status, err_msg);\n \n     // FLAGS_page_size is defaulted to 1024\n     if (FLAGS_page_size != 1024) {\n       char page_size[100];\n       snprintf(page_size, sizeof(page_size), \"PRAGMA page_size = %d\",\n                FLAGS_page_size);\n-      status = sqlite3_exec(db_, page_size, NULL, NULL, &err_msg);\n+      status = sqlite3_exec(db_, page_size, nullptr, nullptr, &err_msg);\n       ExecErrorCheck(status, err_msg);\n     }\n \n@@ -457,34 +451,36 @@ class Benchmark {\n \n       // LevelDB's default cache size is a combined 4 MB\n       std::string WAL_checkpoint = \"PRAGMA wal_autocheckpoint = 4096\";\n-      status = sqlite3_exec(db_, WAL_stmt.c_str(), NULL, NULL, &err_msg);\n+      status = sqlite3_exec(db_, WAL_stmt.c_str(), nullptr, nullptr, &err_msg);\n       ExecErrorCheck(status, err_msg);\n-      status = sqlite3_exec(db_, WAL_checkpoint.c_str(), NULL, NULL, &err_msg);\n+      status =\n+          sqlite3_exec(db_, WAL_checkpoint.c_str(), nullptr, nullptr, &err_msg);\n       ExecErrorCheck(status, err_msg);\n     }\n \n     // Change locking mode to exclusive and create tables/index for database\n     std::string locking_stmt = \"PRAGMA locking_mode = EXCLUSIVE\";\n     std::string create_stmt =\n-          \"CREATE TABLE test (key blob, value blob, PRIMARY KEY(key))\";\n-    std::string stmt_array[] = { locking_stmt, create_stmt };\n+        \"CREATE TABLE test (key blob, value blob, PRIMARY KEY(key))\";\n+    std::string stmt_array[] = {locking_stmt, create_stmt};\n     int stmt_array_length = sizeof(stmt_array) / sizeof(std::string);\n     for (int i = 0; i < stmt_array_length; i++) {\n-      status = sqlite3_exec(db_, stmt_array[i].c_str(), NULL, NULL, &err_msg);\n+      status =\n+          sqlite3_exec(db_, stmt_array[i].c_str(), nullptr, nullptr, &err_msg);\n       ExecErrorCheck(status, err_msg);\n     }\n   }\n \n-  void Write(bool write_sync, Order order, DBState state,\n-             int num_entries, int value_size, int entries_per_batch) {\n+  void Write(bool write_sync, Order order, DBState state, int num_entries,\n+             int value_size, int entries_per_batch) {\n     // Create new database if state == FRESH\n     if (state == FRESH) {\n       if (FLAGS_use_existing_db) {\n         message_ = \"skipping (--use_existing_db is true)\";\n         return;\n       }\n       sqlite3_close(db_);\n-      db_ = NULL;\n+      db_ = nullptr;\n       Open();\n       Start();\n     }\n@@ -495,7 +491,7 @@ class Benchmark {\n       message_ = msg;\n     }\n \n-    char* err_msg = NULL;\n+    char* err_msg = nullptr;\n     int status;\n \n     sqlite3_stmt *replace_stmt, *begin_trans_stmt, *end_trans_stmt;\n@@ -504,20 +500,20 @@ class Benchmark {\n     std::string end_trans_str = \"END TRANSACTION;\";\n \n     // Check for synchronous flag in options\n-    std::string sync_stmt = (write_sync) ? \"PRAGMA synchronous = FULL\" :\n-                                           \"PRAGMA synchronous = OFF\";\n-    status = sqlite3_exec(db_, sync_stmt.c_str(), NULL, NULL, &err_msg);\n+    std::string sync_stmt =\n+        (write_sync) ? \"PRAGMA synchronous = FULL\" : \"PRAGMA synchronous = OFF\";\n+    status = sqlite3_exec(db_, sync_stmt.c_str(), nullptr, nullptr, &err_msg);\n     ExecErrorCheck(status, err_msg);\n \n     // Preparing sqlite3 statements\n-    status = sqlite3_prepare_v2(db_, replace_str.c_str(), -1,\n-                                &replace_stmt, NULL);\n+    status = sqlite3_prepare_v2(db_, replace_str.c_str(), -1, &replace_stmt,\n+                                nullptr);\n     ErrorCheck(status);\n     status = sqlite3_prepare_v2(db_, begin_trans_str.c_str(), -1,\n-                                &begin_trans_stmt, NULL);\n+                                &begin_trans_stmt, nullptr);\n     ErrorCheck(status);\n-    status = sqlite3_prepare_v2(db_, end_trans_str.c_str(), -1,\n-                                &end_trans_stmt, NULL);\n+    status = sqlite3_prepare_v2(db_, end_trans_str.c_str(), -1, &end_trans_stmt,\n+                                nullptr);\n     ErrorCheck(status);\n \n     bool transaction = (entries_per_batch > 1);\n@@ -535,16 +531,16 @@ class Benchmark {\n         const char* value = gen_.Generate(value_size).data();\n \n         // Create values for key-value pair\n-        const int k = (order == SEQUENTIAL) ? i + j :\n-                      (rand_.Next() % num_entries);\n+        const int k =\n+            (order == SEQUENTIAL) ? i + j : (rand_.Next() % num_entries);\n         char key[100];\n         snprintf(key, sizeof(key), \"%016d\", k);\n \n         // Bind KV values into replace_stmt\n         status = sqlite3_bind_blob(replace_stmt, 1, key, 16, SQLITE_STATIC);\n         ErrorCheck(status);\n-        status = sqlite3_bind_blob(replace_stmt, 2, value,\n-                                   value_size, SQLITE_STATIC);\n+        status = sqlite3_bind_blob(replace_stmt, 2, value, value_size,\n+                                   SQLITE_STATIC);\n         ErrorCheck(status);\n \n         // Execute replace_stmt\n@@ -588,12 +584,12 @@ class Benchmark {\n \n     // Preparing sqlite3 statements\n     status = sqlite3_prepare_v2(db_, begin_trans_str.c_str(), -1,\n-                                &begin_trans_stmt, NULL);\n+                                &begin_trans_stmt, nullptr);\n     ErrorCheck(status);\n-    status = sqlite3_prepare_v2(db_, end_trans_str.c_str(), -1,\n-                                &end_trans_stmt, NULL);\n+    status = sqlite3_prepare_v2(db_, end_trans_str.c_str(), -1, &end_trans_stmt,\n+                                nullptr);\n     ErrorCheck(status);\n-    status = sqlite3_prepare_v2(db_, read_str.c_str(), -1, &read_stmt, NULL);\n+    status = sqlite3_prepare_v2(db_, read_str.c_str(), -1, &read_stmt, nullptr);\n     ErrorCheck(status);\n \n     bool transaction = (entries_per_batch > 1);\n@@ -618,7 +614,8 @@ class Benchmark {\n         ErrorCheck(status);\n \n         // Execute read statement\n-        while ((status = sqlite3_step(read_stmt)) == SQLITE_ROW) {}\n+        while ((status = sqlite3_step(read_stmt)) == SQLITE_ROW) {\n+        }\n         StepErrorCheck(status);\n \n         // Reset SQLite statement for another use\n@@ -648,10 +645,10 @@ class Benchmark {\n \n   void ReadSequential() {\n     int status;\n-    sqlite3_stmt *pStmt;\n+    sqlite3_stmt* pStmt;\n     std::string read_str = \"SELECT * FROM test ORDER BY key\";\n \n-    status = sqlite3_prepare_v2(db_, read_str.c_str(), -1, &pStmt, NULL);\n+    status = sqlite3_prepare_v2(db_, read_str.c_str(), -1, &pStmt, nullptr);\n     ErrorCheck(status);\n     for (int i = 0; i < reads_ && SQLITE_ROW == sqlite3_step(pStmt); i++) {\n       bytes_ += sqlite3_column_bytes(pStmt, 1) + sqlite3_column_bytes(pStmt, 2);\n@@ -661,7 +658,6 @@ class Benchmark {\n     status = sqlite3_finalize(pStmt);\n     ErrorCheck(status);\n   }\n-\n };\n \n }  // namespace leveldb\n@@ -706,10 +702,10 @@ int main(int argc, char** argv) {\n   }\n \n   // Choose a location for the test database if none given with --db=<path>\n-  if (FLAGS_db == NULL) {\n-      leveldb::Env::Default()->GetTestDirectory(&default_db_path);\n-      default_db_path += \"/dbbench\";\n-      FLAGS_db = default_db_path.c_str();\n+  if (FLAGS_db == nullptr) {\n+    leveldb::Env::Default()->GetTestDirectory(&default_db_path);\n+    default_db_path += \"/dbbench\";\n+    FLAGS_db = default_db_path.c_str();\n   }\n \n   leveldb::Benchmark benchmark;",
        "previous_filename": "doc/bench/db_bench_sqlite3.cc"
      },
      {
        "sha": "b2f6646d8996d30921279ca7965d9a703af58fc9",
        "filename": "benchmarks/db_bench_tree_db.cc",
        "status": "renamed",
        "additions": 62,
        "deletions": 68,
        "changes": 130,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/benchmarks/db_bench_tree_db.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/benchmarks/db_bench_tree_db.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/benchmarks/db_bench_tree_db.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -2,9 +2,10 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n+#include <kcpolydb.h>\n #include <stdio.h>\n #include <stdlib.h>\n-#include <kcpolydb.h>\n+\n #include \"util/histogram.h\"\n #include \"util/random.h\"\n #include \"util/testutil.h\"\n@@ -34,8 +35,7 @@ static const char* FLAGS_benchmarks =\n     \"fillrand100K,\"\n     \"fillseq100K,\"\n     \"readseq100K,\"\n-    \"readrand100K,\"\n-    ;\n+    \"readrand100K,\";\n \n // Number of key/values to place in database\n static int FLAGS_num = 1000000;\n@@ -69,11 +69,9 @@ static bool FLAGS_use_existing_db = false;\n static bool FLAGS_compression = true;\n \n // Use the db with the following name.\n-static const char* FLAGS_db = NULL;\n+static const char* FLAGS_db = nullptr;\n \n-inline\n-static void DBSynchronize(kyotocabinet::TreeDB* db_)\n-{\n+inline static void DBSynchronize(kyotocabinet::TreeDB* db_) {\n   // Synchronize will flush writes to disk\n   if (!db_->synchronize()) {\n     fprintf(stderr, \"synchronize error: %s\\n\", db_->error().name());\n@@ -121,7 +119,7 @@ static Slice TrimSpace(Slice s) {\n     start++;\n   }\n   int limit = s.size();\n-  while (limit > start && isspace(s[limit-1])) {\n+  while (limit > start && isspace(s[limit - 1])) {\n     limit--;\n   }\n   return Slice(s.data() + start, limit - start);\n@@ -146,7 +144,7 @@ class Benchmark {\n \n   // State kept for progress messages\n   int done_;\n-  int next_report_;     // When to report next\n+  int next_report_;  // When to report next\n \n   void PrintHeader() {\n     const int kKeySize = 16;\n@@ -157,20 +155,20 @@ class Benchmark {\n             static_cast<int>(FLAGS_value_size * FLAGS_compression_ratio + 0.5));\n     fprintf(stdout, \"Entries:    %d\\n\", num_);\n     fprintf(stdout, \"RawSize:    %.1f MB (estimated)\\n\",\n-            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_)\n-             / 1048576.0));\n+            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_) /\n+             1048576.0));\n     fprintf(stdout, \"FileSize:   %.1f MB (estimated)\\n\",\n-            (((kKeySize + FLAGS_value_size * FLAGS_compression_ratio) * num_)\n-             / 1048576.0));\n+            (((kKeySize + FLAGS_value_size * FLAGS_compression_ratio) * num_) /\n+             1048576.0));\n     PrintWarnings();\n     fprintf(stdout, \"------------------------------------------------\\n\");\n   }\n \n   void PrintWarnings() {\n #if defined(__GNUC__) && !defined(__OPTIMIZE__)\n-    fprintf(stdout,\n-            \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\"\n-            );\n+    fprintf(\n+        stdout,\n+        \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\");\n #endif\n #ifndef NDEBUG\n     fprintf(stdout,\n@@ -183,18 +181,18 @@ class Benchmark {\n             kyotocabinet::VERSION, kyotocabinet::LIBVER, kyotocabinet::LIBREV);\n \n #if defined(__linux)\n-    time_t now = time(NULL);\n+    time_t now = time(nullptr);\n     fprintf(stderr, \"Date:           %s\", ctime(&now));  // ctime() adds newline\n \n     FILE* cpuinfo = fopen(\"/proc/cpuinfo\", \"r\");\n-    if (cpuinfo != NULL) {\n+    if (cpuinfo != nullptr) {\n       char line[1000];\n       int num_cpus = 0;\n       std::string cpu_type;\n       std::string cache_size;\n-      while (fgets(line, sizeof(line), cpuinfo) != NULL) {\n+      while (fgets(line, sizeof(line), cpuinfo) != nullptr) {\n         const char* sep = strchr(line, ':');\n-        if (sep == NULL) {\n+        if (sep == nullptr) {\n           continue;\n         }\n         Slice key = TrimSpace(Slice(line, sep - 1 - line));\n@@ -237,13 +235,20 @@ class Benchmark {\n \n     done_++;\n     if (done_ >= next_report_) {\n-      if      (next_report_ < 1000)   next_report_ += 100;\n-      else if (next_report_ < 5000)   next_report_ += 500;\n-      else if (next_report_ < 10000)  next_report_ += 1000;\n-      else if (next_report_ < 50000)  next_report_ += 5000;\n-      else if (next_report_ < 100000) next_report_ += 10000;\n-      else if (next_report_ < 500000) next_report_ += 50000;\n-      else                            next_report_ += 100000;\n+      if (next_report_ < 1000)\n+        next_report_ += 100;\n+      else if (next_report_ < 5000)\n+        next_report_ += 500;\n+      else if (next_report_ < 10000)\n+        next_report_ += 1000;\n+      else if (next_report_ < 50000)\n+        next_report_ += 5000;\n+      else if (next_report_ < 100000)\n+        next_report_ += 10000;\n+      else if (next_report_ < 500000)\n+        next_report_ += 50000;\n+      else\n+        next_report_ += 100000;\n       fprintf(stderr, \"... finished %d ops%30s\\r\", done_, \"\");\n       fflush(stderr);\n     }\n@@ -261,16 +266,14 @@ class Benchmark {\n       snprintf(rate, sizeof(rate), \"%6.1f MB/s\",\n                (bytes_ / 1048576.0) / (finish - start_));\n       if (!message_.empty()) {\n-        message_  = std::string(rate) + \" \" + message_;\n+        message_ = std::string(rate) + \" \" + message_;\n       } else {\n         message_ = rate;\n       }\n     }\n \n-    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\",\n-            name.ToString().c_str(),\n-            (finish - start_) * 1e6 / done_,\n-            (message_.empty() ? \"\" : \" \"),\n+    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\", name.ToString().c_str(),\n+            (finish - start_) * 1e6 / done_, (message_.empty() ? \"\" : \" \"),\n             message_.c_str());\n     if (FLAGS_histogram) {\n       fprintf(stdout, \"Microseconds per op:\\n%s\\n\", hist_.ToString().c_str());\n@@ -279,21 +282,15 @@ class Benchmark {\n   }\n \n  public:\n-  enum Order {\n-    SEQUENTIAL,\n-    RANDOM\n-  };\n-  enum DBState {\n-    FRESH,\n-    EXISTING\n-  };\n+  enum Order { SEQUENTIAL, RANDOM };\n+  enum DBState { FRESH, EXISTING };\n \n   Benchmark()\n-  : db_(NULL),\n-    num_(FLAGS_num),\n-    reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n-    bytes_(0),\n-    rand_(301) {\n+      : db_(nullptr),\n+        num_(FLAGS_num),\n+        reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n+        bytes_(0),\n+        rand_(301) {\n     std::vector<std::string> files;\n     std::string test_dir;\n     Env::Default()->GetTestDirectory(&test_dir);\n@@ -321,12 +318,12 @@ class Benchmark {\n     Open(false);\n \n     const char* benchmarks = FLAGS_benchmarks;\n-    while (benchmarks != NULL) {\n+    while (benchmarks != nullptr) {\n       const char* sep = strchr(benchmarks, ',');\n       Slice name;\n-      if (sep == NULL) {\n+      if (sep == nullptr) {\n         name = benchmarks;\n-        benchmarks = NULL;\n+        benchmarks = nullptr;\n       } else {\n         name = Slice(benchmarks, sep - benchmarks);\n         benchmarks = sep + 1;\n@@ -386,33 +383,31 @@ class Benchmark {\n   }\n \n  private:\n-    void Open(bool sync) {\n-    assert(db_ == NULL);\n+  void Open(bool sync) {\n+    assert(db_ == nullptr);\n \n     // Initialize db_\n     db_ = new kyotocabinet::TreeDB();\n     char file_name[100];\n     db_num_++;\n     std::string test_dir;\n     Env::Default()->GetTestDirectory(&test_dir);\n-    snprintf(file_name, sizeof(file_name),\n-             \"%s/dbbench_polyDB-%d.kct\",\n-             test_dir.c_str(),\n-             db_num_);\n+    snprintf(file_name, sizeof(file_name), \"%s/dbbench_polyDB-%d.kct\",\n+             test_dir.c_str(), db_num_);\n \n     // Create tuning options and open the database\n-    int open_options = kyotocabinet::PolyDB::OWRITER |\n-                       kyotocabinet::PolyDB::OCREATE;\n-    int tune_options = kyotocabinet::TreeDB::TSMALL |\n-        kyotocabinet::TreeDB::TLINEAR;\n+    int open_options =\n+        kyotocabinet::PolyDB::OWRITER | kyotocabinet::PolyDB::OCREATE;\n+    int tune_options =\n+        kyotocabinet::TreeDB::TSMALL | kyotocabinet::TreeDB::TLINEAR;\n     if (FLAGS_compression) {\n       tune_options |= kyotocabinet::TreeDB::TCOMPRESS;\n       db_->tune_compressor(&comp_);\n     }\n     db_->tune_options(tune_options);\n     db_->tune_page_cache(FLAGS_cache_size);\n     db_->tune_page(FLAGS_page_size);\n-    db_->tune_map(256LL<<20);\n+    db_->tune_map(256LL << 20);\n     if (sync) {\n       open_options |= kyotocabinet::PolyDB::OAUTOSYNC;\n     }\n@@ -421,16 +416,16 @@ class Benchmark {\n     }\n   }\n \n-  void Write(bool sync, Order order, DBState state,\n-             int num_entries, int value_size, int entries_per_batch) {\n+  void Write(bool sync, Order order, DBState state, int num_entries,\n+             int value_size, int entries_per_batch) {\n     // Create new database if state == FRESH\n     if (state == FRESH) {\n       if (FLAGS_use_existing_db) {\n         message_ = \"skipping (--use_existing_db is true)\";\n         return;\n       }\n       delete db_;\n-      db_ = NULL;\n+      db_ = nullptr;\n       Open(sync);\n       Start();  // Do not count time taken to destroy/open\n     }\n@@ -442,8 +437,7 @@ class Benchmark {\n     }\n \n     // Write to database\n-    for (int i = 0; i < num_entries; i++)\n-    {\n+    for (int i = 0; i < num_entries; i++) {\n       const int k = (order == SEQUENTIAL) ? i : (rand_.Next() % num_entries);\n       char key[100];\n       snprintf(key, sizeof(key), \"%016d\", k);\n@@ -516,10 +510,10 @@ int main(int argc, char** argv) {\n   }\n \n   // Choose a location for the test database if none given with --db=<path>\n-  if (FLAGS_db == NULL) {\n-      leveldb::Env::Default()->GetTestDirectory(&default_db_path);\n-      default_db_path += \"/dbbench\";\n-      FLAGS_db = default_db_path.c_str();\n+  if (FLAGS_db == nullptr) {\n+    leveldb::Env::Default()->GetTestDirectory(&default_db_path);\n+    default_db_path += \"/dbbench\";\n+    FLAGS_db = default_db_path.c_str();\n   }\n \n   leveldb::Benchmark benchmark;",
        "previous_filename": "doc/bench/db_bench_tree_db.cc"
      },
      {
        "sha": "4a94715900969161b9f29d41e27f0659c648df10",
        "filename": "build_detect_platform",
        "status": "removed",
        "additions": 0,
        "deletions": 259,
        "changes": 259,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/build_detect_platform",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/build_detect_platform",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/build_detect_platform?ref=4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "patch": "@@ -1,259 +0,0 @@\n-#!/bin/sh\n-#\n-# Detects OS we're compiling on and outputs a file specified by the first\n-# argument, which in turn gets read while processing Makefile.\n-#\n-# The output will set the following variables:\n-#   CC                          C Compiler path\n-#   CXX                         C++ Compiler path\n-#   PLATFORM_LDFLAGS            Linker flags\n-#   PLATFORM_LIBS               Libraries flags\n-#   PLATFORM_SHARED_EXT         Extension for shared libraries\n-#   PLATFORM_SHARED_LDFLAGS     Flags for building shared library\n-#                               This flag is embedded just before the name\n-#                               of the shared library without intervening spaces\n-#   PLATFORM_SHARED_CFLAGS      Flags for compiling objects for shared library\n-#   PLATFORM_CCFLAGS            C compiler flags\n-#   PLATFORM_CXXFLAGS           C++ compiler flags.  Will contain:\n-#   PLATFORM_SHARED_VERSIONED   Set to 'true' if platform supports versioned\n-#                               shared libraries, empty otherwise.\n-#\n-# The PLATFORM_CCFLAGS and PLATFORM_CXXFLAGS might include the following:\n-#\n-#       -DLEVELDB_ATOMIC_PRESENT     if <atomic> is present\n-#       -DLEVELDB_PLATFORM_POSIX     for Posix-based platforms\n-#       -DSNAPPY                     if the Snappy library is present\n-#\n-\n-OUTPUT=$1\n-PREFIX=$2\n-if test -z \"$OUTPUT\" || test -z \"$PREFIX\"; then\n-  echo \"usage: $0 <output-filename> <directory_prefix>\" >&2\n-  exit 1\n-fi\n-\n-# Delete existing output, if it exists\n-rm -f $OUTPUT\n-touch $OUTPUT\n-\n-if test -z \"$CC\"; then\n-    CC=cc\n-fi\n-\n-if test -z \"$CXX\"; then\n-    CXX=g++\n-fi\n-\n-if test -z \"$TMPDIR\"; then\n-    TMPDIR=/tmp\n-fi\n-\n-# Detect OS\n-if test -z \"$TARGET_OS\"; then\n-    TARGET_OS=`uname -s`\n-fi\n-\n-COMMON_FLAGS=\n-CROSS_COMPILE=\n-PLATFORM_CCFLAGS=\n-PLATFORM_CXXFLAGS=\n-PLATFORM_LDFLAGS=\n-PLATFORM_LIBS=\n-PLATFORM_SHARED_EXT=\"so\"\n-PLATFORM_SHARED_LDFLAGS=\"-shared -Wl,-soname -Wl,\"\n-PLATFORM_SHARED_CFLAGS=\"-fPIC\"\n-PLATFORM_SHARED_VERSIONED=true\n-PLATFORM_SSEFLAGS=\n-\n-MEMCMP_FLAG=\n-if [ \"$CXX\" = \"g++\" ]; then\n-    # Use libc's memcmp instead of GCC's memcmp.  This results in ~40%\n-    # performance improvement on readrandom under gcc 4.4.3 on Linux/x86.\n-    MEMCMP_FLAG=\"-fno-builtin-memcmp\"\n-fi\n-\n-case \"$TARGET_OS\" in\n-    CYGWIN_*)\n-        PLATFORM=OS_LINUX\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -lpthread -DOS_LINUX -DCYGWIN\"\n-        PLATFORM_LDFLAGS=\"-lpthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    Darwin)\n-        PLATFORM=OS_MACOSX\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -DOS_MACOSX\"\n-        PLATFORM_SHARED_EXT=dylib\n-        [ -z \"$INSTALL_PATH\" ] && INSTALL_PATH=`pwd`\n-        PLATFORM_SHARED_LDFLAGS=\"-dynamiclib -install_name $INSTALL_PATH/\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    Linux)\n-        PLATFORM=OS_LINUX\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -pthread -DOS_LINUX\"\n-        PLATFORM_LDFLAGS=\"-pthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    SunOS)\n-        PLATFORM=OS_SOLARIS\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_SOLARIS\"\n-        PLATFORM_LIBS=\"-lpthread -lrt\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    FreeBSD)\n-        PLATFORM=OS_FREEBSD\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_FREEBSD\"\n-        PLATFORM_LIBS=\"-lpthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    GNU/kFreeBSD)\n-        PLATFORM=OS_KFREEBSD\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_KFREEBSD\"\n-        PLATFORM_LIBS=\"-lpthread\"\n-        PORT_FILE=port/port_posix.cc\n-        ;;\n-    NetBSD)\n-        PLATFORM=OS_NETBSD\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_NETBSD\"\n-        PLATFORM_LIBS=\"-lpthread -lgcc_s\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    OpenBSD)\n-        PLATFORM=OS_OPENBSD\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_OPENBSD\"\n-        PLATFORM_LDFLAGS=\"-pthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    DragonFly)\n-        PLATFORM=OS_DRAGONFLYBSD\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_DRAGONFLYBSD\"\n-        PLATFORM_LIBS=\"-lpthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    OS_ANDROID_CROSSCOMPILE)\n-        PLATFORM=OS_ANDROID\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_ANDROID -DLEVELDB_PLATFORM_POSIX\"\n-        PLATFORM_LDFLAGS=\"\"  # All pthread features are in the Android C library\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        CROSS_COMPILE=true\n-        ;;\n-    HP-UX)\n-        PLATFORM=OS_HPUX\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_HPUX\"\n-        PLATFORM_LDFLAGS=\"-pthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        # man ld: +h internal_name\n-        PLATFORM_SHARED_LDFLAGS=\"-shared -Wl,+h -Wl,\"\n-        ;;\n-    IOS)\n-        PLATFORM=IOS\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -DOS_MACOSX\"\n-        [ -z \"$INSTALL_PATH\" ] && INSTALL_PATH=`pwd`\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        PLATFORM_SHARED_EXT=\n-        PLATFORM_SHARED_LDFLAGS=\n-        PLATFORM_SHARED_CFLAGS=\n-        PLATFORM_SHARED_VERSIONED=\n-        ;;\n-    OS_WINDOWS_CROSSCOMPILE | NATIVE_WINDOWS)\n-        PLATFORM=OS_WINDOWS\n-        COMMON_FLAGS=\"-fno-builtin-memcmp -D_REENTRANT -DOS_WINDOWS -DLEVELDB_PLATFORM_WINDOWS -DWINVER=0x0500 -D__USE_MINGW_ANSI_STDIO=1\"\n-        PLATFORM_SOURCES=\"util/env_win.cc\"\n-        PLATFORM_LIBS=\"-lshlwapi\"\n-        PORT_FILE=port/port_win.cc\n-        CROSS_COMPILE=true\n-        ;;\n-    *)\n-        echo \"Unknown platform!\" >&2\n-        exit 1\n-esac\n-\n-# We want to make a list of all cc files within util, db, table, and helpers\n-# except for the test and benchmark files. By default, find will output a list\n-# of all files matching either rule, so we need to append -print to make the\n-# prune take effect.\n-DIRS=\"$PREFIX/db $PREFIX/util $PREFIX/table\"\n-\n-set -f # temporarily disable globbing so that our patterns aren't expanded\n-PRUNE_TEST=\"-name *test*.cc -prune\"\n-PRUNE_BENCH=\"-name *_bench.cc -prune\"\n-PRUNE_TOOL=\"-name leveldbutil.cc -prune\"\n-PORTABLE_FILES=`find $DIRS $PRUNE_TEST -o $PRUNE_BENCH -o $PRUNE_TOOL -o -name '*.cc' -print | sort | sed \"s,^$PREFIX/,,\" | tr \"\\n\" \" \"`\n-\n-set +f # re-enable globbing\n-\n-# The sources consist of the portable files, plus the platform-specific port\n-# file.\n-echo \"SOURCES=$PORTABLE_FILES $PORT_FILE $PORT_SSE_FILE\" >> $OUTPUT\n-echo \"MEMENV_SOURCES=helpers/memenv/memenv.cc\" >> $OUTPUT\n-\n-if [ \"$CROSS_COMPILE\" = \"true\" ]; then\n-    # Cross-compiling; do not try any compilation tests.\n-    true\n-else\n-    CXXOUTPUT=\"${TMPDIR}/leveldb_build_detect_platform-cxx.$$\"\n-\n-    # If -std=c++0x works, use <atomic> as fallback for when memory barriers\n-    # are not available.\n-    $CXX $CXXFLAGS -std=c++0x -x c++ - -o $CXXOUTPUT 2>/dev/null  <<EOF\n-      #include <atomic>\n-      int main() {}\n-EOF\n-    if [ \"$?\" = 0 ]; then\n-        COMMON_FLAGS=\"$COMMON_FLAGS -DLEVELDB_PLATFORM_POSIX -DLEVELDB_ATOMIC_PRESENT\"\n-        PLATFORM_CXXFLAGS=\"-std=c++0x\"\n-    else\n-        COMMON_FLAGS=\"$COMMON_FLAGS -DLEVELDB_PLATFORM_POSIX\"\n-    fi\n-\n-    # Test whether tcmalloc is available\n-    $CXX $CXXFLAGS -x c++ - -o $CXXOUTPUT -ltcmalloc 2>/dev/null  <<EOF\n-      int main() {}\n-EOF\n-    if [ \"$?\" = 0 ]; then\n-        PLATFORM_LIBS=\"$PLATFORM_LIBS -ltcmalloc\"\n-    fi\n-\n-    rm -f $CXXOUTPUT 2>/dev/null\n-\n-    # Test if gcc SSE 4.2 is supported\n-    $CXX $CXXFLAGS -x c++ - -o $CXXOUTPUT -msse4.2 2>/dev/null  <<EOF\n-      int main() {}\n-EOF\n-    if [ \"$?\" = 0 ]; then\n-        PLATFORM_SSEFLAGS=\"-msse4.2\"\n-    fi\n-\n-    rm -f $CXXOUTPUT 2>/dev/null\n-fi\n-\n-# Use the SSE 4.2 CRC32C intrinsics iff runtime checks indicate compiler supports them.\n-if [ -n \"$PLATFORM_SSEFLAGS\" ]; then\n-    PLATFORM_SSEFLAGS=\"$PLATFORM_SSEFLAGS -DLEVELDB_PLATFORM_POSIX_SSE\"\n-fi\n-\n-PLATFORM_CCFLAGS=\"$PLATFORM_CCFLAGS $COMMON_FLAGS\"\n-PLATFORM_CXXFLAGS=\"$PLATFORM_CXXFLAGS $COMMON_FLAGS\"\n-\n-echo \"CC=$CC\" >> $OUTPUT\n-echo \"CXX=$CXX\" >> $OUTPUT\n-echo \"PLATFORM=$PLATFORM\" >> $OUTPUT\n-echo \"PLATFORM_LDFLAGS=$PLATFORM_LDFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_LIBS=$PLATFORM_LIBS\" >> $OUTPUT\n-echo \"PLATFORM_CCFLAGS=$PLATFORM_CCFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_CXXFLAGS=$PLATFORM_CXXFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_SSEFLAGS=$PLATFORM_SSEFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_SHARED_CFLAGS=$PLATFORM_SHARED_CFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_SHARED_EXT=$PLATFORM_SHARED_EXT\" >> $OUTPUT\n-echo \"PLATFORM_SHARED_LDFLAGS=$PLATFORM_SHARED_LDFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_SHARED_VERSIONED=$PLATFORM_SHARED_VERSIONED\" >> $OUTPUT"
      },
      {
        "sha": "eea6e5c4776bbe6838d323b9e0ea554bc8ec4b32",
        "filename": "cmake/leveldbConfig.cmake",
        "status": "added",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/cmake/leveldbConfig.cmake",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/cmake/leveldbConfig.cmake",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/cmake/leveldbConfig.cmake?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -0,0 +1 @@\n+include(\"${CMAKE_CURRENT_LIST_DIR}/leveldbTargets.cmake\")"
      },
      {
        "sha": "e6c97a05a6b7ff6954224fe62f1f2aec2d52f4a7",
        "filename": "db/autocompact_test.cc",
        "status": "modified",
        "additions": 15,
        "deletions": 21,
        "changes": 36,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/autocompact_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/autocompact_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/autocompact_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -2,21 +2,16 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include \"leveldb/db.h\"\n #include \"db/db_impl.h\"\n #include \"leveldb/cache.h\"\n+#include \"leveldb/db.h\"\n #include \"util/testharness.h\"\n #include \"util/testutil.h\"\n \n namespace leveldb {\n \n class AutoCompactTest {\n  public:\n-  std::string dbname_;\n-  Cache* tiny_cache_;\n-  Options options_;\n-  DB* db_;\n-\n   AutoCompactTest() {\n     dbname_ = test::TmpDir() + \"/autocompact_test\";\n     tiny_cache_ = NewLRUCache(100);\n@@ -47,6 +42,12 @@ class AutoCompactTest {\n   }\n \n   void DoReads(int n);\n+\n+ private:\n+  std::string dbname_;\n+  Cache* tiny_cache_;\n+  Options options_;\n+  DB* db_;\n };\n \n static const int kValueSize = 200 * 1024;\n@@ -81,17 +82,16 @@ void AutoCompactTest::DoReads(int n) {\n     ASSERT_LT(read, 100) << \"Taking too long to compact\";\n     Iterator* iter = db_->NewIterator(ReadOptions());\n     for (iter->SeekToFirst();\n-         iter->Valid() && iter->key().ToString() < limit_key;\n-         iter->Next()) {\n+         iter->Valid() && iter->key().ToString() < limit_key; iter->Next()) {\n       // Drop data\n     }\n     delete iter;\n     // Wait a little bit to allow any triggered compactions to complete.\n     Env::Default()->SleepForMicroseconds(1000000);\n     uint64_t size = Size(Key(0), Key(n));\n-    fprintf(stderr, \"iter %3d => %7.3f MB [other %7.3f MB]\\n\",\n-            read+1, size/1048576.0, Size(Key(n), Key(kCount))/1048576.0);\n-    if (size <= initial_size/10) {\n+    fprintf(stderr, \"iter %3d => %7.3f MB [other %7.3f MB]\\n\", read + 1,\n+            size / 1048576.0, Size(Key(n), Key(kCount)) / 1048576.0);\n+    if (size <= initial_size / 10) {\n       break;\n     }\n   }\n@@ -100,19 +100,13 @@ void AutoCompactTest::DoReads(int n) {\n   // is pretty much unchanged.\n   const int64_t final_other_size = Size(Key(n), Key(kCount));\n   ASSERT_LE(final_other_size, initial_other_size + 1048576);\n-  ASSERT_GE(final_other_size, initial_other_size/5 - 1048576);\n+  ASSERT_GE(final_other_size, initial_other_size / 5 - 1048576);\n }\n \n-TEST(AutoCompactTest, ReadAll) {\n-  DoReads(kCount);\n-}\n+TEST(AutoCompactTest, ReadAll) { DoReads(kCount); }\n \n-TEST(AutoCompactTest, ReadHalf) {\n-  DoReads(kCount/2);\n-}\n+TEST(AutoCompactTest, ReadHalf) { DoReads(kCount / 2); }\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "9520ee4535f496a929fa58a36a3f6b208d0b2f36",
        "filename": "db/builder.cc",
        "status": "modified",
        "additions": 8,
        "deletions": 17,
        "changes": 25,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/builder.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/builder.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/builder.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -4,8 +4,8 @@\n \n #include \"db/builder.h\"\n \n-#include \"db/filename.h\"\n #include \"db/dbformat.h\"\n+#include \"db/filename.h\"\n #include \"db/table_cache.h\"\n #include \"db/version_edit.h\"\n #include \"leveldb/db.h\"\n@@ -14,12 +14,8 @@\n \n namespace leveldb {\n \n-Status BuildTable(const std::string& dbname,\n-                  Env* env,\n-                  const Options& options,\n-                  TableCache* table_cache,\n-                  Iterator* iter,\n-                  FileMetaData* meta) {\n+Status BuildTable(const std::string& dbname, Env* env, const Options& options,\n+                  TableCache* table_cache, Iterator* iter, FileMetaData* meta) {\n   Status s;\n   meta->file_size = 0;\n   iter->SeekToFirst();\n@@ -41,14 +37,10 @@ Status BuildTable(const std::string& dbname,\n     }\n \n     // Finish and check for builder errors\n+    s = builder->Finish();\n     if (s.ok()) {\n-      s = builder->Finish();\n-      if (s.ok()) {\n-        meta->file_size = builder->FileSize();\n-        assert(meta->file_size > 0);\n-      }\n-    } else {\n-      builder->Abandon();\n+      meta->file_size = builder->FileSize();\n+      assert(meta->file_size > 0);\n     }\n     delete builder;\n \n@@ -60,12 +52,11 @@ Status BuildTable(const std::string& dbname,\n       s = file->Close();\n     }\n     delete file;\n-    file = NULL;\n+    file = nullptr;\n \n     if (s.ok()) {\n       // Verify that the table is usable\n-      Iterator* it = table_cache->NewIterator(ReadOptions(),\n-                                              meta->number,\n+      Iterator* it = table_cache->NewIterator(ReadOptions(), meta->number,\n                                               meta->file_size);\n       s = it->status();\n       delete it;"
      },
      {
        "sha": "7bd0b8049b1b322f46edb710d36eacd6a83aba8f",
        "filename": "db/builder.h",
        "status": "modified",
        "additions": 2,
        "deletions": 6,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/builder.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/builder.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/builder.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -22,12 +22,8 @@ class VersionEdit;\n // *meta will be filled with metadata about the generated table.\n // If no data is present in *iter, meta->file_size will be set to\n // zero, and no Table file will be produced.\n-extern Status BuildTable(const std::string& dbname,\n-                         Env* env,\n-                         const Options& options,\n-                         TableCache* table_cache,\n-                         Iterator* iter,\n-                         FileMetaData* meta);\n+Status BuildTable(const std::string& dbname, Env* env, const Options& options,\n+                  TableCache* table_cache, Iterator* iter, FileMetaData* meta);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "3a492f9ac558381d676ceb1249c20346c91eda7d",
        "filename": "db/c.cc",
        "status": "modified",
        "additions": 178,
        "deletions": 213,
        "changes": 391,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/c.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/c.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/c.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -4,10 +4,9 @@\n \n #include \"leveldb/c.h\"\n \n-#include <stdlib.h>\n-#ifndef WIN32\n-#include <unistd.h>\n-#endif\n+#include <cstdint>\n+#include <cstdlib>\n+\n #include \"leveldb/cache.h\"\n #include \"leveldb/comparator.h\"\n #include \"leveldb/db.h\"\n@@ -45,69 +44,72 @@ using leveldb::WriteOptions;\n \n extern \"C\" {\n \n-struct leveldb_t              { DB*               rep; };\n-struct leveldb_iterator_t     { Iterator*         rep; };\n-struct leveldb_writebatch_t   { WriteBatch        rep; };\n-struct leveldb_snapshot_t     { const Snapshot*   rep; };\n-struct leveldb_readoptions_t  { ReadOptions       rep; };\n-struct leveldb_writeoptions_t { WriteOptions      rep; };\n-struct leveldb_options_t      { Options           rep; };\n-struct leveldb_cache_t        { Cache*            rep; };\n-struct leveldb_seqfile_t      { SequentialFile*   rep; };\n-struct leveldb_randomfile_t   { RandomAccessFile* rep; };\n-struct leveldb_writablefile_t { WritableFile*     rep; };\n-struct leveldb_logger_t       { Logger*           rep; };\n-struct leveldb_filelock_t     { FileLock*         rep; };\n+struct leveldb_t {\n+  DB* rep;\n+};\n+struct leveldb_iterator_t {\n+  Iterator* rep;\n+};\n+struct leveldb_writebatch_t {\n+  WriteBatch rep;\n+};\n+struct leveldb_snapshot_t {\n+  const Snapshot* rep;\n+};\n+struct leveldb_readoptions_t {\n+  ReadOptions rep;\n+};\n+struct leveldb_writeoptions_t {\n+  WriteOptions rep;\n+};\n+struct leveldb_options_t {\n+  Options rep;\n+};\n+struct leveldb_cache_t {\n+  Cache* rep;\n+};\n+struct leveldb_seqfile_t {\n+  SequentialFile* rep;\n+};\n+struct leveldb_randomfile_t {\n+  RandomAccessFile* rep;\n+};\n+struct leveldb_writablefile_t {\n+  WritableFile* rep;\n+};\n+struct leveldb_logger_t {\n+  Logger* rep;\n+};\n+struct leveldb_filelock_t {\n+  FileLock* rep;\n+};\n \n struct leveldb_comparator_t : public Comparator {\n-  void* state_;\n-  void (*destructor_)(void*);\n-  int (*compare_)(\n-      void*,\n-      const char* a, size_t alen,\n-      const char* b, size_t blen);\n-  const char* (*name_)(void*);\n+  ~leveldb_comparator_t() override { (*destructor_)(state_); }\n \n-  virtual ~leveldb_comparator_t() {\n-    (*destructor_)(state_);\n-  }\n-\n-  virtual int Compare(const Slice& a, const Slice& b) const {\n+  int Compare(const Slice& a, const Slice& b) const override {\n     return (*compare_)(state_, a.data(), a.size(), b.data(), b.size());\n   }\n \n-  virtual const char* Name() const {\n-    return (*name_)(state_);\n-  }\n+  const char* Name() const override { return (*name_)(state_); }\n \n   // No-ops since the C binding does not support key shortening methods.\n-  virtual void FindShortestSeparator(std::string*, const Slice&) const { }\n-  virtual void FindShortSuccessor(std::string* key) const { }\n-};\n+  void FindShortestSeparator(std::string*, const Slice&) const override {}\n+  void FindShortSuccessor(std::string* key) const override {}\n \n-struct leveldb_filterpolicy_t : public FilterPolicy {\n   void* state_;\n   void (*destructor_)(void*);\n+  int (*compare_)(void*, const char* a, size_t alen, const char* b,\n+                  size_t blen);\n   const char* (*name_)(void*);\n-  char* (*create_)(\n-      void*,\n-      const char* const* key_array, const size_t* key_length_array,\n-      int num_keys,\n-      size_t* filter_length);\n-  unsigned char (*key_match_)(\n-      void*,\n-      const char* key, size_t length,\n-      const char* filter, size_t filter_length);\n-\n-  virtual ~leveldb_filterpolicy_t() {\n-    (*destructor_)(state_);\n-  }\n+};\n \n-  virtual const char* Name() const {\n-    return (*name_)(state_);\n-  }\n+struct leveldb_filterpolicy_t : public FilterPolicy {\n+  ~leveldb_filterpolicy_t() override { (*destructor_)(state_); }\n \n-  virtual void CreateFilter(const Slice* keys, int n, std::string* dst) const {\n+  const char* Name() const override { return (*name_)(state_); }\n+\n+  void CreateFilter(const Slice* keys, int n, std::string* dst) const override {\n     std::vector<const char*> key_pointers(n);\n     std::vector<size_t> key_sizes(n);\n     for (int i = 0; i < n; i++) {\n@@ -120,10 +122,19 @@ struct leveldb_filterpolicy_t : public FilterPolicy {\n     free(filter);\n   }\n \n-  virtual bool KeyMayMatch(const Slice& key, const Slice& filter) const {\n-    return (*key_match_)(state_, key.data(), key.size(),\n-                         filter.data(), filter.size());\n+  bool KeyMayMatch(const Slice& key, const Slice& filter) const override {\n+    return (*key_match_)(state_, key.data(), key.size(), filter.data(),\n+                         filter.size());\n   }\n+\n+  void* state_;\n+  void (*destructor_)(void*);\n+  const char* (*name_)(void*);\n+  char* (*create_)(void*, const char* const* key_array,\n+                   const size_t* key_length_array, int num_keys,\n+                   size_t* filter_length);\n+  uint8_t (*key_match_)(void*, const char* key, size_t length,\n+                        const char* filter, size_t filter_length);\n };\n \n struct leveldb_env_t {\n@@ -132,10 +143,10 @@ struct leveldb_env_t {\n };\n \n static bool SaveError(char** errptr, const Status& s) {\n-  assert(errptr != NULL);\n+  assert(errptr != nullptr);\n   if (s.ok()) {\n     return false;\n-  } else if (*errptr == NULL) {\n+  } else if (*errptr == nullptr) {\n     *errptr = strdup(s.ToString().c_str());\n   } else {\n     // TODO(sanjay): Merge with existing error?\n@@ -151,13 +162,11 @@ static char* CopyString(const std::string& str) {\n   return result;\n }\n \n-leveldb_t* leveldb_open(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr) {\n+leveldb_t* leveldb_open(const leveldb_options_t* options, const char* name,\n+                        char** errptr) {\n   DB* db;\n   if (SaveError(errptr, DB::Open(options->rep, std::string(name), &db))) {\n-    return NULL;\n+    return nullptr;\n   }\n   leveldb_t* result = new leveldb_t;\n   result->rep = db;\n@@ -169,40 +178,27 @@ void leveldb_close(leveldb_t* db) {\n   delete db;\n }\n \n-void leveldb_put(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    const char* key, size_t keylen,\n-    const char* val, size_t vallen,\n-    char** errptr) {\n+void leveldb_put(leveldb_t* db, const leveldb_writeoptions_t* options,\n+                 const char* key, size_t keylen, const char* val, size_t vallen,\n+                 char** errptr) {\n   SaveError(errptr,\n             db->rep->Put(options->rep, Slice(key, keylen), Slice(val, vallen)));\n }\n \n-void leveldb_delete(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    const char* key, size_t keylen,\n-    char** errptr) {\n+void leveldb_delete(leveldb_t* db, const leveldb_writeoptions_t* options,\n+                    const char* key, size_t keylen, char** errptr) {\n   SaveError(errptr, db->rep->Delete(options->rep, Slice(key, keylen)));\n }\n \n-\n-void leveldb_write(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    leveldb_writebatch_t* batch,\n-    char** errptr) {\n+void leveldb_write(leveldb_t* db, const leveldb_writeoptions_t* options,\n+                   leveldb_writebatch_t* batch, char** errptr) {\n   SaveError(errptr, db->rep->Write(options->rep, &batch->rep));\n }\n \n-char* leveldb_get(\n-    leveldb_t* db,\n-    const leveldb_readoptions_t* options,\n-    const char* key, size_t keylen,\n-    size_t* vallen,\n-    char** errptr) {\n-  char* result = NULL;\n+char* leveldb_get(leveldb_t* db, const leveldb_readoptions_t* options,\n+                  const char* key, size_t keylen, size_t* vallen,\n+                  char** errptr) {\n+  char* result = nullptr;\n   std::string tmp;\n   Status s = db->rep->Get(options->rep, Slice(key, keylen), &tmp);\n   if (s.ok()) {\n@@ -218,45 +214,40 @@ char* leveldb_get(\n }\n \n leveldb_iterator_t* leveldb_create_iterator(\n-    leveldb_t* db,\n-    const leveldb_readoptions_t* options) {\n+    leveldb_t* db, const leveldb_readoptions_t* options) {\n   leveldb_iterator_t* result = new leveldb_iterator_t;\n   result->rep = db->rep->NewIterator(options->rep);\n   return result;\n }\n \n-const leveldb_snapshot_t* leveldb_create_snapshot(\n-    leveldb_t* db) {\n+const leveldb_snapshot_t* leveldb_create_snapshot(leveldb_t* db) {\n   leveldb_snapshot_t* result = new leveldb_snapshot_t;\n   result->rep = db->rep->GetSnapshot();\n   return result;\n }\n \n-void leveldb_release_snapshot(\n-    leveldb_t* db,\n-    const leveldb_snapshot_t* snapshot) {\n+void leveldb_release_snapshot(leveldb_t* db,\n+                              const leveldb_snapshot_t* snapshot) {\n   db->rep->ReleaseSnapshot(snapshot->rep);\n   delete snapshot;\n }\n \n-char* leveldb_property_value(\n-    leveldb_t* db,\n-    const char* propname) {\n+char* leveldb_property_value(leveldb_t* db, const char* propname) {\n   std::string tmp;\n   if (db->rep->GetProperty(Slice(propname), &tmp)) {\n     // We use strdup() since we expect human readable output.\n     return strdup(tmp.c_str());\n   } else {\n-    return NULL;\n+    return nullptr;\n   }\n }\n \n-void leveldb_approximate_sizes(\n-    leveldb_t* db,\n-    int num_ranges,\n-    const char* const* range_start_key, const size_t* range_start_key_len,\n-    const char* const* range_limit_key, const size_t* range_limit_key_len,\n-    uint64_t* sizes) {\n+void leveldb_approximate_sizes(leveldb_t* db, int num_ranges,\n+                               const char* const* range_start_key,\n+                               const size_t* range_start_key_len,\n+                               const char* const* range_limit_key,\n+                               const size_t* range_limit_key_len,\n+                               uint64_t* sizes) {\n   Range* ranges = new Range[num_ranges];\n   for (int i = 0; i < num_ranges; i++) {\n     ranges[i].start = Slice(range_start_key[i], range_start_key_len[i]);\n@@ -266,28 +257,23 @@ void leveldb_approximate_sizes(\n   delete[] ranges;\n }\n \n-void leveldb_compact_range(\n-    leveldb_t* db,\n-    const char* start_key, size_t start_key_len,\n-    const char* limit_key, size_t limit_key_len) {\n+void leveldb_compact_range(leveldb_t* db, const char* start_key,\n+                           size_t start_key_len, const char* limit_key,\n+                           size_t limit_key_len) {\n   Slice a, b;\n   db->rep->CompactRange(\n-      // Pass NULL Slice if corresponding \"const char*\" is NULL\n-      (start_key ? (a = Slice(start_key, start_key_len), &a) : NULL),\n-      (limit_key ? (b = Slice(limit_key, limit_key_len), &b) : NULL));\n+      // Pass null Slice if corresponding \"const char*\" is null\n+      (start_key ? (a = Slice(start_key, start_key_len), &a) : nullptr),\n+      (limit_key ? (b = Slice(limit_key, limit_key_len), &b) : nullptr));\n }\n \n-void leveldb_destroy_db(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr) {\n+void leveldb_destroy_db(const leveldb_options_t* options, const char* name,\n+                        char** errptr) {\n   SaveError(errptr, DestroyDB(name, options->rep));\n }\n \n-void leveldb_repair_db(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr) {\n+void leveldb_repair_db(const leveldb_options_t* options, const char* name,\n+                       char** errptr) {\n   SaveError(errptr, RepairDB(name, options->rep));\n }\n \n@@ -296,7 +282,7 @@ void leveldb_iter_destroy(leveldb_iterator_t* iter) {\n   delete iter;\n }\n \n-unsigned char leveldb_iter_valid(const leveldb_iterator_t* iter) {\n+uint8_t leveldb_iter_valid(const leveldb_iterator_t* iter) {\n   return iter->rep->Valid();\n }\n \n@@ -312,13 +298,9 @@ void leveldb_iter_seek(leveldb_iterator_t* iter, const char* k, size_t klen) {\n   iter->rep->Seek(Slice(k, klen));\n }\n \n-void leveldb_iter_next(leveldb_iterator_t* iter) {\n-  iter->rep->Next();\n-}\n+void leveldb_iter_next(leveldb_iterator_t* iter) { iter->rep->Next(); }\n \n-void leveldb_iter_prev(leveldb_iterator_t* iter) {\n-  iter->rep->Prev();\n-}\n+void leveldb_iter_prev(leveldb_iterator_t* iter) { iter->rep->Prev(); }\n \n const char* leveldb_iter_key(const leveldb_iterator_t* iter, size_t* klen) {\n   Slice s = iter->rep->key();\n@@ -340,41 +322,34 @@ leveldb_writebatch_t* leveldb_writebatch_create() {\n   return new leveldb_writebatch_t;\n }\n \n-void leveldb_writebatch_destroy(leveldb_writebatch_t* b) {\n-  delete b;\n-}\n+void leveldb_writebatch_destroy(leveldb_writebatch_t* b) { delete b; }\n \n-void leveldb_writebatch_clear(leveldb_writebatch_t* b) {\n-  b->rep.Clear();\n-}\n+void leveldb_writebatch_clear(leveldb_writebatch_t* b) { b->rep.Clear(); }\n \n-void leveldb_writebatch_put(\n-    leveldb_writebatch_t* b,\n-    const char* key, size_t klen,\n-    const char* val, size_t vlen) {\n+void leveldb_writebatch_put(leveldb_writebatch_t* b, const char* key,\n+                            size_t klen, const char* val, size_t vlen) {\n   b->rep.Put(Slice(key, klen), Slice(val, vlen));\n }\n \n-void leveldb_writebatch_delete(\n-    leveldb_writebatch_t* b,\n-    const char* key, size_t klen) {\n+void leveldb_writebatch_delete(leveldb_writebatch_t* b, const char* key,\n+                               size_t klen) {\n   b->rep.Delete(Slice(key, klen));\n }\n \n-void leveldb_writebatch_iterate(\n-    leveldb_writebatch_t* b,\n-    void* state,\n-    void (*put)(void*, const char* k, size_t klen, const char* v, size_t vlen),\n-    void (*deleted)(void*, const char* k, size_t klen)) {\n+void leveldb_writebatch_iterate(const leveldb_writebatch_t* b, void* state,\n+                                void (*put)(void*, const char* k, size_t klen,\n+                                            const char* v, size_t vlen),\n+                                void (*deleted)(void*, const char* k,\n+                                                size_t klen)) {\n   class H : public WriteBatch::Handler {\n    public:\n     void* state_;\n     void (*put_)(void*, const char* k, size_t klen, const char* v, size_t vlen);\n     void (*deleted_)(void*, const char* k, size_t klen);\n-    virtual void Put(const Slice& key, const Slice& value) {\n+    void Put(const Slice& key, const Slice& value) override {\n       (*put_)(state_, key.data(), key.size(), value.data(), value.size());\n     }\n-    virtual void Delete(const Slice& key) {\n+    void Delete(const Slice& key) override {\n       (*deleted_)(state_, key.data(), key.size());\n     }\n   };\n@@ -385,47 +360,43 @@ void leveldb_writebatch_iterate(\n   b->rep.Iterate(&handler);\n }\n \n-leveldb_options_t* leveldb_options_create() {\n-  return new leveldb_options_t;\n+void leveldb_writebatch_append(leveldb_writebatch_t* destination,\n+                               const leveldb_writebatch_t* source) {\n+  destination->rep.Append(source->rep);\n }\n \n-void leveldb_options_destroy(leveldb_options_t* options) {\n-  delete options;\n-}\n+leveldb_options_t* leveldb_options_create() { return new leveldb_options_t; }\n+\n+void leveldb_options_destroy(leveldb_options_t* options) { delete options; }\n \n-void leveldb_options_set_comparator(\n-    leveldb_options_t* opt,\n-    leveldb_comparator_t* cmp) {\n+void leveldb_options_set_comparator(leveldb_options_t* opt,\n+                                    leveldb_comparator_t* cmp) {\n   opt->rep.comparator = cmp;\n }\n \n-void leveldb_options_set_filter_policy(\n-    leveldb_options_t* opt,\n-    leveldb_filterpolicy_t* policy) {\n+void leveldb_options_set_filter_policy(leveldb_options_t* opt,\n+                                       leveldb_filterpolicy_t* policy) {\n   opt->rep.filter_policy = policy;\n }\n \n-void leveldb_options_set_create_if_missing(\n-    leveldb_options_t* opt, unsigned char v) {\n+void leveldb_options_set_create_if_missing(leveldb_options_t* opt, uint8_t v) {\n   opt->rep.create_if_missing = v;\n }\n \n-void leveldb_options_set_error_if_exists(\n-    leveldb_options_t* opt, unsigned char v) {\n+void leveldb_options_set_error_if_exists(leveldb_options_t* opt, uint8_t v) {\n   opt->rep.error_if_exists = v;\n }\n \n-void leveldb_options_set_paranoid_checks(\n-    leveldb_options_t* opt, unsigned char v) {\n+void leveldb_options_set_paranoid_checks(leveldb_options_t* opt, uint8_t v) {\n   opt->rep.paranoid_checks = v;\n }\n \n void leveldb_options_set_env(leveldb_options_t* opt, leveldb_env_t* env) {\n-  opt->rep.env = (env ? env->rep : NULL);\n+  opt->rep.env = (env ? env->rep : nullptr);\n }\n \n void leveldb_options_set_info_log(leveldb_options_t* opt, leveldb_logger_t* l) {\n-  opt->rep.info_log = (l ? l->rep : NULL);\n+  opt->rep.info_log = (l ? l->rep : nullptr);\n }\n \n void leveldb_options_set_write_buffer_size(leveldb_options_t* opt, size_t s) {\n@@ -448,17 +419,18 @@ void leveldb_options_set_block_restart_interval(leveldb_options_t* opt, int n) {\n   opt->rep.block_restart_interval = n;\n }\n \n+void leveldb_options_set_max_file_size(leveldb_options_t* opt, size_t s) {\n+  opt->rep.max_file_size = s;\n+}\n+\n void leveldb_options_set_compression(leveldb_options_t* opt, int t) {\n   opt->rep.compression = static_cast<CompressionType>(t);\n }\n \n leveldb_comparator_t* leveldb_comparator_create(\n-    void* state,\n-    void (*destructor)(void*),\n-    int (*compare)(\n-        void*,\n-        const char* a, size_t alen,\n-        const char* b, size_t blen),\n+    void* state, void (*destructor)(void*),\n+    int (*compare)(void*, const char* a, size_t alen, const char* b,\n+                   size_t blen),\n     const char* (*name)(void*)) {\n   leveldb_comparator_t* result = new leveldb_comparator_t;\n   result->state_ = state;\n@@ -468,22 +440,15 @@ leveldb_comparator_t* leveldb_comparator_create(\n   return result;\n }\n \n-void leveldb_comparator_destroy(leveldb_comparator_t* cmp) {\n-  delete cmp;\n-}\n+void leveldb_comparator_destroy(leveldb_comparator_t* cmp) { delete cmp; }\n \n leveldb_filterpolicy_t* leveldb_filterpolicy_create(\n-    void* state,\n-    void (*destructor)(void*),\n-    char* (*create_filter)(\n-        void*,\n-        const char* const* key_array, const size_t* key_length_array,\n-        int num_keys,\n-        size_t* filter_length),\n-    unsigned char (*key_may_match)(\n-        void*,\n-        const char* key, size_t length,\n-        const char* filter, size_t filter_length),\n+    void* state, void (*destructor)(void*),\n+    char* (*create_filter)(void*, const char* const* key_array,\n+                           const size_t* key_length_array, int num_keys,\n+                           size_t* filter_length),\n+    uint8_t (*key_may_match)(void*, const char* key, size_t length,\n+                             const char* filter, size_t filter_length),\n     const char* (*name)(void*)) {\n   leveldb_filterpolicy_t* result = new leveldb_filterpolicy_t;\n   result->state_ = state;\n@@ -503,7 +468,8 @@ leveldb_filterpolicy_t* leveldb_filterpolicy_create_bloom(int bits_per_key) {\n   // they delegate to a NewBloomFilterPolicy() instead of user\n   // supplied C functions.\n   struct Wrapper : public leveldb_filterpolicy_t {\n-    const FilterPolicy* rep_;\n+    static void DoNothing(void*) {}\n+\n     ~Wrapper() { delete rep_; }\n     const char* Name() const { return rep_->Name(); }\n     void CreateFilter(const Slice* keys, int n, std::string* dst) const {\n@@ -512,11 +478,12 @@ leveldb_filterpolicy_t* leveldb_filterpolicy_create_bloom(int bits_per_key) {\n     bool KeyMayMatch(const Slice& key, const Slice& filter) const {\n       return rep_->KeyMayMatch(key, filter);\n     }\n-    static void DoNothing(void*) { }\n+\n+    const FilterPolicy* rep_;\n   };\n   Wrapper* wrapper = new Wrapper;\n   wrapper->rep_ = NewBloomFilterPolicy(bits_per_key);\n-  wrapper->state_ = NULL;\n+  wrapper->state_ = nullptr;\n   wrapper->destructor_ = &Wrapper::DoNothing;\n   return wrapper;\n }\n@@ -525,37 +492,29 @@ leveldb_readoptions_t* leveldb_readoptions_create() {\n   return new leveldb_readoptions_t;\n }\n \n-void leveldb_readoptions_destroy(leveldb_readoptions_t* opt) {\n-  delete opt;\n-}\n+void leveldb_readoptions_destroy(leveldb_readoptions_t* opt) { delete opt; }\n \n-void leveldb_readoptions_set_verify_checksums(\n-    leveldb_readoptions_t* opt,\n-    unsigned char v) {\n+void leveldb_readoptions_set_verify_checksums(leveldb_readoptions_t* opt,\n+                                              uint8_t v) {\n   opt->rep.verify_checksums = v;\n }\n \n-void leveldb_readoptions_set_fill_cache(\n-    leveldb_readoptions_t* opt, unsigned char v) {\n+void leveldb_readoptions_set_fill_cache(leveldb_readoptions_t* opt, uint8_t v) {\n   opt->rep.fill_cache = v;\n }\n \n-void leveldb_readoptions_set_snapshot(\n-    leveldb_readoptions_t* opt,\n-    const leveldb_snapshot_t* snap) {\n-  opt->rep.snapshot = (snap ? snap->rep : NULL);\n+void leveldb_readoptions_set_snapshot(leveldb_readoptions_t* opt,\n+                                      const leveldb_snapshot_t* snap) {\n+  opt->rep.snapshot = (snap ? snap->rep : nullptr);\n }\n \n leveldb_writeoptions_t* leveldb_writeoptions_create() {\n   return new leveldb_writeoptions_t;\n }\n \n-void leveldb_writeoptions_destroy(leveldb_writeoptions_t* opt) {\n-  delete opt;\n-}\n+void leveldb_writeoptions_destroy(leveldb_writeoptions_t* opt) { delete opt; }\n \n-void leveldb_writeoptions_set_sync(\n-    leveldb_writeoptions_t* opt, unsigned char v) {\n+void leveldb_writeoptions_set_sync(leveldb_writeoptions_t* opt, uint8_t v) {\n   opt->rep.sync = v;\n }\n \n@@ -582,16 +541,22 @@ void leveldb_env_destroy(leveldb_env_t* env) {\n   delete env;\n }\n \n-void leveldb_free(void* ptr) {\n-  free(ptr);\n-}\n+char* leveldb_env_get_test_directory(leveldb_env_t* env) {\n+  std::string result;\n+  if (!env->rep->GetTestDirectory(&result).ok()) {\n+    return nullptr;\n+  }\n \n-int leveldb_major_version() {\n-  return kMajorVersion;\n+  char* buffer = static_cast<char*>(malloc(result.size() + 1));\n+  memcpy(buffer, result.data(), result.size());\n+  buffer[result.size()] = '\\0';\n+  return buffer;\n }\n \n-int leveldb_minor_version() {\n-  return kMinorVersion;\n-}\n+void leveldb_free(void* ptr) { free(ptr); }\n+\n+int leveldb_major_version() { return kMajorVersion; }\n+\n+int leveldb_minor_version() { return kMinorVersion; }\n \n }  // end extern \"C\""
      },
      {
        "sha": "16c77eed6ad2a51445e93e31d3f52c78531c3c07",
        "filename": "db/c_test.c",
        "status": "modified",
        "additions": 15,
        "deletions": 21,
        "changes": 36,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/c_test.c",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/c_test.c",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/c_test.c?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -8,24 +8,14 @@\n #include <stdio.h>\n #include <stdlib.h>\n #include <string.h>\n-#include <sys/types.h>\n-#include <unistd.h>\n \n const char* phase = \"\";\n-static char dbname[200];\n \n static void StartPhase(const char* name) {\n   fprintf(stderr, \"=== Test %s\\n\", name);\n   phase = name;\n }\n \n-static const char* GetTempDir(void) {\n-    const char* ret = getenv(\"TEST_TMPDIR\");\n-    if (ret == NULL || ret[0] == '\\0')\n-        ret = \"/tmp\";\n-    return ret;\n-}\n-\n #define CheckNoError(err)                                               \\\n   if ((err) != NULL) {                                                  \\\n     fprintf(stderr, \"%s:%d: %s: %s\\n\", __FILE__, __LINE__, phase, (err)); \\\n@@ -130,7 +120,7 @@ static const char* CmpName(void* arg) {\n }\n \n // Custom filter policy\n-static unsigned char fake_filter_result = 1;\n+static uint8_t fake_filter_result = 1;\n static void FilterDestroy(void* arg) { }\n static const char* FilterName(void* arg) {\n   return \"TestFilter\";\n@@ -145,10 +135,8 @@ static char* FilterCreate(\n   memcpy(result, \"fake\", 4);\n   return result;\n }\n-unsigned char FilterKeyMatch(\n-    void* arg,\n-    const char* key, size_t length,\n-    const char* filter, size_t filter_length) {\n+uint8_t FilterKeyMatch(void* arg, const char* key, size_t length,\n+                       const char* filter, size_t filter_length) {\n   CheckCondition(filter_length == 4);\n   CheckCondition(memcmp(filter, \"fake\", 4) == 0);\n   return fake_filter_result;\n@@ -162,21 +150,19 @@ int main(int argc, char** argv) {\n   leveldb_options_t* options;\n   leveldb_readoptions_t* roptions;\n   leveldb_writeoptions_t* woptions;\n+  char* dbname;\n   char* err = NULL;\n   int run = -1;\n \n   CheckCondition(leveldb_major_version() >= 1);\n   CheckCondition(leveldb_minor_version() >= 1);\n \n-  snprintf(dbname, sizeof(dbname),\n-           \"%s/leveldb_c_test-%d\",\n-           GetTempDir(),\n-           ((int) geteuid()));\n-\n   StartPhase(\"create_objects\");\n   cmp = leveldb_comparator_create(NULL, CmpDestroy, CmpCompare, CmpName);\n   env = leveldb_create_default_env();\n   cache = leveldb_cache_create_lru(100000);\n+  dbname = leveldb_env_get_test_directory(env);\n+  CheckCondition(dbname != NULL);\n \n   options = leveldb_options_create();\n   leveldb_options_set_comparator(options, cmp);\n@@ -189,6 +175,7 @@ int main(int argc, char** argv) {\n   leveldb_options_set_max_open_files(options, 10);\n   leveldb_options_set_block_size(options, 1024);\n   leveldb_options_set_block_restart_interval(options, 8);\n+  leveldb_options_set_max_file_size(options, 3 << 20);\n   leveldb_options_set_compression(options, leveldb_no_compression);\n \n   roptions = leveldb_readoptions_create();\n@@ -239,12 +226,18 @@ int main(int argc, char** argv) {\n     leveldb_writebatch_clear(wb);\n     leveldb_writebatch_put(wb, \"bar\", 3, \"b\", 1);\n     leveldb_writebatch_put(wb, \"box\", 3, \"c\", 1);\n-    leveldb_writebatch_delete(wb, \"bar\", 3);\n+\n+    leveldb_writebatch_t* wb2 = leveldb_writebatch_create();\n+    leveldb_writebatch_delete(wb2, \"bar\", 3);\n+    leveldb_writebatch_append(wb, wb2);\n+    leveldb_writebatch_destroy(wb2);\n+\n     leveldb_write(db, woptions, wb, &err);\n     CheckNoError(err);\n     CheckGet(db, roptions, \"foo\", \"hello\");\n     CheckGet(db, roptions, \"bar\", NULL);\n     CheckGet(db, roptions, \"box\", \"c\");\n+\n     int pos = 0;\n     leveldb_writebatch_iterate(wb, &pos, CheckPut, CheckDel);\n     CheckCondition(pos == 3);\n@@ -381,6 +374,7 @@ int main(int argc, char** argv) {\n   leveldb_options_destroy(options);\n   leveldb_readoptions_destroy(roptions);\n   leveldb_writeoptions_destroy(woptions);\n+  leveldb_free(dbname);\n   leveldb_cache_destroy(cache);\n   leveldb_comparator_destroy(cmp);\n   leveldb_env_destroy(env);"
      },
      {
        "sha": "42f5237c659e1c3dd45742152332a007f6f6bca6",
        "filename": "db/corruption_test.cc",
        "status": "modified",
        "additions": 44,
        "deletions": 56,
        "changes": 100,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/corruption_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/corruption_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/corruption_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -2,20 +2,16 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include \"leveldb/db.h\"\n-\n-#include <errno.h>\n-#include <fcntl.h>\n-#include <sys/stat.h>\n #include <sys/types.h>\n-#include \"leveldb/cache.h\"\n-#include \"leveldb/env.h\"\n-#include \"leveldb/table.h\"\n-#include \"leveldb/write_batch.h\"\n+\n #include \"db/db_impl.h\"\n #include \"db/filename.h\"\n #include \"db/log_format.h\"\n #include \"db/version_set.h\"\n+#include \"leveldb/cache.h\"\n+#include \"leveldb/db.h\"\n+#include \"leveldb/table.h\"\n+#include \"leveldb/write_batch.h\"\n #include \"util/logging.h\"\n #include \"util/testharness.h\"\n #include \"util/testutil.h\"\n@@ -26,52 +22,43 @@ static const int kValueSize = 1000;\n \n class CorruptionTest {\n  public:\n-  test::ErrorEnv env_;\n-  std::string dbname_;\n-  Cache* tiny_cache_;\n-  Options options_;\n-  DB* db_;\n-\n-  CorruptionTest() {\n-    tiny_cache_ = NewLRUCache(100);\n+  CorruptionTest()\n+      : db_(nullptr),\n+        dbname_(\"/memenv/corruption_test\"),\n+        tiny_cache_(NewLRUCache(100)) {\n     options_.env = &env_;\n     options_.block_cache = tiny_cache_;\n-    dbname_ = test::TmpDir() + \"/corruption_test\";\n     DestroyDB(dbname_, options_);\n \n-    db_ = NULL;\n     options_.create_if_missing = true;\n     Reopen();\n     options_.create_if_missing = false;\n   }\n \n   ~CorruptionTest() {\n-     delete db_;\n-     DestroyDB(dbname_, Options());\n-     delete tiny_cache_;\n+    delete db_;\n+    delete tiny_cache_;\n   }\n \n   Status TryReopen() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     return DB::Open(options_, dbname_, &db_);\n   }\n \n-  void Reopen() {\n-    ASSERT_OK(TryReopen());\n-  }\n+  void Reopen() { ASSERT_OK(TryReopen()); }\n \n   void RepairDB() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     ASSERT_OK(::leveldb::RepairDB(dbname_, options_));\n   }\n \n   void Build(int n) {\n     std::string key_space, value_space;\n     WriteBatch batch;\n     for (int i = 0; i < n; i++) {\n-      //if ((i % 100) == 0) fprintf(stderr, \"@ %d of %d\\n\", i, n);\n+      // if ((i % 100) == 0) fprintf(stderr, \"@ %d of %d\\n\", i, n);\n       Slice key = Key(i, &key_space);\n       batch.Clear();\n       batch.Put(key, Value(i, &value_space));\n@@ -100,8 +87,7 @@ class CorruptionTest {\n         // Ignore boundary keys.\n         continue;\n       }\n-      if (!ConsumeDecimalNumber(&in, &key) ||\n-          !in.empty() ||\n+      if (!ConsumeDecimalNumber(&in, &key) || !in.empty() ||\n           key < next_expected) {\n         bad_keys++;\n         continue;\n@@ -126,50 +112,46 @@ class CorruptionTest {\n   void Corrupt(FileType filetype, int offset, int bytes_to_corrupt) {\n     // Pick file to corrupt\n     std::vector<std::string> filenames;\n-    ASSERT_OK(env_.GetChildren(dbname_, &filenames));\n+    ASSERT_OK(env_.target()->GetChildren(dbname_, &filenames));\n     uint64_t number;\n     FileType type;\n     std::string fname;\n     int picked_number = -1;\n     for (size_t i = 0; i < filenames.size(); i++) {\n-      if (ParseFileName(filenames[i], &number, &type) &&\n-          type == filetype &&\n+      if (ParseFileName(filenames[i], &number, &type) && type == filetype &&\n           int(number) > picked_number) {  // Pick latest file\n         fname = dbname_ + \"/\" + filenames[i];\n         picked_number = number;\n       }\n     }\n     ASSERT_TRUE(!fname.empty()) << filetype;\n \n-    struct stat sbuf;\n-    if (stat(fname.c_str(), &sbuf) != 0) {\n-      const char* msg = strerror(errno);\n-      ASSERT_TRUE(false) << fname << \": \" << msg;\n-    }\n+    uint64_t file_size;\n+    ASSERT_OK(env_.target()->GetFileSize(fname, &file_size));\n \n     if (offset < 0) {\n       // Relative to end of file; make it absolute\n-      if (-offset > sbuf.st_size) {\n+      if (-offset > file_size) {\n         offset = 0;\n       } else {\n-        offset = sbuf.st_size + offset;\n+        offset = file_size + offset;\n       }\n     }\n-    if (offset > sbuf.st_size) {\n-      offset = sbuf.st_size;\n+    if (offset > file_size) {\n+      offset = file_size;\n     }\n-    if (offset + bytes_to_corrupt > sbuf.st_size) {\n-      bytes_to_corrupt = sbuf.st_size - offset;\n+    if (offset + bytes_to_corrupt > file_size) {\n+      bytes_to_corrupt = file_size - offset;\n     }\n \n     // Do it\n     std::string contents;\n-    Status s = ReadFileToString(Env::Default(), fname, &contents);\n+    Status s = ReadFileToString(env_.target(), fname, &contents);\n     ASSERT_TRUE(s.ok()) << s.ToString();\n     for (int i = 0; i < bytes_to_corrupt; i++) {\n       contents[i + offset] ^= 0x80;\n     }\n-    s = WriteStringToFile(Env::Default(), contents, fname);\n+    s = WriteStringToFile(env_.target(), contents, fname);\n     ASSERT_TRUE(s.ok()) << s.ToString();\n   }\n \n@@ -197,12 +179,20 @@ class CorruptionTest {\n     Random r(k);\n     return test::RandomString(&r, kValueSize, storage);\n   }\n+\n+  test::ErrorEnv env_;\n+  Options options_;\n+  DB* db_;\n+\n+ private:\n+  std::string dbname_;\n+  Cache* tiny_cache_;\n };\n \n TEST(CorruptionTest, Recovery) {\n   Build(100);\n   Check(100, 100);\n-  Corrupt(kLogFile, 19, 1);      // WriteBatch tag for first record\n+  Corrupt(kLogFile, 19, 1);  // WriteBatch tag for first record\n   Corrupt(kLogFile, log::kBlockSize + 1000, 1);  // Somewhere in second block\n   Reopen();\n \n@@ -237,8 +227,8 @@ TEST(CorruptionTest, TableFile) {\n   Build(100);\n   DBImpl* dbi = reinterpret_cast<DBImpl*>(db_);\n   dbi->TEST_CompactMemTable();\n-  dbi->TEST_CompactRange(0, NULL, NULL);\n-  dbi->TEST_CompactRange(1, NULL, NULL);\n+  dbi->TEST_CompactRange(0, nullptr, nullptr);\n+  dbi->TEST_CompactRange(1, nullptr, nullptr);\n \n   Corrupt(kTableFile, 100, 1);\n   Check(90, 99);\n@@ -251,8 +241,8 @@ TEST(CorruptionTest, TableFileRepair) {\n   Build(100);\n   DBImpl* dbi = reinterpret_cast<DBImpl*>(db_);\n   dbi->TEST_CompactMemTable();\n-  dbi->TEST_CompactRange(0, NULL, NULL);\n-  dbi->TEST_CompactRange(1, NULL, NULL);\n+  dbi->TEST_CompactRange(0, nullptr, nullptr);\n+  dbi->TEST_CompactRange(1, nullptr, nullptr);\n \n   Corrupt(kTableFile, 100, 1);\n   RepairDB();\n@@ -302,7 +292,7 @@ TEST(CorruptionTest, CorruptedDescriptor) {\n   ASSERT_OK(db_->Put(WriteOptions(), \"foo\", \"hello\"));\n   DBImpl* dbi = reinterpret_cast<DBImpl*>(db_);\n   dbi->TEST_CompactMemTable();\n-  dbi->TEST_CompactRange(0, NULL, NULL);\n+  dbi->TEST_CompactRange(0, nullptr, nullptr);\n \n   Corrupt(kDescriptorFile, 0, 1000);\n   Status s = TryReopen();\n@@ -343,7 +333,7 @@ TEST(CorruptionTest, CompactionInputErrorParanoid) {\n     Corrupt(kTableFile, 100, 1);\n     env_.SleepForMicroseconds(100000);\n   }\n-  dbi->CompactRange(NULL, NULL);\n+  dbi->CompactRange(nullptr, nullptr);\n \n   // Write must fail because of corrupted table\n   std::string tmp1, tmp2;\n@@ -369,6 +359,4 @@ TEST(CorruptionTest, UnrelatedKeys) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "65e31724bcec1b6e80480d928f129b21be59fba1",
        "filename": "db/db_impl.cc",
        "status": "modified",
        "additions": 267,
        "deletions": 280,
        "changes": 547,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/db_impl.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/db_impl.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/db_impl.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -4,12 +4,15 @@\n \n #include \"db/db_impl.h\"\n \n+#include <stdint.h>\n+#include <stdio.h>\n+\n #include <algorithm>\n+#include <atomic>\n #include <set>\n #include <string>\n-#include <stdint.h>\n-#include <stdio.h>\n #include <vector>\n+\n #include \"db/builder.h\"\n #include \"db/db_iter.h\"\n #include \"db/dbformat.h\"\n@@ -39,16 +42,33 @@ const int kNumNonTableCacheFiles = 10;\n \n // Information kept for every waiting writer\n struct DBImpl::Writer {\n+  explicit Writer(port::Mutex* mu)\n+      : batch(nullptr), sync(false), done(false), cv(mu) {}\n+\n   Status status;\n   WriteBatch* batch;\n   bool sync;\n   bool done;\n   port::CondVar cv;\n-\n-  explicit Writer(port::Mutex* mu) : cv(mu) { }\n };\n \n struct DBImpl::CompactionState {\n+  // Files produced by compaction\n+  struct Output {\n+    uint64_t number;\n+    uint64_t file_size;\n+    InternalKey smallest, largest;\n+  };\n+\n+  Output* current_output() { return &outputs[outputs.size() - 1]; }\n+\n+  explicit CompactionState(Compaction* c)\n+      : compaction(c),\n+        smallest_snapshot(0),\n+        outfile(nullptr),\n+        builder(nullptr),\n+        total_bytes(0) {}\n+\n   Compaction* const compaction;\n \n   // Sequence numbers < smallest_snapshot are not significant since we\n@@ -57,32 +77,17 @@ struct DBImpl::CompactionState {\n   // we can drop all entries for the same key with sequence numbers < S.\n   SequenceNumber smallest_snapshot;\n \n-  // Files produced by compaction\n-  struct Output {\n-    uint64_t number;\n-    uint64_t file_size;\n-    InternalKey smallest, largest;\n-  };\n   std::vector<Output> outputs;\n \n   // State kept for output being generated\n   WritableFile* outfile;\n   TableBuilder* builder;\n \n   uint64_t total_bytes;\n-\n-  Output* current_output() { return &outputs[outputs.size()-1]; }\n-\n-  explicit CompactionState(Compaction* c)\n-      : compaction(c),\n-        outfile(NULL),\n-        builder(NULL),\n-        total_bytes(0) {\n-  }\n };\n \n // Fix user-supplied options to be reasonable\n-template <class T,class V>\n+template <class T, class V>\n static void ClipToRange(T* ptr, V minvalue, V maxvalue) {\n   if (static_cast<V>(*ptr) > maxvalue) *ptr = maxvalue;\n   if (static_cast<V>(*ptr) < minvalue) *ptr = minvalue;\n@@ -93,27 +98,32 @@ Options SanitizeOptions(const std::string& dbname,\n                         const Options& src) {\n   Options result = src;\n   result.comparator = icmp;\n-  result.filter_policy = (src.filter_policy != NULL) ? ipolicy : NULL;\n-  ClipToRange(&result.max_open_files,    64 + kNumNonTableCacheFiles, 50000);\n-  ClipToRange(&result.write_buffer_size, 64<<10,                      1<<30);\n-  ClipToRange(&result.max_file_size,     1<<20,                       1<<30);\n-  ClipToRange(&result.block_size,        1<<10,                       4<<20);\n-  if (result.info_log == NULL) {\n+  result.filter_policy = (src.filter_policy != nullptr) ? ipolicy : nullptr;\n+  ClipToRange(&result.max_open_files, 64 + kNumNonTableCacheFiles, 50000);\n+  ClipToRange(&result.write_buffer_size, 64 << 10, 1 << 30);\n+  ClipToRange(&result.max_file_size, 1 << 20, 1 << 30);\n+  ClipToRange(&result.block_size, 1 << 10, 4 << 20);\n+  if (result.info_log == nullptr) {\n     // Open a log file in the same directory as the db\n     src.env->CreateDir(dbname);  // In case it does not exist\n     src.env->RenameFile(InfoLogFileName(dbname), OldInfoLogFileName(dbname));\n     Status s = src.env->NewLogger(InfoLogFileName(dbname), &result.info_log);\n     if (!s.ok()) {\n       // No place suitable for logging\n-      result.info_log = NULL;\n+      result.info_log = nullptr;\n     }\n   }\n-  if (result.block_cache == NULL) {\n+  if (result.block_cache == nullptr) {\n     result.block_cache = NewLRUCache(8 << 20);\n   }\n   return result;\n }\n \n+static int TableCacheSize(const Options& sanitized_options) {\n+  // Reserve ten files or so for other uses and give the rest to TableCache.\n+  return sanitized_options.max_open_files - kNumNonTableCacheFiles;\n+}\n+\n DBImpl::DBImpl(const Options& raw_options, const std::string& dbname)\n     : env_(raw_options.env),\n       internal_comparator_(raw_options.comparator),\n@@ -123,44 +133,39 @@ DBImpl::DBImpl(const Options& raw_options, const std::string& dbname)\n       owns_info_log_(options_.info_log != raw_options.info_log),\n       owns_cache_(options_.block_cache != raw_options.block_cache),\n       dbname_(dbname),\n-      db_lock_(NULL),\n-      shutting_down_(NULL),\n-      bg_cv_(&mutex_),\n-      mem_(NULL),\n-      imm_(NULL),\n-      logfile_(NULL),\n+      table_cache_(new TableCache(dbname_, options_, TableCacheSize(options_))),\n+      db_lock_(nullptr),\n+      shutting_down_(false),\n+      background_work_finished_signal_(&mutex_),\n+      mem_(nullptr),\n+      imm_(nullptr),\n+      has_imm_(false),\n+      logfile_(nullptr),\n       logfile_number_(0),\n-      log_(NULL),\n+      log_(nullptr),\n       seed_(0),\n       tmp_batch_(new WriteBatch),\n-      bg_compaction_scheduled_(false),\n-      manual_compaction_(NULL) {\n-  has_imm_.Release_Store(NULL);\n-\n-  // Reserve ten files or so for other uses and give the rest to TableCache.\n-  const int table_cache_size = options_.max_open_files - kNumNonTableCacheFiles;\n-  table_cache_ = new TableCache(dbname_, &options_, table_cache_size);\n-\n-  versions_ = new VersionSet(dbname_, &options_, table_cache_,\n-                             &internal_comparator_);\n-}\n+      background_compaction_scheduled_(false),\n+      manual_compaction_(nullptr),\n+      versions_(new VersionSet(dbname_, &options_, table_cache_,\n+                               &internal_comparator_)) {}\n \n DBImpl::~DBImpl() {\n-  // Wait for background work to finish\n+  // Wait for background work to finish.\n   mutex_.Lock();\n-  shutting_down_.Release_Store(this);  // Any non-NULL value is ok\n-  while (bg_compaction_scheduled_) {\n-    bg_cv_.Wait();\n+  shutting_down_.store(true, std::memory_order_release);\n+  while (background_compaction_scheduled_) {\n+    background_work_finished_signal_.Wait();\n   }\n   mutex_.Unlock();\n \n-  if (db_lock_ != NULL) {\n+  if (db_lock_ != nullptr) {\n     env_->UnlockFile(db_lock_);\n   }\n \n   delete versions_;\n-  if (mem_ != NULL) mem_->Unref();\n-  if (imm_ != NULL) imm_->Unref();\n+  if (mem_ != nullptr) mem_->Unref();\n+  if (imm_ != nullptr) imm_->Unref();\n   delete tmp_batch_;\n   delete log_;\n   delete logfile_;\n@@ -216,6 +221,8 @@ void DBImpl::MaybeIgnoreError(Status* s) const {\n }\n \n void DBImpl::DeleteObsoleteFiles() {\n+  mutex_.AssertHeld();\n+\n   if (!bg_error_.ok()) {\n     // After a background error, we don't know whether a new version may\n     // or may not have been committed, so we cannot safely garbage collect.\n@@ -227,11 +234,12 @@ void DBImpl::DeleteObsoleteFiles() {\n   versions_->AddLiveFiles(&live);\n \n   std::vector<std::string> filenames;\n-  env_->GetChildren(dbname_, &filenames); // Ignoring errors on purpose\n+  env_->GetChildren(dbname_, &filenames);  // Ignoring errors on purpose\n   uint64_t number;\n   FileType type;\n-  for (size_t i = 0; i < filenames.size(); i++) {\n-    if (ParseFileName(filenames[i], &number, &type)) {\n+  std::vector<std::string> files_to_delete;\n+  for (std::string& filename : filenames) {\n+    if (ParseFileName(filename, &number, &type)) {\n       bool keep = true;\n       switch (type) {\n         case kLogFile:\n@@ -259,26 +267,34 @@ void DBImpl::DeleteObsoleteFiles() {\n       }\n \n       if (!keep) {\n+        files_to_delete.push_back(std::move(filename));\n         if (type == kTableFile) {\n           table_cache_->Evict(number);\n         }\n-        Log(options_.info_log, \"Delete type=%d #%lld\\n\",\n-            int(type),\n+        Log(options_.info_log, \"Delete type=%d #%lld\\n\", static_cast<int>(type),\n             static_cast<unsigned long long>(number));\n-        env_->DeleteFile(dbname_ + \"/\" + filenames[i]);\n       }\n     }\n   }\n+\n+  // While deleting all files unblock other threads. All files being deleted\n+  // have unique names which will not collide with newly created files and\n+  // are therefore safe to delete while allowing other threads to proceed.\n+  mutex_.Unlock();\n+  for (const std::string& filename : files_to_delete) {\n+    env_->DeleteFile(dbname_ + \"/\" + filename);\n+  }\n+  mutex_.Lock();\n }\n \n-Status DBImpl::Recover(VersionEdit* edit, bool *save_manifest) {\n+Status DBImpl::Recover(VersionEdit* edit, bool* save_manifest) {\n   mutex_.AssertHeld();\n \n   // Ignore error from CreateDir since the creation of the DB is\n   // committed only when the descriptor is created, and this directory\n   // may already exist from a previous failed creation attempt.\n   env_->CreateDir(dbname_);\n-  assert(db_lock_ == NULL);\n+  assert(db_lock_ == nullptr);\n   Status s = env_->LockFile(LockFileName(dbname_), &db_lock_);\n   if (!s.ok()) {\n     return s;\n@@ -296,8 +312,8 @@ Status DBImpl::Recover(VersionEdit* edit, bool *save_manifest) {\n     }\n   } else {\n     if (options_.error_if_exists) {\n-      return Status::InvalidArgument(\n-          dbname_, \"exists (error_if_exists is true)\");\n+      return Status::InvalidArgument(dbname_,\n+                                     \"exists (error_if_exists is true)\");\n     }\n   }\n \n@@ -369,12 +385,12 @@ Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log,\n     Env* env;\n     Logger* info_log;\n     const char* fname;\n-    Status* status;  // NULL if options_.paranoid_checks==false\n-    virtual void Corruption(size_t bytes, const Status& s) {\n+    Status* status;  // null if options_.paranoid_checks==false\n+    void Corruption(size_t bytes, const Status& s) override {\n       Log(info_log, \"%s%s: dropping %d bytes; %s\",\n-          (this->status == NULL ? \"(ignoring error) \" : \"\"),\n-          fname, static_cast<int>(bytes), s.ToString().c_str());\n-      if (this->status != NULL && this->status->ok()) *this->status = s;\n+          (this->status == nullptr ? \"(ignoring error) \" : \"\"), fname,\n+          static_cast<int>(bytes), s.ToString().c_str());\n+      if (this->status != nullptr && this->status->ok()) *this->status = s;\n     }\n   };\n \n@@ -394,32 +410,30 @@ Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log,\n   reporter.env = env_;\n   reporter.info_log = options_.info_log;\n   reporter.fname = fname.c_str();\n-  reporter.status = (options_.paranoid_checks ? &status : NULL);\n+  reporter.status = (options_.paranoid_checks ? &status : nullptr);\n   // We intentionally make log::Reader do checksumming even if\n   // paranoid_checks==false so that corruptions cause entire commits\n   // to be skipped instead of propagating bad information (like overly\n   // large sequence numbers).\n-  log::Reader reader(file, &reporter, true/*checksum*/,\n-                     0/*initial_offset*/);\n+  log::Reader reader(file, &reporter, true /*checksum*/, 0 /*initial_offset*/);\n   Log(options_.info_log, \"Recovering log #%llu\",\n-      (unsigned long long) log_number);\n+      (unsigned long long)log_number);\n \n   // Read all the records and add to a memtable\n   std::string scratch;\n   Slice record;\n   WriteBatch batch;\n   int compactions = 0;\n-  MemTable* mem = NULL;\n-  while (reader.ReadRecord(&record, &scratch) &&\n-         status.ok()) {\n+  MemTable* mem = nullptr;\n+  while (reader.ReadRecord(&record, &scratch) && status.ok()) {\n     if (record.size() < 12) {\n-      reporter.Corruption(\n-          record.size(), Status::Corruption(\"log record too small\", fname));\n+      reporter.Corruption(record.size(),\n+                          Status::Corruption(\"log record too small\", fname));\n       continue;\n     }\n     WriteBatchInternal::SetContents(&batch, record);\n \n-    if (mem == NULL) {\n+    if (mem == nullptr) {\n       mem = new MemTable(internal_comparator_);\n       mem->Ref();\n     }\n@@ -428,19 +442,18 @@ Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log,\n     if (!status.ok()) {\n       break;\n     }\n-    const SequenceNumber last_seq =\n-        WriteBatchInternal::Sequence(&batch) +\n-        WriteBatchInternal::Count(&batch) - 1;\n+    const SequenceNumber last_seq = WriteBatchInternal::Sequence(&batch) +\n+                                    WriteBatchInternal::Count(&batch) - 1;\n     if (last_seq > *max_sequence) {\n       *max_sequence = last_seq;\n     }\n \n     if (mem->ApproximateMemoryUsage() > options_.write_buffer_size) {\n       compactions++;\n       *save_manifest = true;\n-      status = WriteLevel0Table(mem, edit, NULL);\n+      status = WriteLevel0Table(mem, edit, nullptr);\n       mem->Unref();\n-      mem = NULL;\n+      mem = nullptr;\n       if (!status.ok()) {\n         // Reflect errors immediately so that conditions like full\n         // file-systems cause the DB::Open() to fail.\n@@ -453,31 +466,31 @@ Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log,\n \n   // See if we should keep reusing the last log file.\n   if (status.ok() && options_.reuse_logs && last_log && compactions == 0) {\n-    assert(logfile_ == NULL);\n-    assert(log_ == NULL);\n-    assert(mem_ == NULL);\n+    assert(logfile_ == nullptr);\n+    assert(log_ == nullptr);\n+    assert(mem_ == nullptr);\n     uint64_t lfile_size;\n     if (env_->GetFileSize(fname, &lfile_size).ok() &&\n         env_->NewAppendableFile(fname, &logfile_).ok()) {\n       Log(options_.info_log, \"Reusing old log %s \\n\", fname.c_str());\n       log_ = new log::Writer(logfile_, lfile_size);\n       logfile_number_ = log_number;\n-      if (mem != NULL) {\n+      if (mem != nullptr) {\n         mem_ = mem;\n-        mem = NULL;\n+        mem = nullptr;\n       } else {\n-        // mem can be NULL if lognum exists but was empty.\n+        // mem can be nullptr if lognum exists but was empty.\n         mem_ = new MemTable(internal_comparator_);\n         mem_->Ref();\n       }\n     }\n   }\n \n-  if (mem != NULL) {\n+  if (mem != nullptr) {\n     // mem did not get reused; compact it.\n     if (status.ok()) {\n       *save_manifest = true;\n-      status = WriteLevel0Table(mem, edit, NULL);\n+      status = WriteLevel0Table(mem, edit, nullptr);\n     }\n     mem->Unref();\n   }\n@@ -494,7 +507,7 @@ Status DBImpl::WriteLevel0Table(MemTable* mem, VersionEdit* edit,\n   pending_outputs_.insert(meta.number);\n   Iterator* iter = mem->NewIterator();\n   Log(options_.info_log, \"Level-0 table #%llu: started\",\n-      (unsigned long long) meta.number);\n+      (unsigned long long)meta.number);\n \n   Status s;\n   {\n@@ -504,24 +517,22 @@ Status DBImpl::WriteLevel0Table(MemTable* mem, VersionEdit* edit,\n   }\n \n   Log(options_.info_log, \"Level-0 table #%llu: %lld bytes %s\",\n-      (unsigned long long) meta.number,\n-      (unsigned long long) meta.file_size,\n+      (unsigned long long)meta.number, (unsigned long long)meta.file_size,\n       s.ToString().c_str());\n   delete iter;\n   pending_outputs_.erase(meta.number);\n \n-\n   // Note that if file_size is zero, the file has been deleted and\n   // should not be added to the manifest.\n   int level = 0;\n   if (s.ok() && meta.file_size > 0) {\n     const Slice min_user_key = meta.smallest.user_key();\n     const Slice max_user_key = meta.largest.user_key();\n-    if (base != NULL) {\n+    if (base != nullptr) {\n       level = base->PickLevelForMemTableOutput(min_user_key, max_user_key);\n     }\n-    edit->AddFile(level, meta.number, meta.file_size,\n-                  meta.smallest, meta.largest);\n+    edit->AddFile(level, meta.number, meta.file_size, meta.smallest,\n+                  meta.largest);\n   }\n \n   CompactionStats stats;\n@@ -533,7 +544,7 @@ Status DBImpl::WriteLevel0Table(MemTable* mem, VersionEdit* edit,\n \n void DBImpl::CompactMemTable() {\n   mutex_.AssertHeld();\n-  assert(imm_ != NULL);\n+  assert(imm_ != nullptr);\n \n   // Save the contents of the memtable as a new Table\n   VersionEdit edit;\n@@ -542,7 +553,7 @@ void DBImpl::CompactMemTable() {\n   Status s = WriteLevel0Table(imm_, &edit, base);\n   base->Unref();\n \n-  if (s.ok() && shutting_down_.Acquire_Load()) {\n+  if (s.ok() && shutting_down_.load(std::memory_order_acquire)) {\n     s = Status::IOError(\"Deleting DB during memtable compaction\");\n   }\n \n@@ -556,8 +567,8 @@ void DBImpl::CompactMemTable() {\n   if (s.ok()) {\n     // Commit to the new state\n     imm_->Unref();\n-    imm_ = NULL;\n-    has_imm_.Release_Store(NULL);\n+    imm_ = nullptr;\n+    has_imm_.store(false, std::memory_order_release);\n     DeleteObsoleteFiles();\n   } else {\n     RecordBackgroundError(s);\n@@ -575,13 +586,14 @@ void DBImpl::CompactRange(const Slice* begin, const Slice* end) {\n       }\n     }\n   }\n-  TEST_CompactMemTable(); // TODO(sanjay): Skip if memtable does not overlap\n+  TEST_CompactMemTable();  // TODO(sanjay): Skip if memtable does not overlap\n   for (int level = 0; level < max_level_with_files; level++) {\n     TEST_CompactRange(level, begin, end);\n   }\n }\n \n-void DBImpl::TEST_CompactRange(int level, const Slice* begin,const Slice* end) {\n+void DBImpl::TEST_CompactRange(int level, const Slice* begin,\n+                               const Slice* end) {\n   assert(level >= 0);\n   assert(level + 1 < config::kNumLevels);\n \n@@ -590,44 +602,45 @@ void DBImpl::TEST_CompactRange(int level, const Slice* begin,const Slice* end) {\n   ManualCompaction manual;\n   manual.level = level;\n   manual.done = false;\n-  if (begin == NULL) {\n-    manual.begin = NULL;\n+  if (begin == nullptr) {\n+    manual.begin = nullptr;\n   } else {\n     begin_storage = InternalKey(*begin, kMaxSequenceNumber, kValueTypeForSeek);\n     manual.begin = &begin_storage;\n   }\n-  if (end == NULL) {\n-    manual.end = NULL;\n+  if (end == nullptr) {\n+    manual.end = nullptr;\n   } else {\n     end_storage = InternalKey(*end, 0, static_cast<ValueType>(0));\n     manual.end = &end_storage;\n   }\n \n   MutexLock l(&mutex_);\n-  while (!manual.done && !shutting_down_.Acquire_Load() && bg_error_.ok()) {\n-    if (manual_compaction_ == NULL) {  // Idle\n+  while (!manual.done && !shutting_down_.load(std::memory_order_acquire) &&\n+         bg_error_.ok()) {\n+    if (manual_compaction_ == nullptr) {  // Idle\n       manual_compaction_ = &manual;\n       MaybeScheduleCompaction();\n     } else {  // Running either my compaction or another compaction.\n-      bg_cv_.Wait();\n+      background_work_finished_signal_.Wait();\n     }\n   }\n   if (manual_compaction_ == &manual) {\n     // Cancel my manual compaction since we aborted early for some reason.\n-    manual_compaction_ = NULL;\n+    manual_compaction_ = nullptr;\n   }\n }\n \n Status DBImpl::TEST_CompactMemTable() {\n-  // NULL batch means just wait for earlier writes to be done\n-  Status s = Write(WriteOptions(), NULL);\n+  // nullptr batch means just wait for earlier writes to be done\n+  Status s = Write(WriteOptions(), nullptr);\n   if (s.ok()) {\n     // Wait until the compaction completes\n     MutexLock l(&mutex_);\n-    while (imm_ != NULL && bg_error_.ok()) {\n-      bg_cv_.Wait();\n+    while (imm_ != nullptr && bg_error_.ok()) {\n+      background_work_finished_signal_.Wait();\n     }\n-    if (imm_ != NULL) {\n+    if (imm_ != nullptr) {\n       s = bg_error_;\n     }\n   }\n@@ -638,24 +651,23 @@ void DBImpl::RecordBackgroundError(const Status& s) {\n   mutex_.AssertHeld();\n   if (bg_error_.ok()) {\n     bg_error_ = s;\n-    bg_cv_.SignalAll();\n+    background_work_finished_signal_.SignalAll();\n   }\n }\n \n void DBImpl::MaybeScheduleCompaction() {\n   mutex_.AssertHeld();\n-  if (bg_compaction_scheduled_) {\n+  if (background_compaction_scheduled_) {\n     // Already scheduled\n-  } else if (shutting_down_.Acquire_Load()) {\n+  } else if (shutting_down_.load(std::memory_order_acquire)) {\n     // DB is being deleted; no more background compactions\n   } else if (!bg_error_.ok()) {\n     // Already got an error; no more changes\n-  } else if (imm_ == NULL &&\n-             manual_compaction_ == NULL &&\n+  } else if (imm_ == nullptr && manual_compaction_ == nullptr &&\n              !versions_->NeedsCompaction()) {\n     // No work to be done\n   } else {\n-    bg_compaction_scheduled_ = true;\n+    background_compaction_scheduled_ = true;\n     env_->Schedule(&DBImpl::BGWork, this);\n   }\n }\n@@ -666,72 +678,69 @@ void DBImpl::BGWork(void* db) {\n \n void DBImpl::BackgroundCall() {\n   MutexLock l(&mutex_);\n-  assert(bg_compaction_scheduled_);\n-  if (shutting_down_.Acquire_Load()) {\n+  assert(background_compaction_scheduled_);\n+  if (shutting_down_.load(std::memory_order_acquire)) {\n     // No more background work when shutting down.\n   } else if (!bg_error_.ok()) {\n     // No more background work after a background error.\n   } else {\n     BackgroundCompaction();\n   }\n \n-  bg_compaction_scheduled_ = false;\n+  background_compaction_scheduled_ = false;\n \n   // Previous compaction may have produced too many files in a level,\n   // so reschedule another compaction if needed.\n   MaybeScheduleCompaction();\n-  bg_cv_.SignalAll();\n+  background_work_finished_signal_.SignalAll();\n }\n \n void DBImpl::BackgroundCompaction() {\n   mutex_.AssertHeld();\n \n-  if (imm_ != NULL) {\n+  if (imm_ != nullptr) {\n     CompactMemTable();\n     return;\n   }\n \n   Compaction* c;\n-  bool is_manual = (manual_compaction_ != NULL);\n+  bool is_manual = (manual_compaction_ != nullptr);\n   InternalKey manual_end;\n   if (is_manual) {\n     ManualCompaction* m = manual_compaction_;\n     c = versions_->CompactRange(m->level, m->begin, m->end);\n-    m->done = (c == NULL);\n-    if (c != NULL) {\n+    m->done = (c == nullptr);\n+    if (c != nullptr) {\n       manual_end = c->input(0, c->num_input_files(0) - 1)->largest;\n     }\n     Log(options_.info_log,\n         \"Manual compaction at level-%d from %s .. %s; will stop at %s\\n\",\n-        m->level,\n-        (m->begin ? m->begin->DebugString().c_str() : \"(begin)\"),\n+        m->level, (m->begin ? m->begin->DebugString().c_str() : \"(begin)\"),\n         (m->end ? m->end->DebugString().c_str() : \"(end)\"),\n         (m->done ? \"(end)\" : manual_end.DebugString().c_str()));\n   } else {\n     c = versions_->PickCompaction();\n   }\n \n   Status status;\n-  if (c == NULL) {\n+  if (c == nullptr) {\n     // Nothing to do\n   } else if (!is_manual && c->IsTrivialMove()) {\n     // Move file to next level\n     assert(c->num_input_files(0) == 1);\n     FileMetaData* f = c->input(0, 0);\n     c->edit()->DeleteFile(c->level(), f->number);\n-    c->edit()->AddFile(c->level() + 1, f->number, f->file_size,\n-                       f->smallest, f->largest);\n+    c->edit()->AddFile(c->level() + 1, f->number, f->file_size, f->smallest,\n+                       f->largest);\n     status = versions_->LogAndApply(c->edit(), &mutex_);\n     if (!status.ok()) {\n       RecordBackgroundError(status);\n     }\n     VersionSet::LevelSummaryStorage tmp;\n     Log(options_.info_log, \"Moved #%lld to level-%d %lld bytes %s: %s\\n\",\n-        static_cast<unsigned long long>(f->number),\n-        c->level() + 1,\n+        static_cast<unsigned long long>(f->number), c->level() + 1,\n         static_cast<unsigned long long>(f->file_size),\n-        status.ToString().c_str(),\n-        versions_->LevelSummary(&tmp));\n+        status.ToString().c_str(), versions_->LevelSummary(&tmp));\n   } else {\n     CompactionState* compact = new CompactionState(c);\n     status = DoCompactionWork(compact);\n@@ -746,11 +755,10 @@ void DBImpl::BackgroundCompaction() {\n \n   if (status.ok()) {\n     // Done\n-  } else if (shutting_down_.Acquire_Load()) {\n+  } else if (shutting_down_.load(std::memory_order_acquire)) {\n     // Ignore compaction errors found during shutting down\n   } else {\n-    Log(options_.info_log,\n-        \"Compaction error: %s\", status.ToString().c_str());\n+    Log(options_.info_log, \"Compaction error: %s\", status.ToString().c_str());\n   }\n \n   if (is_manual) {\n@@ -764,18 +772,18 @@ void DBImpl::BackgroundCompaction() {\n       m->tmp_storage = manual_end;\n       m->begin = &m->tmp_storage;\n     }\n-    manual_compaction_ = NULL;\n+    manual_compaction_ = nullptr;\n   }\n }\n \n void DBImpl::CleanupCompaction(CompactionState* compact) {\n   mutex_.AssertHeld();\n-  if (compact->builder != NULL) {\n+  if (compact->builder != nullptr) {\n     // May happen if we get a shutdown call in the middle of compaction\n     compact->builder->Abandon();\n     delete compact->builder;\n   } else {\n-    assert(compact->outfile == NULL);\n+    assert(compact->outfile == nullptr);\n   }\n   delete compact->outfile;\n   for (size_t i = 0; i < compact->outputs.size(); i++) {\n@@ -786,8 +794,8 @@ void DBImpl::CleanupCompaction(CompactionState* compact) {\n }\n \n Status DBImpl::OpenCompactionOutputFile(CompactionState* compact) {\n-  assert(compact != NULL);\n-  assert(compact->builder == NULL);\n+  assert(compact != nullptr);\n+  assert(compact->builder == nullptr);\n   uint64_t file_number;\n   {\n     mutex_.Lock();\n@@ -812,9 +820,9 @@ Status DBImpl::OpenCompactionOutputFile(CompactionState* compact) {\n \n Status DBImpl::FinishCompactionOutputFile(CompactionState* compact,\n                                           Iterator* input) {\n-  assert(compact != NULL);\n-  assert(compact->outfile != NULL);\n-  assert(compact->builder != NULL);\n+  assert(compact != nullptr);\n+  assert(compact->outfile != nullptr);\n+  assert(compact->builder != nullptr);\n \n   const uint64_t output_number = compact->current_output()->number;\n   assert(output_number != 0);\n@@ -831,7 +839,7 @@ Status DBImpl::FinishCompactionOutputFile(CompactionState* compact,\n   compact->current_output()->file_size = current_bytes;\n   compact->total_bytes += current_bytes;\n   delete compact->builder;\n-  compact->builder = NULL;\n+  compact->builder = nullptr;\n \n   // Finish and check for file errors\n   if (s.ok()) {\n@@ -841,45 +849,38 @@ Status DBImpl::FinishCompactionOutputFile(CompactionState* compact,\n     s = compact->outfile->Close();\n   }\n   delete compact->outfile;\n-  compact->outfile = NULL;\n+  compact->outfile = nullptr;\n \n   if (s.ok() && current_entries > 0) {\n     // Verify that the table is usable\n-    Iterator* iter = table_cache_->NewIterator(ReadOptions(),\n-                                               output_number,\n-                                               current_bytes);\n+    Iterator* iter =\n+        table_cache_->NewIterator(ReadOptions(), output_number, current_bytes);\n     s = iter->status();\n     delete iter;\n     if (s.ok()) {\n-      Log(options_.info_log,\n-          \"Generated table #%llu@%d: %lld keys, %lld bytes\",\n-          (unsigned long long) output_number,\n-          compact->compaction->level(),\n-          (unsigned long long) current_entries,\n-          (unsigned long long) current_bytes);\n+      Log(options_.info_log, \"Generated table #%llu@%d: %lld keys, %lld bytes\",\n+          (unsigned long long)output_number, compact->compaction->level(),\n+          (unsigned long long)current_entries,\n+          (unsigned long long)current_bytes);\n     }\n   }\n   return s;\n }\n \n-\n Status DBImpl::InstallCompactionResults(CompactionState* compact) {\n   mutex_.AssertHeld();\n-  Log(options_.info_log,  \"Compacted %d@%d + %d@%d files => %lld bytes\",\n-      compact->compaction->num_input_files(0),\n-      compact->compaction->level(),\n-      compact->compaction->num_input_files(1),\n-      compact->compaction->level() + 1,\n+  Log(options_.info_log, \"Compacted %d@%d + %d@%d files => %lld bytes\",\n+      compact->compaction->num_input_files(0), compact->compaction->level(),\n+      compact->compaction->num_input_files(1), compact->compaction->level() + 1,\n       static_cast<long long>(compact->total_bytes));\n \n   // Add compaction outputs\n   compact->compaction->AddInputDeletions(compact->compaction->edit());\n   const int level = compact->compaction->level();\n   for (size_t i = 0; i < compact->outputs.size(); i++) {\n     const CompactionState::Output& out = compact->outputs[i];\n-    compact->compaction->edit()->AddFile(\n-        level + 1,\n-        out.number, out.file_size, out.smallest, out.largest);\n+    compact->compaction->edit()->AddFile(level + 1, out.number, out.file_size,\n+                                         out.smallest, out.largest);\n   }\n   return versions_->LogAndApply(compact->compaction->edit(), &mutex_);\n }\n@@ -888,47 +889,48 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n   const uint64_t start_micros = env_->NowMicros();\n   int64_t imm_micros = 0;  // Micros spent doing imm_ compactions\n \n-  Log(options_.info_log,  \"Compacting %d@%d + %d@%d files\",\n-      compact->compaction->num_input_files(0),\n-      compact->compaction->level(),\n+  Log(options_.info_log, \"Compacting %d@%d + %d@%d files\",\n+      compact->compaction->num_input_files(0), compact->compaction->level(),\n       compact->compaction->num_input_files(1),\n       compact->compaction->level() + 1);\n \n   assert(versions_->NumLevelFiles(compact->compaction->level()) > 0);\n-  assert(compact->builder == NULL);\n-  assert(compact->outfile == NULL);\n+  assert(compact->builder == nullptr);\n+  assert(compact->outfile == nullptr);\n   if (snapshots_.empty()) {\n     compact->smallest_snapshot = versions_->LastSequence();\n   } else {\n-    compact->smallest_snapshot = snapshots_.oldest()->number_;\n+    compact->smallest_snapshot = snapshots_.oldest()->sequence_number();\n   }\n \n+  Iterator* input = versions_->MakeInputIterator(compact->compaction);\n+\n   // Release mutex while we're actually doing the compaction work\n   mutex_.Unlock();\n \n-  Iterator* input = versions_->MakeInputIterator(compact->compaction);\n   input->SeekToFirst();\n   Status status;\n   ParsedInternalKey ikey;\n   std::string current_user_key;\n   bool has_current_user_key = false;\n   SequenceNumber last_sequence_for_key = kMaxSequenceNumber;\n-  for (; input->Valid() && !shutting_down_.Acquire_Load(); ) {\n+  while (input->Valid() && !shutting_down_.load(std::memory_order_acquire)) {\n     // Prioritize immutable compaction work\n-    if (has_imm_.NoBarrier_Load() != NULL) {\n+    if (has_imm_.load(std::memory_order_relaxed)) {\n       const uint64_t imm_start = env_->NowMicros();\n       mutex_.Lock();\n-      if (imm_ != NULL) {\n+      if (imm_ != nullptr) {\n         CompactMemTable();\n-        bg_cv_.SignalAll();  // Wakeup MakeRoomForWrite() if necessary\n+        // Wake up MakeRoomForWrite() if necessary.\n+        background_work_finished_signal_.SignalAll();\n       }\n       mutex_.Unlock();\n       imm_micros += (env_->NowMicros() - imm_start);\n     }\n \n     Slice key = input->key();\n     if (compact->compaction->ShouldStopBefore(key) &&\n-        compact->builder != NULL) {\n+        compact->builder != nullptr) {\n       status = FinishCompactionOutputFile(compact, input);\n       if (!status.ok()) {\n         break;\n@@ -944,8 +946,8 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n       last_sequence_for_key = kMaxSequenceNumber;\n     } else {\n       if (!has_current_user_key ||\n-          user_comparator()->Compare(ikey.user_key,\n-                                     Slice(current_user_key)) != 0) {\n+          user_comparator()->Compare(ikey.user_key, Slice(current_user_key)) !=\n+              0) {\n         // First occurrence of this user key\n         current_user_key.assign(ikey.user_key.data(), ikey.user_key.size());\n         has_current_user_key = true;\n@@ -954,7 +956,7 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n \n       if (last_sequence_for_key <= compact->smallest_snapshot) {\n         // Hidden by an newer entry for same user key\n-        drop = true;    // (A)\n+        drop = true;  // (A)\n       } else if (ikey.type == kTypeDeletion &&\n                  ikey.sequence <= compact->smallest_snapshot &&\n                  compact->compaction->IsBaseLevelForKey(ikey.user_key)) {\n@@ -982,7 +984,7 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n \n     if (!drop) {\n       // Open output file if necessary\n-      if (compact->builder == NULL) {\n+      if (compact->builder == nullptr) {\n         status = OpenCompactionOutputFile(compact);\n         if (!status.ok()) {\n           break;\n@@ -1007,17 +1009,17 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n     input->Next();\n   }\n \n-  if (status.ok() && shutting_down_.Acquire_Load()) {\n+  if (status.ok() && shutting_down_.load(std::memory_order_acquire)) {\n     status = Status::IOError(\"Deleting DB during compaction\");\n   }\n-  if (status.ok() && compact->builder != NULL) {\n+  if (status.ok() && compact->builder != nullptr) {\n     status = FinishCompactionOutputFile(compact, input);\n   }\n   if (status.ok()) {\n     status = input->status();\n   }\n   delete input;\n-  input = NULL;\n+  input = nullptr;\n \n   CompactionStats stats;\n   stats.micros = env_->NowMicros() - start_micros - imm_micros;\n@@ -1040,42 +1042,45 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n     RecordBackgroundError(status);\n   }\n   VersionSet::LevelSummaryStorage tmp;\n-  Log(options_.info_log,\n-      \"compacted to: %s\", versions_->LevelSummary(&tmp));\n+  Log(options_.info_log, \"compacted to: %s\", versions_->LevelSummary(&tmp));\n   return status;\n }\n \n namespace {\n+\n struct IterState {\n-  port::Mutex* mu;\n-  Version* version;\n-  MemTable* mem;\n-  MemTable* imm;\n+  port::Mutex* const mu;\n+  Version* const version GUARDED_BY(mu);\n+  MemTable* const mem GUARDED_BY(mu);\n+  MemTable* const imm GUARDED_BY(mu);\n+\n+  IterState(port::Mutex* mutex, MemTable* mem, MemTable* imm, Version* version)\n+      : mu(mutex), version(version), mem(mem), imm(imm) {}\n };\n \n static void CleanupIteratorState(void* arg1, void* arg2) {\n   IterState* state = reinterpret_cast<IterState*>(arg1);\n   state->mu->Lock();\n   state->mem->Unref();\n-  if (state->imm != NULL) state->imm->Unref();\n+  if (state->imm != nullptr) state->imm->Unref();\n   state->version->Unref();\n   state->mu->Unlock();\n   delete state;\n }\n-}  // namespace\n+\n+}  // anonymous namespace\n \n Iterator* DBImpl::NewInternalIterator(const ReadOptions& options,\n                                       SequenceNumber* latest_snapshot,\n                                       uint32_t* seed) {\n-  IterState* cleanup = new IterState;\n   mutex_.Lock();\n   *latest_snapshot = versions_->LastSequence();\n \n   // Collect together all needed child iterators\n   std::vector<Iterator*> list;\n   list.push_back(mem_->NewIterator());\n   mem_->Ref();\n-  if (imm_ != NULL) {\n+  if (imm_ != nullptr) {\n     list.push_back(imm_->NewIterator());\n     imm_->Ref();\n   }\n@@ -1084,11 +1089,8 @@ Iterator* DBImpl::NewInternalIterator(const ReadOptions& options,\n       NewMergingIterator(&internal_comparator_, &list[0], list.size());\n   versions_->current()->Ref();\n \n-  cleanup->mu = &mutex_;\n-  cleanup->mem = mem_;\n-  cleanup->imm = imm_;\n-  cleanup->version = versions_->current();\n-  internal_iter->RegisterCleanup(CleanupIteratorState, cleanup, NULL);\n+  IterState* cleanup = new IterState(&mutex_, mem_, imm_, versions_->current());\n+  internal_iter->RegisterCleanup(CleanupIteratorState, cleanup, nullptr);\n \n   *seed = ++seed_;\n   mutex_.Unlock();\n@@ -1106,14 +1108,14 @@ int64_t DBImpl::TEST_MaxNextLevelOverlappingBytes() {\n   return versions_->MaxNextLevelOverlappingBytes();\n }\n \n-Status DBImpl::Get(const ReadOptions& options,\n-                   const Slice& key,\n+Status DBImpl::Get(const ReadOptions& options, const Slice& key,\n                    std::string* value) {\n   Status s;\n   MutexLock l(&mutex_);\n   SequenceNumber snapshot;\n-  if (options.snapshot != NULL) {\n-    snapshot = reinterpret_cast<const SnapshotImpl*>(options.snapshot)->number_;\n+  if (options.snapshot != nullptr) {\n+    snapshot =\n+        static_cast<const SnapshotImpl*>(options.snapshot)->sequence_number();\n   } else {\n     snapshot = versions_->LastSequence();\n   }\n@@ -1122,7 +1124,7 @@ Status DBImpl::Get(const ReadOptions& options,\n   MemTable* imm = imm_;\n   Version* current = versions_->current();\n   mem->Ref();\n-  if (imm != NULL) imm->Ref();\n+  if (imm != nullptr) imm->Ref();\n   current->Ref();\n \n   bool have_stat_update = false;\n@@ -1135,7 +1137,7 @@ Status DBImpl::Get(const ReadOptions& options,\n     LookupKey lkey(key, snapshot);\n     if (mem->Get(lkey, value, &s)) {\n       // Done\n-    } else if (imm != NULL && imm->Get(lkey, value, &s)) {\n+    } else if (imm != nullptr && imm->Get(lkey, value, &s)) {\n       // Done\n     } else {\n       s = current->Get(options, lkey, value, &stats);\n@@ -1148,7 +1150,7 @@ Status DBImpl::Get(const ReadOptions& options,\n     MaybeScheduleCompaction();\n   }\n   mem->Unref();\n-  if (imm != NULL) imm->Unref();\n+  if (imm != nullptr) imm->Unref();\n   current->Unref();\n   return s;\n }\n@@ -1157,12 +1159,12 @@ Iterator* DBImpl::NewIterator(const ReadOptions& options) {\n   SequenceNumber latest_snapshot;\n   uint32_t seed;\n   Iterator* iter = NewInternalIterator(options, &latest_snapshot, &seed);\n-  return NewDBIterator(\n-      this, user_comparator(), iter,\n-      (options.snapshot != NULL\n-       ? reinterpret_cast<const SnapshotImpl*>(options.snapshot)->number_\n-       : latest_snapshot),\n-      seed);\n+  return NewDBIterator(this, user_comparator(), iter,\n+                       (options.snapshot != nullptr\n+                            ? static_cast<const SnapshotImpl*>(options.snapshot)\n+                                  ->sequence_number()\n+                            : latest_snapshot),\n+                       seed);\n }\n \n void DBImpl::RecordReadSample(Slice key) {\n@@ -1177,9 +1179,9 @@ const Snapshot* DBImpl::GetSnapshot() {\n   return snapshots_.New(versions_->LastSequence());\n }\n \n-void DBImpl::ReleaseSnapshot(const Snapshot* s) {\n+void DBImpl::ReleaseSnapshot(const Snapshot* snapshot) {\n   MutexLock l(&mutex_);\n-  snapshots_.Delete(reinterpret_cast<const SnapshotImpl*>(s));\n+  snapshots_.Delete(static_cast<const SnapshotImpl*>(snapshot));\n }\n \n // Convenience methods\n@@ -1191,9 +1193,9 @@ Status DBImpl::Delete(const WriteOptions& options, const Slice& key) {\n   return DB::Delete(options, key);\n }\n \n-Status DBImpl::Write(const WriteOptions& options, WriteBatch* my_batch) {\n+Status DBImpl::Write(const WriteOptions& options, WriteBatch* updates) {\n   Writer w(&mutex_);\n-  w.batch = my_batch;\n+  w.batch = updates;\n   w.sync = options.sync;\n   w.done = false;\n \n@@ -1207,21 +1209,21 @@ Status DBImpl::Write(const WriteOptions& options, WriteBatch* my_batch) {\n   }\n \n   // May temporarily unlock and wait.\n-  Status status = MakeRoomForWrite(my_batch == NULL);\n+  Status status = MakeRoomForWrite(updates == nullptr);\n   uint64_t last_sequence = versions_->LastSequence();\n   Writer* last_writer = &w;\n-  if (status.ok() && my_batch != NULL) {  // NULL batch is for compactions\n-    WriteBatch* updates = BuildBatchGroup(&last_writer);\n-    WriteBatchInternal::SetSequence(updates, last_sequence + 1);\n-    last_sequence += WriteBatchInternal::Count(updates);\n+  if (status.ok() && updates != nullptr) {  // nullptr batch is for compactions\n+    WriteBatch* write_batch = BuildBatchGroup(&last_writer);\n+    WriteBatchInternal::SetSequence(write_batch, last_sequence + 1);\n+    last_sequence += WriteBatchInternal::Count(write_batch);\n \n     // Add to log and apply to memtable.  We can release the lock\n     // during this phase since &w is currently responsible for logging\n     // and protects against concurrent loggers and concurrent writes\n     // into mem_.\n     {\n       mutex_.Unlock();\n-      status = log_->AddRecord(WriteBatchInternal::Contents(updates));\n+      status = log_->AddRecord(WriteBatchInternal::Contents(write_batch));\n       bool sync_error = false;\n       if (status.ok() && options.sync) {\n         status = logfile_->Sync();\n@@ -1230,7 +1232,7 @@ Status DBImpl::Write(const WriteOptions& options, WriteBatch* my_batch) {\n         }\n       }\n       if (status.ok()) {\n-        status = WriteBatchInternal::InsertInto(updates, mem_);\n+        status = WriteBatchInternal::InsertInto(write_batch, mem_);\n       }\n       mutex_.Lock();\n       if (sync_error) {\n@@ -1240,7 +1242,7 @@ Status DBImpl::Write(const WriteOptions& options, WriteBatch* my_batch) {\n         RecordBackgroundError(status);\n       }\n     }\n-    if (updates == tmp_batch_) tmp_batch_->Clear();\n+    if (write_batch == tmp_batch_) tmp_batch_->Clear();\n \n     versions_->SetLastSequence(last_sequence);\n   }\n@@ -1265,21 +1267,22 @@ Status DBImpl::Write(const WriteOptions& options, WriteBatch* my_batch) {\n }\n \n // REQUIRES: Writer list must be non-empty\n-// REQUIRES: First writer must have a non-NULL batch\n+// REQUIRES: First writer must have a non-null batch\n WriteBatch* DBImpl::BuildBatchGroup(Writer** last_writer) {\n+  mutex_.AssertHeld();\n   assert(!writers_.empty());\n   Writer* first = writers_.front();\n   WriteBatch* result = first->batch;\n-  assert(result != NULL);\n+  assert(result != nullptr);\n \n   size_t size = WriteBatchInternal::ByteSize(first->batch);\n \n   // Allow the group to grow up to a maximum size, but if the\n   // original write is small, limit the growth so we do not slow\n   // down the small write too much.\n   size_t max_size = 1 << 20;\n-  if (size <= (128<<10)) {\n-    max_size = size + (128<<10);\n+  if (size <= (128 << 10)) {\n+    max_size = size + (128 << 10);\n   }\n \n   *last_writer = first;\n@@ -1292,7 +1295,7 @@ WriteBatch* DBImpl::BuildBatchGroup(Writer** last_writer) {\n       break;\n     }\n \n-    if (w->batch != NULL) {\n+    if (w->batch != nullptr) {\n       size += WriteBatchInternal::ByteSize(w->batch);\n       if (size > max_size) {\n         // Do not make batch too big\n@@ -1325,9 +1328,8 @@ Status DBImpl::MakeRoomForWrite(bool force) {\n       // Yield previous error\n       s = bg_error_;\n       break;\n-    } else if (\n-        allow_delay &&\n-        versions_->NumLevelFiles(0) >= config::kL0_SlowdownWritesTrigger) {\n+    } else if (allow_delay && versions_->NumLevelFiles(0) >=\n+                                  config::kL0_SlowdownWritesTrigger) {\n       // We are getting close to hitting a hard limit on the number of\n       // L0 files.  Rather than delaying a single write by several\n       // seconds when we hit the hard limit, start delaying each\n@@ -1342,20 +1344,20 @@ Status DBImpl::MakeRoomForWrite(bool force) {\n                (mem_->ApproximateMemoryUsage() <= options_.write_buffer_size)) {\n       // There is room in current memtable\n       break;\n-    } else if (imm_ != NULL) {\n+    } else if (imm_ != nullptr) {\n       // We have filled up the current memtable, but the previous\n       // one is still being compacted, so we wait.\n       Log(options_.info_log, \"Current memtable full; waiting...\\n\");\n-      bg_cv_.Wait();\n+      background_work_finished_signal_.Wait();\n     } else if (versions_->NumLevelFiles(0) >= config::kL0_StopWritesTrigger) {\n       // There are too many level-0 files.\n       Log(options_.info_log, \"Too many L0 files; waiting...\\n\");\n-      bg_cv_.Wait();\n+      background_work_finished_signal_.Wait();\n     } else {\n       // Attempt to switch to a new memtable and trigger compaction of old\n       assert(versions_->PrevLogNumber() == 0);\n       uint64_t new_log_number = versions_->NewFileNumber();\n-      WritableFile* lfile = NULL;\n+      WritableFile* lfile = nullptr;\n       s = env_->NewWritableFile(LogFileName(dbname_, new_log_number), &lfile);\n       if (!s.ok()) {\n         // Avoid chewing through file number space in a tight loop.\n@@ -1368,10 +1370,10 @@ Status DBImpl::MakeRoomForWrite(bool force) {\n       logfile_number_ = new_log_number;\n       log_ = new log::Writer(lfile);\n       imm_ = mem_;\n-      has_imm_.Release_Store(imm_);\n+      has_imm_.store(true, std::memory_order_release);\n       mem_ = new MemTable(internal_comparator_);\n       mem_->Ref();\n-      force = false;   // Do not force another compaction if have room\n+      force = false;  // Do not force another compaction if have room\n       MaybeScheduleCompaction();\n     }\n   }\n@@ -1405,21 +1407,16 @@ bool DBImpl::GetProperty(const Slice& property, std::string* value) {\n     snprintf(buf, sizeof(buf),\n              \"                               Compactions\\n\"\n              \"Level  Files Size(MB) Time(sec) Read(MB) Write(MB)\\n\"\n-             \"--------------------------------------------------\\n\"\n-             );\n+             \"--------------------------------------------------\\n\");\n     value->append(buf);\n     for (int level = 0; level < config::kNumLevels; level++) {\n       int files = versions_->NumLevelFiles(level);\n       if (stats_[level].micros > 0 || files > 0) {\n-        snprintf(\n-            buf, sizeof(buf),\n-            \"%3d %8d %8.0f %9.0f %8.0f %9.0f\\n\",\n-            level,\n-            files,\n-            versions_->NumLevelBytes(level) / 1048576.0,\n-            stats_[level].micros / 1e6,\n-            stats_[level].bytes_read / 1048576.0,\n-            stats_[level].bytes_written / 1048576.0);\n+        snprintf(buf, sizeof(buf), \"%3d %8d %8.0f %9.0f %8.0f %9.0f\\n\", level,\n+                 files, versions_->NumLevelBytes(level) / 1048576.0,\n+                 stats_[level].micros / 1e6,\n+                 stats_[level].bytes_read / 1048576.0,\n+                 stats_[level].bytes_written / 1048576.0);\n         value->append(buf);\n       }\n     }\n@@ -1445,16 +1442,11 @@ bool DBImpl::GetProperty(const Slice& property, std::string* value) {\n   return false;\n }\n \n-void DBImpl::GetApproximateSizes(\n-    const Range* range, int n,\n-    uint64_t* sizes) {\n+void DBImpl::GetApproximateSizes(const Range* range, int n, uint64_t* sizes) {\n   // TODO(opt): better implementation\n-  Version* v;\n-  {\n-    MutexLock l(&mutex_);\n-    versions_->current()->Ref();\n-    v = versions_->current();\n-  }\n+  MutexLock l(&mutex_);\n+  Version* v = versions_->current();\n+  v->Ref();\n \n   for (int i = 0; i < n; i++) {\n     // Convert user_key into a corresponding internal key.\n@@ -1465,10 +1457,7 @@ void DBImpl::GetApproximateSizes(\n     sizes[i] = (limit >= start ? limit - start : 0);\n   }\n \n-  {\n-    MutexLock l(&mutex_);\n-    v->Unref();\n-  }\n+  v->Unref();\n }\n \n // Default implementations of convenience methods that subclasses of DB\n@@ -1485,19 +1474,18 @@ Status DB::Delete(const WriteOptions& opt, const Slice& key) {\n   return Write(opt, &batch);\n }\n \n-DB::~DB() { }\n+DB::~DB() = default;\n \n-Status DB::Open(const Options& options, const std::string& dbname,\n-                DB** dbptr) {\n-  *dbptr = NULL;\n+Status DB::Open(const Options& options, const std::string& dbname, DB** dbptr) {\n+  *dbptr = nullptr;\n \n   DBImpl* impl = new DBImpl(options, dbname);\n   impl->mutex_.Lock();\n   VersionEdit edit;\n   // Recover handles create_if_missing, error_if_exists\n   bool save_manifest = false;\n   Status s = impl->Recover(&edit, &save_manifest);\n-  if (s.ok() && impl->mem_ == NULL) {\n+  if (s.ok() && impl->mem_ == nullptr) {\n     // Create new log and a corresponding memtable.\n     uint64_t new_log_number = impl->versions_->NewFileNumber();\n     WritableFile* lfile;\n@@ -1523,29 +1511,28 @@ Status DB::Open(const Options& options, const std::string& dbname,\n   }\n   impl->mutex_.Unlock();\n   if (s.ok()) {\n-    assert(impl->mem_ != NULL);\n+    assert(impl->mem_ != nullptr);\n     *dbptr = impl;\n   } else {\n     delete impl;\n   }\n   return s;\n }\n \n-Snapshot::~Snapshot() {\n-}\n+Snapshot::~Snapshot() = default;\n \n Status DestroyDB(const std::string& dbname, const Options& options) {\n   Env* env = options.env;\n   std::vector<std::string> filenames;\n-  // Ignore error in case directory does not exist\n-  env->GetChildren(dbname, &filenames);\n-  if (filenames.empty()) {\n+  Status result = env->GetChildren(dbname, &filenames);\n+  if (!result.ok()) {\n+    // Ignore error in case directory does not exist\n     return Status::OK();\n   }\n \n   FileLock* lock;\n   const std::string lockname = LockFileName(dbname);\n-  Status result = env->LockFile(lockname, &lock);\n+  result = env->LockFile(lockname, &lock);\n   if (result.ok()) {\n     uint64_t number;\n     FileType type;"
      },
      {
        "sha": "685735c733f9984386fc393cf2dbd85d5a988ade",
        "filename": "db/db_impl.h",
        "status": "modified",
        "additions": 76,
        "deletions": 70,
        "changes": 146,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/db_impl.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/db_impl.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/db_impl.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -5,8 +5,11 @@\n #ifndef STORAGE_LEVELDB_DB_DB_IMPL_H_\n #define STORAGE_LEVELDB_DB_DB_IMPL_H_\n \n+#include <atomic>\n #include <deque>\n #include <set>\n+#include <string>\n+\n #include \"db/dbformat.h\"\n #include \"db/log_writer.h\"\n #include \"db/snapshot.h\"\n@@ -26,21 +29,25 @@ class VersionSet;\n class DBImpl : public DB {\n  public:\n   DBImpl(const Options& options, const std::string& dbname);\n-  virtual ~DBImpl();\n+\n+  DBImpl(const DBImpl&) = delete;\n+  DBImpl& operator=(const DBImpl&) = delete;\n+\n+  ~DBImpl() override;\n \n   // Implementations of the DB interface\n-  virtual Status Put(const WriteOptions&, const Slice& key, const Slice& value);\n-  virtual Status Delete(const WriteOptions&, const Slice& key);\n-  virtual Status Write(const WriteOptions& options, WriteBatch* updates);\n-  virtual Status Get(const ReadOptions& options,\n-                     const Slice& key,\n-                     std::string* value);\n-  virtual Iterator* NewIterator(const ReadOptions&);\n-  virtual const Snapshot* GetSnapshot();\n-  virtual void ReleaseSnapshot(const Snapshot* snapshot);\n-  virtual bool GetProperty(const Slice& property, std::string* value);\n-  virtual void GetApproximateSizes(const Range* range, int n, uint64_t* sizes);\n-  virtual void CompactRange(const Slice* begin, const Slice* end);\n+  Status Put(const WriteOptions&, const Slice& key,\n+             const Slice& value) override;\n+  Status Delete(const WriteOptions&, const Slice& key) override;\n+  Status Write(const WriteOptions& options, WriteBatch* updates) override;\n+  Status Get(const ReadOptions& options, const Slice& key,\n+             std::string* value) override;\n+  Iterator* NewIterator(const ReadOptions&) override;\n+  const Snapshot* GetSnapshot() override;\n+  void ReleaseSnapshot(const Snapshot* snapshot) override;\n+  bool GetProperty(const Slice& property, std::string* value) override;\n+  void GetApproximateSizes(const Range* range, int n, uint64_t* sizes) override;\n+  void CompactRange(const Slice* begin, const Slice* end) override;\n \n   // Extra methods (for testing) that are not in the public DB interface\n \n@@ -69,6 +76,31 @@ class DBImpl : public DB {\n   struct CompactionState;\n   struct Writer;\n \n+  // Information for a manual compaction\n+  struct ManualCompaction {\n+    int level;\n+    bool done;\n+    const InternalKey* begin;  // null means beginning of key range\n+    const InternalKey* end;    // null means end of key range\n+    InternalKey tmp_storage;   // Used to keep track of compaction progress\n+  };\n+\n+  // Per level compaction stats.  stats_[level] stores the stats for\n+  // compactions that produced data for the specified \"level\".\n+  struct CompactionStats {\n+    CompactionStats() : micros(0), bytes_read(0), bytes_written(0) {}\n+\n+    void Add(const CompactionStats& c) {\n+      this->micros += c.micros;\n+      this->bytes_read += c.bytes_read;\n+      this->bytes_written += c.bytes_written;\n+    }\n+\n+    int64_t micros;\n+    int64_t bytes_read;\n+    int64_t bytes_written;\n+  };\n+\n   Iterator* NewInternalIterator(const ReadOptions&,\n                                 SequenceNumber* latest_snapshot,\n                                 uint32_t* seed);\n@@ -84,7 +116,7 @@ class DBImpl : public DB {\n   void MaybeIgnoreError(Status* s) const;\n \n   // Delete any unneeded files and stale in-memory entries.\n-  void DeleteObsoleteFiles();\n+  void DeleteObsoleteFiles() EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n   // Compact the in-memory write buffer to disk.  Switches to a new\n   // log-file/memtable and writes a new descriptor iff successful.\n@@ -100,14 +132,15 @@ class DBImpl : public DB {\n \n   Status MakeRoomForWrite(bool force /* compact even if there is room? */)\n       EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n-  WriteBatch* BuildBatchGroup(Writer** last_writer);\n+  WriteBatch* BuildBatchGroup(Writer** last_writer)\n+      EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n   void RecordBackgroundError(const Status& s);\n \n   void MaybeScheduleCompaction() EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n   static void BGWork(void* db);\n   void BackgroundCall();\n-  void  BackgroundCompaction() EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n+  void BackgroundCompaction() EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n   void CleanupCompaction(CompactionState* compact)\n       EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n   Status DoCompactionWork(CompactionState* compact)\n@@ -118,93 +151,66 @@ class DBImpl : public DB {\n   Status InstallCompactionResults(CompactionState* compact)\n       EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n+  const Comparator* user_comparator() const {\n+    return internal_comparator_.user_comparator();\n+  }\n+\n   // Constant after construction\n   Env* const env_;\n   const InternalKeyComparator internal_comparator_;\n   const InternalFilterPolicy internal_filter_policy_;\n   const Options options_;  // options_.comparator == &internal_comparator_\n-  bool owns_info_log_;\n-  bool owns_cache_;\n+  const bool owns_info_log_;\n+  const bool owns_cache_;\n   const std::string dbname_;\n \n   // table_cache_ provides its own synchronization\n-  TableCache* table_cache_;\n+  TableCache* const table_cache_;\n \n-  // Lock over the persistent DB state.  Non-NULL iff successfully acquired.\n+  // Lock over the persistent DB state.  Non-null iff successfully acquired.\n   FileLock* db_lock_;\n \n   // State below is protected by mutex_\n   port::Mutex mutex_;\n-  port::AtomicPointer shutting_down_;\n-  port::CondVar bg_cv_;          // Signalled when background work finishes\n+  std::atomic<bool> shutting_down_;\n+  port::CondVar background_work_finished_signal_ GUARDED_BY(mutex_);\n   MemTable* mem_;\n-  MemTable* imm_;                // Memtable being compacted\n-  port::AtomicPointer has_imm_;  // So bg thread can detect non-NULL imm_\n+  MemTable* imm_ GUARDED_BY(mutex_);  // Memtable being compacted\n+  std::atomic<bool> has_imm_;         // So bg thread can detect non-null imm_\n   WritableFile* logfile_;\n-  uint64_t logfile_number_;\n+  uint64_t logfile_number_ GUARDED_BY(mutex_);\n   log::Writer* log_;\n-  uint32_t seed_;                // For sampling.\n+  uint32_t seed_ GUARDED_BY(mutex_);  // For sampling.\n \n   // Queue of writers.\n-  std::deque<Writer*> writers_;\n-  WriteBatch* tmp_batch_;\n+  std::deque<Writer*> writers_ GUARDED_BY(mutex_);\n+  WriteBatch* tmp_batch_ GUARDED_BY(mutex_);\n \n-  SnapshotList snapshots_;\n+  SnapshotList snapshots_ GUARDED_BY(mutex_);\n \n   // Set of table files to protect from deletion because they are\n   // part of ongoing compactions.\n-  std::set<uint64_t> pending_outputs_;\n+  std::set<uint64_t> pending_outputs_ GUARDED_BY(mutex_);\n \n   // Has a background compaction been scheduled or is running?\n-  bool bg_compaction_scheduled_;\n+  bool background_compaction_scheduled_ GUARDED_BY(mutex_);\n \n-  // Information for a manual compaction\n-  struct ManualCompaction {\n-    int level;\n-    bool done;\n-    const InternalKey* begin;   // NULL means beginning of key range\n-    const InternalKey* end;     // NULL means end of key range\n-    InternalKey tmp_storage;    // Used to keep track of compaction progress\n-  };\n-  ManualCompaction* manual_compaction_;\n+  ManualCompaction* manual_compaction_ GUARDED_BY(mutex_);\n \n-  VersionSet* versions_;\n+  VersionSet* const versions_ GUARDED_BY(mutex_);\n \n   // Have we encountered a background error in paranoid mode?\n-  Status bg_error_;\n-\n-  // Per level compaction stats.  stats_[level] stores the stats for\n-  // compactions that produced data for the specified \"level\".\n-  struct CompactionStats {\n-    int64_t micros;\n-    int64_t bytes_read;\n-    int64_t bytes_written;\n-\n-    CompactionStats() : micros(0), bytes_read(0), bytes_written(0) { }\n+  Status bg_error_ GUARDED_BY(mutex_);\n \n-    void Add(const CompactionStats& c) {\n-      this->micros += c.micros;\n-      this->bytes_read += c.bytes_read;\n-      this->bytes_written += c.bytes_written;\n-    }\n-  };\n-  CompactionStats stats_[config::kNumLevels];\n-\n-  // No copying allowed\n-  DBImpl(const DBImpl&);\n-  void operator=(const DBImpl&);\n-\n-  const Comparator* user_comparator() const {\n-    return internal_comparator_.user_comparator();\n-  }\n+  CompactionStats stats_[config::kNumLevels] GUARDED_BY(mutex_);\n };\n \n // Sanitize db options.  The caller should delete result.info_log if\n // it is not equal to src.info_log.\n-extern Options SanitizeOptions(const std::string& db,\n-                               const InternalKeyComparator* icmp,\n-                               const InternalFilterPolicy* ipolicy,\n-                               const Options& src);\n+Options SanitizeOptions(const std::string& db,\n+                        const InternalKeyComparator* icmp,\n+                        const InternalFilterPolicy* ipolicy,\n+                        const Options& src);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "98715a950235b506c9d752ce1be5f680f01cc601",
        "filename": "db/db_iter.cc",
        "status": "modified",
        "additions": 47,
        "deletions": 46,
        "changes": 93,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/db_iter.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/db_iter.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/db_iter.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -4,9 +4,9 @@\n \n #include \"db/db_iter.h\"\n \n-#include \"db/filename.h\"\n #include \"db/db_impl.h\"\n #include \"db/dbformat.h\"\n+#include \"db/filename.h\"\n #include \"leveldb/env.h\"\n #include \"leveldb/iterator.h\"\n #include \"port/port.h\"\n@@ -36,17 +36,14 @@ namespace {\n // combines multiple entries for the same userkey found in the DB\n // representation into a single entry while accounting for sequence\n // numbers, deletion markers, overwrites, etc.\n-class DBIter: public Iterator {\n+class DBIter : public Iterator {\n  public:\n   // Which direction is the iterator currently moving?\n   // (1) When moving forward, the internal iterator is positioned at\n   //     the exact entry that yields this->key(), this->value()\n   // (2) When moving backwards, the internal iterator is positioned\n   //     just before all entries whose user key == this->key().\n-  enum Direction {\n-    kForward,\n-    kReverse\n-  };\n+  enum Direction { kForward, kReverse };\n \n   DBIter(DBImpl* db, const Comparator* cmp, Iterator* iter, SequenceNumber s,\n          uint32_t seed)\n@@ -57,33 +54,34 @@ class DBIter: public Iterator {\n         direction_(kForward),\n         valid_(false),\n         rnd_(seed),\n-        bytes_counter_(RandomPeriod()) {\n-  }\n-  virtual ~DBIter() {\n-    delete iter_;\n-  }\n-  virtual bool Valid() const { return valid_; }\n-  virtual Slice key() const {\n+        bytes_until_read_sampling_(RandomCompactionPeriod()) {}\n+\n+  DBIter(const DBIter&) = delete;\n+  DBIter& operator=(const DBIter&) = delete;\n+\n+  ~DBIter() override { delete iter_; }\n+  bool Valid() const override { return valid_; }\n+  Slice key() const override {\n     assert(valid_);\n     return (direction_ == kForward) ? ExtractUserKey(iter_->key()) : saved_key_;\n   }\n-  virtual Slice value() const {\n+  Slice value() const override {\n     assert(valid_);\n     return (direction_ == kForward) ? iter_->value() : saved_value_;\n   }\n-  virtual Status status() const {\n+  Status status() const override {\n     if (status_.ok()) {\n       return iter_->status();\n     } else {\n       return status_;\n     }\n   }\n \n-  virtual void Next();\n-  virtual void Prev();\n-  virtual void Seek(const Slice& target);\n-  virtual void SeekToFirst();\n-  virtual void SeekToLast();\n+  void Next() override;\n+  void Prev() override;\n+  void Seek(const Slice& target) override;\n+  void SeekToFirst() override;\n+  void SeekToLast() override;\n \n  private:\n   void FindNextUserEntry(bool skipping, std::string* skip);\n@@ -103,38 +101,35 @@ class DBIter: public Iterator {\n     }\n   }\n \n-  // Pick next gap with average value of config::kReadBytesPeriod.\n-  ssize_t RandomPeriod() {\n-    return rnd_.Uniform(2*config::kReadBytesPeriod);\n+  // Picks the number of bytes that can be read until a compaction is scheduled.\n+  size_t RandomCompactionPeriod() {\n+    return rnd_.Uniform(2 * config::kReadBytesPeriod);\n   }\n \n   DBImpl* db_;\n   const Comparator* const user_comparator_;\n   Iterator* const iter_;\n   SequenceNumber const sequence_;\n-\n   Status status_;\n-  std::string saved_key_;     // == current key when direction_==kReverse\n-  std::string saved_value_;   // == current raw value when direction_==kReverse\n+  std::string saved_key_;    // == current key when direction_==kReverse\n+  std::string saved_value_;  // == current raw value when direction_==kReverse\n   Direction direction_;\n   bool valid_;\n-\n   Random rnd_;\n-  ssize_t bytes_counter_;\n-\n-  // No copying allowed\n-  DBIter(const DBIter&);\n-  void operator=(const DBIter&);\n+  size_t bytes_until_read_sampling_;\n };\n \n inline bool DBIter::ParseKey(ParsedInternalKey* ikey) {\n   Slice k = iter_->key();\n-  ssize_t n = k.size() + iter_->value().size();\n-  bytes_counter_ -= n;\n-  while (bytes_counter_ < 0) {\n-    bytes_counter_ += RandomPeriod();\n+\n+  size_t bytes_read = k.size() + iter_->value().size();\n+  while (bytes_until_read_sampling_ < bytes_read) {\n+    bytes_until_read_sampling_ += RandomCompactionPeriod();\n     db_->RecordReadSample(k);\n   }\n+  assert(bytes_until_read_sampling_ >= bytes_read);\n+  bytes_until_read_sampling_ -= bytes_read;\n+\n   if (!ParseInternalKey(k, ikey)) {\n     status_ = Status::Corruption(\"corrupted internal key in DBIter\");\n     return false;\n@@ -165,6 +160,15 @@ void DBIter::Next() {\n   } else {\n     // Store in saved_key_ the current key so we skip it below.\n     SaveKey(ExtractUserKey(iter_->key()), &saved_key_);\n+\n+    // iter_ is pointing to current key. We can now safely move to the next to\n+    // avoid checking current key.\n+    iter_->Next();\n+    if (!iter_->Valid()) {\n+      valid_ = false;\n+      saved_key_.clear();\n+      return;\n+    }\n   }\n \n   FindNextUserEntry(true, &saved_key_);\n@@ -218,8 +222,8 @@ void DBIter::Prev() {\n         ClearSavedValue();\n         return;\n       }\n-      if (user_comparator_->Compare(ExtractUserKey(iter_->key()),\n-                                    saved_key_) < 0) {\n+      if (user_comparator_->Compare(ExtractUserKey(iter_->key()), saved_key_) <\n+          0) {\n         break;\n       }\n     }\n@@ -275,8 +279,8 @@ void DBIter::Seek(const Slice& target) {\n   direction_ = kForward;\n   ClearSavedValue();\n   saved_key_.clear();\n-  AppendInternalKey(\n-      &saved_key_, ParsedInternalKey(target, sequence_, kValueTypeForSeek));\n+  AppendInternalKey(&saved_key_,\n+                    ParsedInternalKey(target, sequence_, kValueTypeForSeek));\n   iter_->Seek(saved_key_);\n   if (iter_->Valid()) {\n     FindNextUserEntry(false, &saved_key_ /* temporary storage */);\n@@ -305,12 +309,9 @@ void DBIter::SeekToLast() {\n \n }  // anonymous namespace\n \n-Iterator* NewDBIterator(\n-    DBImpl* db,\n-    const Comparator* user_key_comparator,\n-    Iterator* internal_iter,\n-    SequenceNumber sequence,\n-    uint32_t seed) {\n+Iterator* NewDBIterator(DBImpl* db, const Comparator* user_key_comparator,\n+                        Iterator* internal_iter, SequenceNumber sequence,\n+                        uint32_t seed) {\n   return new DBIter(db, user_key_comparator, internal_iter, sequence, seed);\n }\n "
      },
      {
        "sha": "fd93e912a0de2e5c226474717758c45cca8ba21e",
        "filename": "db/db_iter.h",
        "status": "modified",
        "additions": 5,
        "deletions": 7,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/db_iter.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/db_iter.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/db_iter.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -6,8 +6,9 @@\n #define STORAGE_LEVELDB_DB_DB_ITER_H_\n \n #include <stdint.h>\n-#include \"leveldb/db.h\"\n+\n #include \"db/dbformat.h\"\n+#include \"leveldb/db.h\"\n \n namespace leveldb {\n \n@@ -16,12 +17,9 @@ class DBImpl;\n // Return a new iterator that converts internal keys (yielded by\n // \"*internal_iter\") that were live at the specified \"sequence\" number\n // into appropriate user keys.\n-extern Iterator* NewDBIterator(\n-    DBImpl* db,\n-    const Comparator* user_key_comparator,\n-    Iterator* internal_iter,\n-    SequenceNumber sequence,\n-    uint32_t seed);\n+Iterator* NewDBIterator(DBImpl* db, const Comparator* user_key_comparator,\n+                        Iterator* internal_iter, SequenceNumber sequence,\n+                        uint32_t seed);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "beb1d3bdef61d6a885061c8eb95f1c2d13dd0d2a",
        "filename": "db/db_test.cc",
        "status": "modified",
        "additions": 433,
        "deletions": 289,
        "changes": 722,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/db_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/db_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/db_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -3,14 +3,20 @@\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n #include \"leveldb/db.h\"\n-#include \"leveldb/filter_policy.h\"\n+\n+#include <atomic>\n+#include <string>\n+\n #include \"db/db_impl.h\"\n #include \"db/filename.h\"\n #include \"db/version_set.h\"\n #include \"db/write_batch_internal.h\"\n #include \"leveldb/cache.h\"\n #include \"leveldb/env.h\"\n+#include \"leveldb/filter_policy.h\"\n #include \"leveldb/table.h\"\n+#include \"port/port.h\"\n+#include \"port/thread_annotations.h\"\n #include \"util/hash.h\"\n #include \"util/logging.h\"\n #include \"util/mutexlock.h\"\n@@ -25,83 +31,116 @@ static std::string RandomString(Random* rnd, int len) {\n   return r;\n }\n \n+static std::string RandomKey(Random* rnd) {\n+  int len =\n+      (rnd->OneIn(3) ? 1  // Short sometimes to encourage collisions\n+                     : (rnd->OneIn(100) ? rnd->Skewed(10) : rnd->Uniform(10)));\n+  return test::RandomKey(rnd, len);\n+}\n+\n namespace {\n class AtomicCounter {\n- private:\n-  port::Mutex mu_;\n-  int count_;\n  public:\n-  AtomicCounter() : count_(0) { }\n-  void Increment() {\n-    IncrementBy(1);\n-  }\n-  void IncrementBy(int count) {\n+  AtomicCounter() : count_(0) {}\n+  void Increment() { IncrementBy(1); }\n+  void IncrementBy(int count) LOCKS_EXCLUDED(mu_) {\n     MutexLock l(&mu_);\n     count_ += count;\n   }\n-  int Read() {\n+  int Read() LOCKS_EXCLUDED(mu_) {\n     MutexLock l(&mu_);\n     return count_;\n   }\n-  void Reset() {\n+  void Reset() LOCKS_EXCLUDED(mu_) {\n     MutexLock l(&mu_);\n     count_ = 0;\n   }\n+\n+ private:\n+  port::Mutex mu_;\n+  int count_ GUARDED_BY(mu_);\n };\n \n void DelayMilliseconds(int millis) {\n   Env::Default()->SleepForMicroseconds(millis * 1000);\n }\n-}\n+}  // namespace\n+\n+// Test Env to override default Env behavior for testing.\n+class TestEnv : public EnvWrapper {\n+ public:\n+  explicit TestEnv(Env* base) : EnvWrapper(base), ignore_dot_files_(false) {}\n+\n+  void SetIgnoreDotFiles(bool ignored) { ignore_dot_files_ = ignored; }\n+\n+  Status GetChildren(const std::string& dir,\n+                     std::vector<std::string>* result) override {\n+    Status s = target()->GetChildren(dir, result);\n+    if (!s.ok() || !ignore_dot_files_) {\n+      return s;\n+    }\n+\n+    std::vector<std::string>::iterator it = result->begin();\n+    while (it != result->end()) {\n+      if ((*it == \".\") || (*it == \"..\")) {\n+        it = result->erase(it);\n+      } else {\n+        ++it;\n+      }\n+    }\n+\n+    return s;\n+  }\n+\n+ private:\n+  bool ignore_dot_files_;\n+};\n \n-// Special Env used to delay background operations\n+// Special Env used to delay background operations.\n class SpecialEnv : public EnvWrapper {\n  public:\n-  // sstable/log Sync() calls are blocked while this pointer is non-NULL.\n-  port::AtomicPointer delay_data_sync_;\n+  // sstable/log Sync() calls are blocked while this pointer is non-null.\n+  std::atomic<bool> delay_data_sync_;\n \n   // sstable/log Sync() calls return an error.\n-  port::AtomicPointer data_sync_error_;\n+  std::atomic<bool> data_sync_error_;\n \n-  // Simulate no-space errors while this pointer is non-NULL.\n-  port::AtomicPointer no_space_;\n+  // Simulate no-space errors while this pointer is non-null.\n+  std::atomic<bool> no_space_;\n \n-  // Simulate non-writable file system while this pointer is non-NULL\n-  port::AtomicPointer non_writable_;\n+  // Simulate non-writable file system while this pointer is non-null.\n+  std::atomic<bool> non_writable_;\n \n-  // Force sync of manifest files to fail while this pointer is non-NULL\n-  port::AtomicPointer manifest_sync_error_;\n+  // Force sync of manifest files to fail while this pointer is non-null.\n+  std::atomic<bool> manifest_sync_error_;\n \n-  // Force write to manifest files to fail while this pointer is non-NULL\n-  port::AtomicPointer manifest_write_error_;\n+  // Force write to manifest files to fail while this pointer is non-null.\n+  std::atomic<bool> manifest_write_error_;\n \n   bool count_random_reads_;\n   AtomicCounter random_read_counter_;\n \n-  explicit SpecialEnv(Env* base) : EnvWrapper(base) {\n-    delay_data_sync_.Release_Store(NULL);\n-    data_sync_error_.Release_Store(NULL);\n-    no_space_.Release_Store(NULL);\n-    non_writable_.Release_Store(NULL);\n-    count_random_reads_ = false;\n-    manifest_sync_error_.Release_Store(NULL);\n-    manifest_write_error_.Release_Store(NULL);\n-  }\n+  explicit SpecialEnv(Env* base)\n+      : EnvWrapper(base),\n+        delay_data_sync_(false),\n+        data_sync_error_(false),\n+        no_space_(false),\n+        non_writable_(false),\n+        manifest_sync_error_(false),\n+        manifest_write_error_(false),\n+        count_random_reads_(false) {}\n \n   Status NewWritableFile(const std::string& f, WritableFile** r) {\n     class DataFile : public WritableFile {\n      private:\n-      SpecialEnv* env_;\n-      WritableFile* base_;\n+      SpecialEnv* const env_;\n+      WritableFile* const base_;\n \n      public:\n-      DataFile(SpecialEnv* env, WritableFile* base)\n-          : env_(env),\n-            base_(base) {\n-      }\n+      DataFile(SpecialEnv* env, WritableFile* base) : env_(env), base_(base) {}\n       ~DataFile() { delete base_; }\n       Status Append(const Slice& data) {\n-        if (env_->no_space_.Acquire_Load() != NULL) {\n+        if (env_->no_space_.load(std::memory_order_acquire)) {\n           // Drop writes on the floor\n           return Status::OK();\n         } else {\n@@ -111,24 +150,26 @@ class SpecialEnv : public EnvWrapper {\n       Status Close() { return base_->Close(); }\n       Status Flush() { return base_->Flush(); }\n       Status Sync() {\n-        if (env_->data_sync_error_.Acquire_Load() != NULL) {\n+        if (env_->data_sync_error_.load(std::memory_order_acquire)) {\n           return Status::IOError(\"simulated data sync error\");\n         }\n-        while (env_->delay_data_sync_.Acquire_Load() != NULL) {\n+        while (env_->delay_data_sync_.load(std::memory_order_acquire)) {\n           DelayMilliseconds(100);\n         }\n         return base_->Sync();\n       }\n+      std::string GetName() const override { return \"\"; }\n     };\n     class ManifestFile : public WritableFile {\n      private:\n       SpecialEnv* env_;\n       WritableFile* base_;\n+\n      public:\n-      ManifestFile(SpecialEnv* env, WritableFile* b) : env_(env), base_(b) { }\n+      ManifestFile(SpecialEnv* env, WritableFile* b) : env_(env), base_(b) {}\n       ~ManifestFile() { delete base_; }\n       Status Append(const Slice& data) {\n-        if (env_->manifest_write_error_.Acquire_Load() != NULL) {\n+        if (env_->manifest_write_error_.load(std::memory_order_acquire)) {\n           return Status::IOError(\"simulated writer error\");\n         } else {\n           return base_->Append(data);\n@@ -137,24 +178,25 @@ class SpecialEnv : public EnvWrapper {\n       Status Close() { return base_->Close(); }\n       Status Flush() { return base_->Flush(); }\n       Status Sync() {\n-        if (env_->manifest_sync_error_.Acquire_Load() != NULL) {\n+        if (env_->manifest_sync_error_.load(std::memory_order_acquire)) {\n           return Status::IOError(\"simulated sync error\");\n         } else {\n           return base_->Sync();\n         }\n       }\n+      std::string GetName() const override { return \"\"; }\n     };\n \n-    if (non_writable_.Acquire_Load() != NULL) {\n+    if (non_writable_.load(std::memory_order_acquire)) {\n       return Status::IOError(\"simulated write error\");\n     }\n \n     Status s = target()->NewWritableFile(f, r);\n     if (s.ok()) {\n-      if (strstr(f.c_str(), \".ldb\") != NULL ||\n-          strstr(f.c_str(), \".log\") != NULL) {\n+      if (strstr(f.c_str(), \".ldb\") != nullptr ||\n+          strstr(f.c_str(), \".log\") != nullptr) {\n         *r = new DataFile(this, *r);\n-      } else if (strstr(f.c_str(), \"MANIFEST\") != NULL) {\n+      } else if (strstr(f.c_str(), \"MANIFEST\") != nullptr) {\n         *r = new ManifestFile(this, *r);\n       }\n     }\n@@ -166,16 +208,17 @@ class SpecialEnv : public EnvWrapper {\n      private:\n       RandomAccessFile* target_;\n       AtomicCounter* counter_;\n+\n      public:\n       CountingFile(RandomAccessFile* target, AtomicCounter* counter)\n-          : target_(target), counter_(counter) {\n-      }\n-      virtual ~CountingFile() { delete target_; }\n-      virtual Status Read(uint64_t offset, size_t n, Slice* result,\n-                          char* scratch) const {\n+          : target_(target), counter_(counter) {}\n+      ~CountingFile() override { delete target_; }\n+      Status Read(uint64_t offset, size_t n, Slice* result,\n+                  char* scratch) const override {\n         counter_->Increment();\n         return target_->Read(offset, n, result, scratch);\n       }\n+      std::string GetName() const override { return \"\"; }\n     };\n \n     Status s = target()->NewRandomAccessFile(f, r);\n@@ -187,32 +230,18 @@ class SpecialEnv : public EnvWrapper {\n };\n \n class DBTest {\n- private:\n-  const FilterPolicy* filter_policy_;\n-\n-  // Sequence of option configurations to try\n-  enum OptionConfig {\n-    kDefault,\n-    kReuse,\n-    kFilter,\n-    kUncompressed,\n-    kEnd\n-  };\n-  int option_config_;\n-\n  public:\n   std::string dbname_;\n   SpecialEnv* env_;\n   DB* db_;\n \n   Options last_options_;\n \n-  DBTest() : option_config_(kDefault),\n-             env_(new SpecialEnv(Env::Default())) {\n+  DBTest() : env_(new SpecialEnv(Env::Default())), option_config_(kDefault) {\n     filter_policy_ = NewBloomFilterPolicy(10);\n     dbname_ = test::TmpDir() + \"/db_test\";\n     DestroyDB(dbname_, Options());\n-    db_ = NULL;\n+    db_ = nullptr;\n     Reopen();\n   }\n \n@@ -255,31 +284,27 @@ class DBTest {\n     return options;\n   }\n \n-  DBImpl* dbfull() {\n-    return reinterpret_cast<DBImpl*>(db_);\n-  }\n+  DBImpl* dbfull() { return reinterpret_cast<DBImpl*>(db_); }\n \n-  void Reopen(Options* options = NULL) {\n-    ASSERT_OK(TryReopen(options));\n-  }\n+  void Reopen(Options* options = nullptr) { ASSERT_OK(TryReopen(options)); }\n \n   void Close() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n   }\n \n-  void DestroyAndReopen(Options* options = NULL) {\n+  void DestroyAndReopen(Options* options = nullptr) {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     DestroyDB(dbname_, Options());\n     ASSERT_OK(TryReopen(options));\n   }\n \n   Status TryReopen(Options* options) {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     Options opts;\n-    if (options != NULL) {\n+    if (options != nullptr) {\n       opts = *options;\n     } else {\n       opts = CurrentOptions();\n@@ -294,11 +319,9 @@ class DBTest {\n     return db_->Put(WriteOptions(), k, v);\n   }\n \n-  Status Delete(const std::string& k) {\n-    return db_->Delete(WriteOptions(), k);\n-  }\n+  Status Delete(const std::string& k) { return db_->Delete(WriteOptions(), k); }\n \n-  std::string Get(const std::string& k, const Snapshot* snapshot = NULL) {\n+  std::string Get(const std::string& k, const Snapshot* snapshot = nullptr) {\n     ReadOptions options;\n     options.snapshot = snapshot;\n     std::string result;\n@@ -382,10 +405,9 @@ class DBTest {\n \n   int NumTableFilesAtLevel(int level) {\n     std::string property;\n-    ASSERT_TRUE(\n-        db_->GetProperty(\"leveldb.num-files-at-level\" + NumberToString(level),\n-                         &property));\n-    return atoi(property.c_str());\n+    ASSERT_TRUE(db_->GetProperty(\n+        \"leveldb.num-files-at-level\" + NumberToString(level), &property));\n+    return std::stoi(property);\n   }\n \n   int TotalTableFiles() {\n@@ -431,11 +453,12 @@ class DBTest {\n   }\n \n   // Do n memtable compactions, each of which produces an sstable\n-  // covering the range [small,large].\n-  void MakeTables(int n, const std::string& small, const std::string& large) {\n+  // covering the range [small_key,large_key].\n+  void MakeTables(int n, const std::string& small_key,\n+                  const std::string& large_key) {\n     for (int i = 0; i < n; i++) {\n-      Put(small, \"begin\");\n-      Put(large, \"end\");\n+      Put(small_key, \"begin\");\n+      Put(large_key, \"end\");\n       dbfull()->TEST_CompactMemTable();\n     }\n   }\n@@ -448,9 +471,9 @@ class DBTest {\n \n   void DumpFileCounts(const char* label) {\n     fprintf(stderr, \"---\\n%s:\\n\", label);\n-    fprintf(stderr, \"maxoverlap: %lld\\n\",\n-            static_cast<long long>(\n-                dbfull()->TEST_MaxNextLevelOverlappingBytes()));\n+    fprintf(\n+        stderr, \"maxoverlap: %lld\\n\",\n+        static_cast<long long>(dbfull()->TEST_MaxNextLevelOverlappingBytes()));\n     for (int level = 0; level < config::kNumLevels; level++) {\n       int num = NumTableFilesAtLevel(level);\n       if (num > 0) {\n@@ -506,15 +529,42 @@ class DBTest {\n     }\n     return files_renamed;\n   }\n+\n+ private:\n+  // Sequence of option configurations to try\n+  enum OptionConfig { kDefault, kReuse, kFilter, kUncompressed, kEnd };\n+\n+  const FilterPolicy* filter_policy_;\n+  int option_config_;\n };\n \n TEST(DBTest, Empty) {\n   do {\n-    ASSERT_TRUE(db_ != NULL);\n+    ASSERT_TRUE(db_ != nullptr);\n     ASSERT_EQ(\"NOT_FOUND\", Get(\"foo\"));\n   } while (ChangeOptions());\n }\n \n+TEST(DBTest, EmptyKey) {\n+  do {\n+    ASSERT_OK(Put(\"\", \"v1\"));\n+    ASSERT_EQ(\"v1\", Get(\"\"));\n+    ASSERT_OK(Put(\"\", \"v2\"));\n+    ASSERT_EQ(\"v2\", Get(\"\"));\n+  } while (ChangeOptions());\n+}\n+\n+TEST(DBTest, EmptyValue) {\n+  do {\n+    ASSERT_OK(Put(\"key\", \"v1\"));\n+    ASSERT_EQ(\"v1\", Get(\"key\"));\n+    ASSERT_OK(Put(\"key\", \"\"));\n+    ASSERT_EQ(\"\", Get(\"key\"));\n+    ASSERT_OK(Put(\"key\", \"v2\"));\n+    ASSERT_EQ(\"v2\", Get(\"key\"));\n+  } while (ChangeOptions());\n+}\n+\n TEST(DBTest, ReadWrite) {\n   do {\n     ASSERT_OK(Put(\"foo\", \"v1\"));\n@@ -547,11 +597,13 @@ TEST(DBTest, GetFromImmutableLayer) {\n     ASSERT_OK(Put(\"foo\", \"v1\"));\n     ASSERT_EQ(\"v1\", Get(\"foo\"));\n \n-    env_->delay_data_sync_.Release_Store(env_);      // Block sync calls\n-    Put(\"k1\", std::string(100000, 'x'));             // Fill memtable\n-    Put(\"k2\", std::string(100000, 'y'));             // Trigger compaction\n+    // Block sync calls.\n+    env_->delay_data_sync_.store(true, std::memory_order_release);\n+    Put(\"k1\", std::string(100000, 'x'));  // Fill memtable.\n+    Put(\"k2\", std::string(100000, 'y'));  // Trigger compaction.\n     ASSERT_EQ(\"v1\", Get(\"foo\"));\n-    env_->delay_data_sync_.Release_Store(NULL);      // Release sync calls\n+    // Release sync calls.\n+    env_->delay_data_sync_.store(false, std::memory_order_release);\n   } while (ChangeOptions());\n }\n \n@@ -568,9 +620,9 @@ TEST(DBTest, GetMemUsage) {\n     ASSERT_OK(Put(\"foo\", \"v1\"));\n     std::string val;\n     ASSERT_TRUE(db_->GetProperty(\"leveldb.approximate-memory-usage\", &val));\n-    int mem_usage = atoi(val.c_str());\n+    int mem_usage = std::stoi(val);\n     ASSERT_GT(mem_usage, 0);\n-    ASSERT_LT(mem_usage, 5*1024*1024);\n+    ASSERT_LT(mem_usage, 5 * 1024 * 1024);\n   } while (ChangeOptions());\n }\n \n@@ -592,6 +644,55 @@ TEST(DBTest, GetSnapshot) {\n   } while (ChangeOptions());\n }\n \n+TEST(DBTest, GetIdenticalSnapshots) {\n+  do {\n+    // Try with both a short key and a long key\n+    for (int i = 0; i < 2; i++) {\n+      std::string key = (i == 0) ? std::string(\"foo\") : std::string(200, 'x');\n+      ASSERT_OK(Put(key, \"v1\"));\n+      const Snapshot* s1 = db_->GetSnapshot();\n+      const Snapshot* s2 = db_->GetSnapshot();\n+      const Snapshot* s3 = db_->GetSnapshot();\n+      ASSERT_OK(Put(key, \"v2\"));\n+      ASSERT_EQ(\"v2\", Get(key));\n+      ASSERT_EQ(\"v1\", Get(key, s1));\n+      ASSERT_EQ(\"v1\", Get(key, s2));\n+      ASSERT_EQ(\"v1\", Get(key, s3));\n+      db_->ReleaseSnapshot(s1);\n+      dbfull()->TEST_CompactMemTable();\n+      ASSERT_EQ(\"v2\", Get(key));\n+      ASSERT_EQ(\"v1\", Get(key, s2));\n+      db_->ReleaseSnapshot(s2);\n+      ASSERT_EQ(\"v1\", Get(key, s3));\n+      db_->ReleaseSnapshot(s3);\n+    }\n+  } while (ChangeOptions());\n+}\n+\n+TEST(DBTest, IterateOverEmptySnapshot) {\n+  do {\n+    const Snapshot* snapshot = db_->GetSnapshot();\n+    ReadOptions read_options;\n+    read_options.snapshot = snapshot;\n+    ASSERT_OK(Put(\"foo\", \"v1\"));\n+    ASSERT_OK(Put(\"foo\", \"v2\"));\n+\n+    Iterator* iterator1 = db_->NewIterator(read_options);\n+    iterator1->SeekToFirst();\n+    ASSERT_TRUE(!iterator1->Valid());\n+    delete iterator1;\n+\n+    dbfull()->TEST_CompactMemTable();\n+\n+    Iterator* iterator2 = db_->NewIterator(read_options);\n+    iterator2->SeekToFirst();\n+    ASSERT_TRUE(!iterator2->Valid());\n+    delete iterator2;\n+\n+    db_->ReleaseSnapshot(snapshot);\n+  } while (ChangeOptions());\n+}\n+\n TEST(DBTest, GetLevel0Ordering) {\n   do {\n     // Check that we process level-0 files in correct order.  The code\n@@ -646,8 +747,7 @@ TEST(DBTest, GetEncountersEmptyLevel) {\n \n     // Step 1: First place sstables in levels 0 and 2\n     int compaction_count = 0;\n-    while (NumTableFilesAtLevel(0) == 0 ||\n-           NumTableFilesAtLevel(2) == 0) {\n+    while (NumTableFilesAtLevel(0) == 0 || NumTableFilesAtLevel(2) == 0) {\n       ASSERT_LE(compaction_count, 100) << \"could not fill levels 0 and 2\";\n       compaction_count++;\n       Put(\"a\", \"begin\");\n@@ -656,7 +756,7 @@ TEST(DBTest, GetEncountersEmptyLevel) {\n     }\n \n     // Step 2: clear level 1 if necessary.\n-    dbfull()->TEST_CompactRange(1, NULL, NULL);\n+    dbfull()->TEST_CompactRange(1, nullptr, nullptr);\n     ASSERT_EQ(NumTableFilesAtLevel(0), 1);\n     ASSERT_EQ(NumTableFilesAtLevel(1), 0);\n     ASSERT_EQ(NumTableFilesAtLevel(2), 1);\n@@ -784,10 +884,10 @@ TEST(DBTest, IterMulti) {\n   ASSERT_EQ(IterStatus(iter), \"b->vb\");\n \n   // Make sure iter stays at snapshot\n-  ASSERT_OK(Put(\"a\",  \"va2\"));\n+  ASSERT_OK(Put(\"a\", \"va2\"));\n   ASSERT_OK(Put(\"a2\", \"va3\"));\n-  ASSERT_OK(Put(\"b\",  \"vb2\"));\n-  ASSERT_OK(Put(\"c\",  \"vc2\"));\n+  ASSERT_OK(Put(\"b\", \"vb2\"));\n+  ASSERT_OK(Put(\"c\", \"vc2\"));\n   ASSERT_OK(Delete(\"b\"));\n   iter->SeekToFirst();\n   ASSERT_EQ(IterStatus(iter), \"a->va\");\n@@ -978,7 +1078,7 @@ TEST(DBTest, RecoverWithLargeLog) {\n \n TEST(DBTest, CompactionsGenerateMultipleFiles) {\n   Options options = CurrentOptions();\n-  options.write_buffer_size = 100000000;        // Large write buffer\n+  options.write_buffer_size = 100000000;  // Large write buffer\n   Reopen(&options);\n \n   Random rnd(301);\n@@ -993,7 +1093,7 @@ TEST(DBTest, CompactionsGenerateMultipleFiles) {\n \n   // Reopening moves updates to level-0\n   Reopen(&options);\n-  dbfull()->TEST_CompactRange(0, NULL, NULL);\n+  dbfull()->TEST_CompactRange(0, nullptr, nullptr);\n \n   ASSERT_EQ(NumTableFilesAtLevel(0), 0);\n   ASSERT_GT(NumTableFilesAtLevel(1), 1);\n@@ -1017,7 +1117,7 @@ TEST(DBTest, RepeatedWritesToSameKey) {\n   for (int i = 0; i < 5 * kMaxFiles; i++) {\n     Put(\"key\", value);\n     ASSERT_LE(TotalTableFiles(), kMaxFiles);\n-    fprintf(stderr, \"after %d: %d files\\n\", int(i+1), TotalTableFiles());\n+    fprintf(stderr, \"after %d: %d files\\n\", i + 1, TotalTableFiles());\n   }\n }\n \n@@ -1044,29 +1144,28 @@ TEST(DBTest, SparseMerge) {\n   }\n   Put(\"C\", \"vc\");\n   dbfull()->TEST_CompactMemTable();\n-  dbfull()->TEST_CompactRange(0, NULL, NULL);\n+  dbfull()->TEST_CompactRange(0, nullptr, nullptr);\n \n   // Make sparse update\n-  Put(\"A\",    \"va2\");\n+  Put(\"A\", \"va2\");\n   Put(\"B100\", \"bvalue2\");\n-  Put(\"C\",    \"vc2\");\n+  Put(\"C\", \"vc2\");\n   dbfull()->TEST_CompactMemTable();\n \n   // Compactions should not cause us to create a situation where\n   // a file overlaps too much data at the next level.\n-  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20*1048576);\n-  dbfull()->TEST_CompactRange(0, NULL, NULL);\n-  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20*1048576);\n-  dbfull()->TEST_CompactRange(1, NULL, NULL);\n-  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20*1048576);\n+  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20 * 1048576);\n+  dbfull()->TEST_CompactRange(0, nullptr, nullptr);\n+  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20 * 1048576);\n+  dbfull()->TEST_CompactRange(1, nullptr, nullptr);\n+  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20 * 1048576);\n }\n \n static bool Between(uint64_t val, uint64_t low, uint64_t high) {\n   bool result = (val >= low) && (val <= high);\n   if (!result) {\n     fprintf(stderr, \"Value %llu is not in range [%llu, %llu]\\n\",\n-            (unsigned long long)(val),\n-            (unsigned long long)(low),\n+            (unsigned long long)(val), (unsigned long long)(low),\n             (unsigned long long)(high));\n   }\n   return result;\n@@ -1075,7 +1174,7 @@ static bool Between(uint64_t val, uint64_t low, uint64_t high) {\n TEST(DBTest, ApproximateSizes) {\n   do {\n     Options options = CurrentOptions();\n-    options.write_buffer_size = 100000000;        // Large write buffer\n+    options.write_buffer_size = 100000000;  // Large write buffer\n     options.compression = kNoCompression;\n     DestroyAndReopen();\n \n@@ -1110,12 +1209,13 @@ TEST(DBTest, ApproximateSizes) {\n \n       for (int compact_start = 0; compact_start < N; compact_start += 10) {\n         for (int i = 0; i < N; i += 10) {\n-          ASSERT_TRUE(Between(Size(\"\", Key(i)), S1*i, S2*i));\n-          ASSERT_TRUE(Between(Size(\"\", Key(i)+\".suffix\"), S1*(i+1), S2*(i+1)));\n-          ASSERT_TRUE(Between(Size(Key(i), Key(i+10)), S1*10, S2*10));\n+          ASSERT_TRUE(Between(Size(\"\", Key(i)), S1 * i, S2 * i));\n+          ASSERT_TRUE(Between(Size(\"\", Key(i) + \".suffix\"), S1 * (i + 1),\n+                              S2 * (i + 1)));\n+          ASSERT_TRUE(Between(Size(Key(i), Key(i + 10)), S1 * 10, S2 * 10));\n         }\n-        ASSERT_TRUE(Between(Size(\"\", Key(50)), S1*50, S2*50));\n-        ASSERT_TRUE(Between(Size(\"\", Key(50)+\".suffix\"), S1*50, S2*50));\n+        ASSERT_TRUE(Between(Size(\"\", Key(50)), S1 * 50, S2 * 50));\n+        ASSERT_TRUE(Between(Size(\"\", Key(50) + \".suffix\"), S1 * 50, S2 * 50));\n \n         std::string cstart_str = Key(compact_start);\n         std::string cend_str = Key(compact_start + 9);\n@@ -1168,7 +1268,7 @@ TEST(DBTest, ApproximateSizes_MixOfSmallAndLarge) {\n \n       ASSERT_TRUE(Between(Size(Key(3), Key(5)), 110000, 111000));\n \n-      dbfull()->TEST_CompactRange(0, NULL, NULL);\n+      dbfull()->TEST_CompactRange(0, nullptr, nullptr);\n     }\n   } while (ChangeOptions());\n }\n@@ -1182,7 +1282,7 @@ TEST(DBTest, IteratorPinsRef) {\n   // Write to force compactions\n   Put(\"foo\", \"newvalue1\");\n   for (int i = 0; i < 100; i++) {\n-    ASSERT_OK(Put(Key(i), Key(i) + std::string(100000, 'v'))); // 100K values\n+    ASSERT_OK(Put(Key(i), Key(i) + std::string(100000, 'v')));  // 100K values\n   }\n   Put(\"foo\", \"newvalue2\");\n \n@@ -1234,7 +1334,7 @@ TEST(DBTest, HiddenValuesAreRemoved) {\n     Put(\"pastfoo\", \"v\");\n     const Snapshot* snapshot = db_->GetSnapshot();\n     Put(\"foo\", \"tiny\");\n-    Put(\"pastfoo2\", \"v2\");        // Advance sequence number one more\n+    Put(\"pastfoo2\", \"v2\");  // Advance sequence number one more\n \n     ASSERT_OK(dbfull()->TEST_CompactMemTable());\n     ASSERT_GT(NumTableFilesAtLevel(0), 0);\n@@ -1244,11 +1344,11 @@ TEST(DBTest, HiddenValuesAreRemoved) {\n     db_->ReleaseSnapshot(snapshot);\n     ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ tiny, \" + big + \" ]\");\n     Slice x(\"x\");\n-    dbfull()->TEST_CompactRange(0, NULL, &x);\n+    dbfull()->TEST_CompactRange(0, nullptr, &x);\n     ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ tiny ]\");\n     ASSERT_EQ(NumTableFilesAtLevel(0), 0);\n     ASSERT_GE(NumTableFilesAtLevel(1), 1);\n-    dbfull()->TEST_CompactRange(1, NULL, &x);\n+    dbfull()->TEST_CompactRange(1, nullptr, &x);\n     ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ tiny ]\");\n \n     ASSERT_TRUE(Between(Size(\"\", \"pastfoo\"), 0, 1000));\n@@ -1259,26 +1359,26 @@ TEST(DBTest, DeletionMarkers1) {\n   Put(\"foo\", \"v1\");\n   ASSERT_OK(dbfull()->TEST_CompactMemTable());\n   const int last = config::kMaxMemCompactLevel;\n-  ASSERT_EQ(NumTableFilesAtLevel(last), 1);   // foo => v1 is now in last level\n+  ASSERT_EQ(NumTableFilesAtLevel(last), 1);  // foo => v1 is now in last level\n \n   // Place a table at level last-1 to prevent merging with preceding mutation\n   Put(\"a\", \"begin\");\n   Put(\"z\", \"end\");\n   dbfull()->TEST_CompactMemTable();\n   ASSERT_EQ(NumTableFilesAtLevel(last), 1);\n-  ASSERT_EQ(NumTableFilesAtLevel(last-1), 1);\n+  ASSERT_EQ(NumTableFilesAtLevel(last - 1), 1);\n \n   Delete(\"foo\");\n   Put(\"foo\", \"v2\");\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ v2, DEL, v1 ]\");\n   ASSERT_OK(dbfull()->TEST_CompactMemTable());  // Moves to level last-2\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ v2, DEL, v1 ]\");\n   Slice z(\"z\");\n-  dbfull()->TEST_CompactRange(last-2, NULL, &z);\n+  dbfull()->TEST_CompactRange(last - 2, nullptr, &z);\n   // DEL eliminated, but v1 remains because we aren't compacting that level\n   // (DEL can be eliminated because v2 hides v1).\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ v2, v1 ]\");\n-  dbfull()->TEST_CompactRange(last-1, NULL, NULL);\n+  dbfull()->TEST_CompactRange(last - 1, nullptr, nullptr);\n   // Merging last-1 w/ last, so we are the base level for \"foo\", so\n   // DEL is removed.  (as is v1).\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ v2 ]\");\n@@ -1288,23 +1388,23 @@ TEST(DBTest, DeletionMarkers2) {\n   Put(\"foo\", \"v1\");\n   ASSERT_OK(dbfull()->TEST_CompactMemTable());\n   const int last = config::kMaxMemCompactLevel;\n-  ASSERT_EQ(NumTableFilesAtLevel(last), 1);   // foo => v1 is now in last level\n+  ASSERT_EQ(NumTableFilesAtLevel(last), 1);  // foo => v1 is now in last level\n \n   // Place a table at level last-1 to prevent merging with preceding mutation\n   Put(\"a\", \"begin\");\n   Put(\"z\", \"end\");\n   dbfull()->TEST_CompactMemTable();\n   ASSERT_EQ(NumTableFilesAtLevel(last), 1);\n-  ASSERT_EQ(NumTableFilesAtLevel(last-1), 1);\n+  ASSERT_EQ(NumTableFilesAtLevel(last - 1), 1);\n \n   Delete(\"foo\");\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ DEL, v1 ]\");\n   ASSERT_OK(dbfull()->TEST_CompactMemTable());  // Moves to level last-2\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ DEL, v1 ]\");\n-  dbfull()->TEST_CompactRange(last-2, NULL, NULL);\n+  dbfull()->TEST_CompactRange(last - 2, nullptr, nullptr);\n   // DEL kept: \"last\" file overlaps\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ DEL, v1 ]\");\n-  dbfull()->TEST_CompactRange(last-1, NULL, NULL);\n+  dbfull()->TEST_CompactRange(last - 1, nullptr, nullptr);\n   // Merging last-1 w/ last, so we are the base level for \"foo\", so\n   // DEL is removed.  (as is v1).\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ ]\");\n@@ -1314,7 +1414,8 @@ TEST(DBTest, OverlapInLevel0) {\n   do {\n     ASSERT_EQ(config::kMaxMemCompactLevel, 2) << \"Fix test to match config\";\n \n-    // Fill levels 1 and 2 to disable the pushing of new memtables to levels > 0.\n+    // Fill levels 1 and 2 to disable the pushing of new memtables to levels >\n+    // 0.\n     ASSERT_OK(Put(\"100\", \"v100\"));\n     ASSERT_OK(Put(\"999\", \"v999\"));\n     dbfull()->TEST_CompactMemTable();\n@@ -1337,8 +1438,8 @@ TEST(DBTest, OverlapInLevel0) {\n     ASSERT_EQ(\"2,1,1\", FilesPerLevel());\n \n     // Compact away the placeholder files we created initially\n-    dbfull()->TEST_CompactRange(1, NULL, NULL);\n-    dbfull()->TEST_CompactRange(2, NULL, NULL);\n+    dbfull()->TEST_CompactRange(1, nullptr, nullptr);\n+    dbfull()->TEST_CompactRange(2, nullptr, nullptr);\n     ASSERT_EQ(\"2\", FilesPerLevel());\n \n     // Do a memtable compaction.  Before bug-fix, the compaction would\n@@ -1370,21 +1471,21 @@ TEST(DBTest, L0_CompactionBug_Issue44_a) {\n \n TEST(DBTest, L0_CompactionBug_Issue44_b) {\n   Reopen();\n-  Put(\"\",\"\");\n+  Put(\"\", \"\");\n   Reopen();\n   Delete(\"e\");\n-  Put(\"\",\"\");\n+  Put(\"\", \"\");\n   Reopen();\n   Put(\"c\", \"cv\");\n   Reopen();\n-  Put(\"\",\"\");\n+  Put(\"\", \"\");\n   Reopen();\n-  Put(\"\",\"\");\n+  Put(\"\", \"\");\n   DelayMilliseconds(1000);  // Wait for compaction to finish\n   Reopen();\n-  Put(\"d\",\"dv\");\n+  Put(\"d\", \"dv\");\n   Reopen();\n-  Put(\"\",\"\");\n+  Put(\"\", \"\");\n   Reopen();\n   Delete(\"d\");\n   Delete(\"b\");\n@@ -1394,17 +1495,26 @@ TEST(DBTest, L0_CompactionBug_Issue44_b) {\n   ASSERT_EQ(\"(->)(c->cv)\", Contents());\n }\n \n+TEST(DBTest, Fflush_Issue474) {\n+  static const int kNum = 100000;\n+  Random rnd(test::RandomSeed());\n+  for (int i = 0; i < kNum; i++) {\n+    fflush(nullptr);\n+    ASSERT_OK(Put(RandomKey(&rnd), RandomString(&rnd, 100)));\n+  }\n+}\n+\n TEST(DBTest, ComparatorCheck) {\n   class NewComparator : public Comparator {\n    public:\n-    virtual const char* Name() const { return \"leveldb.NewComparator\"; }\n-    virtual int Compare(const Slice& a, const Slice& b) const {\n+    const char* Name() const override { return \"leveldb.NewComparator\"; }\n+    int Compare(const Slice& a, const Slice& b) const override {\n       return BytewiseComparator()->Compare(a, b);\n     }\n-    virtual void FindShortestSeparator(std::string* s, const Slice& l) const {\n+    void FindShortestSeparator(std::string* s, const Slice& l) const override {\n       BytewiseComparator()->FindShortestSeparator(s, l);\n     }\n-    virtual void FindShortSuccessor(std::string* key) const {\n+    void FindShortSuccessor(std::string* key) const override {\n       BytewiseComparator()->FindShortSuccessor(key);\n     }\n   };\n@@ -1420,21 +1530,22 @@ TEST(DBTest, ComparatorCheck) {\n TEST(DBTest, CustomComparator) {\n   class NumberComparator : public Comparator {\n    public:\n-    virtual const char* Name() const { return \"test.NumberComparator\"; }\n-    virtual int Compare(const Slice& a, const Slice& b) const {\n+    const char* Name() const override { return \"test.NumberComparator\"; }\n+    int Compare(const Slice& a, const Slice& b) const override {\n       return ToNumber(a) - ToNumber(b);\n     }\n-    virtual void FindShortestSeparator(std::string* s, const Slice& l) const {\n-      ToNumber(*s);     // Check format\n-      ToNumber(l);      // Check format\n+    void FindShortestSeparator(std::string* s, const Slice& l) const override {\n+      ToNumber(*s);  // Check format\n+      ToNumber(l);   // Check format\n     }\n-    virtual void FindShortSuccessor(std::string* key) const {\n-      ToNumber(*key);   // Check format\n+    void FindShortSuccessor(std::string* key) const override {\n+      ToNumber(*key);  // Check format\n     }\n+\n    private:\n     static int ToNumber(const Slice& x) {\n       // Check that there are no extra characters.\n-      ASSERT_TRUE(x.size() >= 2 && x[0] == '[' && x[x.size()-1] == ']')\n+      ASSERT_TRUE(x.size() >= 2 && x[0] == '[' && x[x.size() - 1] == ']')\n           << EscapeString(x);\n       int val;\n       char ignored;\n@@ -1447,7 +1558,7 @@ TEST(DBTest, CustomComparator) {\n   Options new_options = CurrentOptions();\n   new_options.create_if_missing = true;\n   new_options.comparator = &cmp;\n-  new_options.filter_policy = NULL;     // Cannot use bloom filters\n+  new_options.filter_policy = nullptr;   // Cannot use bloom filters\n   new_options.write_buffer_size = 1000;  // Compact more often\n   DestroyAndReopen(&new_options);\n   ASSERT_OK(Put(\"[10]\", \"ten\"));\n@@ -1465,7 +1576,7 @@ TEST(DBTest, CustomComparator) {\n   for (int run = 0; run < 2; run++) {\n     for (int i = 0; i < 1000; i++) {\n       char buf[100];\n-      snprintf(buf, sizeof(buf), \"[%d]\", i*10);\n+      snprintf(buf, sizeof(buf), \"[%d]\", i * 10);\n       ASSERT_OK(Put(buf, buf));\n     }\n     Compact(\"[0]\", \"[1000000]\");\n@@ -1502,7 +1613,7 @@ TEST(DBTest, ManualCompaction) {\n   // Compact all\n   MakeTables(1, \"a\", \"z\");\n   ASSERT_EQ(\"0,1,2\", FilesPerLevel());\n-  db_->CompactRange(NULL, NULL);\n+  db_->CompactRange(nullptr, nullptr);\n   ASSERT_EQ(\"0,0,1\", FilesPerLevel());\n }\n \n@@ -1511,42 +1622,94 @@ TEST(DBTest, DBOpen_Options) {\n   DestroyDB(dbname, Options());\n \n   // Does not exist, and create_if_missing == false: error\n-  DB* db = NULL;\n+  DB* db = nullptr;\n   Options opts;\n   opts.create_if_missing = false;\n   Status s = DB::Open(opts, dbname, &db);\n-  ASSERT_TRUE(strstr(s.ToString().c_str(), \"does not exist\") != NULL);\n-  ASSERT_TRUE(db == NULL);\n+  ASSERT_TRUE(strstr(s.ToString().c_str(), \"does not exist\") != nullptr);\n+  ASSERT_TRUE(db == nullptr);\n \n   // Does not exist, and create_if_missing == true: OK\n   opts.create_if_missing = true;\n   s = DB::Open(opts, dbname, &db);\n   ASSERT_OK(s);\n-  ASSERT_TRUE(db != NULL);\n+  ASSERT_TRUE(db != nullptr);\n \n   delete db;\n-  db = NULL;\n+  db = nullptr;\n \n   // Does exist, and error_if_exists == true: error\n   opts.create_if_missing = false;\n   opts.error_if_exists = true;\n   s = DB::Open(opts, dbname, &db);\n-  ASSERT_TRUE(strstr(s.ToString().c_str(), \"exists\") != NULL);\n-  ASSERT_TRUE(db == NULL);\n+  ASSERT_TRUE(strstr(s.ToString().c_str(), \"exists\") != nullptr);\n+  ASSERT_TRUE(db == nullptr);\n \n   // Does exist, and error_if_exists == false: OK\n   opts.create_if_missing = true;\n   opts.error_if_exists = false;\n   s = DB::Open(opts, dbname, &db);\n   ASSERT_OK(s);\n-  ASSERT_TRUE(db != NULL);\n+  ASSERT_TRUE(db != nullptr);\n+\n+  delete db;\n+  db = nullptr;\n+}\n+\n+TEST(DBTest, DestroyEmptyDir) {\n+  std::string dbname = test::TmpDir() + \"/db_empty_dir\";\n+  TestEnv env(Env::Default());\n+  env.DeleteDir(dbname);\n+  ASSERT_TRUE(!env.FileExists(dbname));\n+\n+  Options opts;\n+  opts.env = &env;\n+\n+  ASSERT_OK(env.CreateDir(dbname));\n+  ASSERT_TRUE(env.FileExists(dbname));\n+  std::vector<std::string> children;\n+  ASSERT_OK(env.GetChildren(dbname, &children));\n+  // The stock Env's do not filter out '.' and '..' special files.\n+  ASSERT_EQ(2, children.size());\n+  ASSERT_OK(DestroyDB(dbname, opts));\n+  ASSERT_TRUE(!env.FileExists(dbname));\n+\n+  // Should also be destroyed if Env is filtering out dot files.\n+  env.SetIgnoreDotFiles(true);\n+  ASSERT_OK(env.CreateDir(dbname));\n+  ASSERT_TRUE(env.FileExists(dbname));\n+  ASSERT_OK(env.GetChildren(dbname, &children));\n+  ASSERT_EQ(0, children.size());\n+  ASSERT_OK(DestroyDB(dbname, opts));\n+  ASSERT_TRUE(!env.FileExists(dbname));\n+}\n+\n+TEST(DBTest, DestroyOpenDB) {\n+  std::string dbname = test::TmpDir() + \"/open_db_dir\";\n+  env_->DeleteDir(dbname);\n+  ASSERT_TRUE(!env_->FileExists(dbname));\n+\n+  Options opts;\n+  opts.create_if_missing = true;\n+  DB* db = nullptr;\n+  ASSERT_OK(DB::Open(opts, dbname, &db));\n+  ASSERT_TRUE(db != nullptr);\n+\n+  // Must fail to destroy an open db.\n+  ASSERT_TRUE(env_->FileExists(dbname));\n+  ASSERT_TRUE(!DestroyDB(dbname, Options()).ok());\n+  ASSERT_TRUE(env_->FileExists(dbname));\n \n   delete db;\n-  db = NULL;\n+  db = nullptr;\n+\n+  // Should succeed destroying a closed db.\n+  ASSERT_OK(DestroyDB(dbname, Options()));\n+  ASSERT_TRUE(!env_->FileExists(dbname));\n }\n \n TEST(DBTest, Locking) {\n-  DB* db2 = NULL;\n+  DB* db2 = nullptr;\n   Status s = DB::Open(CurrentOptions(), dbname_, &db2);\n   ASSERT_TRUE(!s.ok()) << \"Locking did not prevent re-opening db\";\n }\n@@ -1561,13 +1724,14 @@ TEST(DBTest, NoSpace) {\n   ASSERT_EQ(\"v1\", Get(\"foo\"));\n   Compact(\"a\", \"z\");\n   const int num_files = CountFiles();\n-  env_->no_space_.Release_Store(env_);   // Force out-of-space errors\n+  // Force out-of-space errors.\n+  env_->no_space_.store(true, std::memory_order_release);\n   for (int i = 0; i < 10; i++) {\n-    for (int level = 0; level < config::kNumLevels-1; level++) {\n-      dbfull()->TEST_CompactRange(level, NULL, NULL);\n+    for (int level = 0; level < config::kNumLevels - 1; level++) {\n+      dbfull()->TEST_CompactRange(level, nullptr, nullptr);\n     }\n   }\n-  env_->no_space_.Release_Store(NULL);\n+  env_->no_space_.store(false, std::memory_order_release);\n   ASSERT_LT(CountFiles(), num_files + 3);\n }\n \n@@ -1577,7 +1741,8 @@ TEST(DBTest, NonWritableFileSystem) {\n   options.env = env_;\n   Reopen(&options);\n   ASSERT_OK(Put(\"foo\", \"v1\"));\n-  env_->non_writable_.Release_Store(env_);  // Force errors for new files\n+  // Force errors for new files.\n+  env_->non_writable_.store(true, std::memory_order_release);\n   std::string big(100000, 'x');\n   int errors = 0;\n   for (int i = 0; i < 20; i++) {\n@@ -1588,7 +1753,7 @@ TEST(DBTest, NonWritableFileSystem) {\n     }\n   }\n   ASSERT_GT(errors, 0);\n-  env_->non_writable_.Release_Store(NULL);\n+  env_->non_writable_.store(false, std::memory_order_release);\n }\n \n TEST(DBTest, WriteSyncError) {\n@@ -1598,7 +1763,7 @@ TEST(DBTest, WriteSyncError) {\n   Options options = CurrentOptions();\n   options.env = env_;\n   Reopen(&options);\n-  env_->data_sync_error_.Release_Store(env_);\n+  env_->data_sync_error_.store(true, std::memory_order_release);\n \n   // (b) Normal write should succeed\n   WriteOptions w;\n@@ -1612,7 +1777,7 @@ TEST(DBTest, WriteSyncError) {\n   ASSERT_EQ(\"NOT_FOUND\", Get(\"k2\"));\n \n   // (d) make sync behave normally\n-  env_->data_sync_error_.Release_Store(NULL);\n+  env_->data_sync_error_.store(false, std::memory_order_release);\n \n   // (e) Do a non-sync write; should fail\n   w.sync = false;\n@@ -1632,9 +1797,8 @@ TEST(DBTest, ManifestWriteError) {\n   // We iterate twice.  In the second iteration, everything is the\n   // same except the log record never makes it to the MANIFEST file.\n   for (int iter = 0; iter < 2; iter++) {\n-    port::AtomicPointer* error_type = (iter == 0)\n-        ? &env_->manifest_sync_error_\n-        : &env_->manifest_write_error_;\n+    std::atomic<bool>* error_type = (iter == 0) ? &env_->manifest_sync_error_\n+                                                : &env_->manifest_write_error_;\n \n     // Insert foo=>bar mapping\n     Options options = CurrentOptions();\n@@ -1649,15 +1813,15 @@ TEST(DBTest, ManifestWriteError) {\n     dbfull()->TEST_CompactMemTable();\n     ASSERT_EQ(\"bar\", Get(\"foo\"));\n     const int last = config::kMaxMemCompactLevel;\n-    ASSERT_EQ(NumTableFilesAtLevel(last), 1);   // foo=>bar is now in last level\n+    ASSERT_EQ(NumTableFilesAtLevel(last), 1);  // foo=>bar is now in last level\n \n     // Merging compaction (will fail)\n-    error_type->Release_Store(env_);\n-    dbfull()->TEST_CompactRange(last, NULL, NULL);  // Should fail\n+    error_type->store(true, std::memory_order_release);\n+    dbfull()->TEST_CompactRange(last, nullptr, nullptr);  // Should fail\n     ASSERT_EQ(\"bar\", Get(\"foo\"));\n \n     // Recovery: should not lose data\n-    error_type->Release_Store(NULL);\n+    error_type->store(false, std::memory_order_release);\n     Reopen(&options);\n     ASSERT_EQ(\"bar\", Get(\"foo\"));\n   }\n@@ -1677,8 +1841,7 @@ TEST(DBTest, MissingSSTFile) {\n   options.paranoid_checks = true;\n   Status s = TryReopen(&options);\n   ASSERT_TRUE(!s.ok());\n-  ASSERT_TRUE(s.ToString().find(\"issing\") != std::string::npos)\n-      << s.ToString();\n+  ASSERT_TRUE(s.ToString().find(\"issing\") != std::string::npos) << s.ToString();\n }\n \n TEST(DBTest, StillReadSST) {\n@@ -1728,7 +1891,7 @@ TEST(DBTest, BloomFilter) {\n   dbfull()->TEST_CompactMemTable();\n \n   // Prevent auto compactions triggered by seeks\n-  env_->delay_data_sync_.Release_Store(env_);\n+  env_->delay_data_sync_.store(true, std::memory_order_release);\n \n   // Lookup present keys.  Should rarely read from small sstable.\n   env_->random_read_counter_.Reset();\n@@ -1738,7 +1901,7 @@ TEST(DBTest, BloomFilter) {\n   int reads = env_->random_read_counter_.Read();\n   fprintf(stderr, \"%d present => %d reads\\n\", N, reads);\n   ASSERT_GE(reads, N);\n-  ASSERT_LE(reads, N + 2*N/100);\n+  ASSERT_LE(reads, N + 2 * N / 100);\n \n   // Lookup present keys.  Should rarely read from either sstable.\n   env_->random_read_counter_.Reset();\n@@ -1747,9 +1910,9 @@ TEST(DBTest, BloomFilter) {\n   }\n   reads = env_->random_read_counter_.Read();\n   fprintf(stderr, \"%d missing => %d reads\\n\", N, reads);\n-  ASSERT_LE(reads, 3*N/100);\n+  ASSERT_LE(reads, 3 * N / 100);\n \n-  env_->delay_data_sync_.Release_Store(NULL);\n+  env_->delay_data_sync_.store(false, std::memory_order_release);\n   Close();\n   delete options.block_cache;\n   delete options.filter_policy;\n@@ -1764,9 +1927,9 @@ static const int kNumKeys = 1000;\n \n struct MTState {\n   DBTest* test;\n-  port::AtomicPointer stop;\n-  port::AtomicPointer counter[kNumThreads];\n-  port::AtomicPointer thread_done[kNumThreads];\n+  std::atomic<bool> stop;\n+  std::atomic<int> counter[kNumThreads];\n+  std::atomic<bool> thread_done[kNumThreads];\n };\n \n struct MTThread {\n@@ -1778,13 +1941,13 @@ static void MTThreadBody(void* arg) {\n   MTThread* t = reinterpret_cast<MTThread*>(arg);\n   int id = t->id;\n   DB* db = t->state->test->db_;\n-  uintptr_t counter = 0;\n+  int counter = 0;\n   fprintf(stderr, \"... starting thread %d\\n\", id);\n   Random rnd(1000 + id);\n   std::string value;\n   char valbuf[1500];\n-  while (t->state->stop.Acquire_Load() == NULL) {\n-    t->state->counter[id].Release_Store(reinterpret_cast<void*>(counter));\n+  while (!t->state->stop.load(std::memory_order_acquire)) {\n+    t->state->counter[id].store(counter, std::memory_order_release);\n \n     int key = rnd.Uniform(kNumKeys);\n     char keybuf[20];\n@@ -1793,8 +1956,8 @@ static void MTThreadBody(void* arg) {\n     if (rnd.OneIn(2)) {\n       // Write values of the form <key, my id, counter>.\n       // We add some padding for force compactions.\n-      snprintf(valbuf, sizeof(valbuf), \"%d.%d.%-1000d\",\n-               key, id, static_cast<int>(counter));\n+      snprintf(valbuf, sizeof(valbuf), \"%d.%d.%-1000d\", key, id,\n+               static_cast<int>(counter));\n       ASSERT_OK(db->Put(WriteOptions(), Slice(keybuf), Slice(valbuf)));\n     } else {\n       // Read a value and verify that it matches the pattern written above.\n@@ -1809,14 +1972,13 @@ static void MTThreadBody(void* arg) {\n         ASSERT_EQ(k, key);\n         ASSERT_GE(w, 0);\n         ASSERT_LT(w, kNumThreads);\n-        ASSERT_LE(static_cast<uintptr_t>(c), reinterpret_cast<uintptr_t>(\n-            t->state->counter[w].Acquire_Load()));\n+        ASSERT_LE(c, t->state->counter[w].load(std::memory_order_acquire));\n       }\n     }\n     counter++;\n   }\n-  t->state->thread_done[id].Release_Store(t);\n-  fprintf(stderr, \"... stopping thread %d after %d ops\\n\", id, int(counter));\n+  t->state->thread_done[id].store(true, std::memory_order_release);\n+  fprintf(stderr, \"... stopping thread %d after %d ops\\n\", id, counter);\n }\n \n }  // namespace\n@@ -1826,10 +1988,10 @@ TEST(DBTest, MultiThreaded) {\n     // Initialize state\n     MTState mt;\n     mt.test = this;\n-    mt.stop.Release_Store(0);\n+    mt.stop.store(false, std::memory_order_release);\n     for (int id = 0; id < kNumThreads; id++) {\n-      mt.counter[id].Release_Store(0);\n-      mt.thread_done[id].Release_Store(0);\n+      mt.counter[id].store(false, std::memory_order_release);\n+      mt.thread_done[id].store(false, std::memory_order_release);\n     }\n \n     // Start threads\n@@ -1844,9 +2006,9 @@ TEST(DBTest, MultiThreaded) {\n     DelayMilliseconds(kTestSeconds * 1000);\n \n     // Stop the threads and wait for them to finish\n-    mt.stop.Release_Store(&mt);\n+    mt.stop.store(true, std::memory_order_release);\n     for (int id = 0; id < kNumThreads; id++) {\n-      while (mt.thread_done[id].Acquire_Load() == NULL) {\n+      while (!mt.thread_done[id].load(std::memory_order_acquire)) {\n         DelayMilliseconds(100);\n       }\n     }\n@@ -1857,28 +2019,28 @@ namespace {\n typedef std::map<std::string, std::string> KVMap;\n }\n \n-class ModelDB: public DB {\n+class ModelDB : public DB {\n  public:\n   class ModelSnapshot : public Snapshot {\n    public:\n     KVMap map_;\n   };\n \n-  explicit ModelDB(const Options& options): options_(options) { }\n-  ~ModelDB() { }\n-  virtual Status Put(const WriteOptions& o, const Slice& k, const Slice& v) {\n+  explicit ModelDB(const Options& options) : options_(options) {}\n+  ~ModelDB() override = default;\n+  Status Put(const WriteOptions& o, const Slice& k, const Slice& v) override {\n     return DB::Put(o, k, v);\n   }\n-  virtual Status Delete(const WriteOptions& o, const Slice& key) {\n+  Status Delete(const WriteOptions& o, const Slice& key) override {\n     return DB::Delete(o, key);\n   }\n-  virtual Status Get(const ReadOptions& options,\n-                     const Slice& key, std::string* value) {\n-    assert(false);      // Not implemented\n+  Status Get(const ReadOptions& options, const Slice& key,\n+             std::string* value) override {\n+    assert(false);  // Not implemented\n     return Status::NotFound(key);\n   }\n-  virtual Iterator* NewIterator(const ReadOptions& options) {\n-    if (options.snapshot == NULL) {\n+  Iterator* NewIterator(const ReadOptions& options) override {\n+    if (options.snapshot == nullptr) {\n       KVMap* saved = new KVMap;\n       *saved = map_;\n       return new ModelIter(saved, true);\n@@ -1888,68 +2050,65 @@ class ModelDB: public DB {\n       return new ModelIter(snapshot_state, false);\n     }\n   }\n-  virtual const Snapshot* GetSnapshot() {\n+  const Snapshot* GetSnapshot() override {\n     ModelSnapshot* snapshot = new ModelSnapshot;\n     snapshot->map_ = map_;\n     return snapshot;\n   }\n \n-  virtual void ReleaseSnapshot(const Snapshot* snapshot) {\n+  void ReleaseSnapshot(const Snapshot* snapshot) override {\n     delete reinterpret_cast<const ModelSnapshot*>(snapshot);\n   }\n-  virtual Status Write(const WriteOptions& options, WriteBatch* batch) {\n+  Status Write(const WriteOptions& options, WriteBatch* batch) override {\n     class Handler : public WriteBatch::Handler {\n      public:\n       KVMap* map_;\n-      virtual void Put(const Slice& key, const Slice& value) {\n+      void Put(const Slice& key, const Slice& value) override {\n         (*map_)[key.ToString()] = value.ToString();\n       }\n-      virtual void Delete(const Slice& key) {\n-        map_->erase(key.ToString());\n-      }\n+      void Delete(const Slice& key) override { map_->erase(key.ToString()); }\n     };\n     Handler handler;\n     handler.map_ = &map_;\n     return batch->Iterate(&handler);\n   }\n \n-  virtual bool GetProperty(const Slice& property, std::string* value) {\n+  bool GetProperty(const Slice& property, std::string* value) override {\n     return false;\n   }\n-  virtual void GetApproximateSizes(const Range* r, int n, uint64_t* sizes) {\n+  void GetApproximateSizes(const Range* r, int n, uint64_t* sizes) override {\n     for (int i = 0; i < n; i++) {\n       sizes[i] = 0;\n     }\n   }\n-  virtual void CompactRange(const Slice* start, const Slice* end) {\n-  }\n+  void CompactRange(const Slice* start, const Slice* end) override {}\n \n  private:\n-  class ModelIter: public Iterator {\n+  class ModelIter : public Iterator {\n    public:\n     ModelIter(const KVMap* map, bool owned)\n-        : map_(map), owned_(owned), iter_(map_->end()) {\n-    }\n-    ~ModelIter() {\n+        : map_(map), owned_(owned), iter_(map_->end()) {}\n+    ~ModelIter() override {\n       if (owned_) delete map_;\n     }\n-    virtual bool Valid() const { return iter_ != map_->end(); }\n-    virtual void SeekToFirst() { iter_ = map_->begin(); }\n-    virtual void SeekToLast() {\n+    bool Valid() const override { return iter_ != map_->end(); }\n+    void SeekToFirst() override { iter_ = map_->begin(); }\n+    void SeekToLast() override {\n       if (map_->empty()) {\n         iter_ = map_->end();\n       } else {\n         iter_ = map_->find(map_->rbegin()->first);\n       }\n     }\n-    virtual void Seek(const Slice& k) {\n+    void Seek(const Slice& k) override {\n       iter_ = map_->lower_bound(k.ToString());\n     }\n-    virtual void Next() { ++iter_; }\n-    virtual void Prev() { --iter_; }\n-    virtual Slice key() const { return iter_->first; }\n-    virtual Slice value() const { return iter_->second; }\n-    virtual Status status() const { return Status::OK(); }\n+    void Next() override { ++iter_; }\n+    void Prev() override { --iter_; }\n+    Slice key() const override { return iter_->first; }\n+    Slice value() const override { return iter_->second; }\n+    Status status() const override { return Status::OK(); }\n+\n    private:\n     const KVMap* const map_;\n     const bool owned_;  // Do we own map_\n@@ -1959,16 +2118,7 @@ class ModelDB: public DB {\n   KVMap map_;\n };\n \n-static std::string RandomKey(Random* rnd) {\n-  int len = (rnd->OneIn(3)\n-             ? 1                // Short sometimes to encourage collisions\n-             : (rnd->OneIn(100) ? rnd->Skewed(10) : rnd->Uniform(10)));\n-  return test::RandomKey(rnd, len);\n-}\n-\n-static bool CompareIterators(int step,\n-                             DB* model,\n-                             DB* db,\n+static bool CompareIterators(int step, DB* model, DB* db,\n                              const Snapshot* model_snap,\n                              const Snapshot* db_snap) {\n   ReadOptions options;\n@@ -1979,12 +2129,10 @@ static bool CompareIterators(int step,\n   bool ok = true;\n   int count = 0;\n   for (miter->SeekToFirst(), dbiter->SeekToFirst();\n-       ok && miter->Valid() && dbiter->Valid();\n-       miter->Next(), dbiter->Next()) {\n+       ok && miter->Valid() && dbiter->Valid(); miter->Next(), dbiter->Next()) {\n     count++;\n     if (miter->key().compare(dbiter->key()) != 0) {\n-      fprintf(stderr, \"step %d: Key mismatch: '%s' vs. '%s'\\n\",\n-              step,\n+      fprintf(stderr, \"step %d: Key mismatch: '%s' vs. '%s'\\n\", step,\n               EscapeString(miter->key()).c_str(),\n               EscapeString(dbiter->key()).c_str());\n       ok = false;\n@@ -1993,8 +2141,7 @@ static bool CompareIterators(int step,\n \n     if (miter->value().compare(dbiter->value()) != 0) {\n       fprintf(stderr, \"step %d: Value mismatch for key '%s': '%s' vs. '%s'\\n\",\n-              step,\n-              EscapeString(miter->key()).c_str(),\n+              step, EscapeString(miter->key()).c_str(),\n               EscapeString(miter->value()).c_str(),\n               EscapeString(miter->value()).c_str());\n       ok = false;\n@@ -2019,31 +2166,28 @@ TEST(DBTest, Randomized) {\n   do {\n     ModelDB model(CurrentOptions());\n     const int N = 10000;\n-    const Snapshot* model_snap = NULL;\n-    const Snapshot* db_snap = NULL;\n+    const Snapshot* model_snap = nullptr;\n+    const Snapshot* db_snap = nullptr;\n     std::string k, v;\n     for (int step = 0; step < N; step++) {\n       if (step % 100 == 0) {\n         fprintf(stderr, \"Step %d of %d\\n\", step, N);\n       }\n       // TODO(sanjay): Test Get() works\n       int p = rnd.Uniform(100);\n-      if (p < 45) {                               // Put\n+      if (p < 45) {  // Put\n         k = RandomKey(&rnd);\n-        v = RandomString(&rnd,\n-                         rnd.OneIn(20)\n-                         ? 100 + rnd.Uniform(100)\n-                         : rnd.Uniform(8));\n+        v = RandomString(\n+            &rnd, rnd.OneIn(20) ? 100 + rnd.Uniform(100) : rnd.Uniform(8));\n         ASSERT_OK(model.Put(WriteOptions(), k, v));\n         ASSERT_OK(db_->Put(WriteOptions(), k, v));\n \n-      } else if (p < 90) {                        // Delete\n+      } else if (p < 90) {  // Delete\n         k = RandomKey(&rnd);\n         ASSERT_OK(model.Delete(WriteOptions(), k));\n         ASSERT_OK(db_->Delete(WriteOptions(), k));\n \n-\n-      } else {                                    // Multi-element batch\n+      } else {  // Multi-element batch\n         WriteBatch b;\n         const int num = rnd.Uniform(8);\n         for (int i = 0; i < num; i++) {\n@@ -2065,23 +2209,23 @@ TEST(DBTest, Randomized) {\n       }\n \n       if ((step % 100) == 0) {\n-        ASSERT_TRUE(CompareIterators(step, &model, db_, NULL, NULL));\n+        ASSERT_TRUE(CompareIterators(step, &model, db_, nullptr, nullptr));\n         ASSERT_TRUE(CompareIterators(step, &model, db_, model_snap, db_snap));\n         // Save a snapshot from each DB this time that we'll use next\n         // time we compare things, to make sure the current state is\n         // preserved with the snapshot\n-        if (model_snap != NULL) model.ReleaseSnapshot(model_snap);\n-        if (db_snap != NULL) db_->ReleaseSnapshot(db_snap);\n+        if (model_snap != nullptr) model.ReleaseSnapshot(model_snap);\n+        if (db_snap != nullptr) db_->ReleaseSnapshot(db_snap);\n \n         Reopen();\n-        ASSERT_TRUE(CompareIterators(step, &model, db_, NULL, NULL));\n+        ASSERT_TRUE(CompareIterators(step, &model, db_, nullptr, nullptr));\n \n         model_snap = model.GetSnapshot();\n         db_snap = db_->GetSnapshot();\n       }\n     }\n-    if (model_snap != NULL) model.ReleaseSnapshot(model_snap);\n-    if (db_snap != NULL) db_->ReleaseSnapshot(db_snap);\n+    if (model_snap != nullptr) model.ReleaseSnapshot(model_snap);\n+    if (db_snap != nullptr) db_->ReleaseSnapshot(db_snap);\n   } while (ChangeOptions());\n }\n \n@@ -2095,15 +2239,15 @@ void BM_LogAndApply(int iters, int num_base_files) {\n   std::string dbname = test::TmpDir() + \"/leveldb_test_benchmark\";\n   DestroyDB(dbname, Options());\n \n-  DB* db = NULL;\n+  DB* db = nullptr;\n   Options opts;\n   opts.create_if_missing = true;\n   Status s = DB::Open(opts, dbname, &db);\n   ASSERT_OK(s);\n-  ASSERT_TRUE(db != NULL);\n+  ASSERT_TRUE(db != nullptr);\n \n   delete db;\n-  db = NULL;\n+  db = nullptr;\n \n   Env* env = Env::Default();\n \n@@ -2112,14 +2256,14 @@ void BM_LogAndApply(int iters, int num_base_files) {\n \n   InternalKeyComparator cmp(BytewiseComparator());\n   Options options;\n-  VersionSet vset(dbname, &options, NULL, &cmp);\n+  VersionSet vset(dbname, &options, nullptr, &cmp);\n   bool save_manifest;\n   ASSERT_OK(vset.Recover(&save_manifest));\n   VersionEdit vbase;\n   uint64_t fnum = 1;\n   for (int i = 0; i < num_base_files; i++) {\n-    InternalKey start(MakeKey(2*fnum), 1, kTypeValue);\n-    InternalKey limit(MakeKey(2*fnum+1), 1, kTypeDeletion);\n+    InternalKey start(MakeKey(2 * fnum), 1, kTypeValue);\n+    InternalKey limit(MakeKey(2 * fnum + 1), 1, kTypeDeletion);\n     vbase.AddFile(2, fnum++, 1 /* file size */, start, limit);\n   }\n   ASSERT_OK(vset.LogAndApply(&vbase, &mu));\n@@ -2129,8 +2273,8 @@ void BM_LogAndApply(int iters, int num_base_files) {\n   for (int i = 0; i < iters; i++) {\n     VersionEdit vedit;\n     vedit.DeleteFile(2, fnum);\n-    InternalKey start(MakeKey(2*fnum), 1, kTypeValue);\n-    InternalKey limit(MakeKey(2*fnum+1), 1, kTypeDeletion);\n+    InternalKey start(MakeKey(2 * fnum), 1, kTypeValue);\n+    InternalKey limit(MakeKey(2 * fnum + 1), 1, kTypeDeletion);\n     vedit.AddFile(2, fnum++, 1 /* file size */, start, limit);\n     vset.LogAndApply(&vedit, &mu);\n   }\n@@ -2139,8 +2283,8 @@ void BM_LogAndApply(int iters, int num_base_files) {\n   char buf[16];\n   snprintf(buf, sizeof(buf), \"%d\", num_base_files);\n   fprintf(stderr,\n-          \"BM_LogAndApply/%-6s   %8d iters : %9u us (%7.0f us / iter)\\n\",\n-          buf, iters, us, ((float)us) / iters);\n+          \"BM_LogAndApply/%-6s   %8d iters : %9u us (%7.0f us / iter)\\n\", buf,\n+          iters, us, ((float)us) / iters);\n }\n \n }  // namespace leveldb"
      },
      {
        "sha": "459eddf5b136f06876192b893a7b5cb0fea3800e",
        "filename": "db/dbformat.cc",
        "status": "modified",
        "additions": 20,
        "deletions": 23,
        "changes": 43,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/dbformat.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/dbformat.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/dbformat.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -2,8 +2,12 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include <stdio.h>\n #include \"db/dbformat.h\"\n+\n+#include <stdio.h>\n+\n+#include <sstream>\n+\n #include \"port/port.h\"\n #include \"util/coding.h\"\n \n@@ -21,26 +25,20 @@ void AppendInternalKey(std::string* result, const ParsedInternalKey& key) {\n }\n \n std::string ParsedInternalKey::DebugString() const {\n-  char buf[50];\n-  snprintf(buf, sizeof(buf), \"' @ %llu : %d\",\n-           (unsigned long long) sequence,\n-           int(type));\n-  std::string result = \"'\";\n-  result += EscapeString(user_key.ToString());\n-  result += buf;\n-  return result;\n+  std::ostringstream ss;\n+  ss << '\\'' << EscapeString(user_key.ToString()) << \"' @ \" << sequence << \" : \"\n+     << static_cast<int>(type);\n+  return ss.str();\n }\n \n std::string InternalKey::DebugString() const {\n-  std::string result;\n   ParsedInternalKey parsed;\n   if (ParseInternalKey(rep_, &parsed)) {\n-    result = parsed.DebugString();\n-  } else {\n-    result = \"(bad)\";\n-    result.append(EscapeString(rep_));\n+    return parsed.DebugString();\n   }\n-  return result;\n+  std::ostringstream ss;\n+  ss << \"(bad)\" << EscapeString(rep_);\n+  return ss.str();\n }\n \n const char* InternalKeyComparator::Name() const {\n@@ -65,9 +63,8 @@ int InternalKeyComparator::Compare(const Slice& akey, const Slice& bkey) const {\n   return r;\n }\n \n-void InternalKeyComparator::FindShortestSeparator(\n-      std::string* start,\n-      const Slice& limit) const {\n+void InternalKeyComparator::FindShortestSeparator(std::string* start,\n+                                                  const Slice& limit) const {\n   // Attempt to shorten the user portion of the key\n   Slice user_start = ExtractUserKey(*start);\n   Slice user_limit = ExtractUserKey(limit);\n@@ -77,7 +74,8 @@ void InternalKeyComparator::FindShortestSeparator(\n       user_comparator_->Compare(user_start, tmp) < 0) {\n     // User key has become shorter physically, but larger logically.\n     // Tack on the earliest possible number to the shortened user key.\n-    PutFixed64(&tmp, PackSequenceAndType(kMaxSequenceNumber,kValueTypeForSeek));\n+    PutFixed64(&tmp,\n+               PackSequenceAndType(kMaxSequenceNumber, kValueTypeForSeek));\n     assert(this->Compare(*start, tmp) < 0);\n     assert(this->Compare(tmp, limit) < 0);\n     start->swap(tmp);\n@@ -92,15 +90,14 @@ void InternalKeyComparator::FindShortSuccessor(std::string* key) const {\n       user_comparator_->Compare(user_key, tmp) < 0) {\n     // User key has become shorter physically, but larger logically.\n     // Tack on the earliest possible number to the shortened user key.\n-    PutFixed64(&tmp, PackSequenceAndType(kMaxSequenceNumber,kValueTypeForSeek));\n+    PutFixed64(&tmp,\n+               PackSequenceAndType(kMaxSequenceNumber, kValueTypeForSeek));\n     assert(this->Compare(*key, tmp) < 0);\n     key->swap(tmp);\n   }\n }\n \n-const char* InternalFilterPolicy::Name() const {\n-  return user_policy_->Name();\n-}\n+const char* InternalFilterPolicy::Name() const { return user_policy_->Name(); }\n \n void InternalFilterPolicy::CreateFilter(const Slice* keys, int n,\n                                         std::string* dst) const {"
      },
      {
        "sha": "a1c30ed88c2c822e3d8f529649492d069156cfda",
        "filename": "db/dbformat.h",
        "status": "modified",
        "additions": 37,
        "deletions": 43,
        "changes": 80,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/dbformat.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/dbformat.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/dbformat.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -5,7 +5,10 @@\n #ifndef STORAGE_LEVELDB_DB_DBFORMAT_H_\n #define STORAGE_LEVELDB_DB_DBFORMAT_H_\n \n-#include <stdio.h>\n+#include <cstddef>\n+#include <cstdint>\n+#include <string>\n+\n #include \"leveldb/comparator.h\"\n #include \"leveldb/db.h\"\n #include \"leveldb/filter_policy.h\"\n@@ -48,10 +51,7 @@ class InternalKey;\n // Value types encoded as the last component of internal keys.\n // DO NOT CHANGE THESE ENUM VALUES: they are embedded in the on-disk\n // data structures.\n-enum ValueType {\n-  kTypeDeletion = 0x0,\n-  kTypeValue = 0x1\n-};\n+enum ValueType { kTypeDeletion = 0x0, kTypeValue = 0x1 };\n // kValueTypeForSeek defines the ValueType that should be passed when\n // constructing a ParsedInternalKey object for seeking to a particular\n // sequence number (since we sort sequence numbers in decreasing order\n@@ -64,17 +64,16 @@ typedef uint64_t SequenceNumber;\n \n // We leave eight bits empty at the bottom so a type and sequence#\n // can be packed together into 64-bits.\n-static const SequenceNumber kMaxSequenceNumber =\n-    ((0x1ull << 56) - 1);\n+static const SequenceNumber kMaxSequenceNumber = ((0x1ull << 56) - 1);\n \n struct ParsedInternalKey {\n   Slice user_key;\n   SequenceNumber sequence;\n   ValueType type;\n \n-  ParsedInternalKey() { }  // Intentionally left uninitialized (for speed)\n+  ParsedInternalKey() {}  // Intentionally left uninitialized (for speed)\n   ParsedInternalKey(const Slice& u, const SequenceNumber& seq, ValueType t)\n-      : user_key(u), sequence(seq), type(t) { }\n+      : user_key(u), sequence(seq), type(t) {}\n   std::string DebugString() const;\n };\n \n@@ -84,43 +83,33 @@ inline size_t InternalKeyEncodingLength(const ParsedInternalKey& key) {\n }\n \n // Append the serialization of \"key\" to *result.\n-extern void AppendInternalKey(std::string* result,\n-                              const ParsedInternalKey& key);\n+void AppendInternalKey(std::string* result, const ParsedInternalKey& key);\n \n // Attempt to parse an internal key from \"internal_key\".  On success,\n // stores the parsed data in \"*result\", and returns true.\n //\n // On error, returns false, leaves \"*result\" in an undefined state.\n-extern bool ParseInternalKey(const Slice& internal_key,\n-                             ParsedInternalKey* result);\n+bool ParseInternalKey(const Slice& internal_key, ParsedInternalKey* result);\n \n // Returns the user key portion of an internal key.\n inline Slice ExtractUserKey(const Slice& internal_key) {\n   assert(internal_key.size() >= 8);\n   return Slice(internal_key.data(), internal_key.size() - 8);\n }\n \n-inline ValueType ExtractValueType(const Slice& internal_key) {\n-  assert(internal_key.size() >= 8);\n-  const size_t n = internal_key.size();\n-  uint64_t num = DecodeFixed64(internal_key.data() + n - 8);\n-  unsigned char c = num & 0xff;\n-  return static_cast<ValueType>(c);\n-}\n-\n // A comparator for internal keys that uses a specified comparator for\n // the user key portion and breaks ties by decreasing sequence number.\n class InternalKeyComparator : public Comparator {\n  private:\n   const Comparator* user_comparator_;\n+\n  public:\n-  explicit InternalKeyComparator(const Comparator* c) : user_comparator_(c) { }\n-  virtual const char* Name() const;\n-  virtual int Compare(const Slice& a, const Slice& b) const;\n-  virtual void FindShortestSeparator(\n-      std::string* start,\n-      const Slice& limit) const;\n-  virtual void FindShortSuccessor(std::string* key) const;\n+  explicit InternalKeyComparator(const Comparator* c) : user_comparator_(c) {}\n+  const char* Name() const override;\n+  int Compare(const Slice& a, const Slice& b) const override;\n+  void FindShortestSeparator(std::string* start,\n+                             const Slice& limit) const override;\n+  void FindShortSuccessor(std::string* key) const override;\n \n   const Comparator* user_comparator() const { return user_comparator_; }\n \n@@ -131,11 +120,12 @@ class InternalKeyComparator : public Comparator {\n class InternalFilterPolicy : public FilterPolicy {\n  private:\n   const FilterPolicy* const user_policy_;\n+\n  public:\n-  explicit InternalFilterPolicy(const FilterPolicy* p) : user_policy_(p) { }\n-  virtual const char* Name() const;\n-  virtual void CreateFilter(const Slice* keys, int n, std::string* dst) const;\n-  virtual bool KeyMayMatch(const Slice& key, const Slice& filter) const;\n+  explicit InternalFilterPolicy(const FilterPolicy* p) : user_policy_(p) {}\n+  const char* Name() const override;\n+  void CreateFilter(const Slice* keys, int n, std::string* dst) const override;\n+  bool KeyMayMatch(const Slice& key, const Slice& filter) const override;\n };\n \n // Modules in this directory should keep internal keys wrapped inside\n@@ -144,13 +134,18 @@ class InternalFilterPolicy : public FilterPolicy {\n class InternalKey {\n  private:\n   std::string rep_;\n+\n  public:\n-  InternalKey() { }   // Leave rep_ as empty to indicate it is invalid\n+  InternalKey() {}  // Leave rep_ as empty to indicate it is invalid\n   InternalKey(const Slice& user_key, SequenceNumber s, ValueType t) {\n     AppendInternalKey(&rep_, ParsedInternalKey(user_key, s, t));\n   }\n \n-  void DecodeFrom(const Slice& s) { rep_.assign(s.data(), s.size()); }\n+  bool DecodeFrom(const Slice& s) {\n+    rep_.assign(s.data(), s.size());\n+    return !rep_.empty();\n+  }\n+\n   Slice Encode() const {\n     assert(!rep_.empty());\n     return rep_;\n@@ -168,8 +163,8 @@ class InternalKey {\n   std::string DebugString() const;\n };\n \n-inline int InternalKeyComparator::Compare(\n-    const InternalKey& a, const InternalKey& b) const {\n+inline int InternalKeyComparator::Compare(const InternalKey& a,\n+                                          const InternalKey& b) const {\n   return Compare(a.Encode(), b.Encode());\n }\n \n@@ -178,11 +173,11 @@ inline bool ParseInternalKey(const Slice& internal_key,\n   const size_t n = internal_key.size();\n   if (n < 8) return false;\n   uint64_t num = DecodeFixed64(internal_key.data() + n - 8);\n-  unsigned char c = num & 0xff;\n+  uint8_t c = num & 0xff;\n   result->sequence = num >> 8;\n   result->type = static_cast<ValueType>(c);\n   result->user_key = Slice(internal_key.data(), n - 8);\n-  return (c <= static_cast<unsigned char>(kTypeValue));\n+  return (c <= static_cast<uint8_t>(kTypeValue));\n }\n \n // A helper class useful for DBImpl::Get()\n@@ -192,6 +187,9 @@ class LookupKey {\n   // the specified sequence number.\n   LookupKey(const Slice& user_key, SequenceNumber sequence);\n \n+  LookupKey(const LookupKey&) = delete;\n+  LookupKey& operator=(const LookupKey&) = delete;\n+\n   ~LookupKey();\n \n   // Return a key suitable for lookup in a MemTable.\n@@ -214,11 +212,7 @@ class LookupKey {\n   const char* start_;\n   const char* kstart_;\n   const char* end_;\n-  char space_[200];      // Avoid allocation for short keys\n-\n-  // No copying allowed\n-  LookupKey(const LookupKey&);\n-  void operator=(const LookupKey&);\n+  char space_[200];  // Avoid allocation for short keys\n };\n \n inline LookupKey::~LookupKey() {"
      },
      {
        "sha": "1209369c31a038ca1c895b213b509155a8d54a8f",
        "filename": "db/dbformat_test.cc",
        "status": "modified",
        "additions": 57,
        "deletions": 38,
        "changes": 95,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/dbformat_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/dbformat_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/dbformat_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -8,8 +8,7 @@\n \n namespace leveldb {\n \n-static std::string IKey(const std::string& user_key,\n-                        uint64_t seq,\n+static std::string IKey(const std::string& user_key, uint64_t seq,\n                         ValueType vt) {\n   std::string encoded;\n   AppendInternalKey(&encoded, ParsedInternalKey(user_key, seq, vt));\n@@ -28,9 +27,7 @@ static std::string ShortSuccessor(const std::string& s) {\n   return result;\n }\n \n-static void TestKey(const std::string& key,\n-                    uint64_t seq,\n-                    ValueType vt) {\n+static void TestKey(const std::string& key, uint64_t seq, ValueType vt) {\n   std::string encoded = IKey(key, seq, vt);\n \n   Slice in(encoded);\n@@ -44,16 +41,22 @@ static void TestKey(const std::string& key,\n   ASSERT_TRUE(!ParseInternalKey(Slice(\"bar\"), &decoded));\n }\n \n-class FormatTest { };\n+class FormatTest {};\n \n TEST(FormatTest, InternalKey_EncodeDecode) {\n-  const char* keys[] = { \"\", \"k\", \"hello\", \"longggggggggggggggggggggg\" };\n-  const uint64_t seq[] = {\n-    1, 2, 3,\n-    (1ull << 8) - 1, 1ull << 8, (1ull << 8) + 1,\n-    (1ull << 16) - 1, 1ull << 16, (1ull << 16) + 1,\n-    (1ull << 32) - 1, 1ull << 32, (1ull << 32) + 1\n-  };\n+  const char* keys[] = {\"\", \"k\", \"hello\", \"longggggggggggggggggggggg\"};\n+  const uint64_t seq[] = {1,\n+                          2,\n+                          3,\n+                          (1ull << 8) - 1,\n+                          1ull << 8,\n+                          (1ull << 8) + 1,\n+                          (1ull << 16) - 1,\n+                          1ull << 16,\n+                          (1ull << 16) + 1,\n+                          (1ull << 32) - 1,\n+                          1ull << 32,\n+                          (1ull << 32) + 1};\n   for (int k = 0; k < sizeof(keys) / sizeof(keys[0]); k++) {\n     for (int s = 0; s < sizeof(seq) / sizeof(seq[0]); s++) {\n       TestKey(keys[k], seq[s], kTypeValue);\n@@ -62,40 +65,44 @@ TEST(FormatTest, InternalKey_EncodeDecode) {\n   }\n }\n \n+TEST(FormatTest, InternalKey_DecodeFromEmpty) {\n+  InternalKey internal_key;\n+\n+  ASSERT_TRUE(!internal_key.DecodeFrom(\"\"));\n+}\n+\n TEST(FormatTest, InternalKeyShortSeparator) {\n   // When user keys are same\n   ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"foo\", 99, kTypeValue)));\n-  ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"foo\", 101, kTypeValue)));\n-  ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"foo\", 100, kTypeValue)));\n-  ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"foo\", 100, kTypeDeletion)));\n+            Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"foo\", 99, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"foo\", 100, kTypeValue),\n+      Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"foo\", 101, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"foo\", 100, kTypeValue),\n+      Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"foo\", 100, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"foo\", 100, kTypeValue),\n+      Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"foo\", 100, kTypeDeletion)));\n \n   // When user keys are misordered\n   ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"bar\", 99, kTypeValue)));\n+            Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"bar\", 99, kTypeValue)));\n \n   // When user keys are different, but correctly ordered\n-  ASSERT_EQ(IKey(\"g\", kMaxSequenceNumber, kValueTypeForSeek),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"hello\", 200, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"g\", kMaxSequenceNumber, kValueTypeForSeek),\n+      Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"hello\", 200, kTypeValue)));\n \n   // When start user key is prefix of limit user key\n-  ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"foobar\", 200, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"foo\", 100, kTypeValue),\n+      Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"foobar\", 200, kTypeValue)));\n \n   // When limit user key is prefix of start user key\n-  ASSERT_EQ(IKey(\"foobar\", 100, kTypeValue),\n-            Shorten(IKey(\"foobar\", 100, kTypeValue),\n-                    IKey(\"foo\", 200, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"foobar\", 100, kTypeValue),\n+      Shorten(IKey(\"foobar\", 100, kTypeValue), IKey(\"foo\", 200, kTypeValue)));\n }\n \n TEST(FormatTest, InternalKeyShortestSuccessor) {\n@@ -105,8 +112,20 @@ TEST(FormatTest, InternalKeyShortestSuccessor) {\n             ShortSuccessor(IKey(\"\\xff\\xff\", 100, kTypeValue)));\n }\n \n-}  // namespace leveldb\n+TEST(FormatTest, ParsedInternalKeyDebugString) {\n+  ParsedInternalKey key(\"The \\\"key\\\" in 'single quotes'\", 42, kTypeValue);\n+\n+  ASSERT_EQ(\"'The \\\"key\\\" in 'single quotes'' @ 42 : 1\", key.DebugString());\n+}\n+\n+TEST(FormatTest, InternalKeyDebugString) {\n+  InternalKey key(\"The \\\"key\\\" in 'single quotes'\", 42, kTypeValue);\n+  ASSERT_EQ(\"'The \\\"key\\\" in 'single quotes'' @ 42 : 1\", key.DebugString());\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n+  InternalKey invalid_key;\n+  ASSERT_EQ(\"(bad)\", invalid_key.DebugString());\n }\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "77d59003cf9696c9eba8728ffee67035cde5cd57",
        "filename": "db/dumpfile.cc",
        "status": "modified",
        "additions": 18,
        "deletions": 11,
        "changes": 29,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/dumpfile.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/dumpfile.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/dumpfile.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -2,7 +2,10 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n+#include \"leveldb/dumpfile.h\"\n+\n #include <stdio.h>\n+\n #include \"db/dbformat.h\"\n #include \"db/filename.h\"\n #include \"db/log_reader.h\"\n@@ -35,15 +38,16 @@ bool GuessType(const std::string& fname, FileType* type) {\n // Notified when log reader encounters corruption.\n class CorruptionReporter : public log::Reader::Reporter {\n  public:\n-  WritableFile* dst_;\n-  virtual void Corruption(size_t bytes, const Status& status) {\n+  void Corruption(size_t bytes, const Status& status) override {\n     std::string r = \"corruption: \";\n     AppendNumberTo(&r, bytes);\n     r += \" bytes; \";\n     r += status.ToString();\n     r.push_back('\\n');\n     dst_->Append(r);\n   }\n+\n+  WritableFile* dst_;\n };\n \n // Print contents of a log file. (*func)() is called on every record.\n@@ -70,23 +74,23 @@ Status PrintLogContents(Env* env, const std::string& fname,\n // Called on every item found in a WriteBatch.\n class WriteBatchItemPrinter : public WriteBatch::Handler {\n  public:\n-  WritableFile* dst_;\n-  virtual void Put(const Slice& key, const Slice& value) {\n+  void Put(const Slice& key, const Slice& value) override {\n     std::string r = \"  put '\";\n     AppendEscapedStringTo(&r, key);\n     r += \"' '\";\n     AppendEscapedStringTo(&r, value);\n     r += \"'\\n\";\n     dst_->Append(r);\n   }\n-  virtual void Delete(const Slice& key) {\n+  void Delete(const Slice& key) override {\n     std::string r = \"  del '\";\n     AppendEscapedStringTo(&r, key);\n     r += \"'\\n\";\n     dst_->Append(r);\n   }\n-};\n \n+  WritableFile* dst_;\n+};\n \n // Called on every log record (each one of which is a WriteBatch)\n // found in a kLogFile.\n@@ -142,8 +146,8 @@ Status DumpDescriptor(Env* env, const std::string& fname, WritableFile* dst) {\n \n Status DumpTable(Env* env, const std::string& fname, WritableFile* dst) {\n   uint64_t file_size;\n-  RandomAccessFile* file = NULL;\n-  Table* table = NULL;\n+  RandomAccessFile* file = nullptr;\n+  Table* table = nullptr;\n   Status s = env->GetFileSize(fname, &file_size);\n   if (s.ok()) {\n     s = env->NewRandomAccessFile(fname, &file);\n@@ -213,9 +217,12 @@ Status DumpFile(Env* env, const std::string& fname, WritableFile* dst) {\n     return Status::InvalidArgument(fname + \": unknown file type\");\n   }\n   switch (ftype) {\n-    case kLogFile:         return DumpLog(env, fname, dst);\n-    case kDescriptorFile:  return DumpDescriptor(env, fname, dst);\n-    case kTableFile:       return DumpTable(env, fname, dst);\n+    case kLogFile:\n+      return DumpLog(env, fname, dst);\n+    case kDescriptorFile:\n+      return DumpDescriptor(env, fname, dst);\n+    case kTableFile:\n+      return DumpTable(env, fname, dst);\n     default:\n       break;\n   }"
      },
      {
        "sha": "bf705cb60f2431f8b6d163a5fd94656b47eda431",
        "filename": "db/fault_injection_test.cc",
        "status": "modified",
        "additions": 65,
        "deletions": 67,
        "changes": 132,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/fault_injection_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/fault_injection_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/fault_injection_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -6,18 +6,20 @@\n // the last \"sync\". It then checks for data loss errors by purposely dropping\n // file data (or entire files) not protected by a \"sync\".\n \n-#include \"leveldb/db.h\"\n-\n #include <map>\n #include <set>\n+\n #include \"db/db_impl.h\"\n #include \"db/filename.h\"\n #include \"db/log_format.h\"\n #include \"db/version_set.h\"\n #include \"leveldb/cache.h\"\n+#include \"leveldb/db.h\"\n #include \"leveldb/env.h\"\n #include \"leveldb/table.h\"\n #include \"leveldb/write_batch.h\"\n+#include \"port/port.h\"\n+#include \"port/thread_annotations.h\"\n #include \"util/logging.h\"\n #include \"util/mutexlock.h\"\n #include \"util/testharness.h\"\n@@ -34,7 +36,7 @@ class FaultInjectionTestEnv;\n namespace {\n \n // Assume a filename, and not a directory name like \"/foo/bar/\"\n-static std::string GetDirName(const std::string filename) {\n+static std::string GetDirName(const std::string& filename) {\n   size_t found = filename.find_last_of(\"/\\\\\");\n   if (found == std::string::npos) {\n     return \"\";\n@@ -54,8 +56,7 @@ Status Truncate(const std::string& filename, uint64_t length) {\n \n   SequentialFile* orig_file;\n   Status s = env->NewSequentialFile(filename, &orig_file);\n-  if (!s.ok())\n-    return s;\n+  if (!s.ok()) return s;\n \n   char* scratch = new char[length];\n   leveldb::Slice result;\n@@ -83,15 +84,15 @@ Status Truncate(const std::string& filename, uint64_t length) {\n \n struct FileState {\n   std::string filename_;\n-  ssize_t pos_;\n-  ssize_t pos_at_last_sync_;\n-  ssize_t pos_at_last_flush_;\n+  int64_t pos_;\n+  int64_t pos_at_last_sync_;\n+  int64_t pos_at_last_flush_;\n \n   FileState(const std::string& filename)\n       : filename_(filename),\n         pos_(-1),\n         pos_at_last_sync_(-1),\n-        pos_at_last_flush_(-1) { }\n+        pos_at_last_flush_(-1) {}\n \n   FileState() : pos_(-1), pos_at_last_sync_(-1), pos_at_last_flush_(-1) {}\n \n@@ -106,14 +107,14 @@ struct FileState {\n // is written to or sync'ed.\n class TestWritableFile : public WritableFile {\n  public:\n-  TestWritableFile(const FileState& state,\n-                   WritableFile* f,\n+  TestWritableFile(const FileState& state, WritableFile* f,\n                    FaultInjectionTestEnv* env);\n-  virtual ~TestWritableFile();\n-  virtual Status Append(const Slice& data);\n-  virtual Status Close();\n-  virtual Status Flush();\n-  virtual Status Sync();\n+  ~TestWritableFile() override;\n+  Status Append(const Slice& data) override;\n+  Status Close() override;\n+  Status Flush() override;\n+  Status Sync() override;\n+  std::string GetName() const override { return \"\"; }\n \n  private:\n   FileState state_;\n@@ -126,14 +127,15 @@ class TestWritableFile : public WritableFile {\n \n class FaultInjectionTestEnv : public EnvWrapper {\n  public:\n-  FaultInjectionTestEnv() : EnvWrapper(Env::Default()), filesystem_active_(true) {}\n-  virtual ~FaultInjectionTestEnv() { }\n-  virtual Status NewWritableFile(const std::string& fname,\n-                                 WritableFile** result);\n-  virtual Status NewAppendableFile(const std::string& fname,\n-                                   WritableFile** result);\n-  virtual Status DeleteFile(const std::string& f);\n-  virtual Status RenameFile(const std::string& s, const std::string& t);\n+  FaultInjectionTestEnv()\n+      : EnvWrapper(Env::Default()), filesystem_active_(true) {}\n+  ~FaultInjectionTestEnv() override = default;\n+  Status NewWritableFile(const std::string& fname,\n+                         WritableFile** result) override;\n+  Status NewAppendableFile(const std::string& fname,\n+                           WritableFile** result) override;\n+  Status DeleteFile(const std::string& f) override;\n+  Status RenameFile(const std::string& s, const std::string& t) override;\n \n   void WritableFileClosed(const FileState& state);\n   Status DropUnsyncedFileData();\n@@ -146,24 +148,26 @@ class FaultInjectionTestEnv : public EnvWrapper {\n   // system reset. Setting to inactive will freeze our saved filesystem state so\n   // that it will stop being recorded. It can then be reset back to the state at\n   // the time of the reset.\n-  bool IsFilesystemActive() const { return filesystem_active_; }\n-  void SetFilesystemActive(bool active) { filesystem_active_ = active; }\n+  bool IsFilesystemActive() LOCKS_EXCLUDED(mutex_) {\n+    MutexLock l(&mutex_);\n+    return filesystem_active_;\n+  }\n+  void SetFilesystemActive(bool active) LOCKS_EXCLUDED(mutex_) {\n+    MutexLock l(&mutex_);\n+    filesystem_active_ = active;\n+  }\n \n  private:\n   port::Mutex mutex_;\n-  std::map<std::string, FileState> db_file_state_;\n-  std::set<std::string> new_files_since_last_dir_sync_;\n-  bool filesystem_active_;  // Record flushes, syncs, writes\n+  std::map<std::string, FileState> db_file_state_ GUARDED_BY(mutex_);\n+  std::set<std::string> new_files_since_last_dir_sync_ GUARDED_BY(mutex_);\n+  bool filesystem_active_ GUARDED_BY(mutex_);  // Record flushes, syncs, writes\n };\n \n-TestWritableFile::TestWritableFile(const FileState& state,\n-                                   WritableFile* f,\n+TestWritableFile::TestWritableFile(const FileState& state, WritableFile* f,\n                                    FaultInjectionTestEnv* env)\n-    : state_(state),\n-      target_(f),\n-      writable_file_opened_(true),\n-      env_(env) {\n-  assert(f != NULL);\n+    : state_(state), target_(f), writable_file_opened_(true), env_(env) {\n+  assert(f != nullptr);\n }\n \n TestWritableFile::~TestWritableFile() {\n@@ -265,10 +269,11 @@ Status FaultInjectionTestEnv::NewAppendableFile(const std::string& fname,\n Status FaultInjectionTestEnv::DropUnsyncedFileData() {\n   Status s;\n   MutexLock l(&mutex_);\n-  for (std::map<std::string, FileState>::const_iterator it =\n-           db_file_state_.begin();\n-       s.ok() && it != db_file_state_.end(); ++it) {\n-    const FileState& state = it->second;\n+  for (const auto& kvp : db_file_state_) {\n+    if (!s.ok()) {\n+      break;\n+    }\n+    const FileState& state = kvp.second;\n     if (!state.IsFullySynced()) {\n       s = state.DropUnsyncedData();\n     }\n@@ -328,7 +333,6 @@ void FaultInjectionTestEnv::ResetState() {\n   // Since we are not destroying the database, the existing files\n   // should keep their recorded synced/flushed state. Therefore\n   // we do not reset db_file_state_ and new_files_since_last_dir_sync_.\n-  MutexLock l(&mutex_);\n   SetFilesystemActive(true);\n }\n \n@@ -338,12 +342,14 @@ Status FaultInjectionTestEnv::DeleteFilesCreatedAfterLastDirSync() {\n   std::set<std::string> new_files(new_files_since_last_dir_sync_.begin(),\n                                   new_files_since_last_dir_sync_.end());\n   mutex_.Unlock();\n-  Status s;\n-  std::set<std::string>::const_iterator it;\n-  for (it = new_files.begin(); s.ok() && it != new_files.end(); ++it) {\n-    s = DeleteFile(*it);\n+  Status status;\n+  for (const auto& new_file : new_files) {\n+    Status delete_status = DeleteFile(new_file);\n+    if (!delete_status.ok() && status.ok()) {\n+      status = std::move(delete_status);\n+    }\n   }\n-  return s;\n+  return status;\n }\n \n void FaultInjectionTestEnv::WritableFileClosed(const FileState& state) {\n@@ -352,7 +358,7 @@ void FaultInjectionTestEnv::WritableFileClosed(const FileState& state) {\n }\n \n Status FileState::DropUnsyncedData() const {\n-  ssize_t sync_pos = pos_at_last_sync_ == -1 ? 0 : pos_at_last_sync_;\n+  int64_t sync_pos = pos_at_last_sync_ == -1 ? 0 : pos_at_last_sync_;\n   return Truncate(filename_, sync_pos);\n }\n \n@@ -370,7 +376,7 @@ class FaultInjectionTest {\n   FaultInjectionTest()\n       : env_(new FaultInjectionTestEnv),\n         tiny_cache_(NewLRUCache(100)),\n-        db_(NULL) {\n+        db_(nullptr) {\n     dbname_ = test::TmpDir() + \"/fault_test\";\n     DestroyDB(dbname_, Options());  // Destroy any db from earlier run\n     options_.reuse_logs = true;\n@@ -387,9 +393,7 @@ class FaultInjectionTest {\n     delete env_;\n   }\n \n-  void ReuseLogs(bool reuse) {\n-    options_.reuse_logs = reuse;\n-  }\n+  void ReuseLogs(bool reuse) { options_.reuse_logs = reuse; }\n \n   void Build(int start_idx, int num_vals) {\n     std::string key_space, value_space;\n@@ -449,19 +453,18 @@ class FaultInjectionTest {\n \n   Status OpenDB() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     env_->ResetState();\n     return DB::Open(options_, dbname_, &db_);\n   }\n \n   void CloseDB() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n   }\n \n   void DeleteAllData() {\n     Iterator* iter = db_->NewIterator(ReadOptions());\n-    WriteOptions options;\n     for (iter->SeekToFirst(); iter->Valid(); iter->Next()) {\n       ASSERT_OK(db_->Delete(WriteOptions(), iter->key()));\n     }\n@@ -485,23 +488,22 @@ class FaultInjectionTest {\n   void PartialCompactTestPreFault(int num_pre_sync, int num_post_sync) {\n     DeleteAllData();\n     Build(0, num_pre_sync);\n-    db_->CompactRange(NULL, NULL);\n+    db_->CompactRange(nullptr, nullptr);\n     Build(num_pre_sync, num_post_sync);\n   }\n \n   void PartialCompactTestReopenWithFault(ResetMethod reset_method,\n-                                         int num_pre_sync,\n-                                         int num_post_sync) {\n+                                         int num_pre_sync, int num_post_sync) {\n     env_->SetFilesystemActive(false);\n     CloseDB();\n     ResetDBState(reset_method);\n     ASSERT_OK(OpenDB());\n     ASSERT_OK(Verify(0, num_pre_sync, FaultInjectionTest::VAL_EXPECT_NO_ERROR));\n-    ASSERT_OK(Verify(num_pre_sync, num_post_sync, FaultInjectionTest::VAL_EXPECT_ERROR));\n+    ASSERT_OK(Verify(num_pre_sync, num_post_sync,\n+                     FaultInjectionTest::VAL_EXPECT_ERROR));\n   }\n \n-  void NoWriteTestPreFault() {\n-  }\n+  void NoWriteTestPreFault() {}\n \n   void NoWriteTestReopenWithFault(ResetMethod reset_method) {\n     CloseDB();\n@@ -517,8 +519,7 @@ class FaultInjectionTest {\n       int num_post_sync = rnd.Uniform(kMaxNumValues);\n \n       PartialCompactTestPreFault(num_pre_sync, num_post_sync);\n-      PartialCompactTestReopenWithFault(RESET_DROP_UNSYNCED_DATA,\n-                                        num_pre_sync,\n+      PartialCompactTestReopenWithFault(RESET_DROP_UNSYNCED_DATA, num_pre_sync,\n                                         num_post_sync);\n \n       NoWriteTestPreFault();\n@@ -528,8 +529,7 @@ class FaultInjectionTest {\n       // No new files created so we expect all values since no files will be\n       // dropped.\n       PartialCompactTestReopenWithFault(RESET_DELETE_UNSYNCED_FILES,\n-                                        num_pre_sync + num_post_sync,\n-                                        0);\n+                                        num_pre_sync + num_post_sync, 0);\n \n       NoWriteTestPreFault();\n       NoWriteTestReopenWithFault(RESET_DELETE_UNSYNCED_FILES);\n@@ -549,6 +549,4 @@ TEST(FaultInjectionTest, FaultTestWithLogReuse) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "85de45c507b78cc7040ba117b414f6a228d7554d",
        "filename": "db/filename.cc",
        "status": "modified",
        "additions": 17,
        "deletions": 20,
        "changes": 37,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/filename.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/filename.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/filename.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -2,41 +2,42 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n+#include \"db/filename.h\"\n+\n #include <ctype.h>\n #include <stdio.h>\n-#include \"db/filename.h\"\n+\n #include \"db/dbformat.h\"\n #include \"leveldb/env.h\"\n #include \"util/logging.h\"\n \n namespace leveldb {\n \n // A utility routine: write \"data\" to the named file and Sync() it.\n-extern Status WriteStringToFileSync(Env* env, const Slice& data,\n-                                    const std::string& fname);\n+Status WriteStringToFileSync(Env* env, const Slice& data,\n+                             const std::string& fname);\n \n-static std::string MakeFileName(const std::string& name, uint64_t number,\n+static std::string MakeFileName(const std::string& dbname, uint64_t number,\n                                 const char* suffix) {\n   char buf[100];\n   snprintf(buf, sizeof(buf), \"/%06llu.%s\",\n-           static_cast<unsigned long long>(number),\n-           suffix);\n-  return name + buf;\n+           static_cast<unsigned long long>(number), suffix);\n+  return dbname + buf;\n }\n \n-std::string LogFileName(const std::string& name, uint64_t number) {\n+std::string LogFileName(const std::string& dbname, uint64_t number) {\n   assert(number > 0);\n-  return MakeFileName(name, number, \"log\");\n+  return MakeFileName(dbname, number, \"log\");\n }\n \n-std::string TableFileName(const std::string& name, uint64_t number) {\n+std::string TableFileName(const std::string& dbname, uint64_t number) {\n   assert(number > 0);\n-  return MakeFileName(name, number, \"ldb\");\n+  return MakeFileName(dbname, number, \"ldb\");\n }\n \n-std::string SSTTableFileName(const std::string& name, uint64_t number) {\n+std::string SSTTableFileName(const std::string& dbname, uint64_t number) {\n   assert(number > 0);\n-  return MakeFileName(name, number, \"sst\");\n+  return MakeFileName(dbname, number, \"sst\");\n }\n \n std::string DescriptorFileName(const std::string& dbname, uint64_t number) {\n@@ -51,9 +52,7 @@ std::string CurrentFileName(const std::string& dbname) {\n   return dbname + \"/CURRENT\";\n }\n \n-std::string LockFileName(const std::string& dbname) {\n-  return dbname + \"/LOCK\";\n-}\n+std::string LockFileName(const std::string& dbname) { return dbname + \"/LOCK\"; }\n \n std::string TempFileName(const std::string& dbname, uint64_t number) {\n   assert(number > 0);\n@@ -69,18 +68,16 @@ std::string OldInfoLogFileName(const std::string& dbname) {\n   return dbname + \"/LOG.old\";\n }\n \n-\n // Owned filenames have the form:\n //    dbname/CURRENT\n //    dbname/LOCK\n //    dbname/LOG\n //    dbname/LOG.old\n //    dbname/MANIFEST-[0-9]+\n //    dbname/[0-9]+.(log|sst|ldb)\n-bool ParseFileName(const std::string& fname,\n-                   uint64_t* number,\n+bool ParseFileName(const std::string& filename, uint64_t* number,\n                    FileType* type) {\n-  Slice rest(fname);\n+  Slice rest(filename);\n   if (rest == \"CURRENT\") {\n     *number = 0;\n     *type = kCurrentFile;"
      },
      {
        "sha": "524e813c06d2e5333881041fe50eae277d8f5382",
        "filename": "db/filename.h",
        "status": "modified",
        "additions": 15,
        "deletions": 16,
        "changes": 31,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/filename.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/filename.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/filename.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -8,7 +8,9 @@\n #define STORAGE_LEVELDB_DB_FILENAME_H_\n \n #include <stdint.h>\n+\n #include <string>\n+\n #include \"leveldb/slice.h\"\n #include \"leveldb/status.h\"\n #include \"port/port.h\"\n@@ -30,55 +32,52 @@ enum FileType {\n // Return the name of the log file with the specified number\n // in the db named by \"dbname\".  The result will be prefixed with\n // \"dbname\".\n-extern std::string LogFileName(const std::string& dbname, uint64_t number);\n+std::string LogFileName(const std::string& dbname, uint64_t number);\n \n // Return the name of the sstable with the specified number\n // in the db named by \"dbname\".  The result will be prefixed with\n // \"dbname\".\n-extern std::string TableFileName(const std::string& dbname, uint64_t number);\n+std::string TableFileName(const std::string& dbname, uint64_t number);\n \n // Return the legacy file name for an sstable with the specified number\n // in the db named by \"dbname\". The result will be prefixed with\n // \"dbname\".\n-extern std::string SSTTableFileName(const std::string& dbname, uint64_t number);\n+std::string SSTTableFileName(const std::string& dbname, uint64_t number);\n \n // Return the name of the descriptor file for the db named by\n // \"dbname\" and the specified incarnation number.  The result will be\n // prefixed with \"dbname\".\n-extern std::string DescriptorFileName(const std::string& dbname,\n-                                      uint64_t number);\n+std::string DescriptorFileName(const std::string& dbname, uint64_t number);\n \n // Return the name of the current file.  This file contains the name\n // of the current manifest file.  The result will be prefixed with\n // \"dbname\".\n-extern std::string CurrentFileName(const std::string& dbname);\n+std::string CurrentFileName(const std::string& dbname);\n \n // Return the name of the lock file for the db named by\n // \"dbname\".  The result will be prefixed with \"dbname\".\n-extern std::string LockFileName(const std::string& dbname);\n+std::string LockFileName(const std::string& dbname);\n \n // Return the name of a temporary file owned by the db named \"dbname\".\n // The result will be prefixed with \"dbname\".\n-extern std::string TempFileName(const std::string& dbname, uint64_t number);\n+std::string TempFileName(const std::string& dbname, uint64_t number);\n \n // Return the name of the info log file for \"dbname\".\n-extern std::string InfoLogFileName(const std::string& dbname);\n+std::string InfoLogFileName(const std::string& dbname);\n \n // Return the name of the old info log file for \"dbname\".\n-extern std::string OldInfoLogFileName(const std::string& dbname);\n+std::string OldInfoLogFileName(const std::string& dbname);\n \n // If filename is a leveldb file, store the type of the file in *type.\n // The number encoded in the filename is stored in *number.  If the\n // filename was successfully parsed, returns true.  Else return false.\n-extern bool ParseFileName(const std::string& filename,\n-                          uint64_t* number,\n-                          FileType* type);\n+bool ParseFileName(const std::string& filename, uint64_t* number,\n+                   FileType* type);\n \n // Make the CURRENT file point to the descriptor file with the\n // specified number.\n-extern Status SetCurrentFile(Env* env, const std::string& dbname,\n-                             uint64_t descriptor_number);\n-\n+Status SetCurrentFile(Env* env, const std::string& dbname,\n+                      uint64_t descriptor_number);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "952f32008ed7ffeb01860d67812c905abbde9ff8",
        "filename": "db/filename_test.cc",
        "status": "modified",
        "additions": 47,
        "deletions": 39,
        "changes": 86,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/filename_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/filename_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/filename_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -11,7 +11,7 @@\n \n namespace leveldb {\n \n-class FileNameTest { };\n+class FileNameTest {};\n \n TEST(FileNameTest, Parse) {\n   Slice db;\n@@ -24,17 +24,17 @@ TEST(FileNameTest, Parse) {\n     uint64_t number;\n     FileType type;\n   } cases[] = {\n-    { \"100.log\",            100,   kLogFile },\n-    { \"0.log\",              0,     kLogFile },\n-    { \"0.sst\",              0,     kTableFile },\n-    { \"0.ldb\",              0,     kTableFile },\n-    { \"CURRENT\",            0,     kCurrentFile },\n-    { \"LOCK\",               0,     kDBLockFile },\n-    { \"MANIFEST-2\",         2,     kDescriptorFile },\n-    { \"MANIFEST-7\",         7,     kDescriptorFile },\n-    { \"LOG\",                0,     kInfoLogFile },\n-    { \"LOG.old\",            0,     kInfoLogFile },\n-    { \"18446744073709551615.log\", 18446744073709551615ull, kLogFile },\n+      {\"100.log\", 100, kLogFile},\n+      {\"0.log\", 0, kLogFile},\n+      {\"0.sst\", 0, kTableFile},\n+      {\"0.ldb\", 0, kTableFile},\n+      {\"CURRENT\", 0, kCurrentFile},\n+      {\"LOCK\", 0, kDBLockFile},\n+      {\"MANIFEST-2\", 2, kDescriptorFile},\n+      {\"MANIFEST-7\", 7, kDescriptorFile},\n+      {\"LOG\", 0, kInfoLogFile},\n+      {\"LOG.old\", 0, kInfoLogFile},\n+      {\"18446744073709551615.log\", 18446744073709551615ull, kLogFile},\n   };\n   for (int i = 0; i < sizeof(cases) / sizeof(cases[0]); i++) {\n     std::string f = cases[i].fname;\n@@ -44,30 +44,28 @@ TEST(FileNameTest, Parse) {\n   }\n \n   // Errors\n-  static const char* errors[] = {\n-    \"\",\n-    \"foo\",\n-    \"foo-dx-100.log\",\n-    \".log\",\n-    \"\",\n-    \"manifest\",\n-    \"CURREN\",\n-    \"CURRENTX\",\n-    \"MANIFES\",\n-    \"MANIFEST\",\n-    \"MANIFEST-\",\n-    \"XMANIFEST-3\",\n-    \"MANIFEST-3x\",\n-    \"LOC\",\n-    \"LOCKx\",\n-    \"LO\",\n-    \"LOGx\",\n-    \"18446744073709551616.log\",\n-    \"184467440737095516150.log\",\n-    \"100\",\n-    \"100.\",\n-    \"100.lop\"\n-  };\n+  static const char* errors[] = {\"\",\n+                                 \"foo\",\n+                                 \"foo-dx-100.log\",\n+                                 \".log\",\n+                                 \"\",\n+                                 \"manifest\",\n+                                 \"CURREN\",\n+                                 \"CURRENTX\",\n+                                 \"MANIFES\",\n+                                 \"MANIFEST\",\n+                                 \"MANIFEST-\",\n+                                 \"XMANIFEST-3\",\n+                                 \"MANIFEST-3x\",\n+                                 \"LOC\",\n+                                 \"LOCKx\",\n+                                 \"LO\",\n+                                 \"LOGx\",\n+                                 \"18446744073709551616.log\",\n+                                 \"184467440737095516150.log\",\n+                                 \"100\",\n+                                 \"100.\",\n+                                 \"100.lop\"};\n   for (int i = 0; i < sizeof(errors) / sizeof(errors[0]); i++) {\n     std::string f = errors[i];\n     ASSERT_TRUE(!ParseFileName(f, &number, &type)) << f;\n@@ -114,10 +112,20 @@ TEST(FileNameTest, Construction) {\n   ASSERT_TRUE(ParseFileName(fname.c_str() + 4, &number, &type));\n   ASSERT_EQ(999, number);\n   ASSERT_EQ(kTempFile, type);\n+\n+  fname = InfoLogFileName(\"foo\");\n+  ASSERT_EQ(\"foo/\", std::string(fname.data(), 4));\n+  ASSERT_TRUE(ParseFileName(fname.c_str() + 4, &number, &type));\n+  ASSERT_EQ(0, number);\n+  ASSERT_EQ(kInfoLogFile, type);\n+\n+  fname = OldInfoLogFileName(\"foo\");\n+  ASSERT_EQ(\"foo/\", std::string(fname.data(), 4));\n+  ASSERT_TRUE(ParseFileName(fname.c_str() + 4, &number, &type));\n+  ASSERT_EQ(0, number);\n+  ASSERT_EQ(kInfoLogFile, type);\n }\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "9ed9667d376b3a8946166af399e271a22009c5d9",
        "filename": "db/leveldbutil.cc",
        "status": "modified",
        "additions": 10,
        "deletions": 11,
        "changes": 21,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/leveldbutil.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/leveldbutil.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/leveldbutil.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -3,6 +3,7 @@\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n #include <stdio.h>\n+\n #include \"leveldb/dumpfile.h\"\n #include \"leveldb/env.h\"\n #include \"leveldb/status.h\"\n@@ -12,14 +13,14 @@ namespace {\n \n class StdoutPrinter : public WritableFile {\n  public:\n-  virtual Status Append(const Slice& data) {\n+  Status Append(const Slice& data) override {\n     fwrite(data.data(), 1, data.size(), stdout);\n     return Status::OK();\n   }\n-  virtual Status Close() { return Status::OK(); }\n-  virtual Status Flush() { return Status::OK(); }\n-  virtual Status Sync() { return Status::OK(); }\n-  virtual std::string GetName() const { return \"[stdout]\"; }\n+  Status Close() override { return Status::OK(); }\n+  Status Flush() override { return Status::OK(); }\n+  Status Sync() override { return Status::OK(); }\n+  std::string GetName() const override { return \"[stdout]\"; }\n };\n \n bool HandleDumpCommand(Env* env, char** files, int num) {\n@@ -39,11 +40,9 @@ bool HandleDumpCommand(Env* env, char** files, int num) {\n }  // namespace leveldb\n \n static void Usage() {\n-  fprintf(\n-      stderr,\n-      \"Usage: leveldbutil command...\\n\"\n-      \"   dump files...         -- dump contents of specified files\\n\"\n-      );\n+  fprintf(stderr,\n+          \"Usage: leveldbutil command...\\n\"\n+          \"   dump files...         -- dump contents of specified files\\n\");\n }\n \n int main(int argc, char** argv) {\n@@ -55,7 +54,7 @@ int main(int argc, char** argv) {\n   } else {\n     std::string command = argv[1];\n     if (command == \"dump\") {\n-      ok = leveldb::HandleDumpCommand(env, argv+2, argc-2);\n+      ok = leveldb::HandleDumpCommand(env, argv + 2, argc - 2);\n     } else {\n       Usage();\n       ok = false;"
      },
      {
        "sha": "1ccfb7b34aa85a6f37b5e515ff10e09b786c642a",
        "filename": "db/log_reader.cc",
        "status": "modified",
        "additions": 9,
        "deletions": 19,
        "changes": 28,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/log_reader.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/log_reader.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/log_reader.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -5,15 +5,15 @@\n #include \"db/log_reader.h\"\n \n #include <stdio.h>\n+\n #include \"leveldb/env.h\"\n #include \"util/coding.h\"\n #include \"util/crc32c.h\"\n \n namespace leveldb {\n namespace log {\n \n-Reader::Reporter::~Reporter() {\n-}\n+Reader::Reporter::~Reporter() = default;\n \n Reader::Reader(SequentialFile* file, Reporter* reporter, bool checksum,\n                uint64_t initial_offset)\n@@ -26,20 +26,16 @@ Reader::Reader(SequentialFile* file, Reporter* reporter, bool checksum,\n       last_record_offset_(0),\n       end_of_buffer_offset_(0),\n       initial_offset_(initial_offset),\n-      resyncing_(initial_offset > 0) {\n-}\n+      resyncing_(initial_offset > 0) {}\n \n-Reader::~Reader() {\n-  delete[] backing_store_;\n-}\n+Reader::~Reader() { delete[] backing_store_; }\n \n bool Reader::SkipToInitialBlock() {\n-  size_t offset_in_block = initial_offset_ % kBlockSize;\n+  const size_t offset_in_block = initial_offset_ % kBlockSize;\n   uint64_t block_start_location = initial_offset_ - offset_in_block;\n \n   // Don't search a block if we'd be in the trailer\n   if (offset_in_block > kBlockSize - 6) {\n-    offset_in_block = 0;\n     block_start_location += kBlockSize;\n   }\n \n@@ -99,9 +95,7 @@ bool Reader::ReadRecord(Slice* record, std::string* scratch) {\n           // it could emit an empty kFirstType record at the tail end\n           // of a block followed by a kFullType or kFirstType record\n           // at the beginning of the next block.\n-          if (scratch->empty()) {\n-            in_fragmented_record = false;\n-          } else {\n+          if (!scratch->empty()) {\n             ReportCorruption(scratch->size(), \"partial record without end(1)\");\n           }\n         }\n@@ -117,9 +111,7 @@ bool Reader::ReadRecord(Slice* record, std::string* scratch) {\n           // it could emit an empty kFirstType record at the tail end\n           // of a block followed by a kFullType or kFirstType record\n           // at the beginning of the next block.\n-          if (scratch->empty()) {\n-            in_fragmented_record = false;\n-          } else {\n+          if (!scratch->empty()) {\n             ReportCorruption(scratch->size(), \"partial record without end(2)\");\n           }\n         }\n@@ -181,16 +173,14 @@ bool Reader::ReadRecord(Slice* record, std::string* scratch) {\n   return false;\n }\n \n-uint64_t Reader::LastRecordOffset() {\n-  return last_record_offset_;\n-}\n+uint64_t Reader::LastRecordOffset() { return last_record_offset_; }\n \n void Reader::ReportCorruption(uint64_t bytes, const char* reason) {\n   ReportDrop(bytes, Status::Corruption(reason, file_->GetName()));\n }\n \n void Reader::ReportDrop(uint64_t bytes, const Status& reason) {\n-  if (reporter_ != NULL &&\n+  if (reporter_ != nullptr &&\n       end_of_buffer_offset_ - buffer_.size() - bytes >= initial_offset_) {\n     reporter_->Corruption(static_cast<size_t>(bytes), reason);\n   }"
      },
      {
        "sha": "001da8948a12c9146b34f10a757c4382cd8a781e",
        "filename": "db/log_reader.h",
        "status": "modified",
        "additions": 23,
        "deletions": 24,
        "changes": 47,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/log_reader.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/log_reader.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/log_reader.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -32,7 +32,7 @@ class Reader {\n   // Create a reader that will return log records from \"*file\".\n   // \"*file\" must remain live while this Reader is in use.\n   //\n-  // If \"reporter\" is non-NULL, it is notified whenever some data is\n+  // If \"reporter\" is non-null, it is notified whenever some data is\n   // dropped due to a detected corruption.  \"*reporter\" must remain\n   // live while this Reader is in use.\n   //\n@@ -43,6 +43,9 @@ class Reader {\n   Reader(SequentialFile* file, Reporter* reporter, bool checksum,\n          uint64_t initial_offset);\n \n+  Reader(const Reader&) = delete;\n+  Reader& operator=(const Reader&) = delete;\n+\n   ~Reader();\n \n   // Read the next record into *record.  Returns true if read\n@@ -58,26 +61,6 @@ class Reader {\n   uint64_t LastRecordOffset();\n \n  private:\n-  SequentialFile* const file_;\n-  Reporter* const reporter_;\n-  bool const checksum_;\n-  char* const backing_store_;\n-  Slice buffer_;\n-  bool eof_;   // Last Read() indicated EOF by returning < kBlockSize\n-\n-  // Offset of the last record returned by ReadRecord.\n-  uint64_t last_record_offset_;\n-  // Offset of the first location past the end of buffer_.\n-  uint64_t end_of_buffer_offset_;\n-\n-  // Offset at which to start looking for the first record to return\n-  uint64_t const initial_offset_;\n-\n-  // True if we are resynchronizing after a seek (initial_offset_ > 0). In\n-  // particular, a run of kMiddleType and kLastType records can be silently\n-  // skipped in this mode\n-  bool resyncing_;\n-\n   // Extend record types with the following special values\n   enum {\n     kEof = kMaxRecordType + 1,\n@@ -102,9 +85,25 @@ class Reader {\n   void ReportCorruption(uint64_t bytes, const char* reason);\n   void ReportDrop(uint64_t bytes, const Status& reason);\n \n-  // No copying allowed\n-  Reader(const Reader&);\n-  void operator=(const Reader&);\n+  SequentialFile* const file_;\n+  Reporter* const reporter_;\n+  bool const checksum_;\n+  char* const backing_store_;\n+  Slice buffer_;\n+  bool eof_;  // Last Read() indicated EOF by returning < kBlockSize\n+\n+  // Offset of the last record returned by ReadRecord.\n+  uint64_t last_record_offset_;\n+  // Offset of the first location past the end of buffer_.\n+  uint64_t end_of_buffer_offset_;\n+\n+  // Offset at which to start looking for the first record to return\n+  uint64_t const initial_offset_;\n+\n+  // True if we are resynchronizing after a seek (initial_offset_ > 0). In\n+  // particular, a run of kMiddleType and kLastType records can be silently\n+  // skipped in this mode\n+  bool resyncing_;\n };\n \n }  // namespace log"
      },
      {
        "sha": "41fc043068dcec4d587f36d80bff5013761e1149",
        "filename": "db/log_test.cc",
        "status": "modified",
        "additions": 131,
        "deletions": 160,
        "changes": 291,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/log_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/log_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/log_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -37,87 +37,12 @@ static std::string RandomSkewedString(int i, Random* rnd) {\n }\n \n class LogTest {\n- private:\n-  class StringDest : public WritableFile {\n-   public:\n-    std::string contents_;\n-\n-    virtual Status Close() { return Status::OK(); }\n-    virtual Status Flush() { return Status::OK(); }\n-    virtual Status Sync() { return Status::OK(); }\n-    virtual Status Append(const Slice& slice) {\n-      contents_.append(slice.data(), slice.size());\n-      return Status::OK();\n-    }\n-  };\n-\n-  class StringSource : public SequentialFile {\n-   public:\n-    Slice contents_;\n-    bool force_error_;\n-    bool returned_partial_;\n-    StringSource() : force_error_(false), returned_partial_(false) { }\n-\n-    virtual Status Read(size_t n, Slice* result, char* scratch) {\n-      ASSERT_TRUE(!returned_partial_) << \"must not Read() after eof/error\";\n-\n-      if (force_error_) {\n-        force_error_ = false;\n-        returned_partial_ = true;\n-        return Status::Corruption(\"read error\");\n-      }\n-\n-      if (contents_.size() < n) {\n-        n = contents_.size();\n-        returned_partial_ = true;\n-      }\n-      *result = Slice(contents_.data(), n);\n-      contents_.remove_prefix(n);\n-      return Status::OK();\n-    }\n-\n-    virtual Status Skip(uint64_t n) {\n-      if (n > contents_.size()) {\n-        contents_.clear();\n-        return Status::NotFound(\"in-memory file skipped past end\");\n-      }\n-\n-      contents_.remove_prefix(n);\n-\n-      return Status::OK();\n-    }\n-  };\n-\n-  class ReportCollector : public Reader::Reporter {\n-   public:\n-    size_t dropped_bytes_;\n-    std::string message_;\n-\n-    ReportCollector() : dropped_bytes_(0) { }\n-    virtual void Corruption(size_t bytes, const Status& status) {\n-      dropped_bytes_ += bytes;\n-      message_.append(status.ToString());\n-    }\n-  };\n-\n-  StringDest dest_;\n-  StringSource source_;\n-  ReportCollector report_;\n-  bool reading_;\n-  Writer* writer_;\n-  Reader* reader_;\n-\n-  // Record metadata for testing initial offset functionality\n-  static size_t initial_offset_record_sizes_[];\n-  static uint64_t initial_offset_last_record_offsets_[];\n-  static int num_initial_offset_records_;\n-\n  public:\n-  LogTest() : reading_(false),\n-              writer_(new Writer(&dest_)),\n-              reader_(new Reader(&source_, &report_, true/*checksum*/,\n-                      0/*initial_offset*/)) {\n-  }\n+  LogTest()\n+      : reading_(false),\n+        writer_(new Writer(&dest_)),\n+        reader_(new Reader(&source_, &report_, true /*checksum*/,\n+                           0 /*initial_offset*/)) {}\n \n   ~LogTest() {\n     delete writer_;\n@@ -134,9 +59,7 @@ class LogTest {\n     writer_->AddRecord(Slice(msg));\n   }\n \n-  size_t WrittenBytes() const {\n-    return dest_.contents_.size();\n-  }\n+  size_t WrittenBytes() const { return dest_.contents_.size(); }\n \n   std::string Read() {\n     if (!reading_) {\n@@ -166,22 +89,16 @@ class LogTest {\n \n   void FixChecksum(int header_offset, int len) {\n     // Compute crc of type/len/data\n-    uint32_t crc = crc32c::Value(&dest_.contents_[header_offset+6], 1 + len);\n+    uint32_t crc = crc32c::Value(&dest_.contents_[header_offset + 6], 1 + len);\n     crc = crc32c::Mask(crc);\n     EncodeFixed32(&dest_.contents_[header_offset], crc);\n   }\n \n-  void ForceError() {\n-    source_.force_error_ = true;\n-  }\n+  void ForceError() { source_.force_error_ = true; }\n \n-  size_t DroppedBytes() const {\n-    return report_.dropped_bytes_;\n-  }\n+  size_t DroppedBytes() const { return report_.dropped_bytes_; }\n \n-  std::string ReportMessage() const {\n-    return report_.message_;\n-  }\n+  std::string ReportMessage() const { return report_.message_; }\n \n   // Returns OK iff recorded error message contains \"msg\"\n   std::string MatchError(const std::string& msg) const {\n@@ -202,14 +119,14 @@ class LogTest {\n \n   void StartReadingAt(uint64_t initial_offset) {\n     delete reader_;\n-    reader_ = new Reader(&source_, &report_, true/*checksum*/, initial_offset);\n+    reader_ = new Reader(&source_, &report_, true /*checksum*/, initial_offset);\n   }\n \n   void CheckOffsetPastEndReturnsNoRecords(uint64_t offset_past_end) {\n     WriteInitialOffsetLog();\n     reading_ = true;\n     source_.contents_ = Slice(dest_.contents_);\n-    Reader* offset_reader = new Reader(&source_, &report_, true/*checksum*/,\n+    Reader* offset_reader = new Reader(&source_, &report_, true /*checksum*/,\n                                        WrittenBytes() + offset_past_end);\n     Slice record;\n     std::string scratch;\n@@ -222,8 +139,8 @@ class LogTest {\n     WriteInitialOffsetLog();\n     reading_ = true;\n     source_.contents_ = Slice(dest_.contents_);\n-    Reader* offset_reader = new Reader(&source_, &report_, true/*checksum*/,\n-                                       initial_offset);\n+    Reader* offset_reader =\n+        new Reader(&source_, &report_, true /*checksum*/, initial_offset);\n \n     // Read all records from expected_record_offset through the last one.\n     ASSERT_LT(expected_record_offset, num_initial_offset_records_);\n@@ -240,36 +157,110 @@ class LogTest {\n     }\n     delete offset_reader;\n   }\n+\n+ private:\n+  class StringDest : public WritableFile {\n+   public:\n+    Status Close() override { return Status::OK(); }\n+    Status Flush() override { return Status::OK(); }\n+    Status Sync() override { return Status::OK(); }\n+    Status Append(const Slice& slice) override {\n+      contents_.append(slice.data(), slice.size());\n+      return Status::OK();\n+    }\n+    std::string GetName() const override { return \"\"; }\n+\n+    std::string contents_;\n+  };\n+\n+  class StringSource : public SequentialFile {\n+   public:\n+    StringSource() : force_error_(false), returned_partial_(false) {}\n+\n+    Status Read(size_t n, Slice* result, char* scratch) override {\n+      ASSERT_TRUE(!returned_partial_) << \"must not Read() after eof/error\";\n+\n+      if (force_error_) {\n+        force_error_ = false;\n+        returned_partial_ = true;\n+        return Status::Corruption(\"read error\");\n+      }\n+\n+      if (contents_.size() < n) {\n+        n = contents_.size();\n+        returned_partial_ = true;\n+      }\n+      *result = Slice(contents_.data(), n);\n+      contents_.remove_prefix(n);\n+      return Status::OK();\n+    }\n+\n+    Status Skip(uint64_t n) override {\n+      if (n > contents_.size()) {\n+        contents_.clear();\n+        return Status::NotFound(\"in-memory file skipped past end\");\n+      }\n+\n+      contents_.remove_prefix(n);\n+\n+      return Status::OK();\n+    }\n+    std::string GetName() const { return \"\"; }\n+\n+    Slice contents_;\n+    bool force_error_;\n+    bool returned_partial_;\n+  };\n+\n+  class ReportCollector : public Reader::Reporter {\n+   public:\n+    ReportCollector() : dropped_bytes_(0) {}\n+    void Corruption(size_t bytes, const Status& status) override {\n+      dropped_bytes_ += bytes;\n+      message_.append(status.ToString());\n+    }\n+\n+    size_t dropped_bytes_;\n+    std::string message_;\n+  };\n+\n+  // Record metadata for testing initial offset functionality\n+  static size_t initial_offset_record_sizes_[];\n+  static uint64_t initial_offset_last_record_offsets_[];\n+  static int num_initial_offset_records_;\n+\n+  StringDest dest_;\n+  StringSource source_;\n+  ReportCollector report_;\n+  bool reading_;\n+  Writer* writer_;\n+  Reader* reader_;\n+};\n+\n+size_t LogTest::initial_offset_record_sizes_[] = {\n+    10000,  // Two sizable records in first block\n+    10000,\n+    2 * log::kBlockSize - 1000,  // Span three blocks\n+    1,\n+    13716,                          // Consume all but two bytes of block 3.\n+    log::kBlockSize - kHeaderSize,  // Consume the entirety of block 4.\n };\n \n-size_t LogTest::initial_offset_record_sizes_[] =\n-    {10000,  // Two sizable records in first block\n-     10000,\n-     2 * log::kBlockSize - 1000,  // Span three blocks\n-     1,\n-     13716,  // Consume all but two bytes of block 3.\n-     log::kBlockSize - kHeaderSize, // Consume the entirety of block 4.\n-    };\n-\n-uint64_t LogTest::initial_offset_last_record_offsets_[] =\n-    {0,\n-     kHeaderSize + 10000,\n-     2 * (kHeaderSize + 10000),\n-     2 * (kHeaderSize + 10000) +\n-         (2 * log::kBlockSize - 1000) + 3 * kHeaderSize,\n-     2 * (kHeaderSize + 10000) +\n-         (2 * log::kBlockSize - 1000) + 3 * kHeaderSize\n-         + kHeaderSize + 1,\n-     3 * log::kBlockSize,\n-    };\n+uint64_t LogTest::initial_offset_last_record_offsets_[] = {\n+    0,\n+    kHeaderSize + 10000,\n+    2 * (kHeaderSize + 10000),\n+    2 * (kHeaderSize + 10000) + (2 * log::kBlockSize - 1000) + 3 * kHeaderSize,\n+    2 * (kHeaderSize + 10000) + (2 * log::kBlockSize - 1000) + 3 * kHeaderSize +\n+        kHeaderSize + 1,\n+    3 * log::kBlockSize,\n+};\n \n // LogTest::initial_offset_last_record_offsets_ must be defined before this.\n int LogTest::num_initial_offset_records_ =\n-    sizeof(LogTest::initial_offset_last_record_offsets_)/sizeof(uint64_t);\n+    sizeof(LogTest::initial_offset_last_record_offsets_) / sizeof(uint64_t);\n \n-TEST(LogTest, Empty) {\n-  ASSERT_EQ(\"EOF\", Read());\n-}\n+TEST(LogTest, Empty) { ASSERT_EQ(\"EOF\", Read()); }\n \n TEST(LogTest, ReadWrite) {\n   Write(\"foo\");\n@@ -306,7 +297,7 @@ TEST(LogTest, Fragmentation) {\n \n TEST(LogTest, MarginalTrailer) {\n   // Make a trailer that is exactly the same length as an empty record.\n-  const int n = kBlockSize - 2*kHeaderSize;\n+  const int n = kBlockSize - 2 * kHeaderSize;\n   Write(BigString(\"foo\", n));\n   ASSERT_EQ(kBlockSize - kHeaderSize, WrittenBytes());\n   Write(\"\");\n@@ -319,7 +310,7 @@ TEST(LogTest, MarginalTrailer) {\n \n TEST(LogTest, MarginalTrailer2) {\n   // Make a trailer that is exactly the same length as an empty record.\n-  const int n = kBlockSize - 2*kHeaderSize;\n+  const int n = kBlockSize - 2 * kHeaderSize;\n   Write(BigString(\"foo\", n));\n   ASSERT_EQ(kBlockSize - kHeaderSize, WrittenBytes());\n   Write(\"bar\");\n@@ -331,7 +322,7 @@ TEST(LogTest, MarginalTrailer2) {\n }\n \n TEST(LogTest, ShortTrailer) {\n-  const int n = kBlockSize - 2*kHeaderSize + 4;\n+  const int n = kBlockSize - 2 * kHeaderSize + 4;\n   Write(BigString(\"foo\", n));\n   ASSERT_EQ(kBlockSize - kHeaderSize + 4, WrittenBytes());\n   Write(\"\");\n@@ -343,7 +334,7 @@ TEST(LogTest, ShortTrailer) {\n }\n \n TEST(LogTest, AlignedEof) {\n-  const int n = kBlockSize - 2*kHeaderSize + 4;\n+  const int n = kBlockSize - 2 * kHeaderSize + 4;\n   Write(BigString(\"foo\", n));\n   ASSERT_EQ(kBlockSize - kHeaderSize + 4, WrittenBytes());\n   ASSERT_EQ(BigString(\"foo\", n), Read());\n@@ -394,7 +385,7 @@ TEST(LogTest, BadRecordType) {\n \n TEST(LogTest, TruncatedTrailingRecordIsIgnored) {\n   Write(\"foo\");\n-  ShrinkSize(4);   // Drop all payload as well as a header byte\n+  ShrinkSize(4);  // Drop all payload as well as a header byte\n   ASSERT_EQ(\"EOF\", Read());\n   // Truncated last record is ignored, not treated as an error.\n   ASSERT_EQ(0, DroppedBytes());\n@@ -492,7 +483,7 @@ TEST(LogTest, SkipIntoMultiRecord) {\n   // If initial_offset points to a record after first(R1) but before first(R2)\n   // incomplete fragment errors are not actual errors, and must be suppressed\n   // until a new first or full record is encountered.\n-  Write(BigString(\"foo\", 3*kBlockSize));\n+  Write(BigString(\"foo\", 3 * kBlockSize));\n   Write(\"correct\");\n   StartReadingAt(kBlockSize);\n \n@@ -514,44 +505,30 @@ TEST(LogTest, ErrorJoinsRecords) {\n   Write(\"correct\");\n \n   // Wipe the middle block\n-  for (int offset = kBlockSize; offset < 2*kBlockSize; offset++) {\n+  for (int offset = kBlockSize; offset < 2 * kBlockSize; offset++) {\n     SetByte(offset, 'x');\n   }\n \n   ASSERT_EQ(\"correct\", Read());\n   ASSERT_EQ(\"EOF\", Read());\n   const size_t dropped = DroppedBytes();\n-  ASSERT_LE(dropped, 2*kBlockSize + 100);\n-  ASSERT_GE(dropped, 2*kBlockSize);\n+  ASSERT_LE(dropped, 2 * kBlockSize + 100);\n+  ASSERT_GE(dropped, 2 * kBlockSize);\n }\n \n-TEST(LogTest, ReadStart) {\n-  CheckInitialOffsetRecord(0, 0);\n-}\n+TEST(LogTest, ReadStart) { CheckInitialOffsetRecord(0, 0); }\n \n-TEST(LogTest, ReadSecondOneOff) {\n-  CheckInitialOffsetRecord(1, 1);\n-}\n+TEST(LogTest, ReadSecondOneOff) { CheckInitialOffsetRecord(1, 1); }\n \n-TEST(LogTest, ReadSecondTenThousand) {\n-  CheckInitialOffsetRecord(10000, 1);\n-}\n+TEST(LogTest, ReadSecondTenThousand) { CheckInitialOffsetRecord(10000, 1); }\n \n-TEST(LogTest, ReadSecondStart) {\n-  CheckInitialOffsetRecord(10007, 1);\n-}\n+TEST(LogTest, ReadSecondStart) { CheckInitialOffsetRecord(10007, 1); }\n \n-TEST(LogTest, ReadThirdOneOff) {\n-  CheckInitialOffsetRecord(10008, 2);\n-}\n+TEST(LogTest, ReadThirdOneOff) { CheckInitialOffsetRecord(10008, 2); }\n \n-TEST(LogTest, ReadThirdStart) {\n-  CheckInitialOffsetRecord(20014, 2);\n-}\n+TEST(LogTest, ReadThirdStart) { CheckInitialOffsetRecord(20014, 2); }\n \n-TEST(LogTest, ReadFourthOneOff) {\n-  CheckInitialOffsetRecord(20015, 3);\n-}\n+TEST(LogTest, ReadFourthOneOff) { CheckInitialOffsetRecord(20015, 3); }\n \n TEST(LogTest, ReadFourthFirstBlockTrailer) {\n   CheckInitialOffsetRecord(log::kBlockSize - 4, 3);\n@@ -575,17 +552,11 @@ TEST(LogTest, ReadInitialOffsetIntoBlockPadding) {\n   CheckInitialOffsetRecord(3 * log::kBlockSize - 3, 5);\n }\n \n-TEST(LogTest, ReadEnd) {\n-  CheckOffsetPastEndReturnsNoRecords(0);\n-}\n+TEST(LogTest, ReadEnd) { CheckOffsetPastEndReturnsNoRecords(0); }\n \n-TEST(LogTest, ReadPastEnd) {\n-  CheckOffsetPastEndReturnsNoRecords(5);\n-}\n+TEST(LogTest, ReadPastEnd) { CheckOffsetPastEndReturnsNoRecords(5); }\n \n }  // namespace log\n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "bfb16fb486269e1b648c70693c18bd3e14d9ec63",
        "filename": "db/log_writer.cc",
        "status": "modified",
        "additions": 14,
        "deletions": 15,
        "changes": 29,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/log_writer.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/log_writer.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/log_writer.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -5,6 +5,7 @@\n #include \"db/log_writer.h\"\n \n #include <stdint.h>\n+\n #include \"leveldb/env.h\"\n #include \"util/coding.h\"\n #include \"util/crc32c.h\"\n@@ -19,9 +20,7 @@ static void InitTypeCrc(uint32_t* type_crc) {\n   }\n }\n \n-Writer::Writer(WritableFile* dest)\n-    : dest_(dest),\n-      block_offset_(0) {\n+Writer::Writer(WritableFile* dest) : dest_(dest), block_offset_(0) {\n   InitTypeCrc(type_crc_);\n }\n \n@@ -30,8 +29,7 @@ Writer::Writer(WritableFile* dest, uint64_t dest_length)\n   InitTypeCrc(type_crc_);\n }\n \n-Writer::~Writer() {\n-}\n+Writer::~Writer() = default;\n \n Status Writer::AddRecord(const Slice& slice) {\n   const char* ptr = slice.data();\n@@ -49,7 +47,7 @@ Status Writer::AddRecord(const Slice& slice) {\n       // Switch to a new block\n       if (leftover > 0) {\n         // Fill the trailer (literal below relies on kHeaderSize being 7)\n-        assert(kHeaderSize == 7);\n+        static_assert(kHeaderSize == 7, \"\");\n         dest_->Append(Slice(\"\\x00\\x00\\x00\\x00\\x00\\x00\", leftover));\n       }\n       block_offset_ = 0;\n@@ -81,30 +79,31 @@ Status Writer::AddRecord(const Slice& slice) {\n   return s;\n }\n \n-Status Writer::EmitPhysicalRecord(RecordType t, const char* ptr, size_t n) {\n-  assert(n <= 0xffff);  // Must fit in two bytes\n-  assert(block_offset_ + kHeaderSize + n <= kBlockSize);\n+Status Writer::EmitPhysicalRecord(RecordType t, const char* ptr,\n+                                  size_t length) {\n+  assert(length <= 0xffff);  // Must fit in two bytes\n+  assert(block_offset_ + kHeaderSize + length <= kBlockSize);\n \n   // Format the header\n   char buf[kHeaderSize];\n-  buf[4] = static_cast<char>(n & 0xff);\n-  buf[5] = static_cast<char>(n >> 8);\n+  buf[4] = static_cast<char>(length & 0xff);\n+  buf[5] = static_cast<char>(length >> 8);\n   buf[6] = static_cast<char>(t);\n \n   // Compute the crc of the record type and the payload.\n-  uint32_t crc = crc32c::Extend(type_crc_[t], ptr, n);\n-  crc = crc32c::Mask(crc);                 // Adjust for storage\n+  uint32_t crc = crc32c::Extend(type_crc_[t], ptr, length);\n+  crc = crc32c::Mask(crc);  // Adjust for storage\n   EncodeFixed32(buf, crc);\n \n   // Write the header and the payload\n   Status s = dest_->Append(Slice(buf, kHeaderSize));\n   if (s.ok()) {\n-    s = dest_->Append(Slice(ptr, n));\n+    s = dest_->Append(Slice(ptr, length));\n     if (s.ok()) {\n       s = dest_->Flush();\n     }\n   }\n-  block_offset_ += kHeaderSize + n;\n+  block_offset_ += kHeaderSize + length;\n   return s;\n }\n "
      },
      {
        "sha": "c0a21147ee9cd7de674de47315b121050108628c",
        "filename": "db/log_writer.h",
        "status": "modified",
        "additions": 7,
        "deletions": 7,
        "changes": 14,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/log_writer.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/log_writer.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/log_writer.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -6,6 +6,7 @@\n #define STORAGE_LEVELDB_DB_LOG_WRITER_H_\n \n #include <stdint.h>\n+\n #include \"db/log_format.h\"\n #include \"leveldb/slice.h\"\n #include \"leveldb/status.h\"\n@@ -28,24 +29,23 @@ class Writer {\n   // \"*dest\" must remain live while this Writer is in use.\n   Writer(WritableFile* dest, uint64_t dest_length);\n \n+  Writer(const Writer&) = delete;\n+  Writer& operator=(const Writer&) = delete;\n+\n   ~Writer();\n \n   Status AddRecord(const Slice& slice);\n \n  private:\n+  Status EmitPhysicalRecord(RecordType type, const char* ptr, size_t length);\n+\n   WritableFile* dest_;\n-  int block_offset_;       // Current offset in block\n+  int block_offset_;  // Current offset in block\n \n   // crc32c values for all supported record types.  These are\n   // pre-computed to reduce the overhead of computing the crc of the\n   // record type stored in the header.\n   uint32_t type_crc_[kMaxRecordType + 1];\n-\n-  Status EmitPhysicalRecord(RecordType type, const char* ptr, size_t length);\n-\n-  // No copying allowed\n-  Writer(const Writer&);\n-  void operator=(const Writer&);\n };\n \n }  // namespace log"
      },
      {
        "sha": "00931d4671b0630d71483a02850a754f7f5fb99b",
        "filename": "db/memtable.cc",
        "status": "modified",
        "additions": 30,
        "deletions": 38,
        "changes": 68,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/memtable.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/memtable.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/memtable.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -18,20 +18,15 @@ static Slice GetLengthPrefixedSlice(const char* data) {\n   return Slice(p, len);\n }\n \n-MemTable::MemTable(const InternalKeyComparator& cmp)\n-    : comparator_(cmp),\n-      refs_(0),\n-      table_(comparator_, &arena_) {\n-}\n+MemTable::MemTable(const InternalKeyComparator& comparator)\n+    : comparator_(comparator), refs_(0), table_(comparator_, &arena_) {}\n \n-MemTable::~MemTable() {\n-  assert(refs_ == 0);\n-}\n+MemTable::~MemTable() { assert(refs_ == 0); }\n \n size_t MemTable::ApproximateMemoryUsage() { return arena_.MemoryUsage(); }\n \n-int MemTable::KeyComparator::operator()(const char* aptr, const char* bptr)\n-    const {\n+int MemTable::KeyComparator::operator()(const char* aptr,\n+                                        const char* bptr) const {\n   // Internal keys are encoded as length-prefixed strings.\n   Slice a = GetLengthPrefixedSlice(aptr);\n   Slice b = GetLengthPrefixedSlice(bptr);\n@@ -48,39 +43,37 @@ static const char* EncodeKey(std::string* scratch, const Slice& target) {\n   return scratch->data();\n }\n \n-class MemTableIterator: public Iterator {\n+class MemTableIterator : public Iterator {\n  public:\n-  explicit MemTableIterator(MemTable::Table* table) : iter_(table) { }\n-\n-  virtual bool Valid() const { return iter_.Valid(); }\n-  virtual void Seek(const Slice& k) { iter_.Seek(EncodeKey(&tmp_, k)); }\n-  virtual void SeekToFirst() { iter_.SeekToFirst(); }\n-  virtual void SeekToLast() { iter_.SeekToLast(); }\n-  virtual void Next() { iter_.Next(); }\n-  virtual void Prev() { iter_.Prev(); }\n-  virtual Slice key() const { return GetLengthPrefixedSlice(iter_.key()); }\n-  virtual Slice value() const {\n+  explicit MemTableIterator(MemTable::Table* table) : iter_(table) {}\n+\n+  MemTableIterator(const MemTableIterator&) = delete;\n+  MemTableIterator& operator=(const MemTableIterator&) = delete;\n+\n+  ~MemTableIterator() override = default;\n+\n+  bool Valid() const override { return iter_.Valid(); }\n+  void Seek(const Slice& k) override { iter_.Seek(EncodeKey(&tmp_, k)); }\n+  void SeekToFirst() override { iter_.SeekToFirst(); }\n+  void SeekToLast() override { iter_.SeekToLast(); }\n+  void Next() override { iter_.Next(); }\n+  void Prev() override { iter_.Prev(); }\n+  Slice key() const override { return GetLengthPrefixedSlice(iter_.key()); }\n+  Slice value() const override {\n     Slice key_slice = GetLengthPrefixedSlice(iter_.key());\n     return GetLengthPrefixedSlice(key_slice.data() + key_slice.size());\n   }\n \n-  virtual Status status() const { return Status::OK(); }\n+  Status status() const override { return Status::OK(); }\n \n  private:\n   MemTable::Table::Iterator iter_;\n-  std::string tmp_;       // For passing to EncodeKey\n-\n-  // No copying allowed\n-  MemTableIterator(const MemTableIterator&);\n-  void operator=(const MemTableIterator&);\n+  std::string tmp_;  // For passing to EncodeKey\n };\n \n-Iterator* MemTable::NewIterator() {\n-  return new MemTableIterator(&table_);\n-}\n+Iterator* MemTable::NewIterator() { return new MemTableIterator(&table_); }\n \n-void MemTable::Add(SequenceNumber s, ValueType type,\n-                   const Slice& key,\n+void MemTable::Add(SequenceNumber s, ValueType type, const Slice& key,\n                    const Slice& value) {\n   // Format of an entry is concatenation of:\n   //  key_size     : varint32 of internal_key.size()\n@@ -90,9 +83,9 @@ void MemTable::Add(SequenceNumber s, ValueType type,\n   size_t key_size = key.size();\n   size_t val_size = value.size();\n   size_t internal_key_size = key_size + 8;\n-  const size_t encoded_len =\n-      VarintLength(internal_key_size) + internal_key_size +\n-      VarintLength(val_size) + val_size;\n+  const size_t encoded_len = VarintLength(internal_key_size) +\n+                             internal_key_size + VarintLength(val_size) +\n+                             val_size;\n   char* buf = arena_.Allocate(encoded_len);\n   char* p = EncodeVarint32(buf, internal_key_size);\n   memcpy(p, key.data(), key_size);\n@@ -121,10 +114,9 @@ bool MemTable::Get(const LookupKey& key, std::string* value, Status* s) {\n     // all entries with overly large sequence numbers.\n     const char* entry = iter.key();\n     uint32_t key_length;\n-    const char* key_ptr = GetVarint32Ptr(entry, entry+5, &key_length);\n+    const char* key_ptr = GetVarint32Ptr(entry, entry + 5, &key_length);\n     if (comparator_.comparator.user_comparator()->Compare(\n-            Slice(key_ptr, key_length - 8),\n-            key.user_key()) == 0) {\n+            Slice(key_ptr, key_length - 8), key.user_key()) == 0) {\n       // Correct user key\n       const uint64_t tag = DecodeFixed64(key_ptr + key_length - 8);\n       switch (static_cast<ValueType>(tag & 0xff)) {"
      },
      {
        "sha": "9d986b1070203243854e9e6d2479b89c1fb3f96a",
        "filename": "db/memtable.h",
        "status": "modified",
        "additions": 11,
        "deletions": 12,
        "changes": 23,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/memtable.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/memtable.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/memtable.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -6,15 +6,15 @@\n #define STORAGE_LEVELDB_DB_MEMTABLE_H_\n \n #include <string>\n-#include \"leveldb/db.h\"\n+\n #include \"db/dbformat.h\"\n #include \"db/skiplist.h\"\n+#include \"leveldb/db.h\"\n #include \"util/arena.h\"\n \n namespace leveldb {\n \n class InternalKeyComparator;\n-class Mutex;\n class MemTableIterator;\n \n class MemTable {\n@@ -23,6 +23,9 @@ class MemTable {\n   // is zero and the caller must call Ref() at least once.\n   explicit MemTable(const InternalKeyComparator& comparator);\n \n+  MemTable(const MemTable&) = delete;\n+  MemTable& operator=(const MemTable&) = delete;\n+\n   // Increase reference count.\n   void Ref() { ++refs_; }\n \n@@ -50,8 +53,7 @@ class MemTable {\n   // Add an entry into memtable that maps key to value at the\n   // specified sequence number and with the specified type.\n   // Typically value will be empty if type==kTypeDeletion.\n-  void Add(SequenceNumber seq, ValueType type,\n-           const Slice& key,\n+  void Add(SequenceNumber seq, ValueType type, const Slice& key,\n            const Slice& value);\n \n   // If memtable contains a value for key, store it in *value and return true.\n@@ -61,26 +63,23 @@ class MemTable {\n   bool Get(const LookupKey& key, std::string* value, Status* s);\n \n  private:\n-  ~MemTable();  // Private since only Unref() should be used to delete it\n+  friend class MemTableIterator;\n+  friend class MemTableBackwardIterator;\n \n   struct KeyComparator {\n     const InternalKeyComparator comparator;\n-    explicit KeyComparator(const InternalKeyComparator& c) : comparator(c) { }\n+    explicit KeyComparator(const InternalKeyComparator& c) : comparator(c) {}\n     int operator()(const char* a, const char* b) const;\n   };\n-  friend class MemTableIterator;\n-  friend class MemTableBackwardIterator;\n \n   typedef SkipList<const char*, KeyComparator> Table;\n \n+  ~MemTable();  // Private since only Unref() should be used to delete it\n+\n   KeyComparator comparator_;\n   int refs_;\n   Arena arena_;\n   Table table_;\n-\n-  // No copying allowed\n-  MemTable(const MemTable&);\n-  void operator=(const MemTable&);\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "547a9591ea067d03ce6fbb15ed17c51a399315ad",
        "filename": "db/recovery_test.cc",
        "status": "modified",
        "additions": 39,
        "deletions": 33,
        "changes": 72,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/recovery_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/recovery_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/recovery_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -17,7 +17,7 @@ namespace leveldb {\n \n class RecoveryTest {\n  public:\n-  RecoveryTest() : env_(Env::Default()), db_(NULL) {\n+  RecoveryTest() : env_(Env::Default()), db_(nullptr) {\n     dbname_ = test::TmpDir() + \"/recovery_test\";\n     DestroyDB(dbname_, Options());\n     Open();\n@@ -44,30 +44,34 @@ class RecoveryTest {\n \n   void Close() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n   }\n \n-  void Open(Options* options = NULL) {\n+  Status OpenWithStatus(Options* options = nullptr) {\n     Close();\n     Options opts;\n-    if (options != NULL) {\n+    if (options != nullptr) {\n       opts = *options;\n     } else {\n       opts.reuse_logs = true;  // TODO(sanjay): test both ways\n       opts.create_if_missing = true;\n     }\n-    if (opts.env == NULL) {\n+    if (opts.env == nullptr) {\n       opts.env = env_;\n     }\n-    ASSERT_OK(DB::Open(opts, dbname_, &db_));\n+    return DB::Open(opts, dbname_, &db_);\n+  }\n+\n+  void Open(Options* options = nullptr) {\n+    ASSERT_OK(OpenWithStatus(options));\n     ASSERT_EQ(1, NumLogs());\n   }\n \n   Status Put(const std::string& k, const std::string& v) {\n     return db_->Put(WriteOptions(), k, v);\n   }\n \n-  std::string Get(const std::string& k, const Snapshot* snapshot = NULL) {\n+  std::string Get(const std::string& k, const Snapshot* snapshot = nullptr) {\n     std::string result;\n     Status s = db_->Get(ReadOptions(), k, &result);\n     if (s.IsNotFound()) {\n@@ -82,27 +86,28 @@ class RecoveryTest {\n     std::string current;\n     ASSERT_OK(ReadFileToString(env_, CurrentFileName(dbname_), &current));\n     size_t len = current.size();\n-    if (len > 0 && current[len-1] == '\\n') {\n+    if (len > 0 && current[len - 1] == '\\n') {\n       current.resize(len - 1);\n     }\n     return dbname_ + \"/\" + current;\n   }\n \n-  std::string LogName(uint64_t number) {\n-    return LogFileName(dbname_, number);\n-  }\n+  std::string LogName(uint64_t number) { return LogFileName(dbname_, number); }\n \n   size_t DeleteLogFiles() {\n+    // Linux allows unlinking open files, but Windows does not.\n+    // Closing the db allows for file deletion.\n+    Close();\n     std::vector<uint64_t> logs = GetFiles(kLogFile);\n     for (size_t i = 0; i < logs.size(); i++) {\n       ASSERT_OK(env_->DeleteFile(LogName(logs[i]))) << LogName(logs[i]);\n     }\n     return logs.size();\n   }\n \n-  uint64_t FirstLogFile() {\n-    return GetFiles(kLogFile)[0];\n-  }\n+  void DeleteManifestFile() { ASSERT_OK(env_->DeleteFile(ManifestFileName())); }\n+\n+  uint64_t FirstLogFile() { return GetFiles(kLogFile)[0]; }\n \n   std::vector<uint64_t> GetFiles(FileType t) {\n     std::vector<std::string> filenames;\n@@ -118,23 +123,17 @@ class RecoveryTest {\n     return result;\n   }\n \n-  int NumLogs() {\n-    return GetFiles(kLogFile).size();\n-  }\n+  int NumLogs() { return GetFiles(kLogFile).size(); }\n \n-  int NumTables() {\n-    return GetFiles(kTableFile).size();\n-  }\n+  int NumTables() { return GetFiles(kTableFile).size(); }\n \n   uint64_t FileSize(const std::string& fname) {\n     uint64_t result;\n     ASSERT_OK(env_->GetFileSize(fname, &result)) << fname;\n     return result;\n   }\n \n-  void CompactMemTable() {\n-    dbfull()->TEST_CompactMemTable();\n-  }\n+  void CompactMemTable() { dbfull()->TEST_CompactMemTable(); }\n \n   // Directly construct a log file that sets key to val.\n   void MakeLogFile(uint64_t lognum, SequenceNumber seq, Slice key, Slice val) {\n@@ -186,7 +185,7 @@ TEST(RecoveryTest, LargeManifestCompacted) {\n     uint64_t len = FileSize(old_manifest);\n     WritableFile* file;\n     ASSERT_OK(env()->NewAppendableFile(old_manifest, &file));\n-    std::string zeroes(3*1048576 - static_cast<size_t>(len), 0);\n+    std::string zeroes(3 * 1048576 - static_cast<size_t>(len), 0);\n     ASSERT_OK(file->Append(zeroes));\n     ASSERT_OK(file->Flush());\n     delete file;\n@@ -259,7 +258,7 @@ TEST(RecoveryTest, MultipleMemTables) {\n   // Force creation of multiple memtables by reducing the write buffer size.\n   Options opt;\n   opt.reuse_logs = true;\n-  opt.write_buffer_size = (kNum*100) / 2;\n+  opt.write_buffer_size = (kNum * 100) / 2;\n   Open(&opt);\n   ASSERT_LE(2, NumTables());\n   ASSERT_EQ(1, NumLogs());\n@@ -278,16 +277,16 @@ TEST(RecoveryTest, MultipleLogFiles) {\n \n   // Make a bunch of uncompacted log files.\n   uint64_t old_log = FirstLogFile();\n-  MakeLogFile(old_log+1, 1000, \"hello\", \"world\");\n-  MakeLogFile(old_log+2, 1001, \"hi\", \"there\");\n-  MakeLogFile(old_log+3, 1002, \"foo\", \"bar2\");\n+  MakeLogFile(old_log + 1, 1000, \"hello\", \"world\");\n+  MakeLogFile(old_log + 2, 1001, \"hi\", \"there\");\n+  MakeLogFile(old_log + 3, 1002, \"foo\", \"bar2\");\n \n   // Recover and check that all log files were processed.\n   Open();\n   ASSERT_LE(1, NumTables());\n   ASSERT_EQ(1, NumLogs());\n   uint64_t new_log = FirstLogFile();\n-  ASSERT_LE(old_log+3, new_log);\n+  ASSERT_LE(old_log + 3, new_log);\n   ASSERT_EQ(\"bar2\", Get(\"foo\"));\n   ASSERT_EQ(\"world\", Get(\"hello\"));\n   ASSERT_EQ(\"there\", Get(\"hi\"));\n@@ -305,7 +304,7 @@ TEST(RecoveryTest, MultipleLogFiles) {\n \n   // Check that introducing an older log file does not cause it to be re-read.\n   Close();\n-  MakeLogFile(old_log+1, 2000, \"hello\", \"stale write\");\n+  MakeLogFile(old_log + 1, 2000, \"hello\", \"stale write\");\n   Open();\n   ASSERT_LE(1, NumTables());\n   ASSERT_EQ(1, NumLogs());\n@@ -317,8 +316,15 @@ TEST(RecoveryTest, MultipleLogFiles) {\n   ASSERT_EQ(\"there\", Get(\"hi\"));\n }\n \n-}  // namespace leveldb\n+TEST(RecoveryTest, ManifestMissing) {\n+  ASSERT_OK(Put(\"foo\", \"bar\"));\n+  Close();\n+  DeleteManifestFile();\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n+  Status status = OpenWithStatus();\n+  ASSERT_TRUE(status.IsCorruption());\n }\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "04847c3bbfb73d40f3c2ebb90ef701fd957ea3b1",
        "filename": "db/repair.cc",
        "status": "modified",
        "additions": 42,
        "deletions": 53,
        "changes": 95,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/repair.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/repair.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/repair.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -54,7 +54,7 @@ class Repairer {\n         owns_cache_(options_.block_cache != options.block_cache),\n         next_file_number_(1) {\n     // TableCache can be small since we expect each table to be opened once.\n-    table_cache_ = new TableCache(dbname_, &options_, 10);\n+    table_cache_ = new TableCache(dbname_, options_, 10);\n   }\n \n   ~Repairer() {\n@@ -84,9 +84,7 @@ class Repairer {\n           \"recovered %d files; %llu bytes. \"\n           \"Some data may have been lost. \"\n           \"****\",\n-          dbname_.c_str(),\n-          static_cast<int>(tables_.size()),\n-          bytes);\n+          dbname_.c_str(), static_cast<int>(tables_.size()), bytes);\n     }\n     return status;\n   }\n@@ -97,22 +95,6 @@ class Repairer {\n     SequenceNumber max_sequence;\n   };\n \n-  std::string const dbname_;\n-  Env* const env_;\n-  InternalKeyComparator const icmp_;\n-  InternalFilterPolicy const ipolicy_;\n-  Options const options_;\n-  bool owns_info_log_;\n-  bool owns_cache_;\n-  TableCache* table_cache_;\n-  VersionEdit edit_;\n-\n-  std::vector<std::string> manifests_;\n-  std::vector<uint64_t> table_numbers_;\n-  std::vector<uint64_t> logs_;\n-  std::vector<TableInfo> tables_;\n-  uint64_t next_file_number_;\n-\n   Status FindFiles() {\n     std::vector<std::string> filenames;\n     Status status = env_->GetChildren(dbname_, &filenames);\n@@ -152,8 +134,7 @@ class Repairer {\n       Status status = ConvertLogToTable(logs_[i]);\n       if (!status.ok()) {\n         Log(options_.info_log, \"Log #%llu: ignoring conversion error: %s\",\n-            (unsigned long long) logs_[i],\n-            status.ToString().c_str());\n+            (unsigned long long)logs_[i], status.ToString().c_str());\n       }\n       ArchiveFile(logname);\n     }\n@@ -164,11 +145,10 @@ class Repairer {\n       Env* env;\n       Logger* info_log;\n       uint64_t lognum;\n-      virtual void Corruption(size_t bytes, const Status& s) {\n+      void Corruption(size_t bytes, const Status& s) override {\n         // We print error messages for corruption, but continue repairing.\n         Log(info_log, \"Log #%llu: dropping %d bytes; %s\",\n-            (unsigned long long) lognum,\n-            static_cast<int>(bytes),\n+            (unsigned long long)lognum, static_cast<int>(bytes),\n             s.ToString().c_str());\n       }\n     };\n@@ -190,8 +170,8 @@ class Repairer {\n     // corruptions cause entire commits to be skipped instead of\n     // propagating bad information (like overly large sequence\n     // numbers).\n-    log::Reader reader(lfile, &reporter, false/*do not checksum*/,\n-                       0/*initial_offset*/);\n+    log::Reader reader(lfile, &reporter, false /*do not checksum*/,\n+                       0 /*initial_offset*/);\n \n     // Read all the records and add to a memtable\n     std::string scratch;\n@@ -202,8 +182,8 @@ class Repairer {\n     int counter = 0;\n     while (reader.ReadRecord(&record, &scratch)) {\n       if (record.size() < 12) {\n-        reporter.Corruption(\n-            record.size(), Status::Corruption(\"log record too small\", logname));\n+        reporter.Corruption(record.size(),\n+                            Status::Corruption(\"log record too small\", logname));\n         continue;\n       }\n       WriteBatchInternal::SetContents(&batch, record);\n@@ -212,8 +192,7 @@ class Repairer {\n         counter += WriteBatchInternal::Count(&batch);\n       } else {\n         Log(options_.info_log, \"Log #%llu: ignoring %s\",\n-            (unsigned long long) log,\n-            status.ToString().c_str());\n+            (unsigned long long)log, status.ToString().c_str());\n         status = Status::OK();  // Keep going with rest of file\n       }\n     }\n@@ -227,16 +206,14 @@ class Repairer {\n     status = BuildTable(dbname_, env_, options_, table_cache_, iter, &meta);\n     delete iter;\n     mem->Unref();\n-    mem = NULL;\n+    mem = nullptr;\n     if (status.ok()) {\n       if (meta.file_size > 0) {\n         table_numbers_.push_back(meta.number);\n       }\n     }\n     Log(options_.info_log, \"Log #%llu: %d ops saved to Table #%llu %s\",\n-        (unsigned long long) log,\n-        counter,\n-        (unsigned long long) meta.number,\n+        (unsigned long long)log, counter, (unsigned long long)meta.number,\n         status.ToString().c_str());\n     return status;\n   }\n@@ -272,8 +249,7 @@ class Repairer {\n       ArchiveFile(TableFileName(dbname_, number));\n       ArchiveFile(SSTTableFileName(dbname_, number));\n       Log(options_.info_log, \"Table #%llu: dropped: %s\",\n-          (unsigned long long) t.meta.number,\n-          status.ToString().c_str());\n+          (unsigned long long)t.meta.number, status.ToString().c_str());\n       return;\n     }\n \n@@ -287,8 +263,7 @@ class Repairer {\n       Slice key = iter->key();\n       if (!ParseInternalKey(key, &parsed)) {\n         Log(options_.info_log, \"Table #%llu: unparsable key %s\",\n-            (unsigned long long) t.meta.number,\n-            EscapeString(key).c_str());\n+            (unsigned long long)t.meta.number, EscapeString(key).c_str());\n         continue;\n       }\n \n@@ -307,9 +282,7 @@ class Repairer {\n     }\n     delete iter;\n     Log(options_.info_log, \"Table #%llu: %d entries %s\",\n-        (unsigned long long) t.meta.number,\n-        counter,\n-        status.ToString().c_str());\n+        (unsigned long long)t.meta.number, counter, status.ToString().c_str());\n \n     if (status.ok()) {\n       tables_.push_back(t);\n@@ -350,20 +323,20 @@ class Repairer {\n       }\n     }\n     delete builder;\n-    builder = NULL;\n+    builder = nullptr;\n \n     if (s.ok()) {\n       s = file->Close();\n     }\n     delete file;\n-    file = NULL;\n+    file = nullptr;\n \n     if (counter > 0 && s.ok()) {\n       std::string orig = TableFileName(dbname_, t.meta.number);\n       s = env_->RenameFile(copy, orig);\n       if (s.ok()) {\n         Log(options_.info_log, \"Table #%llu: %d entries repaired\",\n-            (unsigned long long) t.meta.number, counter);\n+            (unsigned long long)t.meta.number, counter);\n         tables_.push_back(t);\n       }\n     }\n@@ -395,11 +368,11 @@ class Repairer {\n     for (size_t i = 0; i < tables_.size(); i++) {\n       // TODO(opt): separate out into multiple levels\n       const TableInfo& t = tables_[i];\n-      edit_.AddFile(0, t.meta.number, t.meta.file_size,\n-                    t.meta.smallest, t.meta.largest);\n+      edit_.AddFile(0, t.meta.number, t.meta.file_size, t.meta.smallest,\n+                    t.meta.largest);\n     }\n \n-    //fprintf(stderr, \"NewDescriptor:\\n%s\\n\", edit_.DebugString().c_str());\n+    // fprintf(stderr, \"NewDescriptor:\\n%s\\n\", edit_.DebugString().c_str());\n     {\n       log::Writer log(file);\n       std::string record;\n@@ -410,7 +383,7 @@ class Repairer {\n       status = file->Close();\n     }\n     delete file;\n-    file = NULL;\n+    file = nullptr;\n \n     if (!status.ok()) {\n       env_->DeleteFile(tmp);\n@@ -438,18 +411,34 @@ class Repairer {\n     //    dir/lost/foo\n     const char* slash = strrchr(fname.c_str(), '/');\n     std::string new_dir;\n-    if (slash != NULL) {\n+    if (slash != nullptr) {\n       new_dir.assign(fname.data(), slash - fname.data());\n     }\n     new_dir.append(\"/lost\");\n     env_->CreateDir(new_dir);  // Ignore error\n     std::string new_file = new_dir;\n     new_file.append(\"/\");\n-    new_file.append((slash == NULL) ? fname.c_str() : slash + 1);\n+    new_file.append((slash == nullptr) ? fname.c_str() : slash + 1);\n     Status s = env_->RenameFile(fname, new_file);\n-    Log(options_.info_log, \"Archiving %s: %s\\n\",\n-        fname.c_str(), s.ToString().c_str());\n+    Log(options_.info_log, \"Archiving %s: %s\\n\", fname.c_str(),\n+        s.ToString().c_str());\n   }\n+\n+  const std::string dbname_;\n+  Env* const env_;\n+  InternalKeyComparator const icmp_;\n+  InternalFilterPolicy const ipolicy_;\n+  const Options options_;\n+  bool owns_info_log_;\n+  bool owns_cache_;\n+  TableCache* table_cache_;\n+  VersionEdit edit_;\n+\n+  std::vector<std::string> manifests_;\n+  std::vector<uint64_t> table_numbers_;\n+  std::vector<uint64_t> logs_;\n+  std::vector<TableInfo> tables_;\n+  uint64_t next_file_number_;\n };\n }  // namespace\n "
      },
      {
        "sha": "a59b45b3800574a3b70f151ed611be577399baf9",
        "filename": "db/skiplist.h",
        "status": "modified",
        "additions": 90,
        "deletions": 92,
        "changes": 182,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/skiplist.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/skiplist.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/skiplist.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -27,17 +27,18 @@\n //\n // ... prev vs. next pointer ordering ...\n \n-#include <assert.h>\n-#include <stdlib.h>\n-#include \"port/port.h\"\n+#include <atomic>\n+#include <cassert>\n+#include <cstdlib>\n+\n #include \"util/arena.h\"\n #include \"util/random.h\"\n \n namespace leveldb {\n \n class Arena;\n \n-template<typename Key, class Comparator>\n+template <typename Key, class Comparator>\n class SkipList {\n  private:\n   struct Node;\n@@ -48,6 +49,9 @@ class SkipList {\n   // must remain allocated for the lifetime of the skiplist object.\n   explicit SkipList(Comparator cmp, Arena* arena);\n \n+  SkipList(const SkipList&) = delete;\n+  SkipList& operator=(const SkipList&) = delete;\n+\n   // Insert key into the list.\n   // REQUIRES: nothing that compares equal to key is currently in the list.\n   void Insert(const Key& key);\n@@ -97,24 +101,10 @@ class SkipList {\n  private:\n   enum { kMaxHeight = 12 };\n \n-  // Immutable after construction\n-  Comparator const compare_;\n-  Arena* const arena_;    // Arena used for allocations of nodes\n-\n-  Node* const head_;\n-\n-  // Modified only by Insert().  Read racily by readers, but stale\n-  // values are ok.\n-  port::AtomicPointer max_height_;   // Height of the entire list\n-\n   inline int GetMaxHeight() const {\n-    return static_cast<int>(\n-        reinterpret_cast<intptr_t>(max_height_.NoBarrier_Load()));\n+    return max_height_.load(std::memory_order_relaxed);\n   }\n \n-  // Read/written only by Insert().\n-  Random rnd_;\n-\n   Node* NewNode(const Key& key, int height);\n   int RandomHeight();\n   bool Equal(const Key& a, const Key& b) const { return (compare_(a, b) == 0); }\n@@ -123,9 +113,9 @@ class SkipList {\n   bool KeyIsAfterNode(const Key& key, Node* n) const;\n \n   // Return the earliest node that comes at or after key.\n-  // Return NULL if there is no such node.\n+  // Return nullptr if there is no such node.\n   //\n-  // If prev is non-NULL, fills prev[level] with pointer to previous\n+  // If prev is non-null, fills prev[level] with pointer to previous\n   // node at \"level\" for every level in [0..max_height_-1].\n   Node* FindGreaterOrEqual(const Key& key, Node** prev) const;\n \n@@ -137,15 +127,24 @@ class SkipList {\n   // Return head_ if list is empty.\n   Node* FindLast() const;\n \n-  // No copying allowed\n-  SkipList(const SkipList&);\n-  void operator=(const SkipList&);\n+  // Immutable after construction\n+  Comparator const compare_;\n+  Arena* const arena_;  // Arena used for allocations of nodes\n+\n+  Node* const head_;\n+\n+  // Modified only by Insert().  Read racily by readers, but stale\n+  // values are ok.\n+  std::atomic<int> max_height_;  // Height of the entire list\n+\n+  // Read/written only by Insert().\n+  Random rnd_;\n };\n \n // Implementation details follow\n-template<typename Key, class Comparator>\n-struct SkipList<Key,Comparator>::Node {\n-  explicit Node(const Key& k) : key(k) { }\n+template <typename Key, class Comparator>\n+struct SkipList<Key, Comparator>::Node {\n+  explicit Node(const Key& k) : key(k) {}\n \n   Key const key;\n \n@@ -155,92 +154,92 @@ struct SkipList<Key,Comparator>::Node {\n     assert(n >= 0);\n     // Use an 'acquire load' so that we observe a fully initialized\n     // version of the returned Node.\n-    return reinterpret_cast<Node*>(next_[n].Acquire_Load());\n+    return next_[n].load(std::memory_order_acquire);\n   }\n   void SetNext(int n, Node* x) {\n     assert(n >= 0);\n     // Use a 'release store' so that anybody who reads through this\n     // pointer observes a fully initialized version of the inserted node.\n-    next_[n].Release_Store(x);\n+    next_[n].store(x, std::memory_order_release);\n   }\n \n   // No-barrier variants that can be safely used in a few locations.\n   Node* NoBarrier_Next(int n) {\n     assert(n >= 0);\n-    return reinterpret_cast<Node*>(next_[n].NoBarrier_Load());\n+    return next_[n].load(std::memory_order_relaxed);\n   }\n   void NoBarrier_SetNext(int n, Node* x) {\n     assert(n >= 0);\n-    next_[n].NoBarrier_Store(x);\n+    next_[n].store(x, std::memory_order_relaxed);\n   }\n \n  private:\n   // Array of length equal to the node height.  next_[0] is lowest level link.\n-  port::AtomicPointer next_[1];\n+  std::atomic<Node*> next_[1];\n };\n \n-template<typename Key, class Comparator>\n-typename SkipList<Key,Comparator>::Node*\n-SkipList<Key,Comparator>::NewNode(const Key& key, int height) {\n-  char* mem = arena_->AllocateAligned(\n-      sizeof(Node) + sizeof(port::AtomicPointer) * (height - 1));\n-  return new (mem) Node(key);\n+template <typename Key, class Comparator>\n+typename SkipList<Key, Comparator>::Node* SkipList<Key, Comparator>::NewNode(\n+    const Key& key, int height) {\n+  char* const node_memory = arena_->AllocateAligned(\n+      sizeof(Node) + sizeof(std::atomic<Node*>) * (height - 1));\n+  return new (node_memory) Node(key);\n }\n \n-template<typename Key, class Comparator>\n-inline SkipList<Key,Comparator>::Iterator::Iterator(const SkipList* list) {\n+template <typename Key, class Comparator>\n+inline SkipList<Key, Comparator>::Iterator::Iterator(const SkipList* list) {\n   list_ = list;\n-  node_ = NULL;\n+  node_ = nullptr;\n }\n \n-template<typename Key, class Comparator>\n-inline bool SkipList<Key,Comparator>::Iterator::Valid() const {\n-  return node_ != NULL;\n+template <typename Key, class Comparator>\n+inline bool SkipList<Key, Comparator>::Iterator::Valid() const {\n+  return node_ != nullptr;\n }\n \n-template<typename Key, class Comparator>\n-inline const Key& SkipList<Key,Comparator>::Iterator::key() const {\n+template <typename Key, class Comparator>\n+inline const Key& SkipList<Key, Comparator>::Iterator::key() const {\n   assert(Valid());\n   return node_->key;\n }\n \n-template<typename Key, class Comparator>\n-inline void SkipList<Key,Comparator>::Iterator::Next() {\n+template <typename Key, class Comparator>\n+inline void SkipList<Key, Comparator>::Iterator::Next() {\n   assert(Valid());\n   node_ = node_->Next(0);\n }\n \n-template<typename Key, class Comparator>\n-inline void SkipList<Key,Comparator>::Iterator::Prev() {\n+template <typename Key, class Comparator>\n+inline void SkipList<Key, Comparator>::Iterator::Prev() {\n   // Instead of using explicit \"prev\" links, we just search for the\n   // last node that falls before key.\n   assert(Valid());\n   node_ = list_->FindLessThan(node_->key);\n   if (node_ == list_->head_) {\n-    node_ = NULL;\n+    node_ = nullptr;\n   }\n }\n \n-template<typename Key, class Comparator>\n-inline void SkipList<Key,Comparator>::Iterator::Seek(const Key& target) {\n-  node_ = list_->FindGreaterOrEqual(target, NULL);\n+template <typename Key, class Comparator>\n+inline void SkipList<Key, Comparator>::Iterator::Seek(const Key& target) {\n+  node_ = list_->FindGreaterOrEqual(target, nullptr);\n }\n \n-template<typename Key, class Comparator>\n-inline void SkipList<Key,Comparator>::Iterator::SeekToFirst() {\n+template <typename Key, class Comparator>\n+inline void SkipList<Key, Comparator>::Iterator::SeekToFirst() {\n   node_ = list_->head_->Next(0);\n }\n \n-template<typename Key, class Comparator>\n-inline void SkipList<Key,Comparator>::Iterator::SeekToLast() {\n+template <typename Key, class Comparator>\n+inline void SkipList<Key, Comparator>::Iterator::SeekToLast() {\n   node_ = list_->FindLast();\n   if (node_ == list_->head_) {\n-    node_ = NULL;\n+    node_ = nullptr;\n   }\n }\n \n-template<typename Key, class Comparator>\n-int SkipList<Key,Comparator>::RandomHeight() {\n+template <typename Key, class Comparator>\n+int SkipList<Key, Comparator>::RandomHeight() {\n   // Increase height with probability 1 in kBranching\n   static const unsigned int kBranching = 4;\n   int height = 1;\n@@ -252,15 +251,16 @@ int SkipList<Key,Comparator>::RandomHeight() {\n   return height;\n }\n \n-template<typename Key, class Comparator>\n-bool SkipList<Key,Comparator>::KeyIsAfterNode(const Key& key, Node* n) const {\n-  // NULL n is considered infinite\n-  return (n != NULL) && (compare_(n->key, key) < 0);\n+template <typename Key, class Comparator>\n+bool SkipList<Key, Comparator>::KeyIsAfterNode(const Key& key, Node* n) const {\n+  // null n is considered infinite\n+  return (n != nullptr) && (compare_(n->key, key) < 0);\n }\n \n-template<typename Key, class Comparator>\n-typename SkipList<Key,Comparator>::Node* SkipList<Key,Comparator>::FindGreaterOrEqual(const Key& key, Node** prev)\n-    const {\n+template <typename Key, class Comparator>\n+typename SkipList<Key, Comparator>::Node*\n+SkipList<Key, Comparator>::FindGreaterOrEqual(const Key& key,\n+                                              Node** prev) const {\n   Node* x = head_;\n   int level = GetMaxHeight() - 1;\n   while (true) {\n@@ -269,7 +269,7 @@ typename SkipList<Key,Comparator>::Node* SkipList<Key,Comparator>::FindGreaterOr\n       // Keep searching in this list\n       x = next;\n     } else {\n-      if (prev != NULL) prev[level] = x;\n+      if (prev != nullptr) prev[level] = x;\n       if (level == 0) {\n         return next;\n       } else {\n@@ -280,15 +280,15 @@ typename SkipList<Key,Comparator>::Node* SkipList<Key,Comparator>::FindGreaterOr\n   }\n }\n \n-template<typename Key, class Comparator>\n-typename SkipList<Key,Comparator>::Node*\n-SkipList<Key,Comparator>::FindLessThan(const Key& key) const {\n+template <typename Key, class Comparator>\n+typename SkipList<Key, Comparator>::Node*\n+SkipList<Key, Comparator>::FindLessThan(const Key& key) const {\n   Node* x = head_;\n   int level = GetMaxHeight() - 1;\n   while (true) {\n     assert(x == head_ || compare_(x->key, key) < 0);\n     Node* next = x->Next(level);\n-    if (next == NULL || compare_(next->key, key) >= 0) {\n+    if (next == nullptr || compare_(next->key, key) >= 0) {\n       if (level == 0) {\n         return x;\n       } else {\n@@ -301,14 +301,14 @@ SkipList<Key,Comparator>::FindLessThan(const Key& key) const {\n   }\n }\n \n-template<typename Key, class Comparator>\n-typename SkipList<Key,Comparator>::Node* SkipList<Key,Comparator>::FindLast()\n+template <typename Key, class Comparator>\n+typename SkipList<Key, Comparator>::Node* SkipList<Key, Comparator>::FindLast()\n     const {\n   Node* x = head_;\n   int level = GetMaxHeight() - 1;\n   while (true) {\n     Node* next = x->Next(level);\n-    if (next == NULL) {\n+    if (next == nullptr) {\n       if (level == 0) {\n         return x;\n       } else {\n@@ -321,43 +321,41 @@ typename SkipList<Key,Comparator>::Node* SkipList<Key,Comparator>::FindLast()\n   }\n }\n \n-template<typename Key, class Comparator>\n-SkipList<Key,Comparator>::SkipList(Comparator cmp, Arena* arena)\n+template <typename Key, class Comparator>\n+SkipList<Key, Comparator>::SkipList(Comparator cmp, Arena* arena)\n     : compare_(cmp),\n       arena_(arena),\n       head_(NewNode(0 /* any key will do */, kMaxHeight)),\n-      max_height_(reinterpret_cast<void*>(1)),\n+      max_height_(1),\n       rnd_(0xdeadbeef) {\n   for (int i = 0; i < kMaxHeight; i++) {\n-    head_->SetNext(i, NULL);\n+    head_->SetNext(i, nullptr);\n   }\n }\n \n-template<typename Key, class Comparator>\n-void SkipList<Key,Comparator>::Insert(const Key& key) {\n+template <typename Key, class Comparator>\n+void SkipList<Key, Comparator>::Insert(const Key& key) {\n   // TODO(opt): We can use a barrier-free variant of FindGreaterOrEqual()\n   // here since Insert() is externally synchronized.\n   Node* prev[kMaxHeight];\n   Node* x = FindGreaterOrEqual(key, prev);\n \n   // Our data structure does not allow duplicate insertion\n-  assert(x == NULL || !Equal(key, x->key));\n+  assert(x == nullptr || !Equal(key, x->key));\n \n   int height = RandomHeight();\n   if (height > GetMaxHeight()) {\n     for (int i = GetMaxHeight(); i < height; i++) {\n       prev[i] = head_;\n     }\n-    //fprintf(stderr, \"Change height from %d to %d\\n\", max_height_, height);\n-\n     // It is ok to mutate max_height_ without any synchronization\n     // with concurrent readers.  A concurrent reader that observes\n     // the new value of max_height_ will see either the old value of\n-    // new level pointers from head_ (NULL), or a new value set in\n+    // new level pointers from head_ (nullptr), or a new value set in\n     // the loop below.  In the former case the reader will\n-    // immediately drop to the next level since NULL sorts after all\n+    // immediately drop to the next level since nullptr sorts after all\n     // keys.  In the latter case the reader will use the new node.\n-    max_height_.NoBarrier_Store(reinterpret_cast<void*>(height));\n+    max_height_.store(height, std::memory_order_relaxed);\n   }\n \n   x = NewNode(key, height);\n@@ -369,10 +367,10 @@ void SkipList<Key,Comparator>::Insert(const Key& key) {\n   }\n }\n \n-template<typename Key, class Comparator>\n-bool SkipList<Key,Comparator>::Contains(const Key& key) const {\n-  Node* x = FindGreaterOrEqual(key, NULL);\n-  if (x != NULL && Equal(key, x->key)) {\n+template <typename Key, class Comparator>\n+bool SkipList<Key, Comparator>::Contains(const Key& key) const {\n+  Node* x = FindGreaterOrEqual(key, nullptr);\n+  if (x != nullptr && Equal(key, x->key)) {\n     return true;\n   } else {\n     return false;"
      },
      {
        "sha": "9fa2d968291d67b465c2cd733f7d16d35aceb950",
        "filename": "db/skiplist_test.cc",
        "status": "modified",
        "additions": 28,
        "deletions": 37,
        "changes": 65,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/skiplist_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/skiplist_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/skiplist_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -3,8 +3,13 @@\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n #include \"db/skiplist.h\"\n+\n+#include <atomic>\n #include <set>\n+\n #include \"leveldb/env.h\"\n+#include \"port/port.h\"\n+#include \"port/thread_annotations.h\"\n #include \"util/arena.h\"\n #include \"util/hash.h\"\n #include \"util/random.h\"\n@@ -26,7 +31,7 @@ struct Comparator {\n   }\n };\n \n-class SkipTest { };\n+class SkipTest {};\n \n TEST(SkipTest, Empty) {\n   Arena arena;\n@@ -112,8 +117,7 @@ TEST(SkipTest, InsertAndLookup) {\n \n     // Compare against model iterator\n     for (std::set<Key>::reverse_iterator model_iter = keys.rbegin();\n-         model_iter != keys.rend();\n-         ++model_iter) {\n+         model_iter != keys.rend(); ++model_iter) {\n       ASSERT_TRUE(iter.Valid());\n       ASSERT_EQ(*model_iter, iter.key());\n       iter.Prev();\n@@ -126,7 +130,7 @@ TEST(SkipTest, InsertAndLookup) {\n // concurrent readers (with no synchronization other than when a\n // reader's iterator is created), the reader always observes all the\n // data that was present in the skip list when the iterator was\n-// constructor.  Because insertions are happening concurrently, we may\n+// constructed.  Because insertions are happening concurrently, we may\n // also observe new values that were inserted since the iterator was\n // constructed, but we should never miss any values that were present\n // at iterator construction time.\n@@ -155,12 +159,12 @@ class ConcurrentTest {\n   static uint64_t hash(Key key) { return key & 0xff; }\n \n   static uint64_t HashNumbers(uint64_t k, uint64_t g) {\n-    uint64_t data[2] = { k, g };\n+    uint64_t data[2] = {k, g};\n     return Hash(reinterpret_cast<char*>(data), sizeof(data), 0);\n   }\n \n   static Key MakeKey(uint64_t k, uint64_t g) {\n-    assert(sizeof(Key) == sizeof(uint64_t));\n+    static_assert(sizeof(Key) == sizeof(uint64_t), \"\");\n     assert(k <= K);  // We sometimes pass K to seek to the end of the skiplist\n     assert(g <= 0xffffffffu);\n     return ((k << 40) | (g << 8) | (HashNumbers(k, g) & 0xff));\n@@ -186,13 +190,11 @@ class ConcurrentTest {\n \n   // Per-key generation\n   struct State {\n-    port::AtomicPointer generation[K];\n-    void Set(int k, intptr_t v) {\n-      generation[k].Release_Store(reinterpret_cast<void*>(v));\n-    }\n-    intptr_t Get(int k) {\n-      return reinterpret_cast<intptr_t>(generation[k].Acquire_Load());\n+    std::atomic<int> generation[K];\n+    void Set(int k, int v) {\n+      generation[k].store(v, std::memory_order_release);\n     }\n+    int Get(int k) { return generation[k].load(std::memory_order_acquire); }\n \n     State() {\n       for (int k = 0; k < K; k++) {\n@@ -211,7 +213,7 @@ class ConcurrentTest {\n   SkipList<Key, Comparator> list_;\n \n  public:\n-  ConcurrentTest() : list_(Comparator(), &arena_) { }\n+  ConcurrentTest() : list_(Comparator(), &arena_) {}\n \n   // REQUIRES: External synchronization\n   void WriteStep(Random* rnd) {\n@@ -250,11 +252,9 @@ class ConcurrentTest {\n         // Note that generation 0 is never inserted, so it is ok if\n         // <*,0,*> is missing.\n         ASSERT_TRUE((gen(pos) == 0) ||\n-                    (gen(pos) > static_cast<Key>(initial_state.Get(key(pos))))\n-                    ) << \"key: \" << key(pos)\n-                      << \"; gen: \" << gen(pos)\n-                      << \"; initgen: \"\n-                      << initial_state.Get(key(pos));\n+                    (gen(pos) > static_cast<Key>(initial_state.Get(key(pos)))))\n+            << \"key: \" << key(pos) << \"; gen: \" << gen(pos)\n+            << \"; initgen: \" << initial_state.Get(key(pos));\n \n         // Advance to next key in the valid key space\n         if (key(pos) < key(current)) {\n@@ -298,29 +298,22 @@ class TestState {\n  public:\n   ConcurrentTest t_;\n   int seed_;\n-  port::AtomicPointer quit_flag_;\n+  std::atomic<bool> quit_flag_;\n \n-  enum ReaderState {\n-    STARTING,\n-    RUNNING,\n-    DONE\n-  };\n+  enum ReaderState { STARTING, RUNNING, DONE };\n \n   explicit TestState(int s)\n-      : seed_(s),\n-        quit_flag_(NULL),\n-        state_(STARTING),\n-        state_cv_(&mu_) {}\n+      : seed_(s), quit_flag_(false), state_(STARTING), state_cv_(&mu_) {}\n \n-  void Wait(ReaderState s) {\n+  void Wait(ReaderState s) LOCKS_EXCLUDED(mu_) {\n     mu_.Lock();\n     while (state_ != s) {\n       state_cv_.Wait();\n     }\n     mu_.Unlock();\n   }\n \n-  void Change(ReaderState s) {\n+  void Change(ReaderState s) LOCKS_EXCLUDED(mu_) {\n     mu_.Lock();\n     state_ = s;\n     state_cv_.Signal();\n@@ -329,16 +322,16 @@ class TestState {\n \n  private:\n   port::Mutex mu_;\n-  ReaderState state_;\n-  port::CondVar state_cv_;\n+  ReaderState state_ GUARDED_BY(mu_);\n+  port::CondVar state_cv_ GUARDED_BY(mu_);\n };\n \n static void ConcurrentReader(void* arg) {\n   TestState* state = reinterpret_cast<TestState*>(arg);\n   Random rnd(state->seed_);\n   int64_t reads = 0;\n   state->Change(TestState::RUNNING);\n-  while (!state->quit_flag_.Acquire_Load()) {\n+  while (!state->quit_flag_.load(std::memory_order_acquire)) {\n     state->t_.ReadStep(&rnd);\n     ++reads;\n   }\n@@ -360,7 +353,7 @@ static void RunConcurrent(int run) {\n     for (int i = 0; i < kSize; i++) {\n       state.t_.WriteStep(&rnd);\n     }\n-    state.quit_flag_.Release_Store(&state);  // Any non-NULL arg will do\n+    state.quit_flag_.store(true, std::memory_order_release);\n     state.Wait(TestState::DONE);\n   }\n }\n@@ -373,6 +366,4 @@ TEST(SkipTest, Concurrent5) { RunConcurrent(5); }\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "9f1d66491d32f4d000a399391925751301bb7eec",
        "filename": "db/snapshot.h",
        "status": "modified",
        "additions": 53,
        "deletions": 25,
        "changes": 78,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/snapshot.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/snapshot.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/snapshot.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -16,50 +16,78 @@ class SnapshotList;\n // Each SnapshotImpl corresponds to a particular sequence number.\n class SnapshotImpl : public Snapshot {\n  public:\n-  SequenceNumber number_;  // const after creation\n+  SnapshotImpl(SequenceNumber sequence_number)\n+      : sequence_number_(sequence_number) {}\n+\n+  SequenceNumber sequence_number() const { return sequence_number_; }\n \n  private:\n   friend class SnapshotList;\n \n-  // SnapshotImpl is kept in a doubly-linked circular list\n+  // SnapshotImpl is kept in a doubly-linked circular list. The SnapshotList\n+  // implementation operates on the next/previous fields direcly.\n   SnapshotImpl* prev_;\n   SnapshotImpl* next_;\n \n-  SnapshotList* list_;                 // just for sanity checks\n+  const SequenceNumber sequence_number_;\n+\n+#if !defined(NDEBUG)\n+  SnapshotList* list_ = nullptr;\n+#endif  // !defined(NDEBUG)\n };\n \n class SnapshotList {\n  public:\n-  SnapshotList() {\n-    list_.prev_ = &list_;\n-    list_.next_ = &list_;\n+  SnapshotList() : head_(0) {\n+    head_.prev_ = &head_;\n+    head_.next_ = &head_;\n+  }\n+\n+  bool empty() const { return head_.next_ == &head_; }\n+  SnapshotImpl* oldest() const {\n+    assert(!empty());\n+    return head_.next_;\n   }\n+  SnapshotImpl* newest() const {\n+    assert(!empty());\n+    return head_.prev_;\n+  }\n+\n+  // Creates a SnapshotImpl and appends it to the end of the list.\n+  SnapshotImpl* New(SequenceNumber sequence_number) {\n+    assert(empty() || newest()->sequence_number_ <= sequence_number);\n+\n+    SnapshotImpl* snapshot = new SnapshotImpl(sequence_number);\n \n-  bool empty() const { return list_.next_ == &list_; }\n-  SnapshotImpl* oldest() const { assert(!empty()); return list_.next_; }\n-  SnapshotImpl* newest() const { assert(!empty()); return list_.prev_; }\n-\n-  const SnapshotImpl* New(SequenceNumber seq) {\n-    SnapshotImpl* s = new SnapshotImpl;\n-    s->number_ = seq;\n-    s->list_ = this;\n-    s->next_ = &list_;\n-    s->prev_ = list_.prev_;\n-    s->prev_->next_ = s;\n-    s->next_->prev_ = s;\n-    return s;\n+#if !defined(NDEBUG)\n+    snapshot->list_ = this;\n+#endif  // !defined(NDEBUG)\n+    snapshot->next_ = &head_;\n+    snapshot->prev_ = head_.prev_;\n+    snapshot->prev_->next_ = snapshot;\n+    snapshot->next_->prev_ = snapshot;\n+    return snapshot;\n   }\n \n-  void Delete(const SnapshotImpl* s) {\n-    assert(s->list_ == this);\n-    s->prev_->next_ = s->next_;\n-    s->next_->prev_ = s->prev_;\n-    delete s;\n+  // Removes a SnapshotImpl from this list.\n+  //\n+  // The snapshot must have been created by calling New() on this list.\n+  //\n+  // The snapshot pointer should not be const, because its memory is\n+  // deallocated. However, that would force us to change DB::ReleaseSnapshot(),\n+  // which is in the API, and currently takes a const Snapshot.\n+  void Delete(const SnapshotImpl* snapshot) {\n+#if !defined(NDEBUG)\n+    assert(snapshot->list_ == this);\n+#endif  // !defined(NDEBUG)\n+    snapshot->prev_->next_ = snapshot->next_;\n+    snapshot->next_->prev_ = snapshot->prev_;\n+    delete snapshot;\n   }\n \n  private:\n   // Dummy head of doubly-linked list of snapshots\n-  SnapshotImpl list_;\n+  SnapshotImpl head_;\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "73f05fd7b1e7943ecca5eb0ea87c64475049644d",
        "filename": "db/table_cache.cc",
        "status": "modified",
        "additions": 20,
        "deletions": 27,
        "changes": 47,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/table_cache.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/table_cache.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/table_cache.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -29,18 +29,14 @@ static void UnrefEntry(void* arg1, void* arg2) {\n   cache->Release(h);\n }\n \n-TableCache::TableCache(const std::string& dbname,\n-                       const Options* options,\n+TableCache::TableCache(const std::string& dbname, const Options& options,\n                        int entries)\n-    : env_(options->env),\n+    : env_(options.env),\n       dbname_(dbname),\n       options_(options),\n-      cache_(NewLRUCache(entries)) {\n-}\n+      cache_(NewLRUCache(entries)) {}\n \n-TableCache::~TableCache() {\n-  delete cache_;\n-}\n+TableCache::~TableCache() { delete cache_; }\n \n Status TableCache::FindTable(uint64_t file_number, uint64_t file_size,\n                              Cache::Handle** handle) {\n@@ -49,10 +45,10 @@ Status TableCache::FindTable(uint64_t file_number, uint64_t file_size,\n   EncodeFixed64(buf, file_number);\n   Slice key(buf, sizeof(buf));\n   *handle = cache_->Lookup(key);\n-  if (*handle == NULL) {\n+  if (*handle == nullptr) {\n     std::string fname = TableFileName(dbname_, file_number);\n-    RandomAccessFile* file = NULL;\n-    Table* table = NULL;\n+    RandomAccessFile* file = nullptr;\n+    Table* table = nullptr;\n     s = env_->NewRandomAccessFile(fname, &file);\n     if (!s.ok()) {\n       std::string old_fname = SSTTableFileName(dbname_, file_number);\n@@ -61,11 +57,11 @@ Status TableCache::FindTable(uint64_t file_number, uint64_t file_size,\n       }\n     }\n     if (s.ok()) {\n-      s = Table::Open(*options_, file, file_size, &table);\n+      s = Table::Open(options_, file, file_size, &table);\n     }\n \n     if (!s.ok()) {\n-      assert(table == NULL);\n+      assert(table == nullptr);\n       delete file;\n       // We do not cache error results so that if the error is transient,\n       // or somebody repairs the file, we recover automatically.\n@@ -80,14 +76,13 @@ Status TableCache::FindTable(uint64_t file_number, uint64_t file_size,\n }\n \n Iterator* TableCache::NewIterator(const ReadOptions& options,\n-                                  uint64_t file_number,\n-                                  uint64_t file_size,\n+                                  uint64_t file_number, uint64_t file_size,\n                                   Table** tableptr) {\n-  if (tableptr != NULL) {\n-    *tableptr = NULL;\n+  if (tableptr != nullptr) {\n+    *tableptr = nullptr;\n   }\n \n-  Cache::Handle* handle = NULL;\n+  Cache::Handle* handle = nullptr;\n   Status s = FindTable(file_number, file_size, &handle);\n   if (!s.ok()) {\n     return NewErrorIterator(s);\n@@ -96,23 +91,21 @@ Iterator* TableCache::NewIterator(const ReadOptions& options,\n   Table* table = reinterpret_cast<TableAndFile*>(cache_->Value(handle))->table;\n   Iterator* result = table->NewIterator(options);\n   result->RegisterCleanup(&UnrefEntry, cache_, handle);\n-  if (tableptr != NULL) {\n+  if (tableptr != nullptr) {\n     *tableptr = table;\n   }\n   return result;\n }\n \n-Status TableCache::Get(const ReadOptions& options,\n-                       uint64_t file_number,\n-                       uint64_t file_size,\n-                       const Slice& k,\n-                       void* arg,\n-                       void (*saver)(void*, const Slice&, const Slice&)) {\n-  Cache::Handle* handle = NULL;\n+Status TableCache::Get(const ReadOptions& options, uint64_t file_number,\n+                       uint64_t file_size, const Slice& k, void* arg,\n+                       void (*handle_result)(void*, const Slice&,\n+                                             const Slice&)) {\n+  Cache::Handle* handle = nullptr;\n   Status s = FindTable(file_number, file_size, &handle);\n   if (s.ok()) {\n     Table* t = reinterpret_cast<TableAndFile*>(cache_->Value(handle))->table;\n-    s = t->InternalGet(options, k, arg, saver);\n+    s = t->InternalGet(options, k, arg, handle_result);\n     cache_->Release(handle);\n   }\n   return s;"
      },
      {
        "sha": "93069c88442627690329fa302d4c9076c1914083",
        "filename": "db/table_cache.h",
        "status": "modified",
        "additions": 15,
        "deletions": 18,
        "changes": 33,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/table_cache.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/table_cache.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/table_cache.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -7,8 +7,10 @@\n #ifndef STORAGE_LEVELDB_DB_TABLE_CACHE_H_\n #define STORAGE_LEVELDB_DB_TABLE_CACHE_H_\n \n-#include <string>\n #include <stdint.h>\n+\n+#include <string>\n+\n #include \"db/dbformat.h\"\n #include \"leveldb/cache.h\"\n #include \"leveldb/table.h\"\n@@ -20,40 +22,35 @@ class Env;\n \n class TableCache {\n  public:\n-  TableCache(const std::string& dbname, const Options* options, int entries);\n+  TableCache(const std::string& dbname, const Options& options, int entries);\n   ~TableCache();\n \n   // Return an iterator for the specified file number (the corresponding\n   // file length must be exactly \"file_size\" bytes).  If \"tableptr\" is\n-  // non-NULL, also sets \"*tableptr\" to point to the Table object\n-  // underlying the returned iterator, or NULL if no Table object underlies\n-  // the returned iterator.  The returned \"*tableptr\" object is owned by\n-  // the cache and should not be deleted, and is valid for as long as the\n+  // non-null, also sets \"*tableptr\" to point to the Table object\n+  // underlying the returned iterator, or to nullptr if no Table object\n+  // underlies the returned iterator.  The returned \"*tableptr\" object is owned\n+  // by the cache and should not be deleted, and is valid for as long as the\n   // returned iterator is live.\n-  Iterator* NewIterator(const ReadOptions& options,\n-                        uint64_t file_number,\n-                        uint64_t file_size,\n-                        Table** tableptr = NULL);\n+  Iterator* NewIterator(const ReadOptions& options, uint64_t file_number,\n+                        uint64_t file_size, Table** tableptr = nullptr);\n \n   // If a seek to internal key \"k\" in specified file finds an entry,\n   // call (*handle_result)(arg, found_key, found_value).\n-  Status Get(const ReadOptions& options,\n-             uint64_t file_number,\n-             uint64_t file_size,\n-             const Slice& k,\n-             void* arg,\n+  Status Get(const ReadOptions& options, uint64_t file_number,\n+             uint64_t file_size, const Slice& k, void* arg,\n              void (*handle_result)(void*, const Slice&, const Slice&));\n \n   // Evict any entry for the specified file number\n   void Evict(uint64_t file_number);\n \n  private:\n+  Status FindTable(uint64_t file_number, uint64_t file_size, Cache::Handle**);\n+\n   Env* const env_;\n   const std::string dbname_;\n-  const Options* options_;\n+  const Options& options_;\n   Cache* cache_;\n-\n-  Status FindTable(uint64_t file_number, uint64_t file_size, Cache::Handle**);\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "cd770ef12d842da25c622f1bf5eb649884321f18",
        "filename": "db/version_edit.cc",
        "status": "modified",
        "additions": 23,
        "deletions": 32,
        "changes": 55,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/version_edit.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/version_edit.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/version_edit.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -12,15 +12,15 @@ namespace leveldb {\n // Tag numbers for serialized VersionEdit.  These numbers are written to\n // disk and should not be changed.\n enum Tag {\n-  kComparator           = 1,\n-  kLogNumber            = 2,\n-  kNextFileNumber       = 3,\n-  kLastSequence         = 4,\n-  kCompactPointer       = 5,\n-  kDeletedFile          = 6,\n-  kNewFile              = 7,\n+  kComparator = 1,\n+  kLogNumber = 2,\n+  kNextFileNumber = 3,\n+  kLastSequence = 4,\n+  kCompactPointer = 5,\n+  kDeletedFile = 6,\n+  kNewFile = 7,\n   // 8 was used for large value refs\n-  kPrevLogNumber        = 9\n+  kPrevLogNumber = 9\n };\n \n void VersionEdit::Clear() {\n@@ -66,12 +66,10 @@ void VersionEdit::EncodeTo(std::string* dst) const {\n     PutLengthPrefixedSlice(dst, compact_pointers_[i].second.Encode());\n   }\n \n-  for (DeletedFileSet::const_iterator iter = deleted_files_.begin();\n-       iter != deleted_files_.end();\n-       ++iter) {\n+  for (const auto& deleted_file_kvp : deleted_files_) {\n     PutVarint32(dst, kDeletedFile);\n-    PutVarint32(dst, iter->first);   // level\n-    PutVarint64(dst, iter->second);  // file number\n+    PutVarint32(dst, deleted_file_kvp.first);   // level\n+    PutVarint64(dst, deleted_file_kvp.second);  // file number\n   }\n \n   for (size_t i = 0; i < new_files_.size(); i++) {\n@@ -88,17 +86,15 @@ void VersionEdit::EncodeTo(std::string* dst) const {\n static bool GetInternalKey(Slice* input, InternalKey* dst) {\n   Slice str;\n   if (GetLengthPrefixedSlice(input, &str)) {\n-    dst->DecodeFrom(str);\n-    return true;\n+    return dst->DecodeFrom(str);\n   } else {\n     return false;\n   }\n }\n \n static bool GetLevel(Slice* input, int* level) {\n   uint32_t v;\n-  if (GetVarint32(input, &v) &&\n-      v < config::kNumLevels) {\n+  if (GetVarint32(input, &v) && v < config::kNumLevels) {\n     *level = v;\n     return true;\n   } else {\n@@ -109,7 +105,7 @@ static bool GetLevel(Slice* input, int* level) {\n Status VersionEdit::DecodeFrom(const Slice& src) {\n   Clear();\n   Slice input = src;\n-  const char* msg = NULL;\n+  const char* msg = nullptr;\n   uint32_t tag;\n \n   // Temporary storage for parsing\n@@ -119,7 +115,7 @@ Status VersionEdit::DecodeFrom(const Slice& src) {\n   Slice str;\n   InternalKey key;\n \n-  while (msg == NULL && GetVarint32(&input, &tag)) {\n+  while (msg == nullptr && GetVarint32(&input, &tag)) {\n     switch (tag) {\n       case kComparator:\n         if (GetLengthPrefixedSlice(&input, &str)) {\n@@ -163,26 +159,23 @@ Status VersionEdit::DecodeFrom(const Slice& src) {\n         break;\n \n       case kCompactPointer:\n-        if (GetLevel(&input, &level) &&\n-            GetInternalKey(&input, &key)) {\n+        if (GetLevel(&input, &level) && GetInternalKey(&input, &key)) {\n           compact_pointers_.push_back(std::make_pair(level, key));\n         } else {\n           msg = \"compaction pointer\";\n         }\n         break;\n \n       case kDeletedFile:\n-        if (GetLevel(&input, &level) &&\n-            GetVarint64(&input, &number)) {\n+        if (GetLevel(&input, &level) && GetVarint64(&input, &number)) {\n           deleted_files_.insert(std::make_pair(level, number));\n         } else {\n           msg = \"deleted file\";\n         }\n         break;\n \n       case kNewFile:\n-        if (GetLevel(&input, &level) &&\n-            GetVarint64(&input, &f.number) &&\n+        if (GetLevel(&input, &level) && GetVarint64(&input, &f.number) &&\n             GetVarint64(&input, &f.file_size) &&\n             GetInternalKey(&input, &f.smallest) &&\n             GetInternalKey(&input, &f.largest)) {\n@@ -198,12 +191,12 @@ Status VersionEdit::DecodeFrom(const Slice& src) {\n     }\n   }\n \n-  if (msg == NULL && !input.empty()) {\n+  if (msg == nullptr && !input.empty()) {\n     msg = \"invalid tag\";\n   }\n \n   Status result;\n-  if (msg != NULL) {\n+  if (msg != nullptr) {\n     result = Status::Corruption(\"VersionEdit\", msg);\n   }\n   return result;\n@@ -238,13 +231,11 @@ std::string VersionEdit::DebugString() const {\n     r.append(\" \");\n     r.append(compact_pointers_[i].second.DebugString());\n   }\n-  for (DeletedFileSet::const_iterator iter = deleted_files_.begin();\n-       iter != deleted_files_.end();\n-       ++iter) {\n+  for (const auto& deleted_files_kvp : deleted_files_) {\n     r.append(\"\\n  DeleteFile: \");\n-    AppendNumberTo(&r, iter->first);\n+    AppendNumberTo(&r, deleted_files_kvp.first);\n     r.append(\" \");\n-    AppendNumberTo(&r, iter->second);\n+    AppendNumberTo(&r, deleted_files_kvp.second);\n   }\n   for (size_t i = 0; i < new_files_.size(); i++) {\n     const FileMetaData& f = new_files_[i].second;"
      },
      {
        "sha": "0de4531773883813820de74be034c1c2c0a66c99",
        "filename": "db/version_edit.h",
        "status": "modified",
        "additions": 13,
        "deletions": 14,
        "changes": 27,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/version_edit.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/version_edit.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/version_edit.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -8,27 +8,28 @@\n #include <set>\n #include <utility>\n #include <vector>\n+\n #include \"db/dbformat.h\"\n \n namespace leveldb {\n \n class VersionSet;\n \n struct FileMetaData {\n+  FileMetaData() : refs(0), allowed_seeks(1 << 30), file_size(0) {}\n+\n   int refs;\n-  int allowed_seeks;          // Seeks allowed until compaction\n+  int allowed_seeks;  // Seeks allowed until compaction\n   uint64_t number;\n-  uint64_t file_size;         // File size in bytes\n-  InternalKey smallest;       // Smallest internal key served by table\n-  InternalKey largest;        // Largest internal key served by table\n-\n-  FileMetaData() : refs(0), allowed_seeks(1 << 30), file_size(0) { }\n+  uint64_t file_size;    // File size in bytes\n+  InternalKey smallest;  // Smallest internal key served by table\n+  InternalKey largest;   // Largest internal key served by table\n };\n \n class VersionEdit {\n  public:\n   VersionEdit() { Clear(); }\n-  ~VersionEdit() { }\n+  ~VersionEdit() = default;\n \n   void Clear();\n \n@@ -59,10 +60,8 @@ class VersionEdit {\n   // Add the specified file at the specified number.\n   // REQUIRES: This version has not been saved (see VersionSet::SaveTo)\n   // REQUIRES: \"smallest\" and \"largest\" are smallest and largest keys in file\n-  void AddFile(int level, uint64_t file,\n-               uint64_t file_size,\n-               const InternalKey& smallest,\n-               const InternalKey& largest) {\n+  void AddFile(int level, uint64_t file, uint64_t file_size,\n+               const InternalKey& smallest, const InternalKey& largest) {\n     FileMetaData f;\n     f.number = file;\n     f.file_size = file_size;\n@@ -84,7 +83,7 @@ class VersionEdit {\n  private:\n   friend class VersionSet;\n \n-  typedef std::set< std::pair<int, uint64_t> > DeletedFileSet;\n+  typedef std::set<std::pair<int, uint64_t>> DeletedFileSet;\n \n   std::string comparator_;\n   uint64_t log_number_;\n@@ -97,9 +96,9 @@ class VersionEdit {\n   bool has_next_file_number_;\n   bool has_last_sequence_;\n \n-  std::vector< std::pair<int, InternalKey> > compact_pointers_;\n+  std::vector<std::pair<int, InternalKey>> compact_pointers_;\n   DeletedFileSet deleted_files_;\n-  std::vector< std::pair<int, FileMetaData> > new_files_;\n+  std::vector<std::pair<int, FileMetaData>> new_files_;\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "0b7cda8854825d97c83fcb598a62d4c311becb0f",
        "filename": "db/version_edit_test.cc",
        "status": "modified",
        "additions": 2,
        "deletions": 4,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/version_edit_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/version_edit_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/version_edit_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -17,7 +17,7 @@ static void TestEncodeDecode(const VersionEdit& edit) {\n   ASSERT_EQ(encoded, encoded2);\n }\n \n-class VersionEditTest { };\n+class VersionEditTest {};\n \n TEST(VersionEditTest, EncodeDecode) {\n   static const uint64_t kBig = 1ull << 50;\n@@ -41,6 +41,4 @@ TEST(VersionEditTest, EncodeDecode) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "cd07346ea8a029bdc57dc9ca7339f79060369521",
        "filename": "db/version_set.cc",
        "status": "modified",
        "additions": 272,
        "deletions": 245,
        "changes": 517,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/version_set.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/version_set.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/version_set.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -4,8 +4,10 @@\n \n #include \"db/version_set.h\"\n \n-#include <algorithm>\n #include <stdio.h>\n+\n+#include <algorithm>\n+\n #include \"db/filename.h\"\n #include \"db/log_reader.h\"\n #include \"db/log_writer.h\"\n@@ -84,8 +86,7 @@ Version::~Version() {\n }\n \n int FindFile(const InternalKeyComparator& icmp,\n-             const std::vector<FileMetaData*>& files,\n-             const Slice& key) {\n+             const std::vector<FileMetaData*>& files, const Slice& key) {\n   uint32_t left = 0;\n   uint32_t right = files.size();\n   while (left < right) {\n@@ -104,26 +105,25 @@ int FindFile(const InternalKeyComparator& icmp,\n   return right;\n }\n \n-static bool AfterFile(const Comparator* ucmp,\n-                      const Slice* user_key, const FileMetaData* f) {\n-  // NULL user_key occurs before all keys and is therefore never after *f\n-  return (user_key != NULL &&\n+static bool AfterFile(const Comparator* ucmp, const Slice* user_key,\n+                      const FileMetaData* f) {\n+  // null user_key occurs before all keys and is therefore never after *f\n+  return (user_key != nullptr &&\n           ucmp->Compare(*user_key, f->largest.user_key()) > 0);\n }\n \n-static bool BeforeFile(const Comparator* ucmp,\n-                       const Slice* user_key, const FileMetaData* f) {\n-  // NULL user_key occurs after all keys and is therefore never before *f\n-  return (user_key != NULL &&\n+static bool BeforeFile(const Comparator* ucmp, const Slice* user_key,\n+                       const FileMetaData* f) {\n+  // null user_key occurs after all keys and is therefore never before *f\n+  return (user_key != nullptr &&\n           ucmp->Compare(*user_key, f->smallest.user_key()) < 0);\n }\n \n-bool SomeFileOverlapsRange(\n-    const InternalKeyComparator& icmp,\n-    bool disjoint_sorted_files,\n-    const std::vector<FileMetaData*>& files,\n-    const Slice* smallest_user_key,\n-    const Slice* largest_user_key) {\n+bool SomeFileOverlapsRange(const InternalKeyComparator& icmp,\n+                           bool disjoint_sorted_files,\n+                           const std::vector<FileMetaData*>& files,\n+                           const Slice* smallest_user_key,\n+                           const Slice* largest_user_key) {\n   const Comparator* ucmp = icmp.user_comparator();\n   if (!disjoint_sorted_files) {\n     // Need to check against all files\n@@ -141,10 +141,11 @@ bool SomeFileOverlapsRange(\n \n   // Binary search over file list\n   uint32_t index = 0;\n-  if (smallest_user_key != NULL) {\n+  if (smallest_user_key != nullptr) {\n     // Find the earliest possible internal key for smallest_user_key\n-    InternalKey small(*smallest_user_key, kMaxSequenceNumber,kValueTypeForSeek);\n-    index = FindFile(icmp, files, small.Encode());\n+    InternalKey small_key(*smallest_user_key, kMaxSequenceNumber,\n+                          kValueTypeForSeek);\n+    index = FindFile(icmp, files, small_key.Encode());\n   }\n \n   if (index >= files.size()) {\n@@ -164,43 +165,40 @@ class Version::LevelFileNumIterator : public Iterator {\n  public:\n   LevelFileNumIterator(const InternalKeyComparator& icmp,\n                        const std::vector<FileMetaData*>* flist)\n-      : icmp_(icmp),\n-        flist_(flist),\n-        index_(flist->size()) {        // Marks as invalid\n-  }\n-  virtual bool Valid() const {\n-    return index_ < flist_->size();\n+      : icmp_(icmp), flist_(flist), index_(flist->size()) {  // Marks as invalid\n   }\n-  virtual void Seek(const Slice& target) {\n+  bool Valid() const override { return index_ < flist_->size(); }\n+  void Seek(const Slice& target) override {\n     index_ = FindFile(icmp_, *flist_, target);\n   }\n-  virtual void SeekToFirst() { index_ = 0; }\n-  virtual void SeekToLast() {\n+  void SeekToFirst() override { index_ = 0; }\n+  void SeekToLast() override {\n     index_ = flist_->empty() ? 0 : flist_->size() - 1;\n   }\n-  virtual void Next() {\n+  void Next() override {\n     assert(Valid());\n     index_++;\n   }\n-  virtual void Prev() {\n+  void Prev() override {\n     assert(Valid());\n     if (index_ == 0) {\n       index_ = flist_->size();  // Marks as invalid\n     } else {\n       index_--;\n     }\n   }\n-  Slice key() const {\n+  Slice key() const override {\n     assert(Valid());\n     return (*flist_)[index_]->largest.Encode();\n   }\n-  Slice value() const {\n+  Slice value() const override {\n     assert(Valid());\n     EncodeFixed64(value_buf_, (*flist_)[index_]->number);\n-    EncodeFixed64(value_buf_+8, (*flist_)[index_]->file_size);\n+    EncodeFixed64(value_buf_ + 8, (*flist_)[index_]->file_size);\n     return Slice(value_buf_, sizeof(value_buf_));\n   }\n-  virtual Status status() const { return Status::OK(); }\n+  Status status() const override { return Status::OK(); }\n+\n  private:\n   const InternalKeyComparator icmp_;\n   const std::vector<FileMetaData*>* const flist_;\n@@ -210,34 +208,31 @@ class Version::LevelFileNumIterator : public Iterator {\n   mutable char value_buf_[16];\n };\n \n-static Iterator* GetFileIterator(void* arg,\n-                                 const ReadOptions& options,\n+static Iterator* GetFileIterator(void* arg, const ReadOptions& options,\n                                  const Slice& file_value) {\n   TableCache* cache = reinterpret_cast<TableCache*>(arg);\n   if (file_value.size() != 16) {\n     return NewErrorIterator(\n         Status::Corruption(\"FileReader invoked with unexpected value\"));\n   } else {\n-    return cache->NewIterator(options,\n-                              DecodeFixed64(file_value.data()),\n+    return cache->NewIterator(options, DecodeFixed64(file_value.data()),\n                               DecodeFixed64(file_value.data() + 8));\n   }\n }\n \n Iterator* Version::NewConcatenatingIterator(const ReadOptions& options,\n                                             int level) const {\n   return NewTwoLevelIterator(\n-      new LevelFileNumIterator(vset_->icmp_, &files_[level]),\n-      &GetFileIterator, vset_->table_cache_, options);\n+      new LevelFileNumIterator(vset_->icmp_, &files_[level]), &GetFileIterator,\n+      vset_->table_cache_, options);\n }\n \n void Version::AddIterators(const ReadOptions& options,\n                            std::vector<Iterator*>* iters) {\n   // Merge all level zero files together since they may overlap\n   for (size_t i = 0; i < files_[0].size(); i++) {\n-    iters->push_back(\n-        vset_->table_cache_->NewIterator(\n-            options, files_[0][i]->number, files_[0][i]->file_size));\n+    iters->push_back(vset_->table_cache_->NewIterator(\n+        options, files_[0][i]->number, files_[0][i]->file_size));\n   }\n \n   // For levels > 0, we can use a concatenating iterator that sequentially\n@@ -264,7 +259,7 @@ struct Saver {\n   Slice user_key;\n   std::string* value;\n };\n-}\n+}  // namespace\n static void SaveValue(void* arg, const Slice& ikey, const Slice& v) {\n   Saver* s = reinterpret_cast<Saver*>(arg);\n   ParsedInternalKey parsed_key;\n@@ -284,10 +279,8 @@ static bool NewestFirst(FileMetaData* a, FileMetaData* b) {\n   return a->number > b->number;\n }\n \n-void Version::ForEachOverlapping(Slice user_key, Slice internal_key,\n-                                 void* arg,\n+void Version::ForEachOverlapping(Slice user_key, Slice internal_key, void* arg,\n                                  bool (*func)(void*, int, FileMetaData*)) {\n-  // TODO(sanjay): Change Version::Get() to use this function.\n   const Comparator* ucmp = vset_->icmp_.user_comparator();\n \n   // Search level-0 in order from newest to oldest.\n@@ -329,110 +322,89 @@ void Version::ForEachOverlapping(Slice user_key, Slice internal_key,\n   }\n }\n \n-Status Version::Get(const ReadOptions& options,\n-                    const LookupKey& k,\n-                    std::string* value,\n-                    GetStats* stats) {\n-  Slice ikey = k.internal_key();\n-  Slice user_key = k.user_key();\n-  const Comparator* ucmp = vset_->icmp_.user_comparator();\n-  Status s;\n-\n-  stats->seek_file = NULL;\n+Status Version::Get(const ReadOptions& options, const LookupKey& k,\n+                    std::string* value, GetStats* stats) {\n+  stats->seek_file = nullptr;\n   stats->seek_file_level = -1;\n-  FileMetaData* last_file_read = NULL;\n-  int last_file_read_level = -1;\n \n-  // We can search level-by-level since entries never hop across\n-  // levels.  Therefore we are guaranteed that if we find data\n-  // in an smaller level, later levels are irrelevant.\n-  std::vector<FileMetaData*> tmp;\n-  FileMetaData* tmp2;\n-  for (int level = 0; level < config::kNumLevels; level++) {\n-    size_t num_files = files_[level].size();\n-    if (num_files == 0) continue;\n+  struct State {\n+    Saver saver;\n+    GetStats* stats;\n+    const ReadOptions* options;\n+    Slice ikey;\n+    FileMetaData* last_file_read;\n+    int last_file_read_level;\n \n-    // Get the list of files to search in this level\n-    FileMetaData* const* files = &files_[level][0];\n-    if (level == 0) {\n-      // Level-0 files may overlap each other.  Find all files that\n-      // overlap user_key and process them in order from newest to oldest.\n-      tmp.reserve(num_files);\n-      for (uint32_t i = 0; i < num_files; i++) {\n-        FileMetaData* f = files[i];\n-        if (ucmp->Compare(user_key, f->smallest.user_key()) >= 0 &&\n-            ucmp->Compare(user_key, f->largest.user_key()) <= 0) {\n-          tmp.push_back(f);\n-        }\n-      }\n-      if (tmp.empty()) continue;\n+    VersionSet* vset;\n+    Status s;\n+    bool found;\n \n-      std::sort(tmp.begin(), tmp.end(), NewestFirst);\n-      files = &tmp[0];\n-      num_files = tmp.size();\n-    } else {\n-      // Binary search to find earliest index whose largest key >= ikey.\n-      uint32_t index = FindFile(vset_->icmp_, files_[level], ikey);\n-      if (index >= num_files) {\n-        files = NULL;\n-        num_files = 0;\n-      } else {\n-        tmp2 = files[index];\n-        if (ucmp->Compare(user_key, tmp2->smallest.user_key()) < 0) {\n-          // All of \"tmp2\" is past any data for user_key\n-          files = NULL;\n-          num_files = 0;\n-        } else {\n-          files = &tmp2;\n-          num_files = 1;\n-        }\n-      }\n-    }\n+    static bool Match(void* arg, int level, FileMetaData* f) {\n+      State* state = reinterpret_cast<State*>(arg);\n \n-    for (uint32_t i = 0; i < num_files; ++i) {\n-      if (last_file_read != NULL && stats->seek_file == NULL) {\n+      if (state->stats->seek_file == nullptr &&\n+          state->last_file_read != nullptr) {\n         // We have had more than one seek for this read.  Charge the 1st file.\n-        stats->seek_file = last_file_read;\n-        stats->seek_file_level = last_file_read_level;\n+        state->stats->seek_file = state->last_file_read;\n+        state->stats->seek_file_level = state->last_file_read_level;\n       }\n \n-      FileMetaData* f = files[i];\n-      last_file_read = f;\n-      last_file_read_level = level;\n-\n-      Saver saver;\n-      saver.state = kNotFound;\n-      saver.ucmp = ucmp;\n-      saver.user_key = user_key;\n-      saver.value = value;\n-      s = vset_->table_cache_->Get(options, f->number, f->file_size,\n-                                   ikey, &saver, SaveValue);\n-      if (!s.ok()) {\n-        return s;\n+      state->last_file_read = f;\n+      state->last_file_read_level = level;\n+\n+      state->s = state->vset->table_cache_->Get(*state->options, f->number,\n+                                                f->file_size, state->ikey,\n+                                                &state->saver, SaveValue);\n+      if (!state->s.ok()) {\n+        state->found = true;\n+        return false;\n       }\n-      switch (saver.state) {\n+      switch (state->saver.state) {\n         case kNotFound:\n-          break;      // Keep searching in other files\n+          return true;  // Keep searching in other files\n         case kFound:\n-          return s;\n+          state->found = true;\n+          return false;\n         case kDeleted:\n-          s = Status::NotFound(Slice());  // Use empty error message for speed\n-          return s;\n+          return false;\n         case kCorrupt:\n-          s = Status::Corruption(\"corrupted key for \", user_key);\n-          return s;\n+          state->s =\n+              Status::Corruption(\"corrupted key for \", state->saver.user_key);\n+          state->found = true;\n+          return false;\n       }\n+\n+      // Not reached. Added to avoid false compilation warnings of\n+      // \"control reaches end of non-void function\".\n+      return false;\n     }\n-  }\n+  };\n+\n+  State state;\n+  state.found = false;\n+  state.stats = stats;\n+  state.last_file_read = nullptr;\n+  state.last_file_read_level = -1;\n \n-  return Status::NotFound(Slice());  // Use an empty error message for speed\n+  state.options = &options;\n+  state.ikey = k.internal_key();\n+  state.vset = vset_;\n+\n+  state.saver.state = kNotFound;\n+  state.saver.ucmp = vset_->icmp_.user_comparator();\n+  state.saver.user_key = k.user_key();\n+  state.saver.value = value;\n+\n+  ForEachOverlapping(state.saver.user_key, state.ikey, &state, &State::Match);\n+\n+  return state.found ? state.s : Status::NotFound(Slice());\n }\n \n bool Version::UpdateStats(const GetStats& stats) {\n   FileMetaData* f = stats.seek_file;\n-  if (f != NULL) {\n+  if (f != nullptr) {\n     f->allowed_seeks--;\n-    if (f->allowed_seeks <= 0 && file_to_compact_ == NULL) {\n+    if (f->allowed_seeks <= 0 && file_to_compact_ == nullptr) {\n       file_to_compact_ = f;\n       file_to_compact_level_ = stats.seek_file_level;\n       return true;\n@@ -479,9 +451,7 @@ bool Version::RecordReadSample(Slice internal_key) {\n   return false;\n }\n \n-void Version::Ref() {\n-  ++refs_;\n-}\n+void Version::Ref() { ++refs_; }\n \n void Version::Unref() {\n   assert(this != &vset_->dummy_versions_);\n@@ -492,16 +462,14 @@ void Version::Unref() {\n   }\n }\n \n-bool Version::OverlapInLevel(int level,\n-                             const Slice* smallest_user_key,\n+bool Version::OverlapInLevel(int level, const Slice* smallest_user_key,\n                              const Slice* largest_user_key) {\n   return SomeFileOverlapsRange(vset_->icmp_, (level > 0), files_[level],\n                                smallest_user_key, largest_user_key);\n }\n \n-int Version::PickLevelForMemTableOutput(\n-    const Slice& smallest_user_key,\n-    const Slice& largest_user_key) {\n+int Version::PickLevelForMemTableOutput(const Slice& smallest_user_key,\n+                                        const Slice& largest_user_key) {\n   int level = 0;\n   if (!OverlapInLevel(0, &smallest_user_key, &largest_user_key)) {\n     // Push to next level if there is no overlap in next level,\n@@ -528,40 +496,39 @@ int Version::PickLevelForMemTableOutput(\n }\n \n // Store in \"*inputs\" all files in \"level\" that overlap [begin,end]\n-void Version::GetOverlappingInputs(\n-    int level,\n-    const InternalKey* begin,\n-    const InternalKey* end,\n-    std::vector<FileMetaData*>* inputs) {\n+void Version::GetOverlappingInputs(int level, const InternalKey* begin,\n+                                   const InternalKey* end,\n+                                   std::vector<FileMetaData*>* inputs) {\n   assert(level >= 0);\n   assert(level < config::kNumLevels);\n   inputs->clear();\n   Slice user_begin, user_end;\n-  if (begin != NULL) {\n+  if (begin != nullptr) {\n     user_begin = begin->user_key();\n   }\n-  if (end != NULL) {\n+  if (end != nullptr) {\n     user_end = end->user_key();\n   }\n   const Comparator* user_cmp = vset_->icmp_.user_comparator();\n-  for (size_t i = 0; i < files_[level].size(); ) {\n+  for (size_t i = 0; i < files_[level].size();) {\n     FileMetaData* f = files_[level][i++];\n     const Slice file_start = f->smallest.user_key();\n     const Slice file_limit = f->largest.user_key();\n-    if (begin != NULL && user_cmp->Compare(file_limit, user_begin) < 0) {\n+    if (begin != nullptr && user_cmp->Compare(file_limit, user_begin) < 0) {\n       // \"f\" is completely before specified range; skip it\n-    } else if (end != NULL && user_cmp->Compare(file_start, user_end) > 0) {\n+    } else if (end != nullptr && user_cmp->Compare(file_start, user_end) > 0) {\n       // \"f\" is completely after specified range; skip it\n     } else {\n       inputs->push_back(f);\n       if (level == 0) {\n         // Level-0 files may overlap each other.  So check if the newly\n         // added file has expanded the range.  If so, restart search.\n-        if (begin != NULL && user_cmp->Compare(file_start, user_begin) < 0) {\n+        if (begin != nullptr && user_cmp->Compare(file_start, user_begin) < 0) {\n           user_begin = file_start;\n           inputs->clear();\n           i = 0;\n-        } else if (end != NULL && user_cmp->Compare(file_limit, user_end) > 0) {\n+        } else if (end != nullptr &&\n+                   user_cmp->Compare(file_limit, user_end) > 0) {\n           user_end = file_limit;\n           inputs->clear();\n           i = 0;\n@@ -629,9 +596,7 @@ class VersionSet::Builder {\n \n  public:\n   // Initialize a builder with the files from *base and other info from *vset\n-  Builder(VersionSet* vset, Version* base)\n-      : vset_(vset),\n-        base_(base) {\n+  Builder(VersionSet* vset, Version* base) : vset_(vset), base_(base) {\n     base_->Ref();\n     BySmallestKey cmp;\n     cmp.internal_comparator = &vset_->icmp_;\n@@ -645,8 +610,8 @@ class VersionSet::Builder {\n       const FileSet* added = levels_[level].added_files;\n       std::vector<FileMetaData*> to_unref;\n       to_unref.reserve(added->size());\n-      for (FileSet::const_iterator it = added->begin();\n-          it != added->end(); ++it) {\n+      for (FileSet::const_iterator it = added->begin(); it != added->end();\n+           ++it) {\n         to_unref.push_back(*it);\n       }\n       delete added;\n@@ -671,12 +636,9 @@ class VersionSet::Builder {\n     }\n \n     // Delete files\n-    const VersionEdit::DeletedFileSet& del = edit->deleted_files_;\n-    for (VersionEdit::DeletedFileSet::const_iterator iter = del.begin();\n-         iter != del.end();\n-         ++iter) {\n-      const int level = iter->first;\n-      const uint64_t number = iter->second;\n+    for (const auto& deleted_file_set_kvp : edit->deleted_files_) {\n+      const int level = deleted_file_set_kvp.first;\n+      const uint64_t number = deleted_file_set_kvp.second;\n       levels_[level].deleted_files.insert(number);\n     }\n \n@@ -699,7 +661,7 @@ class VersionSet::Builder {\n       // same as the compaction of 40KB of data.  We are a little\n       // conservative and allow approximately one seek for every 16KB\n       // of data before triggering a compaction.\n-      f->allowed_seeks = (f->file_size / 16384);\n+      f->allowed_seeks = static_cast<int>((f->file_size / 16384U));\n       if (f->allowed_seeks < 100) f->allowed_seeks = 100;\n \n       levels_[level].deleted_files.erase(f->number);\n@@ -717,20 +679,17 @@ class VersionSet::Builder {\n       const std::vector<FileMetaData*>& base_files = base_->files_[level];\n       std::vector<FileMetaData*>::const_iterator base_iter = base_files.begin();\n       std::vector<FileMetaData*>::const_iterator base_end = base_files.end();\n-      const FileSet* added = levels_[level].added_files;\n-      v->files_[level].reserve(base_files.size() + added->size());\n-      for (FileSet::const_iterator added_iter = added->begin();\n-           added_iter != added->end();\n-           ++added_iter) {\n+      const FileSet* added_files = levels_[level].added_files;\n+      v->files_[level].reserve(base_files.size() + added_files->size());\n+      for (const auto& added_file : *added_files) {\n         // Add all smaller files listed in base_\n-        for (std::vector<FileMetaData*>::const_iterator bpos\n-                 = std::upper_bound(base_iter, base_end, *added_iter, cmp);\n-             base_iter != bpos;\n-             ++base_iter) {\n+        for (std::vector<FileMetaData*>::const_iterator bpos =\n+                 std::upper_bound(base_iter, base_end, added_file, cmp);\n+             base_iter != bpos; ++base_iter) {\n           MaybeAddFile(v, level, *base_iter);\n         }\n \n-        MaybeAddFile(v, level, *added_iter);\n+        MaybeAddFile(v, level, added_file);\n       }\n \n       // Add remaining base files\n@@ -742,7 +701,7 @@ class VersionSet::Builder {\n       // Make sure there is no overlap in levels > 0\n       if (level > 0) {\n         for (uint32_t i = 1; i < v->files_[level].size(); i++) {\n-          const InternalKey& prev_end = v->files_[level][i-1]->largest;\n+          const InternalKey& prev_end = v->files_[level][i - 1]->largest;\n           const InternalKey& this_begin = v->files_[level][i]->smallest;\n           if (vset_->icmp_.Compare(prev_end, this_begin) >= 0) {\n             fprintf(stderr, \"overlapping ranges in same level %s vs. %s\\n\",\n@@ -763,7 +722,7 @@ class VersionSet::Builder {\n       std::vector<FileMetaData*>* files = &v->files_[level];\n       if (level > 0 && !files->empty()) {\n         // Must not overlap\n-        assert(vset_->icmp_.Compare((*files)[files->size()-1]->largest,\n+        assert(vset_->icmp_.Compare((*files)[files->size() - 1]->largest,\n                                     f->smallest) < 0);\n       }\n       f->refs++;\n@@ -772,8 +731,7 @@ class VersionSet::Builder {\n   }\n };\n \n-VersionSet::VersionSet(const std::string& dbname,\n-                       const Options* options,\n+VersionSet::VersionSet(const std::string& dbname, const Options* options,\n                        TableCache* table_cache,\n                        const InternalKeyComparator* cmp)\n     : env_(options->env),\n@@ -786,10 +744,10 @@ VersionSet::VersionSet(const std::string& dbname,\n       last_sequence_(0),\n       log_number_(0),\n       prev_log_number_(0),\n-      descriptor_file_(NULL),\n-      descriptor_log_(NULL),\n+      descriptor_file_(nullptr),\n+      descriptor_log_(nullptr),\n       dummy_versions_(this),\n-      current_(NULL) {\n+      current_(nullptr) {\n   AppendVersion(new Version(this));\n }\n \n@@ -804,7 +762,7 @@ void VersionSet::AppendVersion(Version* v) {\n   // Make \"v\" current\n   assert(v->refs_ == 0);\n   assert(v != current_);\n-  if (current_ != NULL) {\n+  if (current_ != nullptr) {\n     current_->Unref();\n   }\n   current_ = v;\n@@ -844,10 +802,10 @@ Status VersionSet::LogAndApply(VersionEdit* edit, port::Mutex* mu) {\n   // a temporary file that contains a snapshot of the current version.\n   std::string new_manifest_file;\n   Status s;\n-  if (descriptor_log_ == NULL) {\n+  if (descriptor_log_ == nullptr) {\n     // No reason to unlock *mu here since we only hit this path in the\n     // first call to LogAndApply (when opening the database).\n-    assert(descriptor_file_ == NULL);\n+    assert(descriptor_file_ == nullptr);\n     new_manifest_file = DescriptorFileName(dbname_, manifest_file_number_);\n     edit->SetNextFile(next_file_number_);\n     s = env_->NewWritableFile(new_manifest_file, &descriptor_file_);\n@@ -893,19 +851,19 @@ Status VersionSet::LogAndApply(VersionEdit* edit, port::Mutex* mu) {\n     if (!new_manifest_file.empty()) {\n       delete descriptor_log_;\n       delete descriptor_file_;\n-      descriptor_log_ = NULL;\n-      descriptor_file_ = NULL;\n+      descriptor_log_ = nullptr;\n+      descriptor_file_ = nullptr;\n       env_->DeleteFile(new_manifest_file);\n     }\n   }\n \n   return s;\n }\n \n-Status VersionSet::Recover(bool *save_manifest) {\n+Status VersionSet::Recover(bool* save_manifest) {\n   struct LogReporter : public log::Reader::Reporter {\n     Status* status;\n-    virtual void Corruption(size_t bytes, const Status& s) {\n+    void Corruption(size_t bytes, const Status& s) override {\n       if (this->status->ok()) *this->status = s;\n     }\n   };\n@@ -916,7 +874,7 @@ Status VersionSet::Recover(bool *save_manifest) {\n   if (!s.ok()) {\n     return s;\n   }\n-  if (current.empty() || current[current.size()-1] != '\\n') {\n+  if (current.empty() || current[current.size() - 1] != '\\n') {\n     return Status::Corruption(\"CURRENT file does not end with newline\");\n   }\n   current.resize(current.size() - 1);\n@@ -925,6 +883,10 @@ Status VersionSet::Recover(bool *save_manifest) {\n   SequentialFile* file;\n   s = env_->NewSequentialFile(dscname, &file);\n   if (!s.ok()) {\n+    if (s.IsNotFound()) {\n+      return Status::Corruption(\"CURRENT points to a non-existent file\",\n+                                s.ToString());\n+    }\n     return s;\n   }\n \n@@ -941,7 +903,8 @@ Status VersionSet::Recover(bool *save_manifest) {\n   {\n     LogReporter reporter;\n     reporter.status = &s;\n-    log::Reader reader(file, &reporter, true/*checksum*/, 0/*initial_offset*/);\n+    log::Reader reader(file, &reporter, true /*checksum*/,\n+                       0 /*initial_offset*/);\n     Slice record;\n     std::string scratch;\n     while (reader.ReadRecord(&record, &scratch) && s.ok()) {\n@@ -982,7 +945,7 @@ Status VersionSet::Recover(bool *save_manifest) {\n     }\n   }\n   delete file;\n-  file = NULL;\n+  file = nullptr;\n \n   if (s.ok()) {\n     if (!have_next_file) {\n@@ -1040,12 +1003,12 @@ bool VersionSet::ReuseManifest(const std::string& dscname,\n     return false;\n   }\n \n-  assert(descriptor_file_ == NULL);\n-  assert(descriptor_log_ == NULL);\n+  assert(descriptor_file_ == nullptr);\n+  assert(descriptor_log_ == nullptr);\n   Status r = env_->NewAppendableFile(dscname, &descriptor_file_);\n   if (!r.ok()) {\n     Log(options_->info_log, \"Reuse MANIFEST: %s\\n\", r.ToString().c_str());\n-    assert(descriptor_file_ == NULL);\n+    assert(descriptor_file_ == nullptr);\n     return false;\n   }\n \n@@ -1066,7 +1029,7 @@ void VersionSet::Finalize(Version* v) {\n   int best_level = -1;\n   double best_score = -1;\n \n-  for (int level = 0; level < config::kNumLevels-1; level++) {\n+  for (int level = 0; level < config::kNumLevels - 1; level++) {\n     double score;\n     if (level == 0) {\n       // We treat level-0 specially by bounding the number of files\n@@ -1081,7 +1044,7 @@ void VersionSet::Finalize(Version* v) {\n       // setting, or very high compression ratios, or lots of\n       // overwrites/deletions).\n       score = v->files_[level].size() /\n-          static_cast<double>(config::kL0_CompactionTrigger);\n+              static_cast<double>(config::kL0_CompactionTrigger);\n     } else {\n       // Compute the ratio of current size to size limit.\n       const uint64_t level_bytes = TotalFileSize(v->files_[level]);\n@@ -1137,16 +1100,12 @@ int VersionSet::NumLevelFiles(int level) const {\n \n const char* VersionSet::LevelSummary(LevelSummaryStorage* scratch) const {\n   // Update code if kNumLevels changes\n-  assert(config::kNumLevels == 7);\n+  static_assert(config::kNumLevels == 7, \"\");\n   snprintf(scratch->buffer, sizeof(scratch->buffer),\n-           \"files[ %d %d %d %d %d %d %d ]\",\n-           int(current_->files_[0].size()),\n-           int(current_->files_[1].size()),\n-           int(current_->files_[2].size()),\n-           int(current_->files_[3].size()),\n-           int(current_->files_[4].size()),\n-           int(current_->files_[5].size()),\n-           int(current_->files_[6].size()));\n+           \"files[ %d %d %d %d %d %d %d ]\", int(current_->files_[0].size()),\n+           int(current_->files_[1].size()), int(current_->files_[2].size()),\n+           int(current_->files_[3].size()), int(current_->files_[4].size()),\n+           int(current_->files_[5].size()), int(current_->files_[6].size()));\n   return scratch->buffer;\n }\n \n@@ -1172,7 +1131,7 @@ uint64_t VersionSet::ApproximateOffsetOf(Version* v, const InternalKey& ikey) {\n         Table* tableptr;\n         Iterator* iter = table_cache_->NewIterator(\n             ReadOptions(), files[i]->number, files[i]->file_size, &tableptr);\n-        if (tableptr != NULL) {\n+        if (tableptr != nullptr) {\n           result += tableptr->ApproximateOffsetOf(ikey.Encode());\n         }\n         delete iter;\n@@ -1183,8 +1142,7 @@ uint64_t VersionSet::ApproximateOffsetOf(Version* v, const InternalKey& ikey) {\n }\n \n void VersionSet::AddLiveFiles(std::set<uint64_t>* live) {\n-  for (Version* v = dummy_versions_.next_;\n-       v != &dummy_versions_;\n+  for (Version* v = dummy_versions_.next_; v != &dummy_versions_;\n        v = v->next_) {\n     for (int level = 0; level < config::kNumLevels; level++) {\n       const std::vector<FileMetaData*>& files = v->files_[level];\n@@ -1207,7 +1165,7 @@ int64_t VersionSet::MaxNextLevelOverlappingBytes() {\n   for (int level = 1; level < config::kNumLevels - 1; level++) {\n     for (size_t i = 0; i < current_->files_[level].size(); i++) {\n       const FileMetaData* f = current_->files_[level][i];\n-      current_->GetOverlappingInputs(level+1, &f->smallest, &f->largest,\n+      current_->GetOverlappingInputs(level + 1, &f->smallest, &f->largest,\n                                      &overlaps);\n       const int64_t sum = TotalFileSize(overlaps);\n       if (sum > result) {\n@@ -1222,8 +1180,7 @@ int64_t VersionSet::MaxNextLevelOverlappingBytes() {\n // *smallest, *largest.\n // REQUIRES: inputs is not empty\n void VersionSet::GetRange(const std::vector<FileMetaData*>& inputs,\n-                          InternalKey* smallest,\n-                          InternalKey* largest) {\n+                          InternalKey* smallest, InternalKey* largest) {\n   assert(!inputs.empty());\n   smallest->Clear();\n   largest->Clear();\n@@ -1248,8 +1205,7 @@ void VersionSet::GetRange(const std::vector<FileMetaData*>& inputs,\n // REQUIRES: inputs is not empty\n void VersionSet::GetRange2(const std::vector<FileMetaData*>& inputs1,\n                            const std::vector<FileMetaData*>& inputs2,\n-                           InternalKey* smallest,\n-                           InternalKey* largest) {\n+                           InternalKey* smallest, InternalKey* largest) {\n   std::vector<FileMetaData*> all = inputs1;\n   all.insert(all.end(), inputs2.begin(), inputs2.end());\n   GetRange(all, smallest, largest);\n@@ -1271,8 +1227,8 @@ Iterator* VersionSet::MakeInputIterator(Compaction* c) {\n       if (c->level() + which == 0) {\n         const std::vector<FileMetaData*>& files = c->inputs_[which];\n         for (size_t i = 0; i < files.size(); i++) {\n-          list[num++] = table_cache_->NewIterator(\n-              options, files[i]->number, files[i]->file_size);\n+          list[num++] = table_cache_->NewIterator(options, files[i]->number,\n+                                                  files[i]->file_size);\n         }\n       } else {\n         // Create concatenating iterator for the files from this level\n@@ -1295,11 +1251,11 @@ Compaction* VersionSet::PickCompaction() {\n   // We prefer compactions triggered by too much data in a level over\n   // the compactions triggered by seeks.\n   const bool size_compaction = (current_->compaction_score_ >= 1);\n-  const bool seek_compaction = (current_->file_to_compact_ != NULL);\n+  const bool seek_compaction = (current_->file_to_compact_ != nullptr);\n   if (size_compaction) {\n     level = current_->compaction_level_;\n     assert(level >= 0);\n-    assert(level+1 < config::kNumLevels);\n+    assert(level + 1 < config::kNumLevels);\n     c = new Compaction(options_, level);\n \n     // Pick the first file that comes after compact_pointer_[level]\n@@ -1320,7 +1276,7 @@ Compaction* VersionSet::PickCompaction() {\n     c = new Compaction(options_, level);\n     c->inputs_[0].push_back(current_->file_to_compact_);\n   } else {\n-    return NULL;\n+    return nullptr;\n   }\n \n   c->input_version_ = current_;\n@@ -1342,12 +1298,94 @@ Compaction* VersionSet::PickCompaction() {\n   return c;\n }\n \n+// Finds the largest key in a vector of files. Returns true if files it not\n+// empty.\n+bool FindLargestKey(const InternalKeyComparator& icmp,\n+                    const std::vector<FileMetaData*>& files,\n+                    InternalKey* largest_key) {\n+  if (files.empty()) {\n+    return false;\n+  }\n+  *largest_key = files[0]->largest;\n+  for (size_t i = 1; i < files.size(); ++i) {\n+    FileMetaData* f = files[i];\n+    if (icmp.Compare(f->largest, *largest_key) > 0) {\n+      *largest_key = f->largest;\n+    }\n+  }\n+  return true;\n+}\n+\n+// Finds minimum file b2=(l2, u2) in level file for which l2 > u1 and\n+// user_key(l2) = user_key(u1)\n+FileMetaData* FindSmallestBoundaryFile(\n+    const InternalKeyComparator& icmp,\n+    const std::vector<FileMetaData*>& level_files,\n+    const InternalKey& largest_key) {\n+  const Comparator* user_cmp = icmp.user_comparator();\n+  FileMetaData* smallest_boundary_file = nullptr;\n+  for (size_t i = 0; i < level_files.size(); ++i) {\n+    FileMetaData* f = level_files[i];\n+    if (icmp.Compare(f->smallest, largest_key) > 0 &&\n+        user_cmp->Compare(f->smallest.user_key(), largest_key.user_key()) ==\n+            0) {\n+      if (smallest_boundary_file == nullptr ||\n+          icmp.Compare(f->smallest, smallest_boundary_file->smallest) < 0) {\n+        smallest_boundary_file = f;\n+      }\n+    }\n+  }\n+  return smallest_boundary_file;\n+}\n+\n+// Extracts the largest file b1 from |compaction_files| and then searches for a\n+// b2 in |level_files| for which user_key(u1) = user_key(l2). If it finds such a\n+// file b2 (known as a boundary file) it adds it to |compaction_files| and then\n+// searches again using this new upper bound.\n+//\n+// If there are two blocks, b1=(l1, u1) and b2=(l2, u2) and\n+// user_key(u1) = user_key(l2), and if we compact b1 but not b2 then a\n+// subsequent get operation will yield an incorrect result because it will\n+// return the record from b2 in level i rather than from b1 because it searches\n+// level by level for records matching the supplied user key.\n+//\n+// parameters:\n+//   in     level_files:      List of files to search for boundary files.\n+//   in/out compaction_files: List of files to extend by adding boundary files.\n+void AddBoundaryInputs(const InternalKeyComparator& icmp,\n+                       const std::vector<FileMetaData*>& level_files,\n+                       std::vector<FileMetaData*>* compaction_files) {\n+  InternalKey largest_key;\n+\n+  // Quick return if compaction_files is empty.\n+  if (!FindLargestKey(icmp, *compaction_files, &largest_key)) {\n+    return;\n+  }\n+\n+  bool continue_searching = true;\n+  while (continue_searching) {\n+    FileMetaData* smallest_boundary_file =\n+        FindSmallestBoundaryFile(icmp, level_files, largest_key);\n+\n+    // If a boundary file was found advance largest_key, otherwise we're done.\n+    if (smallest_boundary_file != NULL) {\n+      compaction_files->push_back(smallest_boundary_file);\n+      largest_key = smallest_boundary_file->largest;\n+    } else {\n+      continue_searching = false;\n+    }\n+  }\n+}\n+\n void VersionSet::SetupOtherInputs(Compaction* c) {\n   const int level = c->level();\n   InternalKey smallest, largest;\n+\n+  AddBoundaryInputs(icmp_, current_->files_[level], &c->inputs_[0]);\n   GetRange(c->inputs_[0], &smallest, &largest);\n \n-  current_->GetOverlappingInputs(level+1, &smallest, &largest, &c->inputs_[1]);\n+  current_->GetOverlappingInputs(level + 1, &smallest, &largest,\n+                                 &c->inputs_[1]);\n \n   // Get entire range covered by compaction\n   InternalKey all_start, all_limit;\n@@ -1358,6 +1396,7 @@ void VersionSet::SetupOtherInputs(Compaction* c) {\n   if (!c->inputs_[1].empty()) {\n     std::vector<FileMetaData*> expanded0;\n     current_->GetOverlappingInputs(level, &all_start, &all_limit, &expanded0);\n+    AddBoundaryInputs(icmp_, current_->files_[level], &expanded0);\n     const int64_t inputs0_size = TotalFileSize(c->inputs_[0]);\n     const int64_t inputs1_size = TotalFileSize(c->inputs_[1]);\n     const int64_t expanded0_size = TotalFileSize(expanded0);\n@@ -1367,18 +1406,14 @@ void VersionSet::SetupOtherInputs(Compaction* c) {\n       InternalKey new_start, new_limit;\n       GetRange(expanded0, &new_start, &new_limit);\n       std::vector<FileMetaData*> expanded1;\n-      current_->GetOverlappingInputs(level+1, &new_start, &new_limit,\n+      current_->GetOverlappingInputs(level + 1, &new_start, &new_limit,\n                                      &expanded1);\n       if (expanded1.size() == c->inputs_[1].size()) {\n         Log(options_->info_log,\n             \"Expanding@%d %d+%d (%ld+%ld bytes) to %d+%d (%ld+%ld bytes)\\n\",\n-            level,\n-            int(c->inputs_[0].size()),\n-            int(c->inputs_[1].size()),\n-            long(inputs0_size), long(inputs1_size),\n-            int(expanded0.size()),\n-            int(expanded1.size()),\n-            long(expanded0_size), long(inputs1_size));\n+            level, int(c->inputs_[0].size()), int(c->inputs_[1].size()),\n+            long(inputs0_size), long(inputs1_size), int(expanded0.size()),\n+            int(expanded1.size()), long(expanded0_size), long(inputs1_size));\n         smallest = new_start;\n         largest = new_limit;\n         c->inputs_[0] = expanded0;\n@@ -1395,13 +1430,6 @@ void VersionSet::SetupOtherInputs(Compaction* c) {\n                                    &c->grandparents_);\n   }\n \n-  if (false) {\n-    Log(options_->info_log, \"Compacting %d '%s' .. '%s'\",\n-        level,\n-        smallest.DebugString().c_str(),\n-        largest.DebugString().c_str());\n-  }\n-\n   // Update the place where we will do the next compaction for this level.\n   // We update this immediately instead of waiting for the VersionEdit\n   // to be applied so that if the compaction fails, we will try a different\n@@ -1410,14 +1438,12 @@ void VersionSet::SetupOtherInputs(Compaction* c) {\n   c->edit_.SetCompactPointer(level, largest);\n }\n \n-Compaction* VersionSet::CompactRange(\n-    int level,\n-    const InternalKey* begin,\n-    const InternalKey* end) {\n+Compaction* VersionSet::CompactRange(int level, const InternalKey* begin,\n+                                     const InternalKey* end) {\n   std::vector<FileMetaData*> inputs;\n   current_->GetOverlappingInputs(level, begin, end, &inputs);\n   if (inputs.empty()) {\n-    return NULL;\n+    return nullptr;\n   }\n \n   // Avoid compacting too much in one shot in case the range is large.\n@@ -1448,7 +1474,7 @@ Compaction* VersionSet::CompactRange(\n Compaction::Compaction(const Options* options, int level)\n     : level_(level),\n       max_output_file_size_(MaxFileSizeForLevel(options, level)),\n-      input_version_(NULL),\n+      input_version_(nullptr),\n       grandparent_index_(0),\n       seen_key_(false),\n       overlapped_bytes_(0) {\n@@ -1458,7 +1484,7 @@ Compaction::Compaction(const Options* options, int level)\n }\n \n Compaction::~Compaction() {\n-  if (input_version_ != NULL) {\n+  if (input_version_ != nullptr) {\n     input_version_->Unref();\n   }\n }\n@@ -1486,7 +1512,7 @@ bool Compaction::IsBaseLevelForKey(const Slice& user_key) {\n   const Comparator* user_cmp = input_version_->vset_->icmp_.user_comparator();\n   for (int lvl = level_ + 2; lvl < config::kNumLevels; lvl++) {\n     const std::vector<FileMetaData*>& files = input_version_->files_[lvl];\n-    for (; level_ptrs_[lvl] < files.size(); ) {\n+    while (level_ptrs_[lvl] < files.size()) {\n       FileMetaData* f = files[level_ptrs_[lvl]];\n       if (user_cmp->Compare(user_key, f->largest.user_key()) <= 0) {\n         // We've advanced far enough\n@@ -1507,8 +1533,9 @@ bool Compaction::ShouldStopBefore(const Slice& internal_key) {\n   // Scan to find earliest grandparent file that contains key.\n   const InternalKeyComparator* icmp = &vset->icmp_;\n   while (grandparent_index_ < grandparents_.size() &&\n-      icmp->Compare(internal_key,\n-                    grandparents_[grandparent_index_]->largest.Encode()) > 0) {\n+         icmp->Compare(internal_key,\n+                       grandparents_[grandparent_index_]->largest.Encode()) >\n+             0) {\n     if (seen_key_) {\n       overlapped_bytes_ += grandparents_[grandparent_index_]->file_size;\n     }\n@@ -1526,9 +1553,9 @@ bool Compaction::ShouldStopBefore(const Slice& internal_key) {\n }\n \n void Compaction::ReleaseInputs() {\n-  if (input_version_ != NULL) {\n+  if (input_version_ != nullptr) {\n     input_version_->Unref();\n-    input_version_ = NULL;\n+    input_version_ = nullptr;\n   }\n }\n "
      },
      {
        "sha": "69f3d701330f0967f1b04e4daae6f513dca9af85",
        "filename": "db/version_set.h",
        "status": "modified",
        "additions": 59,
        "deletions": 64,
        "changes": 123,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/version_set.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/version_set.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/version_set.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -18,14 +18,17 @@\n #include <map>\n #include <set>\n #include <vector>\n+\n #include \"db/dbformat.h\"\n #include \"db/version_edit.h\"\n #include \"port/port.h\"\n #include \"port/thread_annotations.h\"\n \n namespace leveldb {\n \n-namespace log { class Writer; }\n+namespace log {\n+class Writer;\n+}\n \n class Compaction;\n class Iterator;\n@@ -39,37 +42,36 @@ class WritableFile;\n // Return the smallest index i such that files[i]->largest >= key.\n // Return files.size() if there is no such file.\n // REQUIRES: \"files\" contains a sorted list of non-overlapping files.\n-extern int FindFile(const InternalKeyComparator& icmp,\n-                    const std::vector<FileMetaData*>& files,\n-                    const Slice& key);\n+int FindFile(const InternalKeyComparator& icmp,\n+             const std::vector<FileMetaData*>& files, const Slice& key);\n \n // Returns true iff some file in \"files\" overlaps the user key range\n // [*smallest,*largest].\n-// smallest==NULL represents a key smaller than all keys in the DB.\n-// largest==NULL represents a key largest than all keys in the DB.\n+// smallest==nullptr represents a key smaller than all keys in the DB.\n+// largest==nullptr represents a key largest than all keys in the DB.\n // REQUIRES: If disjoint_sorted_files, files[] contains disjoint ranges\n //           in sorted order.\n-extern bool SomeFileOverlapsRange(\n-    const InternalKeyComparator& icmp,\n-    bool disjoint_sorted_files,\n-    const std::vector<FileMetaData*>& files,\n-    const Slice* smallest_user_key,\n-    const Slice* largest_user_key);\n+bool SomeFileOverlapsRange(const InternalKeyComparator& icmp,\n+                           bool disjoint_sorted_files,\n+                           const std::vector<FileMetaData*>& files,\n+                           const Slice* smallest_user_key,\n+                           const Slice* largest_user_key);\n \n class Version {\n  public:\n-  // Append to *iters a sequence of iterators that will\n-  // yield the contents of this Version when merged together.\n-  // REQUIRES: This version has been saved (see VersionSet::SaveTo)\n-  void AddIterators(const ReadOptions&, std::vector<Iterator*>* iters);\n-\n   // Lookup the value for key.  If found, store it in *val and\n   // return OK.  Else return a non-OK status.  Fills *stats.\n   // REQUIRES: lock is not held\n   struct GetStats {\n     FileMetaData* seek_file;\n     int seek_file_level;\n   };\n+\n+  // Append to *iters a sequence of iterators that will\n+  // yield the contents of this Version when merged together.\n+  // REQUIRES: This version has been saved (see VersionSet::SaveTo)\n+  void AddIterators(const ReadOptions&, std::vector<Iterator*>* iters);\n+\n   Status Get(const ReadOptions&, const LookupKey& key, std::string* val,\n              GetStats* stats);\n \n@@ -91,16 +93,15 @@ class Version {\n \n   void GetOverlappingInputs(\n       int level,\n-      const InternalKey* begin,         // NULL means before all keys\n-      const InternalKey* end,           // NULL means after all keys\n+      const InternalKey* begin,  // nullptr means before all keys\n+      const InternalKey* end,    // nullptr means after all keys\n       std::vector<FileMetaData*>* inputs);\n \n   // Returns true iff some file in the specified level overlaps\n   // some part of [*smallest_user_key,*largest_user_key].\n-  // smallest_user_key==NULL represents a key smaller than all keys in the DB.\n-  // largest_user_key==NULL represents a key largest than all keys in the DB.\n-  bool OverlapInLevel(int level,\n-                      const Slice* smallest_user_key,\n+  // smallest_user_key==nullptr represents a key smaller than all the DB's keys.\n+  // largest_user_key==nullptr represents a key largest than all the DB's keys.\n+  bool OverlapInLevel(int level, const Slice* smallest_user_key,\n                       const Slice* largest_user_key);\n \n   // Return the level at which we should place a new memtable compaction\n@@ -118,21 +119,36 @@ class Version {\n   friend class VersionSet;\n \n   class LevelFileNumIterator;\n+\n+  explicit Version(VersionSet* vset)\n+      : vset_(vset),\n+        next_(this),\n+        prev_(this),\n+        refs_(0),\n+        file_to_compact_(nullptr),\n+        file_to_compact_level_(-1),\n+        compaction_score_(-1),\n+        compaction_level_(-1) {}\n+\n+  Version(const Version&) = delete;\n+  Version& operator=(const Version&) = delete;\n+\n+  ~Version();\n+\n   Iterator* NewConcatenatingIterator(const ReadOptions&, int level) const;\n \n   // Call func(arg, level, f) for every file that overlaps user_key in\n   // order from newest to oldest.  If an invocation of func returns\n   // false, makes no more calls.\n   //\n   // REQUIRES: user portion of internal_key == user_key.\n-  void ForEachOverlapping(Slice user_key, Slice internal_key,\n-                          void* arg,\n+  void ForEachOverlapping(Slice user_key, Slice internal_key, void* arg,\n                           bool (*func)(void*, int, FileMetaData*));\n \n-  VersionSet* vset_;            // VersionSet to which this Version belongs\n-  Version* next_;               // Next version in linked list\n-  Version* prev_;               // Previous version in linked list\n-  int refs_;                    // Number of live refs to this version\n+  VersionSet* vset_;  // VersionSet to which this Version belongs\n+  Version* next_;     // Next version in linked list\n+  Version* prev_;     // Previous version in linked list\n+  int refs_;          // Number of live refs to this version\n \n   // List of files per level\n   std::vector<FileMetaData*> files_[config::kNumLevels];\n@@ -146,28 +162,15 @@ class Version {\n   // are initialized by Finalize().\n   double compaction_score_;\n   int compaction_level_;\n-\n-  explicit Version(VersionSet* vset)\n-      : vset_(vset), next_(this), prev_(this), refs_(0),\n-        file_to_compact_(NULL),\n-        file_to_compact_level_(-1),\n-        compaction_score_(-1),\n-        compaction_level_(-1) {\n-  }\n-\n-  ~Version();\n-\n-  // No copying allowed\n-  Version(const Version&);\n-  void operator=(const Version&);\n };\n \n class VersionSet {\n  public:\n-  VersionSet(const std::string& dbname,\n-             const Options* options,\n-             TableCache* table_cache,\n-             const InternalKeyComparator*);\n+  VersionSet(const std::string& dbname, const Options* options,\n+             TableCache* table_cache, const InternalKeyComparator*);\n+  VersionSet(const VersionSet&) = delete;\n+  VersionSet& operator=(const VersionSet&) = delete;\n+\n   ~VersionSet();\n \n   // Apply *edit to the current version to form a new descriptor that\n@@ -179,7 +182,7 @@ class VersionSet {\n       EXCLUSIVE_LOCKS_REQUIRED(mu);\n \n   // Recover the last saved descriptor from persistent storage.\n-  Status Recover(bool *save_manifest);\n+  Status Recover(bool* save_manifest);\n \n   // Return the current version.\n   Version* current() const { return current_; }\n@@ -225,19 +228,17 @@ class VersionSet {\n   uint64_t PrevLogNumber() const { return prev_log_number_; }\n \n   // Pick level and inputs for a new compaction.\n-  // Returns NULL if there is no compaction to be done.\n+  // Returns nullptr if there is no compaction to be done.\n   // Otherwise returns a pointer to a heap-allocated object that\n   // describes the compaction.  Caller should delete the result.\n   Compaction* PickCompaction();\n \n   // Return a compaction object for compacting the range [begin,end] in\n-  // the specified level.  Returns NULL if there is nothing in that\n+  // the specified level.  Returns nullptr if there is nothing in that\n   // level that overlaps the specified range.  Caller should delete\n   // the result.\n-  Compaction* CompactRange(\n-      int level,\n-      const InternalKey* begin,\n-      const InternalKey* end);\n+  Compaction* CompactRange(int level, const InternalKey* begin,\n+                           const InternalKey* end);\n \n   // Return the maximum overlapping data (in bytes) at next level for any\n   // file at a level >= 1.\n@@ -250,7 +251,7 @@ class VersionSet {\n   // Returns true iff some level needs a compaction.\n   bool NeedsCompaction() const {\n     Version* v = current_;\n-    return (v->compaction_score_ >= 1) || (v->file_to_compact_ != NULL);\n+    return (v->compaction_score_ >= 1) || (v->file_to_compact_ != nullptr);\n   }\n \n   // Add all files listed in any live version to *live.\n@@ -278,14 +279,12 @@ class VersionSet {\n \n   void Finalize(Version* v);\n \n-  void GetRange(const std::vector<FileMetaData*>& inputs,\n-                InternalKey* smallest,\n+  void GetRange(const std::vector<FileMetaData*>& inputs, InternalKey* smallest,\n                 InternalKey* largest);\n \n   void GetRange2(const std::vector<FileMetaData*>& inputs1,\n                  const std::vector<FileMetaData*>& inputs2,\n-                 InternalKey* smallest,\n-                 InternalKey* largest);\n+                 InternalKey* smallest, InternalKey* largest);\n \n   void SetupOtherInputs(Compaction* c);\n \n@@ -314,10 +313,6 @@ class VersionSet {\n   // Per-level key at which the next compaction at that level should start.\n   // Either an empty string, or a valid InternalKey.\n   std::string compact_pointer_[config::kNumLevels];\n-\n-  // No copying allowed\n-  VersionSet(const VersionSet&);\n-  void operator=(const VersionSet&);\n };\n \n // A Compaction encapsulates information about a compaction.\n@@ -374,7 +369,7 @@ class Compaction {\n   VersionEdit edit_;\n \n   // Each compaction reads inputs from \"level_\" and \"level_+1\"\n-  std::vector<FileMetaData*> inputs_[2];      // The two sets of inputs\n+  std::vector<FileMetaData*> inputs_[2];  // The two sets of inputs\n \n   // State used to check for number of overlapping grandparent files\n   // (parent == level_ + 1, grandparent == level_ + 2)"
      },
      {
        "sha": "c1056a1e7de40960afb5d58861d2145790865b8a",
        "filename": "db/version_set_test.cc",
        "status": "modified",
        "additions": 198,
        "deletions": 45,
        "changes": 243,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/version_set_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/version_set_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/version_set_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -11,10 +11,7 @@ namespace leveldb {\n \n class FindFileTest {\n  public:\n-  std::vector<FileMetaData*> files_;\n-  bool disjoint_sorted_files_;\n-\n-  FindFileTest() : disjoint_sorted_files_(true) { }\n+  FindFileTest() : disjoint_sorted_files_(true) {}\n \n   ~FindFileTest() {\n     for (int i = 0; i < files_.size(); i++) {\n@@ -40,20 +37,25 @@ class FindFileTest {\n \n   bool Overlaps(const char* smallest, const char* largest) {\n     InternalKeyComparator cmp(BytewiseComparator());\n-    Slice s(smallest != NULL ? smallest : \"\");\n-    Slice l(largest != NULL ? largest : \"\");\n+    Slice s(smallest != nullptr ? smallest : \"\");\n+    Slice l(largest != nullptr ? largest : \"\");\n     return SomeFileOverlapsRange(cmp, disjoint_sorted_files_, files_,\n-                                 (smallest != NULL ? &s : NULL),\n-                                 (largest != NULL ? &l : NULL));\n+                                 (smallest != nullptr ? &s : nullptr),\n+                                 (largest != nullptr ? &l : nullptr));\n   }\n+\n+  bool disjoint_sorted_files_;\n+\n+ private:\n+  std::vector<FileMetaData*> files_;\n };\n \n TEST(FindFileTest, Empty) {\n   ASSERT_EQ(0, Find(\"foo\"));\n-  ASSERT_TRUE(! Overlaps(\"a\", \"z\"));\n-  ASSERT_TRUE(! Overlaps(NULL, \"z\"));\n-  ASSERT_TRUE(! Overlaps(\"a\", NULL));\n-  ASSERT_TRUE(! Overlaps(NULL, NULL));\n+  ASSERT_TRUE(!Overlaps(\"a\", \"z\"));\n+  ASSERT_TRUE(!Overlaps(nullptr, \"z\"));\n+  ASSERT_TRUE(!Overlaps(\"a\", nullptr));\n+  ASSERT_TRUE(!Overlaps(nullptr, nullptr));\n }\n \n TEST(FindFileTest, Single) {\n@@ -65,8 +67,8 @@ TEST(FindFileTest, Single) {\n   ASSERT_EQ(1, Find(\"q1\"));\n   ASSERT_EQ(1, Find(\"z\"));\n \n-  ASSERT_TRUE(! Overlaps(\"a\", \"b\"));\n-  ASSERT_TRUE(! Overlaps(\"z1\", \"z2\"));\n+  ASSERT_TRUE(!Overlaps(\"a\", \"b\"));\n+  ASSERT_TRUE(!Overlaps(\"z1\", \"z2\"));\n   ASSERT_TRUE(Overlaps(\"a\", \"p\"));\n   ASSERT_TRUE(Overlaps(\"a\", \"q\"));\n   ASSERT_TRUE(Overlaps(\"a\", \"z\"));\n@@ -78,15 +80,14 @@ TEST(FindFileTest, Single) {\n   ASSERT_TRUE(Overlaps(\"q\", \"q\"));\n   ASSERT_TRUE(Overlaps(\"q\", \"q1\"));\n \n-  ASSERT_TRUE(! Overlaps(NULL, \"j\"));\n-  ASSERT_TRUE(! Overlaps(\"r\", NULL));\n-  ASSERT_TRUE(Overlaps(NULL, \"p\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"p1\"));\n-  ASSERT_TRUE(Overlaps(\"q\", NULL));\n-  ASSERT_TRUE(Overlaps(NULL, NULL));\n+  ASSERT_TRUE(!Overlaps(nullptr, \"j\"));\n+  ASSERT_TRUE(!Overlaps(\"r\", nullptr));\n+  ASSERT_TRUE(Overlaps(nullptr, \"p\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"p1\"));\n+  ASSERT_TRUE(Overlaps(\"q\", nullptr));\n+  ASSERT_TRUE(Overlaps(nullptr, nullptr));\n }\n \n-\n TEST(FindFileTest, Multiple) {\n   Add(\"150\", \"200\");\n   Add(\"200\", \"250\");\n@@ -110,10 +111,10 @@ TEST(FindFileTest, Multiple) {\n   ASSERT_EQ(3, Find(\"450\"));\n   ASSERT_EQ(4, Find(\"451\"));\n \n-  ASSERT_TRUE(! Overlaps(\"100\", \"149\"));\n-  ASSERT_TRUE(! Overlaps(\"251\", \"299\"));\n-  ASSERT_TRUE(! Overlaps(\"451\", \"500\"));\n-  ASSERT_TRUE(! Overlaps(\"351\", \"399\"));\n+  ASSERT_TRUE(!Overlaps(\"100\", \"149\"));\n+  ASSERT_TRUE(!Overlaps(\"251\", \"299\"));\n+  ASSERT_TRUE(!Overlaps(\"451\", \"500\"));\n+  ASSERT_TRUE(!Overlaps(\"351\", \"399\"));\n \n   ASSERT_TRUE(Overlaps(\"100\", \"150\"));\n   ASSERT_TRUE(Overlaps(\"100\", \"200\"));\n@@ -130,25 +131,25 @@ TEST(FindFileTest, MultipleNullBoundaries) {\n   Add(\"200\", \"250\");\n   Add(\"300\", \"350\");\n   Add(\"400\", \"450\");\n-  ASSERT_TRUE(! Overlaps(NULL, \"149\"));\n-  ASSERT_TRUE(! Overlaps(\"451\", NULL));\n-  ASSERT_TRUE(Overlaps(NULL, NULL));\n-  ASSERT_TRUE(Overlaps(NULL, \"150\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"199\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"200\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"201\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"400\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"800\"));\n-  ASSERT_TRUE(Overlaps(\"100\", NULL));\n-  ASSERT_TRUE(Overlaps(\"200\", NULL));\n-  ASSERT_TRUE(Overlaps(\"449\", NULL));\n-  ASSERT_TRUE(Overlaps(\"450\", NULL));\n+  ASSERT_TRUE(!Overlaps(nullptr, \"149\"));\n+  ASSERT_TRUE(!Overlaps(\"451\", nullptr));\n+  ASSERT_TRUE(Overlaps(nullptr, nullptr));\n+  ASSERT_TRUE(Overlaps(nullptr, \"150\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"199\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"200\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"201\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"400\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"800\"));\n+  ASSERT_TRUE(Overlaps(\"100\", nullptr));\n+  ASSERT_TRUE(Overlaps(\"200\", nullptr));\n+  ASSERT_TRUE(Overlaps(\"449\", nullptr));\n+  ASSERT_TRUE(Overlaps(\"450\", nullptr));\n }\n \n TEST(FindFileTest, OverlapSequenceChecks) {\n   Add(\"200\", \"200\", 5000, 3000);\n-  ASSERT_TRUE(! Overlaps(\"199\", \"199\"));\n-  ASSERT_TRUE(! Overlaps(\"201\", \"300\"));\n+  ASSERT_TRUE(!Overlaps(\"199\", \"199\"));\n+  ASSERT_TRUE(!Overlaps(\"201\", \"300\"));\n   ASSERT_TRUE(Overlaps(\"200\", \"200\"));\n   ASSERT_TRUE(Overlaps(\"190\", \"200\"));\n   ASSERT_TRUE(Overlaps(\"200\", \"210\"));\n@@ -158,8 +159,8 @@ TEST(FindFileTest, OverlappingFiles) {\n   Add(\"150\", \"600\");\n   Add(\"400\", \"500\");\n   disjoint_sorted_files_ = false;\n-  ASSERT_TRUE(! Overlaps(\"100\", \"149\"));\n-  ASSERT_TRUE(! Overlaps(\"601\", \"700\"));\n+  ASSERT_TRUE(!Overlaps(\"100\", \"149\"));\n+  ASSERT_TRUE(!Overlaps(\"601\", \"700\"));\n   ASSERT_TRUE(Overlaps(\"100\", \"150\"));\n   ASSERT_TRUE(Overlaps(\"100\", \"200\"));\n   ASSERT_TRUE(Overlaps(\"100\", \"300\"));\n@@ -172,8 +173,160 @@ TEST(FindFileTest, OverlappingFiles) {\n   ASSERT_TRUE(Overlaps(\"600\", \"700\"));\n }\n \n-}  // namespace leveldb\n+void AddBoundaryInputs(const InternalKeyComparator& icmp,\n+                       const std::vector<FileMetaData*>& level_files,\n+                       std::vector<FileMetaData*>* compaction_files);\n+\n+class AddBoundaryInputsTest {\n+ public:\n+  std::vector<FileMetaData*> level_files_;\n+  std::vector<FileMetaData*> compaction_files_;\n+  std::vector<FileMetaData*> all_files_;\n+  InternalKeyComparator icmp_;\n+\n+  AddBoundaryInputsTest() : icmp_(BytewiseComparator()) {}\n+\n+  ~AddBoundaryInputsTest() {\n+    for (size_t i = 0; i < all_files_.size(); ++i) {\n+      delete all_files_[i];\n+    }\n+    all_files_.clear();\n+  }\n+\n+  FileMetaData* CreateFileMetaData(uint64_t number, InternalKey smallest,\n+                                   InternalKey largest) {\n+    FileMetaData* f = new FileMetaData();\n+    f->number = number;\n+    f->smallest = smallest;\n+    f->largest = largest;\n+    all_files_.push_back(f);\n+    return f;\n+  }\n+};\n+\n+TEST(AddBoundaryInputsTest, TestEmptyFileSets) {\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_TRUE(compaction_files_.empty());\n+  ASSERT_TRUE(level_files_.empty());\n+}\n+\n+TEST(AddBoundaryInputsTest, TestEmptyLevelFiles) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 1, kTypeValue)));\n+  compaction_files_.push_back(f1);\n+\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_EQ(1, compaction_files_.size());\n+  ASSERT_EQ(f1, compaction_files_[0]);\n+  ASSERT_TRUE(level_files_.empty());\n+}\n+\n+TEST(AddBoundaryInputsTest, TestEmptyCompactionFiles) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 1, kTypeValue)));\n+  level_files_.push_back(f1);\n+\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_TRUE(compaction_files_.empty());\n+  ASSERT_EQ(1, level_files_.size());\n+  ASSERT_EQ(f1, level_files_[0]);\n+}\n+\n+TEST(AddBoundaryInputsTest, TestNoBoundaryFiles) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 1, kTypeValue)));\n+  FileMetaData* f2 =\n+      CreateFileMetaData(1, InternalKey(\"200\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"200\", 1, kTypeValue)));\n+  FileMetaData* f3 =\n+      CreateFileMetaData(1, InternalKey(\"300\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"300\", 1, kTypeValue)));\n+\n+  level_files_.push_back(f3);\n+  level_files_.push_back(f2);\n+  level_files_.push_back(f1);\n+  compaction_files_.push_back(f2);\n+  compaction_files_.push_back(f3);\n+\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_EQ(2, compaction_files_.size());\n+}\n+\n+TEST(AddBoundaryInputsTest, TestOneBoundaryFiles) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 3, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 2, kTypeValue)));\n+  FileMetaData* f2 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 1, kTypeValue),\n+                         InternalKey(InternalKey(\"200\", 3, kTypeValue)));\n+  FileMetaData* f3 =\n+      CreateFileMetaData(1, InternalKey(\"300\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"300\", 1, kTypeValue)));\n+\n+  level_files_.push_back(f3);\n+  level_files_.push_back(f2);\n+  level_files_.push_back(f1);\n+  compaction_files_.push_back(f1);\n+\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_EQ(2, compaction_files_.size());\n+  ASSERT_EQ(f1, compaction_files_[0]);\n+  ASSERT_EQ(f2, compaction_files_[1]);\n+}\n+\n+TEST(AddBoundaryInputsTest, TestTwoBoundaryFiles) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 6, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 5, kTypeValue)));\n+  FileMetaData* f2 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"300\", 1, kTypeValue)));\n+  FileMetaData* f3 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 4, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 3, kTypeValue)));\n+\n+  level_files_.push_back(f2);\n+  level_files_.push_back(f3);\n+  level_files_.push_back(f1);\n+  compaction_files_.push_back(f1);\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_EQ(3, compaction_files_.size());\n+  ASSERT_EQ(f1, compaction_files_[0]);\n+  ASSERT_EQ(f3, compaction_files_[1]);\n+  ASSERT_EQ(f2, compaction_files_[2]);\n }\n+\n+TEST(AddBoundaryInputsTest, TestDisjoinFilePointers) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 6, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 5, kTypeValue)));\n+  FileMetaData* f2 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 6, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 5, kTypeValue)));\n+  FileMetaData* f3 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"300\", 1, kTypeValue)));\n+  FileMetaData* f4 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 4, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 3, kTypeValue)));\n+\n+  level_files_.push_back(f2);\n+  level_files_.push_back(f3);\n+  level_files_.push_back(f4);\n+\n+  compaction_files_.push_back(f1);\n+\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_EQ(3, compaction_files_.size());\n+  ASSERT_EQ(f1, compaction_files_[0]);\n+  ASSERT_EQ(f4, compaction_files_[1]);\n+  ASSERT_EQ(f3, compaction_files_[2]);\n+}\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "b54313c35e9370e49e53e07349d6475d680c3cfe",
        "filename": "db/write_batch.cc",
        "status": "modified",
        "additions": 13,
        "deletions": 10,
        "changes": 23,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/write_batch.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/write_batch.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/write_batch.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -15,30 +15,30 @@\n \n #include \"leveldb/write_batch.h\"\n \n-#include \"leveldb/db.h\"\n #include \"db/dbformat.h\"\n #include \"db/memtable.h\"\n #include \"db/write_batch_internal.h\"\n+#include \"leveldb/db.h\"\n #include \"util/coding.h\"\n \n namespace leveldb {\n \n // WriteBatch header has an 8-byte sequence number followed by a 4-byte count.\n static const size_t kHeader = 12;\n \n-WriteBatch::WriteBatch() {\n-  Clear();\n-}\n+WriteBatch::WriteBatch() { Clear(); }\n \n-WriteBatch::~WriteBatch() { }\n+WriteBatch::~WriteBatch() = default;\n \n-WriteBatch::Handler::~Handler() { }\n+WriteBatch::Handler::~Handler() = default;\n \n void WriteBatch::Clear() {\n   rep_.clear();\n   rep_.resize(kHeader);\n }\n \n+size_t WriteBatch::ApproximateSize() const { return rep_.size(); }\n+\n Status WriteBatch::Iterate(Handler* handler) const {\n   Slice input(rep_);\n   if (input.size() < kHeader) {\n@@ -108,25 +108,28 @@ void WriteBatch::Delete(const Slice& key) {\n   PutLengthPrefixedSlice(&rep_, key);\n }\n \n+void WriteBatch::Append(const WriteBatch& source) {\n+  WriteBatchInternal::Append(this, &source);\n+}\n+\n namespace {\n class MemTableInserter : public WriteBatch::Handler {\n  public:\n   SequenceNumber sequence_;\n   MemTable* mem_;\n \n-  virtual void Put(const Slice& key, const Slice& value) {\n+  void Put(const Slice& key, const Slice& value) override {\n     mem_->Add(sequence_, kTypeValue, key, value);\n     sequence_++;\n   }\n-  virtual void Delete(const Slice& key) {\n+  void Delete(const Slice& key) override {\n     mem_->Add(sequence_, kTypeDeletion, key, Slice());\n     sequence_++;\n   }\n };\n }  // namespace\n \n-Status WriteBatchInternal::InsertInto(const WriteBatch* b,\n-                                      MemTable* memtable) {\n+Status WriteBatchInternal::InsertInto(const WriteBatch* b, MemTable* memtable) {\n   MemTableInserter inserter;\n   inserter.sequence_ = WriteBatchInternal::Sequence(b);\n   inserter.mem_ = memtable;"
      },
      {
        "sha": "fce86e3f1f192cb9b30703a669f650aacb0ebd32",
        "filename": "db/write_batch_internal.h",
        "status": "modified",
        "additions": 2,
        "deletions": 7,
        "changes": 9,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/write_batch_internal.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/write_batch_internal.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/write_batch_internal.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -29,13 +29,9 @@ class WriteBatchInternal {\n   // this batch.\n   static void SetSequence(WriteBatch* batch, SequenceNumber seq);\n \n-  static Slice Contents(const WriteBatch* batch) {\n-    return Slice(batch->rep_);\n-  }\n+  static Slice Contents(const WriteBatch* batch) { return Slice(batch->rep_); }\n \n-  static size_t ByteSize(const WriteBatch* batch) {\n-    return batch->rep_.size();\n-  }\n+  static size_t ByteSize(const WriteBatch* batch) { return batch->rep_.size(); }\n \n   static void SetContents(WriteBatch* batch, const Slice& contents);\n \n@@ -46,5 +42,4 @@ class WriteBatchInternal {\n \n }  // namespace leveldb\n \n-\n #endif  // STORAGE_LEVELDB_DB_WRITE_BATCH_INTERNAL_H_"
      },
      {
        "sha": "c32317fb5e80a8f6813e5663a5916cbccaca2c51",
        "filename": "db/write_batch_test.cc",
        "status": "modified",
        "additions": 45,
        "deletions": 28,
        "changes": 73,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/db/write_batch_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/db/write_batch_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/db/write_batch_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -52,7 +52,7 @@ static std::string PrintContents(WriteBatch* b) {\n   return state;\n }\n \n-class WriteBatchTest { };\n+class WriteBatchTest {};\n \n TEST(WriteBatchTest, Empty) {\n   WriteBatch batch;\n@@ -68,10 +68,11 @@ TEST(WriteBatchTest, Multiple) {\n   WriteBatchInternal::SetSequence(&batch, 100);\n   ASSERT_EQ(100, WriteBatchInternal::Sequence(&batch));\n   ASSERT_EQ(3, WriteBatchInternal::Count(&batch));\n-  ASSERT_EQ(\"Put(baz, boo)@102\"\n-            \"Delete(box)@101\"\n-            \"Put(foo, bar)@100\",\n-            PrintContents(&batch));\n+  ASSERT_EQ(\n+      \"Put(baz, boo)@102\"\n+      \"Delete(box)@101\"\n+      \"Put(foo, bar)@100\",\n+      PrintContents(&batch));\n }\n \n TEST(WriteBatchTest, Corruption) {\n@@ -81,40 +82,56 @@ TEST(WriteBatchTest, Corruption) {\n   WriteBatchInternal::SetSequence(&batch, 200);\n   Slice contents = WriteBatchInternal::Contents(&batch);\n   WriteBatchInternal::SetContents(&batch,\n-                                  Slice(contents.data(),contents.size()-1));\n-  ASSERT_EQ(\"Put(foo, bar)@200\"\n-            \"ParseError()\",\n-            PrintContents(&batch));\n+                                  Slice(contents.data(), contents.size() - 1));\n+  ASSERT_EQ(\n+      \"Put(foo, bar)@200\"\n+      \"ParseError()\",\n+      PrintContents(&batch));\n }\n \n TEST(WriteBatchTest, Append) {\n   WriteBatch b1, b2;\n   WriteBatchInternal::SetSequence(&b1, 200);\n   WriteBatchInternal::SetSequence(&b2, 300);\n-  WriteBatchInternal::Append(&b1, &b2);\n-  ASSERT_EQ(\"\",\n-            PrintContents(&b1));\n+  b1.Append(b2);\n+  ASSERT_EQ(\"\", PrintContents(&b1));\n   b2.Put(\"a\", \"va\");\n-  WriteBatchInternal::Append(&b1, &b2);\n-  ASSERT_EQ(\"Put(a, va)@200\",\n-            PrintContents(&b1));\n+  b1.Append(b2);\n+  ASSERT_EQ(\"Put(a, va)@200\", PrintContents(&b1));\n   b2.Clear();\n   b2.Put(\"b\", \"vb\");\n-  WriteBatchInternal::Append(&b1, &b2);\n-  ASSERT_EQ(\"Put(a, va)@200\"\n-            \"Put(b, vb)@201\",\n-            PrintContents(&b1));\n+  b1.Append(b2);\n+  ASSERT_EQ(\n+      \"Put(a, va)@200\"\n+      \"Put(b, vb)@201\",\n+      PrintContents(&b1));\n   b2.Delete(\"foo\");\n-  WriteBatchInternal::Append(&b1, &b2);\n-  ASSERT_EQ(\"Put(a, va)@200\"\n-            \"Put(b, vb)@202\"\n-            \"Put(b, vb)@201\"\n-            \"Delete(foo)@203\",\n-            PrintContents(&b1));\n+  b1.Append(b2);\n+  ASSERT_EQ(\n+      \"Put(a, va)@200\"\n+      \"Put(b, vb)@202\"\n+      \"Put(b, vb)@201\"\n+      \"Delete(foo)@203\",\n+      PrintContents(&b1));\n }\n \n-}  // namespace leveldb\n+TEST(WriteBatchTest, ApproximateSize) {\n+  WriteBatch batch;\n+  size_t empty_size = batch.ApproximateSize();\n+\n+  batch.Put(Slice(\"foo\"), Slice(\"bar\"));\n+  size_t one_key_size = batch.ApproximateSize();\n+  ASSERT_LT(empty_size, one_key_size);\n+\n+  batch.Put(Slice(\"baz\"), Slice(\"boo\"));\n+  size_t two_keys_size = batch.ApproximateSize();\n+  ASSERT_LT(one_key_size, two_keys_size);\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n+  batch.Delete(Slice(\"box\"));\n+  size_t post_delete_size = batch.ApproximateSize();\n+  ASSERT_LT(two_keys_size, post_delete_size);\n }\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "f3fd77144c35258e8c55d0ef939b4def424ae989",
        "filename": "doc/benchmark.html",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/doc/benchmark.html",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/doc/benchmark.html",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/benchmark.html?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -90,9 +90,9 @@ <h1>LevelDB Benchmarks</h1>\n <h4>Benchmark Source Code</h4>\n <p>We wrote benchmark tools for SQLite and Kyoto TreeDB based on LevelDB's <span class=\"code\">db_bench</span>. The code for each of the benchmarks resides here:</p>\n <ul>\n-\t<li> <b>LevelDB:</b> <a href=\"http://code.google.com/p/leveldb/source/browse/trunk/db/db_bench.cc\">db/db_bench.cc</a>.</li>\n-\t<li> <b>SQLite:</b> <a href=\"http://code.google.com/p/leveldb/source/browse/#svn%2Ftrunk%2Fdoc%2Fbench%2Fdb_bench_sqlite3.cc\">doc/bench/db_bench_sqlite3.cc</a>.</li>\n-\t<li> <b>Kyoto TreeDB:</b> <a href=\"http://code.google.com/p/leveldb/source/browse/#svn%2Ftrunk%2Fdoc%2Fbench%2Fdb_bench_tree_db.cc\">doc/bench/db_bench_tree_db.cc</a>.</li>\n+\t<li> <b>LevelDB:</b> <a href=\"https://github.com/google/leveldb/blob/master/benchmarks/db_bench.cc\">benchmarks/db_bench.cc</a>.</li>\n+\t<li> <b>SQLite:</b> <a href=\"https://github.com/google/leveldb/blob/master/benchmarks/db_bench_sqlite3.cc\">benchmarks/db_bench_sqlite3.cc</a>.</li>\n+\t<li> <b>Kyoto TreeDB:</b> <a href=\"https://github.com/google/leveldb/blob/master/benchmarks/db_bench_tree_db.cc\">benchmarks/db_bench_tree_db.cc</a>.</li>\n </ul>\n \n <h4>Custom Build Specifications</h4>"
      },
      {
        "sha": "cacabb96fc70e63b845b50bf85219254d8142288",
        "filename": "doc/impl.md",
        "status": "modified",
        "additions": 8,
        "deletions": 6,
        "changes": 14,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/doc/impl.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/doc/impl.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/impl.md?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -64,13 +64,15 @@ Other files used for miscellaneous purposes may also be present (LOCK, *.dbtmp).\n \n ## Level 0\n \n-When the log file grows above a certain size (1MB by default):\n-Create a brand new memtable and log file and direct future updates here\n+When the log file grows above a certain size (4MB by default):\n+Create a brand new memtable and log file and direct future updates here.\n+\n In the background:\n-Write the contents of the previous memtable to an sstable\n-Discard the memtable\n-Delete the old log file and the old memtable\n-Add the new sstable to the young (level-0) level.\n+\n+1. Write the contents of the previous memtable to an sstable.\n+2. Discard the memtable.\n+3. Delete the old log file and the old memtable.\n+4. Add the new sstable to the young (level-0) level.\n \n ## Compactions\n "
      },
      {
        "sha": "3d9a25805b7bffae11648cd573fd4d3fa4ed0282",
        "filename": "doc/index.md",
        "status": "modified",
        "additions": 5,
        "deletions": 5,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/doc/index.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/doc/index.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/index.md?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -307,7 +307,7 @@ version numbers found in the keys to decide how to interpret them.\n ## Performance\n \n Performance can be tuned by changing the default values of the types defined in\n-`include/leveldb/options.h`.\n+`include/options.h`.\n \n ### Block size\n \n@@ -338,19 +338,19 @@ options.compression = leveldb::kNoCompression;\n ### Cache\n \n The contents of the database are stored in a set of files in the filesystem and\n-each file stores a sequence of compressed blocks. If options.cache is non-NULL,\n-it is used to cache frequently used uncompressed block contents.\n+each file stores a sequence of compressed blocks. If options.block_cache is\n+non-NULL, it is used to cache frequently used uncompressed block contents.\n \n ```c++\n #include \"leveldb/cache.h\"\n \n leveldb::Options options;\n-options.cache = leveldb::NewLRUCache(100 * 1048576);  // 100MB cache\n+options.block_cache = leveldb::NewLRUCache(100 * 1048576);  // 100MB cache\n leveldb::DB* db;\n leveldb::DB::Open(options, name, &db);\n ... use the db ...\n delete db\n-delete options.cache;\n+delete options.block_cache;\n ```\n \n Note that the cache holds uncompressed data, and therefore it should be sized"
      },
      {
        "sha": "47e4481f7c55ef33ce26c0ca9bf4f30c9f0ef629",
        "filename": "helpers/memenv/memenv.cc",
        "status": "modified",
        "additions": 98,
        "deletions": 105,
        "changes": 203,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/helpers/memenv/memenv.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/helpers/memenv/memenv.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/helpers/memenv/memenv.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -4,14 +4,18 @@\n \n #include \"helpers/memenv/memenv.h\"\n \n+#include <string.h>\n+\n+#include <limits>\n+#include <map>\n+#include <string>\n+#include <vector>\n+\n #include \"leveldb/env.h\"\n #include \"leveldb/status.h\"\n #include \"port/port.h\"\n+#include \"port/thread_annotations.h\"\n #include \"util/mutexlock.h\"\n-#include <map>\n-#include <string.h>\n-#include <string>\n-#include <vector>\n \n namespace leveldb {\n \n@@ -23,6 +27,10 @@ class FileState {\n   // and the caller must call Ref() at least once.\n   FileState() : refs_(0), size_(0) {}\n \n+  // No copying allowed.\n+  FileState(const FileState&) = delete;\n+  FileState& operator=(const FileState&) = delete;\n+\n   // Increase the reference count.\n   void Ref() {\n     MutexLock lock(&refs_mutex_);\n@@ -47,9 +55,22 @@ class FileState {\n     }\n   }\n \n-  uint64_t Size() const { return size_; }\n+  uint64_t Size() const {\n+    MutexLock lock(&blocks_mutex_);\n+    return size_;\n+  }\n+\n+  void Truncate() {\n+    MutexLock lock(&blocks_mutex_);\n+    for (char*& block : blocks_) {\n+      delete[] block;\n+    }\n+    blocks_.clear();\n+    size_ = 0;\n+  }\n \n   Status Read(uint64_t offset, size_t n, Slice* result, char* scratch) const {\n+    MutexLock lock(&blocks_mutex_);\n     if (offset > size_) {\n       return Status::IOError(\"Offset greater than file size.\");\n     }\n@@ -62,16 +83,9 @@ class FileState {\n       return Status::OK();\n     }\n \n-    assert(offset / kBlockSize <= SIZE_MAX);\n+    assert(offset / kBlockSize <= std::numeric_limits<size_t>::max());\n     size_t block = static_cast<size_t>(offset / kBlockSize);\n     size_t block_offset = offset % kBlockSize;\n-\n-    if (n <= kBlockSize - block_offset) {\n-      // The requested bytes are all in the first block.\n-      *result = Slice(blocks_[block] + block_offset, n);\n-      return Status::OK();\n-    }\n-\n     size_t bytes_to_copy = n;\n     char* dst = scratch;\n \n@@ -96,6 +110,7 @@ class FileState {\n     const char* src = data.data();\n     size_t src_len = data.size();\n \n+    MutexLock lock(&blocks_mutex_);\n     while (src_len > 0) {\n       size_t avail;\n       size_t offset = size_ % kBlockSize;\n@@ -122,28 +137,17 @@ class FileState {\n   }\n \n  private:\n-  // Private since only Unref() should be used to delete it.\n-  ~FileState() {\n-    for (std::vector<char*>::iterator i = blocks_.begin(); i != blocks_.end();\n-         ++i) {\n-      delete [] *i;\n-    }\n-  }\n+  enum { kBlockSize = 8 * 1024 };\n \n-  // No copying allowed.\n-  FileState(const FileState&);\n-  void operator=(const FileState&);\n+  // Private since only Unref() should be used to delete it.\n+  ~FileState() { Truncate(); }\n \n   port::Mutex refs_mutex_;\n-  int refs_;  // Protected by refs_mutex_;\n+  int refs_ GUARDED_BY(refs_mutex_);\n \n-  // The following fields are not protected by any mutex. They are only mutable\n-  // while the file is being written, and concurrent access is not allowed\n-  // to writable files.\n-  std::vector<char*> blocks_;\n-  uint64_t size_;\n-\n-  enum { kBlockSize = 8 * 1024 };\n+  mutable port::Mutex blocks_mutex_;\n+  std::vector<char*> blocks_ GUARDED_BY(blocks_mutex_);\n+  uint64_t size_ GUARDED_BY(blocks_mutex_);\n };\n \n class SequentialFileImpl : public SequentialFile {\n@@ -152,19 +156,17 @@ class SequentialFileImpl : public SequentialFile {\n     file_->Ref();\n   }\n \n-  ~SequentialFileImpl() {\n-    file_->Unref();\n-  }\n+  ~SequentialFileImpl() override { file_->Unref(); }\n \n-  virtual Status Read(size_t n, Slice* result, char* scratch) {\n+  Status Read(size_t n, Slice* result, char* scratch) override {\n     Status s = file_->Read(pos_, n, result, scratch);\n     if (s.ok()) {\n       pos_ += result->size();\n     }\n     return s;\n   }\n \n-  virtual Status Skip(uint64_t n) {\n+  Status Skip(uint64_t n) override {\n     if (pos_ > file_->Size()) {\n       return Status::IOError(\"pos_ > file_->Size()\");\n     }\n@@ -176,135 +178,130 @@ class SequentialFileImpl : public SequentialFile {\n     return Status::OK();\n   }\n \n-  virtual std::string GetName() const { return \"[memenv]\"; }\n+  virtual std::string GetName() const override { return \"[memenv]\"; }\n  private:\n   FileState* file_;\n   uint64_t pos_;\n };\n \n class RandomAccessFileImpl : public RandomAccessFile {\n  public:\n-  explicit RandomAccessFileImpl(FileState* file) : file_(file) {\n-    file_->Ref();\n-  }\n+  explicit RandomAccessFileImpl(FileState* file) : file_(file) { file_->Ref(); }\n \n-  ~RandomAccessFileImpl() {\n-    file_->Unref();\n-  }\n+  ~RandomAccessFileImpl() override { file_->Unref(); }\n \n-  virtual Status Read(uint64_t offset, size_t n, Slice* result,\n-                      char* scratch) const {\n+  Status Read(uint64_t offset, size_t n, Slice* result,\n+              char* scratch) const override {\n     return file_->Read(offset, n, result, scratch);\n   }\n \n-  virtual std::string GetName() const { return \"[memenv]\"; }\n+  virtual std::string GetName() const override { return \"[memenv]\"; }\n  private:\n   FileState* file_;\n };\n \n class WritableFileImpl : public WritableFile {\n  public:\n-  WritableFileImpl(FileState* file) : file_(file) {\n-    file_->Ref();\n-  }\n+  WritableFileImpl(FileState* file) : file_(file) { file_->Ref(); }\n \n-  ~WritableFileImpl() {\n-    file_->Unref();\n-  }\n+  ~WritableFileImpl() override { file_->Unref(); }\n \n-  virtual Status Append(const Slice& data) {\n-    return file_->Append(data);\n-  }\n+  Status Append(const Slice& data) override { return file_->Append(data); }\n \n-  virtual Status Close() { return Status::OK(); }\n-  virtual Status Flush() { return Status::OK(); }\n-  virtual Status Sync() { return Status::OK(); }\n+  Status Close() override { return Status::OK(); }\n+  Status Flush() override { return Status::OK(); }\n+  Status Sync() override { return Status::OK(); }\n \n-  virtual std::string GetName() const { return \"[memenv]\"; }\n+  virtual std::string GetName() const override { return \"[memenv]\"; }\n  private:\n   FileState* file_;\n };\n \n class NoOpLogger : public Logger {\n  public:\n-  virtual void Logv(const char* format, va_list ap) { }\n+  void Logv(const char* format, va_list ap) override {}\n };\n \n class InMemoryEnv : public EnvWrapper {\n  public:\n-  explicit InMemoryEnv(Env* base_env) : EnvWrapper(base_env) { }\n+  explicit InMemoryEnv(Env* base_env) : EnvWrapper(base_env) {}\n \n-  virtual ~InMemoryEnv() {\n-    for (FileSystem::iterator i = file_map_.begin(); i != file_map_.end(); ++i){\n-      i->second->Unref();\n+  ~InMemoryEnv() override {\n+    for (const auto& kvp : file_map_) {\n+      kvp.second->Unref();\n     }\n   }\n \n   // Partial implementation of the Env interface.\n-  virtual Status NewSequentialFile(const std::string& fname,\n-                                   SequentialFile** result) {\n+  Status NewSequentialFile(const std::string& fname,\n+                           SequentialFile** result) override {\n     MutexLock lock(&mutex_);\n     if (file_map_.find(fname) == file_map_.end()) {\n-      *result = NULL;\n+      *result = nullptr;\n       return Status::IOError(fname, \"File not found\");\n     }\n \n     *result = new SequentialFileImpl(file_map_[fname]);\n     return Status::OK();\n   }\n \n-  virtual Status NewRandomAccessFile(const std::string& fname,\n-                                     RandomAccessFile** result) {\n+  Status NewRandomAccessFile(const std::string& fname,\n+                             RandomAccessFile** result) override {\n     MutexLock lock(&mutex_);\n     if (file_map_.find(fname) == file_map_.end()) {\n-      *result = NULL;\n+      *result = nullptr;\n       return Status::IOError(fname, \"File not found\");\n     }\n \n     *result = new RandomAccessFileImpl(file_map_[fname]);\n     return Status::OK();\n   }\n \n-  virtual Status NewWritableFile(const std::string& fname,\n-                                 WritableFile** result) {\n+  Status NewWritableFile(const std::string& fname,\n+                         WritableFile** result) override {\n     MutexLock lock(&mutex_);\n-    if (file_map_.find(fname) != file_map_.end()) {\n-      DeleteFileInternal(fname);\n-    }\n+    FileSystem::iterator it = file_map_.find(fname);\n \n-    FileState* file = new FileState();\n-    file->Ref();\n-    file_map_[fname] = file;\n+    FileState* file;\n+    if (it == file_map_.end()) {\n+      // File is not currently open.\n+      file = new FileState();\n+      file->Ref();\n+      file_map_[fname] = file;\n+    } else {\n+      file = it->second;\n+      file->Truncate();\n+    }\n \n     *result = new WritableFileImpl(file);\n     return Status::OK();\n   }\n \n-  virtual Status NewAppendableFile(const std::string& fname,\n-                                   WritableFile** result) {\n+  Status NewAppendableFile(const std::string& fname,\n+                           WritableFile** result) override {\n     MutexLock lock(&mutex_);\n     FileState** sptr = &file_map_[fname];\n     FileState* file = *sptr;\n-    if (file == NULL) {\n+    if (file == nullptr) {\n       file = new FileState();\n       file->Ref();\n     }\n     *result = new WritableFileImpl(file);\n     return Status::OK();\n   }\n \n-  virtual bool FileExists(const std::string& fname) {\n+  bool FileExists(const std::string& fname) override {\n     MutexLock lock(&mutex_);\n     return file_map_.find(fname) != file_map_.end();\n   }\n \n-  virtual Status GetChildren(const std::string& dir,\n-                             std::vector<std::string>* result) {\n+  Status GetChildren(const std::string& dir,\n+                     std::vector<std::string>* result) override {\n     MutexLock lock(&mutex_);\n     result->clear();\n \n-    for (FileSystem::iterator i = file_map_.begin(); i != file_map_.end(); ++i){\n-      const std::string& filename = i->first;\n+    for (const auto& kvp : file_map_) {\n+      const std::string& filename = kvp.first;\n \n       if (filename.size() >= dir.size() + 1 && filename[dir.size()] == '/' &&\n           Slice(filename).starts_with(Slice(dir))) {\n@@ -315,7 +312,8 @@ class InMemoryEnv : public EnvWrapper {\n     return Status::OK();\n   }\n \n-  void DeleteFileInternal(const std::string& fname) {\n+  void DeleteFileInternal(const std::string& fname)\n+      EXCLUSIVE_LOCKS_REQUIRED(mutex_) {\n     if (file_map_.find(fname) == file_map_.end()) {\n       return;\n     }\n@@ -324,7 +322,7 @@ class InMemoryEnv : public EnvWrapper {\n     file_map_.erase(fname);\n   }\n \n-  virtual Status DeleteFile(const std::string& fname) {\n+  Status DeleteFile(const std::string& fname) override {\n     MutexLock lock(&mutex_);\n     if (file_map_.find(fname) == file_map_.end()) {\n       return Status::IOError(fname, \"File not found\");\n@@ -334,15 +332,11 @@ class InMemoryEnv : public EnvWrapper {\n     return Status::OK();\n   }\n \n-  virtual Status CreateDir(const std::string& dirname) {\n-    return Status::OK();\n-  }\n+  Status CreateDir(const std::string& dirname) override { return Status::OK(); }\n \n-  virtual Status DeleteDir(const std::string& dirname) {\n-    return Status::OK();\n-  }\n+  Status DeleteDir(const std::string& dirname) override { return Status::OK(); }\n \n-  virtual Status GetFileSize(const std::string& fname, uint64_t* file_size) {\n+  Status GetFileSize(const std::string& fname, uint64_t* file_size) override {\n     MutexLock lock(&mutex_);\n     if (file_map_.find(fname) == file_map_.end()) {\n       return Status::IOError(fname, \"File not found\");\n@@ -352,8 +346,8 @@ class InMemoryEnv : public EnvWrapper {\n     return Status::OK();\n   }\n \n-  virtual Status RenameFile(const std::string& src,\n-                            const std::string& target) {\n+  Status RenameFile(const std::string& src,\n+                    const std::string& target) override {\n     MutexLock lock(&mutex_);\n     if (file_map_.find(src) == file_map_.end()) {\n       return Status::IOError(src, \"File not found\");\n@@ -365,37 +359,36 @@ class InMemoryEnv : public EnvWrapper {\n     return Status::OK();\n   }\n \n-  virtual Status LockFile(const std::string& fname, FileLock** lock) {\n+  Status LockFile(const std::string& fname, FileLock** lock) override {\n     *lock = new FileLock;\n     return Status::OK();\n   }\n \n-  virtual Status UnlockFile(FileLock* lock) {\n+  Status UnlockFile(FileLock* lock) override {\n     delete lock;\n     return Status::OK();\n   }\n \n-  virtual Status GetTestDirectory(std::string* path) {\n+  Status GetTestDirectory(std::string* path) override {\n     *path = \"/test\";\n     return Status::OK();\n   }\n \n-  virtual Status NewLogger(const std::string& fname, Logger** result) {\n+  Status NewLogger(const std::string& fname, Logger** result) override {\n     *result = new NoOpLogger;\n     return Status::OK();\n   }\n \n  private:\n   // Map from filenames to FileState objects, representing a simple file system.\n   typedef std::map<std::string, FileState*> FileSystem;\n+\n   port::Mutex mutex_;\n-  FileSystem file_map_;  // Protected by mutex_.\n+  FileSystem file_map_ GUARDED_BY(mutex_);\n };\n \n }  // namespace\n \n-Env* NewMemEnv(Env* base_env) {\n-  return new InMemoryEnv(base_env);\n-}\n+Env* NewMemEnv(Env* base_env) { return new InMemoryEnv(base_env); }\n \n }  // namespace leveldb"
      },
      {
        "sha": "3d929e4c4e564d6d2d981328465b1e65fc2cea59",
        "filename": "helpers/memenv/memenv.h",
        "status": "modified",
        "additions": 3,
        "deletions": 1,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/helpers/memenv/memenv.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/helpers/memenv/memenv.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/helpers/memenv/memenv.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -5,6 +5,8 @@\n #ifndef STORAGE_LEVELDB_HELPERS_MEMENV_MEMENV_H_\n #define STORAGE_LEVELDB_HELPERS_MEMENV_MEMENV_H_\n \n+#include \"leveldb/export.h\"\n+\n namespace leveldb {\n \n class Env;\n@@ -13,7 +15,7 @@ class Env;\n // all non-file-storage tasks to base_env. The caller must delete the result\n // when it is no longer needed.\n // *base_env must remain live while the result is in use.\n-Env* NewMemEnv(Env* base_env);\n+LEVELDB_EXPORT Env* NewMemEnv(Env* base_env);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "94ad06be6817406f7f1624174931af442ee679f6",
        "filename": "helpers/memenv/memenv_test.cc",
        "status": "modified",
        "additions": 39,
        "deletions": 21,
        "changes": 60,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/helpers/memenv/memenv_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/helpers/memenv/memenv_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/helpers/memenv/memenv_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -4,25 +4,22 @@\n \n #include \"helpers/memenv/memenv.h\"\n \n+#include <string>\n+#include <vector>\n+\n #include \"db/db_impl.h\"\n #include \"leveldb/db.h\"\n #include \"leveldb/env.h\"\n #include \"util/testharness.h\"\n-#include <string>\n-#include <vector>\n \n namespace leveldb {\n \n class MemEnvTest {\n  public:\n-  Env* env_;\n+  MemEnvTest() : env_(NewMemEnv(Env::Default())) {}\n+  ~MemEnvTest() { delete env_; }\n \n-  MemEnvTest()\n-      : env_(NewMemEnv(Env::Default())) {\n-  }\n-  ~MemEnvTest() {\n-    delete env_;\n-  }\n+  Env* env_;\n };\n \n TEST(MemEnvTest, Basics) {\n@@ -109,25 +106,25 @@ TEST(MemEnvTest, ReadWrite) {\n \n   // Read sequentially.\n   ASSERT_OK(env_->NewSequentialFile(\"/dir/f\", &seq_file));\n-  ASSERT_OK(seq_file->Read(5, &result, scratch)); // Read \"hello\".\n+  ASSERT_OK(seq_file->Read(5, &result, scratch));  // Read \"hello\".\n   ASSERT_EQ(0, result.compare(\"hello\"));\n   ASSERT_OK(seq_file->Skip(1));\n-  ASSERT_OK(seq_file->Read(1000, &result, scratch)); // Read \"world\".\n+  ASSERT_OK(seq_file->Read(1000, &result, scratch));  // Read \"world\".\n   ASSERT_EQ(0, result.compare(\"world\"));\n-  ASSERT_OK(seq_file->Read(1000, &result, scratch)); // Try reading past EOF.\n+  ASSERT_OK(seq_file->Read(1000, &result, scratch));  // Try reading past EOF.\n   ASSERT_EQ(0, result.size());\n-  ASSERT_OK(seq_file->Skip(100)); // Try to skip past end of file.\n+  ASSERT_OK(seq_file->Skip(100));  // Try to skip past end of file.\n   ASSERT_OK(seq_file->Read(1000, &result, scratch));\n   ASSERT_EQ(0, result.size());\n   delete seq_file;\n \n   // Random reads.\n   ASSERT_OK(env_->NewRandomAccessFile(\"/dir/f\", &rand_file));\n-  ASSERT_OK(rand_file->Read(6, 5, &result, scratch)); // Read \"world\".\n+  ASSERT_OK(rand_file->Read(6, 5, &result, scratch));  // Read \"world\".\n   ASSERT_EQ(0, result.compare(\"world\"));\n-  ASSERT_OK(rand_file->Read(0, 5, &result, scratch)); // Read \"hello\".\n+  ASSERT_OK(rand_file->Read(0, 5, &result, scratch));  // Read \"hello\".\n   ASSERT_EQ(0, result.compare(\"hello\"));\n-  ASSERT_OK(rand_file->Read(10, 100, &result, scratch)); // Read \"d\".\n+  ASSERT_OK(rand_file->Read(10, 100, &result, scratch));  // Read \"d\".\n   ASSERT_EQ(0, result.compare(\"d\"));\n \n   // Too high offset.\n@@ -176,7 +173,7 @@ TEST(MemEnvTest, LargeWrite) {\n   SequentialFile* seq_file;\n   Slice result;\n   ASSERT_OK(env_->NewSequentialFile(\"/dir/f\", &seq_file));\n-  ASSERT_OK(seq_file->Read(3, &result, scratch)); // Read \"foo\".\n+  ASSERT_OK(seq_file->Read(3, &result, scratch));  // Read \"foo\".\n   ASSERT_EQ(0, result.compare(\"foo\"));\n \n   size_t read = 0;\n@@ -188,7 +185,30 @@ TEST(MemEnvTest, LargeWrite) {\n   }\n   ASSERT_TRUE(write_data == read_data);\n   delete seq_file;\n-  delete [] scratch;\n+  delete[] scratch;\n+}\n+\n+TEST(MemEnvTest, OverwriteOpenFile) {\n+  const char kWrite1Data[] = \"Write #1 data\";\n+  const size_t kFileDataLen = sizeof(kWrite1Data) - 1;\n+  const std::string kTestFileName = test::TmpDir() + \"/leveldb-TestFile.dat\";\n+\n+  ASSERT_OK(WriteStringToFile(env_, kWrite1Data, kTestFileName));\n+\n+  RandomAccessFile* rand_file;\n+  ASSERT_OK(env_->NewRandomAccessFile(kTestFileName, &rand_file));\n+\n+  const char kWrite2Data[] = \"Write #2 data\";\n+  ASSERT_OK(WriteStringToFile(env_, kWrite2Data, kTestFileName));\n+\n+  // Verify that overwriting an open file will result in the new file data\n+  // being read from files opened before the write.\n+  Slice result;\n+  char scratch[kFileDataLen];\n+  ASSERT_OK(rand_file->Read(0, kFileDataLen, &result, scratch));\n+  ASSERT_EQ(0, result.compare(kWrite2Data));\n+\n+  delete rand_file;\n }\n \n TEST(MemEnvTest, DBTest) {\n@@ -236,6 +256,4 @@ TEST(MemEnvTest, DBTest) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "02c79ba72e0919ddec530b936fb75f5fd98b4f15",
        "filename": "include/leveldb/c.h",
        "status": "modified",
        "additions": 150,
        "deletions": 170,
        "changes": 320,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/c.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/c.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/c.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -32,7 +32,7 @@\n   On failure, leveldb frees the old value of *errptr and\n   set *errptr to a malloc()ed error message.\n \n-  (4) Bools have the type unsigned char (0 == false; rest == true)\n+  (4) Bools have the type uint8_t (0 == false; rest == true)\n \n   (5) All of the pointer arguments must be non-NULL.\n */\n@@ -48,225 +48,205 @@ extern \"C\" {\n #include <stddef.h>\n #include <stdint.h>\n \n+#include \"leveldb/export.h\"\n+\n /* Exported types */\n \n-typedef struct leveldb_t               leveldb_t;\n-typedef struct leveldb_cache_t         leveldb_cache_t;\n-typedef struct leveldb_comparator_t    leveldb_comparator_t;\n-typedef struct leveldb_env_t           leveldb_env_t;\n-typedef struct leveldb_filelock_t      leveldb_filelock_t;\n-typedef struct leveldb_filterpolicy_t  leveldb_filterpolicy_t;\n-typedef struct leveldb_iterator_t      leveldb_iterator_t;\n-typedef struct leveldb_logger_t        leveldb_logger_t;\n-typedef struct leveldb_options_t       leveldb_options_t;\n-typedef struct leveldb_randomfile_t    leveldb_randomfile_t;\n-typedef struct leveldb_readoptions_t   leveldb_readoptions_t;\n-typedef struct leveldb_seqfile_t       leveldb_seqfile_t;\n-typedef struct leveldb_snapshot_t      leveldb_snapshot_t;\n-typedef struct leveldb_writablefile_t  leveldb_writablefile_t;\n-typedef struct leveldb_writebatch_t    leveldb_writebatch_t;\n-typedef struct leveldb_writeoptions_t  leveldb_writeoptions_t;\n+typedef struct leveldb_t leveldb_t;\n+typedef struct leveldb_cache_t leveldb_cache_t;\n+typedef struct leveldb_comparator_t leveldb_comparator_t;\n+typedef struct leveldb_env_t leveldb_env_t;\n+typedef struct leveldb_filelock_t leveldb_filelock_t;\n+typedef struct leveldb_filterpolicy_t leveldb_filterpolicy_t;\n+typedef struct leveldb_iterator_t leveldb_iterator_t;\n+typedef struct leveldb_logger_t leveldb_logger_t;\n+typedef struct leveldb_options_t leveldb_options_t;\n+typedef struct leveldb_randomfile_t leveldb_randomfile_t;\n+typedef struct leveldb_readoptions_t leveldb_readoptions_t;\n+typedef struct leveldb_seqfile_t leveldb_seqfile_t;\n+typedef struct leveldb_snapshot_t leveldb_snapshot_t;\n+typedef struct leveldb_writablefile_t leveldb_writablefile_t;\n+typedef struct leveldb_writebatch_t leveldb_writebatch_t;\n+typedef struct leveldb_writeoptions_t leveldb_writeoptions_t;\n \n /* DB operations */\n \n-extern leveldb_t* leveldb_open(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr);\n+LEVELDB_EXPORT leveldb_t* leveldb_open(const leveldb_options_t* options,\n+                                       const char* name, char** errptr);\n \n-extern void leveldb_close(leveldb_t* db);\n+LEVELDB_EXPORT void leveldb_close(leveldb_t* db);\n \n-extern void leveldb_put(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    const char* key, size_t keylen,\n-    const char* val, size_t vallen,\n-    char** errptr);\n+LEVELDB_EXPORT void leveldb_put(leveldb_t* db,\n+                                const leveldb_writeoptions_t* options,\n+                                const char* key, size_t keylen, const char* val,\n+                                size_t vallen, char** errptr);\n \n-extern void leveldb_delete(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    const char* key, size_t keylen,\n-    char** errptr);\n+LEVELDB_EXPORT void leveldb_delete(leveldb_t* db,\n+                                   const leveldb_writeoptions_t* options,\n+                                   const char* key, size_t keylen,\n+                                   char** errptr);\n \n-extern void leveldb_write(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    leveldb_writebatch_t* batch,\n-    char** errptr);\n+LEVELDB_EXPORT void leveldb_write(leveldb_t* db,\n+                                  const leveldb_writeoptions_t* options,\n+                                  leveldb_writebatch_t* batch, char** errptr);\n \n /* Returns NULL if not found.  A malloc()ed array otherwise.\n    Stores the length of the array in *vallen. */\n-extern char* leveldb_get(\n-    leveldb_t* db,\n-    const leveldb_readoptions_t* options,\n-    const char* key, size_t keylen,\n-    size_t* vallen,\n-    char** errptr);\n+LEVELDB_EXPORT char* leveldb_get(leveldb_t* db,\n+                                 const leveldb_readoptions_t* options,\n+                                 const char* key, size_t keylen, size_t* vallen,\n+                                 char** errptr);\n \n-extern leveldb_iterator_t* leveldb_create_iterator(\n-    leveldb_t* db,\n-    const leveldb_readoptions_t* options);\n+LEVELDB_EXPORT leveldb_iterator_t* leveldb_create_iterator(\n+    leveldb_t* db, const leveldb_readoptions_t* options);\n \n-extern const leveldb_snapshot_t* leveldb_create_snapshot(\n-    leveldb_t* db);\n+LEVELDB_EXPORT const leveldb_snapshot_t* leveldb_create_snapshot(leveldb_t* db);\n \n-extern void leveldb_release_snapshot(\n-    leveldb_t* db,\n-    const leveldb_snapshot_t* snapshot);\n+LEVELDB_EXPORT void leveldb_release_snapshot(\n+    leveldb_t* db, const leveldb_snapshot_t* snapshot);\n \n /* Returns NULL if property name is unknown.\n    Else returns a pointer to a malloc()-ed null-terminated value. */\n-extern char* leveldb_property_value(\n-    leveldb_t* db,\n-    const char* propname);\n-\n-extern void leveldb_approximate_sizes(\n-    leveldb_t* db,\n-    int num_ranges,\n-    const char* const* range_start_key, const size_t* range_start_key_len,\n-    const char* const* range_limit_key, const size_t* range_limit_key_len,\n-    uint64_t* sizes);\n-\n-extern void leveldb_compact_range(\n-    leveldb_t* db,\n-    const char* start_key, size_t start_key_len,\n-    const char* limit_key, size_t limit_key_len);\n+LEVELDB_EXPORT char* leveldb_property_value(leveldb_t* db,\n+                                            const char* propname);\n+\n+LEVELDB_EXPORT void leveldb_approximate_sizes(\n+    leveldb_t* db, int num_ranges, const char* const* range_start_key,\n+    const size_t* range_start_key_len, const char* const* range_limit_key,\n+    const size_t* range_limit_key_len, uint64_t* sizes);\n+\n+LEVELDB_EXPORT void leveldb_compact_range(leveldb_t* db, const char* start_key,\n+                                          size_t start_key_len,\n+                                          const char* limit_key,\n+                                          size_t limit_key_len);\n \n /* Management operations */\n \n-extern void leveldb_destroy_db(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr);\n+LEVELDB_EXPORT void leveldb_destroy_db(const leveldb_options_t* options,\n+                                       const char* name, char** errptr);\n \n-extern void leveldb_repair_db(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr);\n+LEVELDB_EXPORT void leveldb_repair_db(const leveldb_options_t* options,\n+                                      const char* name, char** errptr);\n \n /* Iterator */\n \n-extern void leveldb_iter_destroy(leveldb_iterator_t*);\n-extern unsigned char leveldb_iter_valid(const leveldb_iterator_t*);\n-extern void leveldb_iter_seek_to_first(leveldb_iterator_t*);\n-extern void leveldb_iter_seek_to_last(leveldb_iterator_t*);\n-extern void leveldb_iter_seek(leveldb_iterator_t*, const char* k, size_t klen);\n-extern void leveldb_iter_next(leveldb_iterator_t*);\n-extern void leveldb_iter_prev(leveldb_iterator_t*);\n-extern const char* leveldb_iter_key(const leveldb_iterator_t*, size_t* klen);\n-extern const char* leveldb_iter_value(const leveldb_iterator_t*, size_t* vlen);\n-extern void leveldb_iter_get_error(const leveldb_iterator_t*, char** errptr);\n+LEVELDB_EXPORT void leveldb_iter_destroy(leveldb_iterator_t*);\n+LEVELDB_EXPORT uint8_t leveldb_iter_valid(const leveldb_iterator_t*);\n+LEVELDB_EXPORT void leveldb_iter_seek_to_first(leveldb_iterator_t*);\n+LEVELDB_EXPORT void leveldb_iter_seek_to_last(leveldb_iterator_t*);\n+LEVELDB_EXPORT void leveldb_iter_seek(leveldb_iterator_t*, const char* k,\n+                                      size_t klen);\n+LEVELDB_EXPORT void leveldb_iter_next(leveldb_iterator_t*);\n+LEVELDB_EXPORT void leveldb_iter_prev(leveldb_iterator_t*);\n+LEVELDB_EXPORT const char* leveldb_iter_key(const leveldb_iterator_t*,\n+                                            size_t* klen);\n+LEVELDB_EXPORT const char* leveldb_iter_value(const leveldb_iterator_t*,\n+                                              size_t* vlen);\n+LEVELDB_EXPORT void leveldb_iter_get_error(const leveldb_iterator_t*,\n+                                           char** errptr);\n \n /* Write batch */\n \n-extern leveldb_writebatch_t* leveldb_writebatch_create();\n-extern void leveldb_writebatch_destroy(leveldb_writebatch_t*);\n-extern void leveldb_writebatch_clear(leveldb_writebatch_t*);\n-extern void leveldb_writebatch_put(\n-    leveldb_writebatch_t*,\n-    const char* key, size_t klen,\n-    const char* val, size_t vlen);\n-extern void leveldb_writebatch_delete(\n-    leveldb_writebatch_t*,\n-    const char* key, size_t klen);\n-extern void leveldb_writebatch_iterate(\n-    leveldb_writebatch_t*,\n-    void* state,\n+LEVELDB_EXPORT leveldb_writebatch_t* leveldb_writebatch_create(void);\n+LEVELDB_EXPORT void leveldb_writebatch_destroy(leveldb_writebatch_t*);\n+LEVELDB_EXPORT void leveldb_writebatch_clear(leveldb_writebatch_t*);\n+LEVELDB_EXPORT void leveldb_writebatch_put(leveldb_writebatch_t*,\n+                                           const char* key, size_t klen,\n+                                           const char* val, size_t vlen);\n+LEVELDB_EXPORT void leveldb_writebatch_delete(leveldb_writebatch_t*,\n+                                              const char* key, size_t klen);\n+LEVELDB_EXPORT void leveldb_writebatch_iterate(\n+    const leveldb_writebatch_t*, void* state,\n     void (*put)(void*, const char* k, size_t klen, const char* v, size_t vlen),\n     void (*deleted)(void*, const char* k, size_t klen));\n+LEVELDB_EXPORT void leveldb_writebatch_append(\n+    leveldb_writebatch_t* destination, const leveldb_writebatch_t* source);\n \n /* Options */\n \n-extern leveldb_options_t* leveldb_options_create();\n-extern void leveldb_options_destroy(leveldb_options_t*);\n-extern void leveldb_options_set_comparator(\n-    leveldb_options_t*,\n-    leveldb_comparator_t*);\n-extern void leveldb_options_set_filter_policy(\n-    leveldb_options_t*,\n-    leveldb_filterpolicy_t*);\n-extern void leveldb_options_set_create_if_missing(\n-    leveldb_options_t*, unsigned char);\n-extern void leveldb_options_set_error_if_exists(\n-    leveldb_options_t*, unsigned char);\n-extern void leveldb_options_set_paranoid_checks(\n-    leveldb_options_t*, unsigned char);\n-extern void leveldb_options_set_env(leveldb_options_t*, leveldb_env_t*);\n-extern void leveldb_options_set_info_log(leveldb_options_t*, leveldb_logger_t*);\n-extern void leveldb_options_set_write_buffer_size(leveldb_options_t*, size_t);\n-extern void leveldb_options_set_max_open_files(leveldb_options_t*, int);\n-extern void leveldb_options_set_cache(leveldb_options_t*, leveldb_cache_t*);\n-extern void leveldb_options_set_block_size(leveldb_options_t*, size_t);\n-extern void leveldb_options_set_block_restart_interval(leveldb_options_t*, int);\n-\n-enum {\n-  leveldb_no_compression = 0,\n-  leveldb_snappy_compression = 1\n-};\n-extern void leveldb_options_set_compression(leveldb_options_t*, int);\n+LEVELDB_EXPORT leveldb_options_t* leveldb_options_create(void);\n+LEVELDB_EXPORT void leveldb_options_destroy(leveldb_options_t*);\n+LEVELDB_EXPORT void leveldb_options_set_comparator(leveldb_options_t*,\n+                                                   leveldb_comparator_t*);\n+LEVELDB_EXPORT void leveldb_options_set_filter_policy(leveldb_options_t*,\n+                                                      leveldb_filterpolicy_t*);\n+LEVELDB_EXPORT void leveldb_options_set_create_if_missing(leveldb_options_t*,\n+                                                          uint8_t);\n+LEVELDB_EXPORT void leveldb_options_set_error_if_exists(leveldb_options_t*,\n+                                                        uint8_t);\n+LEVELDB_EXPORT void leveldb_options_set_paranoid_checks(leveldb_options_t*,\n+                                                        uint8_t);\n+LEVELDB_EXPORT void leveldb_options_set_env(leveldb_options_t*, leveldb_env_t*);\n+LEVELDB_EXPORT void leveldb_options_set_info_log(leveldb_options_t*,\n+                                                 leveldb_logger_t*);\n+LEVELDB_EXPORT void leveldb_options_set_write_buffer_size(leveldb_options_t*,\n+                                                          size_t);\n+LEVELDB_EXPORT void leveldb_options_set_max_open_files(leveldb_options_t*, int);\n+LEVELDB_EXPORT void leveldb_options_set_cache(leveldb_options_t*,\n+                                              leveldb_cache_t*);\n+LEVELDB_EXPORT void leveldb_options_set_block_size(leveldb_options_t*, size_t);\n+LEVELDB_EXPORT void leveldb_options_set_block_restart_interval(\n+    leveldb_options_t*, int);\n+LEVELDB_EXPORT void leveldb_options_set_max_file_size(leveldb_options_t*,\n+                                                      size_t);\n+\n+enum { leveldb_no_compression = 0, leveldb_snappy_compression = 1 };\n+LEVELDB_EXPORT void leveldb_options_set_compression(leveldb_options_t*, int);\n \n /* Comparator */\n \n-extern leveldb_comparator_t* leveldb_comparator_create(\n-    void* state,\n-    void (*destructor)(void*),\n-    int (*compare)(\n-        void*,\n-        const char* a, size_t alen,\n-        const char* b, size_t blen),\n+LEVELDB_EXPORT leveldb_comparator_t* leveldb_comparator_create(\n+    void* state, void (*destructor)(void*),\n+    int (*compare)(void*, const char* a, size_t alen, const char* b,\n+                   size_t blen),\n     const char* (*name)(void*));\n-extern void leveldb_comparator_destroy(leveldb_comparator_t*);\n+LEVELDB_EXPORT void leveldb_comparator_destroy(leveldb_comparator_t*);\n \n /* Filter policy */\n \n-extern leveldb_filterpolicy_t* leveldb_filterpolicy_create(\n-    void* state,\n-    void (*destructor)(void*),\n-    char* (*create_filter)(\n-        void*,\n-        const char* const* key_array, const size_t* key_length_array,\n-        int num_keys,\n-        size_t* filter_length),\n-    unsigned char (*key_may_match)(\n-        void*,\n-        const char* key, size_t length,\n-        const char* filter, size_t filter_length),\n+LEVELDB_EXPORT leveldb_filterpolicy_t* leveldb_filterpolicy_create(\n+    void* state, void (*destructor)(void*),\n+    char* (*create_filter)(void*, const char* const* key_array,\n+                           const size_t* key_length_array, int num_keys,\n+                           size_t* filter_length),\n+    uint8_t (*key_may_match)(void*, const char* key, size_t length,\n+                             const char* filter, size_t filter_length),\n     const char* (*name)(void*));\n-extern void leveldb_filterpolicy_destroy(leveldb_filterpolicy_t*);\n+LEVELDB_EXPORT void leveldb_filterpolicy_destroy(leveldb_filterpolicy_t*);\n \n-extern leveldb_filterpolicy_t* leveldb_filterpolicy_create_bloom(\n+LEVELDB_EXPORT leveldb_filterpolicy_t* leveldb_filterpolicy_create_bloom(\n     int bits_per_key);\n \n /* Read options */\n \n-extern leveldb_readoptions_t* leveldb_readoptions_create();\n-extern void leveldb_readoptions_destroy(leveldb_readoptions_t*);\n-extern void leveldb_readoptions_set_verify_checksums(\n-    leveldb_readoptions_t*,\n-    unsigned char);\n-extern void leveldb_readoptions_set_fill_cache(\n-    leveldb_readoptions_t*, unsigned char);\n-extern void leveldb_readoptions_set_snapshot(\n-    leveldb_readoptions_t*,\n-    const leveldb_snapshot_t*);\n+LEVELDB_EXPORT leveldb_readoptions_t* leveldb_readoptions_create(void);\n+LEVELDB_EXPORT void leveldb_readoptions_destroy(leveldb_readoptions_t*);\n+LEVELDB_EXPORT void leveldb_readoptions_set_verify_checksums(\n+    leveldb_readoptions_t*, uint8_t);\n+LEVELDB_EXPORT void leveldb_readoptions_set_fill_cache(leveldb_readoptions_t*,\n+                                                       uint8_t);\n+LEVELDB_EXPORT void leveldb_readoptions_set_snapshot(leveldb_readoptions_t*,\n+                                                     const leveldb_snapshot_t*);\n \n /* Write options */\n \n-extern leveldb_writeoptions_t* leveldb_writeoptions_create();\n-extern void leveldb_writeoptions_destroy(leveldb_writeoptions_t*);\n-extern void leveldb_writeoptions_set_sync(\n-    leveldb_writeoptions_t*, unsigned char);\n+LEVELDB_EXPORT leveldb_writeoptions_t* leveldb_writeoptions_create(void);\n+LEVELDB_EXPORT void leveldb_writeoptions_destroy(leveldb_writeoptions_t*);\n+LEVELDB_EXPORT void leveldb_writeoptions_set_sync(leveldb_writeoptions_t*,\n+                                                  uint8_t);\n \n /* Cache */\n \n-extern leveldb_cache_t* leveldb_cache_create_lru(size_t capacity);\n-extern void leveldb_cache_destroy(leveldb_cache_t* cache);\n+LEVELDB_EXPORT leveldb_cache_t* leveldb_cache_create_lru(size_t capacity);\n+LEVELDB_EXPORT void leveldb_cache_destroy(leveldb_cache_t* cache);\n \n /* Env */\n \n-extern leveldb_env_t* leveldb_create_default_env();\n-extern void leveldb_env_destroy(leveldb_env_t*);\n+LEVELDB_EXPORT leveldb_env_t* leveldb_create_default_env(void);\n+LEVELDB_EXPORT void leveldb_env_destroy(leveldb_env_t*);\n+\n+/* If not NULL, the returned buffer must be released using leveldb_free(). */\n+LEVELDB_EXPORT char* leveldb_env_get_test_directory(leveldb_env_t*);\n \n /* Utility */\n \n@@ -275,16 +255,16 @@ extern void leveldb_env_destroy(leveldb_env_t*);\n    in this file.  Note that in certain cases (typically on Windows), you\n    may need to call this routine instead of free(ptr) to dispose of\n    malloc()-ed memory returned by this library. */\n-extern void leveldb_free(void* ptr);\n+LEVELDB_EXPORT void leveldb_free(void* ptr);\n \n /* Return the major version number for this release. */\n-extern int leveldb_major_version();\n+LEVELDB_EXPORT int leveldb_major_version(void);\n \n /* Return the minor version number for this release. */\n-extern int leveldb_minor_version();\n+LEVELDB_EXPORT int leveldb_minor_version(void);\n \n #ifdef __cplusplus\n-}  /* end extern \"C\" */\n+} /* end extern \"C\" */\n #endif\n \n-#endif  /* STORAGE_LEVELDB_INCLUDE_C_H_ */\n+#endif /* STORAGE_LEVELDB_INCLUDE_C_H_ */"
      },
      {
        "sha": "7d1a221193f6dd9a605991065a31cacfc3ab305d",
        "filename": "include/leveldb/cache.h",
        "status": "modified",
        "additions": 11,
        "deletions": 10,
        "changes": 21,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/cache.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/cache.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/cache.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -19,26 +19,31 @@\n #define STORAGE_LEVELDB_INCLUDE_CACHE_H_\n \n #include <stdint.h>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/slice.h\"\n \n namespace leveldb {\n \n-class Cache;\n+class LEVELDB_EXPORT Cache;\n \n // Create a new cache with a fixed size capacity.  This implementation\n // of Cache uses a least-recently-used eviction policy.\n-extern Cache* NewLRUCache(size_t capacity);\n+LEVELDB_EXPORT Cache* NewLRUCache(size_t capacity);\n \n-class Cache {\n+class LEVELDB_EXPORT Cache {\n  public:\n-  Cache() { }\n+  Cache() = default;\n+\n+  Cache(const Cache&) = delete;\n+  Cache& operator=(const Cache&) = delete;\n \n   // Destroys all existing entries by calling the \"deleter\"\n   // function that was passed to the constructor.\n   virtual ~Cache();\n \n   // Opaque handle to an entry stored in the cache.\n-  struct Handle { };\n+  struct Handle {};\n \n   // Insert a mapping from key->value into the cache and assign it\n   // the specified charge against the total cache capacity.\n@@ -52,7 +57,7 @@ class Cache {\n   virtual Handle* Insert(const Slice& key, void* value, size_t charge,\n                          void (*deleter)(const Slice& key, void* value)) = 0;\n \n-  // If the cache has no mapping for \"key\", returns NULL.\n+  // If the cache has no mapping for \"key\", returns nullptr.\n   //\n   // Else return a handle that corresponds to the mapping.  The caller\n   // must call this->Release(handle) when the returned mapping is no\n@@ -99,10 +104,6 @@ class Cache {\n \n   struct Rep;\n   Rep* rep_;\n-\n-  // No copying allowed\n-  Cache(const Cache&);\n-  void operator=(const Cache&);\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "a85b51ebd886aeb675423e2cbc7afe2fcb5a1023",
        "filename": "include/leveldb/comparator.h",
        "status": "modified",
        "additions": 6,
        "deletions": 5,
        "changes": 11,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/comparator.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/comparator.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/comparator.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -7,6 +7,8 @@\n \n #include <string>\n \n+#include \"leveldb/export.h\"\n+\n namespace leveldb {\n \n class Slice;\n@@ -15,7 +17,7 @@ class Slice;\n // used as keys in an sstable or a database.  A Comparator implementation\n // must be thread-safe since leveldb may invoke its methods concurrently\n // from multiple threads.\n-class Comparator {\n+class LEVELDB_EXPORT Comparator {\n  public:\n   virtual ~Comparator();\n \n@@ -43,9 +45,8 @@ class Comparator {\n   // If *start < limit, changes *start to a short string in [start,limit).\n   // Simple comparator implementations may return with *start unchanged,\n   // i.e., an implementation of this method that does nothing is correct.\n-  virtual void FindShortestSeparator(\n-      std::string* start,\n-      const Slice& limit) const = 0;\n+  virtual void FindShortestSeparator(std::string* start,\n+                                     const Slice& limit) const = 0;\n \n   // Changes *key to a short string >= *key.\n   // Simple comparator implementations may return with *key unchanged,\n@@ -56,7 +57,7 @@ class Comparator {\n // Return a builtin comparator that uses lexicographic byte-wise\n // ordering.  The result remains the property of this module and\n // must not be deleted.\n-extern const Comparator* BytewiseComparator();\n+LEVELDB_EXPORT const Comparator* BytewiseComparator();\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "b73014a2214ae67c52d8bc8f1589fe1a76b1eabe",
        "filename": "include/leveldb/db.h",
        "status": "modified",
        "additions": 31,
        "deletions": 27,
        "changes": 58,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/db.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/db.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/db.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -7,14 +7,16 @@\n \n #include <stdint.h>\n #include <stdio.h>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/iterator.h\"\n #include \"leveldb/options.h\"\n \n namespace leveldb {\n \n-// Update Makefile if you change these\n+// Update CMakeLists.txt if you change these\n static const int kMajorVersion = 1;\n-static const int kMinorVersion = 20;\n+static const int kMinorVersion = 22;\n \n struct Options;\n struct ReadOptions;\n@@ -24,42 +26,44 @@ class WriteBatch;\n // Abstract handle to particular state of a DB.\n // A Snapshot is an immutable object and can therefore be safely\n // accessed from multiple threads without any external synchronization.\n-class Snapshot {\n+class LEVELDB_EXPORT Snapshot {\n  protected:\n   virtual ~Snapshot();\n };\n \n // A range of keys\n-struct Range {\n-  Slice start;          // Included in the range\n-  Slice limit;          // Not included in the range\n+struct LEVELDB_EXPORT Range {\n+  Range() = default;\n+  Range(const Slice& s, const Slice& l) : start(s), limit(l) {}\n \n-  Range() { }\n-  Range(const Slice& s, const Slice& l) : start(s), limit(l) { }\n+  Slice start;  // Included in the range\n+  Slice limit;  // Not included in the range\n };\n \n // A DB is a persistent ordered map from keys to values.\n // A DB is safe for concurrent access from multiple threads without\n // any external synchronization.\n-class DB {\n+class LEVELDB_EXPORT DB {\n  public:\n   // Open the database with the specified \"name\".\n   // Stores a pointer to a heap-allocated database in *dbptr and returns\n   // OK on success.\n-  // Stores NULL in *dbptr and returns a non-OK status on error.\n+  // Stores nullptr in *dbptr and returns a non-OK status on error.\n   // Caller should delete *dbptr when it is no longer needed.\n-  static Status Open(const Options& options,\n-                     const std::string& name,\n+  static Status Open(const Options& options, const std::string& name,\n                      DB** dbptr);\n \n-  DB() { }\n+  DB() = default;\n+\n+  DB(const DB&) = delete;\n+  DB& operator=(const DB&) = delete;\n+\n   virtual ~DB();\n \n   // Set the database entry for \"key\" to \"value\".  Returns OK on success,\n   // and a non-OK status on error.\n   // Note: consider setting options.sync = true.\n-  virtual Status Put(const WriteOptions& options,\n-                     const Slice& key,\n+  virtual Status Put(const WriteOptions& options, const Slice& key,\n                      const Slice& value) = 0;\n \n   // Remove the database entry (if any) for \"key\".  Returns OK on\n@@ -80,8 +84,8 @@ class DB {\n   // a status for which Status::IsNotFound() returns true.\n   //\n   // May return some other Status on an error.\n-  virtual Status Get(const ReadOptions& options,\n-                     const Slice& key, std::string* value) = 0;\n+  virtual Status Get(const ReadOptions& options, const Slice& key,\n+                     std::string* value) = 0;\n \n   // Return a heap-allocated iterator over the contents of the database.\n   // The result of NewIterator() is initially invalid (caller must\n@@ -136,27 +140,27 @@ class DB {\n   // needed to access the data.  This operation should typically only\n   // be invoked by users who understand the underlying implementation.\n   //\n-  // begin==NULL is treated as a key before all keys in the database.\n-  // end==NULL is treated as a key after all keys in the database.\n+  // begin==nullptr is treated as a key before all keys in the database.\n+  // end==nullptr is treated as a key after all keys in the database.\n   // Therefore the following call will compact the entire database:\n-  //    db->CompactRange(NULL, NULL);\n+  //    db->CompactRange(nullptr, nullptr);\n   virtual void CompactRange(const Slice* begin, const Slice* end) = 0;\n-\n- private:\n-  // No copying allowed\n-  DB(const DB&);\n-  void operator=(const DB&);\n };\n \n // Destroy the contents of the specified database.\n // Be very careful using this method.\n-Status DestroyDB(const std::string& name, const Options& options);\n+//\n+// Note: For backwards compatibility, if DestroyDB is unable to list the\n+// database files, Status::OK() will still be returned masking this failure.\n+LEVELDB_EXPORT Status DestroyDB(const std::string& name,\n+                                const Options& options);\n \n // If a DB cannot be opened, you may attempt to call this method to\n // resurrect as much of the contents of the database as possible.\n // Some data may be lost, so be careful when calling this function\n // on a database that contains important information.\n-Status RepairDB(const std::string& dbname, const Options& options);\n+LEVELDB_EXPORT Status RepairDB(const std::string& dbname,\n+                               const Options& options);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "a58bc6b36c16d764dd3738d49078c648d7e1003d",
        "filename": "include/leveldb/dumpfile.h",
        "status": "modified",
        "additions": 4,
        "deletions": 1,
        "changes": 5,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/dumpfile.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/dumpfile.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/dumpfile.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -6,7 +6,9 @@\n #define STORAGE_LEVELDB_INCLUDE_DUMPFILE_H_\n \n #include <string>\n+\n #include \"leveldb/env.h\"\n+#include \"leveldb/export.h\"\n #include \"leveldb/status.h\"\n \n namespace leveldb {\n@@ -18,7 +20,8 @@ namespace leveldb {\n //\n // Returns a non-OK result if fname does not name a leveldb storage\n // file, or if the file cannot be read.\n-Status DumpFile(Env* env, const std::string& fname, WritableFile* dst);\n+LEVELDB_EXPORT Status DumpFile(Env* env, const std::string& fname,\n+                               WritableFile* dst);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "96c21b3966c4c35a6012450474f12868dc4e006b",
        "filename": "include/leveldb/env.h",
        "status": "modified",
        "additions": 128,
        "deletions": 92,
        "changes": 220,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/env.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/env.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/env.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -13,12 +13,36 @@\n #ifndef STORAGE_LEVELDB_INCLUDE_ENV_H_\n #define STORAGE_LEVELDB_INCLUDE_ENV_H_\n \n-#include <string>\n-#include <vector>\n #include <stdarg.h>\n #include <stdint.h>\n+\n+#include <string>\n+#include <vector>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/status.h\"\n \n+#if defined(_WIN32)\n+// The leveldb::Env class below contains a DeleteFile method.\n+// At the same time, <windows.h>, a fairly popular header\n+// file for Windows applications, defines a DeleteFile macro.\n+//\n+// Without any intervention on our part, the result of this\n+// unfortunate coincidence is that the name of the\n+// leveldb::Env::DeleteFile method seen by the compiler depends on\n+// whether <windows.h> was included before or after the LevelDB\n+// headers.\n+//\n+// To avoid headaches, we undefined DeleteFile (if defined) and\n+// redefine it at the bottom of this file. This way <windows.h>\n+// can be included before this file (or not at all) and the\n+// exported method will always be leveldb::Env::DeleteFile.\n+#if defined(DeleteFile)\n+#undef DeleteFile\n+#define LEVELDB_DELETEFILE_UNDEFINED\n+#endif  // defined(DeleteFile)\n+#endif  // defined(_WIN32)\n+\n namespace leveldb {\n \n class FileLock;\n@@ -28,9 +52,13 @@ class SequentialFile;\n class Slice;\n class WritableFile;\n \n-class Env {\n+class LEVELDB_EXPORT Env {\n  public:\n-  Env() { }\n+  Env() = default;\n+\n+  Env(const Env&) = delete;\n+  Env& operator=(const Env&) = delete;\n+\n   virtual ~Env();\n \n   // Return a default environment suitable for the current operating\n@@ -40,20 +68,22 @@ class Env {\n   // The result of Default() belongs to leveldb and must never be deleted.\n   static Env* Default();\n \n-  // Create a brand new sequentially-readable file with the specified name.\n+  // Create an object that sequentially reads the file with the specified name.\n   // On success, stores a pointer to the new file in *result and returns OK.\n-  // On failure stores NULL in *result and returns non-OK.  If the file does\n-  // not exist, returns a non-OK status.\n+  // On failure stores nullptr in *result and returns non-OK.  If the file does\n+  // not exist, returns a non-OK status.  Implementations should return a\n+  // NotFound status when the file does not exist.\n   //\n   // The returned file will only be accessed by one thread at a time.\n   virtual Status NewSequentialFile(const std::string& fname,\n                                    SequentialFile** result) = 0;\n \n-  // Create a brand new random access read-only file with the\n+  // Create an object supporting random-access reads from the file with the\n   // specified name.  On success, stores a pointer to the new file in\n-  // *result and returns OK.  On failure stores NULL in *result and\n+  // *result and returns OK.  On failure stores nullptr in *result and\n   // returns non-OK.  If the file does not exist, returns a non-OK\n-  // status.\n+  // status.  Implementations should return a NotFound status when the file does\n+  // not exist.\n   //\n   // The returned file may be concurrently accessed by multiple threads.\n   virtual Status NewRandomAccessFile(const std::string& fname,\n@@ -62,7 +92,7 @@ class Env {\n   // Create an object that writes to a new file with the specified\n   // name.  Deletes any existing file with the same name and creates a\n   // new file.  On success, stores a pointer to the new file in\n-  // *result and returns OK.  On failure stores NULL in *result and\n+  // *result and returns OK.  On failure stores nullptr in *result and\n   // returns non-OK.\n   //\n   // The returned file will only be accessed by one thread at a time.\n@@ -72,7 +102,7 @@ class Env {\n   // Create an object that either appends to an existing file, or\n   // writes to a new file (if the file does not exist to begin with).\n   // On success, stores a pointer to the new file in *result and\n-  // returns OK.  On failure stores NULL in *result and returns\n+  // returns OK.  On failure stores nullptr in *result and returns\n   // non-OK.\n   //\n   // The returned file will only be accessed by one thread at a time.\n@@ -110,7 +140,7 @@ class Env {\n                             const std::string& target) = 0;\n \n   // Lock the specified file.  Used to prevent concurrent access to\n-  // the same db by multiple processes.  On failure, stores NULL in\n+  // the same db by multiple processes.  On failure, stores nullptr in\n   // *lock and returns non-OK.\n   //\n   // On success, stores a pointer to the object that represents the\n@@ -136,16 +166,14 @@ class Env {\n   // added to the same Env may run concurrently in different threads.\n   // I.e., the caller may not assume that background work items are\n   // serialized.\n-  virtual void Schedule(\n-      void (*function)(void* arg),\n-      void* arg) = 0;\n+  virtual void Schedule(void (*function)(void* arg), void* arg) = 0;\n \n   // Start a new thread, invoking \"function(arg)\" within the new thread.\n   // When \"function(arg)\" returns, the thread will be destroyed.\n   virtual void StartThread(void (*function)(void* arg), void* arg) = 0;\n \n   // *path is set to a temporary directory that can be used for testing. It may\n-  // or many not have just been created. The directory may or may not differ\n+  // or may not have just been created. The directory may or may not differ\n   // between runs of the same process, but subsequent calls will return the\n   // same directory.\n   virtual Status GetTestDirectory(std::string* path) = 0;\n@@ -159,17 +187,16 @@ class Env {\n \n   // Sleep/delay the thread for the prescribed number of micro-seconds.\n   virtual void SleepForMicroseconds(int micros) = 0;\n-\n- private:\n-  // No copying allowed\n-  Env(const Env&);\n-  void operator=(const Env&);\n };\n \n // A file abstraction for reading sequentially through a file\n-class SequentialFile {\n+class LEVELDB_EXPORT SequentialFile {\n  public:\n-  SequentialFile() { }\n+  SequentialFile() = default;\n+\n+  SequentialFile(const SequentialFile&) = delete;\n+  SequentialFile& operator=(const SequentialFile&) = delete;\n+\n   virtual ~SequentialFile();\n \n   // Read up to \"n\" bytes from the file.  \"scratch[0..n-1]\" may be\n@@ -193,17 +220,16 @@ class SequentialFile {\n \n   // Get a name for the file, only for error reporting\n   virtual std::string GetName() const = 0;\n-\n- private:\n-  // No copying allowed\n-  SequentialFile(const SequentialFile&);\n-  void operator=(const SequentialFile&);\n };\n \n // A file abstraction for randomly reading the contents of a file.\n-class RandomAccessFile {\n+class LEVELDB_EXPORT RandomAccessFile {\n  public:\n-  RandomAccessFile() { }\n+  RandomAccessFile() = default;\n+\n+  RandomAccessFile(const RandomAccessFile&) = delete;\n+  RandomAccessFile& operator=(const RandomAccessFile&) = delete;\n+\n   virtual ~RandomAccessFile();\n \n   // Read up to \"n\" bytes from the file starting at \"offset\".\n@@ -220,19 +246,18 @@ class RandomAccessFile {\n \n   // Get a name for the file, only for error reporting\n   virtual std::string GetName() const = 0;\n-\n- private:\n-  // No copying allowed\n-  RandomAccessFile(const RandomAccessFile&);\n-  void operator=(const RandomAccessFile&);\n };\n \n // A file abstraction for sequential writing.  The implementation\n // must provide buffering since callers may append small fragments\n // at a time to the file.\n-class WritableFile {\n+class LEVELDB_EXPORT WritableFile {\n  public:\n-  WritableFile() { }\n+  WritableFile() = default;\n+\n+  WritableFile(const WritableFile&) = delete;\n+  WritableFile& operator=(const WritableFile&) = delete;\n+\n   virtual ~WritableFile();\n \n   virtual Status Append(const Slice& data) = 0;\n@@ -242,119 +267,130 @@ class WritableFile {\n \n   // Get a name for the file, only for error reporting\n   virtual std::string GetName() const = 0;\n-\n- private:\n-  // No copying allowed\n-  WritableFile(const WritableFile&);\n-  void operator=(const WritableFile&);\n };\n \n // An interface for writing log messages.\n-class Logger {\n+class LEVELDB_EXPORT Logger {\n  public:\n-  Logger() { }\n+  Logger() = default;\n+\n+  Logger(const Logger&) = delete;\n+  Logger& operator=(const Logger&) = delete;\n+\n   virtual ~Logger();\n \n   // Write an entry to the log file with the specified format.\n   virtual void Logv(const char* format, va_list ap) = 0;\n-\n- private:\n-  // No copying allowed\n-  Logger(const Logger&);\n-  void operator=(const Logger&);\n };\n \n-\n // Identifies a locked file.\n-class FileLock {\n+class LEVELDB_EXPORT FileLock {\n  public:\n-  FileLock() { }\n+  FileLock() = default;\n+\n+  FileLock(const FileLock&) = delete;\n+  FileLock& operator=(const FileLock&) = delete;\n+\n   virtual ~FileLock();\n- private:\n-  // No copying allowed\n-  FileLock(const FileLock&);\n-  void operator=(const FileLock&);\n };\n \n-// Log the specified data to *info_log if info_log is non-NULL.\n-extern void Log(Logger* info_log, const char* format, ...)\n-#   if defined(__GNUC__) || defined(__clang__)\n-    __attribute__((__format__ (__printf__, 2, 3)))\n-#   endif\n+// Log the specified data to *info_log if info_log is non-null.\n+void Log(Logger* info_log, const char* format, ...)\n+#if defined(__GNUC__) || defined(__clang__)\n+    __attribute__((__format__(__printf__, 2, 3)))\n+#endif\n     ;\n \n // A utility routine: write \"data\" to the named file.\n-extern Status WriteStringToFile(Env* env, const Slice& data,\n-                                const std::string& fname);\n+LEVELDB_EXPORT Status WriteStringToFile(Env* env, const Slice& data,\n+                                        const std::string& fname);\n \n // A utility routine: read contents of named file into *data\n-extern Status ReadFileToString(Env* env, const std::string& fname,\n-                               std::string* data);\n+LEVELDB_EXPORT Status ReadFileToString(Env* env, const std::string& fname,\n+                                       std::string* data);\n \n // An implementation of Env that forwards all calls to another Env.\n // May be useful to clients who wish to override just part of the\n // functionality of another Env.\n-class EnvWrapper : public Env {\n+class LEVELDB_EXPORT EnvWrapper : public Env {\n  public:\n-  // Initialize an EnvWrapper that delegates all calls to *t\n-  explicit EnvWrapper(Env* t) : target_(t) { }\n+  // Initialize an EnvWrapper that delegates all calls to *t.\n+  explicit EnvWrapper(Env* t) : target_(t) {}\n   virtual ~EnvWrapper();\n \n-  // Return the target to which this Env forwards all calls\n+  // Return the target to which this Env forwards all calls.\n   Env* target() const { return target_; }\n \n-  // The following text is boilerplate that forwards all methods to target()\n-  Status NewSequentialFile(const std::string& f, SequentialFile** r) {\n+  // The following text is boilerplate that forwards all methods to target().\n+  Status NewSequentialFile(const std::string& f, SequentialFile** r) override {\n     return target_->NewSequentialFile(f, r);\n   }\n-  Status NewRandomAccessFile(const std::string& f, RandomAccessFile** r) {\n+  Status NewRandomAccessFile(const std::string& f,\n+                             RandomAccessFile** r) override {\n     return target_->NewRandomAccessFile(f, r);\n   }\n-  Status NewWritableFile(const std::string& f, WritableFile** r) {\n+  Status NewWritableFile(const std::string& f, WritableFile** r) override {\n     return target_->NewWritableFile(f, r);\n   }\n-  Status NewAppendableFile(const std::string& f, WritableFile** r) {\n+  Status NewAppendableFile(const std::string& f, WritableFile** r) override {\n     return target_->NewAppendableFile(f, r);\n   }\n-  bool FileExists(const std::string& f) { return target_->FileExists(f); }\n-  Status GetChildren(const std::string& dir, std::vector<std::string>* r) {\n+  bool FileExists(const std::string& f) override {\n+    return target_->FileExists(f);\n+  }\n+  Status GetChildren(const std::string& dir,\n+                     std::vector<std::string>* r) override {\n     return target_->GetChildren(dir, r);\n   }\n-  Status DeleteFile(const std::string& f) { return target_->DeleteFile(f); }\n-  Status CreateDir(const std::string& d) { return target_->CreateDir(d); }\n-  Status DeleteDir(const std::string& d) { return target_->DeleteDir(d); }\n-  Status GetFileSize(const std::string& f, uint64_t* s) {\n+  Status DeleteFile(const std::string& f) override {\n+    return target_->DeleteFile(f);\n+  }\n+  Status CreateDir(const std::string& d) override {\n+    return target_->CreateDir(d);\n+  }\n+  Status DeleteDir(const std::string& d) override {\n+    return target_->DeleteDir(d);\n+  }\n+  Status GetFileSize(const std::string& f, uint64_t* s) override {\n     return target_->GetFileSize(f, s);\n   }\n-  Status RenameFile(const std::string& s, const std::string& t) {\n+  Status RenameFile(const std::string& s, const std::string& t) override {\n     return target_->RenameFile(s, t);\n   }\n-  Status LockFile(const std::string& f, FileLock** l) {\n+  Status LockFile(const std::string& f, FileLock** l) override {\n     return target_->LockFile(f, l);\n   }\n-  Status UnlockFile(FileLock* l) { return target_->UnlockFile(l); }\n-  void Schedule(void (*f)(void*), void* a) {\n+  Status UnlockFile(FileLock* l) override { return target_->UnlockFile(l); }\n+  void Schedule(void (*f)(void*), void* a) override {\n     return target_->Schedule(f, a);\n   }\n-  void StartThread(void (*f)(void*), void* a) {\n+  void StartThread(void (*f)(void*), void* a) override {\n     return target_->StartThread(f, a);\n   }\n-  virtual Status GetTestDirectory(std::string* path) {\n+  Status GetTestDirectory(std::string* path) override {\n     return target_->GetTestDirectory(path);\n   }\n-  virtual Status NewLogger(const std::string& fname, Logger** result) {\n+  Status NewLogger(const std::string& fname, Logger** result) override {\n     return target_->NewLogger(fname, result);\n   }\n-  uint64_t NowMicros() {\n-    return target_->NowMicros();\n-  }\n-  void SleepForMicroseconds(int micros) {\n+  uint64_t NowMicros() override { return target_->NowMicros(); }\n+  void SleepForMicroseconds(int micros) override {\n     target_->SleepForMicroseconds(micros);\n   }\n+\n  private:\n   Env* target_;\n };\n \n }  // namespace leveldb\n \n+// Redefine DeleteFile if necessary.\n+#if defined(_WIN32) && defined(LEVELDB_DELETEFILE_UNDEFINED)\n+#if defined(UNICODE)\n+#define DeleteFile DeleteFileW\n+#else\n+#define DeleteFile DeleteFileA\n+#endif  // defined(UNICODE)\n+#endif  // defined(_WIN32) && defined(LEVELDB_DELETEFILE_UNDEFINED)\n+\n #endif  // STORAGE_LEVELDB_INCLUDE_ENV_H_"
      },
      {
        "sha": "6ba9b183da49e96603aec7d8c4e6b01442ff3c2a",
        "filename": "include/leveldb/export.h",
        "status": "added",
        "additions": 33,
        "deletions": 0,
        "changes": 33,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/export.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/export.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/export.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -0,0 +1,33 @@\n+// Copyright (c) 2017 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef STORAGE_LEVELDB_INCLUDE_EXPORT_H_\n+#define STORAGE_LEVELDB_INCLUDE_EXPORT_H_\n+\n+#if !defined(LEVELDB_EXPORT)\n+\n+#if defined(LEVELDB_SHARED_LIBRARY)\n+#if defined(_WIN32)\n+\n+#if defined(LEVELDB_COMPILE_LIBRARY)\n+#define LEVELDB_EXPORT __declspec(dllexport)\n+#else\n+#define LEVELDB_EXPORT __declspec(dllimport)\n+#endif  // defined(LEVELDB_COMPILE_LIBRARY)\n+\n+#else  // defined(_WIN32)\n+#if defined(LEVELDB_COMPILE_LIBRARY)\n+#define LEVELDB_EXPORT __attribute__((visibility(\"default\")))\n+#else\n+#define LEVELDB_EXPORT\n+#endif\n+#endif  // defined(_WIN32)\n+\n+#else  // defined(LEVELDB_SHARED_LIBRARY)\n+#define LEVELDB_EXPORT\n+#endif\n+\n+#endif  // !defined(LEVELDB_EXPORT)\n+\n+#endif  // STORAGE_LEVELDB_INCLUDE_EXPORT_H_"
      },
      {
        "sha": "49c8eda7768ad342d6d53054cd6595ceaf355b73",
        "filename": "include/leveldb/filter_policy.h",
        "status": "modified",
        "additions": 7,
        "deletions": 5,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/filter_policy.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/filter_policy.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/filter_policy.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -18,11 +18,13 @@\n \n #include <string>\n \n+#include \"leveldb/export.h\"\n+\n namespace leveldb {\n \n class Slice;\n \n-class FilterPolicy {\n+class LEVELDB_EXPORT FilterPolicy {\n  public:\n   virtual ~FilterPolicy();\n \n@@ -38,8 +40,8 @@ class FilterPolicy {\n   //\n   // Warning: do not change the initial contents of *dst.  Instead,\n   // append the newly constructed filter to *dst.\n-  virtual void CreateFilter(const Slice* keys, int n, std::string* dst)\n-      const = 0;\n+  virtual void CreateFilter(const Slice* keys, int n,\n+                            std::string* dst) const = 0;\n \n   // \"filter\" contains the data appended by a preceding call to\n   // CreateFilter() on this class.  This method must return true if\n@@ -63,8 +65,8 @@ class FilterPolicy {\n // ignores trailing spaces, it would be incorrect to use a\n // FilterPolicy (like NewBloomFilterPolicy) that does not ignore\n // trailing spaces in keys.\n-extern const FilterPolicy* NewBloomFilterPolicy(int bits_per_key);\n+LEVELDB_EXPORT const FilterPolicy* NewBloomFilterPolicy(int bits_per_key);\n \n-}\n+}  // namespace leveldb\n \n #endif  // STORAGE_LEVELDB_INCLUDE_FILTER_POLICY_H_"
      },
      {
        "sha": "bb9a5df8f54a798654b82fdd2bd0bae61620eb61",
        "filename": "include/leveldb/iterator.h",
        "status": "modified",
        "additions": 23,
        "deletions": 11,
        "changes": 34,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/iterator.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/iterator.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/iterator.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -15,14 +15,19 @@\n #ifndef STORAGE_LEVELDB_INCLUDE_ITERATOR_H_\n #define STORAGE_LEVELDB_INCLUDE_ITERATOR_H_\n \n+#include \"leveldb/export.h\"\n #include \"leveldb/slice.h\"\n #include \"leveldb/status.h\"\n \n namespace leveldb {\n \n-class Iterator {\n+class LEVELDB_EXPORT Iterator {\n  public:\n   Iterator();\n+\n+  Iterator(const Iterator&) = delete;\n+  Iterator& operator=(const Iterator&) = delete;\n+\n   virtual ~Iterator();\n \n   // An iterator is either positioned at a key/value pair, or\n@@ -72,28 +77,35 @@ class Iterator {\n   //\n   // Note that unlike all of the preceding methods, this method is\n   // not abstract and therefore clients should not override it.\n-  typedef void (*CleanupFunction)(void* arg1, void* arg2);\n+  using CleanupFunction = void (*)(void* arg1, void* arg2);\n   void RegisterCleanup(CleanupFunction function, void* arg1, void* arg2);\n \n  private:\n-  struct Cleanup {\n+  // Cleanup functions are stored in a single-linked list.\n+  // The list's head node is inlined in the iterator.\n+  struct CleanupNode {\n+    // True if the node is not used. Only head nodes might be unused.\n+    bool IsEmpty() const { return function == nullptr; }\n+    // Invokes the cleanup function.\n+    void Run() {\n+      assert(function != nullptr);\n+      (*function)(arg1, arg2);\n+    }\n+\n+    // The head node is used if the function pointer is not null.\n     CleanupFunction function;\n     void* arg1;\n     void* arg2;\n-    Cleanup* next;\n+    CleanupNode* next;\n   };\n-  Cleanup cleanup_;\n-\n-  // No copying allowed\n-  Iterator(const Iterator&);\n-  void operator=(const Iterator&);\n+  CleanupNode cleanup_head_;\n };\n \n // Return an empty iterator (yields nothing).\n-extern Iterator* NewEmptyIterator();\n+LEVELDB_EXPORT Iterator* NewEmptyIterator();\n \n // Return an empty iterator with the specified status.\n-extern Iterator* NewErrorIterator(const Status& status);\n+LEVELDB_EXPORT Iterator* NewErrorIterator(const Status& status);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "b7487726bcac7929d4c2a591cd1c1c5c06ea4ab0",
        "filename": "include/leveldb/options.h",
        "status": "modified",
        "additions": 37,
        "deletions": 63,
        "changes": 100,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/options.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/options.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/options.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -7,6 +7,8 @@\n \n #include <stddef.h>\n \n+#include \"leveldb/export.h\"\n+\n namespace leveldb {\n \n class Cache;\n@@ -23,12 +25,15 @@ class Snapshot;\n enum CompressionType {\n   // NOTE: do not change the values of existing entries, as these are\n   // part of the persistent format on disk.\n-  kNoCompression     = 0x0,\n+  kNoCompression = 0x0,\n   kSnappyCompression = 0x1\n };\n \n // Options to control the behavior of a database (passed to DB::Open)\n-struct Options {\n+struct LEVELDB_EXPORT Options {\n+  // Create an Options object with default values for all fields.\n+  Options();\n+\n   // -------------------\n   // Parameters that affect behavior\n \n@@ -41,31 +46,27 @@ struct Options {\n   const Comparator* comparator;\n \n   // If true, the database will be created if it is missing.\n-  // Default: false\n-  bool create_if_missing;\n+  bool create_if_missing = false;\n \n   // If true, an error is raised if the database already exists.\n-  // Default: false\n-  bool error_if_exists;\n+  bool error_if_exists = false;\n \n   // If true, the implementation will do aggressive checking of the\n   // data it is processing and will stop early if it detects any\n   // errors.  This may have unforeseen ramifications: for example, a\n   // corruption of one DB entry may cause a large number of entries to\n   // become unreadable or for the entire DB to become unopenable.\n-  // Default: false\n-  bool paranoid_checks;\n+  bool paranoid_checks = false;\n \n   // Use the specified object to interact with the environment,\n   // e.g. to read/write files, schedule background work, etc.\n   // Default: Env::Default()\n   Env* env;\n \n   // Any internal progress/error information generated by the db will\n-  // be written to info_log if it is non-NULL, or to a file stored\n-  // in the same directory as the DB contents if info_log is NULL.\n-  // Default: NULL\n-  Logger* info_log;\n+  // be written to info_log if it is non-null, or to a file stored\n+  // in the same directory as the DB contents if info_log is null.\n+  Logger* info_log = nullptr;\n \n   // -------------------\n   // Parameters that affect performance\n@@ -78,39 +79,30 @@ struct Options {\n   // so you may wish to adjust this parameter to control memory usage.\n   // Also, a larger write buffer will result in a longer recovery time\n   // the next time the database is opened.\n-  //\n-  // Default: 4MB\n-  size_t write_buffer_size;\n+  size_t write_buffer_size = 4 * 1024 * 1024;\n \n   // Number of open files that can be used by the DB.  You may need to\n   // increase this if your database has a large working set (budget\n   // one open file per 2MB of working set).\n-  //\n-  // Default: 1000\n-  int max_open_files;\n+  int max_open_files = 1000;\n \n   // Control over blocks (user data is stored in a set of blocks, and\n   // a block is the unit of reading from disk).\n \n-  // If non-NULL, use the specified cache for blocks.\n-  // If NULL, leveldb will automatically create and use an 8MB internal cache.\n-  // Default: NULL\n-  Cache* block_cache;\n+  // If non-null, use the specified cache for blocks.\n+  // If null, leveldb will automatically create and use an 8MB internal cache.\n+  Cache* block_cache = nullptr;\n \n   // Approximate size of user data packed per block.  Note that the\n   // block size specified here corresponds to uncompressed data.  The\n   // actual size of the unit read from disk may be smaller if\n   // compression is enabled.  This parameter can be changed dynamically.\n-  //\n-  // Default: 4K\n-  size_t block_size;\n+  size_t block_size = 4 * 1024;\n \n   // Number of keys between restart points for delta encoding of keys.\n   // This parameter can be changed dynamically.  Most clients should\n   // leave this parameter alone.\n-  //\n-  // Default: 16\n-  int block_restart_interval;\n+  int block_restart_interval = 16;\n \n   // Leveldb will write up to this amount of bytes to a file before\n   // switching to a new one.\n@@ -120,9 +112,7 @@ struct Options {\n   // compactions and hence longer latency/performance hiccups.\n   // Another reason to increase this parameter might be when you are\n   // initially populating a large database.\n-  //\n-  // Default: 2MB\n-  size_t max_file_size;\n+  size_t max_file_size = 2 * 1024 * 1024;\n \n   // Compress blocks using the specified compression algorithm.  This\n   // parameter can be changed dynamically.\n@@ -138,53 +128,43 @@ struct Options {\n   // worth switching to kNoCompression.  Even if the input data is\n   // incompressible, the kSnappyCompression implementation will\n   // efficiently detect that and will switch to uncompressed mode.\n-  CompressionType compression;\n+  CompressionType compression = kSnappyCompression;\n \n   // EXPERIMENTAL: If true, append to existing MANIFEST and log files\n   // when a database is opened.  This can significantly speed up open.\n   //\n   // Default: currently false, but may become true later.\n-  bool reuse_logs;\n+  bool reuse_logs = false;\n \n-  // If non-NULL, use the specified filter policy to reduce disk reads.\n+  // If non-null, use the specified filter policy to reduce disk reads.\n   // Many applications will benefit from passing the result of\n   // NewBloomFilterPolicy() here.\n-  //\n-  // Default: NULL\n-  const FilterPolicy* filter_policy;\n-\n-  // Create an Options object with default values for all fields.\n-  Options();\n+  const FilterPolicy* filter_policy = nullptr;\n };\n \n // Options that control read operations\n-struct ReadOptions {\n+struct LEVELDB_EXPORT ReadOptions {\n+  ReadOptions() = default;\n+\n   // If true, all data read from underlying storage will be\n   // verified against corresponding checksums.\n-  // Default: false\n-  bool verify_checksums;\n+  bool verify_checksums = false;\n \n   // Should the data read for this iteration be cached in memory?\n   // Callers may wish to set this field to false for bulk scans.\n-  // Default: true\n-  bool fill_cache;\n+  bool fill_cache = true;\n \n-  // If \"snapshot\" is non-NULL, read as of the supplied snapshot\n+  // If \"snapshot\" is non-null, read as of the supplied snapshot\n   // (which must belong to the DB that is being read and which must\n-  // not have been released).  If \"snapshot\" is NULL, use an implicit\n+  // not have been released).  If \"snapshot\" is null, use an implicit\n   // snapshot of the state at the beginning of this read operation.\n-  // Default: NULL\n-  const Snapshot* snapshot;\n-\n-  ReadOptions()\n-      : verify_checksums(false),\n-        fill_cache(true),\n-        snapshot(NULL) {\n-  }\n+  const Snapshot* snapshot = nullptr;\n };\n \n // Options that control write operations\n-struct WriteOptions {\n+struct LEVELDB_EXPORT WriteOptions {\n+  WriteOptions() = default;\n+\n   // If true, the write will be flushed from the operating system\n   // buffer cache (by calling WritableFile::Sync()) before the write\n   // is considered complete.  If this flag is true, writes will be\n@@ -199,13 +179,7 @@ struct WriteOptions {\n   // crash semantics as the \"write()\" system call.  A DB write\n   // with sync==true has similar crash semantics to a \"write()\"\n   // system call followed by \"fsync()\".\n-  //\n-  // Default: false\n-  bool sync;\n-\n-  WriteOptions()\n-      : sync(false) {\n-  }\n+  bool sync = false;\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "2df417dc3135865ee267ce30d72fad6e8bf00908",
        "filename": "include/leveldb/slice.h",
        "status": "modified",
        "additions": 22,
        "deletions": 16,
        "changes": 38,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/slice.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/slice.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/slice.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -18,23 +18,30 @@\n #include <assert.h>\n #include <stddef.h>\n #include <string.h>\n+\n #include <string>\n \n+#include \"leveldb/export.h\"\n+\n namespace leveldb {\n \n-class Slice {\n+class LEVELDB_EXPORT Slice {\n  public:\n   // Create an empty slice.\n-  Slice() : data_(\"\"), size_(0) { }\n+  Slice() : data_(\"\"), size_(0) {}\n \n   // Create a slice that refers to d[0,n-1].\n-  Slice(const char* d, size_t n) : data_(d), size_(n) { }\n+  Slice(const char* d, size_t n) : data_(d), size_(n) {}\n \n   // Create a slice that refers to the contents of \"s\"\n-  Slice(const std::string& s) : data_(s.data()), size_(s.size()) { }\n+  Slice(const std::string& s) : data_(s.data()), size_(s.size()) {}\n \n   // Create a slice that refers to s[0,strlen(s)-1]\n-  Slice(const char* s) : data_(s), size_(strlen(s)) { }\n+  Slice(const char* s) : data_(s), size_(strlen(s)) {}\n+\n+  // Intentionally copyable.\n+  Slice(const Slice&) = default;\n+  Slice& operator=(const Slice&) = default;\n \n   // Return a pointer to the beginning of the referenced data\n   const char* data() const { return data_; }\n@@ -53,7 +60,10 @@ class Slice {\n   }\n \n   // Change this slice to refer to an empty array\n-  void clear() { data_ = \"\"; size_ = 0; }\n+  void clear() {\n+    data_ = \"\";\n+    size_ = 0;\n+  }\n \n   // Drop the first \"n\" bytes from this slice.\n   void remove_prefix(size_t n) {\n@@ -73,37 +83,33 @@ class Slice {\n \n   // Return true iff \"x\" is a prefix of \"*this\"\n   bool starts_with(const Slice& x) const {\n-    return ((size_ >= x.size_) &&\n-            (memcmp(data_, x.data_, x.size_) == 0));\n+    return ((size_ >= x.size_) && (memcmp(data_, x.data_, x.size_) == 0));\n   }\n \n  private:\n   const char* data_;\n   size_t size_;\n-\n-  // Intentionally copyable\n };\n \n inline bool operator==(const Slice& x, const Slice& y) {\n   return ((x.size() == y.size()) &&\n           (memcmp(x.data(), y.data(), x.size()) == 0));\n }\n \n-inline bool operator!=(const Slice& x, const Slice& y) {\n-  return !(x == y);\n-}\n+inline bool operator!=(const Slice& x, const Slice& y) { return !(x == y); }\n \n inline int Slice::compare(const Slice& b) const {\n   const size_t min_len = (size_ < b.size_) ? size_ : b.size_;\n   int r = memcmp(data_, b.data_, min_len);\n   if (r == 0) {\n-    if (size_ < b.size_) r = -1;\n-    else if (size_ > b.size_) r = +1;\n+    if (size_ < b.size_)\n+      r = -1;\n+    else if (size_ > b.size_)\n+      r = +1;\n   }\n   return r;\n }\n \n }  // namespace leveldb\n \n-\n #endif  // STORAGE_LEVELDB_INCLUDE_SLICE_H_"
      },
      {
        "sha": "e3273144e481174cee99c1db73bef9ca6925f46a",
        "filename": "include/leveldb/status.h",
        "status": "modified",
        "additions": 31,
        "deletions": 21,
        "changes": 52,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/status.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/status.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/status.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -13,20 +13,25 @@\n #ifndef STORAGE_LEVELDB_INCLUDE_STATUS_H_\n #define STORAGE_LEVELDB_INCLUDE_STATUS_H_\n \n+#include <algorithm>\n #include <string>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/slice.h\"\n \n namespace leveldb {\n \n-class Status {\n+class LEVELDB_EXPORT Status {\n  public:\n   // Create a success status.\n-  Status() : state_(NULL) { }\n+  Status() noexcept : state_(nullptr) {}\n   ~Status() { delete[] state_; }\n \n-  // Copy the specified status.\n-  Status(const Status& s);\n-  void operator=(const Status& s);\n+  Status(const Status& rhs);\n+  Status& operator=(const Status& rhs);\n+\n+  Status(Status&& rhs) noexcept : state_(rhs.state_) { rhs.state_ = nullptr; }\n+  Status& operator=(Status&& rhs) noexcept;\n \n   // Return a success status.\n   static Status OK() { return Status(); }\n@@ -49,7 +54,7 @@ class Status {\n   }\n \n   // Returns true iff the status indicates success.\n-  bool ok() const { return (state_ == NULL); }\n+  bool ok() const { return (state_ == nullptr); }\n \n   // Returns true iff the status indicates a NotFound error.\n   bool IsNotFound() const { return code() == kNotFound; }\n@@ -71,13 +76,6 @@ class Status {\n   std::string ToString() const;\n \n  private:\n-  // OK status has a NULL state_.  Otherwise, state_ is a new[] array\n-  // of the following form:\n-  //    state_[0..3] == length of message\n-  //    state_[4]    == code\n-  //    state_[5..]  == message\n-  const char* state_;\n-\n   enum Code {\n     kOk = 0,\n     kNotFound = 1,\n@@ -88,23 +86,35 @@ class Status {\n   };\n \n   Code code() const {\n-    return (state_ == NULL) ? kOk : static_cast<Code>(state_[4]);\n+    return (state_ == nullptr) ? kOk : static_cast<Code>(state_[4]);\n   }\n \n   Status(Code code, const Slice& msg, const Slice& msg2);\n   static const char* CopyState(const char* s);\n+\n+  // OK status has a null state_.  Otherwise, state_ is a new[] array\n+  // of the following form:\n+  //    state_[0..3] == length of message\n+  //    state_[4]    == code\n+  //    state_[5..]  == message\n+  const char* state_;\n };\n \n-inline Status::Status(const Status& s) {\n-  state_ = (s.state_ == NULL) ? NULL : CopyState(s.state_);\n+inline Status::Status(const Status& rhs) {\n+  state_ = (rhs.state_ == nullptr) ? nullptr : CopyState(rhs.state_);\n }\n-inline void Status::operator=(const Status& s) {\n-  // The following condition catches both aliasing (when this == &s),\n-  // and the common case where both s and *this are ok.\n-  if (state_ != s.state_) {\n+inline Status& Status::operator=(const Status& rhs) {\n+  // The following condition catches both aliasing (when this == &rhs),\n+  // and the common case where both rhs and *this are ok.\n+  if (state_ != rhs.state_) {\n     delete[] state_;\n-    state_ = (s.state_ == NULL) ? NULL : CopyState(s.state_);\n+    state_ = (rhs.state_ == nullptr) ? nullptr : CopyState(rhs.state_);\n   }\n+  return *this;\n+}\n+inline Status& Status::operator=(Status&& rhs) noexcept {\n+  std::swap(state_, rhs.state_);\n+  return *this;\n }\n \n }  // namespace leveldb"
      },
      {
        "sha": "25c601311648b40842b268b3dd27e409c45908f4",
        "filename": "include/leveldb/table.h",
        "status": "modified",
        "additions": 16,
        "deletions": 17,
        "changes": 33,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/table.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/table.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/table.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -6,6 +6,8 @@\n #define STORAGE_LEVELDB_INCLUDE_TABLE_H_\n \n #include <stdint.h>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/iterator.h\"\n \n namespace leveldb {\n@@ -21,7 +23,7 @@ class TableCache;\n // A Table is a sorted map from strings to strings.  Tables are\n // immutable and persistent.  A Table may be safely accessed from\n // multiple threads without external synchronization.\n-class Table {\n+class LEVELDB_EXPORT Table {\n  public:\n   // Attempt to open the table that is stored in bytes [0..file_size)\n   // of \"file\", and read the metadata entries necessary to allow\n@@ -30,15 +32,16 @@ class Table {\n   // If successful, returns ok and sets \"*table\" to the newly opened\n   // table.  The client should delete \"*table\" when no longer needed.\n   // If there was an error while initializing the table, sets \"*table\"\n-  // to NULL and returns a non-ok status.  Does not take ownership of\n+  // to nullptr and returns a non-ok status.  Does not take ownership of\n   // \"*source\", but the client must ensure that \"source\" remains live\n   // for the duration of the returned table's lifetime.\n   //\n   // *file must remain live while this Table is in use.\n-  static Status Open(const Options& options,\n-                     RandomAccessFile* file,\n-                     uint64_t file_size,\n-                     Table** table);\n+  static Status Open(const Options& options, RandomAccessFile* file,\n+                     uint64_t file_size, Table** table);\n+\n+  Table(const Table&) = delete;\n+  Table& operator=(const Table&) = delete;\n \n   ~Table();\n \n@@ -56,28 +59,24 @@ class Table {\n   uint64_t ApproximateOffsetOf(const Slice& key) const;\n \n  private:\n+  friend class TableCache;\n   struct Rep;\n-  Rep* rep_;\n \n-  explicit Table(Rep* rep) { rep_ = rep; }\n   static Iterator* BlockReader(void*, const ReadOptions&, const Slice&);\n \n+  explicit Table(Rep* rep) : rep_(rep) {}\n+\n   // Calls (*handle_result)(arg, ...) with the entry found after a call\n   // to Seek(key).  May not make such a call if filter policy says\n   // that key is not present.\n-  friend class TableCache;\n-  Status InternalGet(\n-      const ReadOptions&, const Slice& key,\n-      void* arg,\n-      void (*handle_result)(void* arg, const Slice& k, const Slice& v));\n-\n+  Status InternalGet(const ReadOptions&, const Slice& key, void* arg,\n+                     void (*handle_result)(void* arg, const Slice& k,\n+                                           const Slice& v));\n \n   void ReadMeta(const Footer& footer);\n   void ReadFilter(const Slice& filter_handle_value);\n \n-  // No copying allowed\n-  Table(const Table&);\n-  void operator=(const Table&);\n+  Rep* const rep_;\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "7d8896bb89c4a0f8ba24bc18314af4a37fde18ac",
        "filename": "include/leveldb/table_builder.h",
        "status": "modified",
        "additions": 6,
        "deletions": 5,
        "changes": 11,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/table_builder.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/table_builder.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/table_builder.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -14,6 +14,8 @@\n #define STORAGE_LEVELDB_INCLUDE_TABLE_BUILDER_H_\n \n #include <stdint.h>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/options.h\"\n #include \"leveldb/status.h\"\n \n@@ -23,13 +25,16 @@ class BlockBuilder;\n class BlockHandle;\n class WritableFile;\n \n-class TableBuilder {\n+class LEVELDB_EXPORT TableBuilder {\n  public:\n   // Create a builder that will store the contents of the table it is\n   // building in *file.  Does not close the file.  It is up to the\n   // caller to close the file after calling Finish().\n   TableBuilder(const Options& options, WritableFile* file);\n \n+  TableBuilder(const TableBuilder&) = delete;\n+  TableBuilder& operator=(const TableBuilder&) = delete;\n+\n   // REQUIRES: Either Finish() or Abandon() has been called.\n   ~TableBuilder();\n \n@@ -81,10 +86,6 @@ class TableBuilder {\n \n   struct Rep;\n   Rep* rep_;\n-\n-  // No copying allowed\n-  TableBuilder(const TableBuilder&);\n-  void operator=(const TableBuilder&);\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "94d4115fed5a2dccc6450d84d0df53bcac7624e3",
        "filename": "include/leveldb/write_batch.h",
        "status": "modified",
        "additions": 28,
        "deletions": 9,
        "changes": 37,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/write_batch.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/include/leveldb/write_batch.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/leveldb/write_batch.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -22,15 +22,29 @@\n #define STORAGE_LEVELDB_INCLUDE_WRITE_BATCH_H_\n \n #include <string>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/status.h\"\n \n namespace leveldb {\n \n class Slice;\n \n-class WriteBatch {\n+class LEVELDB_EXPORT WriteBatch {\n  public:\n+  class LEVELDB_EXPORT Handler {\n+   public:\n+    virtual ~Handler();\n+    virtual void Put(const Slice& key, const Slice& value) = 0;\n+    virtual void Delete(const Slice& key) = 0;\n+  };\n+\n   WriteBatch();\n+\n+  // Intentionally copyable.\n+  WriteBatch(const WriteBatch&) = default;\n+  WriteBatch& operator=(const WriteBatch&) = default;\n+\n   ~WriteBatch();\n \n   // Store the mapping \"key->value\" in the database.\n@@ -42,21 +56,26 @@ class WriteBatch {\n   // Clear all updates buffered in this batch.\n   void Clear();\n \n+  // The size of the database changes caused by this batch.\n+  //\n+  // This number is tied to implementation details, and may change across\n+  // releases. It is intended for LevelDB usage metrics.\n+  size_t ApproximateSize() const;\n+\n+  // Copies the operations in \"source\" to this batch.\n+  //\n+  // This runs in O(source size) time. However, the constant factor is better\n+  // than calling Iterate() over the source batch with a Handler that replicates\n+  // the operations into this batch.\n+  void Append(const WriteBatch& source);\n+\n   // Support for iterating over the contents of a batch.\n-  class Handler {\n-   public:\n-    virtual ~Handler();\n-    virtual void Put(const Slice& key, const Slice& value) = 0;\n-    virtual void Delete(const Slice& key) = 0;\n-  };\n   Status Iterate(Handler* handler) const;\n \n  private:\n   friend class WriteBatchInternal;\n \n   std::string rep_;  // See comment in write_batch.cc for the format of rep_\n-\n-  // Intentionally copyable\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "d50ffeb9d4185de40801404007821f0193ca6a2e",
        "filename": "issues/issue178_test.cc",
        "status": "modified",
        "additions": 4,
        "deletions": 8,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/issues/issue178_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/issues/issue178_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/issues/issue178_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -3,9 +3,9 @@\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n // Test for issue 178: a manual compaction causes deleted data to reappear.\n+#include <cstdlib>\n #include <iostream>\n #include <sstream>\n-#include <cstdlib>\n \n #include \"leveldb/db.h\"\n #include \"leveldb/write_batch.h\"\n@@ -21,11 +21,9 @@ std::string Key1(int i) {\n   return buf;\n }\n \n-std::string Key2(int i) {\n-  return Key1(i) + \"_xxx\";\n-}\n+std::string Key2(int i) { return Key1(i) + \"_xxx\"; }\n \n-class Issue178 { };\n+class Issue178 {};\n \n TEST(Issue178, Test) {\n   // Get rid of any state from an old run.\n@@ -87,6 +85,4 @@ TEST(Issue178, Test) {\n \n }  // anonymous namespace\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "877b2afc47458147ebc0c8342001f9c8f53f8573",
        "filename": "issues/issue200_test.cc",
        "status": "modified",
        "additions": 4,
        "deletions": 6,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/issues/issue200_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/issues/issue200_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/issues/issue200_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -11,14 +11,14 @@\n \n namespace leveldb {\n \n-class Issue200 { };\n+class Issue200 {};\n \n TEST(Issue200, Test) {\n   // Get rid of any state from an old run.\n   std::string dbpath = test::TmpDir() + \"/leveldb_issue200_test\";\n   DestroyDB(dbpath, Options());\n \n-  DB *db;\n+  DB* db;\n   Options options;\n   options.create_if_missing = true;\n   ASSERT_OK(DB::Open(options, dbpath, &db));\n@@ -31,7 +31,7 @@ TEST(Issue200, Test) {\n   ASSERT_OK(db->Put(write_options, \"5\", \"f\"));\n \n   ReadOptions read_options;\n-  Iterator *iter = db->NewIterator(read_options);\n+  Iterator* iter = db->NewIterator(read_options);\n \n   // Add an element that should not be reflected in the iterator.\n   ASSERT_OK(db->Put(write_options, \"25\", \"cd\"));\n@@ -54,6 +54,4 @@ TEST(Issue200, Test) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "c5fcbfc6e76492e6fe38bfc3eda6db12476f98a0",
        "filename": "issues/issue320_test.cc",
        "status": "added",
        "additions": 128,
        "deletions": 0,
        "changes": 128,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/issues/issue320_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/issues/issue320_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/issues/issue320_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -0,0 +1,128 @@\n+// Copyright (c) 2019 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include <cstdint>\n+#include <cstdlib>\n+#include <iostream>\n+#include <memory>\n+#include <string>\n+#include <vector>\n+\n+#include \"leveldb/db.h\"\n+#include \"leveldb/write_batch.h\"\n+#include \"util/testharness.h\"\n+\n+namespace leveldb {\n+\n+namespace {\n+\n+// Creates a random number in the range of [0, max).\n+int GenerateRandomNumber(int max) { return std::rand() % max; }\n+\n+std::string CreateRandomString(int32_t index) {\n+  static const size_t len = 1024;\n+  char bytes[len];\n+  size_t i = 0;\n+  while (i < 8) {\n+    bytes[i] = 'a' + ((index >> (4 * i)) & 0xf);\n+    ++i;\n+  }\n+  while (i < sizeof(bytes)) {\n+    bytes[i] = 'a' + GenerateRandomNumber(26);\n+    ++i;\n+  }\n+  return std::string(bytes, sizeof(bytes));\n+}\n+\n+}  // namespace\n+\n+class Issue320 {};\n+\n+TEST(Issue320, Test) {\n+  std::srand(0);\n+\n+  bool delete_before_put = false;\n+  bool keep_snapshots = true;\n+\n+  std::vector<std::unique_ptr<std::pair<std::string, std::string>>> test_map(\n+      10000);\n+  std::vector<Snapshot const*> snapshots(100, nullptr);\n+\n+  DB* db;\n+  Options options;\n+  options.create_if_missing = true;\n+\n+  std::string dbpath = test::TmpDir() + \"/leveldb_issue320_test\";\n+  ASSERT_OK(DB::Open(options, dbpath, &db));\n+\n+  uint32_t target_size = 10000;\n+  uint32_t num_items = 0;\n+  uint32_t count = 0;\n+  std::string key;\n+  std::string value, old_value;\n+\n+  WriteOptions writeOptions;\n+  ReadOptions readOptions;\n+  while (count < 200000) {\n+    if ((++count % 1000) == 0) {\n+      std::cout << \"count: \" << count << std::endl;\n+    }\n+\n+    int index = GenerateRandomNumber(test_map.size());\n+    WriteBatch batch;\n+\n+    if (test_map[index] == nullptr) {\n+      num_items++;\n+      test_map[index].reset(new std::pair<std::string, std::string>(\n+          CreateRandomString(index), CreateRandomString(index)));\n+      batch.Put(test_map[index]->first, test_map[index]->second);\n+    } else {\n+      ASSERT_OK(db->Get(readOptions, test_map[index]->first, &old_value));\n+      if (old_value != test_map[index]->second) {\n+        std::cout << \"ERROR incorrect value returned by Get\" << std::endl;\n+        std::cout << \"  count=\" << count << std::endl;\n+        std::cout << \"  old value=\" << old_value << std::endl;\n+        std::cout << \"  test_map[index]->second=\" << test_map[index]->second\n+                  << std::endl;\n+        std::cout << \"  test_map[index]->first=\" << test_map[index]->first\n+                  << std::endl;\n+        std::cout << \"  index=\" << index << std::endl;\n+        ASSERT_EQ(old_value, test_map[index]->second);\n+      }\n+\n+      if (num_items >= target_size && GenerateRandomNumber(100) > 30) {\n+        batch.Delete(test_map[index]->first);\n+        test_map[index] = nullptr;\n+        --num_items;\n+      } else {\n+        test_map[index]->second = CreateRandomString(index);\n+        if (delete_before_put) batch.Delete(test_map[index]->first);\n+        batch.Put(test_map[index]->first, test_map[index]->second);\n+      }\n+    }\n+\n+    ASSERT_OK(db->Write(writeOptions, &batch));\n+\n+    if (keep_snapshots && GenerateRandomNumber(10) == 0) {\n+      int i = GenerateRandomNumber(snapshots.size());\n+      if (snapshots[i] != nullptr) {\n+        db->ReleaseSnapshot(snapshots[i]);\n+      }\n+      snapshots[i] = db->GetSnapshot();\n+    }\n+  }\n+\n+  for (Snapshot const* snapshot : snapshots) {\n+    if (snapshot) {\n+      db->ReleaseSnapshot(snapshot);\n+    }\n+  }\n+\n+  delete db;\n+  DestroyDB(dbpath, options);\n+}\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "8b171532e153e072f131152ab03c7e5a2a232e9f",
        "filename": "port/README.md",
        "status": "renamed",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/port/README.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/port/README.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/README.md?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -5,6 +5,6 @@ Code in the rest of the package includes \"port.h\" from this directory.\n \"port.h\" in turn includes a platform specific \"port_<platform>.h\" file\n that provides the platform specific implementation.\n \n-See port_posix.h for an example of what must be provided in a platform\n+See port_stdcxx.h for an example of what must be provided in a platform\n specific header file.\n ",
        "previous_filename": "port/README"
      },
      {
        "sha": "d79a02230d57fe085949936b26b9a7af413e07b8",
        "filename": "port/atomic_pointer.h",
        "status": "removed",
        "additions": 0,
        "deletions": 245,
        "changes": 245,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/atomic_pointer.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/atomic_pointer.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/atomic_pointer.h?ref=4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "patch": "@@ -1,245 +0,0 @@\n-// Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-\n-// AtomicPointer provides storage for a lock-free pointer.\n-// Platform-dependent implementation of AtomicPointer:\n-// - If the platform provides a cheap barrier, we use it with raw pointers\n-// - If <atomic> is present (on newer versions of gcc, it is), we use\n-//   a <atomic>-based AtomicPointer.  However we prefer the memory\n-//   barrier based version, because at least on a gcc 4.4 32-bit build\n-//   on linux, we have encountered a buggy <atomic> implementation.\n-//   Also, some <atomic> implementations are much slower than a memory-barrier\n-//   based implementation (~16ns for <atomic> based acquire-load vs. ~1ns for\n-//   a barrier based acquire-load).\n-// This code is based on atomicops-internals-* in Google's perftools:\n-// http://code.google.com/p/google-perftools/source/browse/#svn%2Ftrunk%2Fsrc%2Fbase\n-\n-#ifndef PORT_ATOMIC_POINTER_H_\n-#define PORT_ATOMIC_POINTER_H_\n-\n-#include <stdint.h>\n-#ifdef LEVELDB_ATOMIC_PRESENT\n-#include <atomic>\n-#endif\n-#ifdef OS_WIN\n-#include <windows.h>\n-#endif\n-#ifdef OS_MACOSX\n-#include <libkern/OSAtomic.h>\n-#endif\n-\n-#if defined(_M_X64) || defined(__x86_64__)\n-#define ARCH_CPU_X86_FAMILY 1\n-#elif defined(_M_IX86) || defined(__i386__) || defined(__i386)\n-#define ARCH_CPU_X86_FAMILY 1\n-#elif defined(__ARMEL__)\n-#define ARCH_CPU_ARM_FAMILY 1\n-#elif defined(__aarch64__)\n-#define ARCH_CPU_ARM64_FAMILY 1\n-#elif defined(__ppc__) || defined(__powerpc__) || defined(__powerpc64__)\n-#define ARCH_CPU_PPC_FAMILY 1\n-#elif defined(__mips__)\n-#define ARCH_CPU_MIPS_FAMILY 1\n-#endif\n-\n-namespace leveldb {\n-namespace port {\n-\n-// AtomicPointer based on <cstdatomic> if available\n-#if defined(LEVELDB_ATOMIC_PRESENT)\n-class AtomicPointer {\n- private:\n-  std::atomic<void*> rep_;\n- public:\n-  AtomicPointer() { }\n-  explicit AtomicPointer(void* v) : rep_(v) { }\n-  inline void* Acquire_Load() const {\n-    return rep_.load(std::memory_order_acquire);\n-  }\n-  inline void Release_Store(void* v) {\n-    rep_.store(v, std::memory_order_release);\n-  }\n-  inline void* NoBarrier_Load() const {\n-    return rep_.load(std::memory_order_relaxed);\n-  }\n-  inline void NoBarrier_Store(void* v) {\n-    rep_.store(v, std::memory_order_relaxed);\n-  }\n-};\n-\n-#else\n-\n-// Define MemoryBarrier() if available\n-// Windows on x86\n-#if defined(OS_WIN) && defined(COMPILER_MSVC) && defined(ARCH_CPU_X86_FAMILY)\n-// windows.h already provides a MemoryBarrier(void) macro\n-// http://msdn.microsoft.com/en-us/library/ms684208(v=vs.85).aspx\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// Mac OS\n-#elif defined(OS_MACOSX)\n-inline void MemoryBarrier() {\n-  OSMemoryBarrier();\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// Gcc on x86\n-#elif defined(ARCH_CPU_X86_FAMILY) && defined(__GNUC__)\n-inline void MemoryBarrier() {\n-  // See http://gcc.gnu.org/ml/gcc/2003-04/msg01180.html for a discussion on\n-  // this idiom. Also see http://en.wikipedia.org/wiki/Memory_ordering.\n-  __asm__ __volatile__(\"\" : : : \"memory\");\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// Sun Studio\n-#elif defined(ARCH_CPU_X86_FAMILY) && defined(__SUNPRO_CC)\n-inline void MemoryBarrier() {\n-  // See http://gcc.gnu.org/ml/gcc/2003-04/msg01180.html for a discussion on\n-  // this idiom. Also see http://en.wikipedia.org/wiki/Memory_ordering.\n-  asm volatile(\"\" : : : \"memory\");\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// ARM Linux\n-#elif defined(ARCH_CPU_ARM_FAMILY) && defined(__linux__)\n-typedef void (*LinuxKernelMemoryBarrierFunc)(void);\n-// The Linux ARM kernel provides a highly optimized device-specific memory\n-// barrier function at a fixed memory address that is mapped in every\n-// user-level process.\n-//\n-// This beats using CPU-specific instructions which are, on single-core\n-// devices, un-necessary and very costly (e.g. ARMv7-A \"dmb\" takes more\n-// than 180ns on a Cortex-A8 like the one on a Nexus One). Benchmarking\n-// shows that the extra function call cost is completely negligible on\n-// multi-core devices.\n-//\n-inline void MemoryBarrier() {\n-  (*(LinuxKernelMemoryBarrierFunc)0xffff0fa0)();\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// ARM64\n-#elif defined(ARCH_CPU_ARM64_FAMILY)\n-inline void MemoryBarrier() {\n-  asm volatile(\"dmb sy\" : : : \"memory\");\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// PPC\n-#elif defined(ARCH_CPU_PPC_FAMILY) && defined(__GNUC__)\n-inline void MemoryBarrier() {\n-  // TODO for some powerpc expert: is there a cheaper suitable variant?\n-  // Perhaps by having separate barriers for acquire and release ops.\n-  asm volatile(\"sync\" : : : \"memory\");\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// MIPS\n-#elif defined(ARCH_CPU_MIPS_FAMILY) && defined(__GNUC__)\n-inline void MemoryBarrier() {\n-  __asm__ __volatile__(\"sync\" : : : \"memory\");\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-#endif\n-\n-// AtomicPointer built using platform-specific MemoryBarrier()\n-#if defined(LEVELDB_HAVE_MEMORY_BARRIER)\n-class AtomicPointer {\n- private:\n-  void* rep_;\n- public:\n-  AtomicPointer() { }\n-  explicit AtomicPointer(void* p) : rep_(p) {}\n-  inline void* NoBarrier_Load() const { return rep_; }\n-  inline void NoBarrier_Store(void* v) { rep_ = v; }\n-  inline void* Acquire_Load() const {\n-    void* result = rep_;\n-    MemoryBarrier();\n-    return result;\n-  }\n-  inline void Release_Store(void* v) {\n-    MemoryBarrier();\n-    rep_ = v;\n-  }\n-};\n-\n-// Atomic pointer based on sparc memory barriers\n-#elif defined(__sparcv9) && defined(__GNUC__)\n-class AtomicPointer {\n- private:\n-  void* rep_;\n- public:\n-  AtomicPointer() { }\n-  explicit AtomicPointer(void* v) : rep_(v) { }\n-  inline void* Acquire_Load() const {\n-    void* val;\n-    __asm__ __volatile__ (\n-        \"ldx [%[rep_]], %[val] \\n\\t\"\n-         \"membar #LoadLoad|#LoadStore \\n\\t\"\n-        : [val] \"=r\" (val)\n-        : [rep_] \"r\" (&rep_)\n-        : \"memory\");\n-    return val;\n-  }\n-  inline void Release_Store(void* v) {\n-    __asm__ __volatile__ (\n-        \"membar #LoadStore|#StoreStore \\n\\t\"\n-        \"stx %[v], [%[rep_]] \\n\\t\"\n-        :\n-        : [rep_] \"r\" (&rep_), [v] \"r\" (v)\n-        : \"memory\");\n-  }\n-  inline void* NoBarrier_Load() const { return rep_; }\n-  inline void NoBarrier_Store(void* v) { rep_ = v; }\n-};\n-\n-// Atomic pointer based on ia64 acq/rel\n-#elif defined(__ia64) && defined(__GNUC__)\n-class AtomicPointer {\n- private:\n-  void* rep_;\n- public:\n-  AtomicPointer() { }\n-  explicit AtomicPointer(void* v) : rep_(v) { }\n-  inline void* Acquire_Load() const {\n-    void* val    ;\n-    __asm__ __volatile__ (\n-        \"ld8.acq %[val] = [%[rep_]] \\n\\t\"\n-        : [val] \"=r\" (val)\n-        : [rep_] \"r\" (&rep_)\n-        : \"memory\"\n-        );\n-    return val;\n-  }\n-  inline void Release_Store(void* v) {\n-    __asm__ __volatile__ (\n-        \"st8.rel [%[rep_]] = %[v]  \\n\\t\"\n-        :\n-        : [rep_] \"r\" (&rep_), [v] \"r\" (v)\n-        : \"memory\"\n-        );\n-  }\n-  inline void* NoBarrier_Load() const { return rep_; }\n-  inline void NoBarrier_Store(void* v) { rep_ = v; }\n-};\n-\n-// We have neither MemoryBarrier(), nor <atomic>\n-#else\n-#error Please implement AtomicPointer for this platform.\n-\n-#endif\n-#endif\n-\n-#undef LEVELDB_HAVE_MEMORY_BARRIER\n-#undef ARCH_CPU_X86_FAMILY\n-#undef ARCH_CPU_ARM_FAMILY\n-#undef ARCH_CPU_ARM64_FAMILY\n-#undef ARCH_CPU_PPC_FAMILY\n-\n-}  // namespace port\n-}  // namespace leveldb\n-\n-#endif  // PORT_ATOMIC_POINTER_H_"
      },
      {
        "sha": "4b247f74f9f5b848a5cc3225c23be0dd7726b53e",
        "filename": "port/port.h",
        "status": "modified",
        "additions": 3,
        "deletions": 5,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/port/port.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/port/port.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/port.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -10,12 +10,10 @@\n // Include the appropriate platform specific file below.  If you are\n // porting to a new platform, see \"port_example.h\" for documentation\n // of what the new port_<platform>.h file must provide.\n-#if defined(LEVELDB_PLATFORM_POSIX)\n-#  include \"port/port_posix.h\"\n+#if defined(LEVELDB_PLATFORM_POSIX) || defined(LEVELDB_PLATFORM_WINDOWS)\n+#include \"port/port_stdcxx.h\"\n #elif defined(LEVELDB_PLATFORM_CHROMIUM)\n-#  include \"port/port_chromium.h\"\n-#elif defined(LEVELDB_PLATFORM_WINDOWS)\n-#  include \"port/port_win.h\"\n+#include \"port/port_chromium.h\"\n #endif\n \n #endif  // STORAGE_LEVELDB_PORT_PORT_H_"
      },
      {
        "sha": "21273153a3fed2ef47ef11f89398e5c09fdd06a0",
        "filename": "port/port_config.h.in",
        "status": "added",
        "additions": 39,
        "deletions": 0,
        "changes": 39,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/port/port_config.h.in",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/port/port_config.h.in",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/port_config.h.in?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -0,0 +1,39 @@\n+// Copyright 2017 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef STORAGE_LEVELDB_PORT_PORT_CONFIG_H_\n+#define STORAGE_LEVELDB_PORT_PORT_CONFIG_H_\n+\n+// Define to 1 if you have a definition for fdatasync() in <unistd.h>.\n+#if !defined(HAVE_FDATASYNC)\n+#cmakedefine01 HAVE_FDATASYNC\n+#endif  // !defined(HAVE_FDATASYNC)\n+\n+// Define to 1 if you have a definition for F_FULLFSYNC in <fcntl.h>.\n+#if !defined(HAVE_FULLFSYNC)\n+#cmakedefine01 HAVE_FULLFSYNC\n+#endif  // !defined(HAVE_FULLFSYNC)\n+\n+// Define to 1 if you have a definition for O_CLOEXEC in <fcntl.h>.\n+#if !defined(HAVE_O_CLOEXEC)\n+#cmakedefine01 HAVE_O_CLOEXEC\n+#endif  // !defined(HAVE_O_CLOEXEC)\n+\n+// Define to 1 if you have Google CRC32C.\n+#if !defined(HAVE_CRC32C)\n+#cmakedefine01 HAVE_CRC32C\n+#endif  // !defined(HAVE_CRC32C)\n+\n+// Define to 1 if you have Google Snappy.\n+#if !defined(HAVE_SNAPPY)\n+#cmakedefine01 HAVE_SNAPPY\n+#endif  // !defined(HAVE_SNAPPY)\n+\n+// Define to 1 if your processor stores words with the most significant byte\n+// first (like Motorola and SPARC, unlike Intel and VAX).\n+#if !defined(LEVELDB_IS_BIG_ENDIAN)\n+#cmakedefine01 LEVELDB_IS_BIG_ENDIAN\n+#endif  // !defined(LEVELDB_IS_BIG_ENDIAN)\n+\n+#endif  // STORAGE_LEVELDB_PORT_PORT_CONFIG_H_\n\\ No newline at end of file"
      },
      {
        "sha": "1a8fca24b36cbdcae7dadabd6f19d21a5240cf95",
        "filename": "port/port_example.h",
        "status": "modified",
        "additions": 13,
        "deletions": 54,
        "changes": 67,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/port/port_example.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/port/port_example.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/port_example.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -10,6 +10,8 @@\n #ifndef STORAGE_LEVELDB_PORT_PORT_EXAMPLE_H_\n #define STORAGE_LEVELDB_PORT_PORT_EXAMPLE_H_\n \n+#include \"port/thread_annotations.h\"\n+\n namespace leveldb {\n namespace port {\n \n@@ -23,23 +25,23 @@ static const bool kLittleEndian = true /* or some other expression */;\n // ------------------ Threading -------------------\n \n // A Mutex represents an exclusive lock.\n-class Mutex {\n+class LOCKABLE Mutex {\n  public:\n   Mutex();\n   ~Mutex();\n \n   // Lock the mutex.  Waits until other lockers have exited.\n   // Will deadlock if the mutex is already locked by this thread.\n-  void Lock();\n+  void Lock() EXCLUSIVE_LOCK_FUNCTION();\n \n   // Unlock the mutex.\n   // REQUIRES: This mutex was locked by this thread.\n-  void Unlock();\n+  void Unlock() UNLOCK_FUNCTION();\n \n   // Optionally crash if this thread does not hold this mutex.\n   // The implementation must be fast, especially if NDEBUG is\n   // defined.  The implementation is allowed to skip all checks.\n-  void AssertHeld();\n+  void AssertHeld() ASSERT_EXCLUSIVE_LOCK();\n };\n \n class CondVar {\n@@ -60,57 +62,18 @@ class CondVar {\n   void SignallAll();\n };\n \n-// Thread-safe initialization.\n-// Used as follows:\n-//      static port::OnceType init_control = LEVELDB_ONCE_INIT;\n-//      static void Initializer() { ... do something ...; }\n-//      ...\n-//      port::InitOnce(&init_control, &Initializer);\n-typedef intptr_t OnceType;\n-#define LEVELDB_ONCE_INIT 0\n-extern void InitOnce(port::OnceType*, void (*initializer)());\n-\n-// A type that holds a pointer that can be read or written atomically\n-// (i.e., without word-tearing.)\n-class AtomicPointer {\n- private:\n-  intptr_t rep_;\n- public:\n-  // Initialize to arbitrary value\n-  AtomicPointer();\n-\n-  // Initialize to hold v\n-  explicit AtomicPointer(void* v) : rep_(v) { }\n-\n-  // Read and return the stored pointer with the guarantee that no\n-  // later memory access (read or write) by this thread can be\n-  // reordered ahead of this read.\n-  void* Acquire_Load() const;\n-\n-  // Set v as the stored pointer with the guarantee that no earlier\n-  // memory access (read or write) by this thread can be reordered\n-  // after this store.\n-  void Release_Store(void* v);\n-\n-  // Read the stored pointer with no ordering guarantees.\n-  void* NoBarrier_Load() const;\n-\n-  // Set va as the stored pointer with no ordering guarantees.\n-  void NoBarrier_Store(void* v);\n-};\n-\n // ------------------ Compression -------------------\n \n // Store the snappy compression of \"input[0,input_length-1]\" in *output.\n // Returns false if snappy is not supported by this port.\n-extern bool Snappy_Compress(const char* input, size_t input_length,\n-                            std::string* output);\n+bool Snappy_Compress(const char* input, size_t input_length,\n+                     std::string* output);\n \n // If input[0,input_length-1] looks like a valid snappy compressed\n // buffer, store the size of the uncompressed data in *result and\n // return true.  Else return false.\n-extern bool Snappy_GetUncompressedLength(const char* input, size_t length,\n-                                         size_t* result);\n+bool Snappy_GetUncompressedLength(const char* input, size_t length,\n+                                  size_t* result);\n \n // Attempt to snappy uncompress input[0,input_length-1] into *output.\n // Returns true if successful, false if the input is invalid lightweight\n@@ -119,19 +82,15 @@ extern bool Snappy_GetUncompressedLength(const char* input, size_t length,\n // REQUIRES: at least the first \"n\" bytes of output[] must be writable\n // where \"n\" is the result of a successful call to\n // Snappy_GetUncompressedLength.\n-extern bool Snappy_Uncompress(const char* input_data, size_t input_length,\n-                              char* output);\n+bool Snappy_Uncompress(const char* input_data, size_t input_length,\n+                       char* output);\n \n // ------------------ Miscellaneous -------------------\n \n // If heap profiling is not supported, returns false.\n // Else repeatedly calls (*func)(arg, data, n) and then returns true.\n // The concatenation of all \"data[0,n-1]\" fragments is the heap profile.\n-extern bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg);\n-\n-// Determine whether a working accelerated crc32 implementation exists\n-// Returns true if AcceleratedCRC32C is safe to call\n-bool HasAcceleratedCRC32C();\n+bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg);\n \n // Extend the CRC to include the first n bytes of buf.\n //"
      },
      {
        "sha": "ec39e921957f6507e3eb5f5ed5b6e15fea69e527",
        "filename": "port/port_posix.cc",
        "status": "removed",
        "additions": 0,
        "deletions": 67,
        "changes": 67,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/port_posix.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/port_posix.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/port_posix.cc?ref=4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "patch": "@@ -1,67 +0,0 @@\n-// Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-\n-#include \"port/port_posix.h\"\n-\n-#include <cstdlib>\n-#include <stdio.h>\n-#include <string.h>\n-\n-#if (defined(__x86_64__) || defined(__i386__)) && defined(__GNUC__)\n-#include <cpuid.h>\n-#endif\n-\n-namespace leveldb {\n-namespace port {\n-\n-static void PthreadCall(const char* label, int result) {\n-  if (result != 0) {\n-    fprintf(stderr, \"pthread %s: %s\\n\", label, strerror(result));\n-    abort();\n-  }\n-}\n-\n-Mutex::Mutex() { PthreadCall(\"init mutex\", pthread_mutex_init(&mu_, NULL)); }\n-\n-Mutex::~Mutex() { PthreadCall(\"destroy mutex\", pthread_mutex_destroy(&mu_)); }\n-\n-void Mutex::Lock() { PthreadCall(\"lock\", pthread_mutex_lock(&mu_)); }\n-\n-void Mutex::Unlock() { PthreadCall(\"unlock\", pthread_mutex_unlock(&mu_)); }\n-\n-CondVar::CondVar(Mutex* mu)\n-    : mu_(mu) {\n-    PthreadCall(\"init cv\", pthread_cond_init(&cv_, NULL));\n-}\n-\n-CondVar::~CondVar() { PthreadCall(\"destroy cv\", pthread_cond_destroy(&cv_)); }\n-\n-void CondVar::Wait() {\n-  PthreadCall(\"wait\", pthread_cond_wait(&cv_, &mu_->mu_));\n-}\n-\n-void CondVar::Signal() {\n-  PthreadCall(\"signal\", pthread_cond_signal(&cv_));\n-}\n-\n-void CondVar::SignalAll() {\n-  PthreadCall(\"broadcast\", pthread_cond_broadcast(&cv_));\n-}\n-\n-void InitOnce(OnceType* once, void (*initializer)()) {\n-  PthreadCall(\"once\", pthread_once(once, initializer));\n-}\n-\n-bool HasAcceleratedCRC32C() {\n-#if (defined(__x86_64__) || defined(__i386__)) && defined(__GNUC__)\n-  unsigned int eax, ebx, ecx, edx;\n-  __get_cpuid(1, &eax, &ebx, &ecx, &edx);\n-  return (ecx & (1 << 20)) != 0;\n-#else\n-  return false;\n-#endif\n-}\n-\n-}  // namespace port\n-}  // namespace leveldb"
      },
      {
        "sha": "d85fa5d63fe0fc593cb2c9c12471d884622189b6",
        "filename": "port/port_posix.h",
        "status": "removed",
        "additions": 0,
        "deletions": 161,
        "changes": 161,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/port_posix.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/port_posix.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/port_posix.h?ref=4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "patch": "@@ -1,161 +0,0 @@\n-// Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-//\n-// See port_example.h for documentation for the following types/functions.\n-\n-#ifndef STORAGE_LEVELDB_PORT_PORT_POSIX_H_\n-#define STORAGE_LEVELDB_PORT_PORT_POSIX_H_\n-\n-#undef PLATFORM_IS_LITTLE_ENDIAN\n-#if defined(OS_MACOSX)\n-  #include <machine/endian.h>\n-  #if defined(__DARWIN_LITTLE_ENDIAN) && defined(__DARWIN_BYTE_ORDER)\n-    #define PLATFORM_IS_LITTLE_ENDIAN \\\n-        (__DARWIN_BYTE_ORDER == __DARWIN_LITTLE_ENDIAN)\n-  #endif\n-#elif defined(OS_SOLARIS)\n-  #include <sys/isa_defs.h>\n-  #ifdef _LITTLE_ENDIAN\n-    #define PLATFORM_IS_LITTLE_ENDIAN true\n-  #else\n-    #define PLATFORM_IS_LITTLE_ENDIAN false\n-  #endif\n-#elif defined(OS_FREEBSD) || defined(OS_OPENBSD) ||\\\n-      defined(OS_NETBSD) || defined(OS_DRAGONFLYBSD)\n-  #include <sys/types.h>\n-  #include <sys/endian.h>\n-  #define PLATFORM_IS_LITTLE_ENDIAN (_BYTE_ORDER == _LITTLE_ENDIAN)\n-#elif defined(OS_HPUX)\n-  #define PLATFORM_IS_LITTLE_ENDIAN false\n-#elif defined(OS_ANDROID)\n-  // Due to a bug in the NDK x86 <sys/endian.h> definition,\n-  // _BYTE_ORDER must be used instead of __BYTE_ORDER on Android.\n-  // See http://code.google.com/p/android/issues/detail?id=39824\n-  #include <endian.h>\n-  #define PLATFORM_IS_LITTLE_ENDIAN  (_BYTE_ORDER == _LITTLE_ENDIAN)\n-#else\n-  #include <endian.h>\n-#endif\n-\n-#include <pthread.h>\n-#ifdef SNAPPY\n-#include <snappy.h>\n-#endif\n-#include <stdint.h>\n-#include <string>\n-#include \"port/atomic_pointer.h\"\n-\n-#ifndef PLATFORM_IS_LITTLE_ENDIAN\n-#define PLATFORM_IS_LITTLE_ENDIAN (__BYTE_ORDER == __LITTLE_ENDIAN)\n-#endif\n-\n-#if defined(OS_MACOSX) || defined(OS_SOLARIS) || defined(OS_FREEBSD) ||\\\n-    defined(OS_NETBSD) || defined(OS_OPENBSD) || defined(OS_DRAGONFLYBSD) ||\\\n-    defined(OS_ANDROID) || defined(OS_HPUX) || defined(CYGWIN)\n-// Use fread/fwrite/fflush on platforms without _unlocked variants\n-#define fread_unlocked fread\n-#define fwrite_unlocked fwrite\n-#define fflush_unlocked fflush\n-#endif\n-\n-#if defined(OS_FREEBSD) ||\\\n-    defined(OS_OPENBSD) || defined(OS_DRAGONFLYBSD)\n-// Use fsync() on platforms without fdatasync()\n-#define fdatasync fsync\n-#endif\n-\n-#if defined(OS_MACOSX)\n-#define fdatasync(fd) fcntl(fd, F_FULLFSYNC, 0)\n-#endif\n-\n-#if defined(OS_ANDROID) && __ANDROID_API__ < 9\n-// fdatasync() was only introduced in API level 9 on Android. Use fsync()\n-// when targetting older platforms.\n-#define fdatasync fsync\n-#endif\n-\n-namespace leveldb {\n-namespace port {\n-\n-static const bool kLittleEndian = PLATFORM_IS_LITTLE_ENDIAN;\n-#undef PLATFORM_IS_LITTLE_ENDIAN\n-\n-class CondVar;\n-\n-class Mutex {\n- public:\n-  Mutex();\n-  ~Mutex();\n-\n-  void Lock();\n-  void Unlock();\n-  void AssertHeld() { }\n-\n- private:\n-  friend class CondVar;\n-  pthread_mutex_t mu_;\n-\n-  // No copying\n-  Mutex(const Mutex&);\n-  void operator=(const Mutex&);\n-};\n-\n-class CondVar {\n- public:\n-  explicit CondVar(Mutex* mu);\n-  ~CondVar();\n-  void Wait();\n-  void Signal();\n-  void SignalAll();\n- private:\n-  pthread_cond_t cv_;\n-  Mutex* mu_;\n-};\n-\n-typedef pthread_once_t OnceType;\n-#define LEVELDB_ONCE_INIT PTHREAD_ONCE_INIT\n-extern void InitOnce(OnceType* once, void (*initializer)());\n-\n-inline bool Snappy_Compress(const char* input, size_t length,\n-                            ::std::string* output) {\n-#ifdef SNAPPY\n-  output->resize(snappy::MaxCompressedLength(length));\n-  size_t outlen;\n-  snappy::RawCompress(input, length, &(*output)[0], &outlen);\n-  output->resize(outlen);\n-  return true;\n-#endif\n-\n-  return false;\n-}\n-\n-inline bool Snappy_GetUncompressedLength(const char* input, size_t length,\n-                                         size_t* result) {\n-#ifdef SNAPPY\n-  return snappy::GetUncompressedLength(input, length, result);\n-#else\n-  return false;\n-#endif\n-}\n-\n-inline bool Snappy_Uncompress(const char* input, size_t length,\n-                              char* output) {\n-#ifdef SNAPPY\n-  return snappy::RawUncompress(input, length, output);\n-#else\n-  return false;\n-#endif\n-}\n-\n-inline bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg) {\n-  return false;\n-}\n-\n-bool HasAcceleratedCRC32C();\n-uint32_t AcceleratedCRC32C(uint32_t crc, const char* buf, size_t size);\n-\n-} // namespace port\n-} // namespace leveldb\n-\n-#endif  // STORAGE_LEVELDB_PORT_PORT_POSIX_H_"
      },
      {
        "sha": "2d49c21dd8b0eb08fa0fd33411c50f2d277c94d6",
        "filename": "port/port_posix_sse.cc",
        "status": "removed",
        "additions": 0,
        "deletions": 110,
        "changes": 110,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/port_posix_sse.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/port_posix_sse.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/port_posix_sse.cc?ref=4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "patch": "@@ -1,110 +0,0 @@\n-// Copyright 2016 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-//\n-// A portable implementation of crc32c, optimized to handle\n-// four bytes at a time.\n-//\n-// In a separate source file to allow this accelerated CRC32C function to be\n-// compiled with the appropriate compiler flags to enable x86 SSE 4.2\n-// instructions.\n-\n-#include <stdint.h>\n-#include <string.h>\n-#include \"port/port.h\"\n-\n-#if defined(LEVELDB_PLATFORM_POSIX_SSE)\n-\n-#if defined(_MSC_VER)\n-#include <intrin.h>\n-#elif defined(__GNUC__) && defined(__SSE4_2__)\n-#include <nmmintrin.h>\n-#endif\n-\n-#endif  // defined(LEVELDB_PLATFORM_POSIX_SSE)\n-\n-namespace leveldb {\n-namespace port {\n-\n-#if defined(LEVELDB_PLATFORM_POSIX_SSE)\n-\n-// Used to fetch a naturally-aligned 32-bit word in little endian byte-order\n-static inline uint32_t LE_LOAD32(const uint8_t *p) {\n-  // SSE is x86 only, so ensured that |p| is always little-endian.\n-  uint32_t word;\n-  memcpy(&word, p, sizeof(word));\n-  return word;\n-}\n-\n-#if defined(_M_X64) || defined(__x86_64__)  // LE_LOAD64 is only used on x64.\n-\n-// Used to fetch a naturally-aligned 64-bit word in little endian byte-order\n-static inline uint64_t LE_LOAD64(const uint8_t *p) {\n-  uint64_t dword;\n-  memcpy(&dword, p, sizeof(dword));\n-  return dword;\n-}\n-\n-#endif  // defined(_M_X64) || defined(__x86_64__)\n-\n-#endif  // defined(LEVELDB_PLATFORM_POSIX_SSE)\n-\n-// For further improvements see Intel publication at:\n-// http://download.intel.com/design/intarch/papers/323405.pdf\n-uint32_t AcceleratedCRC32C(uint32_t crc, const char* buf, size_t size) {\n-#if !defined(LEVELDB_PLATFORM_POSIX_SSE)\n-  return 0;\n-#else\n-\n-  const uint8_t *p = reinterpret_cast<const uint8_t *>(buf);\n-  const uint8_t *e = p + size;\n-  uint32_t l = crc ^ 0xffffffffu;\n-\n-#define STEP1 do {                              \\\n-    l = _mm_crc32_u8(l, *p++);                  \\\n-} while (0)\n-#define STEP4 do {                              \\\n-    l = _mm_crc32_u32(l, LE_LOAD32(p));         \\\n-    p += 4;                                     \\\n-} while (0)\n-#define STEP8 do {                              \\\n-    l = _mm_crc32_u64(l, LE_LOAD64(p));         \\\n-    p += 8;                                     \\\n-} while (0)\n-\n-  if (size > 16) {\n-    // Process unaligned bytes\n-    for (unsigned int i = reinterpret_cast<uintptr_t>(p) % 8; i; --i) {\n-      STEP1;\n-    }\n-\n-    // _mm_crc32_u64 is only available on x64.\n-#if defined(_M_X64) || defined(__x86_64__)\n-    // Process 8 bytes at a time\n-    while ((e-p) >= 8) {\n-      STEP8;\n-    }\n-    // Process 4 bytes at a time\n-    if ((e-p) >= 4) {\n-      STEP4;\n-    }\n-#else  // !(defined(_M_X64) || defined(__x86_64__))\n-    // Process 4 bytes at a time\n-    while ((e-p) >= 4) {\n-      STEP4;\n-    }\n-#endif  // defined(_M_X64) || defined(__x86_64__)\n-  }\n-  // Process the last few bytes\n-  while (p != e) {\n-    STEP1;\n-  }\n-#undef STEP8\n-#undef STEP4\n-#undef STEP1\n-  return l ^ 0xffffffffu;\n-#endif  // defined(LEVELDB_PLATFORM_POSIX_SSE)\n-}\n-\n-}  // namespace port\n-}  // namespace leveldb"
      },
      {
        "sha": "e9cb0e53afdbefd56b0932272e27717680866be3",
        "filename": "port/port_stdcxx.h",
        "status": "added",
        "additions": 153,
        "deletions": 0,
        "changes": 153,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/port/port_stdcxx.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/port/port_stdcxx.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/port_stdcxx.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -0,0 +1,153 @@\n+// Copyright (c) 2018 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef STORAGE_LEVELDB_PORT_PORT_STDCXX_H_\n+#define STORAGE_LEVELDB_PORT_PORT_STDCXX_H_\n+\n+// port/port_config.h availability is automatically detected via __has_include\n+// in newer compilers. If LEVELDB_HAS_PORT_CONFIG_H is defined, it overrides the\n+// configuration detection.\n+#if defined(LEVELDB_HAS_PORT_CONFIG_H)\n+\n+#if LEVELDB_HAS_PORT_CONFIG_H\n+#include \"port/port_config.h\"\n+#endif  // LEVELDB_HAS_PORT_CONFIG_H\n+\n+#elif defined(__has_include)\n+\n+#if __has_include(\"port/port_config.h\")\n+#include \"port/port_config.h\"\n+#endif  // __has_include(\"port/port_config.h\")\n+\n+#endif  // defined(LEVELDB_HAS_PORT_CONFIG_H)\n+\n+#if HAVE_CRC32C\n+#include <crc32c/crc32c.h>\n+#endif  // HAVE_CRC32C\n+#if HAVE_SNAPPY\n+#include <snappy.h>\n+#endif  // HAVE_SNAPPY\n+\n+#include <cassert>\n+#include <condition_variable>  // NOLINT\n+#include <cstddef>\n+#include <cstdint>\n+#include <mutex>  // NOLINT\n+#include <string>\n+\n+#include \"port/thread_annotations.h\"\n+\n+namespace leveldb {\n+namespace port {\n+\n+static const bool kLittleEndian = !LEVELDB_IS_BIG_ENDIAN;\n+\n+class CondVar;\n+\n+// Thinly wraps std::mutex.\n+class LOCKABLE Mutex {\n+ public:\n+  Mutex() = default;\n+  ~Mutex() = default;\n+\n+  Mutex(const Mutex&) = delete;\n+  Mutex& operator=(const Mutex&) = delete;\n+\n+  void Lock() EXCLUSIVE_LOCK_FUNCTION() { mu_.lock(); }\n+  void Unlock() UNLOCK_FUNCTION() { mu_.unlock(); }\n+  void AssertHeld() ASSERT_EXCLUSIVE_LOCK() {}\n+\n+ private:\n+  friend class CondVar;\n+  std::mutex mu_;\n+};\n+\n+// Thinly wraps std::condition_variable.\n+class CondVar {\n+ public:\n+  explicit CondVar(Mutex* mu) : mu_(mu) { assert(mu != nullptr); }\n+  ~CondVar() = default;\n+\n+  CondVar(const CondVar&) = delete;\n+  CondVar& operator=(const CondVar&) = delete;\n+\n+  void Wait() {\n+    std::unique_lock<std::mutex> lock(mu_->mu_, std::adopt_lock);\n+    cv_.wait(lock);\n+    lock.release();\n+  }\n+  void Signal() { cv_.notify_one(); }\n+  void SignalAll() { cv_.notify_all(); }\n+\n+ private:\n+  std::condition_variable cv_;\n+  Mutex* const mu_;\n+};\n+\n+inline bool Snappy_Compress(const char* input, size_t length,\n+                            std::string* output) {\n+#if HAVE_SNAPPY\n+  output->resize(snappy::MaxCompressedLength(length));\n+  size_t outlen;\n+  snappy::RawCompress(input, length, &(*output)[0], &outlen);\n+  output->resize(outlen);\n+  return true;\n+#else\n+  // Silence compiler warnings about unused arguments.\n+  (void)input;\n+  (void)length;\n+  (void)output;\n+#endif  // HAVE_SNAPPY\n+\n+  return false;\n+}\n+\n+inline bool Snappy_GetUncompressedLength(const char* input, size_t length,\n+                                         size_t* result) {\n+#if HAVE_SNAPPY\n+  return snappy::GetUncompressedLength(input, length, result);\n+#else\n+  // Silence compiler warnings about unused arguments.\n+  (void)input;\n+  (void)length;\n+  (void)result;\n+  return false;\n+#endif  // HAVE_SNAPPY\n+}\n+\n+inline bool Snappy_Uncompress(const char* input, size_t length, char* output) {\n+#if HAVE_SNAPPY\n+  return snappy::RawUncompress(input, length, output);\n+#else\n+  // Silence compiler warnings about unused arguments.\n+  (void)input;\n+  (void)length;\n+  (void)output;\n+  return false;\n+#endif  // HAVE_SNAPPY\n+}\n+\n+inline bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg) {\n+  // Silence compiler warnings about unused arguments.\n+  (void)func;\n+  (void)arg;\n+  return false;\n+}\n+\n+inline uint32_t AcceleratedCRC32C(uint32_t crc, const char* buf, size_t size) {\n+#if HAVE_CRC32C\n+  return ::crc32c::Extend(crc, reinterpret_cast<const uint8_t*>(buf), size);\n+#else\n+  // Silence compiler warnings about unused arguments.\n+  (void)crc;\n+  (void)buf;\n+  (void)size;\n+  return 0;\n+#endif  // HAVE_CRC32C\n+}\n+\n+}  // namespace port\n+}  // namespace leveldb\n+\n+#endif  // STORAGE_LEVELDB_PORT_PORT_STDCXX_H_"
      },
      {
        "sha": "1be9e8d5b0b41ea458b42bb17f2e3a18eefac315",
        "filename": "port/port_win.cc",
        "status": "removed",
        "additions": 0,
        "deletions": 158,
        "changes": 158,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/port_win.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/port_win.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/port_win.cc?ref=4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "patch": "@@ -1,158 +0,0 @@\n-// LevelDB Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-//\n-// See port_example.h for documentation for the following types/functions.\n-\n-// Redistribution and use in source and binary forms, with or without\n-// modification, are permitted provided that the following conditions are met:\n-// \n-//  * Redistributions of source code must retain the above copyright\n-//    notice, this list of conditions and the following disclaimer.\n-//  * Redistributions in binary form must reproduce the above copyright\n-//    notice, this list of conditions and the following disclaimer in the\n-//    documentation and/or other materials provided with the distribution.\n-//  * Neither the name of the University of California, Berkeley nor the\n-//    names of its contributors may be used to endorse or promote products\n-//    derived from this software without specific prior written permission.\n-// \n-// THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND ANY\n-// EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n-// WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n-// DISCLAIMED. IN NO EVENT SHALL THE REGENTS AND CONTRIBUTORS BE LIABLE FOR ANY\n-// DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n-// (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n-// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n-// ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n-//\n-\n-#include \"port/port_win.h\"\n-\n-#include <windows.h>\n-#include <cassert>\n-#include <intrin.h>\n-\n-namespace leveldb {\n-namespace port {\n-\n-Mutex::Mutex() :\n-    cs_(NULL) {\n-  assert(!cs_);\n-  cs_ = static_cast<void *>(new CRITICAL_SECTION());\n-  ::InitializeCriticalSection(static_cast<CRITICAL_SECTION *>(cs_));\n-  assert(cs_);\n-}\n-\n-Mutex::~Mutex() {\n-  assert(cs_);\n-  ::DeleteCriticalSection(static_cast<CRITICAL_SECTION *>(cs_));\n-  delete static_cast<CRITICAL_SECTION *>(cs_);\n-  cs_ = NULL;\n-  assert(!cs_);\n-}\n-\n-void Mutex::Lock() {\n-  assert(cs_);\n-  ::EnterCriticalSection(static_cast<CRITICAL_SECTION *>(cs_));\n-}\n-\n-void Mutex::Unlock() {\n-  assert(cs_);\n-  ::LeaveCriticalSection(static_cast<CRITICAL_SECTION *>(cs_));\n-}\n-\n-void Mutex::AssertHeld() {\n-  assert(cs_);\n-  assert(1);\n-}\n-\n-CondVar::CondVar(Mutex* mu) :\n-    waiting_(0), \n-    mu_(mu), \n-    sem1_(::CreateSemaphore(NULL, 0, 10000, NULL)), \n-    sem2_(::CreateSemaphore(NULL, 0, 10000, NULL)) {\n-  assert(mu_);\n-}\n-\n-CondVar::~CondVar() {\n-  ::CloseHandle(sem1_);\n-  ::CloseHandle(sem2_);\n-}\n-\n-void CondVar::Wait() {\n-  mu_->AssertHeld();\n-\n-  wait_mtx_.Lock();\n-  ++waiting_;\n-  wait_mtx_.Unlock();\n-\n-  mu_->Unlock();\n-\n-  // initiate handshake\n-  ::WaitForSingleObject(sem1_, INFINITE);\n-  ::ReleaseSemaphore(sem2_, 1, NULL);\n-  mu_->Lock();\n-}\n-\n-void CondVar::Signal() {\n-  wait_mtx_.Lock();\n-  if (waiting_ > 0) {\n-    --waiting_;\n-\n-    // finalize handshake\n-    ::ReleaseSemaphore(sem1_, 1, NULL);\n-    ::WaitForSingleObject(sem2_, INFINITE);\n-  }\n-  wait_mtx_.Unlock();\n-}\n-\n-void CondVar::SignalAll() {\n-  wait_mtx_.Lock();\n-  ::ReleaseSemaphore(sem1_, waiting_, NULL);\n-  while(waiting_ > 0) {\n-    --waiting_;\n-    ::WaitForSingleObject(sem2_, INFINITE);\n-  }\n-  wait_mtx_.Unlock();\n-}\n-\n-AtomicPointer::AtomicPointer(void* v) {\n-  Release_Store(v);\n-}\n-\n-void InitOnce(OnceType* once, void (*initializer)()) {\n-  once->InitOnce(initializer);\n-}\n-\n-void* AtomicPointer::Acquire_Load() const {\n-  void * p = NULL;\n-  InterlockedExchangePointer(&p, rep_);\n-  return p;\n-}\n-\n-void AtomicPointer::Release_Store(void* v) {\n-  InterlockedExchangePointer(&rep_, v);\n-}\n-\n-void* AtomicPointer::NoBarrier_Load() const {\n-  return rep_;\n-}\n-\n-void AtomicPointer::NoBarrier_Store(void* v) {\n-  rep_ = v;\n-}\n-\n-bool HasAcceleratedCRC32C() {\n-#if defined(__x86_64__) || defined(__i386__)\n-  int cpu_info[4];\n-  __cpuid(cpu_info, 1);\n-  return (cpu_info[2] & (1 << 20)) != 0;\n-#else\n-  return false;\n-#endif\n-}\n-\n-}\n-}"
      },
      {
        "sha": "989c15cd91d05713a42c22d92c1be0edacb47bb3",
        "filename": "port/port_win.h",
        "status": "removed",
        "additions": 0,
        "deletions": 184,
        "changes": 184,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/port_win.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/port_win.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/port_win.h?ref=4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "patch": "@@ -1,184 +0,0 @@\n-// LevelDB Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-//\n-// See port_example.h for documentation for the following types/functions.\n-\n-// Redistribution and use in source and binary forms, with or without\n-// modification, are permitted provided that the following conditions are met:\n-// \n-//  * Redistributions of source code must retain the above copyright\n-//    notice, this list of conditions and the following disclaimer.\n-//  * Redistributions in binary form must reproduce the above copyright\n-//    notice, this list of conditions and the following disclaimer in the\n-//    documentation and/or other materials provided with the distribution.\n-//  * Neither the name of the University of California, Berkeley nor the\n-//    names of its contributors may be used to endorse or promote products\n-//    derived from this software without specific prior written permission.\n-// \n-// THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND ANY\n-// EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n-// WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n-// DISCLAIMED. IN NO EVENT SHALL THE REGENTS AND CONTRIBUTORS BE LIABLE FOR ANY\n-// DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n-// (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n-// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n-// ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n-//\n-\n-#ifndef STORAGE_LEVELDB_PORT_PORT_WIN_H_\n-#define STORAGE_LEVELDB_PORT_PORT_WIN_H_\n-\n-#ifdef _MSC_VER\n-#if !(_MSC_VER >= 1900)\n-#define snprintf _snprintf\n-#endif\n-#define close _close\n-#define fread_unlocked _fread_nolock\n-#ifdef _WIN64\n-#define ssize_t int64_t\n-#else\n-#define ssize_t int32_t\n-#endif\n-#endif\n-\n-#include <string>\n-#include <stdint.h>\n-#ifdef SNAPPY\n-#include <snappy.h>\n-#endif\n-\n-namespace leveldb {\n-namespace port {\n-\n-// Windows is little endian (for now :p)\n-static const bool kLittleEndian = true;\n-\n-class CondVar;\n-\n-class Mutex {\n- public:\n-  Mutex();\n-  ~Mutex();\n-\n-  void Lock();\n-  void Unlock();\n-  void AssertHeld();\n-\n- private:\n-  friend class CondVar;\n-  // critical sections are more efficient than mutexes\n-  // but they are not recursive and can only be used to synchronize threads within the same process\n-  // we use opaque void * to avoid including windows.h in port_win.h\n-  void * cs_;\n-\n-  // No copying\n-  Mutex(const Mutex&);\n-  void operator=(const Mutex&);\n-};\n-\n-// the Win32 API offers a dependable condition variable mechanism, but only starting with\n-// Windows 2008 and Vista\n-// no matter what we will implement our own condition variable with a semaphore\n-// implementation as described in a paper written by Andrew D. Birrell in 2003\n-class CondVar {\n- public:\n-  explicit CondVar(Mutex* mu);\n-  ~CondVar();\n-  void Wait();\n-  void Signal();\n-  void SignalAll();\n- private:\n-  Mutex* mu_;\n-  \n-  Mutex wait_mtx_;\n-  long waiting_;\n-  \n-  void * sem1_;\n-  void * sem2_;\n-  \n-  \n-};\n-\n-class OnceType {\n-public:\n-//    OnceType() : init_(false) {}\n-    OnceType(const OnceType &once) : init_(once.init_) {}\n-    OnceType(bool f) : init_(f) {}\n-    void InitOnce(void (*initializer)()) {\n-        mutex_.Lock();\n-        if (!init_) {\n-            init_ = true;\n-            initializer();\n-        }\n-        mutex_.Unlock();\n-    }\n-\n-private:\n-    bool init_;\n-    Mutex mutex_;\n-};\n-\n-#define LEVELDB_ONCE_INIT false\n-extern void InitOnce(port::OnceType*, void (*initializer)());\n-\n-// Storage for a lock-free pointer\n-class AtomicPointer {\n- private:\n-  void * rep_;\n- public:\n-  AtomicPointer() : rep_(NULL) { }\n-  explicit AtomicPointer(void* v); \n-  void* Acquire_Load() const;\n-\n-  void Release_Store(void* v);\n-\n-  void* NoBarrier_Load() const;\n-\n-  void NoBarrier_Store(void* v);\n-};\n-\n-inline bool Snappy_Compress(const char* input, size_t length,\n-                            ::std::string* output) {\n-#ifdef SNAPPY\n-  output->resize(snappy::MaxCompressedLength(length));\n-  size_t outlen;\n-  snappy::RawCompress(input, length, &(*output)[0], &outlen);\n-  output->resize(outlen);\n-  return true;\n-#endif\n-\n-  return false;\n-}\n-\n-inline bool Snappy_GetUncompressedLength(const char* input, size_t length,\n-                                         size_t* result) {\n-#ifdef SNAPPY\n-  return snappy::GetUncompressedLength(input, length, result);\n-#else\n-  return false;\n-#endif\n-}\n-\n-inline bool Snappy_Uncompress(const char* input, size_t length,\n-                              char* output) {\n-#ifdef SNAPPY\n-  return snappy::RawUncompress(input, length, output);\n-#else\n-  return false;\n-#endif\n-}\n-\n-inline bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg) {\n-  return false;\n-}\n-\n-bool HasAcceleratedCRC32C();\n-uint32_t AcceleratedCRC32C(uint32_t crc, const char* buf, size_t size);\n-\n-}\n-}\n-\n-#endif  // STORAGE_LEVELDB_PORT_PORT_WIN_H_"
      },
      {
        "sha": "1547df908fb629f2dc29d705f2d4cb1d46b89ea2",
        "filename": "port/thread_annotations.h",
        "status": "modified",
        "additions": 63,
        "deletions": 15,
        "changes": 78,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/port/thread_annotations.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/port/thread_annotations.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/thread_annotations.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -5,56 +5,104 @@\n #ifndef STORAGE_LEVELDB_PORT_THREAD_ANNOTATIONS_H_\n #define STORAGE_LEVELDB_PORT_THREAD_ANNOTATIONS_H_\n \n-// Some environments provide custom macros to aid in static thread-safety\n-// analysis.  Provide empty definitions of such macros unless they are already\n-// defined.\n+// Use Clang's thread safety analysis annotations when available. In other\n+// environments, the macros receive empty definitions.\n+// Usage documentation: https://clang.llvm.org/docs/ThreadSafetyAnalysis.html\n+\n+#if !defined(THREAD_ANNOTATION_ATTRIBUTE__)\n+\n+#if defined(__clang__)\n+\n+#define THREAD_ANNOTATION_ATTRIBUTE__(x) __attribute__((x))\n+#else\n+#define THREAD_ANNOTATION_ATTRIBUTE__(x)  // no-op\n+#endif\n+\n+#endif  // !defined(THREAD_ANNOTATION_ATTRIBUTE__)\n+\n+#ifndef GUARDED_BY\n+#define GUARDED_BY(x) THREAD_ANNOTATION_ATTRIBUTE__(guarded_by(x))\n+#endif\n+\n+#ifndef PT_GUARDED_BY\n+#define PT_GUARDED_BY(x) THREAD_ANNOTATION_ATTRIBUTE__(pt_guarded_by(x))\n+#endif\n+\n+#ifndef ACQUIRED_AFTER\n+#define ACQUIRED_AFTER(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(acquired_after(__VA_ARGS__))\n+#endif\n+\n+#ifndef ACQUIRED_BEFORE\n+#define ACQUIRED_BEFORE(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(acquired_before(__VA_ARGS__))\n+#endif\n \n #ifndef EXCLUSIVE_LOCKS_REQUIRED\n-#define EXCLUSIVE_LOCKS_REQUIRED(...)\n+#define EXCLUSIVE_LOCKS_REQUIRED(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(exclusive_locks_required(__VA_ARGS__))\n #endif\n \n #ifndef SHARED_LOCKS_REQUIRED\n-#define SHARED_LOCKS_REQUIRED(...)\n+#define SHARED_LOCKS_REQUIRED(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(shared_locks_required(__VA_ARGS__))\n #endif\n \n #ifndef LOCKS_EXCLUDED\n-#define LOCKS_EXCLUDED(...)\n+#define LOCKS_EXCLUDED(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(locks_excluded(__VA_ARGS__))\n #endif\n \n #ifndef LOCK_RETURNED\n-#define LOCK_RETURNED(x)\n+#define LOCK_RETURNED(x) THREAD_ANNOTATION_ATTRIBUTE__(lock_returned(x))\n #endif\n \n #ifndef LOCKABLE\n-#define LOCKABLE\n+#define LOCKABLE THREAD_ANNOTATION_ATTRIBUTE__(lockable)\n #endif\n \n #ifndef SCOPED_LOCKABLE\n-#define SCOPED_LOCKABLE\n+#define SCOPED_LOCKABLE THREAD_ANNOTATION_ATTRIBUTE__(scoped_lockable)\n #endif\n \n #ifndef EXCLUSIVE_LOCK_FUNCTION\n-#define EXCLUSIVE_LOCK_FUNCTION(...)\n+#define EXCLUSIVE_LOCK_FUNCTION(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(exclusive_lock_function(__VA_ARGS__))\n #endif\n \n #ifndef SHARED_LOCK_FUNCTION\n-#define SHARED_LOCK_FUNCTION(...)\n+#define SHARED_LOCK_FUNCTION(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(shared_lock_function(__VA_ARGS__))\n #endif\n \n #ifndef EXCLUSIVE_TRYLOCK_FUNCTION\n-#define EXCLUSIVE_TRYLOCK_FUNCTION(...)\n+#define EXCLUSIVE_TRYLOCK_FUNCTION(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(exclusive_trylock_function(__VA_ARGS__))\n #endif\n \n #ifndef SHARED_TRYLOCK_FUNCTION\n-#define SHARED_TRYLOCK_FUNCTION(...)\n+#define SHARED_TRYLOCK_FUNCTION(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(shared_trylock_function(__VA_ARGS__))\n #endif\n \n #ifndef UNLOCK_FUNCTION\n-#define UNLOCK_FUNCTION(...)\n+#define UNLOCK_FUNCTION(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(unlock_function(__VA_ARGS__))\n #endif\n \n #ifndef NO_THREAD_SAFETY_ANALYSIS\n-#define NO_THREAD_SAFETY_ANALYSIS\n+#define NO_THREAD_SAFETY_ANALYSIS \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(no_thread_safety_analysis)\n+#endif\n+\n+#ifndef ASSERT_EXCLUSIVE_LOCK\n+#define ASSERT_EXCLUSIVE_LOCK(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(assert_exclusive_lock(__VA_ARGS__))\n+#endif\n+\n+#ifndef ASSERT_SHARED_LOCK\n+#define ASSERT_SHARED_LOCK(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(assert_shared_lock(__VA_ARGS__))\n #endif\n \n #endif  // STORAGE_LEVELDB_PORT_THREAD_ANNOTATIONS_H_"
      },
      {
        "sha": "39edd0db13f436dc57dd28ed4013ab4d55a28a31",
        "filename": "port/win/stdint.h",
        "status": "removed",
        "additions": 0,
        "deletions": 24,
        "changes": 24,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/win/stdint.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/port/win/stdint.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/port/win/stdint.h?ref=4f2e6c8b881b7ccda36233332dfd1bd231389a8e",
        "patch": "@@ -1,24 +0,0 @@\n-// Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-\n-// MSVC didn't ship with this file until the 2010 version.\n-\n-#ifndef STORAGE_LEVELDB_PORT_WIN_STDINT_H_\n-#define STORAGE_LEVELDB_PORT_WIN_STDINT_H_\n-\n-#if !defined(_MSC_VER)\n-#error This file should only be included when compiling with MSVC.\n-#endif\n-\n-// Define C99 equivalent types.\n-typedef signed char           int8_t;\n-typedef signed short          int16_t;\n-typedef signed int            int32_t;\n-typedef signed long long      int64_t;\n-typedef unsigned char         uint8_t;\n-typedef unsigned short        uint16_t;\n-typedef unsigned int          uint32_t;\n-typedef unsigned long long    uint64_t;\n-\n-#endif  // STORAGE_LEVELDB_PORT_WIN_STDINT_H_"
      },
      {
        "sha": "2fe89eaa4593d328db2bea5456ecbfc0e797b1b9",
        "filename": "table/block.cc",
        "status": "modified",
        "additions": 34,
        "deletions": 35,
        "changes": 69,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/block.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/block.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/block.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -6,8 +6,10 @@\n \n #include \"table/block.h\"\n \n-#include <vector>\n #include <algorithm>\n+#include <cstdint>\n+#include <vector>\n+\n #include \"leveldb/comparator.h\"\n #include \"table/format.h\"\n #include \"util/coding.h\"\n@@ -27,7 +29,7 @@ Block::Block(const BlockContents& contents)\n   if (size_ < sizeof(uint32_t)) {\n     size_ = 0;  // Error marker\n   } else {\n-    size_t max_restarts_allowed = (size_-sizeof(uint32_t)) / sizeof(uint32_t);\n+    size_t max_restarts_allowed = (size_ - sizeof(uint32_t)) / sizeof(uint32_t);\n     if (NumRestarts() > max_restarts_allowed) {\n       // The size is too small for NumRestarts()\n       size_ = 0;\n@@ -48,37 +50,36 @@ Block::~Block() {\n // and the length of the value in \"*shared\", \"*non_shared\", and\n // \"*value_length\", respectively.  Will not dereference past \"limit\".\n //\n-// If any errors are detected, returns NULL.  Otherwise, returns a\n+// If any errors are detected, returns nullptr.  Otherwise, returns a\n // pointer to the key delta (just past the three decoded values).\n static inline const char* DecodeEntry(const char* p, const char* limit,\n-                                      uint32_t* shared,\n-                                      uint32_t* non_shared,\n+                                      uint32_t* shared, uint32_t* non_shared,\n                                       uint32_t* value_length) {\n-  if (limit - p < 3) return NULL;\n-  *shared = reinterpret_cast<const unsigned char*>(p)[0];\n-  *non_shared = reinterpret_cast<const unsigned char*>(p)[1];\n-  *value_length = reinterpret_cast<const unsigned char*>(p)[2];\n+  if (limit - p < 3) return nullptr;\n+  *shared = reinterpret_cast<const uint8_t*>(p)[0];\n+  *non_shared = reinterpret_cast<const uint8_t*>(p)[1];\n+  *value_length = reinterpret_cast<const uint8_t*>(p)[2];\n   if ((*shared | *non_shared | *value_length) < 128) {\n     // Fast path: all three values are encoded in one byte each\n     p += 3;\n   } else {\n-    if ((p = GetVarint32Ptr(p, limit, shared)) == NULL) return NULL;\n-    if ((p = GetVarint32Ptr(p, limit, non_shared)) == NULL) return NULL;\n-    if ((p = GetVarint32Ptr(p, limit, value_length)) == NULL) return NULL;\n+    if ((p = GetVarint32Ptr(p, limit, shared)) == nullptr) return nullptr;\n+    if ((p = GetVarint32Ptr(p, limit, non_shared)) == nullptr) return nullptr;\n+    if ((p = GetVarint32Ptr(p, limit, value_length)) == nullptr) return nullptr;\n   }\n \n   if (static_cast<uint32_t>(limit - p) < (*non_shared + *value_length)) {\n-    return NULL;\n+    return nullptr;\n   }\n   return p;\n }\n \n class Block::Iter : public Iterator {\n  private:\n   const Comparator* const comparator_;\n-  const char* const data_;      // underlying block contents\n-  uint32_t const restarts_;     // Offset of restart array (list of fixed32)\n-  uint32_t const num_restarts_; // Number of uint32_t entries in restart array\n+  const char* const data_;       // underlying block contents\n+  uint32_t const restarts_;      // Offset of restart array (list of fixed32)\n+  uint32_t const num_restarts_;  // Number of uint32_t entries in restart array\n \n   // current_ is offset in data_ of current entry.  >= restarts_ if !Valid\n   uint32_t current_;\n@@ -112,9 +113,7 @@ class Block::Iter : public Iterator {\n   }\n \n  public:\n-  Iter(const Comparator* comparator,\n-       const char* data,\n-       uint32_t restarts,\n+  Iter(const Comparator* comparator, const char* data, uint32_t restarts,\n        uint32_t num_restarts)\n       : comparator_(comparator),\n         data_(data),\n@@ -125,23 +124,23 @@ class Block::Iter : public Iterator {\n     assert(num_restarts_ > 0);\n   }\n \n-  virtual bool Valid() const { return current_ < restarts_; }\n-  virtual Status status() const { return status_; }\n-  virtual Slice key() const {\n+  bool Valid() const override { return current_ < restarts_; }\n+  Status status() const override { return status_; }\n+  Slice key() const override {\n     assert(Valid());\n     return key_;\n   }\n-  virtual Slice value() const {\n+  Slice value() const override {\n     assert(Valid());\n     return value_;\n   }\n \n-  virtual void Next() {\n+  void Next() override {\n     assert(Valid());\n     ParseNextKey();\n   }\n \n-  virtual void Prev() {\n+  void Prev() override {\n     assert(Valid());\n \n     // Scan backwards to a restart point before current_\n@@ -162,7 +161,7 @@ class Block::Iter : public Iterator {\n     } while (ParseNextKey() && NextEntryOffset() < original);\n   }\n \n-  virtual void Seek(const Slice& target) {\n+  void Seek(const Slice& target) override {\n     // Binary search in restart array to find the last restart point\n     // with a key < target\n     uint32_t left = 0;\n@@ -171,10 +170,10 @@ class Block::Iter : public Iterator {\n       uint32_t mid = (left + right + 1) / 2;\n       uint32_t region_offset = GetRestartPoint(mid);\n       uint32_t shared, non_shared, value_length;\n-      const char* key_ptr = DecodeEntry(data_ + region_offset,\n-                                        data_ + restarts_,\n-                                        &shared, &non_shared, &value_length);\n-      if (key_ptr == NULL || (shared != 0)) {\n+      const char* key_ptr =\n+          DecodeEntry(data_ + region_offset, data_ + restarts_, &shared,\n+                      &non_shared, &value_length);\n+      if (key_ptr == nullptr || (shared != 0)) {\n         CorruptionError();\n         return;\n       }\n@@ -202,12 +201,12 @@ class Block::Iter : public Iterator {\n     }\n   }\n \n-  virtual void SeekToFirst() {\n+  void SeekToFirst() override {\n     SeekToRestartPoint(0);\n     ParseNextKey();\n   }\n \n-  virtual void SeekToLast() {\n+  void SeekToLast() override {\n     SeekToRestartPoint(num_restarts_ - 1);\n     while (ParseNextKey() && NextEntryOffset() < restarts_) {\n       // Keep skipping\n@@ -237,7 +236,7 @@ class Block::Iter : public Iterator {\n     // Decode next entry\n     uint32_t shared, non_shared, value_length;\n     p = DecodeEntry(p, limit, &shared, &non_shared, &value_length);\n-    if (p == NULL || key_.size() < shared) {\n+    if (p == nullptr || key_.size() < shared) {\n       CorruptionError();\n       return false;\n     } else {\n@@ -253,15 +252,15 @@ class Block::Iter : public Iterator {\n   }\n };\n \n-Iterator* Block::NewIterator(const Comparator* cmp) {\n+Iterator* Block::NewIterator(const Comparator* comparator) {\n   if (size_ < sizeof(uint32_t)) {\n     return NewErrorIterator(Status::Corruption(\"bad block contents\"));\n   }\n   const uint32_t num_restarts = NumRestarts();\n   if (num_restarts == 0) {\n     return NewEmptyIterator();\n   } else {\n-    return new Iter(cmp, data_, restart_offset_, num_restarts);\n+    return new Iter(comparator, data_, restart_offset_, num_restarts);\n   }\n }\n "
      },
      {
        "sha": "c8f1f7b436a3c1743a22cf09e7f5c93a66b655fa",
        "filename": "table/block.h",
        "status": "modified",
        "additions": 8,
        "deletions": 8,
        "changes": 16,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/block.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/block.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/block.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -7,6 +7,7 @@\n \n #include <stddef.h>\n #include <stdint.h>\n+\n #include \"leveldb/iterator.h\"\n \n namespace leveldb {\n@@ -19,24 +20,23 @@ class Block {\n   // Initialize the block with the specified contents.\n   explicit Block(const BlockContents& contents);\n \n+  Block(const Block&) = delete;\n+  Block& operator=(const Block&) = delete;\n+\n   ~Block();\n \n   size_t size() const { return size_; }\n   Iterator* NewIterator(const Comparator* comparator);\n \n  private:\n+  class Iter;\n+\n   uint32_t NumRestarts() const;\n \n   const char* data_;\n   size_t size_;\n-  uint32_t restart_offset_;     // Offset in data_ of restart array\n-  bool owned_;                  // Block owns data_[]\n-\n-  // No copying allowed\n-  Block(const Block&);\n-  void operator=(const Block&);\n-\n-  class Iter;\n+  uint32_t restart_offset_;  // Offset in data_ of restart array\n+  bool owned_;               // Block owns data_[]\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "919cff5c9322df8dd8f016bed383a15a6b51754e",
        "filename": "table/block_builder.cc",
        "status": "modified",
        "additions": 11,
        "deletions": 12,
        "changes": 23,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/block_builder.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/block_builder.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/block_builder.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -28,36 +28,35 @@\n \n #include \"table/block_builder.h\"\n \n-#include <algorithm>\n #include <assert.h>\n+\n+#include <algorithm>\n+\n #include \"leveldb/comparator.h\"\n-#include \"leveldb/table_builder.h\"\n+#include \"leveldb/options.h\"\n #include \"util/coding.h\"\n \n namespace leveldb {\n \n BlockBuilder::BlockBuilder(const Options* options)\n-    : options_(options),\n-      restarts_(),\n-      counter_(0),\n-      finished_(false) {\n+    : options_(options), restarts_(), counter_(0), finished_(false) {\n   assert(options->block_restart_interval >= 1);\n-  restarts_.push_back(0);       // First restart point is at offset 0\n+  restarts_.push_back(0);  // First restart point is at offset 0\n }\n \n void BlockBuilder::Reset() {\n   buffer_.clear();\n   restarts_.clear();\n-  restarts_.push_back(0);       // First restart point is at offset 0\n+  restarts_.push_back(0);  // First restart point is at offset 0\n   counter_ = 0;\n   finished_ = false;\n   last_key_.clear();\n }\n \n size_t BlockBuilder::CurrentSizeEstimate() const {\n-  return (buffer_.size() +                        // Raw data buffer\n-          restarts_.size() * sizeof(uint32_t) +   // Restart array\n-          sizeof(uint32_t));                      // Restart array length\n+  return (buffer_.size() +                       // Raw data buffer\n+          restarts_.size() * sizeof(uint32_t) +  // Restart array\n+          sizeof(uint32_t));                     // Restart array length\n }\n \n Slice BlockBuilder::Finish() {\n@@ -74,7 +73,7 @@ void BlockBuilder::Add(const Slice& key, const Slice& value) {\n   Slice last_key_piece(last_key_);\n   assert(!finished_);\n   assert(counter_ <= options_->block_restart_interval);\n-  assert(buffer_.empty() // No values yet?\n+  assert(buffer_.empty()  // No values yet?\n          || options_->comparator->Compare(key, last_key_piece) > 0);\n   size_t shared = 0;\n   if (counter_ < options_->block_restart_interval) {"
      },
      {
        "sha": "f91f5e6d47e363c9292827b4ffda809d3f160274",
        "filename": "table/block_builder.h",
        "status": "modified",
        "additions": 12,
        "deletions": 14,
        "changes": 26,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/block_builder.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/block_builder.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/block_builder.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -5,9 +5,10 @@\n #ifndef STORAGE_LEVELDB_TABLE_BLOCK_BUILDER_H_\n #define STORAGE_LEVELDB_TABLE_BLOCK_BUILDER_H_\n \n+#include <stdint.h>\n+\n #include <vector>\n \n-#include <stdint.h>\n #include \"leveldb/slice.h\"\n \n namespace leveldb {\n@@ -18,6 +19,9 @@ class BlockBuilder {\n  public:\n   explicit BlockBuilder(const Options* options);\n \n+  BlockBuilder(const BlockBuilder&) = delete;\n+  BlockBuilder& operator=(const BlockBuilder&) = delete;\n+\n   // Reset the contents as if the BlockBuilder was just constructed.\n   void Reset();\n \n@@ -35,21 +39,15 @@ class BlockBuilder {\n   size_t CurrentSizeEstimate() const;\n \n   // Return true iff no entries have been added since the last Reset()\n-  bool empty() const {\n-    return buffer_.empty();\n-  }\n+  bool empty() const { return buffer_.empty(); }\n \n  private:\n-  const Options*        options_;\n-  std::string           buffer_;      // Destination buffer\n-  std::vector<uint32_t> restarts_;    // Restart points\n-  int                   counter_;     // Number of entries emitted since restart\n-  bool                  finished_;    // Has Finish() been called?\n-  std::string           last_key_;\n-\n-  // No copying allowed\n-  BlockBuilder(const BlockBuilder&);\n-  void operator=(const BlockBuilder&);\n+  const Options* options_;\n+  std::string buffer_;              // Destination buffer\n+  std::vector<uint32_t> restarts_;  // Restart points\n+  int counter_;                     // Number of entries emitted since restart\n+  bool finished_;                   // Has Finish() been called?\n+  std::string last_key_;\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "09ec0094bd8b4b788c3d21079ec4a317e3a9808d",
        "filename": "table/filter_block.cc",
        "status": "modified",
        "additions": 7,
        "deletions": 12,
        "changes": 19,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/filter_block.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/filter_block.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/filter_block.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -16,8 +16,7 @@ static const size_t kFilterBaseLg = 11;\n static const size_t kFilterBase = 1 << kFilterBaseLg;\n \n FilterBlockBuilder::FilterBlockBuilder(const FilterPolicy* policy)\n-    : policy_(policy) {\n-}\n+    : policy_(policy) {}\n \n void FilterBlockBuilder::StartBlock(uint64_t block_offset) {\n   uint64_t filter_index = (block_offset / kFilterBase);\n@@ -62,7 +61,7 @@ void FilterBlockBuilder::GenerateFilter() {\n   tmp_keys_.resize(num_keys);\n   for (size_t i = 0; i < num_keys; i++) {\n     const char* base = keys_.data() + start_[i];\n-    size_t length = start_[i+1] - start_[i];\n+    size_t length = start_[i + 1] - start_[i];\n     tmp_keys_[i] = Slice(base, length);\n   }\n \n@@ -77,14 +76,10 @@ void FilterBlockBuilder::GenerateFilter() {\n \n FilterBlockReader::FilterBlockReader(const FilterPolicy* policy,\n                                      const Slice& contents)\n-    : policy_(policy),\n-      data_(NULL),\n-      offset_(NULL),\n-      num_(0),\n-      base_lg_(0) {\n+    : policy_(policy), data_(nullptr), offset_(nullptr), num_(0), base_lg_(0) {\n   size_t n = contents.size();\n   if (n < 5) return;  // 1 byte for base_lg_ and 4 for start of offset array\n-  base_lg_ = contents[n-1];\n+  base_lg_ = contents[n - 1];\n   uint32_t last_word = DecodeFixed32(contents.data() + n - 5);\n   if (last_word > n - 5) return;\n   data_ = contents.data();\n@@ -95,8 +90,8 @@ FilterBlockReader::FilterBlockReader(const FilterPolicy* policy,\n bool FilterBlockReader::KeyMayMatch(uint64_t block_offset, const Slice& key) {\n   uint64_t index = block_offset >> base_lg_;\n   if (index < num_) {\n-    uint32_t start = DecodeFixed32(offset_ + index*4);\n-    uint32_t limit = DecodeFixed32(offset_ + index*4 + 4);\n+    uint32_t start = DecodeFixed32(offset_ + index * 4);\n+    uint32_t limit = DecodeFixed32(offset_ + index * 4 + 4);\n     if (start <= limit && limit <= static_cast<size_t>(offset_ - data_)) {\n       Slice filter = Slice(data_ + start, limit - start);\n       return policy_->KeyMayMatch(key, filter);\n@@ -108,4 +103,4 @@ bool FilterBlockReader::KeyMayMatch(uint64_t block_offset, const Slice& key) {\n   return true;  // Errors are treated as potential matches\n }\n \n-}\n+}  // namespace leveldb"
      },
      {
        "sha": "73b5399249666dc99518dfbc54e508f9c29dbe2e",
        "filename": "table/filter_block.h",
        "status": "modified",
        "additions": 11,
        "deletions": 10,
        "changes": 21,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/filter_block.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/filter_block.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/filter_block.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -11,8 +11,10 @@\n \n #include <stddef.h>\n #include <stdint.h>\n+\n #include <string>\n #include <vector>\n+\n #include \"leveldb/slice.h\"\n #include \"util/hash.h\"\n \n@@ -30,6 +32,9 @@ class FilterBlockBuilder {\n  public:\n   explicit FilterBlockBuilder(const FilterPolicy*);\n \n+  FilterBlockBuilder(const FilterBlockBuilder&) = delete;\n+  FilterBlockBuilder& operator=(const FilterBlockBuilder&) = delete;\n+\n   void StartBlock(uint64_t block_offset);\n   void AddKey(const Slice& key);\n   Slice Finish();\n@@ -38,20 +43,16 @@ class FilterBlockBuilder {\n   void GenerateFilter();\n \n   const FilterPolicy* policy_;\n-  std::string keys_;              // Flattened key contents\n-  std::vector<size_t> start_;     // Starting index in keys_ of each key\n-  std::string result_;            // Filter data computed so far\n-  std::vector<Slice> tmp_keys_;   // policy_->CreateFilter() argument\n+  std::string keys_;             // Flattened key contents\n+  std::vector<size_t> start_;    // Starting index in keys_ of each key\n+  std::string result_;           // Filter data computed so far\n+  std::vector<Slice> tmp_keys_;  // policy_->CreateFilter() argument\n   std::vector<uint32_t> filter_offsets_;\n-\n-  // No copying allowed\n-  FilterBlockBuilder(const FilterBlockBuilder&);\n-  void operator=(const FilterBlockBuilder&);\n };\n \n class FilterBlockReader {\n  public:\n- // REQUIRES: \"contents\" and *policy must stay live while *this is live.\n+  // REQUIRES: \"contents\" and *policy must stay live while *this is live.\n   FilterBlockReader(const FilterPolicy* policy, const Slice& contents);\n   bool KeyMayMatch(uint64_t block_offset, const Slice& key);\n \n@@ -63,6 +64,6 @@ class FilterBlockReader {\n   size_t base_lg_;      // Encoding parameter (see kFilterBaseLg in .cc file)\n };\n \n-}\n+}  // namespace leveldb\n \n #endif  // STORAGE_LEVELDB_TABLE_FILTER_BLOCK_H_"
      },
      {
        "sha": "8b33bbdd181331f4bb2e81c4108753f0258d6198",
        "filename": "table/filter_block_test.cc",
        "status": "modified",
        "additions": 17,
        "deletions": 21,
        "changes": 38,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/filter_block_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/filter_block_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/filter_block_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -16,18 +16,16 @@ namespace leveldb {\n // For testing: emit an array with one hash value per key\n class TestHashFilter : public FilterPolicy {\n  public:\n-  virtual const char* Name() const {\n-    return \"TestHashFilter\";\n-  }\n+  const char* Name() const override { return \"TestHashFilter\"; }\n \n-  virtual void CreateFilter(const Slice* keys, int n, std::string* dst) const {\n+  void CreateFilter(const Slice* keys, int n, std::string* dst) const override {\n     for (int i = 0; i < n; i++) {\n       uint32_t h = Hash(keys[i].data(), keys[i].size(), 1);\n       PutFixed32(dst, h);\n     }\n   }\n \n-  virtual bool KeyMayMatch(const Slice& key, const Slice& filter) const {\n+  bool KeyMayMatch(const Slice& key, const Slice& filter) const override {\n     uint32_t h = Hash(key.data(), key.size(), 1);\n     for (size_t i = 0; i + 4 <= filter.size(); i += 4) {\n       if (h == DecodeFixed32(filter.data() + i)) {\n@@ -69,8 +67,8 @@ TEST(FilterBlockTest, SingleChunk) {\n   ASSERT_TRUE(reader.KeyMayMatch(100, \"box\"));\n   ASSERT_TRUE(reader.KeyMayMatch(100, \"hello\"));\n   ASSERT_TRUE(reader.KeyMayMatch(100, \"foo\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(100, \"missing\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(100, \"other\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(100, \"missing\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(100, \"other\"));\n }\n \n TEST(FilterBlockTest, MultiChunk) {\n@@ -99,30 +97,28 @@ TEST(FilterBlockTest, MultiChunk) {\n   // Check first filter\n   ASSERT_TRUE(reader.KeyMayMatch(0, \"foo\"));\n   ASSERT_TRUE(reader.KeyMayMatch(2000, \"bar\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(0, \"box\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(0, \"hello\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(0, \"box\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(0, \"hello\"));\n \n   // Check second filter\n   ASSERT_TRUE(reader.KeyMayMatch(3100, \"box\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(3100, \"foo\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(3100, \"bar\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(3100, \"hello\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(3100, \"foo\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(3100, \"bar\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(3100, \"hello\"));\n \n   // Check third filter (empty)\n-  ASSERT_TRUE(! reader.KeyMayMatch(4100, \"foo\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(4100, \"bar\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(4100, \"box\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(4100, \"hello\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(4100, \"foo\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(4100, \"bar\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(4100, \"box\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(4100, \"hello\"));\n \n   // Check last filter\n   ASSERT_TRUE(reader.KeyMayMatch(9000, \"box\"));\n   ASSERT_TRUE(reader.KeyMayMatch(9000, \"hello\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(9000, \"foo\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(9000, \"bar\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(9000, \"foo\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(9000, \"bar\"));\n }\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "a3d67de2e41d4ffa16e927432ee389568cfda32f",
        "filename": "table/format.cc",
        "status": "modified",
        "additions": 4,
        "deletions": 7,
        "changes": 11,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/format.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/format.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/format.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -21,8 +21,7 @@ void BlockHandle::EncodeTo(std::string* dst) const {\n }\n \n Status BlockHandle::DecodeFrom(Slice* input) {\n-  if (GetVarint64(input, &offset_) &&\n-      GetVarint64(input, &size_)) {\n+  if (GetVarint64(input, &offset_) && GetVarint64(input, &size_)) {\n     return Status::OK();\n   } else {\n     return Status::Corruption(\"bad block handle\");\n@@ -62,10 +61,8 @@ Status Footer::DecodeFrom(Slice* input) {\n   return result;\n }\n \n-Status ReadBlock(RandomAccessFile* file,\n-                 const ReadOptions& options,\n-                 const BlockHandle& handle,\n-                 BlockContents* result) {\n+Status ReadBlock(RandomAccessFile* file, const ReadOptions& options,\n+                 const BlockHandle& handle, BlockContents* result) {\n   result->data = Slice();\n   result->cachable = false;\n   result->heap_allocated = false;\n@@ -86,7 +83,7 @@ Status ReadBlock(RandomAccessFile* file,\n   }\n \n   // Check the crc of the type and the block contents\n-  const char* data = contents.data();    // Pointer to where Read put the data\n+  const char* data = contents.data();  // Pointer to where Read put the data\n   if (options.verify_checksums) {\n     const uint32_t crc = crc32c::Unmask(DecodeFixed32(data + n + 1));\n     const uint32_t actual = crc32c::Value(data, n + 1);"
      },
      {
        "sha": "e49dfdc0477f340710810d6391b0f83605ba8787",
        "filename": "table/format.h",
        "status": "modified",
        "additions": 17,
        "deletions": 25,
        "changes": 42,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/format.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/format.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/format.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -5,8 +5,10 @@\n #ifndef STORAGE_LEVELDB_TABLE_FORMAT_H_\n #define STORAGE_LEVELDB_TABLE_FORMAT_H_\n \n-#include <string>\n #include <stdint.h>\n+\n+#include <string>\n+\n #include \"leveldb/slice.h\"\n #include \"leveldb/status.h\"\n #include \"leveldb/table_builder.h\"\n@@ -21,6 +23,9 @@ struct ReadOptions;\n // block or a meta block.\n class BlockHandle {\n  public:\n+  // Maximum encoding length of a BlockHandle\n+  enum { kMaxEncodedLength = 10 + 10 };\n+\n   BlockHandle();\n \n   // The offset of the block in the file.\n@@ -34,9 +39,6 @@ class BlockHandle {\n   void EncodeTo(std::string* dst) const;\n   Status DecodeFrom(Slice* input);\n \n-  // Maximum encoding length of a BlockHandle\n-  enum { kMaxEncodedLength = 10 + 10 };\n-\n  private:\n   uint64_t offset_;\n   uint64_t size_;\n@@ -46,30 +48,24 @@ class BlockHandle {\n // end of every table file.\n class Footer {\n  public:\n-  Footer() { }\n+  // Encoded length of a Footer.  Note that the serialization of a\n+  // Footer will always occupy exactly this many bytes.  It consists\n+  // of two block handles and a magic number.\n+  enum { kEncodedLength = 2 * BlockHandle::kMaxEncodedLength + 8 };\n+\n+  Footer() = default;\n \n   // The block handle for the metaindex block of the table\n   const BlockHandle& metaindex_handle() const { return metaindex_handle_; }\n   void set_metaindex_handle(const BlockHandle& h) { metaindex_handle_ = h; }\n \n   // The block handle for the index block of the table\n-  const BlockHandle& index_handle() const {\n-    return index_handle_;\n-  }\n-  void set_index_handle(const BlockHandle& h) {\n-    index_handle_ = h;\n-  }\n+  const BlockHandle& index_handle() const { return index_handle_; }\n+  void set_index_handle(const BlockHandle& h) { index_handle_ = h; }\n \n   void EncodeTo(std::string* dst) const;\n   Status DecodeFrom(Slice* input);\n \n-  // Encoded length of a Footer.  Note that the serialization of a\n-  // Footer will always occupy exactly this many bytes.  It consists\n-  // of two block handles and a magic number.\n-  enum {\n-    kEncodedLength = 2*BlockHandle::kMaxEncodedLength + 8\n-  };\n-\n  private:\n   BlockHandle metaindex_handle_;\n   BlockHandle index_handle_;\n@@ -91,17 +87,13 @@ struct BlockContents {\n \n // Read the block identified by \"handle\" from \"file\".  On failure\n // return non-OK.  On success fill *result and return OK.\n-extern Status ReadBlock(RandomAccessFile* file,\n-                        const ReadOptions& options,\n-                        const BlockHandle& handle,\n-                        BlockContents* result);\n+Status ReadBlock(RandomAccessFile* file, const ReadOptions& options,\n+                 const BlockHandle& handle, BlockContents* result);\n \n // Implementation details follow.  Clients should ignore,\n \n inline BlockHandle::BlockHandle()\n-    : offset_(~static_cast<uint64_t>(0)),\n-      size_(~static_cast<uint64_t>(0)) {\n-}\n+    : offset_(~static_cast<uint64_t>(0)), size_(~static_cast<uint64_t>(0)) {}\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "dfef083d4d756069b5c16d5684b3bd741b0ff814",
        "filename": "table/iterator.cc",
        "status": "modified",
        "additions": 42,
        "deletions": 33,
        "changes": 75,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/iterator.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/iterator.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/iterator.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -7,58 +7,67 @@\n namespace leveldb {\n \n Iterator::Iterator() {\n-  cleanup_.function = NULL;\n-  cleanup_.next = NULL;\n+  cleanup_head_.function = nullptr;\n+  cleanup_head_.next = nullptr;\n }\n \n Iterator::~Iterator() {\n-  if (cleanup_.function != NULL) {\n-    (*cleanup_.function)(cleanup_.arg1, cleanup_.arg2);\n-    for (Cleanup* c = cleanup_.next; c != NULL; ) {\n-      (*c->function)(c->arg1, c->arg2);\n-      Cleanup* next = c->next;\n-      delete c;\n-      c = next;\n+  if (!cleanup_head_.IsEmpty()) {\n+    cleanup_head_.Run();\n+    for (CleanupNode* node = cleanup_head_.next; node != nullptr;) {\n+      node->Run();\n+      CleanupNode* next_node = node->next;\n+      delete node;\n+      node = next_node;\n     }\n   }\n }\n \n void Iterator::RegisterCleanup(CleanupFunction func, void* arg1, void* arg2) {\n-  assert(func != NULL);\n-  Cleanup* c;\n-  if (cleanup_.function == NULL) {\n-    c = &cleanup_;\n+  assert(func != nullptr);\n+  CleanupNode* node;\n+  if (cleanup_head_.IsEmpty()) {\n+    node = &cleanup_head_;\n   } else {\n-    c = new Cleanup;\n-    c->next = cleanup_.next;\n-    cleanup_.next = c;\n+    node = new CleanupNode();\n+    node->next = cleanup_head_.next;\n+    cleanup_head_.next = node;\n   }\n-  c->function = func;\n-  c->arg1 = arg1;\n-  c->arg2 = arg2;\n+  node->function = func;\n+  node->arg1 = arg1;\n+  node->arg2 = arg2;\n }\n \n namespace {\n+\n class EmptyIterator : public Iterator {\n  public:\n-  EmptyIterator(const Status& s) : status_(s) { }\n-  virtual bool Valid() const { return false; }\n-  virtual void Seek(const Slice& target) { }\n-  virtual void SeekToFirst() { }\n-  virtual void SeekToLast() { }\n-  virtual void Next() { assert(false); }\n-  virtual void Prev() { assert(false); }\n-  Slice key() const { assert(false); return Slice(); }\n-  Slice value() const { assert(false); return Slice(); }\n-  virtual Status status() const { return status_; }\n+  EmptyIterator(const Status& s) : status_(s) {}\n+  ~EmptyIterator() override = default;\n+\n+  bool Valid() const override { return false; }\n+  void Seek(const Slice& target) override {}\n+  void SeekToFirst() override {}\n+  void SeekToLast() override {}\n+  void Next() override { assert(false); }\n+  void Prev() override { assert(false); }\n+  Slice key() const override {\n+    assert(false);\n+    return Slice();\n+  }\n+  Slice value() const override {\n+    assert(false);\n+    return Slice();\n+  }\n+  Status status() const override { return status_; }\n+\n  private:\n   Status status_;\n };\n-}  // namespace\n \n-Iterator* NewEmptyIterator() {\n-  return new EmptyIterator(Status::OK());\n-}\n+}  // anonymous namespace\n+\n+Iterator* NewEmptyIterator() { return new EmptyIterator(Status::OK()); }\n \n Iterator* NewErrorIterator(const Status& status) {\n   return new EmptyIterator(status);"
      },
      {
        "sha": "c230572529ce5394887fd48a926b4afbaba060f7",
        "filename": "table/iterator_wrapper.h",
        "status": "modified",
        "additions": 42,
        "deletions": 16,
        "changes": 58,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/iterator_wrapper.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/iterator_wrapper.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/iterator_wrapper.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -16,10 +16,8 @@ namespace leveldb {\n // cache locality.\n class IteratorWrapper {\n  public:\n-  IteratorWrapper(): iter_(NULL), valid_(false) { }\n-  explicit IteratorWrapper(Iterator* iter): iter_(NULL) {\n-    Set(iter);\n-  }\n+  IteratorWrapper() : iter_(nullptr), valid_(false) {}\n+  explicit IteratorWrapper(Iterator* iter) : iter_(nullptr) { Set(iter); }\n   ~IteratorWrapper() { delete iter_; }\n   Iterator* iter() const { return iter_; }\n \n@@ -28,25 +26,53 @@ class IteratorWrapper {\n   void Set(Iterator* iter) {\n     delete iter_;\n     iter_ = iter;\n-    if (iter_ == NULL) {\n+    if (iter_ == nullptr) {\n       valid_ = false;\n     } else {\n       Update();\n     }\n   }\n \n-\n   // Iterator interface methods\n-  bool Valid() const        { return valid_; }\n-  Slice key() const         { assert(Valid()); return key_; }\n-  Slice value() const       { assert(Valid()); return iter_->value(); }\n-  // Methods below require iter() != NULL\n-  Status status() const     { assert(iter_); return iter_->status(); }\n-  void Next()               { assert(iter_); iter_->Next();        Update(); }\n-  void Prev()               { assert(iter_); iter_->Prev();        Update(); }\n-  void Seek(const Slice& k) { assert(iter_); iter_->Seek(k);       Update(); }\n-  void SeekToFirst()        { assert(iter_); iter_->SeekToFirst(); Update(); }\n-  void SeekToLast()         { assert(iter_); iter_->SeekToLast();  Update(); }\n+  bool Valid() const { return valid_; }\n+  Slice key() const {\n+    assert(Valid());\n+    return key_;\n+  }\n+  Slice value() const {\n+    assert(Valid());\n+    return iter_->value();\n+  }\n+  // Methods below require iter() != nullptr\n+  Status status() const {\n+    assert(iter_);\n+    return iter_->status();\n+  }\n+  void Next() {\n+    assert(iter_);\n+    iter_->Next();\n+    Update();\n+  }\n+  void Prev() {\n+    assert(iter_);\n+    iter_->Prev();\n+    Update();\n+  }\n+  void Seek(const Slice& k) {\n+    assert(iter_);\n+    iter_->Seek(k);\n+    Update();\n+  }\n+  void SeekToFirst() {\n+    assert(iter_);\n+    iter_->SeekToFirst();\n+    Update();\n+  }\n+  void SeekToLast() {\n+    assert(iter_);\n+    iter_->SeekToLast();\n+    Update();\n+  }\n \n  private:\n   void Update() {"
      },
      {
        "sha": "76441b1cc21747bacd41bc8e02cd03ca3ac970d9",
        "filename": "table/merger.cc",
        "status": "modified",
        "additions": 23,
        "deletions": 29,
        "changes": 52,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/merger.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/merger.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/merger.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -17,46 +17,42 @@ class MergingIterator : public Iterator {\n       : comparator_(comparator),\n         children_(new IteratorWrapper[n]),\n         n_(n),\n-        current_(NULL),\n+        current_(nullptr),\n         direction_(kForward) {\n     for (int i = 0; i < n; i++) {\n       children_[i].Set(children[i]);\n     }\n   }\n \n-  virtual ~MergingIterator() {\n-    delete[] children_;\n-  }\n+  ~MergingIterator() override { delete[] children_; }\n \n-  virtual bool Valid() const {\n-    return (current_ != NULL);\n-  }\n+  bool Valid() const override { return (current_ != nullptr); }\n \n-  virtual void SeekToFirst() {\n+  void SeekToFirst() override {\n     for (int i = 0; i < n_; i++) {\n       children_[i].SeekToFirst();\n     }\n     FindSmallest();\n     direction_ = kForward;\n   }\n \n-  virtual void SeekToLast() {\n+  void SeekToLast() override {\n     for (int i = 0; i < n_; i++) {\n       children_[i].SeekToLast();\n     }\n     FindLargest();\n     direction_ = kReverse;\n   }\n \n-  virtual void Seek(const Slice& target) {\n+  void Seek(const Slice& target) override {\n     for (int i = 0; i < n_; i++) {\n       children_[i].Seek(target);\n     }\n     FindSmallest();\n     direction_ = kForward;\n   }\n \n-  virtual void Next() {\n+  void Next() override {\n     assert(Valid());\n \n     // Ensure that all children are positioned after key().\n@@ -82,7 +78,7 @@ class MergingIterator : public Iterator {\n     FindSmallest();\n   }\n \n-  virtual void Prev() {\n+  void Prev() override {\n     assert(Valid());\n \n     // Ensure that all children are positioned before key().\n@@ -111,17 +107,17 @@ class MergingIterator : public Iterator {\n     FindLargest();\n   }\n \n-  virtual Slice key() const {\n+  Slice key() const override {\n     assert(Valid());\n     return current_->key();\n   }\n \n-  virtual Slice value() const {\n+  Slice value() const override {\n     assert(Valid());\n     return current_->value();\n   }\n \n-  virtual Status status() const {\n+  Status status() const override {\n     Status status;\n     for (int i = 0; i < n_; i++) {\n       status = children_[i].status();\n@@ -133,6 +129,9 @@ class MergingIterator : public Iterator {\n   }\n \n  private:\n+  // Which direction is the iterator moving?\n+  enum Direction { kForward, kReverse };\n+\n   void FindSmallest();\n   void FindLargest();\n \n@@ -143,21 +142,15 @@ class MergingIterator : public Iterator {\n   IteratorWrapper* children_;\n   int n_;\n   IteratorWrapper* current_;\n-\n-  // Which direction is the iterator moving?\n-  enum Direction {\n-    kForward,\n-    kReverse\n-  };\n   Direction direction_;\n };\n \n void MergingIterator::FindSmallest() {\n-  IteratorWrapper* smallest = NULL;\n+  IteratorWrapper* smallest = nullptr;\n   for (int i = 0; i < n_; i++) {\n     IteratorWrapper* child = &children_[i];\n     if (child->Valid()) {\n-      if (smallest == NULL) {\n+      if (smallest == nullptr) {\n         smallest = child;\n       } else if (comparator_->Compare(child->key(), smallest->key()) < 0) {\n         smallest = child;\n@@ -168,11 +161,11 @@ void MergingIterator::FindSmallest() {\n }\n \n void MergingIterator::FindLargest() {\n-  IteratorWrapper* largest = NULL;\n-  for (int i = n_-1; i >= 0; i--) {\n+  IteratorWrapper* largest = nullptr;\n+  for (int i = n_ - 1; i >= 0; i--) {\n     IteratorWrapper* child = &children_[i];\n     if (child->Valid()) {\n-      if (largest == NULL) {\n+      if (largest == nullptr) {\n         largest = child;\n       } else if (comparator_->Compare(child->key(), largest->key()) > 0) {\n         largest = child;\n@@ -183,14 +176,15 @@ void MergingIterator::FindLargest() {\n }\n }  // namespace\n \n-Iterator* NewMergingIterator(const Comparator* cmp, Iterator** list, int n) {\n+Iterator* NewMergingIterator(const Comparator* comparator, Iterator** children,\n+                             int n) {\n   assert(n >= 0);\n   if (n == 0) {\n     return NewEmptyIterator();\n   } else if (n == 1) {\n-    return list[0];\n+    return children[0];\n   } else {\n-    return new MergingIterator(cmp, list, n);\n+    return new MergingIterator(comparator, children, n);\n   }\n }\n "
      },
      {
        "sha": "41cedc525448a6597662590d3642f0898f704816",
        "filename": "table/merger.h",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/merger.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/merger.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/merger.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -18,8 +18,8 @@ class Iterator;\n // key is present in K child iterators, it will be yielded K times.\n //\n // REQUIRES: n >= 0\n-extern Iterator* NewMergingIterator(\n-    const Comparator* comparator, Iterator** children, int n);\n+Iterator* NewMergingIterator(const Comparator* comparator, Iterator** children,\n+                             int n);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "b07bc88c7eb4d7166ef2bd30af215a14a554718f",
        "filename": "table/table.cc",
        "status": "modified",
        "additions": 28,
        "deletions": 40,
        "changes": 68,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/table.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/table.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/table.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -20,7 +20,7 @@ namespace leveldb {\n struct Table::Rep {\n   ~Rep() {\n     delete filter;\n-    delete [] filter_data;\n+    delete[] filter_data;\n     delete index_block;\n   }\n \n@@ -35,11 +35,9 @@ struct Table::Rep {\n   Block* index_block;\n };\n \n-Status Table::Open(const Options& options,\n-                   RandomAccessFile* file,\n-                   uint64_t size,\n-                   Table** table) {\n-  *table = NULL;\n+Status Table::Open(const Options& options, RandomAccessFile* file,\n+                   uint64_t size, Table** table) {\n+  *table = nullptr;\n   if (size < Footer::kEncodedLength) {\n     return Status::Corruption(\"file is too short to be an sstable\");\n   }\n@@ -55,41 +53,36 @@ Status Table::Open(const Options& options,\n   if (!s.ok()) return s;\n \n   // Read the index block\n-  BlockContents contents;\n-  Block* index_block = NULL;\n+  BlockContents index_block_contents;\n   if (s.ok()) {\n     ReadOptions opt;\n     if (options.paranoid_checks) {\n       opt.verify_checksums = true;\n     }\n-    s = ReadBlock(file, opt, footer.index_handle(), &contents);\n-    if (s.ok()) {\n-      index_block = new Block(contents);\n-    }\n+    s = ReadBlock(file, opt, footer.index_handle(), &index_block_contents);\n   }\n \n   if (s.ok()) {\n     // We've successfully read the footer and the index block: we're\n     // ready to serve requests.\n+    Block* index_block = new Block(index_block_contents);\n     Rep* rep = new Table::Rep;\n     rep->options = options;\n     rep->file = file;\n     rep->metaindex_handle = footer.metaindex_handle();\n     rep->index_block = index_block;\n     rep->cache_id = (options.block_cache ? options.block_cache->NewId() : 0);\n-    rep->filter_data = NULL;\n-    rep->filter = NULL;\n+    rep->filter_data = nullptr;\n+    rep->filter = nullptr;\n     *table = new Table(rep);\n     (*table)->ReadMeta(footer);\n-  } else {\n-    delete index_block;\n   }\n \n   return s;\n }\n \n void Table::ReadMeta(const Footer& footer) {\n-  if (rep_->options.filter_policy == NULL) {\n+  if (rep_->options.filter_policy == nullptr) {\n     return;  // Do not need any metadata\n   }\n \n@@ -135,14 +128,12 @@ void Table::ReadFilter(const Slice& filter_handle_value) {\n     return;\n   }\n   if (block.heap_allocated) {\n-    rep_->filter_data = block.data.data();     // Will need to delete later\n+    rep_->filter_data = block.data.data();  // Will need to delete later\n   }\n   rep_->filter = new FilterBlockReader(rep_->options.filter_policy, block.data);\n }\n \n-Table::~Table() {\n-  delete rep_;\n-}\n+Table::~Table() { delete rep_; }\n \n static void DeleteBlock(void* arg, void* ignored) {\n   delete reinterpret_cast<Block*>(arg);\n@@ -161,13 +152,12 @@ static void ReleaseBlock(void* arg, void* h) {\n \n // Convert an index iterator value (i.e., an encoded BlockHandle)\n // into an iterator over the contents of the corresponding block.\n-Iterator* Table::BlockReader(void* arg,\n-                             const ReadOptions& options,\n+Iterator* Table::BlockReader(void* arg, const ReadOptions& options,\n                              const Slice& index_value) {\n   Table* table = reinterpret_cast<Table*>(arg);\n   Cache* block_cache = table->rep_->options.block_cache;\n-  Block* block = NULL;\n-  Cache::Handle* cache_handle = NULL;\n+  Block* block = nullptr;\n+  Cache::Handle* cache_handle = nullptr;\n \n   BlockHandle handle;\n   Slice input = index_value;\n@@ -177,21 +167,21 @@ Iterator* Table::BlockReader(void* arg,\n \n   if (s.ok()) {\n     BlockContents contents;\n-    if (block_cache != NULL) {\n+    if (block_cache != nullptr) {\n       char cache_key_buffer[16];\n       EncodeFixed64(cache_key_buffer, table->rep_->cache_id);\n-      EncodeFixed64(cache_key_buffer+8, handle.offset());\n+      EncodeFixed64(cache_key_buffer + 8, handle.offset());\n       Slice key(cache_key_buffer, sizeof(cache_key_buffer));\n       cache_handle = block_cache->Lookup(key);\n-      if (cache_handle != NULL) {\n+      if (cache_handle != nullptr) {\n         block = reinterpret_cast<Block*>(block_cache->Value(cache_handle));\n       } else {\n         s = ReadBlock(table->rep_->file, options, handle, &contents);\n         if (s.ok()) {\n           block = new Block(contents);\n           if (contents.cachable && options.fill_cache) {\n-            cache_handle = block_cache->Insert(\n-                key, block, block->size(), &DeleteCachedBlock);\n+            cache_handle = block_cache->Insert(key, block, block->size(),\n+                                               &DeleteCachedBlock);\n           }\n         }\n       }\n@@ -204,10 +194,10 @@ Iterator* Table::BlockReader(void* arg,\n   }\n \n   Iterator* iter;\n-  if (block != NULL) {\n+  if (block != nullptr) {\n     iter = block->NewIterator(table->rep_->options.comparator);\n-    if (cache_handle == NULL) {\n-      iter->RegisterCleanup(&DeleteBlock, block, NULL);\n+    if (cache_handle == nullptr) {\n+      iter->RegisterCleanup(&DeleteBlock, block, nullptr);\n     } else {\n       iter->RegisterCleanup(&ReleaseBlock, block_cache, cache_handle);\n     }\n@@ -223,25 +213,24 @@ Iterator* Table::NewIterator(const ReadOptions& options) const {\n       &Table::BlockReader, const_cast<Table*>(this), options);\n }\n \n-Status Table::InternalGet(const ReadOptions& options, const Slice& k,\n-                          void* arg,\n-                          void (*saver)(void*, const Slice&, const Slice&)) {\n+Status Table::InternalGet(const ReadOptions& options, const Slice& k, void* arg,\n+                          void (*handle_result)(void*, const Slice&,\n+                                                const Slice&)) {\n   Status s;\n   Iterator* iiter = rep_->index_block->NewIterator(rep_->options.comparator);\n   iiter->Seek(k);\n   if (iiter->Valid()) {\n     Slice handle_value = iiter->value();\n     FilterBlockReader* filter = rep_->filter;\n     BlockHandle handle;\n-    if (filter != NULL &&\n-        handle.DecodeFrom(&handle_value).ok() &&\n+    if (filter != nullptr && handle.DecodeFrom(&handle_value).ok() &&\n         !filter->KeyMayMatch(handle.offset(), k)) {\n       // Not found\n     } else {\n       Iterator* block_iter = BlockReader(this, options, iiter->value());\n       block_iter->Seek(k);\n       if (block_iter->Valid()) {\n-        (*saver)(arg, block_iter->key(), block_iter->value());\n+        (*handle_result)(arg, block_iter->key(), block_iter->value());\n       }\n       s = block_iter->status();\n       delete block_iter;\n@@ -254,7 +243,6 @@ Status Table::InternalGet(const ReadOptions& options, const Slice& k,\n   return s;\n }\n \n-\n uint64_t Table::ApproximateOffsetOf(const Slice& key) const {\n   Iterator* index_iter =\n       rep_->index_block->NewIterator(rep_->options.comparator);"
      },
      {
        "sha": "278febf94f197ee8ee711c992ce6fd62d5ce88be",
        "filename": "table/table_builder.cc",
        "status": "modified",
        "additions": 28,
        "deletions": 33,
        "changes": 61,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/table_builder.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/table_builder.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/table_builder.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -5,6 +5,7 @@\n #include \"leveldb/table_builder.h\"\n \n #include <assert.h>\n+\n #include \"leveldb/comparator.h\"\n #include \"leveldb/env.h\"\n #include \"leveldb/filter_policy.h\"\n@@ -18,6 +19,22 @@\n namespace leveldb {\n \n struct TableBuilder::Rep {\n+  Rep(const Options& opt, WritableFile* f)\n+      : options(opt),\n+        index_block_options(opt),\n+        file(f),\n+        offset(0),\n+        data_block(&options),\n+        index_block(&index_block_options),\n+        num_entries(0),\n+        closed(false),\n+        filter_block(opt.filter_policy == nullptr\n+                         ? nullptr\n+                         : new FilterBlockBuilder(opt.filter_policy)),\n+        pending_index_entry(false) {\n+    index_block_options.block_restart_interval = 1;\n+  }\n+\n   Options options;\n   Options index_block_options;\n   WritableFile* file;\n@@ -27,7 +44,7 @@ struct TableBuilder::Rep {\n   BlockBuilder index_block;\n   std::string last_key;\n   int64_t num_entries;\n-  bool closed;          // Either Finish() or Abandon() has been called.\n+  bool closed;  // Either Finish() or Abandon() has been called.\n   FilterBlockBuilder* filter_block;\n \n   // We do not emit the index entry for a block until we have seen the\n@@ -43,26 +60,11 @@ struct TableBuilder::Rep {\n   BlockHandle pending_handle;  // Handle to add to index block\n \n   std::string compressed_output;\n-\n-  Rep(const Options& opt, WritableFile* f)\n-      : options(opt),\n-        index_block_options(opt),\n-        file(f),\n-        offset(0),\n-        data_block(&options),\n-        index_block(&index_block_options),\n-        num_entries(0),\n-        closed(false),\n-        filter_block(opt.filter_policy == NULL ? NULL\n-                     : new FilterBlockBuilder(opt.filter_policy)),\n-        pending_index_entry(false) {\n-    index_block_options.block_restart_interval = 1;\n-  }\n };\n \n TableBuilder::TableBuilder(const Options& options, WritableFile* file)\n     : rep_(new Rep(options, file)) {\n-  if (rep_->filter_block != NULL) {\n+  if (rep_->filter_block != nullptr) {\n     rep_->filter_block->StartBlock(0);\n   }\n }\n@@ -106,7 +108,7 @@ void TableBuilder::Add(const Slice& key, const Slice& value) {\n     r->pending_index_entry = false;\n   }\n \n-  if (r->filter_block != NULL) {\n+  if (r->filter_block != nullptr) {\n     r->filter_block->AddKey(key);\n   }\n \n@@ -131,7 +133,7 @@ void TableBuilder::Flush() {\n     r->pending_index_entry = true;\n     r->status = r->file->Flush();\n   }\n-  if (r->filter_block != NULL) {\n+  if (r->filter_block != nullptr) {\n     r->filter_block->StartBlock(r->offset);\n   }\n }\n@@ -173,8 +175,7 @@ void TableBuilder::WriteBlock(BlockBuilder* block, BlockHandle* handle) {\n }\n \n void TableBuilder::WriteRawBlock(const Slice& block_contents,\n-                                 CompressionType type,\n-                                 BlockHandle* handle) {\n+                                 CompressionType type, BlockHandle* handle) {\n   Rep* r = rep_;\n   handle->set_offset(r->offset);\n   handle->set_size(block_contents.size());\n@@ -184,17 +185,15 @@ void TableBuilder::WriteRawBlock(const Slice& block_contents,\n     trailer[0] = type;\n     uint32_t crc = crc32c::Value(block_contents.data(), block_contents.size());\n     crc = crc32c::Extend(crc, trailer, 1);  // Extend crc to cover block type\n-    EncodeFixed32(trailer+1, crc32c::Mask(crc));\n+    EncodeFixed32(trailer + 1, crc32c::Mask(crc));\n     r->status = r->file->Append(Slice(trailer, kBlockTrailerSize));\n     if (r->status.ok()) {\n       r->offset += block_contents.size() + kBlockTrailerSize;\n     }\n   }\n }\n \n-Status TableBuilder::status() const {\n-  return rep_->status;\n-}\n+Status TableBuilder::status() const { return rep_->status; }\n \n Status TableBuilder::Finish() {\n   Rep* r = rep_;\n@@ -205,15 +204,15 @@ Status TableBuilder::Finish() {\n   BlockHandle filter_block_handle, metaindex_block_handle, index_block_handle;\n \n   // Write filter block\n-  if (ok() && r->filter_block != NULL) {\n+  if (ok() && r->filter_block != nullptr) {\n     WriteRawBlock(r->filter_block->Finish(), kNoCompression,\n                   &filter_block_handle);\n   }\n \n   // Write metaindex block\n   if (ok()) {\n     BlockBuilder meta_index_block(&r->options);\n-    if (r->filter_block != NULL) {\n+    if (r->filter_block != nullptr) {\n       // Add mapping from \"filter.Name\" to location of filter data\n       std::string key = \"filter.\";\n       key.append(r->options.filter_policy->Name());\n@@ -259,12 +258,8 @@ void TableBuilder::Abandon() {\n   r->closed = true;\n }\n \n-uint64_t TableBuilder::NumEntries() const {\n-  return rep_->num_entries;\n-}\n+uint64_t TableBuilder::NumEntries() const { return rep_->num_entries; }\n \n-uint64_t TableBuilder::FileSize() const {\n-  return rep_->offset;\n-}\n+uint64_t TableBuilder::FileSize() const { return rep_->offset; }\n \n }  // namespace leveldb"
      },
      {
        "sha": "17aaea2f9e8b48484c4ba129a656854e4681596d",
        "filename": "table/table_test.cc",
        "status": "modified",
        "additions": 138,
        "deletions": 177,
        "changes": 315,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/table_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/table_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/table_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -6,6 +6,7 @@\n \n #include <map>\n #include <string>\n+\n #include \"db/dbformat.h\"\n #include \"db/memtable.h\"\n #include \"db/write_batch_internal.h\"\n@@ -27,8 +28,8 @@ namespace leveldb {\n static std::string Reverse(const Slice& key) {\n   std::string str(key.ToString());\n   std::string rev(\"\");\n-  for (std::string::reverse_iterator rit = str.rbegin();\n-       rit != str.rend(); ++rit) {\n+  for (std::string::reverse_iterator rit = str.rbegin(); rit != str.rend();\n+       ++rit) {\n     rev.push_back(*rit);\n   }\n   return rev;\n@@ -37,24 +38,23 @@ static std::string Reverse(const Slice& key) {\n namespace {\n class ReverseKeyComparator : public Comparator {\n  public:\n-  virtual const char* Name() const {\n+  const char* Name() const override {\n     return \"leveldb.ReverseBytewiseComparator\";\n   }\n \n-  virtual int Compare(const Slice& a, const Slice& b) const {\n+  int Compare(const Slice& a, const Slice& b) const override {\n     return BytewiseComparator()->Compare(Reverse(a), Reverse(b));\n   }\n \n-  virtual void FindShortestSeparator(\n-      std::string* start,\n-      const Slice& limit) const {\n+  void FindShortestSeparator(std::string* start,\n+                             const Slice& limit) const override {\n     std::string s = Reverse(*start);\n     std::string l = Reverse(limit);\n     BytewiseComparator()->FindShortestSeparator(&s, l);\n     *start = Reverse(s);\n   }\n \n-  virtual void FindShortSuccessor(std::string* key) const {\n+  void FindShortSuccessor(std::string* key) const override {\n     std::string s = Reverse(*key);\n     BytewiseComparator()->FindShortSuccessor(&s);\n     *key = Reverse(s);\n@@ -79,47 +79,46 @@ namespace {\n struct STLLessThan {\n   const Comparator* cmp;\n \n-  STLLessThan() : cmp(BytewiseComparator()) { }\n-  STLLessThan(const Comparator* c) : cmp(c) { }\n+  STLLessThan() : cmp(BytewiseComparator()) {}\n+  STLLessThan(const Comparator* c) : cmp(c) {}\n   bool operator()(const std::string& a, const std::string& b) const {\n     return cmp->Compare(Slice(a), Slice(b)) < 0;\n   }\n };\n }  // namespace\n \n-class StringSink: public WritableFile {\n+class StringSink : public WritableFile {\n  public:\n-  ~StringSink() { }\n+  ~StringSink() override = default;\n \n   const std::string& contents() const { return contents_; }\n \n-  virtual Status Close() { return Status::OK(); }\n-  virtual Status Flush() { return Status::OK(); }\n-  virtual Status Sync() { return Status::OK(); }\n+  Status Close() override { return Status::OK(); }\n+  Status Flush() override { return Status::OK(); }\n+  Status Sync() override { return Status::OK(); }\n \n-  virtual Status Append(const Slice& data) {\n+  Status Append(const Slice& data) override {\n     contents_.append(data.data(), data.size());\n     return Status::OK();\n   }\n \n+  std::string GetName() const override { return \"\"; }\n  private:\n   std::string contents_;\n };\n \n-\n-class StringSource: public RandomAccessFile {\n+class StringSource : public RandomAccessFile {\n  public:\n   StringSource(const Slice& contents)\n-      : contents_(contents.data(), contents.size()) {\n-  }\n+      : contents_(contents.data(), contents.size()) {}\n \n-  virtual ~StringSource() { }\n+  ~StringSource() override = default;\n \n   uint64_t Size() const { return contents_.size(); }\n \n-  virtual Status Read(uint64_t offset, size_t n, Slice* result,\n-                       char* scratch) const {\n-    if (offset > contents_.size()) {\n+  Status Read(uint64_t offset, size_t n, Slice* result,\n+              char* scratch) const override {\n+    if (offset >= contents_.size()) {\n       return Status::InvalidArgument(\"invalid Read offset\");\n     }\n     if (offset + n > contents_.size()) {\n@@ -130,6 +129,7 @@ class StringSource: public RandomAccessFile {\n     return Status::OK();\n   }\n \n+  std::string GetName() const { return \"\"; }\n  private:\n   std::string contents_;\n };\n@@ -140,8 +140,8 @@ typedef std::map<std::string, std::string, STLLessThan> KVMap;\n // BlockBuilder/TableBuilder and Block/Table.\n class Constructor {\n  public:\n-  explicit Constructor(const Comparator* cmp) : data_(STLLessThan(cmp)) { }\n-  virtual ~Constructor() { }\n+  explicit Constructor(const Comparator* cmp) : data_(STLLessThan(cmp)) {}\n+  virtual ~Constructor() = default;\n \n   void Add(const std::string& key, const Slice& value) {\n     data_[key] = value.ToString();\n@@ -150,15 +150,12 @@ class Constructor {\n   // Finish constructing the data structure with all the keys that have\n   // been added so far.  Returns the keys in sorted order in \"*keys\"\n   // and stores the key/value pairs in \"*kvmap\"\n-  void Finish(const Options& options,\n-              std::vector<std::string>* keys,\n+  void Finish(const Options& options, std::vector<std::string>* keys,\n               KVMap* kvmap) {\n     *kvmap = data_;\n     keys->clear();\n-    for (KVMap::const_iterator it = data_.begin();\n-         it != data_.end();\n-         ++it) {\n-      keys->push_back(it->first);\n+    for (const auto& kvp : data_) {\n+      keys->push_back(kvp.first);\n     }\n     data_.clear();\n     Status s = FinishImpl(options, *kvmap);\n@@ -170,32 +167,26 @@ class Constructor {\n \n   virtual Iterator* NewIterator() const = 0;\n \n-  virtual const KVMap& data() { return data_; }\n+  const KVMap& data() const { return data_; }\n \n-  virtual DB* db() const { return NULL; }  // Overridden in DBConstructor\n+  virtual DB* db() const { return nullptr; }  // Overridden in DBConstructor\n \n  private:\n   KVMap data_;\n };\n \n-class BlockConstructor: public Constructor {\n+class BlockConstructor : public Constructor {\n  public:\n   explicit BlockConstructor(const Comparator* cmp)\n-      : Constructor(cmp),\n-        comparator_(cmp),\n-        block_(NULL) { }\n-  ~BlockConstructor() {\n+      : Constructor(cmp), comparator_(cmp), block_(nullptr) {}\n+  ~BlockConstructor() override { delete block_; }\n+  Status FinishImpl(const Options& options, const KVMap& data) override {\n     delete block_;\n-  }\n-  virtual Status FinishImpl(const Options& options, const KVMap& data) {\n-    delete block_;\n-    block_ = NULL;\n+    block_ = nullptr;\n     BlockBuilder builder(&options);\n \n-    for (KVMap::const_iterator it = data.begin();\n-         it != data.end();\n-         ++it) {\n-      builder.Add(it->first, it->second);\n+    for (const auto& kvp : data) {\n+      builder.Add(kvp.first, kvp.second);\n     }\n     // Open the block\n     data_ = builder.Finish().ToString();\n@@ -206,36 +197,30 @@ class BlockConstructor: public Constructor {\n     block_ = new Block(contents);\n     return Status::OK();\n   }\n-  virtual Iterator* NewIterator() const {\n+  Iterator* NewIterator() const override {\n     return block_->NewIterator(comparator_);\n   }\n \n  private:\n-  const Comparator* comparator_;\n+  const Comparator* const comparator_;\n   std::string data_;\n   Block* block_;\n \n   BlockConstructor();\n };\n \n-class TableConstructor: public Constructor {\n+class TableConstructor : public Constructor {\n  public:\n   TableConstructor(const Comparator* cmp)\n-      : Constructor(cmp),\n-        source_(NULL), table_(NULL) {\n-  }\n-  ~TableConstructor() {\n-    Reset();\n-  }\n-  virtual Status FinishImpl(const Options& options, const KVMap& data) {\n+      : Constructor(cmp), source_(nullptr), table_(nullptr) {}\n+  ~TableConstructor() override { Reset(); }\n+  Status FinishImpl(const Options& options, const KVMap& data) override {\n     Reset();\n     StringSink sink;\n     TableBuilder builder(options, &sink);\n \n-    for (KVMap::const_iterator it = data.begin();\n-         it != data.end();\n-         ++it) {\n-      builder.Add(it->first, it->second);\n+    for (const auto& kvp : data) {\n+      builder.Add(kvp.first, kvp.second);\n       ASSERT_TRUE(builder.status().ok());\n     }\n     Status s = builder.Finish();\n@@ -250,7 +235,7 @@ class TableConstructor: public Constructor {\n     return Table::Open(table_options, source_, sink.contents().size(), &table_);\n   }\n \n-  virtual Iterator* NewIterator() const {\n+  Iterator* NewIterator() const override {\n     return table_->NewIterator(ReadOptions());\n   }\n \n@@ -262,8 +247,8 @@ class TableConstructor: public Constructor {\n   void Reset() {\n     delete table_;\n     delete source_;\n-    table_ = NULL;\n-    source_ = NULL;\n+    table_ = nullptr;\n+    source_ = nullptr;\n   }\n \n   StringSource* source_;\n@@ -273,23 +258,28 @@ class TableConstructor: public Constructor {\n };\n \n // A helper class that converts internal format keys into user keys\n-class KeyConvertingIterator: public Iterator {\n+class KeyConvertingIterator : public Iterator {\n  public:\n-  explicit KeyConvertingIterator(Iterator* iter) : iter_(iter) { }\n-  virtual ~KeyConvertingIterator() { delete iter_; }\n-  virtual bool Valid() const { return iter_->Valid(); }\n-  virtual void Seek(const Slice& target) {\n+  explicit KeyConvertingIterator(Iterator* iter) : iter_(iter) {}\n+\n+  KeyConvertingIterator(const KeyConvertingIterator&) = delete;\n+  KeyConvertingIterator& operator=(const KeyConvertingIterator&) = delete;\n+\n+  ~KeyConvertingIterator() override { delete iter_; }\n+\n+  bool Valid() const override { return iter_->Valid(); }\n+  void Seek(const Slice& target) override {\n     ParsedInternalKey ikey(target, kMaxSequenceNumber, kTypeValue);\n     std::string encoded;\n     AppendInternalKey(&encoded, ikey);\n     iter_->Seek(encoded);\n   }\n-  virtual void SeekToFirst() { iter_->SeekToFirst(); }\n-  virtual void SeekToLast() { iter_->SeekToLast(); }\n-  virtual void Next() { iter_->Next(); }\n-  virtual void Prev() { iter_->Prev(); }\n+  void SeekToFirst() override { iter_->SeekToFirst(); }\n+  void SeekToLast() override { iter_->SeekToLast(); }\n+  void Next() override { iter_->Next(); }\n+  void Prev() override { iter_->Prev(); }\n \n-  virtual Slice key() const {\n+  Slice key() const override {\n     assert(Valid());\n     ParsedInternalKey key;\n     if (!ParseInternalKey(iter_->key(), &key)) {\n@@ -299,82 +289,68 @@ class KeyConvertingIterator: public Iterator {\n     return key.user_key;\n   }\n \n-  virtual Slice value() const { return iter_->value(); }\n-  virtual Status status() const {\n+  Slice value() const override { return iter_->value(); }\n+  Status status() const override {\n     return status_.ok() ? iter_->status() : status_;\n   }\n \n  private:\n   mutable Status status_;\n   Iterator* iter_;\n-\n-  // No copying allowed\n-  KeyConvertingIterator(const KeyConvertingIterator&);\n-  void operator=(const KeyConvertingIterator&);\n };\n \n-class MemTableConstructor: public Constructor {\n+class MemTableConstructor : public Constructor {\n  public:\n   explicit MemTableConstructor(const Comparator* cmp)\n-      : Constructor(cmp),\n-        internal_comparator_(cmp) {\n+      : Constructor(cmp), internal_comparator_(cmp) {\n     memtable_ = new MemTable(internal_comparator_);\n     memtable_->Ref();\n   }\n-  ~MemTableConstructor() {\n-    memtable_->Unref();\n-  }\n-  virtual Status FinishImpl(const Options& options, const KVMap& data) {\n+  ~MemTableConstructor() override { memtable_->Unref(); }\n+  Status FinishImpl(const Options& options, const KVMap& data) override {\n     memtable_->Unref();\n     memtable_ = new MemTable(internal_comparator_);\n     memtable_->Ref();\n     int seq = 1;\n-    for (KVMap::const_iterator it = data.begin();\n-         it != data.end();\n-         ++it) {\n-      memtable_->Add(seq, kTypeValue, it->first, it->second);\n+    for (const auto& kvp : data) {\n+      memtable_->Add(seq, kTypeValue, kvp.first, kvp.second);\n       seq++;\n     }\n     return Status::OK();\n   }\n-  virtual Iterator* NewIterator() const {\n+  Iterator* NewIterator() const override {\n     return new KeyConvertingIterator(memtable_->NewIterator());\n   }\n \n  private:\n-  InternalKeyComparator internal_comparator_;\n+  const InternalKeyComparator internal_comparator_;\n   MemTable* memtable_;\n };\n \n-class DBConstructor: public Constructor {\n+class DBConstructor : public Constructor {\n  public:\n   explicit DBConstructor(const Comparator* cmp)\n-      : Constructor(cmp),\n-        comparator_(cmp) {\n-    db_ = NULL;\n+      : Constructor(cmp), comparator_(cmp) {\n+    db_ = nullptr;\n     NewDB();\n   }\n-  ~DBConstructor() {\n-    delete db_;\n-  }\n-  virtual Status FinishImpl(const Options& options, const KVMap& data) {\n+  ~DBConstructor() override { delete db_; }\n+  Status FinishImpl(const Options& options, const KVMap& data) override {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     NewDB();\n-    for (KVMap::const_iterator it = data.begin();\n-         it != data.end();\n-         ++it) {\n+    for (const auto& kvp : data) {\n       WriteBatch batch;\n-      batch.Put(it->first, it->second);\n+      batch.Put(kvp.first, kvp.second);\n       ASSERT_TRUE(db_->Write(WriteOptions(), &batch).ok());\n     }\n     return Status::OK();\n   }\n-  virtual Iterator* NewIterator() const {\n+  Iterator* NewIterator() const override {\n     return db_->NewIterator(ReadOptions());\n   }\n \n-  virtual DB* db() const { return db_; }\n+  DB* db() const override { return db_; }\n \n  private:\n   void NewDB() {\n@@ -392,16 +368,11 @@ class DBConstructor: public Constructor {\n     ASSERT_TRUE(status.ok()) << status.ToString();\n   }\n \n-  const Comparator* comparator_;\n+  const Comparator* const comparator_;\n   DB* db_;\n };\n \n-enum TestType {\n-  TABLE_TEST,\n-  BLOCK_TEST,\n-  MEMTABLE_TEST,\n-  DB_TEST\n-};\n+enum TestType { TABLE_TEST, BLOCK_TEST, MEMTABLE_TEST, DB_TEST };\n \n struct TestArgs {\n   TestType type;\n@@ -410,37 +381,37 @@ struct TestArgs {\n };\n \n static const TestArgs kTestArgList[] = {\n-  { TABLE_TEST, false, 16 },\n-  { TABLE_TEST, false, 1 },\n-  { TABLE_TEST, false, 1024 },\n-  { TABLE_TEST, true, 16 },\n-  { TABLE_TEST, true, 1 },\n-  { TABLE_TEST, true, 1024 },\n-\n-  { BLOCK_TEST, false, 16 },\n-  { BLOCK_TEST, false, 1 },\n-  { BLOCK_TEST, false, 1024 },\n-  { BLOCK_TEST, true, 16 },\n-  { BLOCK_TEST, true, 1 },\n-  { BLOCK_TEST, true, 1024 },\n-\n-  // Restart interval does not matter for memtables\n-  { MEMTABLE_TEST, false, 16 },\n-  { MEMTABLE_TEST, true, 16 },\n-\n-  // Do not bother with restart interval variations for DB\n-  { DB_TEST, false, 16 },\n-  { DB_TEST, true, 16 },\n+    {TABLE_TEST, false, 16},\n+    {TABLE_TEST, false, 1},\n+    {TABLE_TEST, false, 1024},\n+    {TABLE_TEST, true, 16},\n+    {TABLE_TEST, true, 1},\n+    {TABLE_TEST, true, 1024},\n+\n+    {BLOCK_TEST, false, 16},\n+    {BLOCK_TEST, false, 1},\n+    {BLOCK_TEST, false, 1024},\n+    {BLOCK_TEST, true, 16},\n+    {BLOCK_TEST, true, 1},\n+    {BLOCK_TEST, true, 1024},\n+\n+    // Restart interval does not matter for memtables\n+    {MEMTABLE_TEST, false, 16},\n+    {MEMTABLE_TEST, true, 16},\n+\n+    // Do not bother with restart interval variations for DB\n+    {DB_TEST, false, 16},\n+    {DB_TEST, true, 16},\n };\n static const int kNumTestArgs = sizeof(kTestArgList) / sizeof(kTestArgList[0]);\n \n class Harness {\n  public:\n-  Harness() : constructor_(NULL) { }\n+  Harness() : constructor_(nullptr) {}\n \n   void Init(const TestArgs& args) {\n     delete constructor_;\n-    constructor_ = NULL;\n+    constructor_ = nullptr;\n     options_ = Options();\n \n     options_.block_restart_interval = args.restart_interval;\n@@ -466,9 +437,7 @@ class Harness {\n     }\n   }\n \n-  ~Harness() {\n-    delete constructor_;\n-  }\n+  ~Harness() { delete constructor_; }\n \n   void Add(const std::string& key, const std::string& value) {\n     constructor_->Add(key, value);\n@@ -490,8 +459,7 @@ class Harness {\n     ASSERT_TRUE(!iter->Valid());\n     iter->SeekToFirst();\n     for (KVMap::const_iterator model_iter = data.begin();\n-         model_iter != data.end();\n-         ++model_iter) {\n+         model_iter != data.end(); ++model_iter) {\n       ASSERT_EQ(ToString(data, model_iter), ToString(iter));\n       iter->Next();\n     }\n@@ -505,17 +473,15 @@ class Harness {\n     ASSERT_TRUE(!iter->Valid());\n     iter->SeekToLast();\n     for (KVMap::const_reverse_iterator model_iter = data.rbegin();\n-         model_iter != data.rend();\n-         ++model_iter) {\n+         model_iter != data.rend(); ++model_iter) {\n       ASSERT_EQ(ToString(data, model_iter), ToString(iter));\n       iter->Prev();\n     }\n     ASSERT_TRUE(!iter->Valid());\n     delete iter;\n   }\n \n-  void TestRandomAccess(Random* rnd,\n-                        const std::vector<std::string>& keys,\n+  void TestRandomAccess(Random* rnd, const std::vector<std::string>& keys,\n                         const KVMap& data) {\n     static const bool kVerbose = false;\n     Iterator* iter = constructor_->NewIterator();\n@@ -546,8 +512,8 @@ class Harness {\n         case 2: {\n           std::string key = PickRandomKey(rnd, keys);\n           model_iter = data.lower_bound(key);\n-          if (kVerbose) fprintf(stderr, \"Seek '%s'\\n\",\n-                                EscapeString(key).c_str());\n+          if (kVerbose)\n+            fprintf(stderr, \"Seek '%s'\\n\", EscapeString(key).c_str());\n           iter->Seek(Slice(key));\n           ASSERT_EQ(ToString(data, model_iter), ToString(iter));\n           break;\n@@ -558,7 +524,7 @@ class Harness {\n             if (kVerbose) fprintf(stderr, \"Prev\\n\");\n             iter->Prev();\n             if (model_iter == data.begin()) {\n-              model_iter = data.end();   // Wrap around to invalid value\n+              model_iter = data.end();  // Wrap around to invalid value\n             } else {\n               --model_iter;\n             }\n@@ -621,8 +587,8 @@ class Harness {\n           break;\n         case 1: {\n           // Attempt to return something smaller than an existing key\n-          if (result.size() > 0 && result[result.size()-1] > '\\0') {\n-            result[result.size()-1]--;\n+          if (!result.empty() && result[result.size() - 1] > '\\0') {\n+            result[result.size() - 1]--;\n           }\n           break;\n         }\n@@ -636,7 +602,7 @@ class Harness {\n     }\n   }\n \n-  // Returns NULL if not running against a DB\n+  // Returns nullptr if not running against a DB\n   DB* db() const { return constructor_->db(); }\n \n  private:\n@@ -720,8 +686,8 @@ TEST(Harness, Randomized) {\n     for (int num_entries = 0; num_entries < 2000;\n          num_entries += (num_entries < 50 ? 1 : 200)) {\n       if ((num_entries % 10) == 0) {\n-        fprintf(stderr, \"case %d of %d: num_entries = %d\\n\",\n-                (i + 1), int(kNumTestArgs), num_entries);\n+        fprintf(stderr, \"case %d of %d: num_entries = %d\\n\", (i + 1),\n+                int(kNumTestArgs), num_entries);\n       }\n       for (int e = 0; e < num_entries; e++) {\n         std::string v;\n@@ -735,7 +701,7 @@ TEST(Harness, Randomized) {\n \n TEST(Harness, RandomizedLongDB) {\n   Random rnd(test::RandomSeed());\n-  TestArgs args = { DB_TEST, false, 16 };\n+  TestArgs args = {DB_TEST, false, 16};\n   Init(args);\n   int num_entries = 100000;\n   for (int e = 0; e < num_entries; e++) {\n@@ -757,7 +723,7 @@ TEST(Harness, RandomizedLongDB) {\n   ASSERT_GT(files, 0);\n }\n \n-class MemTableTest { };\n+class MemTableTest {};\n \n TEST(MemTableTest, Simple) {\n   InternalKeyComparator cmp(BytewiseComparator());\n@@ -774,8 +740,7 @@ TEST(MemTableTest, Simple) {\n   Iterator* iter = memtable->NewIterator();\n   iter->SeekToFirst();\n   while (iter->Valid()) {\n-    fprintf(stderr, \"key: '%s' -> '%s'\\n\",\n-            iter->key().ToString().c_str(),\n+    fprintf(stderr, \"key: '%s' -> '%s'\\n\", iter->key().ToString().c_str(),\n             iter->value().ToString().c_str());\n     iter->Next();\n   }\n@@ -788,14 +753,13 @@ static bool Between(uint64_t val, uint64_t low, uint64_t high) {\n   bool result = (val >= low) && (val <= high);\n   if (!result) {\n     fprintf(stderr, \"Value %llu is not in range [%llu, %llu]\\n\",\n-            (unsigned long long)(val),\n-            (unsigned long long)(low),\n+            (unsigned long long)(val), (unsigned long long)(low),\n             (unsigned long long)(high));\n   }\n   return result;\n }\n \n-class TableTest { };\n+class TableTest {};\n \n TEST(TableTest, ApproximateOffsetOfPlain) {\n   TableConstructor c(BytewiseComparator());\n@@ -813,18 +777,17 @@ TEST(TableTest, ApproximateOffsetOfPlain) {\n   options.compression = kNoCompression;\n   c.Finish(options, &keys, &kvmap);\n \n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"abc\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01a\"),      0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k02\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k03\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k04\"),   10000,  11000));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"abc\"), 0, 0));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01\"), 0, 0));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01a\"), 0, 0));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k02\"), 0, 0));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k03\"), 0, 0));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k04\"), 10000, 11000));\n   ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k04a\"), 210000, 211000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k05\"),  210000, 211000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k06\"),  510000, 511000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k07\"),  510000, 511000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"xyz\"),  610000, 612000));\n-\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k05\"), 210000, 211000));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k06\"), 510000, 511000));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k07\"), 510000, 511000));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"xyz\"), 610000, 612000));\n }\n \n static bool SnappyCompressionSupported() {\n@@ -855,7 +818,7 @@ TEST(TableTest, ApproximateOffsetOfCompressed) {\n \n   // Expected upper and lower bounds of space used by compressible strings.\n   static const int kSlop = 1000;  // Compressor effectiveness varies.\n-  const int expected = 2500;  // 10000 * compression ratio (0.25)\n+  const int expected = 2500;      // 10000 * compression ratio (0.25)\n   const int min_z = expected - kSlop;\n   const int max_z = expected + kSlop;\n \n@@ -871,6 +834,4 @@ TEST(TableTest, ApproximateOffsetOfCompressed) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "144790dd973f7afe6e350932a98844e34c735f96",
        "filename": "table/two_level_iterator.cc",
        "status": "modified",
        "additions": 40,
        "deletions": 51,
        "changes": 91,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/two_level_iterator.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/two_level_iterator.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/two_level_iterator.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -15,38 +15,33 @@ namespace {\n \n typedef Iterator* (*BlockFunction)(void*, const ReadOptions&, const Slice&);\n \n-class TwoLevelIterator: public Iterator {\n+class TwoLevelIterator : public Iterator {\n  public:\n-  TwoLevelIterator(\n-    Iterator* index_iter,\n-    BlockFunction block_function,\n-    void* arg,\n-    const ReadOptions& options);\n-\n-  virtual ~TwoLevelIterator();\n-\n-  virtual void Seek(const Slice& target);\n-  virtual void SeekToFirst();\n-  virtual void SeekToLast();\n-  virtual void Next();\n-  virtual void Prev();\n-\n-  virtual bool Valid() const {\n-    return data_iter_.Valid();\n-  }\n-  virtual Slice key() const {\n+  TwoLevelIterator(Iterator* index_iter, BlockFunction block_function,\n+                   void* arg, const ReadOptions& options);\n+\n+  ~TwoLevelIterator() override;\n+\n+  void Seek(const Slice& target) override;\n+  void SeekToFirst() override;\n+  void SeekToLast() override;\n+  void Next() override;\n+  void Prev() override;\n+\n+  bool Valid() const override { return data_iter_.Valid(); }\n+  Slice key() const override {\n     assert(Valid());\n     return data_iter_.key();\n   }\n-  virtual Slice value() const {\n+  Slice value() const override {\n     assert(Valid());\n     return data_iter_.value();\n   }\n-  virtual Status status() const {\n+  Status status() const override {\n     // It'd be nice if status() returned a const Status& instead of a Status\n     if (!index_iter_.status().ok()) {\n       return index_iter_.status();\n-    } else if (data_iter_.iter() != NULL && !data_iter_.status().ok()) {\n+    } else if (data_iter_.iter() != nullptr && !data_iter_.status().ok()) {\n       return data_iter_.status();\n     } else {\n       return status_;\n@@ -67,45 +62,41 @@ class TwoLevelIterator: public Iterator {\n   const ReadOptions options_;\n   Status status_;\n   IteratorWrapper index_iter_;\n-  IteratorWrapper data_iter_; // May be NULL\n-  // If data_iter_ is non-NULL, then \"data_block_handle_\" holds the\n+  IteratorWrapper data_iter_;  // May be nullptr\n+  // If data_iter_ is non-null, then \"data_block_handle_\" holds the\n   // \"index_value\" passed to block_function_ to create the data_iter_.\n   std::string data_block_handle_;\n };\n \n-TwoLevelIterator::TwoLevelIterator(\n-    Iterator* index_iter,\n-    BlockFunction block_function,\n-    void* arg,\n-    const ReadOptions& options)\n+TwoLevelIterator::TwoLevelIterator(Iterator* index_iter,\n+                                   BlockFunction block_function, void* arg,\n+                                   const ReadOptions& options)\n     : block_function_(block_function),\n       arg_(arg),\n       options_(options),\n       index_iter_(index_iter),\n-      data_iter_(NULL) {\n-}\n+      data_iter_(nullptr) {}\n \n-TwoLevelIterator::~TwoLevelIterator() {\n-}\n+TwoLevelIterator::~TwoLevelIterator() = default;\n \n void TwoLevelIterator::Seek(const Slice& target) {\n   index_iter_.Seek(target);\n   InitDataBlock();\n-  if (data_iter_.iter() != NULL) data_iter_.Seek(target);\n+  if (data_iter_.iter() != nullptr) data_iter_.Seek(target);\n   SkipEmptyDataBlocksForward();\n }\n \n void TwoLevelIterator::SeekToFirst() {\n   index_iter_.SeekToFirst();\n   InitDataBlock();\n-  if (data_iter_.iter() != NULL) data_iter_.SeekToFirst();\n+  if (data_iter_.iter() != nullptr) data_iter_.SeekToFirst();\n   SkipEmptyDataBlocksForward();\n }\n \n void TwoLevelIterator::SeekToLast() {\n   index_iter_.SeekToLast();\n   InitDataBlock();\n-  if (data_iter_.iter() != NULL) data_iter_.SeekToLast();\n+  if (data_iter_.iter() != nullptr) data_iter_.SeekToLast();\n   SkipEmptyDataBlocksBackward();\n }\n \n@@ -121,44 +112,44 @@ void TwoLevelIterator::Prev() {\n   SkipEmptyDataBlocksBackward();\n }\n \n-\n void TwoLevelIterator::SkipEmptyDataBlocksForward() {\n-  while (data_iter_.iter() == NULL || !data_iter_.Valid()) {\n+  while (data_iter_.iter() == nullptr || !data_iter_.Valid()) {\n     // Move to next block\n     if (!index_iter_.Valid()) {\n-      SetDataIterator(NULL);\n+      SetDataIterator(nullptr);\n       return;\n     }\n     index_iter_.Next();\n     InitDataBlock();\n-    if (data_iter_.iter() != NULL) data_iter_.SeekToFirst();\n+    if (data_iter_.iter() != nullptr) data_iter_.SeekToFirst();\n   }\n }\n \n void TwoLevelIterator::SkipEmptyDataBlocksBackward() {\n-  while (data_iter_.iter() == NULL || !data_iter_.Valid()) {\n+  while (data_iter_.iter() == nullptr || !data_iter_.Valid()) {\n     // Move to next block\n     if (!index_iter_.Valid()) {\n-      SetDataIterator(NULL);\n+      SetDataIterator(nullptr);\n       return;\n     }\n     index_iter_.Prev();\n     InitDataBlock();\n-    if (data_iter_.iter() != NULL) data_iter_.SeekToLast();\n+    if (data_iter_.iter() != nullptr) data_iter_.SeekToLast();\n   }\n }\n \n void TwoLevelIterator::SetDataIterator(Iterator* data_iter) {\n-  if (data_iter_.iter() != NULL) SaveError(data_iter_.status());\n+  if (data_iter_.iter() != nullptr) SaveError(data_iter_.status());\n   data_iter_.Set(data_iter);\n }\n \n void TwoLevelIterator::InitDataBlock() {\n   if (!index_iter_.Valid()) {\n-    SetDataIterator(NULL);\n+    SetDataIterator(nullptr);\n   } else {\n     Slice handle = index_iter_.value();\n-    if (data_iter_.iter() != NULL && handle.compare(data_block_handle_) == 0) {\n+    if (data_iter_.iter() != nullptr &&\n+        handle.compare(data_block_handle_) == 0) {\n       // data_iter_ is already constructed with this iterator, so\n       // no need to change anything\n     } else {\n@@ -171,11 +162,9 @@ void TwoLevelIterator::InitDataBlock() {\n \n }  // namespace\n \n-Iterator* NewTwoLevelIterator(\n-    Iterator* index_iter,\n-    BlockFunction block_function,\n-    void* arg,\n-    const ReadOptions& options) {\n+Iterator* NewTwoLevelIterator(Iterator* index_iter,\n+                              BlockFunction block_function, void* arg,\n+                              const ReadOptions& options) {\n   return new TwoLevelIterator(index_iter, block_function, arg, options);\n }\n "
      },
      {
        "sha": "81ffe809ac77ba52703df5ead573ecb00dcd9983",
        "filename": "table/two_level_iterator.h",
        "status": "modified",
        "additions": 4,
        "deletions": 7,
        "changes": 11,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/table/two_level_iterator.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/table/two_level_iterator.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/table/two_level_iterator.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -20,14 +20,11 @@ struct ReadOptions;\n //\n // Uses a supplied function to convert an index_iter value into\n // an iterator over the contents of the corresponding block.\n-extern Iterator* NewTwoLevelIterator(\n+Iterator* NewTwoLevelIterator(\n     Iterator* index_iter,\n-    Iterator* (*block_function)(\n-        void* arg,\n-        const ReadOptions& options,\n-        const Slice& index_value),\n-    void* arg,\n-    const ReadOptions& options);\n+    Iterator* (*block_function)(void* arg, const ReadOptions& options,\n+                                const Slice& index_value),\n+    void* arg, const ReadOptions& options);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "46e3b2eb8f63b0075d6119699018acf24103b42a",
        "filename": "util/arena.cc",
        "status": "modified",
        "additions": 8,
        "deletions": 10,
        "changes": 18,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/arena.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/arena.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/arena.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -3,16 +3,13 @@\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n #include \"util/arena.h\"\n-#include <assert.h>\n \n namespace leveldb {\n \n static const int kBlockSize = 4096;\n \n-Arena::Arena() : memory_usage_(0) {\n-  alloc_ptr_ = NULL;  // First allocation will allocate a block\n-  alloc_bytes_remaining_ = 0;\n-}\n+Arena::Arena()\n+    : alloc_ptr_(nullptr), alloc_bytes_remaining_(0), memory_usage_(0) {}\n \n Arena::~Arena() {\n   for (size_t i = 0; i < blocks_.size(); i++) {\n@@ -40,8 +37,9 @@ char* Arena::AllocateFallback(size_t bytes) {\n \n char* Arena::AllocateAligned(size_t bytes) {\n   const int align = (sizeof(void*) > 8) ? sizeof(void*) : 8;\n-  assert((align & (align-1)) == 0);   // Pointer size should be a power of 2\n-  size_t current_mod = reinterpret_cast<uintptr_t>(alloc_ptr_) & (align-1);\n+  static_assert((align & (align - 1)) == 0,\n+                \"Pointer size should be a power of 2\");\n+  size_t current_mod = reinterpret_cast<uintptr_t>(alloc_ptr_) & (align - 1);\n   size_t slop = (current_mod == 0 ? 0 : align - current_mod);\n   size_t needed = bytes + slop;\n   char* result;\n@@ -53,15 +51,15 @@ char* Arena::AllocateAligned(size_t bytes) {\n     // AllocateFallback always returned aligned memory\n     result = AllocateFallback(bytes);\n   }\n-  assert((reinterpret_cast<uintptr_t>(result) & (align-1)) == 0);\n+  assert((reinterpret_cast<uintptr_t>(result) & (align - 1)) == 0);\n   return result;\n }\n \n char* Arena::AllocateNewBlock(size_t block_bytes) {\n   char* result = new char[block_bytes];\n   blocks_.push_back(result);\n-  memory_usage_.NoBarrier_Store(\n-      reinterpret_cast<void*>(MemoryUsage() + block_bytes + sizeof(char*)));\n+  memory_usage_.fetch_add(block_bytes + sizeof(char*),\n+                          std::memory_order_relaxed);\n   return result;\n }\n "
      },
      {
        "sha": "68fc55d4dda7742362e93974725ec36a102a3f6a",
        "filename": "util/arena.h",
        "status": "modified",
        "additions": 14,
        "deletions": 11,
        "changes": 25,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/arena.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/arena.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/arena.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -5,29 +5,33 @@\n #ifndef STORAGE_LEVELDB_UTIL_ARENA_H_\n #define STORAGE_LEVELDB_UTIL_ARENA_H_\n \n+#include <atomic>\n+#include <cassert>\n+#include <cstddef>\n+#include <cstdint>\n #include <vector>\n-#include <assert.h>\n-#include <stddef.h>\n-#include <stdint.h>\n-#include \"port/port.h\"\n \n namespace leveldb {\n \n class Arena {\n  public:\n   Arena();\n+\n+  Arena(const Arena&) = delete;\n+  Arena& operator=(const Arena&) = delete;\n+\n   ~Arena();\n \n   // Return a pointer to a newly allocated memory block of \"bytes\" bytes.\n   char* Allocate(size_t bytes);\n \n-  // Allocate memory with the normal alignment guarantees provided by malloc\n+  // Allocate memory with the normal alignment guarantees provided by malloc.\n   char* AllocateAligned(size_t bytes);\n \n   // Returns an estimate of the total memory usage of data allocated\n   // by the arena.\n   size_t MemoryUsage() const {\n-    return reinterpret_cast<uintptr_t>(memory_usage_.NoBarrier_Load());\n+    return memory_usage_.load(std::memory_order_relaxed);\n   }\n \n  private:\n@@ -42,11 +46,10 @@ class Arena {\n   std::vector<char*> blocks_;\n \n   // Total memory usage of the arena.\n-  port::AtomicPointer memory_usage_;\n-\n-  // No copying allowed\n-  Arena(const Arena&);\n-  void operator=(const Arena&);\n+  //\n+  // TODO(costan): This member is accessed via atomics, but the others are\n+  //               accessed without any locking. Is this OK?\n+  std::atomic<size_t> memory_usage_;\n };\n \n inline char* Arena::Allocate(size_t bytes) {"
      },
      {
        "sha": "e917228f420729919186465e29531cdc39163e9c",
        "filename": "util/arena_test.cc",
        "status": "modified",
        "additions": 8,
        "deletions": 11,
        "changes": 19,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/arena_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/arena_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/arena_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -9,14 +9,12 @@\n \n namespace leveldb {\n \n-class ArenaTest { };\n+class ArenaTest {};\n \n-TEST(ArenaTest, Empty) {\n-  Arena arena;\n-}\n+TEST(ArenaTest, Empty) { Arena arena; }\n \n TEST(ArenaTest, Simple) {\n-  std::vector<std::pair<size_t, char*> > allocated;\n+  std::vector<std::pair<size_t, char*>> allocated;\n   Arena arena;\n   const int N = 100000;\n   size_t bytes = 0;\n@@ -26,8 +24,9 @@ TEST(ArenaTest, Simple) {\n     if (i % (N / 10) == 0) {\n       s = i;\n     } else {\n-      s = rnd.OneIn(4000) ? rnd.Uniform(6000) :\n-          (rnd.OneIn(10) ? rnd.Uniform(100) : rnd.Uniform(20));\n+      s = rnd.OneIn(4000)\n+              ? rnd.Uniform(6000)\n+              : (rnd.OneIn(10) ? rnd.Uniform(100) : rnd.Uniform(20));\n     }\n     if (s == 0) {\n       // Our arena disallows size 0 allocations.\n@@ -47,7 +46,7 @@ TEST(ArenaTest, Simple) {\n     bytes += s;\n     allocated.push_back(std::make_pair(s, r));\n     ASSERT_GE(arena.MemoryUsage(), bytes);\n-    if (i > N/10) {\n+    if (i > N / 10) {\n       ASSERT_LE(arena.MemoryUsage(), bytes * 1.10);\n     }\n   }\n@@ -63,6 +62,4 @@ TEST(ArenaTest, Simple) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "87547a7e62cdf9f73a99dde32e2bb9a5b1228f68",
        "filename": "util/bloom.cc",
        "status": "modified",
        "additions": 12,
        "deletions": 15,
        "changes": 27,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/bloom.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/bloom.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/bloom.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -15,24 +15,17 @@ static uint32_t BloomHash(const Slice& key) {\n }\n \n class BloomFilterPolicy : public FilterPolicy {\n- private:\n-  size_t bits_per_key_;\n-  size_t k_;\n-\n  public:\n-  explicit BloomFilterPolicy(int bits_per_key)\n-      : bits_per_key_(bits_per_key) {\n+  explicit BloomFilterPolicy(int bits_per_key) : bits_per_key_(bits_per_key) {\n     // We intentionally round down to reduce probing cost a little bit\n     k_ = static_cast<size_t>(bits_per_key * 0.69);  // 0.69 =~ ln(2)\n     if (k_ < 1) k_ = 1;\n     if (k_ > 30) k_ = 30;\n   }\n \n-  virtual const char* Name() const {\n-    return \"leveldb.BuiltinBloomFilter2\";\n-  }\n+  const char* Name() const override { return \"leveldb.BuiltinBloomFilter2\"; }\n \n-  virtual void CreateFilter(const Slice* keys, int n, std::string* dst) const {\n+  void CreateFilter(const Slice* keys, int n, std::string* dst) const override {\n     // Compute bloom filter size (in both bits and bytes)\n     size_t bits = n * bits_per_key_;\n \n@@ -54,13 +47,13 @@ class BloomFilterPolicy : public FilterPolicy {\n       const uint32_t delta = (h >> 17) | (h << 15);  // Rotate right 17 bits\n       for (size_t j = 0; j < k_; j++) {\n         const uint32_t bitpos = h % bits;\n-        array[bitpos/8] |= (1 << (bitpos % 8));\n+        array[bitpos / 8] |= (1 << (bitpos % 8));\n         h += delta;\n       }\n     }\n   }\n \n-  virtual bool KeyMayMatch(const Slice& key, const Slice& bloom_filter) const {\n+  bool KeyMayMatch(const Slice& key, const Slice& bloom_filter) const override {\n     const size_t len = bloom_filter.size();\n     if (len < 2) return false;\n \n@@ -69,7 +62,7 @@ class BloomFilterPolicy : public FilterPolicy {\n \n     // Use the encoded k so that we can read filters generated by\n     // bloom filters created using different parameters.\n-    const size_t k = array[len-1];\n+    const size_t k = array[len - 1];\n     if (k > 30) {\n       // Reserved for potentially new encodings for short bloom filters.\n       // Consider it a match.\n@@ -80,13 +73,17 @@ class BloomFilterPolicy : public FilterPolicy {\n     const uint32_t delta = (h >> 17) | (h << 15);  // Rotate right 17 bits\n     for (size_t j = 0; j < k; j++) {\n       const uint32_t bitpos = h % bits;\n-      if ((array[bitpos/8] & (1 << (bitpos % 8))) == 0) return false;\n+      if ((array[bitpos / 8] & (1 << (bitpos % 8))) == 0) return false;\n       h += delta;\n     }\n     return true;\n   }\n+\n+ private:\n+  size_t bits_per_key_;\n+  size_t k_;\n };\n-}\n+}  // namespace\n \n const FilterPolicy* NewBloomFilterPolicy(int bits_per_key) {\n   return new BloomFilterPolicy(bits_per_key);"
      },
      {
        "sha": "436daa9e995738e84ffdf11af9d19e5412fe563b",
        "filename": "util/bloom_test.cc",
        "status": "modified",
        "additions": 25,
        "deletions": 31,
        "changes": 56,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/bloom_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/bloom_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/bloom_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -19,26 +19,17 @@ static Slice Key(int i, char* buffer) {\n }\n \n class BloomTest {\n- private:\n-  const FilterPolicy* policy_;\n-  std::string filter_;\n-  std::vector<std::string> keys_;\n-\n  public:\n-  BloomTest() : policy_(NewBloomFilterPolicy(10)) { }\n+  BloomTest() : policy_(NewBloomFilterPolicy(10)) {}\n \n-  ~BloomTest() {\n-    delete policy_;\n-  }\n+  ~BloomTest() { delete policy_; }\n \n   void Reset() {\n     keys_.clear();\n     filter_.clear();\n   }\n \n-  void Add(const Slice& s) {\n-    keys_.push_back(s.ToString());\n-  }\n+  void Add(const Slice& s) { keys_.push_back(s.ToString()); }\n \n   void Build() {\n     std::vector<Slice> key_slices;\n@@ -52,16 +43,14 @@ class BloomTest {\n     if (kVerbose >= 2) DumpFilter();\n   }\n \n-  size_t FilterSize() const {\n-    return filter_.size();\n-  }\n+  size_t FilterSize() const { return filter_.size(); }\n \n   void DumpFilter() {\n     fprintf(stderr, \"F(\");\n-    for (size_t i = 0; i+1 < filter_.size(); i++) {\n+    for (size_t i = 0; i + 1 < filter_.size(); i++) {\n       const unsigned int c = static_cast<unsigned int>(filter_[i]);\n       for (int j = 0; j < 8; j++) {\n-        fprintf(stderr, \"%c\", (c & (1 <<j)) ? '1' : '.');\n+        fprintf(stderr, \"%c\", (c & (1 << j)) ? '1' : '.');\n       }\n     }\n     fprintf(stderr, \")\\n\");\n@@ -84,20 +73,25 @@ class BloomTest {\n     }\n     return result / 10000.0;\n   }\n+\n+ private:\n+  const FilterPolicy* policy_;\n+  std::string filter_;\n+  std::vector<std::string> keys_;\n };\n \n TEST(BloomTest, EmptyFilter) {\n-  ASSERT_TRUE(! Matches(\"hello\"));\n-  ASSERT_TRUE(! Matches(\"world\"));\n+  ASSERT_TRUE(!Matches(\"hello\"));\n+  ASSERT_TRUE(!Matches(\"world\"));\n }\n \n TEST(BloomTest, Small) {\n   Add(\"hello\");\n   Add(\"world\");\n   ASSERT_TRUE(Matches(\"hello\"));\n   ASSERT_TRUE(Matches(\"world\"));\n-  ASSERT_TRUE(! Matches(\"x\"));\n-  ASSERT_TRUE(! Matches(\"foo\"));\n+  ASSERT_TRUE(!Matches(\"x\"));\n+  ASSERT_TRUE(!Matches(\"foo\"));\n }\n \n static int NextLength(int length) {\n@@ -140,23 +134,23 @@ TEST(BloomTest, VaryingLengths) {\n     double rate = FalsePositiveRate();\n     if (kVerbose >= 1) {\n       fprintf(stderr, \"False positives: %5.2f%% @ length = %6d ; bytes = %6d\\n\",\n-              rate*100.0, length, static_cast<int>(FilterSize()));\n+              rate * 100.0, length, static_cast<int>(FilterSize()));\n     }\n-    ASSERT_LE(rate, 0.02);   // Must not be over 2%\n-    if (rate > 0.0125) mediocre_filters++;  // Allowed, but not too often\n-    else good_filters++;\n+    ASSERT_LE(rate, 0.02);  // Must not be over 2%\n+    if (rate > 0.0125)\n+      mediocre_filters++;  // Allowed, but not too often\n+    else\n+      good_filters++;\n   }\n   if (kVerbose >= 1) {\n-    fprintf(stderr, \"Filters: %d good, %d mediocre\\n\",\n-            good_filters, mediocre_filters);\n+    fprintf(stderr, \"Filters: %d good, %d mediocre\\n\", good_filters,\n+            mediocre_filters);\n   }\n-  ASSERT_LE(mediocre_filters, good_filters/5);\n+  ASSERT_LE(mediocre_filters, good_filters / 5);\n }\n \n // Different bits-per-byte\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "12de306cad25a675d51f7e8ffd63fbea0fac0690",
        "filename": "util/cache.cc",
        "status": "modified",
        "additions": 59,
        "deletions": 64,
        "changes": 123,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/cache.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/cache.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/cache.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -8,13 +8,13 @@\n \n #include \"leveldb/cache.h\"\n #include \"port/port.h\"\n+#include \"port/thread_annotations.h\"\n #include \"util/hash.h\"\n #include \"util/mutexlock.h\"\n \n namespace leveldb {\n \n-Cache::~Cache() {\n-}\n+Cache::~Cache() {}\n \n namespace {\n \n@@ -45,21 +45,19 @@ struct LRUHandle {\n   LRUHandle* next_hash;\n   LRUHandle* next;\n   LRUHandle* prev;\n-  size_t charge;      // TODO(opt): Only allow uint32_t?\n+  size_t charge;  // TODO(opt): Only allow uint32_t?\n   size_t key_length;\n-  bool in_cache;      // Whether entry is in the cache.\n-  uint32_t refs;      // References, including cache reference, if present.\n-  uint32_t hash;      // Hash of key(); used for fast sharding and comparisons\n-  char key_data[1];   // Beginning of key\n+  bool in_cache;     // Whether entry is in the cache.\n+  uint32_t refs;     // References, including cache reference, if present.\n+  uint32_t hash;     // Hash of key(); used for fast sharding and comparisons\n+  char key_data[1];  // Beginning of key\n \n   Slice key() const {\n-    // For cheaper lookups, we allow a temporary Handle object\n-    // to store a pointer to a key in \"value\".\n-    if (next == this) {\n-      return *(reinterpret_cast<Slice*>(value));\n-    } else {\n-      return Slice(key_data, key_length);\n-    }\n+    // next_ is only equal to this if the LRU handle is the list head of an\n+    // empty list. List heads never have meaningful keys.\n+    assert(next != this);\n+\n+    return Slice(key_data, key_length);\n   }\n };\n \n@@ -70,7 +68,7 @@ struct LRUHandle {\n // 4.4.3's builtin hashtable.\n class HandleTable {\n  public:\n-  HandleTable() : length_(0), elems_(0), list_(NULL) { Resize(); }\n+  HandleTable() : length_(0), elems_(0), list_(nullptr) { Resize(); }\n   ~HandleTable() { delete[] list_; }\n \n   LRUHandle* Lookup(const Slice& key, uint32_t hash) {\n@@ -80,9 +78,9 @@ class HandleTable {\n   LRUHandle* Insert(LRUHandle* h) {\n     LRUHandle** ptr = FindPointer(h->key(), h->hash);\n     LRUHandle* old = *ptr;\n-    h->next_hash = (old == NULL ? NULL : old->next_hash);\n+    h->next_hash = (old == nullptr ? nullptr : old->next_hash);\n     *ptr = h;\n-    if (old == NULL) {\n+    if (old == nullptr) {\n       ++elems_;\n       if (elems_ > length_) {\n         // Since each cache entry is fairly large, we aim for a small\n@@ -96,7 +94,7 @@ class HandleTable {\n   LRUHandle* Remove(const Slice& key, uint32_t hash) {\n     LRUHandle** ptr = FindPointer(key, hash);\n     LRUHandle* result = *ptr;\n-    if (result != NULL) {\n+    if (result != nullptr) {\n       *ptr = result->next_hash;\n       --elems_;\n     }\n@@ -115,8 +113,7 @@ class HandleTable {\n   // pointer to the trailing slot in the corresponding linked list.\n   LRUHandle** FindPointer(const Slice& key, uint32_t hash) {\n     LRUHandle** ptr = &list_[hash & (length_ - 1)];\n-    while (*ptr != NULL &&\n-           ((*ptr)->hash != hash || key != (*ptr)->key())) {\n+    while (*ptr != nullptr && ((*ptr)->hash != hash || key != (*ptr)->key())) {\n       ptr = &(*ptr)->next_hash;\n     }\n     return ptr;\n@@ -132,7 +129,7 @@ class HandleTable {\n     uint32_t count = 0;\n     for (uint32_t i = 0; i < length_; i++) {\n       LRUHandle* h = list_[i];\n-      while (h != NULL) {\n+      while (h != nullptr) {\n         LRUHandle* next = h->next_hash;\n         uint32_t hash = h->hash;\n         LRUHandle** ptr = &new_list[hash & (new_length - 1)];\n@@ -159,8 +156,8 @@ class LRUCache {\n   void SetCapacity(size_t capacity) { capacity_ = capacity; }\n \n   // Like Cache methods, but with an extra \"hash\" parameter.\n-  Cache::Handle* Insert(const Slice& key, uint32_t hash,\n-                        void* value, size_t charge,\n+  Cache::Handle* Insert(const Slice& key, uint32_t hash, void* value,\n+                        size_t charge,\n                         void (*deleter)(const Slice& key, void* value));\n   Cache::Handle* Lookup(const Slice& key, uint32_t hash);\n   void Release(Cache::Handle* handle);\n@@ -173,32 +170,31 @@ class LRUCache {\n \n  private:\n   void LRU_Remove(LRUHandle* e);\n-  void LRU_Append(LRUHandle*list, LRUHandle* e);\n+  void LRU_Append(LRUHandle* list, LRUHandle* e);\n   void Ref(LRUHandle* e);\n   void Unref(LRUHandle* e);\n-  bool FinishErase(LRUHandle* e);\n+  bool FinishErase(LRUHandle* e) EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n   // Initialized before use.\n   size_t capacity_;\n \n   // mutex_ protects the following state.\n   mutable port::Mutex mutex_;\n-  size_t usage_;\n+  size_t usage_ GUARDED_BY(mutex_);\n \n   // Dummy head of LRU list.\n   // lru.prev is newest entry, lru.next is oldest entry.\n   // Entries have refs==1 and in_cache==true.\n-  LRUHandle lru_;\n+  LRUHandle lru_ GUARDED_BY(mutex_);\n \n   // Dummy head of in-use list.\n   // Entries are in use by clients, and have refs >= 2 and in_cache==true.\n-  LRUHandle in_use_;\n+  LRUHandle in_use_ GUARDED_BY(mutex_);\n \n-  HandleTable table_;\n+  HandleTable table_ GUARDED_BY(mutex_);\n };\n \n-LRUCache::LRUCache()\n-    : usage_(0) {\n+LRUCache::LRUCache() : capacity_(0), usage_(0) {\n   // Make empty circular linked lists.\n   lru_.next = &lru_;\n   lru_.prev = &lru_;\n@@ -208,7 +204,7 @@ LRUCache::LRUCache()\n \n LRUCache::~LRUCache() {\n   assert(in_use_.next == &in_use_);  // Error if caller has an unreleased handle\n-  for (LRUHandle* e = lru_.next; e != &lru_; ) {\n+  for (LRUHandle* e = lru_.next; e != &lru_;) {\n     LRUHandle* next = e->next;\n     assert(e->in_cache);\n     e->in_cache = false;\n@@ -229,11 +225,12 @@ void LRUCache::Ref(LRUHandle* e) {\n void LRUCache::Unref(LRUHandle* e) {\n   assert(e->refs > 0);\n   e->refs--;\n-  if (e->refs == 0) { // Deallocate.\n+  if (e->refs == 0) {  // Deallocate.\n     assert(!e->in_cache);\n     (*e->deleter)(e->key(), e->value);\n     free(e);\n-  } else if (e->in_cache && e->refs == 1) {  // No longer in use; move to lru_ list.\n+  } else if (e->in_cache && e->refs == 1) {\n+    // No longer in use; move to lru_ list.\n     LRU_Remove(e);\n     LRU_Append(&lru_, e);\n   }\n@@ -255,7 +252,7 @@ void LRUCache::LRU_Append(LRUHandle* list, LRUHandle* e) {\n Cache::Handle* LRUCache::Lookup(const Slice& key, uint32_t hash) {\n   MutexLock l(&mutex_);\n   LRUHandle* e = table_.Lookup(key, hash);\n-  if (e != NULL) {\n+  if (e != nullptr) {\n     Ref(e);\n   }\n   return reinterpret_cast<Cache::Handle*>(e);\n@@ -266,13 +263,14 @@ void LRUCache::Release(Cache::Handle* handle) {\n   Unref(reinterpret_cast<LRUHandle*>(handle));\n }\n \n-Cache::Handle* LRUCache::Insert(\n-    const Slice& key, uint32_t hash, void* value, size_t charge,\n-    void (*deleter)(const Slice& key, void* value)) {\n+Cache::Handle* LRUCache::Insert(const Slice& key, uint32_t hash, void* value,\n+                                size_t charge,\n+                                void (*deleter)(const Slice& key,\n+                                                void* value)) {\n   MutexLock l(&mutex_);\n \n-  LRUHandle* e = reinterpret_cast<LRUHandle*>(\n-      malloc(sizeof(LRUHandle)-1 + key.size()));\n+  LRUHandle* e =\n+      reinterpret_cast<LRUHandle*>(malloc(sizeof(LRUHandle) - 1 + key.size()));\n   e->value = value;\n   e->deleter = deleter;\n   e->charge = charge;\n@@ -288,8 +286,10 @@ Cache::Handle* LRUCache::Insert(\n     LRU_Append(&in_use_, e);\n     usage_ += charge;\n     FinishErase(table_.Insert(e));\n-  } // else don't cache.  (Tests use capacity_==0 to turn off caching.)\n-\n+  } else {  // don't cache. (capacity_==0 is supported and turns off caching.)\n+    // next is read by key() in an assert, so it must be initialized\n+    e->next = nullptr;\n+  }\n   while (usage_ > capacity_ && lru_.next != &lru_) {\n     LRUHandle* old = lru_.next;\n     assert(old->refs == 1);\n@@ -302,17 +302,17 @@ Cache::Handle* LRUCache::Insert(\n   return reinterpret_cast<Cache::Handle*>(e);\n }\n \n-// If e != NULL, finish removing *e from the cache; it has already been removed\n-// from the hash table.  Return whether e != NULL.  Requires mutex_ held.\n+// If e != nullptr, finish removing *e from the cache; it has already been\n+// removed from the hash table.  Return whether e != nullptr.\n bool LRUCache::FinishErase(LRUHandle* e) {\n-  if (e != NULL) {\n+  if (e != nullptr) {\n     assert(e->in_cache);\n     LRU_Remove(e);\n     e->in_cache = false;\n     usage_ -= e->charge;\n     Unref(e);\n   }\n-  return e != NULL;\n+  return e != nullptr;\n }\n \n void LRUCache::Erase(const Slice& key, uint32_t hash) {\n@@ -345,49 +345,46 @@ class ShardedLRUCache : public Cache {\n     return Hash(s.data(), s.size(), 0);\n   }\n \n-  static uint32_t Shard(uint32_t hash) {\n-    return hash >> (32 - kNumShardBits);\n-  }\n+  static uint32_t Shard(uint32_t hash) { return hash >> (32 - kNumShardBits); }\n \n  public:\n-  explicit ShardedLRUCache(size_t capacity)\n-      : last_id_(0) {\n+  explicit ShardedLRUCache(size_t capacity) : last_id_(0) {\n     const size_t per_shard = (capacity + (kNumShards - 1)) / kNumShards;\n     for (int s = 0; s < kNumShards; s++) {\n       shard_[s].SetCapacity(per_shard);\n     }\n   }\n-  virtual ~ShardedLRUCache() { }\n-  virtual Handle* Insert(const Slice& key, void* value, size_t charge,\n-                         void (*deleter)(const Slice& key, void* value)) {\n+  ~ShardedLRUCache() override {}\n+  Handle* Insert(const Slice& key, void* value, size_t charge,\n+                 void (*deleter)(const Slice& key, void* value)) override {\n     const uint32_t hash = HashSlice(key);\n     return shard_[Shard(hash)].Insert(key, hash, value, charge, deleter);\n   }\n-  virtual Handle* Lookup(const Slice& key) {\n+  Handle* Lookup(const Slice& key) override {\n     const uint32_t hash = HashSlice(key);\n     return shard_[Shard(hash)].Lookup(key, hash);\n   }\n-  virtual void Release(Handle* handle) {\n+  void Release(Handle* handle) override {\n     LRUHandle* h = reinterpret_cast<LRUHandle*>(handle);\n     shard_[Shard(h->hash)].Release(handle);\n   }\n-  virtual void Erase(const Slice& key) {\n+  void Erase(const Slice& key) override {\n     const uint32_t hash = HashSlice(key);\n     shard_[Shard(hash)].Erase(key, hash);\n   }\n-  virtual void* Value(Handle* handle) {\n+  void* Value(Handle* handle) override {\n     return reinterpret_cast<LRUHandle*>(handle)->value;\n   }\n-  virtual uint64_t NewId() {\n+  uint64_t NewId() override {\n     MutexLock l(&id_mutex_);\n     return ++(last_id_);\n   }\n-  virtual void Prune() {\n+  void Prune() override {\n     for (int s = 0; s < kNumShards; s++) {\n       shard_[s].Prune();\n     }\n   }\n-  virtual size_t TotalCharge() const {\n+  size_t TotalCharge() const override {\n     size_t total = 0;\n     for (int s = 0; s < kNumShards; s++) {\n       total += shard_[s].TotalCharge();\n@@ -398,8 +395,6 @@ class ShardedLRUCache : public Cache {\n \n }  // end anonymous namespace\n \n-Cache* NewLRUCache(size_t capacity) {\n-  return new ShardedLRUCache(capacity);\n-}\n+Cache* NewLRUCache(size_t capacity) { return new ShardedLRUCache(capacity); }\n \n }  // namespace leveldb"
      },
      {
        "sha": "974334b9f8e805ddf03197571696d6536047c8ee",
        "filename": "util/cache_test.cc",
        "status": "modified",
        "additions": 30,
        "deletions": 30,
        "changes": 60,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/cache_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/cache_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/cache_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -25,8 +25,6 @@ static int DecodeValue(void* v) { return reinterpret_cast<uintptr_t>(v); }\n \n class CacheTest {\n  public:\n-  static CacheTest* current_;\n-\n   static void Deleter(const Slice& key, void* v) {\n     current_->deleted_keys_.push_back(DecodeKey(key));\n     current_->deleted_values_.push_back(DecodeValue(v));\n@@ -37,18 +35,14 @@ class CacheTest {\n   std::vector<int> deleted_values_;\n   Cache* cache_;\n \n-  CacheTest() : cache_(NewLRUCache(kCacheSize)) {\n-    current_ = this;\n-  }\n+  CacheTest() : cache_(NewLRUCache(kCacheSize)) { current_ = this; }\n \n-  ~CacheTest() {\n-    delete cache_;\n-  }\n+  ~CacheTest() { delete cache_; }\n \n   int Lookup(int key) {\n     Cache::Handle* handle = cache_->Lookup(EncodeKey(key));\n-    const int r = (handle == NULL) ? -1 : DecodeValue(cache_->Value(handle));\n-    if (handle != NULL) {\n+    const int r = (handle == nullptr) ? -1 : DecodeValue(cache_->Value(handle));\n+    if (handle != nullptr) {\n       cache_->Release(handle);\n     }\n     return r;\n@@ -64,9 +58,9 @@ class CacheTest {\n                           &CacheTest::Deleter);\n   }\n \n-  void Erase(int key) {\n-    cache_->Erase(EncodeKey(key));\n-  }\n+  void Erase(int key) { cache_->Erase(EncodeKey(key)); }\n+\n+  static CacheTest* current_;\n };\n CacheTest* CacheTest::current_;\n \n@@ -75,18 +69,18 @@ TEST(CacheTest, HitAndMiss) {\n \n   Insert(100, 101);\n   ASSERT_EQ(101, Lookup(100));\n-  ASSERT_EQ(-1,  Lookup(200));\n-  ASSERT_EQ(-1,  Lookup(300));\n+  ASSERT_EQ(-1, Lookup(200));\n+  ASSERT_EQ(-1, Lookup(300));\n \n   Insert(200, 201);\n   ASSERT_EQ(101, Lookup(100));\n   ASSERT_EQ(201, Lookup(200));\n-  ASSERT_EQ(-1,  Lookup(300));\n+  ASSERT_EQ(-1, Lookup(300));\n \n   Insert(100, 102);\n   ASSERT_EQ(102, Lookup(100));\n   ASSERT_EQ(201, Lookup(200));\n-  ASSERT_EQ(-1,  Lookup(300));\n+  ASSERT_EQ(-1, Lookup(300));\n \n   ASSERT_EQ(1, deleted_keys_.size());\n   ASSERT_EQ(100, deleted_keys_[0]);\n@@ -100,14 +94,14 @@ TEST(CacheTest, Erase) {\n   Insert(100, 101);\n   Insert(200, 201);\n   Erase(100);\n-  ASSERT_EQ(-1,  Lookup(100));\n+  ASSERT_EQ(-1, Lookup(100));\n   ASSERT_EQ(201, Lookup(200));\n   ASSERT_EQ(1, deleted_keys_.size());\n   ASSERT_EQ(100, deleted_keys_[0]);\n   ASSERT_EQ(101, deleted_values_[0]);\n \n   Erase(100);\n-  ASSERT_EQ(-1,  Lookup(100));\n+  ASSERT_EQ(-1, Lookup(100));\n   ASSERT_EQ(201, Lookup(200));\n   ASSERT_EQ(1, deleted_keys_.size());\n }\n@@ -146,8 +140,8 @@ TEST(CacheTest, EvictionPolicy) {\n   // Frequently used entry must be kept around,\n   // as must things that are still in use.\n   for (int i = 0; i < kCacheSize + 100; i++) {\n-    Insert(1000+i, 2000+i);\n-    ASSERT_EQ(2000+i, Lookup(1000+i));\n+    Insert(1000 + i, 2000 + i);\n+    ASSERT_EQ(2000 + i, Lookup(1000 + i));\n     ASSERT_EQ(101, Lookup(100));\n   }\n   ASSERT_EQ(101, Lookup(100));\n@@ -160,12 +154,12 @@ TEST(CacheTest, UseExceedsCacheSize) {\n   // Overfill the cache, keeping handles on all inserted entries.\n   std::vector<Cache::Handle*> h;\n   for (int i = 0; i < kCacheSize + 100; i++) {\n-    h.push_back(InsertAndReturnHandle(1000+i, 2000+i));\n+    h.push_back(InsertAndReturnHandle(1000 + i, 2000 + i));\n   }\n \n   // Check that all the entries can be found in the cache.\n   for (int i = 0; i < h.size(); i++) {\n-    ASSERT_EQ(2000+i, Lookup(1000+i));\n+    ASSERT_EQ(2000 + i, Lookup(1000 + i));\n   }\n \n   for (int i = 0; i < h.size(); i++) {\n@@ -181,9 +175,9 @@ TEST(CacheTest, HeavyEntries) {\n   const int kHeavy = 10;\n   int added = 0;\n   int index = 0;\n-  while (added < 2*kCacheSize) {\n+  while (added < 2 * kCacheSize) {\n     const int weight = (index & 1) ? kLight : kHeavy;\n-    Insert(index, 1000+index, weight);\n+    Insert(index, 1000 + index, weight);\n     added += weight;\n     index++;\n   }\n@@ -194,10 +188,10 @@ TEST(CacheTest, HeavyEntries) {\n     int r = Lookup(i);\n     if (r >= 0) {\n       cached_weight += weight;\n-      ASSERT_EQ(1000+i, r);\n+      ASSERT_EQ(1000 + i, r);\n     }\n   }\n-  ASSERT_LE(cached_weight, kCacheSize + kCacheSize/10);\n+  ASSERT_LE(cached_weight, kCacheSize + kCacheSize / 10);\n }\n \n TEST(CacheTest, NewId) {\n@@ -219,8 +213,14 @@ TEST(CacheTest, Prune) {\n   ASSERT_EQ(-1, Lookup(2));\n }\n \n-}  // namespace leveldb\n+TEST(CacheTest, ZeroSizeCache) {\n+  delete cache_;\n+  cache_ = NewLRUCache(0);\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n+  Insert(1, 100);\n+  ASSERT_EQ(-1, Lookup(1));\n }\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "df3fa10f0da9c9a7fef69c5577e5c9519dbbfd3c",
        "filename": "util/coding.cc",
        "status": "modified",
        "additions": 28,
        "deletions": 56,
        "changes": 84,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/coding.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/coding.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/coding.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -6,32 +6,6 @@\n \n namespace leveldb {\n \n-void EncodeFixed32(char* buf, uint32_t value) {\n-  if (port::kLittleEndian) {\n-    memcpy(buf, &value, sizeof(value));\n-  } else {\n-    buf[0] = value & 0xff;\n-    buf[1] = (value >> 8) & 0xff;\n-    buf[2] = (value >> 16) & 0xff;\n-    buf[3] = (value >> 24) & 0xff;\n-  }\n-}\n-\n-void EncodeFixed64(char* buf, uint64_t value) {\n-  if (port::kLittleEndian) {\n-    memcpy(buf, &value, sizeof(value));\n-  } else {\n-    buf[0] = value & 0xff;\n-    buf[1] = (value >> 8) & 0xff;\n-    buf[2] = (value >> 16) & 0xff;\n-    buf[3] = (value >> 24) & 0xff;\n-    buf[4] = (value >> 32) & 0xff;\n-    buf[5] = (value >> 40) & 0xff;\n-    buf[6] = (value >> 48) & 0xff;\n-    buf[7] = (value >> 56) & 0xff;\n-  }\n-}\n-\n void PutFixed32(std::string* dst, uint32_t value) {\n   char buf[sizeof(value)];\n   EncodeFixed32(buf, value);\n@@ -46,28 +20,28 @@ void PutFixed64(std::string* dst, uint64_t value) {\n \n char* EncodeVarint32(char* dst, uint32_t v) {\n   // Operate on characters as unsigneds\n-  unsigned char* ptr = reinterpret_cast<unsigned char*>(dst);\n+  uint8_t* ptr = reinterpret_cast<uint8_t*>(dst);\n   static const int B = 128;\n-  if (v < (1<<7)) {\n+  if (v < (1 << 7)) {\n     *(ptr++) = v;\n-  } else if (v < (1<<14)) {\n+  } else if (v < (1 << 14)) {\n     *(ptr++) = v | B;\n-    *(ptr++) = v>>7;\n-  } else if (v < (1<<21)) {\n+    *(ptr++) = v >> 7;\n+  } else if (v < (1 << 21)) {\n     *(ptr++) = v | B;\n-    *(ptr++) = (v>>7) | B;\n-    *(ptr++) = v>>14;\n-  } else if (v < (1<<28)) {\n+    *(ptr++) = (v >> 7) | B;\n+    *(ptr++) = v >> 14;\n+  } else if (v < (1 << 28)) {\n     *(ptr++) = v | B;\n-    *(ptr++) = (v>>7) | B;\n-    *(ptr++) = (v>>14) | B;\n-    *(ptr++) = v>>21;\n+    *(ptr++) = (v >> 7) | B;\n+    *(ptr++) = (v >> 14) | B;\n+    *(ptr++) = v >> 21;\n   } else {\n     *(ptr++) = v | B;\n-    *(ptr++) = (v>>7) | B;\n-    *(ptr++) = (v>>14) | B;\n-    *(ptr++) = (v>>21) | B;\n-    *(ptr++) = v>>28;\n+    *(ptr++) = (v >> 7) | B;\n+    *(ptr++) = (v >> 14) | B;\n+    *(ptr++) = (v >> 21) | B;\n+    *(ptr++) = v >> 28;\n   }\n   return reinterpret_cast<char*>(ptr);\n }\n@@ -80,12 +54,12 @@ void PutVarint32(std::string* dst, uint32_t v) {\n \n char* EncodeVarint64(char* dst, uint64_t v) {\n   static const int B = 128;\n-  unsigned char* ptr = reinterpret_cast<unsigned char*>(dst);\n+  uint8_t* ptr = reinterpret_cast<uint8_t*>(dst);\n   while (v >= B) {\n-    *(ptr++) = (v & (B-1)) | B;\n+    *(ptr++) = v | B;\n     v >>= 7;\n   }\n-  *(ptr++) = static_cast<unsigned char>(v);\n+  *(ptr++) = static_cast<uint8_t>(v);\n   return reinterpret_cast<char*>(ptr);\n }\n \n@@ -109,12 +83,11 @@ int VarintLength(uint64_t v) {\n   return len;\n }\n \n-const char* GetVarint32PtrFallback(const char* p,\n-                                   const char* limit,\n+const char* GetVarint32PtrFallback(const char* p, const char* limit,\n                                    uint32_t* value) {\n   uint32_t result = 0;\n   for (uint32_t shift = 0; shift <= 28 && p < limit; shift += 7) {\n-    uint32_t byte = *(reinterpret_cast<const unsigned char*>(p));\n+    uint32_t byte = *(reinterpret_cast<const uint8_t*>(p));\n     p++;\n     if (byte & 128) {\n       // More bytes are present\n@@ -125,14 +98,14 @@ const char* GetVarint32PtrFallback(const char* p,\n       return reinterpret_cast<const char*>(p);\n     }\n   }\n-  return NULL;\n+  return nullptr;\n }\n \n bool GetVarint32(Slice* input, uint32_t* value) {\n   const char* p = input->data();\n   const char* limit = p + input->size();\n   const char* q = GetVarint32Ptr(p, limit, value);\n-  if (q == NULL) {\n+  if (q == nullptr) {\n     return false;\n   } else {\n     *input = Slice(q, limit - q);\n@@ -143,7 +116,7 @@ bool GetVarint32(Slice* input, uint32_t* value) {\n const char* GetVarint64Ptr(const char* p, const char* limit, uint64_t* value) {\n   uint64_t result = 0;\n   for (uint32_t shift = 0; shift <= 63 && p < limit; shift += 7) {\n-    uint64_t byte = *(reinterpret_cast<const unsigned char*>(p));\n+    uint64_t byte = *(reinterpret_cast<const uint8_t*>(p));\n     p++;\n     if (byte & 128) {\n       // More bytes are present\n@@ -154,14 +127,14 @@ const char* GetVarint64Ptr(const char* p, const char* limit, uint64_t* value) {\n       return reinterpret_cast<const char*>(p);\n     }\n   }\n-  return NULL;\n+  return nullptr;\n }\n \n bool GetVarint64(Slice* input, uint64_t* value) {\n   const char* p = input->data();\n   const char* limit = p + input->size();\n   const char* q = GetVarint64Ptr(p, limit, value);\n-  if (q == NULL) {\n+  if (q == nullptr) {\n     return false;\n   } else {\n     *input = Slice(q, limit - q);\n@@ -173,16 +146,15 @@ const char* GetLengthPrefixedSlice(const char* p, const char* limit,\n                                    Slice* result) {\n   uint32_t len;\n   p = GetVarint32Ptr(p, limit, &len);\n-  if (p == NULL) return NULL;\n-  if (p + len > limit) return NULL;\n+  if (p == nullptr) return nullptr;\n+  if (p + len > limit) return nullptr;\n   *result = Slice(p, len);\n   return p + len;\n }\n \n bool GetLengthPrefixedSlice(Slice* input, Slice* result) {\n   uint32_t len;\n-  if (GetVarint32(input, &len) &&\n-      input->size() >= len) {\n+  if (GetVarint32(input, &len) && input->size() >= len) {\n     *result = Slice(input->data(), len);\n     input->remove_prefix(len);\n     return true;"
      },
      {
        "sha": "1983ae71730dd0a407352e22a34092376c84178a",
        "filename": "util/coding.h",
        "status": "modified",
        "additions": 98,
        "deletions": 38,
        "changes": 136,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/coding.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/coding.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/coding.h?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -10,87 +10,147 @@\n #ifndef STORAGE_LEVELDB_UTIL_CODING_H_\n #define STORAGE_LEVELDB_UTIL_CODING_H_\n \n-#include <stdint.h>\n-#include <string.h>\n+#include <cstdint>\n+#include <cstring>\n #include <string>\n+\n #include \"leveldb/slice.h\"\n #include \"port/port.h\"\n \n namespace leveldb {\n \n // Standard Put... routines append to a string\n-extern void PutFixed32(std::string* dst, uint32_t value);\n-extern void PutFixed64(std::string* dst, uint64_t value);\n-extern void PutVarint32(std::string* dst, uint32_t value);\n-extern void PutVarint64(std::string* dst, uint64_t value);\n-extern void PutLengthPrefixedSlice(std::string* dst, const Slice& value);\n+void PutFixed32(std::string* dst, uint32_t value);\n+void PutFixed64(std::string* dst, uint64_t value);\n+void PutVarint32(std::string* dst, uint32_t value);\n+void PutVarint64(std::string* dst, uint64_t value);\n+void PutLengthPrefixedSlice(std::string* dst, const Slice& value);\n \n // Standard Get... routines parse a value from the beginning of a Slice\n // and advance the slice past the parsed value.\n-extern bool GetVarint32(Slice* input, uint32_t* value);\n-extern bool GetVarint64(Slice* input, uint64_t* value);\n-extern bool GetLengthPrefixedSlice(Slice* input, Slice* result);\n+bool GetVarint32(Slice* input, uint32_t* value);\n+bool GetVarint64(Slice* input, uint64_t* value);\n+bool GetLengthPrefixedSlice(Slice* input, Slice* result);\n \n // Pointer-based variants of GetVarint...  These either store a value\n // in *v and return a pointer just past the parsed value, or return\n-// NULL on error.  These routines only look at bytes in the range\n+// nullptr on error.  These routines only look at bytes in the range\n // [p..limit-1]\n-extern const char* GetVarint32Ptr(const char* p,const char* limit, uint32_t* v);\n-extern const char* GetVarint64Ptr(const char* p,const char* limit, uint64_t* v);\n+const char* GetVarint32Ptr(const char* p, const char* limit, uint32_t* v);\n+const char* GetVarint64Ptr(const char* p, const char* limit, uint64_t* v);\n \n // Returns the length of the varint32 or varint64 encoding of \"v\"\n-extern int VarintLength(uint64_t v);\n+int VarintLength(uint64_t v);\n \n // Lower-level versions of Put... that write directly into a character buffer\n+// and return a pointer just past the last byte written.\n // REQUIRES: dst has enough space for the value being written\n-extern void EncodeFixed32(char* dst, uint32_t value);\n-extern void EncodeFixed64(char* dst, uint64_t value);\n+char* EncodeVarint32(char* dst, uint32_t value);\n+char* EncodeVarint64(char* dst, uint64_t value);\n+\n+// TODO(costan): Remove port::kLittleEndian and the fast paths based on\n+//               std::memcpy when clang learns to optimize the generic code, as\n+//               described in https://bugs.llvm.org/show_bug.cgi?id=41761\n+//\n+// The platform-independent code in DecodeFixed{32,64}() gets optimized to mov\n+// on x86 and ldr on ARM64, by both clang and gcc. However, only gcc optimizes\n+// the platform-independent code in EncodeFixed{32,64}() to mov / str.\n \n // Lower-level versions of Put... that write directly into a character buffer\n-// and return a pointer just past the last byte written.\n // REQUIRES: dst has enough space for the value being written\n-extern char* EncodeVarint32(char* dst, uint32_t value);\n-extern char* EncodeVarint64(char* dst, uint64_t value);\n+\n+inline void EncodeFixed32(char* dst, uint32_t value) {\n+  uint8_t* const buffer = reinterpret_cast<uint8_t*>(dst);\n+\n+  if (port::kLittleEndian) {\n+    // Fast path for little-endian CPUs. All major compilers optimize this to a\n+    // single mov (x86_64) / str (ARM) instruction.\n+    std::memcpy(buffer, &value, sizeof(uint32_t));\n+    return;\n+  }\n+\n+  // Platform-independent code.\n+  // Currently, only gcc optimizes this to a single mov / str instruction.\n+  buffer[0] = static_cast<uint8_t>(value);\n+  buffer[1] = static_cast<uint8_t>(value >> 8);\n+  buffer[2] = static_cast<uint8_t>(value >> 16);\n+  buffer[3] = static_cast<uint8_t>(value >> 24);\n+}\n+\n+inline void EncodeFixed64(char* dst, uint64_t value) {\n+  uint8_t* const buffer = reinterpret_cast<uint8_t*>(dst);\n+\n+  if (port::kLittleEndian) {\n+    // Fast path for little-endian CPUs. All major compilers optimize this to a\n+    // single mov (x86_64) / str (ARM) instruction.\n+    std::memcpy(buffer, &value, sizeof(uint64_t));\n+    return;\n+  }\n+\n+  // Platform-independent code.\n+  // Currently, only gcc optimizes this to a single mov / str instruction.\n+  buffer[0] = static_cast<uint8_t>(value);\n+  buffer[1] = static_cast<uint8_t>(value >> 8);\n+  buffer[2] = static_cast<uint8_t>(value >> 16);\n+  buffer[3] = static_cast<uint8_t>(value >> 24);\n+  buffer[4] = static_cast<uint8_t>(value >> 32);\n+  buffer[5] = static_cast<uint8_t>(value >> 40);\n+  buffer[6] = static_cast<uint8_t>(value >> 48);\n+  buffer[7] = static_cast<uint8_t>(value >> 56);\n+}\n \n // Lower-level versions of Get... that read directly from a character buffer\n // without any bounds checking.\n \n inline uint32_t DecodeFixed32(const char* ptr) {\n+  const uint8_t* const buffer = reinterpret_cast<const uint8_t*>(ptr);\n+\n   if (port::kLittleEndian) {\n-    // Load the raw bytes\n+    // Fast path for little-endian CPUs. All major compilers optimize this to a\n+    // single mov (x86_64) / ldr (ARM) instruction.\n     uint32_t result;\n-    memcpy(&result, ptr, sizeof(result));  // gcc optimizes this to a plain load\n+    std::memcpy(&result, buffer, sizeof(uint32_t));\n     return result;\n-  } else {\n-    return ((static_cast<uint32_t>(static_cast<unsigned char>(ptr[0])))\n-        | (static_cast<uint32_t>(static_cast<unsigned char>(ptr[1])) << 8)\n-        | (static_cast<uint32_t>(static_cast<unsigned char>(ptr[2])) << 16)\n-        | (static_cast<uint32_t>(static_cast<unsigned char>(ptr[3])) << 24));\n   }\n+\n+  // Platform-independent code.\n+  // Clang and gcc optimize this to a single mov / ldr instruction.\n+  return (static_cast<uint32_t>(buffer[0])) |\n+         (static_cast<uint32_t>(buffer[1]) << 8) |\n+         (static_cast<uint32_t>(buffer[2]) << 16) |\n+         (static_cast<uint32_t>(buffer[3]) << 24);\n }\n \n inline uint64_t DecodeFixed64(const char* ptr) {\n+  const uint8_t* const buffer = reinterpret_cast<const uint8_t*>(ptr);\n+\n   if (port::kLittleEndian) {\n-    // Load the raw bytes\n+    // Fast path for little-endian CPUs. All major compilers optimize this to a\n+    // single mov (x86_64) / ldr (ARM) instruction.\n     uint64_t result;\n-    memcpy(&result, ptr, sizeof(result));  // gcc optimizes this to a plain load\n+    std::memcpy(&result, buffer, sizeof(uint64_t));\n     return result;\n-  } else {\n-    uint64_t lo = DecodeFixed32(ptr);\n-    uint64_t hi = DecodeFixed32(ptr + 4);\n-    return (hi << 32) | lo;\n   }\n+\n+  // Platform-independent code.\n+  // Clang and gcc optimize this to a single mov / ldr instruction.\n+  return (static_cast<uint64_t>(buffer[0])) |\n+         (static_cast<uint64_t>(buffer[1]) << 8) |\n+         (static_cast<uint64_t>(buffer[2]) << 16) |\n+         (static_cast<uint64_t>(buffer[3]) << 24) |\n+         (static_cast<uint64_t>(buffer[4]) << 32) |\n+         (static_cast<uint64_t>(buffer[5]) << 40) |\n+         (static_cast<uint64_t>(buffer[6]) << 48) |\n+         (static_cast<uint64_t>(buffer[7]) << 56);\n }\n \n // Internal routine for use by fallback path of GetVarint32Ptr\n-extern const char* GetVarint32PtrFallback(const char* p,\n-                                          const char* limit,\n-                                          uint32_t* value);\n-inline const char* GetVarint32Ptr(const char* p,\n-                                  const char* limit,\n+const char* GetVarint32PtrFallback(const char* p, const char* limit,\n+                                   uint32_t* value);\n+inline const char* GetVarint32Ptr(const char* p, const char* limit,\n                                   uint32_t* value) {\n   if (p < limit) {\n-    uint32_t result = *(reinterpret_cast<const unsigned char*>(p));\n+    uint32_t result = *(reinterpret_cast<const uint8_t*>(p));\n     if ((result & 128) == 0) {\n       *value = result;\n       return p + 1;"
      },
      {
        "sha": "0d2a0c51f69e094e146844d97c94a7306e24a676",
        "filename": "util/coding_test.cc",
        "status": "modified",
        "additions": 21,
        "deletions": 21,
        "changes": 42,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/coding_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/coding_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/coding_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -2,13 +2,14 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include \"util/coding.h\"\n+#include <vector>\n \n+#include \"util/coding.h\"\n #include \"util/testharness.h\"\n \n namespace leveldb {\n \n-class Coding { };\n+class Coding {};\n \n TEST(Coding, Fixed32) {\n   std::string s;\n@@ -38,15 +39,15 @@ TEST(Coding, Fixed64) {\n     uint64_t v = static_cast<uint64_t>(1) << power;\n     uint64_t actual;\n     actual = DecodeFixed64(p);\n-    ASSERT_EQ(v-1, actual);\n+    ASSERT_EQ(v - 1, actual);\n     p += sizeof(uint64_t);\n \n     actual = DecodeFixed64(p);\n-    ASSERT_EQ(v+0, actual);\n+    ASSERT_EQ(v + 0, actual);\n     p += sizeof(uint64_t);\n \n     actual = DecodeFixed64(p);\n-    ASSERT_EQ(v+1, actual);\n+    ASSERT_EQ(v + 1, actual);\n     p += sizeof(uint64_t);\n   }\n }\n@@ -88,7 +89,7 @@ TEST(Coding, Varint32) {\n     uint32_t actual;\n     const char* start = p;\n     p = GetVarint32Ptr(p, limit, &actual);\n-    ASSERT_TRUE(p != NULL);\n+    ASSERT_TRUE(p != nullptr);\n     ASSERT_EQ(expected, actual);\n     ASSERT_EQ(VarintLength(actual), p - start);\n   }\n@@ -107,8 +108,8 @@ TEST(Coding, Varint64) {\n     // Test values near powers of two\n     const uint64_t power = 1ull << k;\n     values.push_back(power);\n-    values.push_back(power-1);\n-    values.push_back(power+1);\n+    values.push_back(power - 1);\n+    values.push_back(power + 1);\n   }\n \n   std::string s;\n@@ -123,19 +124,18 @@ TEST(Coding, Varint64) {\n     uint64_t actual;\n     const char* start = p;\n     p = GetVarint64Ptr(p, limit, &actual);\n-    ASSERT_TRUE(p != NULL);\n+    ASSERT_TRUE(p != nullptr);\n     ASSERT_EQ(values[i], actual);\n     ASSERT_EQ(VarintLength(actual), p - start);\n   }\n   ASSERT_EQ(p, limit);\n-\n }\n \n TEST(Coding, Varint32Overflow) {\n   uint32_t result;\n   std::string input(\"\\x81\\x82\\x83\\x84\\x85\\x11\");\n-  ASSERT_TRUE(GetVarint32Ptr(input.data(), input.data() + input.size(), &result)\n-              == NULL);\n+  ASSERT_TRUE(GetVarint32Ptr(input.data(), input.data() + input.size(),\n+                             &result) == nullptr);\n }\n \n TEST(Coding, Varint32Truncation) {\n@@ -144,17 +144,18 @@ TEST(Coding, Varint32Truncation) {\n   PutVarint32(&s, large_value);\n   uint32_t result;\n   for (size_t len = 0; len < s.size() - 1; len++) {\n-    ASSERT_TRUE(GetVarint32Ptr(s.data(), s.data() + len, &result) == NULL);\n+    ASSERT_TRUE(GetVarint32Ptr(s.data(), s.data() + len, &result) == nullptr);\n   }\n-  ASSERT_TRUE(GetVarint32Ptr(s.data(), s.data() + s.size(), &result) != NULL);\n+  ASSERT_TRUE(GetVarint32Ptr(s.data(), s.data() + s.size(), &result) !=\n+              nullptr);\n   ASSERT_EQ(large_value, result);\n }\n \n TEST(Coding, Varint64Overflow) {\n   uint64_t result;\n   std::string input(\"\\x81\\x82\\x83\\x84\\x85\\x81\\x82\\x83\\x84\\x85\\x11\");\n-  ASSERT_TRUE(GetVarint64Ptr(input.data(), input.data() + input.size(), &result)\n-              == NULL);\n+  ASSERT_TRUE(GetVarint64Ptr(input.data(), input.data() + input.size(),\n+                             &result) == nullptr);\n }\n \n TEST(Coding, Varint64Truncation) {\n@@ -163,9 +164,10 @@ TEST(Coding, Varint64Truncation) {\n   PutVarint64(&s, large_value);\n   uint64_t result;\n   for (size_t len = 0; len < s.size() - 1; len++) {\n-    ASSERT_TRUE(GetVarint64Ptr(s.data(), s.data() + len, &result) == NULL);\n+    ASSERT_TRUE(GetVarint64Ptr(s.data(), s.data() + len, &result) == nullptr);\n   }\n-  ASSERT_TRUE(GetVarint64Ptr(s.data(), s.data() + s.size(), &result) != NULL);\n+  ASSERT_TRUE(GetVarint64Ptr(s.data(), s.data() + s.size(), &result) !=\n+              nullptr);\n   ASSERT_EQ(large_value, result);\n }\n \n@@ -191,6 +193,4 @@ TEST(Coding, Strings) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "c5766e9462f4e8466756e83a5b986767fd2566a2",
        "filename": "util/comparator.cc",
        "status": "modified",
        "additions": 17,
        "deletions": 23,
        "changes": 40,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/comparator.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/comparator.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/comparator.cc?ref=66480821b36c839ab7615cb9309850015bceadb0",
        "patch": "@@ -2,33 +2,34 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include <algorithm>\n-#include <stdint.h>\n #include \"leveldb/comparator.h\"\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <string>\n+#include <type_traits>\n+\n #include \"leveldb/slice.h\"\n-#include \"port/port.h\"\n #include \"util/logging.h\"\n+#include \"util/no_destructor.h\"\n \n namespace leveldb {\n \n-Comparator::~Comparator() { }\n+Comparator::~Comparator() = default;\n \n namespace {\n class BytewiseComparatorImpl : public Comparator {\n  public:\n-  BytewiseComparatorImpl() { }\n+  BytewiseComparatorImpl() = default;\n \n-  virtual const char* Name() const {\n-    return \"leveldb.BytewiseComparator\";\n-  }\n+  const char* Name() const override { return \"leveldb.BytewiseComparator\"; }\n \n-  virtual int Compare(const Slice& a, const Slice& b) const {\n+  int Compare(const Slice& a, const Slice& b) const override {\n     return a.compare(b);\n   }\n \n-  virtual void FindShortestSeparator(\n-      std::string* start,\n-      const Slice& limit) const {\n+  void FindShortestSeparator(std::string* start,\n+                             const Slice& limit) const override {\n     // Find length of common prefix\n     size_t min_length = std::min(start->size(), limit.size());\n     size_t diff_index = 0;\n@@ -50,14 +51,14 @@ class BytewiseComparatorImpl : public Comparator {\n     }\n   }\n \n-  virtual void FindShortSuccessor(std::string* key) const {\n+  void FindShortSuccessor(std::string* key) const override {\n     // Find first character that can be incremented\n     size_t n = key->size();\n     for (size_t i = 0; i < n; i++) {\n       const uint8_t byte = (*key)[i];\n       if (byte != static_cast<uint8_t>(0xff)) {\n         (*key)[i] = byte + 1;\n-        key->resize(i+1);\n+        key->resize(i + 1);\n         return;\n       }\n     }\n@@ -66,16 +67,9 @@ class BytewiseComparatorImpl : public Comparator {\n };\n }  // namespace\n \n-static port::OnceType once = LEVELDB_ONCE_INIT;\n-static const Comparator* bytewise;\n-\n-static void InitModule() {\n-  bytewise = new BytewiseComparatorImpl;\n-}\n-\n const Comparator* BytewiseComparator() {\n-  port::InitOnce(&once, InitModule);\n-  return bytewise;\n+  static NoDestructor<BytewiseComparatorImpl> singleton;\n+  return singleton.get();\n }\n \n }  // namespace leveldb"
      },
      {
        "sha": "c2e61f7dbac5089b41acd1208dbb495de06d10f8",
        "filename": "util/crc32c.cc",
        "status": "modified",
        "additions": 0,
        "deletions": 0,
        "changes": 0,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/crc32c.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/crc32c.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/crc32c.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "98fabb0d2f33b624ffae236b050a4f7ee2af9548",
        "filename": "util/crc32c.h",
        "status": "modified",
        "additions": 2,
        "deletions": 4,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/crc32c.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/crc32c.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/crc32c.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "18a8494824d34690df6f4795017206392a0c8005",
        "filename": "util/crc32c_test.cc",
        "status": "modified",
        "additions": 9,
        "deletions": 22,
        "changes": 31,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/crc32c_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/crc32c_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/crc32c_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "d2f0aef3268bb7d5c4bdea235c97e4a69d25334b",
        "filename": "util/env.cc",
        "status": "modified",
        "additions": 9,
        "deletions": 17,
        "changes": 26,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/env.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/env.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/env.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "9f5863a0f35abdfe5c702fd0df2100dcab0ce70a",
        "filename": "util/env_posix.cc",
        "status": "modified",
        "additions": 661,
        "deletions": 461,
        "changes": 1122,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/env_posix.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/env_posix.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/env_posix.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "9675d739adad0adc24ec38e3d4b4f010abfea414",
        "filename": "util/env_posix_test.cc",
        "status": "modified",
        "additions": 292,
        "deletions": 8,
        "changes": 300,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/env_posix_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/env_posix_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/env_posix_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "7db03fc11c083c569d4924e7c9d5230ba99d9c80",
        "filename": "util/env_test.cc",
        "status": "modified",
        "additions": 183,
        "deletions": 52,
        "changes": 235,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/env_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/env_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/env_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "830332abe9b32f2af88f463e26cb5288919a59b1",
        "filename": "util/env_win.cc",
        "status": "removed",
        "additions": 0,
        "deletions": 902,
        "changes": 902,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/util/env_win.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/4f2e6c8b881b7ccda36233332dfd1bd231389a8e/util/env_win.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/env_win.cc?ref=4f2e6c8b881b7ccda36233332dfd1bd231389a8e"
      },
      {
        "sha": "1834206562cbd44456d2c14ad345d7f95b509d4d",
        "filename": "util/env_windows.cc",
        "status": "added",
        "additions": 849,
        "deletions": 0,
        "changes": 849,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/env_windows.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/env_windows.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/env_windows.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "3c22133891e53b0c1878261b22a52d005a5db992",
        "filename": "util/env_windows_test.cc",
        "status": "added",
        "additions": 64,
        "deletions": 0,
        "changes": 64,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/env_windows_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/env_windows_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/env_windows_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "e6f6020561ac919b38413eb3e34f4234107fa4ec",
        "filename": "util/env_windows_test_helper.h",
        "status": "added",
        "additions": 25,
        "deletions": 0,
        "changes": 25,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/env_windows_test_helper.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/env_windows_test_helper.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/env_windows_test_helper.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "90fd754d64a577fa22180f29dbf7388ab8a8ded1",
        "filename": "util/filter_policy.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/filter_policy.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/filter_policy.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/filter_policy.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "dd47c110ee9219bce9462084ac1bb79f23e9bd76",
        "filename": "util/hash.cc",
        "status": "modified",
        "additions": 9,
        "deletions": 6,
        "changes": 15,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/hash.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/hash.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/hash.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "74bdb6e7b20a28bc4f02149f72c2a91a439fbd90",
        "filename": "util/hash.h",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/hash.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/hash.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/hash.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "21f8171da6c94b3ab0a27e55f1fee0a3ddfb4286",
        "filename": "util/hash_test.cc",
        "status": "modified",
        "additions": 11,
        "deletions": 21,
        "changes": 32,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/hash_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/hash_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/hash_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "65092c88f2e3add68ef230be409d698f0140400f",
        "filename": "util/histogram.cc",
        "status": "modified",
        "additions": 170,
        "deletions": 37,
        "changes": 207,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/histogram.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/histogram.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/histogram.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "4da60fba4509b246ee56f6ea5f65156833d0d4e2",
        "filename": "util/histogram.h",
        "status": "modified",
        "additions": 11,
        "deletions": 9,
        "changes": 20,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/histogram.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/histogram.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/histogram.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "75e9d037d3f9ebeadc9bd78185aa9e100b0e42b8",
        "filename": "util/logging.cc",
        "status": "modified",
        "additions": 32,
        "deletions": 20,
        "changes": 52,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/logging.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/logging.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/logging.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "8ff2da86b4960a645fbdcec1a717aa8a87973f46",
        "filename": "util/logging.h",
        "status": "modified",
        "additions": 8,
        "deletions": 6,
        "changes": 14,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/logging.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/logging.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/logging.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "389cbeb14f74520563a2cf8f10389409d30bbdf5",
        "filename": "util/logging_test.cc",
        "status": "added",
        "additions": 143,
        "deletions": 0,
        "changes": 143,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/logging_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/logging_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/logging_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "0cb2e250fb5a1731f99a73453c2d8c2333914809",
        "filename": "util/mutexlock.h",
        "status": "modified",
        "additions": 5,
        "deletions": 7,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/mutexlock.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/mutexlock.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/mutexlock.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "a0d3b8703d750f8e3ea85a1f7269908fb842a910",
        "filename": "util/no_destructor.h",
        "status": "added",
        "additions": 46,
        "deletions": 0,
        "changes": 46,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/no_destructor.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/no_destructor.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/no_destructor.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "b41caca694544f01a800f56f65148ed7b3f4f48c",
        "filename": "util/no_destructor_test.cc",
        "status": "added",
        "additions": 47,
        "deletions": 0,
        "changes": 47,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/no_destructor_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/no_destructor_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/no_destructor_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "62de5bf0d2f7ea06741fda57b5a5cc94ce569a76",
        "filename": "util/options.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 17,
        "changes": 18,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/options.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/options.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/options.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "28e15d10b4d60ffa4dbcf935124f9adbd04fba42",
        "filename": "util/posix_logger.h",
        "status": "modified",
        "additions": 100,
        "deletions": 68,
        "changes": 168,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/posix_logger.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/posix_logger.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/posix_logger.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "76f7daf52a001105dc28a620f62191a1c022dbb6",
        "filename": "util/random.h",
        "status": "modified",
        "additions": 4,
        "deletions": 5,
        "changes": 9,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/random.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/random.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/random.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "15ce747d80ace4893fa134c3b1b61589fc27565c",
        "filename": "util/status.cc",
        "status": "modified",
        "additions": 8,
        "deletions": 6,
        "changes": 14,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/status.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/status.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/status.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "2842319fbdb13616a674c00f216c8eab4da3a55c",
        "filename": "util/status_test.cc",
        "status": "added",
        "additions": 40,
        "deletions": 0,
        "changes": 40,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/status_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/status_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/status_test.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "318ecfa3b7d91c8fc1d9b5d473f0a1bec2d57c61",
        "filename": "util/testharness.cc",
        "status": "modified",
        "additions": 11,
        "deletions": 7,
        "changes": 18,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/testharness.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/testharness.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/testharness.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "72cd1629eb5bf5172ecd073ee2b793d8dbb21543",
        "filename": "util/testharness.h",
        "status": "modified",
        "additions": 44,
        "deletions": 41,
        "changes": 85,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/testharness.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/testharness.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/testharness.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "6b151b9e643f918f6196ed398564d7eb6d2b267a",
        "filename": "util/testutil.cc",
        "status": "modified",
        "additions": 5,
        "deletions": 7,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/testutil.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/testutil.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/testutil.cc?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "bb4051ba076a3250a6d3a82f374ce2a1cd33d169",
        "filename": "util/testutil.h",
        "status": "modified",
        "additions": 16,
        "deletions": 13,
        "changes": 29,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/testutil.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/testutil.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/testutil.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      },
      {
        "sha": "92960638d179529e5d10f4cb35d3c0f692878996",
        "filename": "util/windows_logger.h",
        "status": "added",
        "additions": 124,
        "deletions": 0,
        "changes": 124,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/66480821b36c839ab7615cb9309850015bceadb0/util/windows_logger.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/66480821b36c839ab7615cb9309850015bceadb0/util/windows_logger.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/util/windows_logger.h?ref=66480821b36c839ab7615cb9309850015bceadb0"
      }
    ]
  },
  {
    "sha": "20a6babfa9a66f5432ef19c6c433b4357560f853",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzoyMGE2YmFiZmE5YTY2ZjU0MzJlZjE5YzZjNDMzYjQzNTc1NjBmODUz",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T15:59:07Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T15:59:07Z"
      },
      "message": "Update to leveldb upstream using subtree merge",
      "tree": {
        "sha": "0834cbc4054d41dfb8de5ec90143b4415adbc41d",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/0834cbc4054d41dfb8de5ec90143b4415adbc41d"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/20a6babfa9a66f5432ef19c6c433b4357560f853",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/20a6babfa9a66f5432ef19c6c433b4357560f853",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/20a6babfa9a66f5432ef19c6c433b4357560f853",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/20a6babfa9a66f5432ef19c6c433b4357560f853/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/2755b2b1092d0286022cf3cc3028e96f6bee2b34"
      },
      {
        "sha": "66480821b36c839ab7615cb9309850015bceadb0",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/66480821b36c839ab7615cb9309850015bceadb0",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/66480821b36c839ab7615cb9309850015bceadb0"
      }
    ],
    "stats": {
      "total": 16432,
      "additions": 8569,
      "deletions": 7863
    },
    "files": [
      {
        "sha": "c24b17e8050882e621cb06eca956c38b1edc1121",
        "filename": "src/leveldb/.appveyor.yml",
        "status": "added",
        "additions": 35,
        "deletions": 0,
        "changes": 35,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/.appveyor.yml",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/.appveyor.yml",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/.appveyor.yml?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -0,0 +1,35 @@\n+# Build matrix / environment variables are explained on:\n+# https://www.appveyor.com/docs/appveyor-yml/\n+# This file can be validated on: https://ci.appveyor.com/tools/validate-yaml\n+\n+version: \"{build}\"\n+\n+environment:\n+  matrix:\n+    # AppVeyor currently has no custom job name feature.\n+    # http://help.appveyor.com/discussions/questions/1623-can-i-provide-a-friendly-name-for-jobs\n+    - JOB: Visual Studio 2017\n+      APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2017\n+      CMAKE_GENERATOR: Visual Studio 15 2017\n+\n+platform:\n+  - x86\n+  - x64\n+\n+configuration:\n+  - RelWithDebInfo\n+  - Debug\n+\n+build_script:\n+  - git submodule update --init --recursive\n+  - mkdir build\n+  - cd build\n+  - if \"%platform%\"==\"x64\" set CMAKE_GENERATOR=%CMAKE_GENERATOR% Win64\n+  - cmake --version\n+  - cmake .. -G \"%CMAKE_GENERATOR%\"\n+      -DCMAKE_CONFIGURATION_TYPES=\"%CONFIGURATION%\"\n+  - cmake --build . --config \"%CONFIGURATION%\"\n+  - cd ..\n+\n+test_script:\n+  - cd build && ctest --verbose --build-config \"%CONFIGURATION%\" && cd .."
      },
      {
        "sha": "f493f75382cc0dd27eb40571eb62f6c3b2d65aaf",
        "filename": "src/leveldb/.clang-format",
        "status": "added",
        "additions": 18,
        "deletions": 0,
        "changes": 18,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/.clang-format",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/.clang-format",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/.clang-format?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -0,0 +1,18 @@\n+# Run manually to reformat a file:\n+# clang-format -i --style=file <file>\n+# find . -iname '*.cc' -o -iname '*.h' -o -iname '*.h.in' | xargs clang-format -i --style=file\n+BasedOnStyle: Google\n+DerivePointerAlignment: false\n+\n+# Public headers are in a different location in the internal Google repository.\n+# Order them so that when imported to the authoritative repository they will be\n+# in correct alphabetical order.\n+IncludeCategories:\n+  - Regex:           '^(<|\"(benchmarks|db|helpers)/)'\n+    Priority:        1\n+  - Regex:           '^\"(leveldb)/'\n+    Priority:        2\n+  - Regex:           '^(<|\"(issues|port|table|third_party|util)/)'\n+    Priority:        3\n+  - Regex:           '.*'\n+    Priority:        4"
      },
      {
        "sha": "c4b242534fb45faa8e608f4d5234469439dd1460",
        "filename": "src/leveldb/.gitignore",
        "status": "modified",
        "additions": 8,
        "deletions": 13,
        "changes": 21,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/.gitignore",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/.gitignore",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/.gitignore?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -1,13 +1,8 @@\n-build_config.mk\n-*.a\n-*.o\n-*.dylib*\n-*.so\n-*.so.*\n-*_test\n-db_bench\n-leveldbutil\n-Release\n-Debug\n-Benchmark\n-vs2010.*\n+# Editors.\n+*.sw*\n+.vscode\n+.DS_Store\n+\n+# Build directory.\n+build/\n+out/"
      },
      {
        "sha": "42cbe64fd0ed5c25ad16c2ce9d4ca7522cebcfdd",
        "filename": "src/leveldb/.travis.yml",
        "status": "modified",
        "additions": 75,
        "deletions": 6,
        "changes": 81,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/.travis.yml",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/.travis.yml",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/.travis.yml?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -1,13 +1,82 @@\n+# Build matrix / environment variables are explained on:\n+# http://about.travis-ci.org/docs/user/build-configuration/\n+# This file can be validated on: http://lint.travis-ci.org/\n+\n language: cpp\n+dist: bionic\n+osx_image: xcode10.3\n+\n compiler:\n-- clang\n - gcc\n+- clang\n os:\n - linux\n - osx\n-sudo: false\n-before_install:\n-- echo $LANG\n-- echo $LC_ALL\n+\n+env:\n+- BUILD_TYPE=Debug\n+- BUILD_TYPE=RelWithDebInfo\n+\n+addons:\n+  apt:\n+    sources:\n+    - sourceline: 'deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-9 main'\n+      key_url: 'https://apt.llvm.org/llvm-snapshot.gpg.key'\n+    - sourceline: 'ppa:ubuntu-toolchain-r/test'\n+    packages:\n+    - clang-9\n+    - cmake\n+    - gcc-9\n+    - g++-9\n+    - libgoogle-perftools-dev\n+    - libkyotocabinet-dev\n+    - libsnappy-dev\n+    - libsqlite3-dev\n+    - ninja-build\n+  homebrew:\n+    packages:\n+    - cmake\n+    - crc32c\n+    - gcc@9\n+    - gperftools\n+    - kyoto-cabinet\n+    - llvm@9\n+    - ninja\n+    - snappy\n+    - sqlite3\n+    update: true\n+\n+install:\n+# The following Homebrew packages aren't linked by default, and need to be\n+# prepended to the path explicitly.\n+- if [ \"$TRAVIS_OS_NAME\" = \"osx\" ]; then\n+    export PATH=\"$(brew --prefix llvm)/bin:$PATH\";\n+  fi\n+# /usr/bin/gcc points to an older compiler on both Linux and macOS.\n+- if [ \"$CXX\" = \"g++\" ]; then export CXX=\"g++-9\" CC=\"gcc-9\"; fi\n+# /usr/bin/clang points to an older compiler on both Linux and macOS.\n+#\n+# Homebrew's llvm package doesn't ship a versioned clang++ binary, so the values\n+# below don't work on macOS. Fortunately, the path change above makes the\n+# default values (clang and clang++) resolve to the correct compiler on macOS.\n+- if [ \"$TRAVIS_OS_NAME\" = \"linux\" ]; then\n+    if [ \"$CXX\" = \"clang++\" ]; then export CXX=\"clang++-9\" CC=\"clang-9\"; fi;\n+  fi\n+- echo ${CC}\n+- echo ${CXX}\n+- ${CXX} --version\n+- cmake --version\n+\n+before_script:\n+- mkdir -p build && cd build\n+- cmake .. -G Ninja -DCMAKE_BUILD_TYPE=$BUILD_TYPE\n+    -DCMAKE_INSTALL_PREFIX=$HOME/.local\n+- cmake --build .\n+- cd ..\n+\n script:\n-- make -j 4 check\n+- cd build && ctest --verbose && cd ..\n+- \"if [ -f build/db_bench ] ; then build/db_bench ; fi\"\n+- \"if [ -f build/db_bench_sqlite3 ] ; then build/db_bench_sqlite3 ; fi\"\n+- \"if [ -f build/db_bench_tree_db ] ; then build/db_bench_tree_db ; fi\"\n+- cd build && cmake --build . --target install"
      },
      {
        "sha": "1cb46256c294349c7aaf8c88519fcec1d660b9af",
        "filename": "src/leveldb/CMakeLists.txt",
        "status": "added",
        "additions": 465,
        "deletions": 0,
        "changes": 465,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/CMakeLists.txt",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/CMakeLists.txt",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/CMakeLists.txt?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -0,0 +1,465 @@\n+# Copyright 2017 The LevelDB Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+cmake_minimum_required(VERSION 3.9)\n+# Keep the version below in sync with the one in db.h\n+project(leveldb VERSION 1.22.0 LANGUAGES C CXX)\n+\n+# This project can use C11, but will gracefully decay down to C89.\n+set(CMAKE_C_STANDARD 11)\n+set(CMAKE_C_STANDARD_REQUIRED OFF)\n+set(CMAKE_C_EXTENSIONS OFF)\n+\n+# This project requires C++11.\n+set(CMAKE_CXX_STANDARD 11)\n+set(CMAKE_CXX_STANDARD_REQUIRED ON)\n+set(CMAKE_CXX_EXTENSIONS OFF)\n+\n+if (WIN32)\n+  set(LEVELDB_PLATFORM_NAME LEVELDB_PLATFORM_WINDOWS)\n+  # TODO(cmumford): Make UNICODE configurable for Windows.\n+  add_definitions(-D_UNICODE -DUNICODE)\n+else (WIN32)\n+  set(LEVELDB_PLATFORM_NAME LEVELDB_PLATFORM_POSIX)\n+endif (WIN32)\n+\n+option(LEVELDB_BUILD_TESTS \"Build LevelDB's unit tests\" ON)\n+option(LEVELDB_BUILD_BENCHMARKS \"Build LevelDB's benchmarks\" ON)\n+option(LEVELDB_INSTALL \"Install LevelDB's header and library\" ON)\n+\n+include(TestBigEndian)\n+test_big_endian(LEVELDB_IS_BIG_ENDIAN)\n+\n+include(CheckIncludeFile)\n+check_include_file(\"unistd.h\" HAVE_UNISTD_H)\n+\n+include(CheckLibraryExists)\n+check_library_exists(crc32c crc32c_value \"\" HAVE_CRC32C)\n+check_library_exists(snappy snappy_compress \"\" HAVE_SNAPPY)\n+check_library_exists(tcmalloc malloc \"\" HAVE_TCMALLOC)\n+\n+include(CheckCXXSymbolExists)\n+# Using check_cxx_symbol_exists() instead of check_c_symbol_exists() because\n+# we're including the header from C++, and feature detection should use the same\n+# compiler language that the project will use later. Principles aside, some\n+# versions of do not expose fdatasync() in <unistd.h> in standard C mode\n+# (-std=c11), but do expose the function in standard C++ mode (-std=c++11).\n+check_cxx_symbol_exists(fdatasync \"unistd.h\" HAVE_FDATASYNC)\n+check_cxx_symbol_exists(F_FULLFSYNC \"fcntl.h\" HAVE_FULLFSYNC)\n+check_cxx_symbol_exists(O_CLOEXEC \"fcntl.h\" HAVE_O_CLOEXEC)\n+\n+if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  # Disable C++ exceptions.\n+  string(REGEX REPLACE \"/EH[a-z]+\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /EHs-c-\")\n+  add_definitions(-D_HAS_EXCEPTIONS=0)\n+\n+  # Disable RTTI.\n+  string(REGEX REPLACE \"/GR\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /GR-\")\n+else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  # Enable strict prototype warnings for C code in clang and gcc.\n+  if(NOT CMAKE_C_FLAGS MATCHES \"-Wstrict-prototypes\")\n+    set(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -Wstrict-prototypes\")\n+  endif(NOT CMAKE_C_FLAGS MATCHES \"-Wstrict-prototypes\")\n+\n+  # Disable C++ exceptions.\n+  string(REGEX REPLACE \"-fexceptions\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fno-exceptions\")\n+\n+  # Disable RTTI.\n+  string(REGEX REPLACE \"-frtti\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fno-rtti\")\n+endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+\n+# Test whether -Wthread-safety is available. See\n+# https://clang.llvm.org/docs/ThreadSafetyAnalysis.html\n+include(CheckCXXCompilerFlag)\n+check_cxx_compiler_flag(-Wthread-safety HAVE_CLANG_THREAD_SAFETY)\n+\n+include(CheckCXXSourceCompiles)\n+\n+# Test whether C++17 __has_include is available.\n+check_cxx_source_compiles(\"\n+#if defined(__has_include) &&  __has_include(<string>)\n+#include <string>\n+#endif\n+int main() { std::string str; return 0; }\n+\" HAVE_CXX17_HAS_INCLUDE)\n+\n+set(LEVELDB_PUBLIC_INCLUDE_DIR \"include/leveldb\")\n+set(LEVELDB_PORT_CONFIG_DIR \"include/port\")\n+\n+configure_file(\n+  \"port/port_config.h.in\"\n+  \"${PROJECT_BINARY_DIR}/${LEVELDB_PORT_CONFIG_DIR}/port_config.h\"\n+)\n+\n+include_directories(\n+  \"${PROJECT_BINARY_DIR}/include\"\n+  \".\"\n+)\n+\n+if(BUILD_SHARED_LIBS)\n+  # Only export LEVELDB_EXPORT symbols from the shared library.\n+  add_compile_options(-fvisibility=hidden)\n+endif(BUILD_SHARED_LIBS)\n+\n+# Must be included before CMAKE_INSTALL_INCLUDEDIR is used.\n+include(GNUInstallDirs)\n+\n+add_library(leveldb \"\")\n+target_sources(leveldb\n+  PRIVATE\n+    \"${PROJECT_BINARY_DIR}/${LEVELDB_PORT_CONFIG_DIR}/port_config.h\"\n+    \"db/builder.cc\"\n+    \"db/builder.h\"\n+    \"db/c.cc\"\n+    \"db/db_impl.cc\"\n+    \"db/db_impl.h\"\n+    \"db/db_iter.cc\"\n+    \"db/db_iter.h\"\n+    \"db/dbformat.cc\"\n+    \"db/dbformat.h\"\n+    \"db/dumpfile.cc\"\n+    \"db/filename.cc\"\n+    \"db/filename.h\"\n+    \"db/log_format.h\"\n+    \"db/log_reader.cc\"\n+    \"db/log_reader.h\"\n+    \"db/log_writer.cc\"\n+    \"db/log_writer.h\"\n+    \"db/memtable.cc\"\n+    \"db/memtable.h\"\n+    \"db/repair.cc\"\n+    \"db/skiplist.h\"\n+    \"db/snapshot.h\"\n+    \"db/table_cache.cc\"\n+    \"db/table_cache.h\"\n+    \"db/version_edit.cc\"\n+    \"db/version_edit.h\"\n+    \"db/version_set.cc\"\n+    \"db/version_set.h\"\n+    \"db/write_batch_internal.h\"\n+    \"db/write_batch.cc\"\n+    \"port/port_stdcxx.h\"\n+    \"port/port.h\"\n+    \"port/thread_annotations.h\"\n+    \"table/block_builder.cc\"\n+    \"table/block_builder.h\"\n+    \"table/block.cc\"\n+    \"table/block.h\"\n+    \"table/filter_block.cc\"\n+    \"table/filter_block.h\"\n+    \"table/format.cc\"\n+    \"table/format.h\"\n+    \"table/iterator_wrapper.h\"\n+    \"table/iterator.cc\"\n+    \"table/merger.cc\"\n+    \"table/merger.h\"\n+    \"table/table_builder.cc\"\n+    \"table/table.cc\"\n+    \"table/two_level_iterator.cc\"\n+    \"table/two_level_iterator.h\"\n+    \"util/arena.cc\"\n+    \"util/arena.h\"\n+    \"util/bloom.cc\"\n+    \"util/cache.cc\"\n+    \"util/coding.cc\"\n+    \"util/coding.h\"\n+    \"util/comparator.cc\"\n+    \"util/crc32c.cc\"\n+    \"util/crc32c.h\"\n+    \"util/env.cc\"\n+    \"util/filter_policy.cc\"\n+    \"util/hash.cc\"\n+    \"util/hash.h\"\n+    \"util/logging.cc\"\n+    \"util/logging.h\"\n+    \"util/mutexlock.h\"\n+    \"util/no_destructor.h\"\n+    \"util/options.cc\"\n+    \"util/random.h\"\n+    \"util/status.cc\"\n+\n+  # Only CMake 3.3+ supports PUBLIC sources in targets exported by \"install\".\n+  $<$<VERSION_GREATER:CMAKE_VERSION,3.2>:PUBLIC>\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/c.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/cache.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/comparator.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/db.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/dumpfile.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/env.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/export.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/filter_policy.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/iterator.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/options.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/slice.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/status.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/table_builder.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/table.h\"\n+    \"${LEVELDB_PUBLIC_INCLUDE_DIR}/write_batch.h\"\n+)\n+\n+if (WIN32)\n+  target_sources(leveldb\n+    PRIVATE\n+      \"util/env_windows.cc\"\n+      \"util/windows_logger.h\"\n+  )\n+else (WIN32)\n+  target_sources(leveldb\n+    PRIVATE\n+      \"util/env_posix.cc\"\n+      \"util/posix_logger.h\"\n+  )\n+endif (WIN32)\n+\n+# MemEnv is not part of the interface and could be pulled to a separate library.\n+target_sources(leveldb\n+  PRIVATE\n+    \"helpers/memenv/memenv.cc\"\n+    \"helpers/memenv/memenv.h\"\n+)\n+\n+target_include_directories(leveldb\n+  PUBLIC\n+    $<BUILD_INTERFACE:${PROJECT_SOURCE_DIR}/include>\n+    $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>\n+)\n+\n+set_target_properties(leveldb\n+  PROPERTIES VERSION ${PROJECT_VERSION} SOVERSION ${PROJECT_VERSION_MAJOR})\n+\n+target_compile_definitions(leveldb\n+  PRIVATE\n+    # Used by include/export.h when building shared libraries.\n+    LEVELDB_COMPILE_LIBRARY\n+    # Used by port/port.h.\n+    ${LEVELDB_PLATFORM_NAME}=1\n+)\n+if (NOT HAVE_CXX17_HAS_INCLUDE)\n+  target_compile_definitions(leveldb\n+    PRIVATE\n+      LEVELDB_HAS_PORT_CONFIG_H=1\n+  )\n+endif(NOT HAVE_CXX17_HAS_INCLUDE)\n+\n+if(BUILD_SHARED_LIBS)\n+  target_compile_definitions(leveldb\n+    PUBLIC\n+      # Used by include/export.h.\n+      LEVELDB_SHARED_LIBRARY\n+  )\n+endif(BUILD_SHARED_LIBS)\n+\n+if(HAVE_CLANG_THREAD_SAFETY)\n+  target_compile_options(leveldb\n+    PUBLIC\n+      -Werror -Wthread-safety)\n+endif(HAVE_CLANG_THREAD_SAFETY)\n+\n+if(HAVE_CRC32C)\n+  target_link_libraries(leveldb crc32c)\n+endif(HAVE_CRC32C)\n+if(HAVE_SNAPPY)\n+  target_link_libraries(leveldb snappy)\n+endif(HAVE_SNAPPY)\n+if(HAVE_TCMALLOC)\n+  target_link_libraries(leveldb tcmalloc)\n+endif(HAVE_TCMALLOC)\n+\n+# Needed by port_stdcxx.h\n+find_package(Threads REQUIRED)\n+target_link_libraries(leveldb Threads::Threads)\n+\n+add_executable(leveldbutil\n+  \"db/leveldbutil.cc\"\n+)\n+target_link_libraries(leveldbutil leveldb)\n+\n+if(LEVELDB_BUILD_TESTS)\n+  enable_testing()\n+\n+  function(leveldb_test test_file)\n+    get_filename_component(test_target_name \"${test_file}\" NAME_WE)\n+\n+    add_executable(\"${test_target_name}\" \"\")\n+    target_sources(\"${test_target_name}\"\n+      PRIVATE\n+        \"${PROJECT_BINARY_DIR}/${LEVELDB_PORT_CONFIG_DIR}/port_config.h\"\n+        \"util/testharness.cc\"\n+        \"util/testharness.h\"\n+        \"util/testutil.cc\"\n+        \"util/testutil.h\"\n+\n+        \"${test_file}\"\n+    )\n+    target_link_libraries(\"${test_target_name}\" leveldb)\n+    target_compile_definitions(\"${test_target_name}\"\n+      PRIVATE\n+        ${LEVELDB_PLATFORM_NAME}=1\n+    )\n+    if (NOT HAVE_CXX17_HAS_INCLUDE)\n+      target_compile_definitions(\"${test_target_name}\"\n+        PRIVATE\n+          LEVELDB_HAS_PORT_CONFIG_H=1\n+      )\n+    endif(NOT HAVE_CXX17_HAS_INCLUDE)\n+\n+    add_test(NAME \"${test_target_name}\" COMMAND \"${test_target_name}\")\n+  endfunction(leveldb_test)\n+\n+  leveldb_test(\"db/c_test.c\")\n+  leveldb_test(\"db/fault_injection_test.cc\")\n+\n+  leveldb_test(\"issues/issue178_test.cc\")\n+  leveldb_test(\"issues/issue200_test.cc\")\n+  leveldb_test(\"issues/issue320_test.cc\")\n+\n+  leveldb_test(\"util/env_test.cc\")\n+  leveldb_test(\"util/status_test.cc\")\n+  leveldb_test(\"util/no_destructor_test.cc\")\n+\n+  if(NOT BUILD_SHARED_LIBS)\n+    leveldb_test(\"db/autocompact_test.cc\")\n+    leveldb_test(\"db/corruption_test.cc\")\n+    leveldb_test(\"db/db_test.cc\")\n+    leveldb_test(\"db/dbformat_test.cc\")\n+    leveldb_test(\"db/filename_test.cc\")\n+    leveldb_test(\"db/log_test.cc\")\n+    leveldb_test(\"db/recovery_test.cc\")\n+    leveldb_test(\"db/skiplist_test.cc\")\n+    leveldb_test(\"db/version_edit_test.cc\")\n+    leveldb_test(\"db/version_set_test.cc\")\n+    leveldb_test(\"db/write_batch_test.cc\")\n+\n+    leveldb_test(\"helpers/memenv/memenv_test.cc\")\n+\n+    leveldb_test(\"table/filter_block_test.cc\")\n+    leveldb_test(\"table/table_test.cc\")\n+\n+    leveldb_test(\"util/arena_test.cc\")\n+    leveldb_test(\"util/bloom_test.cc\")\n+    leveldb_test(\"util/cache_test.cc\")\n+    leveldb_test(\"util/coding_test.cc\")\n+    leveldb_test(\"util/crc32c_test.cc\")\n+    leveldb_test(\"util/hash_test.cc\")\n+    leveldb_test(\"util/logging_test.cc\")\n+\n+    # TODO(costan): This test also uses\n+    #               \"util/env_{posix|windows}_test_helper.h\"\n+    if (WIN32)\n+      leveldb_test(\"util/env_windows_test.cc\")\n+    else (WIN32)\n+      leveldb_test(\"util/env_posix_test.cc\")\n+    endif (WIN32)\n+  endif(NOT BUILD_SHARED_LIBS)\n+endif(LEVELDB_BUILD_TESTS)\n+\n+if(LEVELDB_BUILD_BENCHMARKS)\n+  function(leveldb_benchmark bench_file)\n+    get_filename_component(bench_target_name \"${bench_file}\" NAME_WE)\n+\n+    add_executable(\"${bench_target_name}\" \"\")\n+    target_sources(\"${bench_target_name}\"\n+      PRIVATE\n+        \"${PROJECT_BINARY_DIR}/${LEVELDB_PORT_CONFIG_DIR}/port_config.h\"\n+        \"util/histogram.cc\"\n+        \"util/histogram.h\"\n+        \"util/testharness.cc\"\n+        \"util/testharness.h\"\n+        \"util/testutil.cc\"\n+        \"util/testutil.h\"\n+\n+        \"${bench_file}\"\n+    )\n+    target_link_libraries(\"${bench_target_name}\" leveldb)\n+    target_compile_definitions(\"${bench_target_name}\"\n+      PRIVATE\n+        ${LEVELDB_PLATFORM_NAME}=1\n+    )\n+    if (NOT HAVE_CXX17_HAS_INCLUDE)\n+      target_compile_definitions(\"${bench_target_name}\"\n+        PRIVATE\n+          LEVELDB_HAS_PORT_CONFIG_H=1\n+      )\n+    endif(NOT HAVE_CXX17_HAS_INCLUDE)\n+  endfunction(leveldb_benchmark)\n+\n+  if(NOT BUILD_SHARED_LIBS)\n+    leveldb_benchmark(\"benchmarks/db_bench.cc\")\n+  endif(NOT BUILD_SHARED_LIBS)\n+\n+  check_library_exists(sqlite3 sqlite3_open \"\" HAVE_SQLITE3)\n+  if(HAVE_SQLITE3)\n+    leveldb_benchmark(\"benchmarks/db_bench_sqlite3.cc\")\n+    target_link_libraries(db_bench_sqlite3 sqlite3)\n+  endif(HAVE_SQLITE3)\n+\n+  # check_library_exists is insufficient here because the library names have\n+  # different manglings when compiled with clang or gcc, at least when installed\n+  # with Homebrew on Mac.\n+  set(OLD_CMAKE_REQURED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES})\n+  list(APPEND CMAKE_REQUIRED_LIBRARIES kyotocabinet)\n+  check_cxx_source_compiles(\"\n+#include <kcpolydb.h>\n+\n+int main() {\n+  kyotocabinet::TreeDB* db = new kyotocabinet::TreeDB();\n+  delete db;\n+  return 0;\n+}\n+  \"  HAVE_KYOTOCABINET)\n+  set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQURED_LIBRARIES})\n+  if(HAVE_KYOTOCABINET)\n+    leveldb_benchmark(\"benchmarks/db_bench_tree_db.cc\")\n+    target_link_libraries(db_bench_tree_db kyotocabinet)\n+  endif(HAVE_KYOTOCABINET)\n+endif(LEVELDB_BUILD_BENCHMARKS)\n+\n+if(LEVELDB_INSTALL)\n+  install(TARGETS leveldb\n+    EXPORT leveldbTargets\n+    RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR}\n+    LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n+    ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}\n+  )\n+  install(\n+    FILES\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/c.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/cache.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/comparator.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/db.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/dumpfile.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/env.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/export.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/filter_policy.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/iterator.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/options.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/slice.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/status.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/table_builder.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/table.h\"\n+      \"${LEVELDB_PUBLIC_INCLUDE_DIR}/write_batch.h\"\n+    DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/leveldb\n+  )\n+\n+  include(CMakePackageConfigHelpers)\n+  write_basic_package_version_file(\n+      \"${PROJECT_BINARY_DIR}/leveldbConfigVersion.cmake\"\n+      COMPATIBILITY SameMajorVersion\n+  )\n+  install(\n+    EXPORT leveldbTargets\n+    NAMESPACE leveldb::\n+    DESTINATION \"${CMAKE_INSTALL_LIBDIR}/cmake/leveldb\"\n+  )\n+  install(\n+    FILES\n+      \"cmake/leveldbConfig.cmake\"\n+      \"${PROJECT_BINARY_DIR}/leveldbConfigVersion.cmake\"\n+    DESTINATION \"${CMAKE_INSTALL_LIBDIR}/cmake/leveldb\"\n+  )\n+endif(LEVELDB_INSTALL)"
      },
      {
        "sha": "a74572a596396761830c62b38ebddcb836298e03",
        "filename": "src/leveldb/CONTRIBUTING.md",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/CONTRIBUTING.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/CONTRIBUTING.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/CONTRIBUTING.md?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -31,6 +31,6 @@ the CLA.\n \n ## Writing Code ##\n \n-If your contribution contains code, please make sure that it follows \n-[the style guide](http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml).\n+If your contribution contains code, please make sure that it follows\n+[the style guide](http://google.github.io/styleguide/cppguide.html).\n Otherwise we will have to ask you to make changes, and that's no fun for anyone."
      },
      {
        "sha": "f7cc7d736c4f20d6cab6e760d43b76e880b80e95",
        "filename": "src/leveldb/Makefile",
        "status": "removed",
        "additions": 0,
        "deletions": 424,
        "changes": 424,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/Makefile",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/Makefile",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/Makefile?ref=2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "patch": "@@ -1,424 +0,0 @@\n-# Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-# Use of this source code is governed by a BSD-style license that can be\n-# found in the LICENSE file. See the AUTHORS file for names of contributors.\n-\n-#-----------------------------------------------\n-# Uncomment exactly one of the lines labelled (A), (B), and (C) below\n-# to switch between compilation modes.\n-\n-# (A) Production use (optimized mode)\n-OPT ?= -O2 -DNDEBUG\n-# (B) Debug mode, w/ full line-level debugging symbols\n-# OPT ?= -g2\n-# (C) Profiling mode: opt, but w/debugging symbols\n-# OPT ?= -O2 -g2 -DNDEBUG\n-#-----------------------------------------------\n-\n-# detect what platform we're building on\n-$(shell CC=\"$(CC)\" CXX=\"$(CXX)\" TARGET_OS=\"$(TARGET_OS)\" \\\n-    ./build_detect_platform build_config.mk ./)\n-# this file is generated by the previous line to set build flags and sources\n-include build_config.mk\n-\n-TESTS = \\\n-\tdb/autocompact_test \\\n-\tdb/c_test \\\n-\tdb/corruption_test \\\n-\tdb/db_test \\\n-\tdb/dbformat_test \\\n-\tdb/fault_injection_test \\\n-\tdb/filename_test \\\n-\tdb/log_test \\\n-\tdb/recovery_test \\\n-\tdb/skiplist_test \\\n-\tdb/version_edit_test \\\n-\tdb/version_set_test \\\n-\tdb/write_batch_test \\\n-\thelpers/memenv/memenv_test \\\n-\tissues/issue178_test \\\n-\tissues/issue200_test \\\n-\ttable/filter_block_test \\\n-\ttable/table_test \\\n-\tutil/arena_test \\\n-\tutil/bloom_test \\\n-\tutil/cache_test \\\n-\tutil/coding_test \\\n-\tutil/crc32c_test \\\n-\tutil/env_posix_test \\\n-\tutil/env_test \\\n-\tutil/hash_test\n-\n-UTILS = \\\n-\tdb/db_bench \\\n-\tdb/leveldbutil\n-\n-# Put the object files in a subdirectory, but the application at the top of the object dir.\n-PROGNAMES := $(notdir $(TESTS) $(UTILS))\n-\n-# On Linux may need libkyotocabinet-dev for dependency.\n-BENCHMARKS = \\\n-\tdoc/bench/db_bench_sqlite3 \\\n-\tdoc/bench/db_bench_tree_db\n-\n-CFLAGS += -I. -I./include $(PLATFORM_CCFLAGS) $(OPT)\n-CXXFLAGS += -I. -I./include $(PLATFORM_CXXFLAGS) $(OPT)\n-\n-LDFLAGS += $(PLATFORM_LDFLAGS)\n-LIBS += $(PLATFORM_LIBS)\n-\n-SIMULATOR_OUTDIR=out-ios-x86\n-DEVICE_OUTDIR=out-ios-arm\n-\n-ifeq ($(PLATFORM), IOS)\n-# Note: iOS should probably be using libtool, not ar.\n-AR=xcrun ar\n-SIMULATORSDK=$(shell xcrun -sdk iphonesimulator --show-sdk-path)\n-DEVICESDK=$(shell xcrun -sdk iphoneos --show-sdk-path)\n-DEVICE_CFLAGS = -isysroot \"$(DEVICESDK)\" -arch armv6 -arch armv7 -arch armv7s -arch arm64\n-SIMULATOR_CFLAGS = -isysroot \"$(SIMULATORSDK)\" -arch i686 -arch x86_64\n-STATIC_OUTDIR=out-ios-universal\n-else\n-STATIC_OUTDIR=out-static\n-SHARED_OUTDIR=out-shared\n-STATIC_PROGRAMS := $(addprefix $(STATIC_OUTDIR)/, $(PROGNAMES))\n-SHARED_PROGRAMS := $(addprefix $(SHARED_OUTDIR)/, db_bench)\n-endif\n-\n-STATIC_LIBOBJECTS := $(addprefix $(STATIC_OUTDIR)/, $(SOURCES:.cc=.o))\n-STATIC_MEMENVOBJECTS := $(addprefix $(STATIC_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n-\n-DEVICE_LIBOBJECTS := $(addprefix $(DEVICE_OUTDIR)/, $(SOURCES:.cc=.o))\n-DEVICE_MEMENVOBJECTS := $(addprefix $(DEVICE_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n-\n-SIMULATOR_LIBOBJECTS := $(addprefix $(SIMULATOR_OUTDIR)/, $(SOURCES:.cc=.o))\n-SIMULATOR_MEMENVOBJECTS := $(addprefix $(SIMULATOR_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n-\n-SHARED_LIBOBJECTS := $(addprefix $(SHARED_OUTDIR)/, $(SOURCES:.cc=.o))\n-SHARED_MEMENVOBJECTS := $(addprefix $(SHARED_OUTDIR)/, $(MEMENV_SOURCES:.cc=.o))\n-\n-TESTUTIL := $(STATIC_OUTDIR)/util/testutil.o\n-TESTHARNESS := $(STATIC_OUTDIR)/util/testharness.o $(TESTUTIL)\n-\n-STATIC_TESTOBJS := $(addprefix $(STATIC_OUTDIR)/, $(addsuffix .o, $(TESTS)))\n-STATIC_UTILOBJS := $(addprefix $(STATIC_OUTDIR)/, $(addsuffix .o, $(UTILS)))\n-STATIC_ALLOBJS := $(STATIC_LIBOBJECTS) $(STATIC_MEMENVOBJECTS) $(STATIC_TESTOBJS) $(STATIC_UTILOBJS) $(TESTHARNESS)\n-DEVICE_ALLOBJS := $(DEVICE_LIBOBJECTS) $(DEVICE_MEMENVOBJECTS)\n-SIMULATOR_ALLOBJS := $(SIMULATOR_LIBOBJECTS) $(SIMULATOR_MEMENVOBJECTS)\n-\n-default: all\n-\n-# Should we build shared libraries?\n-ifneq ($(PLATFORM_SHARED_EXT),)\n-\n-# Many leveldb test apps use non-exported API's. Only build a subset for testing.\n-SHARED_ALLOBJS := $(SHARED_LIBOBJECTS) $(SHARED_MEMENVOBJECTS) $(TESTHARNESS)\n-\n-ifneq ($(PLATFORM_SHARED_VERSIONED),true)\n-SHARED_LIB1 = libleveldb.$(PLATFORM_SHARED_EXT)\n-SHARED_LIB2 = $(SHARED_LIB1)\n-SHARED_LIB3 = $(SHARED_LIB1)\n-SHARED_LIBS = $(SHARED_LIB1)\n-SHARED_MEMENVLIB = $(SHARED_OUTDIR)/libmemenv.a\n-else\n-# Update db.h if you change these.\n-SHARED_VERSION_MAJOR = 1\n-SHARED_VERSION_MINOR = 20\n-SHARED_LIB1 = libleveldb.$(PLATFORM_SHARED_EXT)\n-SHARED_LIB2 = $(SHARED_LIB1).$(SHARED_VERSION_MAJOR)\n-SHARED_LIB3 = $(SHARED_LIB1).$(SHARED_VERSION_MAJOR).$(SHARED_VERSION_MINOR)\n-SHARED_LIBS = $(SHARED_OUTDIR)/$(SHARED_LIB1) $(SHARED_OUTDIR)/$(SHARED_LIB2) $(SHARED_OUTDIR)/$(SHARED_LIB3)\n-$(SHARED_OUTDIR)/$(SHARED_LIB1): $(SHARED_OUTDIR)/$(SHARED_LIB3)\n-\tln -fs $(SHARED_LIB3) $(SHARED_OUTDIR)/$(SHARED_LIB1)\n-$(SHARED_OUTDIR)/$(SHARED_LIB2): $(SHARED_OUTDIR)/$(SHARED_LIB3)\n-\tln -fs $(SHARED_LIB3) $(SHARED_OUTDIR)/$(SHARED_LIB2)\n-SHARED_MEMENVLIB = $(SHARED_OUTDIR)/libmemenv.a\n-endif\n-\n-$(SHARED_OUTDIR)/$(SHARED_LIB3): $(SHARED_LIBOBJECTS)\n-\t$(CXX) $(LDFLAGS) $(PLATFORM_SHARED_LDFLAGS)$(SHARED_LIB2) $(SHARED_LIBOBJECTS) -o $(SHARED_OUTDIR)/$(SHARED_LIB3) $(LIBS)\n-\n-endif  # PLATFORM_SHARED_EXT\n-\n-all: $(SHARED_LIBS) $(SHARED_PROGRAMS) $(STATIC_OUTDIR)/libleveldb.a $(STATIC_OUTDIR)/libmemenv.a $(STATIC_PROGRAMS)\n-\n-check: $(STATIC_PROGRAMS)\n-\tfor t in $(notdir $(TESTS)); do echo \"***** Running $$t\"; $(STATIC_OUTDIR)/$$t || exit 1; done\n-\n-clean:\n-\t-rm -rf out-static out-shared out-ios-x86 out-ios-arm out-ios-universal\n-\t-rm -f build_config.mk\n-\t-rm -rf ios-x86 ios-arm\n-\n-$(STATIC_OUTDIR):\n-\tmkdir $@\n-\n-$(STATIC_OUTDIR)/db: | $(STATIC_OUTDIR)\n-\tmkdir $@\n-\n-$(STATIC_OUTDIR)/helpers/memenv: | $(STATIC_OUTDIR)\n-\tmkdir -p $@\n-\n-$(STATIC_OUTDIR)/port: | $(STATIC_OUTDIR)\n-\tmkdir $@\n-\n-$(STATIC_OUTDIR)/table: | $(STATIC_OUTDIR)\n-\tmkdir $@\n-\n-$(STATIC_OUTDIR)/util: | $(STATIC_OUTDIR)\n-\tmkdir $@\n-\n-.PHONY: STATIC_OBJDIRS\n-STATIC_OBJDIRS: \\\n-\t$(STATIC_OUTDIR)/db \\\n-\t$(STATIC_OUTDIR)/port \\\n-\t$(STATIC_OUTDIR)/table \\\n-\t$(STATIC_OUTDIR)/util \\\n-\t$(STATIC_OUTDIR)/helpers/memenv\n-\n-$(SHARED_OUTDIR):\n-\tmkdir $@\n-\n-$(SHARED_OUTDIR)/db: | $(SHARED_OUTDIR)\n-\tmkdir $@\n-\n-$(SHARED_OUTDIR)/helpers/memenv: | $(SHARED_OUTDIR)\n-\tmkdir -p $@\n-\n-$(SHARED_OUTDIR)/port: | $(SHARED_OUTDIR)\n-\tmkdir $@\n-\n-$(SHARED_OUTDIR)/table: | $(SHARED_OUTDIR)\n-\tmkdir $@\n-\n-$(SHARED_OUTDIR)/util: | $(SHARED_OUTDIR)\n-\tmkdir $@\n-\n-.PHONY: SHARED_OBJDIRS\n-SHARED_OBJDIRS: \\\n-\t$(SHARED_OUTDIR)/db \\\n-\t$(SHARED_OUTDIR)/port \\\n-\t$(SHARED_OUTDIR)/table \\\n-\t$(SHARED_OUTDIR)/util \\\n-\t$(SHARED_OUTDIR)/helpers/memenv\n-\n-$(DEVICE_OUTDIR):\n-\tmkdir $@\n-\n-$(DEVICE_OUTDIR)/db: | $(DEVICE_OUTDIR)\n-\tmkdir $@\n-\n-$(DEVICE_OUTDIR)/helpers/memenv: | $(DEVICE_OUTDIR)\n-\tmkdir -p $@\n-\n-$(DEVICE_OUTDIR)/port: | $(DEVICE_OUTDIR)\n-\tmkdir $@\n-\n-$(DEVICE_OUTDIR)/table: | $(DEVICE_OUTDIR)\n-\tmkdir $@\n-\n-$(DEVICE_OUTDIR)/util: | $(DEVICE_OUTDIR)\n-\tmkdir $@\n-\n-.PHONY: DEVICE_OBJDIRS\n-DEVICE_OBJDIRS: \\\n-\t$(DEVICE_OUTDIR)/db \\\n-\t$(DEVICE_OUTDIR)/port \\\n-\t$(DEVICE_OUTDIR)/table \\\n-\t$(DEVICE_OUTDIR)/util \\\n-\t$(DEVICE_OUTDIR)/helpers/memenv\n-\n-$(SIMULATOR_OUTDIR):\n-\tmkdir $@\n-\n-$(SIMULATOR_OUTDIR)/db: | $(SIMULATOR_OUTDIR)\n-\tmkdir $@\n-\n-$(SIMULATOR_OUTDIR)/helpers/memenv: | $(SIMULATOR_OUTDIR)\n-\tmkdir -p $@\n-\n-$(SIMULATOR_OUTDIR)/port: | $(SIMULATOR_OUTDIR)\n-\tmkdir $@\n-\n-$(SIMULATOR_OUTDIR)/table: | $(SIMULATOR_OUTDIR)\n-\tmkdir $@\n-\n-$(SIMULATOR_OUTDIR)/util: | $(SIMULATOR_OUTDIR)\n-\tmkdir $@\n-\n-.PHONY: SIMULATOR_OBJDIRS\n-SIMULATOR_OBJDIRS: \\\n-\t$(SIMULATOR_OUTDIR)/db \\\n-\t$(SIMULATOR_OUTDIR)/port \\\n-\t$(SIMULATOR_OUTDIR)/table \\\n-\t$(SIMULATOR_OUTDIR)/util \\\n-\t$(SIMULATOR_OUTDIR)/helpers/memenv\n-\n-$(STATIC_ALLOBJS): | STATIC_OBJDIRS\n-$(DEVICE_ALLOBJS): | DEVICE_OBJDIRS\n-$(SIMULATOR_ALLOBJS): | SIMULATOR_OBJDIRS\n-$(SHARED_ALLOBJS): | SHARED_OBJDIRS\n-\n-ifeq ($(PLATFORM), IOS)\n-$(DEVICE_OUTDIR)/libleveldb.a: $(DEVICE_LIBOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(DEVICE_LIBOBJECTS)\n-\n-$(SIMULATOR_OUTDIR)/libleveldb.a: $(SIMULATOR_LIBOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(SIMULATOR_LIBOBJECTS)\n-\n-$(DEVICE_OUTDIR)/libmemenv.a: $(DEVICE_MEMENVOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(DEVICE_MEMENVOBJECTS)\n-\n-$(SIMULATOR_OUTDIR)/libmemenv.a: $(SIMULATOR_MEMENVOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(SIMULATOR_MEMENVOBJECTS)\n-\n-# For iOS, create universal object libraries to be used on both the simulator and\n-# a device.\n-$(STATIC_OUTDIR)/libleveldb.a: $(STATIC_OUTDIR) $(DEVICE_OUTDIR)/libleveldb.a $(SIMULATOR_OUTDIR)/libleveldb.a\n-\tlipo -create $(DEVICE_OUTDIR)/libleveldb.a $(SIMULATOR_OUTDIR)/libleveldb.a -output $@\n-\n-$(STATIC_OUTDIR)/libmemenv.a: $(STATIC_OUTDIR) $(DEVICE_OUTDIR)/libmemenv.a $(SIMULATOR_OUTDIR)/libmemenv.a\n-\tlipo -create $(DEVICE_OUTDIR)/libmemenv.a $(SIMULATOR_OUTDIR)/libmemenv.a -output $@\n-else\n-$(STATIC_OUTDIR)/libleveldb.a:$(STATIC_LIBOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(STATIC_LIBOBJECTS)\n-\n-$(STATIC_OUTDIR)/libmemenv.a:$(STATIC_MEMENVOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(STATIC_MEMENVOBJECTS)\n-endif\n-\n-$(SHARED_MEMENVLIB):$(SHARED_MEMENVOBJECTS)\n-\trm -f $@\n-\t$(AR) -rs $@ $(SHARED_MEMENVOBJECTS)\n-\n-$(STATIC_OUTDIR)/db_bench:db/db_bench.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/db_bench.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/db_bench_sqlite3:doc/bench/db_bench_sqlite3.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) doc/bench/db_bench_sqlite3.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ -lsqlite3 $(LIBS)\n-\n-$(STATIC_OUTDIR)/db_bench_tree_db:doc/bench/db_bench_tree_db.cc $(STATIC_LIBOBJECTS) $(TESTUTIL)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) doc/bench/db_bench_tree_db.cc $(STATIC_LIBOBJECTS) $(TESTUTIL) -o $@ -lkyotocabinet $(LIBS)\n-\n-$(STATIC_OUTDIR)/leveldbutil:db/leveldbutil.cc $(STATIC_LIBOBJECTS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/leveldbutil.cc $(STATIC_LIBOBJECTS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/arena_test:util/arena_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/arena_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/autocompact_test:db/autocompact_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/autocompact_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/bloom_test:util/bloom_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/bloom_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/c_test:$(STATIC_OUTDIR)/db/c_test.o $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(STATIC_OUTDIR)/db/c_test.o $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/cache_test:util/cache_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/cache_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/coding_test:util/coding_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/coding_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/corruption_test:db/corruption_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/corruption_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/crc32c_test:util/crc32c_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/crc32c_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/db_test:db/db_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/db_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/dbformat_test:db/dbformat_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/dbformat_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/env_posix_test:util/env_posix_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/env_posix_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/env_test:util/env_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/env_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/fault_injection_test:db/fault_injection_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/fault_injection_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/filename_test:db/filename_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/filename_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/filter_block_test:table/filter_block_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) table/filter_block_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/hash_test:util/hash_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) util/hash_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/issue178_test:issues/issue178_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) issues/issue178_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/issue200_test:issues/issue200_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) issues/issue200_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/log_test:db/log_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/log_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/recovery_test:db/recovery_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/recovery_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/table_test:table/table_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) table/table_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/skiplist_test:db/skiplist_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/skiplist_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/version_edit_test:db/version_edit_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/version_edit_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/version_set_test:db/version_set_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/version_set_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/write_batch_test:db/write_batch_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS)\n-\t$(CXX) $(LDFLAGS) $(CXXFLAGS) db/write_batch_test.cc $(STATIC_LIBOBJECTS) $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(STATIC_OUTDIR)/memenv_test:$(STATIC_OUTDIR)/helpers/memenv/memenv_test.o $(STATIC_OUTDIR)/libmemenv.a $(STATIC_OUTDIR)/libleveldb.a $(TESTHARNESS)\n-\t$(XCRUN) $(CXX) $(LDFLAGS) $(STATIC_OUTDIR)/helpers/memenv/memenv_test.o $(STATIC_OUTDIR)/libmemenv.a $(STATIC_OUTDIR)/libleveldb.a $(TESTHARNESS) -o $@ $(LIBS)\n-\n-$(SHARED_OUTDIR)/db_bench:$(SHARED_OUTDIR)/db/db_bench.o $(SHARED_LIBS) $(TESTUTIL)\n-\t$(XCRUN) $(CXX) $(LDFLAGS) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) $(SHARED_OUTDIR)/db/db_bench.o $(TESTUTIL) $(SHARED_OUTDIR)/$(SHARED_LIB3) -o $@ $(LIBS)\n-\n-.PHONY: run-shared\n-run-shared: $(SHARED_OUTDIR)/db_bench\n-\tLD_LIBRARY_PATH=$(SHARED_OUTDIR) $(SHARED_OUTDIR)/db_bench\n-\n-$(SIMULATOR_OUTDIR)/%.o: %.cc\n-\txcrun -sdk iphonesimulator $(CXX) $(CXXFLAGS) $(SIMULATOR_CFLAGS) -c $< -o $@\n-\n-$(DEVICE_OUTDIR)/%.o: %.cc\n-\txcrun -sdk iphoneos $(CXX) $(CXXFLAGS) $(DEVICE_CFLAGS) -c $< -o $@\n-\n-$(SIMULATOR_OUTDIR)/%.o: %.c\n-\txcrun -sdk iphonesimulator $(CC) $(CFLAGS) $(SIMULATOR_CFLAGS) -c $< -o $@\n-\n-$(DEVICE_OUTDIR)/%.o: %.c\n-\txcrun -sdk iphoneos $(CC) $(CFLAGS) $(DEVICE_CFLAGS) -c $< -o $@\n-\n-$(STATIC_OUTDIR)/%.o: %.cc\n-\t$(CXX) $(CXXFLAGS) -c $< -o $@\n-\n-$(STATIC_OUTDIR)/%.o: %.c\n-\t$(CC) $(CFLAGS) -c $< -o $@\n-\n-$(SHARED_OUTDIR)/%.o: %.cc\n-\t$(CXX) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) -c $< -o $@\n-\n-$(SHARED_OUTDIR)/%.o: %.c\n-\t$(CC) $(CFLAGS) $(PLATFORM_SHARED_CFLAGS) -c $< -o $@\n-\n-$(STATIC_OUTDIR)/port/port_posix_sse.o: port/port_posix_sse.cc\n-\t$(CXX) $(CXXFLAGS) $(PLATFORM_SSEFLAGS) -c $< -o $@\n-\n-$(SHARED_OUTDIR)/port/port_posix_sse.o: port/port_posix_sse.cc\n-\t$(CXX) $(CXXFLAGS) $(PLATFORM_SHARED_CFLAGS) $(PLATFORM_SSEFLAGS) -c $< -o $@"
      },
      {
        "sha": "dadfd5693ead7ad7656426fadbf2294c0189a040",
        "filename": "src/leveldb/README.md",
        "status": "modified",
        "additions": 69,
        "deletions": 18,
        "changes": 87,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/README.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/README.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/README.md?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -1,10 +1,12 @@\n **LevelDB is a fast key-value storage library written at Google that provides an ordered mapping from string keys to string values.**\n \n [![Build Status](https://travis-ci.org/google/leveldb.svg?branch=master)](https://travis-ci.org/google/leveldb)\n+[![Build status](https://ci.appveyor.com/api/projects/status/g2j5j4rfkda6eyw5/branch/master?svg=true)](https://ci.appveyor.com/project/pwnall/leveldb)\n \n Authors: Sanjay Ghemawat (sanjay@google.com) and Jeff Dean (jeff@google.com)\n \n # Features\n+\n   * Keys and values are arbitrary byte arrays.\n   * Data is stored sorted by key.\n   * Callers can provide a custom comparison function to override the sort order.\n@@ -16,26 +18,66 @@ Authors: Sanjay Ghemawat (sanjay@google.com) and Jeff Dean (jeff@google.com)\n   * External activity (file system operations etc.) is relayed through a virtual interface so users can customize the operating system interactions.\n \n # Documentation\n-  [LevelDB library documentation](https://github.com/google/leveldb/blob/master/doc/index.md) is online and bundled with the source code.\n \n+  [LevelDB library documentation](https://github.com/google/leveldb/blob/master/doc/index.md) is online and bundled with the source code.\n \n # Limitations\n+\n   * This is not a SQL database.  It does not have a relational data model, it does not support SQL queries, and it has no support for indexes.\n   * Only a single process (possibly multi-threaded) can access a particular database at a time.\n   * There is no client-server support builtin to the library.  An application that needs such support will have to wrap their own server around the library.\n \n+# Building\n+\n+This project supports [CMake](https://cmake.org/) out of the box.\n+\n+### Build for POSIX\n+\n+Quick start:\n+\n+```bash\n+mkdir -p build && cd build\n+cmake -DCMAKE_BUILD_TYPE=Release .. && cmake --build .\n+```\n+\n+### Building for Windows\n+\n+First generate the Visual Studio 2017 project/solution files:\n+\n+```cmd\n+mkdir build\n+cd build\n+cmake -G \"Visual Studio 15\" ..\n+```\n+The default default will build for x86. For 64-bit run:\n+\n+```cmd\n+cmake -G \"Visual Studio 15 Win64\" ..\n+```\n+\n+To compile the Windows solution from the command-line:\n+\n+```cmd\n+devenv /build Debug leveldb.sln\n+```\n+\n+or open leveldb.sln in Visual Studio and build from within.\n+\n+Please see the CMake documentation and `CMakeLists.txt` for more advanced usage.\n+\n # Contributing to the leveldb Project\n+\n The leveldb project welcomes contributions. leveldb's primary goal is to be\n a reliable and fast key/value store. Changes that are in line with the\n features/limitations outlined above, and meet the requirements below,\n will be considered.\n \n Contribution requirements:\n \n-1. **POSIX only**. We _generally_ will only accept changes that are both\n-   compiled, and tested on a POSIX platform - usually Linux. Very small\n-   changes will sometimes be accepted, but consider that more of an\n-   exception than the rule.\n+1. **Tested platforms only**. We _generally_ will only accept changes for\n+   platforms that are compiled and tested. This means POSIX (for Linux and\n+   macOS) or Windows. Very small changes will sometimes be accepted, but\n+   consider that more of an exception than the rule.\n \n 2. **Stable API**. We strive very hard to maintain a stable API. Changes that\n    require changes for projects using leveldb _might_ be rejected without\n@@ -44,7 +86,16 @@ Contribution requirements:\n 3. **Tests**: All changes must be accompanied by a new (or changed) test, or\n    a sufficient explanation as to why a new (or changed) test is not required.\n \n+4. **Consistent Style**: This project conforms to the\n+   [Google C++ Style Guide](https://google.github.io/styleguide/cppguide.html).\n+   To ensure your changes are properly formatted please run:\n+\n+   ```\n+   clang-format -i --style=file <file>\n+   ```\n+\n ## Submitting a Pull Request\n+\n Before any pull request will be accepted the author must first sign a\n Contributor License Agreement (CLA) at https://cla.developers.google.com/.\n \n@@ -138,37 +189,37 @@ uncompressed blocks in memory, the read performance improves again:\n See [doc/index.md](doc/index.md) for more explanation. See\n [doc/impl.md](doc/impl.md) for a brief overview of the implementation.\n \n-The public interface is in include/*.h.  Callers should not include or\n+The public interface is in include/leveldb/*.h.  Callers should not include or\n rely on the details of any other header files in this package.  Those\n internal APIs may be changed without warning.\n \n Guide to header files:\n \n-* **include/db.h**: Main interface to the DB: Start here\n+* **include/leveldb/db.h**: Main interface to the DB: Start here.\n \n-* **include/options.h**: Control over the behavior of an entire database,\n+* **include/leveldb/options.h**: Control over the behavior of an entire database,\n and also control over the behavior of individual reads and writes.\n \n-* **include/comparator.h**: Abstraction for user-specified comparison function.\n+* **include/leveldb/comparator.h**: Abstraction for user-specified comparison function.\n If you want just bytewise comparison of keys, you can use the default\n comparator, but clients can write their own comparator implementations if they\n-want custom ordering (e.g. to handle different character encodings, etc.)\n+want custom ordering (e.g. to handle different character encodings, etc.).\n \n-* **include/iterator.h**: Interface for iterating over data. You can get\n+* **include/leveldb/iterator.h**: Interface for iterating over data. You can get\n an iterator from a DB object.\n \n-* **include/write_batch.h**: Interface for atomically applying multiple\n+* **include/leveldb/write_batch.h**: Interface for atomically applying multiple\n updates to a database.\n \n-* **include/slice.h**: A simple module for maintaining a pointer and a\n+* **include/leveldb/slice.h**: A simple module for maintaining a pointer and a\n length into some other byte array.\n \n-* **include/status.h**: Status is returned from many of the public interfaces\n+* **include/leveldb/status.h**: Status is returned from many of the public interfaces\n and is used to report success and various kinds of errors.\n \n-* **include/env.h**:\n+* **include/leveldb/env.h**:\n Abstraction of the OS environment.  A posix implementation of this interface is\n-in util/env_posix.cc\n+in util/env_posix.cc.\n \n-* **include/table.h, include/table_builder.h**: Lower-level modules that most\n-clients probably won't use directly\n+* **include/leveldb/table.h, include/leveldb/table_builder.h**: Lower-level modules that most\n+clients probably won't use directly."
      },
      {
        "sha": "5b76c2448fe1e475b97d12235bdff53b857557cf",
        "filename": "src/leveldb/WINDOWS.md",
        "status": "removed",
        "additions": 0,
        "deletions": 39,
        "changes": 39,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/WINDOWS.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/WINDOWS.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/WINDOWS.md?ref=2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "patch": "@@ -1,39 +0,0 @@\n-# Building LevelDB On Windows\n-\n-## Prereqs \n-\n-Install the [Windows Software Development Kit version 7.1](http://www.microsoft.com/downloads/dlx/en-us/listdetailsview.aspx?FamilyID=6b6c21d2-2006-4afa-9702-529fa782d63b).\n-\n-Download and extract the [Snappy source distribution](http://snappy.googlecode.com/files/snappy-1.0.5.tar.gz)\n-\n-1. Open the \"Windows SDK 7.1 Command Prompt\" :\n-   Start Menu -> \"Microsoft Windows SDK v7.1\" > \"Windows SDK 7.1 Command Prompt\"\n-2. Change the directory to the leveldb project\n-\n-## Building the Static lib \n-\n-* 32 bit Version \n-\n-        setenv /x86\n-        msbuild.exe /p:Configuration=Release /p:Platform=Win32 /p:Snappy=..\\snappy-1.0.5\n-\n-* 64 bit Version \n-\n-        setenv /x64\n-        msbuild.exe /p:Configuration=Release /p:Platform=x64 /p:Snappy=..\\snappy-1.0.5\n-\n-\n-## Building and Running the Benchmark app\n-\n-* 32 bit Version \n-\n-\t    setenv /x86\n-\t    msbuild.exe /p:Configuration=Benchmark /p:Platform=Win32 /p:Snappy=..\\snappy-1.0.5\n-\t\tBenchmark\\leveldb.exe\n-\n-* 64 bit Version \n-\n-\t    setenv /x64\n-\t    msbuild.exe /p:Configuration=Benchmark /p:Platform=x64 /p:Snappy=..\\snappy-1.0.5\n-\t    x64\\Benchmark\\leveldb.exe\n-"
      },
      {
        "sha": "3696023b702f68c81b6d121e1769a39281cdc7d8",
        "filename": "src/leveldb/benchmarks/db_bench.cc",
        "status": "renamed",
        "additions": 82,
        "deletions": 121,
        "changes": 203,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/benchmarks/db_bench.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/benchmarks/db_bench.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/benchmarks/db_bench.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -2,14 +2,14 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include <sys/types.h>\n #include <stdio.h>\n #include <stdlib.h>\n-#include \"db/db_impl.h\"\n-#include \"db/version_set.h\"\n+#include <sys/types.h>\n+\n #include \"leveldb/cache.h\"\n #include \"leveldb/db.h\"\n #include \"leveldb/env.h\"\n+#include \"leveldb/filter_policy.h\"\n #include \"leveldb/write_batch.h\"\n #include \"port/port.h\"\n #include \"util/crc32c.h\"\n@@ -35,7 +35,6 @@\n //      seekrandom    -- N random seeks\n //      open          -- cost of opening a DB\n //      crc32c        -- repeated crc32c of 4K of data\n-//      acquireload   -- load N*1000 times\n //   Meta operations:\n //      compact     -- Compact the entire DB\n //      stats       -- Print DB stats\n@@ -57,9 +56,7 @@ static const char* FLAGS_benchmarks =\n     \"fill100K,\"\n     \"crc32c,\"\n     \"snappycomp,\"\n-    \"snappyuncomp,\"\n-    \"acquireload,\"\n-    ;\n+    \"snappyuncomp,\";\n \n // Number of key/values to place in database\n static int FLAGS_num = 1000000;\n@@ -112,12 +109,12 @@ static bool FLAGS_use_existing_db = false;\n static bool FLAGS_reuse_logs = false;\n \n // Use the db with the following name.\n-static const char* FLAGS_db = NULL;\n+static const char* FLAGS_db = nullptr;\n \n namespace leveldb {\n \n namespace {\n-leveldb::Env* g_env = NULL;\n+leveldb::Env* g_env = nullptr;\n \n // Helper for quickly generating random data.\n class RandomGenerator {\n@@ -158,7 +155,7 @@ static Slice TrimSpace(Slice s) {\n     start++;\n   }\n   size_t limit = s.size();\n-  while (limit > start && isspace(s[limit-1])) {\n+  while (limit > start && isspace(s[limit - 1])) {\n     limit--;\n   }\n   return Slice(s.data() + start, limit - start);\n@@ -190,14 +187,12 @@ class Stats {\n \n   void Start() {\n     next_report_ = 100;\n-    last_op_finish_ = start_;\n     hist_.Clear();\n     done_ = 0;\n     bytes_ = 0;\n     seconds_ = 0;\n-    start_ = g_env->NowMicros();\n-    finish_ = start_;\n     message_.clear();\n+    start_ = finish_ = last_op_finish_ = g_env->NowMicros();\n   }\n \n   void Merge(const Stats& other) {\n@@ -217,9 +212,7 @@ class Stats {\n     seconds_ = (finish_ - start_) * 1e-6;\n   }\n \n-  void AddMessage(Slice msg) {\n-    AppendWithSpace(&message_, msg);\n-  }\n+  void AddMessage(Slice msg) { AppendWithSpace(&message_, msg); }\n \n   void FinishedSingleOp() {\n     if (FLAGS_histogram) {\n@@ -235,21 +228,26 @@ class Stats {\n \n     done_++;\n     if (done_ >= next_report_) {\n-      if      (next_report_ < 1000)   next_report_ += 100;\n-      else if (next_report_ < 5000)   next_report_ += 500;\n-      else if (next_report_ < 10000)  next_report_ += 1000;\n-      else if (next_report_ < 50000)  next_report_ += 5000;\n-      else if (next_report_ < 100000) next_report_ += 10000;\n-      else if (next_report_ < 500000) next_report_ += 50000;\n-      else                            next_report_ += 100000;\n+      if (next_report_ < 1000)\n+        next_report_ += 100;\n+      else if (next_report_ < 5000)\n+        next_report_ += 500;\n+      else if (next_report_ < 10000)\n+        next_report_ += 1000;\n+      else if (next_report_ < 50000)\n+        next_report_ += 5000;\n+      else if (next_report_ < 100000)\n+        next_report_ += 10000;\n+      else if (next_report_ < 500000)\n+        next_report_ += 50000;\n+      else\n+        next_report_ += 100000;\n       fprintf(stderr, \"... finished %d ops%30s\\r\", done_, \"\");\n       fflush(stderr);\n     }\n   }\n \n-  void AddBytes(int64_t n) {\n-    bytes_ += n;\n-  }\n+  void AddBytes(int64_t n) { bytes_ += n; }\n \n   void Report(const Slice& name) {\n     // Pretend at least one op was done in case we are running a benchmark\n@@ -268,11 +266,8 @@ class Stats {\n     }\n     AppendWithSpace(&extra, message_);\n \n-    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\",\n-            name.ToString().c_str(),\n-            seconds_ * 1e6 / done_,\n-            (extra.empty() ? \"\" : \" \"),\n-            extra.c_str());\n+    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\", name.ToString().c_str(),\n+            seconds_ * 1e6 / done_, (extra.empty() ? \"\" : \" \"), extra.c_str());\n     if (FLAGS_histogram) {\n       fprintf(stdout, \"Microseconds per op:\\n%s\\n\", hist_.ToString().c_str());\n     }\n@@ -283,33 +278,31 @@ class Stats {\n // State shared by all concurrent executions of the same benchmark.\n struct SharedState {\n   port::Mutex mu;\n-  port::CondVar cv;\n-  int total;\n+  port::CondVar cv GUARDED_BY(mu);\n+  int total GUARDED_BY(mu);\n \n   // Each thread goes through the following states:\n   //    (1) initializing\n   //    (2) waiting for others to be initialized\n   //    (3) running\n   //    (4) done\n \n-  int num_initialized;\n-  int num_done;\n-  bool start;\n+  int num_initialized GUARDED_BY(mu);\n+  int num_done GUARDED_BY(mu);\n+  bool start GUARDED_BY(mu);\n \n-  SharedState() : cv(&mu) { }\n+  SharedState(int total)\n+      : cv(&mu), total(total), num_initialized(0), num_done(0), start(false) {}\n };\n \n // Per-thread state for concurrent executions of the same benchmark.\n struct ThreadState {\n-  int tid;             // 0..n-1 when running in n threads\n-  Random rand;         // Has different seeds for different threads\n+  int tid;      // 0..n-1 when running in n threads\n+  Random rand;  // Has different seeds for different threads\n   Stats stats;\n   SharedState* shared;\n \n-  ThreadState(int index)\n-      : tid(index),\n-        rand(1000 + index) {\n-  }\n+  ThreadState(int index) : tid(index), rand(1000 + index), shared(nullptr) {}\n };\n \n }  // namespace\n@@ -335,20 +328,20 @@ class Benchmark {\n             static_cast<int>(FLAGS_value_size * FLAGS_compression_ratio + 0.5));\n     fprintf(stdout, \"Entries:    %d\\n\", num_);\n     fprintf(stdout, \"RawSize:    %.1f MB (estimated)\\n\",\n-            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_)\n-             / 1048576.0));\n+            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_) /\n+             1048576.0));\n     fprintf(stdout, \"FileSize:   %.1f MB (estimated)\\n\",\n-            (((kKeySize + FLAGS_value_size * FLAGS_compression_ratio) * num_)\n-             / 1048576.0));\n+            (((kKeySize + FLAGS_value_size * FLAGS_compression_ratio) * num_) /\n+             1048576.0));\n     PrintWarnings();\n     fprintf(stdout, \"------------------------------------------------\\n\");\n   }\n \n   void PrintWarnings() {\n #if defined(__GNUC__) && !defined(__OPTIMIZE__)\n-    fprintf(stdout,\n-            \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\"\n-            );\n+    fprintf(\n+        stdout,\n+        \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\");\n #endif\n #ifndef NDEBUG\n     fprintf(stdout,\n@@ -366,22 +359,22 @@ class Benchmark {\n   }\n \n   void PrintEnvironment() {\n-    fprintf(stderr, \"LevelDB:    version %d.%d\\n\",\n-            kMajorVersion, kMinorVersion);\n+    fprintf(stderr, \"LevelDB:    version %d.%d\\n\", kMajorVersion,\n+            kMinorVersion);\n \n #if defined(__linux)\n-    time_t now = time(NULL);\n+    time_t now = time(nullptr);\n     fprintf(stderr, \"Date:       %s\", ctime(&now));  // ctime() adds newline\n \n     FILE* cpuinfo = fopen(\"/proc/cpuinfo\", \"r\");\n-    if (cpuinfo != NULL) {\n+    if (cpuinfo != nullptr) {\n       char line[1000];\n       int num_cpus = 0;\n       std::string cpu_type;\n       std::string cache_size;\n-      while (fgets(line, sizeof(line), cpuinfo) != NULL) {\n+      while (fgets(line, sizeof(line), cpuinfo) != nullptr) {\n         const char* sep = strchr(line, ':');\n-        if (sep == NULL) {\n+        if (sep == nullptr) {\n           continue;\n         }\n         Slice key = TrimSpace(Slice(line, sep - 1 - line));\n@@ -402,16 +395,16 @@ class Benchmark {\n \n  public:\n   Benchmark()\n-  : cache_(FLAGS_cache_size >= 0 ? NewLRUCache(FLAGS_cache_size) : NULL),\n-    filter_policy_(FLAGS_bloom_bits >= 0\n-                   ? NewBloomFilterPolicy(FLAGS_bloom_bits)\n-                   : NULL),\n-    db_(NULL),\n-    num_(FLAGS_num),\n-    value_size_(FLAGS_value_size),\n-    entries_per_batch_(1),\n-    reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n-    heap_counter_(0) {\n+      : cache_(FLAGS_cache_size >= 0 ? NewLRUCache(FLAGS_cache_size) : nullptr),\n+        filter_policy_(FLAGS_bloom_bits >= 0\n+                           ? NewBloomFilterPolicy(FLAGS_bloom_bits)\n+                           : nullptr),\n+        db_(nullptr),\n+        num_(FLAGS_num),\n+        value_size_(FLAGS_value_size),\n+        entries_per_batch_(1),\n+        reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n+        heap_counter_(0) {\n     std::vector<std::string> files;\n     g_env->GetChildren(FLAGS_db, &files);\n     for (size_t i = 0; i < files.size(); i++) {\n@@ -435,12 +428,12 @@ class Benchmark {\n     Open();\n \n     const char* benchmarks = FLAGS_benchmarks;\n-    while (benchmarks != NULL) {\n+    while (benchmarks != nullptr) {\n       const char* sep = strchr(benchmarks, ',');\n       Slice name;\n-      if (sep == NULL) {\n+      if (sep == nullptr) {\n         name = benchmarks;\n-        benchmarks = NULL;\n+        benchmarks = nullptr;\n       } else {\n         name = Slice(benchmarks, sep - benchmarks);\n         benchmarks = sep + 1;\n@@ -453,7 +446,7 @@ class Benchmark {\n       entries_per_batch_ = 1;\n       write_options_ = WriteOptions();\n \n-      void (Benchmark::*method)(ThreadState*) = NULL;\n+      void (Benchmark::*method)(ThreadState*) = nullptr;\n       bool fresh_db = false;\n       int num_threads = FLAGS_threads;\n \n@@ -510,8 +503,6 @@ class Benchmark {\n         method = &Benchmark::Compact;\n       } else if (name == Slice(\"crc32c\")) {\n         method = &Benchmark::Crc32c;\n-      } else if (name == Slice(\"acquireload\")) {\n-        method = &Benchmark::AcquireLoad;\n       } else if (name == Slice(\"snappycomp\")) {\n         method = &Benchmark::SnappyCompress;\n       } else if (name == Slice(\"snappyuncomp\")) {\n@@ -523,7 +514,7 @@ class Benchmark {\n       } else if (name == Slice(\"sstables\")) {\n         PrintStats(\"leveldb.sstables\");\n       } else {\n-        if (name != Slice()) {  // No error message for empty name\n+        if (!name.empty()) {  // No error message for empty name\n           fprintf(stderr, \"unknown benchmark '%s'\\n\", name.ToString().c_str());\n         }\n       }\n@@ -532,16 +523,16 @@ class Benchmark {\n         if (FLAGS_use_existing_db) {\n           fprintf(stdout, \"%-12s : skipped (--use_existing_db is true)\\n\",\n                   name.ToString().c_str());\n-          method = NULL;\n+          method = nullptr;\n         } else {\n           delete db_;\n-          db_ = NULL;\n+          db_ = nullptr;\n           DestroyDB(FLAGS_db, Options());\n           Open();\n         }\n       }\n \n-      if (method != NULL) {\n+      if (method != nullptr) {\n         RunBenchmark(num_threads, name, method);\n       }\n     }\n@@ -585,11 +576,7 @@ class Benchmark {\n \n   void RunBenchmark(int n, Slice name,\n                     void (Benchmark::*method)(ThreadState*)) {\n-    SharedState shared;\n-    shared.total = n;\n-    shared.num_initialized = 0;\n-    shared.num_done = 0;\n-    shared.start = false;\n+    SharedState shared(n);\n \n     ThreadArg* arg = new ThreadArg[n];\n     for (int i = 0; i < n; i++) {\n@@ -643,22 +630,6 @@ class Benchmark {\n     thread->stats.AddMessage(label);\n   }\n \n-  void AcquireLoad(ThreadState* thread) {\n-    int dummy;\n-    port::AtomicPointer ap(&dummy);\n-    int count = 0;\n-    void *ptr = NULL;\n-    thread->stats.AddMessage(\"(each op is 1000 loads)\");\n-    while (count < 100000) {\n-      for (int i = 0; i < 1000; i++) {\n-        ptr = ap.Acquire_Load();\n-      }\n-      count++;\n-      thread->stats.FinishedSingleOp();\n-    }\n-    if (ptr == NULL) exit(1); // Disable unused variable warning.\n-  }\n-\n   void SnappyCompress(ThreadState* thread) {\n     RandomGenerator gen;\n     Slice input = gen.Generate(Options().block_size);\n@@ -692,8 +663,8 @@ class Benchmark {\n     int64_t bytes = 0;\n     char* uncompressed = new char[input.size()];\n     while (ok && bytes < 1024 * 1048576) {  // Compress 1G\n-      ok =  port::Snappy_Uncompress(compressed.data(), compressed.size(),\n-                                    uncompressed);\n+      ok = port::Snappy_Uncompress(compressed.data(), compressed.size(),\n+                                   uncompressed);\n       bytes += input.size();\n       thread->stats.FinishedSingleOp();\n     }\n@@ -707,7 +678,7 @@ class Benchmark {\n   }\n \n   void Open() {\n-    assert(db_ == NULL);\n+    assert(db_ == nullptr);\n     Options options;\n     options.env = g_env;\n     options.create_if_missing = !FLAGS_use_existing_db;\n@@ -733,13 +704,9 @@ class Benchmark {\n     }\n   }\n \n-  void WriteSeq(ThreadState* thread) {\n-    DoWrite(thread, true);\n-  }\n+  void WriteSeq(ThreadState* thread) { DoWrite(thread, true); }\n \n-  void WriteRandom(ThreadState* thread) {\n-    DoWrite(thread, false);\n-  }\n+  void WriteRandom(ThreadState* thread) { DoWrite(thread, false); }\n \n   void DoWrite(ThreadState* thread, bool seq) {\n     if (num_ != FLAGS_num) {\n@@ -755,7 +722,7 @@ class Benchmark {\n     for (int i = 0; i < num_; i += entries_per_batch_) {\n       batch.Clear();\n       for (int j = 0; j < entries_per_batch_; j++) {\n-        const int k = seq ? i+j : (thread->rand.Next() % FLAGS_num);\n+        const int k = seq ? i + j : (thread->rand.Next() % FLAGS_num);\n         char key[100];\n         snprintf(key, sizeof(key), \"%016d\", k);\n         batch.Put(key, gen.Generate(value_size_));\n@@ -865,7 +832,7 @@ class Benchmark {\n     for (int i = 0; i < num_; i += entries_per_batch_) {\n       batch.Clear();\n       for (int j = 0; j < entries_per_batch_; j++) {\n-        const int k = seq ? i+j : (thread->rand.Next() % FLAGS_num);\n+        const int k = seq ? i + j : (thread->rand.Next() % FLAGS_num);\n         char key[100];\n         snprintf(key, sizeof(key), \"%016d\", k);\n         batch.Delete(key);\n@@ -879,13 +846,9 @@ class Benchmark {\n     }\n   }\n \n-  void DeleteSeq(ThreadState* thread) {\n-    DoDelete(thread, true);\n-  }\n+  void DeleteSeq(ThreadState* thread) { DoDelete(thread, true); }\n \n-  void DeleteRandom(ThreadState* thread) {\n-    DoDelete(thread, false);\n-  }\n+  void DeleteRandom(ThreadState* thread) { DoDelete(thread, false); }\n \n   void ReadWhileWriting(ThreadState* thread) {\n     if (thread->tid > 0) {\n@@ -917,9 +880,7 @@ class Benchmark {\n     }\n   }\n \n-  void Compact(ThreadState* thread) {\n-    db_->CompactRange(NULL, NULL);\n-  }\n+  void Compact(ThreadState* thread) { db_->CompactRange(nullptr, nullptr); }\n \n   void PrintStats(const char* key) {\n     std::string stats;\n@@ -1008,10 +969,10 @@ int main(int argc, char** argv) {\n   leveldb::g_env = leveldb::Env::Default();\n \n   // Choose a location for the test database if none given with --db=<path>\n-  if (FLAGS_db == NULL) {\n-      leveldb::g_env->GetTestDirectory(&default_db_path);\n-      default_db_path += \"/dbbench\";\n-      FLAGS_db = default_db_path.c_str();\n+  if (FLAGS_db == nullptr) {\n+    leveldb::g_env->GetTestDirectory(&default_db_path);\n+    default_db_path += \"/dbbench\";\n+    FLAGS_db = default_db_path.c_str();\n   }\n \n   leveldb::Benchmark benchmark;",
        "previous_filename": "src/leveldb/db/db_bench.cc"
      },
      {
        "sha": "f183f4fcfdf480186207efc0cee062f86ba5ced8",
        "filename": "src/leveldb/benchmarks/db_bench_sqlite3.cc",
        "status": "renamed",
        "additions": 90,
        "deletions": 94,
        "changes": 184,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/benchmarks/db_bench_sqlite3.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/benchmarks/db_bench_sqlite3.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/benchmarks/db_bench_sqlite3.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -2,9 +2,10 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n+#include <sqlite3.h>\n #include <stdio.h>\n #include <stdlib.h>\n-#include <sqlite3.h>\n+\n #include \"util/histogram.h\"\n #include \"util/random.h\"\n #include \"util/testutil.h\"\n@@ -38,8 +39,7 @@ static const char* FLAGS_benchmarks =\n     \"fillrand100K,\"\n     \"fillseq100K,\"\n     \"readseq,\"\n-    \"readrand100K,\"\n-    ;\n+    \"readrand100K,\";\n \n // Number of key/values to place in database\n static int FLAGS_num = 1000000;\n@@ -76,38 +76,35 @@ static bool FLAGS_transaction = true;\n static bool FLAGS_WAL_enabled = true;\n \n // Use the db with the following name.\n-static const char* FLAGS_db = NULL;\n+static const char* FLAGS_db = nullptr;\n \n-inline\n-static void ExecErrorCheck(int status, char *err_msg) {\n+inline static void ExecErrorCheck(int status, char* err_msg) {\n   if (status != SQLITE_OK) {\n     fprintf(stderr, \"SQL error: %s\\n\", err_msg);\n     sqlite3_free(err_msg);\n     exit(1);\n   }\n }\n \n-inline\n-static void StepErrorCheck(int status) {\n+inline static void StepErrorCheck(int status) {\n   if (status != SQLITE_DONE) {\n     fprintf(stderr, \"SQL step error: status = %d\\n\", status);\n     exit(1);\n   }\n }\n \n-inline\n-static void ErrorCheck(int status) {\n+inline static void ErrorCheck(int status) {\n   if (status != SQLITE_OK) {\n     fprintf(stderr, \"sqlite3 error: status = %d\\n\", status);\n     exit(1);\n   }\n }\n \n-inline\n-static void WalCheckpoint(sqlite3* db_) {\n+inline static void WalCheckpoint(sqlite3* db_) {\n   // Flush all writes to disk\n   if (FLAGS_WAL_enabled) {\n-    sqlite3_wal_checkpoint_v2(db_, NULL, SQLITE_CHECKPOINT_FULL, NULL, NULL);\n+    sqlite3_wal_checkpoint_v2(db_, nullptr, SQLITE_CHECKPOINT_FULL, nullptr,\n+                              nullptr);\n   }\n }\n \n@@ -152,7 +149,7 @@ static Slice TrimSpace(Slice s) {\n     start++;\n   }\n   int limit = s.size();\n-  while (limit > start && isspace(s[limit-1])) {\n+  while (limit > start && isspace(s[limit - 1])) {\n     limit--;\n   }\n   return Slice(s.data() + start, limit - start);\n@@ -176,7 +173,7 @@ class Benchmark {\n \n   // State kept for progress messages\n   int done_;\n-  int next_report_;     // When to report next\n+  int next_report_;  // When to report next\n \n   void PrintHeader() {\n     const int kKeySize = 16;\n@@ -185,17 +182,17 @@ class Benchmark {\n     fprintf(stdout, \"Values:     %d bytes each\\n\", FLAGS_value_size);\n     fprintf(stdout, \"Entries:    %d\\n\", num_);\n     fprintf(stdout, \"RawSize:    %.1f MB (estimated)\\n\",\n-            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_)\n-             / 1048576.0));\n+            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_) /\n+             1048576.0));\n     PrintWarnings();\n     fprintf(stdout, \"------------------------------------------------\\n\");\n   }\n \n   void PrintWarnings() {\n #if defined(__GNUC__) && !defined(__OPTIMIZE__)\n-    fprintf(stdout,\n-            \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\"\n-            );\n+    fprintf(\n+        stdout,\n+        \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\");\n #endif\n #ifndef NDEBUG\n     fprintf(stdout,\n@@ -207,18 +204,18 @@ class Benchmark {\n     fprintf(stderr, \"SQLite:     version %s\\n\", SQLITE_VERSION);\n \n #if defined(__linux)\n-    time_t now = time(NULL);\n+    time_t now = time(nullptr);\n     fprintf(stderr, \"Date:       %s\", ctime(&now));  // ctime() adds newline\n \n     FILE* cpuinfo = fopen(\"/proc/cpuinfo\", \"r\");\n-    if (cpuinfo != NULL) {\n+    if (cpuinfo != nullptr) {\n       char line[1000];\n       int num_cpus = 0;\n       std::string cpu_type;\n       std::string cache_size;\n-      while (fgets(line, sizeof(line), cpuinfo) != NULL) {\n+      while (fgets(line, sizeof(line), cpuinfo) != nullptr) {\n         const char* sep = strchr(line, ':');\n-        if (sep == NULL) {\n+        if (sep == nullptr) {\n           continue;\n         }\n         Slice key = TrimSpace(Slice(line, sep - 1 - line));\n@@ -261,13 +258,20 @@ class Benchmark {\n \n     done_++;\n     if (done_ >= next_report_) {\n-      if      (next_report_ < 1000)   next_report_ += 100;\n-      else if (next_report_ < 5000)   next_report_ += 500;\n-      else if (next_report_ < 10000)  next_report_ += 1000;\n-      else if (next_report_ < 50000)  next_report_ += 5000;\n-      else if (next_report_ < 100000) next_report_ += 10000;\n-      else if (next_report_ < 500000) next_report_ += 50000;\n-      else                            next_report_ += 100000;\n+      if (next_report_ < 1000)\n+        next_report_ += 100;\n+      else if (next_report_ < 5000)\n+        next_report_ += 500;\n+      else if (next_report_ < 10000)\n+        next_report_ += 1000;\n+      else if (next_report_ < 50000)\n+        next_report_ += 5000;\n+      else if (next_report_ < 100000)\n+        next_report_ += 10000;\n+      else if (next_report_ < 500000)\n+        next_report_ += 50000;\n+      else\n+        next_report_ += 100000;\n       fprintf(stderr, \"... finished %d ops%30s\\r\", done_, \"\");\n       fflush(stderr);\n     }\n@@ -285,16 +289,14 @@ class Benchmark {\n       snprintf(rate, sizeof(rate), \"%6.1f MB/s\",\n                (bytes_ / 1048576.0) / (finish - start_));\n       if (!message_.empty()) {\n-        message_  = std::string(rate) + \" \" + message_;\n+        message_ = std::string(rate) + \" \" + message_;\n       } else {\n         message_ = rate;\n       }\n     }\n \n-    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\",\n-            name.ToString().c_str(),\n-            (finish - start_) * 1e6 / done_,\n-            (message_.empty() ? \"\" : \" \"),\n+    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\", name.ToString().c_str(),\n+            (finish - start_) * 1e6 / done_, (message_.empty() ? \"\" : \" \"),\n             message_.c_str());\n     if (FLAGS_histogram) {\n       fprintf(stdout, \"Microseconds per op:\\n%s\\n\", hist_.ToString().c_str());\n@@ -303,22 +305,16 @@ class Benchmark {\n   }\n \n  public:\n-  enum Order {\n-    SEQUENTIAL,\n-    RANDOM\n-  };\n-  enum DBState {\n-    FRESH,\n-    EXISTING\n-  };\n+  enum Order { SEQUENTIAL, RANDOM };\n+  enum DBState { FRESH, EXISTING };\n \n   Benchmark()\n-  : db_(NULL),\n-    db_num_(0),\n-    num_(FLAGS_num),\n-    reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n-    bytes_(0),\n-    rand_(301) {\n+      : db_(nullptr),\n+        db_num_(0),\n+        num_(FLAGS_num),\n+        reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n+        bytes_(0),\n+        rand_(301) {\n     std::vector<std::string> files;\n     std::string test_dir;\n     Env::Default()->GetTestDirectory(&test_dir);\n@@ -345,12 +341,12 @@ class Benchmark {\n     Open();\n \n     const char* benchmarks = FLAGS_benchmarks;\n-    while (benchmarks != NULL) {\n+    while (benchmarks != nullptr) {\n       const char* sep = strchr(benchmarks, ',');\n       Slice name;\n-      if (sep == NULL) {\n+      if (sep == nullptr) {\n         name = benchmarks;\n-        benchmarks = NULL;\n+        benchmarks = nullptr;\n       } else {\n         name = Slice(benchmarks, sep - benchmarks);\n         benchmarks = sep + 1;\n@@ -415,20 +411,18 @@ class Benchmark {\n   }\n \n   void Open() {\n-    assert(db_ == NULL);\n+    assert(db_ == nullptr);\n \n     int status;\n     char file_name[100];\n-    char* err_msg = NULL;\n+    char* err_msg = nullptr;\n     db_num_++;\n \n     // Open database\n     std::string tmp_dir;\n     Env::Default()->GetTestDirectory(&tmp_dir);\n-    snprintf(file_name, sizeof(file_name),\n-             \"%s/dbbench_sqlite3-%d.db\",\n-             tmp_dir.c_str(),\n-             db_num_);\n+    snprintf(file_name, sizeof(file_name), \"%s/dbbench_sqlite3-%d.db\",\n+             tmp_dir.c_str(), db_num_);\n     status = sqlite3_open(file_name, &db_);\n     if (status) {\n       fprintf(stderr, \"open error: %s\\n\", sqlite3_errmsg(db_));\n@@ -439,15 +433,15 @@ class Benchmark {\n     char cache_size[100];\n     snprintf(cache_size, sizeof(cache_size), \"PRAGMA cache_size = %d\",\n              FLAGS_num_pages);\n-    status = sqlite3_exec(db_, cache_size, NULL, NULL, &err_msg);\n+    status = sqlite3_exec(db_, cache_size, nullptr, nullptr, &err_msg);\n     ExecErrorCheck(status, err_msg);\n \n     // FLAGS_page_size is defaulted to 1024\n     if (FLAGS_page_size != 1024) {\n       char page_size[100];\n       snprintf(page_size, sizeof(page_size), \"PRAGMA page_size = %d\",\n                FLAGS_page_size);\n-      status = sqlite3_exec(db_, page_size, NULL, NULL, &err_msg);\n+      status = sqlite3_exec(db_, page_size, nullptr, nullptr, &err_msg);\n       ExecErrorCheck(status, err_msg);\n     }\n \n@@ -457,34 +451,36 @@ class Benchmark {\n \n       // LevelDB's default cache size is a combined 4 MB\n       std::string WAL_checkpoint = \"PRAGMA wal_autocheckpoint = 4096\";\n-      status = sqlite3_exec(db_, WAL_stmt.c_str(), NULL, NULL, &err_msg);\n+      status = sqlite3_exec(db_, WAL_stmt.c_str(), nullptr, nullptr, &err_msg);\n       ExecErrorCheck(status, err_msg);\n-      status = sqlite3_exec(db_, WAL_checkpoint.c_str(), NULL, NULL, &err_msg);\n+      status =\n+          sqlite3_exec(db_, WAL_checkpoint.c_str(), nullptr, nullptr, &err_msg);\n       ExecErrorCheck(status, err_msg);\n     }\n \n     // Change locking mode to exclusive and create tables/index for database\n     std::string locking_stmt = \"PRAGMA locking_mode = EXCLUSIVE\";\n     std::string create_stmt =\n-          \"CREATE TABLE test (key blob, value blob, PRIMARY KEY(key))\";\n-    std::string stmt_array[] = { locking_stmt, create_stmt };\n+        \"CREATE TABLE test (key blob, value blob, PRIMARY KEY(key))\";\n+    std::string stmt_array[] = {locking_stmt, create_stmt};\n     int stmt_array_length = sizeof(stmt_array) / sizeof(std::string);\n     for (int i = 0; i < stmt_array_length; i++) {\n-      status = sqlite3_exec(db_, stmt_array[i].c_str(), NULL, NULL, &err_msg);\n+      status =\n+          sqlite3_exec(db_, stmt_array[i].c_str(), nullptr, nullptr, &err_msg);\n       ExecErrorCheck(status, err_msg);\n     }\n   }\n \n-  void Write(bool write_sync, Order order, DBState state,\n-             int num_entries, int value_size, int entries_per_batch) {\n+  void Write(bool write_sync, Order order, DBState state, int num_entries,\n+             int value_size, int entries_per_batch) {\n     // Create new database if state == FRESH\n     if (state == FRESH) {\n       if (FLAGS_use_existing_db) {\n         message_ = \"skipping (--use_existing_db is true)\";\n         return;\n       }\n       sqlite3_close(db_);\n-      db_ = NULL;\n+      db_ = nullptr;\n       Open();\n       Start();\n     }\n@@ -495,7 +491,7 @@ class Benchmark {\n       message_ = msg;\n     }\n \n-    char* err_msg = NULL;\n+    char* err_msg = nullptr;\n     int status;\n \n     sqlite3_stmt *replace_stmt, *begin_trans_stmt, *end_trans_stmt;\n@@ -504,20 +500,20 @@ class Benchmark {\n     std::string end_trans_str = \"END TRANSACTION;\";\n \n     // Check for synchronous flag in options\n-    std::string sync_stmt = (write_sync) ? \"PRAGMA synchronous = FULL\" :\n-                                           \"PRAGMA synchronous = OFF\";\n-    status = sqlite3_exec(db_, sync_stmt.c_str(), NULL, NULL, &err_msg);\n+    std::string sync_stmt =\n+        (write_sync) ? \"PRAGMA synchronous = FULL\" : \"PRAGMA synchronous = OFF\";\n+    status = sqlite3_exec(db_, sync_stmt.c_str(), nullptr, nullptr, &err_msg);\n     ExecErrorCheck(status, err_msg);\n \n     // Preparing sqlite3 statements\n-    status = sqlite3_prepare_v2(db_, replace_str.c_str(), -1,\n-                                &replace_stmt, NULL);\n+    status = sqlite3_prepare_v2(db_, replace_str.c_str(), -1, &replace_stmt,\n+                                nullptr);\n     ErrorCheck(status);\n     status = sqlite3_prepare_v2(db_, begin_trans_str.c_str(), -1,\n-                                &begin_trans_stmt, NULL);\n+                                &begin_trans_stmt, nullptr);\n     ErrorCheck(status);\n-    status = sqlite3_prepare_v2(db_, end_trans_str.c_str(), -1,\n-                                &end_trans_stmt, NULL);\n+    status = sqlite3_prepare_v2(db_, end_trans_str.c_str(), -1, &end_trans_stmt,\n+                                nullptr);\n     ErrorCheck(status);\n \n     bool transaction = (entries_per_batch > 1);\n@@ -535,16 +531,16 @@ class Benchmark {\n         const char* value = gen_.Generate(value_size).data();\n \n         // Create values for key-value pair\n-        const int k = (order == SEQUENTIAL) ? i + j :\n-                      (rand_.Next() % num_entries);\n+        const int k =\n+            (order == SEQUENTIAL) ? i + j : (rand_.Next() % num_entries);\n         char key[100];\n         snprintf(key, sizeof(key), \"%016d\", k);\n \n         // Bind KV values into replace_stmt\n         status = sqlite3_bind_blob(replace_stmt, 1, key, 16, SQLITE_STATIC);\n         ErrorCheck(status);\n-        status = sqlite3_bind_blob(replace_stmt, 2, value,\n-                                   value_size, SQLITE_STATIC);\n+        status = sqlite3_bind_blob(replace_stmt, 2, value, value_size,\n+                                   SQLITE_STATIC);\n         ErrorCheck(status);\n \n         // Execute replace_stmt\n@@ -588,12 +584,12 @@ class Benchmark {\n \n     // Preparing sqlite3 statements\n     status = sqlite3_prepare_v2(db_, begin_trans_str.c_str(), -1,\n-                                &begin_trans_stmt, NULL);\n+                                &begin_trans_stmt, nullptr);\n     ErrorCheck(status);\n-    status = sqlite3_prepare_v2(db_, end_trans_str.c_str(), -1,\n-                                &end_trans_stmt, NULL);\n+    status = sqlite3_prepare_v2(db_, end_trans_str.c_str(), -1, &end_trans_stmt,\n+                                nullptr);\n     ErrorCheck(status);\n-    status = sqlite3_prepare_v2(db_, read_str.c_str(), -1, &read_stmt, NULL);\n+    status = sqlite3_prepare_v2(db_, read_str.c_str(), -1, &read_stmt, nullptr);\n     ErrorCheck(status);\n \n     bool transaction = (entries_per_batch > 1);\n@@ -618,7 +614,8 @@ class Benchmark {\n         ErrorCheck(status);\n \n         // Execute read statement\n-        while ((status = sqlite3_step(read_stmt)) == SQLITE_ROW) {}\n+        while ((status = sqlite3_step(read_stmt)) == SQLITE_ROW) {\n+        }\n         StepErrorCheck(status);\n \n         // Reset SQLite statement for another use\n@@ -648,10 +645,10 @@ class Benchmark {\n \n   void ReadSequential() {\n     int status;\n-    sqlite3_stmt *pStmt;\n+    sqlite3_stmt* pStmt;\n     std::string read_str = \"SELECT * FROM test ORDER BY key\";\n \n-    status = sqlite3_prepare_v2(db_, read_str.c_str(), -1, &pStmt, NULL);\n+    status = sqlite3_prepare_v2(db_, read_str.c_str(), -1, &pStmt, nullptr);\n     ErrorCheck(status);\n     for (int i = 0; i < reads_ && SQLITE_ROW == sqlite3_step(pStmt); i++) {\n       bytes_ += sqlite3_column_bytes(pStmt, 1) + sqlite3_column_bytes(pStmt, 2);\n@@ -661,7 +658,6 @@ class Benchmark {\n     status = sqlite3_finalize(pStmt);\n     ErrorCheck(status);\n   }\n-\n };\n \n }  // namespace leveldb\n@@ -706,10 +702,10 @@ int main(int argc, char** argv) {\n   }\n \n   // Choose a location for the test database if none given with --db=<path>\n-  if (FLAGS_db == NULL) {\n-      leveldb::Env::Default()->GetTestDirectory(&default_db_path);\n-      default_db_path += \"/dbbench\";\n-      FLAGS_db = default_db_path.c_str();\n+  if (FLAGS_db == nullptr) {\n+    leveldb::Env::Default()->GetTestDirectory(&default_db_path);\n+    default_db_path += \"/dbbench\";\n+    FLAGS_db = default_db_path.c_str();\n   }\n \n   leveldb::Benchmark benchmark;",
        "previous_filename": "src/leveldb/doc/bench/db_bench_sqlite3.cc"
      },
      {
        "sha": "b2f6646d8996d30921279ca7965d9a703af58fc9",
        "filename": "src/leveldb/benchmarks/db_bench_tree_db.cc",
        "status": "renamed",
        "additions": 62,
        "deletions": 68,
        "changes": 130,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/benchmarks/db_bench_tree_db.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/benchmarks/db_bench_tree_db.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/benchmarks/db_bench_tree_db.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -2,9 +2,10 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n+#include <kcpolydb.h>\n #include <stdio.h>\n #include <stdlib.h>\n-#include <kcpolydb.h>\n+\n #include \"util/histogram.h\"\n #include \"util/random.h\"\n #include \"util/testutil.h\"\n@@ -34,8 +35,7 @@ static const char* FLAGS_benchmarks =\n     \"fillrand100K,\"\n     \"fillseq100K,\"\n     \"readseq100K,\"\n-    \"readrand100K,\"\n-    ;\n+    \"readrand100K,\";\n \n // Number of key/values to place in database\n static int FLAGS_num = 1000000;\n@@ -69,11 +69,9 @@ static bool FLAGS_use_existing_db = false;\n static bool FLAGS_compression = true;\n \n // Use the db with the following name.\n-static const char* FLAGS_db = NULL;\n+static const char* FLAGS_db = nullptr;\n \n-inline\n-static void DBSynchronize(kyotocabinet::TreeDB* db_)\n-{\n+inline static void DBSynchronize(kyotocabinet::TreeDB* db_) {\n   // Synchronize will flush writes to disk\n   if (!db_->synchronize()) {\n     fprintf(stderr, \"synchronize error: %s\\n\", db_->error().name());\n@@ -121,7 +119,7 @@ static Slice TrimSpace(Slice s) {\n     start++;\n   }\n   int limit = s.size();\n-  while (limit > start && isspace(s[limit-1])) {\n+  while (limit > start && isspace(s[limit - 1])) {\n     limit--;\n   }\n   return Slice(s.data() + start, limit - start);\n@@ -146,7 +144,7 @@ class Benchmark {\n \n   // State kept for progress messages\n   int done_;\n-  int next_report_;     // When to report next\n+  int next_report_;  // When to report next\n \n   void PrintHeader() {\n     const int kKeySize = 16;\n@@ -157,20 +155,20 @@ class Benchmark {\n             static_cast<int>(FLAGS_value_size * FLAGS_compression_ratio + 0.5));\n     fprintf(stdout, \"Entries:    %d\\n\", num_);\n     fprintf(stdout, \"RawSize:    %.1f MB (estimated)\\n\",\n-            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_)\n-             / 1048576.0));\n+            ((static_cast<int64_t>(kKeySize + FLAGS_value_size) * num_) /\n+             1048576.0));\n     fprintf(stdout, \"FileSize:   %.1f MB (estimated)\\n\",\n-            (((kKeySize + FLAGS_value_size * FLAGS_compression_ratio) * num_)\n-             / 1048576.0));\n+            (((kKeySize + FLAGS_value_size * FLAGS_compression_ratio) * num_) /\n+             1048576.0));\n     PrintWarnings();\n     fprintf(stdout, \"------------------------------------------------\\n\");\n   }\n \n   void PrintWarnings() {\n #if defined(__GNUC__) && !defined(__OPTIMIZE__)\n-    fprintf(stdout,\n-            \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\"\n-            );\n+    fprintf(\n+        stdout,\n+        \"WARNING: Optimization is disabled: benchmarks unnecessarily slow\\n\");\n #endif\n #ifndef NDEBUG\n     fprintf(stdout,\n@@ -183,18 +181,18 @@ class Benchmark {\n             kyotocabinet::VERSION, kyotocabinet::LIBVER, kyotocabinet::LIBREV);\n \n #if defined(__linux)\n-    time_t now = time(NULL);\n+    time_t now = time(nullptr);\n     fprintf(stderr, \"Date:           %s\", ctime(&now));  // ctime() adds newline\n \n     FILE* cpuinfo = fopen(\"/proc/cpuinfo\", \"r\");\n-    if (cpuinfo != NULL) {\n+    if (cpuinfo != nullptr) {\n       char line[1000];\n       int num_cpus = 0;\n       std::string cpu_type;\n       std::string cache_size;\n-      while (fgets(line, sizeof(line), cpuinfo) != NULL) {\n+      while (fgets(line, sizeof(line), cpuinfo) != nullptr) {\n         const char* sep = strchr(line, ':');\n-        if (sep == NULL) {\n+        if (sep == nullptr) {\n           continue;\n         }\n         Slice key = TrimSpace(Slice(line, sep - 1 - line));\n@@ -237,13 +235,20 @@ class Benchmark {\n \n     done_++;\n     if (done_ >= next_report_) {\n-      if      (next_report_ < 1000)   next_report_ += 100;\n-      else if (next_report_ < 5000)   next_report_ += 500;\n-      else if (next_report_ < 10000)  next_report_ += 1000;\n-      else if (next_report_ < 50000)  next_report_ += 5000;\n-      else if (next_report_ < 100000) next_report_ += 10000;\n-      else if (next_report_ < 500000) next_report_ += 50000;\n-      else                            next_report_ += 100000;\n+      if (next_report_ < 1000)\n+        next_report_ += 100;\n+      else if (next_report_ < 5000)\n+        next_report_ += 500;\n+      else if (next_report_ < 10000)\n+        next_report_ += 1000;\n+      else if (next_report_ < 50000)\n+        next_report_ += 5000;\n+      else if (next_report_ < 100000)\n+        next_report_ += 10000;\n+      else if (next_report_ < 500000)\n+        next_report_ += 50000;\n+      else\n+        next_report_ += 100000;\n       fprintf(stderr, \"... finished %d ops%30s\\r\", done_, \"\");\n       fflush(stderr);\n     }\n@@ -261,16 +266,14 @@ class Benchmark {\n       snprintf(rate, sizeof(rate), \"%6.1f MB/s\",\n                (bytes_ / 1048576.0) / (finish - start_));\n       if (!message_.empty()) {\n-        message_  = std::string(rate) + \" \" + message_;\n+        message_ = std::string(rate) + \" \" + message_;\n       } else {\n         message_ = rate;\n       }\n     }\n \n-    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\",\n-            name.ToString().c_str(),\n-            (finish - start_) * 1e6 / done_,\n-            (message_.empty() ? \"\" : \" \"),\n+    fprintf(stdout, \"%-12s : %11.3f micros/op;%s%s\\n\", name.ToString().c_str(),\n+            (finish - start_) * 1e6 / done_, (message_.empty() ? \"\" : \" \"),\n             message_.c_str());\n     if (FLAGS_histogram) {\n       fprintf(stdout, \"Microseconds per op:\\n%s\\n\", hist_.ToString().c_str());\n@@ -279,21 +282,15 @@ class Benchmark {\n   }\n \n  public:\n-  enum Order {\n-    SEQUENTIAL,\n-    RANDOM\n-  };\n-  enum DBState {\n-    FRESH,\n-    EXISTING\n-  };\n+  enum Order { SEQUENTIAL, RANDOM };\n+  enum DBState { FRESH, EXISTING };\n \n   Benchmark()\n-  : db_(NULL),\n-    num_(FLAGS_num),\n-    reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n-    bytes_(0),\n-    rand_(301) {\n+      : db_(nullptr),\n+        num_(FLAGS_num),\n+        reads_(FLAGS_reads < 0 ? FLAGS_num : FLAGS_reads),\n+        bytes_(0),\n+        rand_(301) {\n     std::vector<std::string> files;\n     std::string test_dir;\n     Env::Default()->GetTestDirectory(&test_dir);\n@@ -321,12 +318,12 @@ class Benchmark {\n     Open(false);\n \n     const char* benchmarks = FLAGS_benchmarks;\n-    while (benchmarks != NULL) {\n+    while (benchmarks != nullptr) {\n       const char* sep = strchr(benchmarks, ',');\n       Slice name;\n-      if (sep == NULL) {\n+      if (sep == nullptr) {\n         name = benchmarks;\n-        benchmarks = NULL;\n+        benchmarks = nullptr;\n       } else {\n         name = Slice(benchmarks, sep - benchmarks);\n         benchmarks = sep + 1;\n@@ -386,33 +383,31 @@ class Benchmark {\n   }\n \n  private:\n-    void Open(bool sync) {\n-    assert(db_ == NULL);\n+  void Open(bool sync) {\n+    assert(db_ == nullptr);\n \n     // Initialize db_\n     db_ = new kyotocabinet::TreeDB();\n     char file_name[100];\n     db_num_++;\n     std::string test_dir;\n     Env::Default()->GetTestDirectory(&test_dir);\n-    snprintf(file_name, sizeof(file_name),\n-             \"%s/dbbench_polyDB-%d.kct\",\n-             test_dir.c_str(),\n-             db_num_);\n+    snprintf(file_name, sizeof(file_name), \"%s/dbbench_polyDB-%d.kct\",\n+             test_dir.c_str(), db_num_);\n \n     // Create tuning options and open the database\n-    int open_options = kyotocabinet::PolyDB::OWRITER |\n-                       kyotocabinet::PolyDB::OCREATE;\n-    int tune_options = kyotocabinet::TreeDB::TSMALL |\n-        kyotocabinet::TreeDB::TLINEAR;\n+    int open_options =\n+        kyotocabinet::PolyDB::OWRITER | kyotocabinet::PolyDB::OCREATE;\n+    int tune_options =\n+        kyotocabinet::TreeDB::TSMALL | kyotocabinet::TreeDB::TLINEAR;\n     if (FLAGS_compression) {\n       tune_options |= kyotocabinet::TreeDB::TCOMPRESS;\n       db_->tune_compressor(&comp_);\n     }\n     db_->tune_options(tune_options);\n     db_->tune_page_cache(FLAGS_cache_size);\n     db_->tune_page(FLAGS_page_size);\n-    db_->tune_map(256LL<<20);\n+    db_->tune_map(256LL << 20);\n     if (sync) {\n       open_options |= kyotocabinet::PolyDB::OAUTOSYNC;\n     }\n@@ -421,16 +416,16 @@ class Benchmark {\n     }\n   }\n \n-  void Write(bool sync, Order order, DBState state,\n-             int num_entries, int value_size, int entries_per_batch) {\n+  void Write(bool sync, Order order, DBState state, int num_entries,\n+             int value_size, int entries_per_batch) {\n     // Create new database if state == FRESH\n     if (state == FRESH) {\n       if (FLAGS_use_existing_db) {\n         message_ = \"skipping (--use_existing_db is true)\";\n         return;\n       }\n       delete db_;\n-      db_ = NULL;\n+      db_ = nullptr;\n       Open(sync);\n       Start();  // Do not count time taken to destroy/open\n     }\n@@ -442,8 +437,7 @@ class Benchmark {\n     }\n \n     // Write to database\n-    for (int i = 0; i < num_entries; i++)\n-    {\n+    for (int i = 0; i < num_entries; i++) {\n       const int k = (order == SEQUENTIAL) ? i : (rand_.Next() % num_entries);\n       char key[100];\n       snprintf(key, sizeof(key), \"%016d\", k);\n@@ -516,10 +510,10 @@ int main(int argc, char** argv) {\n   }\n \n   // Choose a location for the test database if none given with --db=<path>\n-  if (FLAGS_db == NULL) {\n-      leveldb::Env::Default()->GetTestDirectory(&default_db_path);\n-      default_db_path += \"/dbbench\";\n-      FLAGS_db = default_db_path.c_str();\n+  if (FLAGS_db == nullptr) {\n+    leveldb::Env::Default()->GetTestDirectory(&default_db_path);\n+    default_db_path += \"/dbbench\";\n+    FLAGS_db = default_db_path.c_str();\n   }\n \n   leveldb::Benchmark benchmark;",
        "previous_filename": "src/leveldb/doc/bench/db_bench_tree_db.cc"
      },
      {
        "sha": "4a94715900969161b9f29d41e27f0659c648df10",
        "filename": "src/leveldb/build_detect_platform",
        "status": "removed",
        "additions": 0,
        "deletions": 259,
        "changes": 259,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/build_detect_platform",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/build_detect_platform",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/build_detect_platform?ref=2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "patch": "@@ -1,259 +0,0 @@\n-#!/bin/sh\n-#\n-# Detects OS we're compiling on and outputs a file specified by the first\n-# argument, which in turn gets read while processing Makefile.\n-#\n-# The output will set the following variables:\n-#   CC                          C Compiler path\n-#   CXX                         C++ Compiler path\n-#   PLATFORM_LDFLAGS            Linker flags\n-#   PLATFORM_LIBS               Libraries flags\n-#   PLATFORM_SHARED_EXT         Extension for shared libraries\n-#   PLATFORM_SHARED_LDFLAGS     Flags for building shared library\n-#                               This flag is embedded just before the name\n-#                               of the shared library without intervening spaces\n-#   PLATFORM_SHARED_CFLAGS      Flags for compiling objects for shared library\n-#   PLATFORM_CCFLAGS            C compiler flags\n-#   PLATFORM_CXXFLAGS           C++ compiler flags.  Will contain:\n-#   PLATFORM_SHARED_VERSIONED   Set to 'true' if platform supports versioned\n-#                               shared libraries, empty otherwise.\n-#\n-# The PLATFORM_CCFLAGS and PLATFORM_CXXFLAGS might include the following:\n-#\n-#       -DLEVELDB_ATOMIC_PRESENT     if <atomic> is present\n-#       -DLEVELDB_PLATFORM_POSIX     for Posix-based platforms\n-#       -DSNAPPY                     if the Snappy library is present\n-#\n-\n-OUTPUT=$1\n-PREFIX=$2\n-if test -z \"$OUTPUT\" || test -z \"$PREFIX\"; then\n-  echo \"usage: $0 <output-filename> <directory_prefix>\" >&2\n-  exit 1\n-fi\n-\n-# Delete existing output, if it exists\n-rm -f $OUTPUT\n-touch $OUTPUT\n-\n-if test -z \"$CC\"; then\n-    CC=cc\n-fi\n-\n-if test -z \"$CXX\"; then\n-    CXX=g++\n-fi\n-\n-if test -z \"$TMPDIR\"; then\n-    TMPDIR=/tmp\n-fi\n-\n-# Detect OS\n-if test -z \"$TARGET_OS\"; then\n-    TARGET_OS=`uname -s`\n-fi\n-\n-COMMON_FLAGS=\n-CROSS_COMPILE=\n-PLATFORM_CCFLAGS=\n-PLATFORM_CXXFLAGS=\n-PLATFORM_LDFLAGS=\n-PLATFORM_LIBS=\n-PLATFORM_SHARED_EXT=\"so\"\n-PLATFORM_SHARED_LDFLAGS=\"-shared -Wl,-soname -Wl,\"\n-PLATFORM_SHARED_CFLAGS=\"-fPIC\"\n-PLATFORM_SHARED_VERSIONED=true\n-PLATFORM_SSEFLAGS=\n-\n-MEMCMP_FLAG=\n-if [ \"$CXX\" = \"g++\" ]; then\n-    # Use libc's memcmp instead of GCC's memcmp.  This results in ~40%\n-    # performance improvement on readrandom under gcc 4.4.3 on Linux/x86.\n-    MEMCMP_FLAG=\"-fno-builtin-memcmp\"\n-fi\n-\n-case \"$TARGET_OS\" in\n-    CYGWIN_*)\n-        PLATFORM=OS_LINUX\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -lpthread -DOS_LINUX -DCYGWIN\"\n-        PLATFORM_LDFLAGS=\"-lpthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    Darwin)\n-        PLATFORM=OS_MACOSX\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -DOS_MACOSX\"\n-        PLATFORM_SHARED_EXT=dylib\n-        [ -z \"$INSTALL_PATH\" ] && INSTALL_PATH=`pwd`\n-        PLATFORM_SHARED_LDFLAGS=\"-dynamiclib -install_name $INSTALL_PATH/\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    Linux)\n-        PLATFORM=OS_LINUX\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -pthread -DOS_LINUX\"\n-        PLATFORM_LDFLAGS=\"-pthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    SunOS)\n-        PLATFORM=OS_SOLARIS\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_SOLARIS\"\n-        PLATFORM_LIBS=\"-lpthread -lrt\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    FreeBSD)\n-        PLATFORM=OS_FREEBSD\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_FREEBSD\"\n-        PLATFORM_LIBS=\"-lpthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    GNU/kFreeBSD)\n-        PLATFORM=OS_KFREEBSD\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_KFREEBSD\"\n-        PLATFORM_LIBS=\"-lpthread\"\n-        PORT_FILE=port/port_posix.cc\n-        ;;\n-    NetBSD)\n-        PLATFORM=OS_NETBSD\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_NETBSD\"\n-        PLATFORM_LIBS=\"-lpthread -lgcc_s\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    OpenBSD)\n-        PLATFORM=OS_OPENBSD\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_OPENBSD\"\n-        PLATFORM_LDFLAGS=\"-pthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    DragonFly)\n-        PLATFORM=OS_DRAGONFLYBSD\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_DRAGONFLYBSD\"\n-        PLATFORM_LIBS=\"-lpthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        ;;\n-    OS_ANDROID_CROSSCOMPILE)\n-        PLATFORM=OS_ANDROID\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_ANDROID -DLEVELDB_PLATFORM_POSIX\"\n-        PLATFORM_LDFLAGS=\"\"  # All pthread features are in the Android C library\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        CROSS_COMPILE=true\n-        ;;\n-    HP-UX)\n-        PLATFORM=OS_HPUX\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -D_REENTRANT -DOS_HPUX\"\n-        PLATFORM_LDFLAGS=\"-pthread\"\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        # man ld: +h internal_name\n-        PLATFORM_SHARED_LDFLAGS=\"-shared -Wl,+h -Wl,\"\n-        ;;\n-    IOS)\n-        PLATFORM=IOS\n-        COMMON_FLAGS=\"$MEMCMP_FLAG -DOS_MACOSX\"\n-        [ -z \"$INSTALL_PATH\" ] && INSTALL_PATH=`pwd`\n-        PORT_FILE=port/port_posix.cc\n-        PORT_SSE_FILE=port/port_posix_sse.cc\n-        PLATFORM_SHARED_EXT=\n-        PLATFORM_SHARED_LDFLAGS=\n-        PLATFORM_SHARED_CFLAGS=\n-        PLATFORM_SHARED_VERSIONED=\n-        ;;\n-    OS_WINDOWS_CROSSCOMPILE | NATIVE_WINDOWS)\n-        PLATFORM=OS_WINDOWS\n-        COMMON_FLAGS=\"-fno-builtin-memcmp -D_REENTRANT -DOS_WINDOWS -DLEVELDB_PLATFORM_WINDOWS -DWINVER=0x0500 -D__USE_MINGW_ANSI_STDIO=1\"\n-        PLATFORM_SOURCES=\"util/env_win.cc\"\n-        PLATFORM_LIBS=\"-lshlwapi\"\n-        PORT_FILE=port/port_win.cc\n-        CROSS_COMPILE=true\n-        ;;\n-    *)\n-        echo \"Unknown platform!\" >&2\n-        exit 1\n-esac\n-\n-# We want to make a list of all cc files within util, db, table, and helpers\n-# except for the test and benchmark files. By default, find will output a list\n-# of all files matching either rule, so we need to append -print to make the\n-# prune take effect.\n-DIRS=\"$PREFIX/db $PREFIX/util $PREFIX/table\"\n-\n-set -f # temporarily disable globbing so that our patterns aren't expanded\n-PRUNE_TEST=\"-name *test*.cc -prune\"\n-PRUNE_BENCH=\"-name *_bench.cc -prune\"\n-PRUNE_TOOL=\"-name leveldbutil.cc -prune\"\n-PORTABLE_FILES=`find $DIRS $PRUNE_TEST -o $PRUNE_BENCH -o $PRUNE_TOOL -o -name '*.cc' -print | sort | sed \"s,^$PREFIX/,,\" | tr \"\\n\" \" \"`\n-\n-set +f # re-enable globbing\n-\n-# The sources consist of the portable files, plus the platform-specific port\n-# file.\n-echo \"SOURCES=$PORTABLE_FILES $PORT_FILE $PORT_SSE_FILE\" >> $OUTPUT\n-echo \"MEMENV_SOURCES=helpers/memenv/memenv.cc\" >> $OUTPUT\n-\n-if [ \"$CROSS_COMPILE\" = \"true\" ]; then\n-    # Cross-compiling; do not try any compilation tests.\n-    true\n-else\n-    CXXOUTPUT=\"${TMPDIR}/leveldb_build_detect_platform-cxx.$$\"\n-\n-    # If -std=c++0x works, use <atomic> as fallback for when memory barriers\n-    # are not available.\n-    $CXX $CXXFLAGS -std=c++0x -x c++ - -o $CXXOUTPUT 2>/dev/null  <<EOF\n-      #include <atomic>\n-      int main() {}\n-EOF\n-    if [ \"$?\" = 0 ]; then\n-        COMMON_FLAGS=\"$COMMON_FLAGS -DLEVELDB_PLATFORM_POSIX -DLEVELDB_ATOMIC_PRESENT\"\n-        PLATFORM_CXXFLAGS=\"-std=c++0x\"\n-    else\n-        COMMON_FLAGS=\"$COMMON_FLAGS -DLEVELDB_PLATFORM_POSIX\"\n-    fi\n-\n-    # Test whether tcmalloc is available\n-    $CXX $CXXFLAGS -x c++ - -o $CXXOUTPUT -ltcmalloc 2>/dev/null  <<EOF\n-      int main() {}\n-EOF\n-    if [ \"$?\" = 0 ]; then\n-        PLATFORM_LIBS=\"$PLATFORM_LIBS -ltcmalloc\"\n-    fi\n-\n-    rm -f $CXXOUTPUT 2>/dev/null\n-\n-    # Test if gcc SSE 4.2 is supported\n-    $CXX $CXXFLAGS -x c++ - -o $CXXOUTPUT -msse4.2 2>/dev/null  <<EOF\n-      int main() {}\n-EOF\n-    if [ \"$?\" = 0 ]; then\n-        PLATFORM_SSEFLAGS=\"-msse4.2\"\n-    fi\n-\n-    rm -f $CXXOUTPUT 2>/dev/null\n-fi\n-\n-# Use the SSE 4.2 CRC32C intrinsics iff runtime checks indicate compiler supports them.\n-if [ -n \"$PLATFORM_SSEFLAGS\" ]; then\n-    PLATFORM_SSEFLAGS=\"$PLATFORM_SSEFLAGS -DLEVELDB_PLATFORM_POSIX_SSE\"\n-fi\n-\n-PLATFORM_CCFLAGS=\"$PLATFORM_CCFLAGS $COMMON_FLAGS\"\n-PLATFORM_CXXFLAGS=\"$PLATFORM_CXXFLAGS $COMMON_FLAGS\"\n-\n-echo \"CC=$CC\" >> $OUTPUT\n-echo \"CXX=$CXX\" >> $OUTPUT\n-echo \"PLATFORM=$PLATFORM\" >> $OUTPUT\n-echo \"PLATFORM_LDFLAGS=$PLATFORM_LDFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_LIBS=$PLATFORM_LIBS\" >> $OUTPUT\n-echo \"PLATFORM_CCFLAGS=$PLATFORM_CCFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_CXXFLAGS=$PLATFORM_CXXFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_SSEFLAGS=$PLATFORM_SSEFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_SHARED_CFLAGS=$PLATFORM_SHARED_CFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_SHARED_EXT=$PLATFORM_SHARED_EXT\" >> $OUTPUT\n-echo \"PLATFORM_SHARED_LDFLAGS=$PLATFORM_SHARED_LDFLAGS\" >> $OUTPUT\n-echo \"PLATFORM_SHARED_VERSIONED=$PLATFORM_SHARED_VERSIONED\" >> $OUTPUT"
      },
      {
        "sha": "eea6e5c4776bbe6838d323b9e0ea554bc8ec4b32",
        "filename": "src/leveldb/cmake/leveldbConfig.cmake",
        "status": "added",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/cmake/leveldbConfig.cmake",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/cmake/leveldbConfig.cmake",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/cmake/leveldbConfig.cmake?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -0,0 +1 @@\n+include(\"${CMAKE_CURRENT_LIST_DIR}/leveldbTargets.cmake\")"
      },
      {
        "sha": "e6c97a05a6b7ff6954224fe62f1f2aec2d52f4a7",
        "filename": "src/leveldb/db/autocompact_test.cc",
        "status": "modified",
        "additions": 15,
        "deletions": 21,
        "changes": 36,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/autocompact_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/autocompact_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/autocompact_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -2,21 +2,16 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include \"leveldb/db.h\"\n #include \"db/db_impl.h\"\n #include \"leveldb/cache.h\"\n+#include \"leveldb/db.h\"\n #include \"util/testharness.h\"\n #include \"util/testutil.h\"\n \n namespace leveldb {\n \n class AutoCompactTest {\n  public:\n-  std::string dbname_;\n-  Cache* tiny_cache_;\n-  Options options_;\n-  DB* db_;\n-\n   AutoCompactTest() {\n     dbname_ = test::TmpDir() + \"/autocompact_test\";\n     tiny_cache_ = NewLRUCache(100);\n@@ -47,6 +42,12 @@ class AutoCompactTest {\n   }\n \n   void DoReads(int n);\n+\n+ private:\n+  std::string dbname_;\n+  Cache* tiny_cache_;\n+  Options options_;\n+  DB* db_;\n };\n \n static const int kValueSize = 200 * 1024;\n@@ -81,17 +82,16 @@ void AutoCompactTest::DoReads(int n) {\n     ASSERT_LT(read, 100) << \"Taking too long to compact\";\n     Iterator* iter = db_->NewIterator(ReadOptions());\n     for (iter->SeekToFirst();\n-         iter->Valid() && iter->key().ToString() < limit_key;\n-         iter->Next()) {\n+         iter->Valid() && iter->key().ToString() < limit_key; iter->Next()) {\n       // Drop data\n     }\n     delete iter;\n     // Wait a little bit to allow any triggered compactions to complete.\n     Env::Default()->SleepForMicroseconds(1000000);\n     uint64_t size = Size(Key(0), Key(n));\n-    fprintf(stderr, \"iter %3d => %7.3f MB [other %7.3f MB]\\n\",\n-            read+1, size/1048576.0, Size(Key(n), Key(kCount))/1048576.0);\n-    if (size <= initial_size/10) {\n+    fprintf(stderr, \"iter %3d => %7.3f MB [other %7.3f MB]\\n\", read + 1,\n+            size / 1048576.0, Size(Key(n), Key(kCount)) / 1048576.0);\n+    if (size <= initial_size / 10) {\n       break;\n     }\n   }\n@@ -100,19 +100,13 @@ void AutoCompactTest::DoReads(int n) {\n   // is pretty much unchanged.\n   const int64_t final_other_size = Size(Key(n), Key(kCount));\n   ASSERT_LE(final_other_size, initial_other_size + 1048576);\n-  ASSERT_GE(final_other_size, initial_other_size/5 - 1048576);\n+  ASSERT_GE(final_other_size, initial_other_size / 5 - 1048576);\n }\n \n-TEST(AutoCompactTest, ReadAll) {\n-  DoReads(kCount);\n-}\n+TEST(AutoCompactTest, ReadAll) { DoReads(kCount); }\n \n-TEST(AutoCompactTest, ReadHalf) {\n-  DoReads(kCount/2);\n-}\n+TEST(AutoCompactTest, ReadHalf) { DoReads(kCount / 2); }\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "9520ee4535f496a929fa58a36a3f6b208d0b2f36",
        "filename": "src/leveldb/db/builder.cc",
        "status": "modified",
        "additions": 8,
        "deletions": 17,
        "changes": 25,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/builder.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/builder.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/builder.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -4,8 +4,8 @@\n \n #include \"db/builder.h\"\n \n-#include \"db/filename.h\"\n #include \"db/dbformat.h\"\n+#include \"db/filename.h\"\n #include \"db/table_cache.h\"\n #include \"db/version_edit.h\"\n #include \"leveldb/db.h\"\n@@ -14,12 +14,8 @@\n \n namespace leveldb {\n \n-Status BuildTable(const std::string& dbname,\n-                  Env* env,\n-                  const Options& options,\n-                  TableCache* table_cache,\n-                  Iterator* iter,\n-                  FileMetaData* meta) {\n+Status BuildTable(const std::string& dbname, Env* env, const Options& options,\n+                  TableCache* table_cache, Iterator* iter, FileMetaData* meta) {\n   Status s;\n   meta->file_size = 0;\n   iter->SeekToFirst();\n@@ -41,14 +37,10 @@ Status BuildTable(const std::string& dbname,\n     }\n \n     // Finish and check for builder errors\n+    s = builder->Finish();\n     if (s.ok()) {\n-      s = builder->Finish();\n-      if (s.ok()) {\n-        meta->file_size = builder->FileSize();\n-        assert(meta->file_size > 0);\n-      }\n-    } else {\n-      builder->Abandon();\n+      meta->file_size = builder->FileSize();\n+      assert(meta->file_size > 0);\n     }\n     delete builder;\n \n@@ -60,12 +52,11 @@ Status BuildTable(const std::string& dbname,\n       s = file->Close();\n     }\n     delete file;\n-    file = NULL;\n+    file = nullptr;\n \n     if (s.ok()) {\n       // Verify that the table is usable\n-      Iterator* it = table_cache->NewIterator(ReadOptions(),\n-                                              meta->number,\n+      Iterator* it = table_cache->NewIterator(ReadOptions(), meta->number,\n                                               meta->file_size);\n       s = it->status();\n       delete it;"
      },
      {
        "sha": "7bd0b8049b1b322f46edb710d36eacd6a83aba8f",
        "filename": "src/leveldb/db/builder.h",
        "status": "modified",
        "additions": 2,
        "deletions": 6,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/builder.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/builder.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/builder.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -22,12 +22,8 @@ class VersionEdit;\n // *meta will be filled with metadata about the generated table.\n // If no data is present in *iter, meta->file_size will be set to\n // zero, and no Table file will be produced.\n-extern Status BuildTable(const std::string& dbname,\n-                         Env* env,\n-                         const Options& options,\n-                         TableCache* table_cache,\n-                         Iterator* iter,\n-                         FileMetaData* meta);\n+Status BuildTable(const std::string& dbname, Env* env, const Options& options,\n+                  TableCache* table_cache, Iterator* iter, FileMetaData* meta);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "3a492f9ac558381d676ceb1249c20346c91eda7d",
        "filename": "src/leveldb/db/c.cc",
        "status": "modified",
        "additions": 178,
        "deletions": 213,
        "changes": 391,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/c.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/c.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/c.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -4,10 +4,9 @@\n \n #include \"leveldb/c.h\"\n \n-#include <stdlib.h>\n-#ifndef WIN32\n-#include <unistd.h>\n-#endif\n+#include <cstdint>\n+#include <cstdlib>\n+\n #include \"leveldb/cache.h\"\n #include \"leveldb/comparator.h\"\n #include \"leveldb/db.h\"\n@@ -45,69 +44,72 @@ using leveldb::WriteOptions;\n \n extern \"C\" {\n \n-struct leveldb_t              { DB*               rep; };\n-struct leveldb_iterator_t     { Iterator*         rep; };\n-struct leveldb_writebatch_t   { WriteBatch        rep; };\n-struct leveldb_snapshot_t     { const Snapshot*   rep; };\n-struct leveldb_readoptions_t  { ReadOptions       rep; };\n-struct leveldb_writeoptions_t { WriteOptions      rep; };\n-struct leveldb_options_t      { Options           rep; };\n-struct leveldb_cache_t        { Cache*            rep; };\n-struct leveldb_seqfile_t      { SequentialFile*   rep; };\n-struct leveldb_randomfile_t   { RandomAccessFile* rep; };\n-struct leveldb_writablefile_t { WritableFile*     rep; };\n-struct leveldb_logger_t       { Logger*           rep; };\n-struct leveldb_filelock_t     { FileLock*         rep; };\n+struct leveldb_t {\n+  DB* rep;\n+};\n+struct leveldb_iterator_t {\n+  Iterator* rep;\n+};\n+struct leveldb_writebatch_t {\n+  WriteBatch rep;\n+};\n+struct leveldb_snapshot_t {\n+  const Snapshot* rep;\n+};\n+struct leveldb_readoptions_t {\n+  ReadOptions rep;\n+};\n+struct leveldb_writeoptions_t {\n+  WriteOptions rep;\n+};\n+struct leveldb_options_t {\n+  Options rep;\n+};\n+struct leveldb_cache_t {\n+  Cache* rep;\n+};\n+struct leveldb_seqfile_t {\n+  SequentialFile* rep;\n+};\n+struct leveldb_randomfile_t {\n+  RandomAccessFile* rep;\n+};\n+struct leveldb_writablefile_t {\n+  WritableFile* rep;\n+};\n+struct leveldb_logger_t {\n+  Logger* rep;\n+};\n+struct leveldb_filelock_t {\n+  FileLock* rep;\n+};\n \n struct leveldb_comparator_t : public Comparator {\n-  void* state_;\n-  void (*destructor_)(void*);\n-  int (*compare_)(\n-      void*,\n-      const char* a, size_t alen,\n-      const char* b, size_t blen);\n-  const char* (*name_)(void*);\n+  ~leveldb_comparator_t() override { (*destructor_)(state_); }\n \n-  virtual ~leveldb_comparator_t() {\n-    (*destructor_)(state_);\n-  }\n-\n-  virtual int Compare(const Slice& a, const Slice& b) const {\n+  int Compare(const Slice& a, const Slice& b) const override {\n     return (*compare_)(state_, a.data(), a.size(), b.data(), b.size());\n   }\n \n-  virtual const char* Name() const {\n-    return (*name_)(state_);\n-  }\n+  const char* Name() const override { return (*name_)(state_); }\n \n   // No-ops since the C binding does not support key shortening methods.\n-  virtual void FindShortestSeparator(std::string*, const Slice&) const { }\n-  virtual void FindShortSuccessor(std::string* key) const { }\n-};\n+  void FindShortestSeparator(std::string*, const Slice&) const override {}\n+  void FindShortSuccessor(std::string* key) const override {}\n \n-struct leveldb_filterpolicy_t : public FilterPolicy {\n   void* state_;\n   void (*destructor_)(void*);\n+  int (*compare_)(void*, const char* a, size_t alen, const char* b,\n+                  size_t blen);\n   const char* (*name_)(void*);\n-  char* (*create_)(\n-      void*,\n-      const char* const* key_array, const size_t* key_length_array,\n-      int num_keys,\n-      size_t* filter_length);\n-  unsigned char (*key_match_)(\n-      void*,\n-      const char* key, size_t length,\n-      const char* filter, size_t filter_length);\n-\n-  virtual ~leveldb_filterpolicy_t() {\n-    (*destructor_)(state_);\n-  }\n+};\n \n-  virtual const char* Name() const {\n-    return (*name_)(state_);\n-  }\n+struct leveldb_filterpolicy_t : public FilterPolicy {\n+  ~leveldb_filterpolicy_t() override { (*destructor_)(state_); }\n \n-  virtual void CreateFilter(const Slice* keys, int n, std::string* dst) const {\n+  const char* Name() const override { return (*name_)(state_); }\n+\n+  void CreateFilter(const Slice* keys, int n, std::string* dst) const override {\n     std::vector<const char*> key_pointers(n);\n     std::vector<size_t> key_sizes(n);\n     for (int i = 0; i < n; i++) {\n@@ -120,10 +122,19 @@ struct leveldb_filterpolicy_t : public FilterPolicy {\n     free(filter);\n   }\n \n-  virtual bool KeyMayMatch(const Slice& key, const Slice& filter) const {\n-    return (*key_match_)(state_, key.data(), key.size(),\n-                         filter.data(), filter.size());\n+  bool KeyMayMatch(const Slice& key, const Slice& filter) const override {\n+    return (*key_match_)(state_, key.data(), key.size(), filter.data(),\n+                         filter.size());\n   }\n+\n+  void* state_;\n+  void (*destructor_)(void*);\n+  const char* (*name_)(void*);\n+  char* (*create_)(void*, const char* const* key_array,\n+                   const size_t* key_length_array, int num_keys,\n+                   size_t* filter_length);\n+  uint8_t (*key_match_)(void*, const char* key, size_t length,\n+                        const char* filter, size_t filter_length);\n };\n \n struct leveldb_env_t {\n@@ -132,10 +143,10 @@ struct leveldb_env_t {\n };\n \n static bool SaveError(char** errptr, const Status& s) {\n-  assert(errptr != NULL);\n+  assert(errptr != nullptr);\n   if (s.ok()) {\n     return false;\n-  } else if (*errptr == NULL) {\n+  } else if (*errptr == nullptr) {\n     *errptr = strdup(s.ToString().c_str());\n   } else {\n     // TODO(sanjay): Merge with existing error?\n@@ -151,13 +162,11 @@ static char* CopyString(const std::string& str) {\n   return result;\n }\n \n-leveldb_t* leveldb_open(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr) {\n+leveldb_t* leveldb_open(const leveldb_options_t* options, const char* name,\n+                        char** errptr) {\n   DB* db;\n   if (SaveError(errptr, DB::Open(options->rep, std::string(name), &db))) {\n-    return NULL;\n+    return nullptr;\n   }\n   leveldb_t* result = new leveldb_t;\n   result->rep = db;\n@@ -169,40 +178,27 @@ void leveldb_close(leveldb_t* db) {\n   delete db;\n }\n \n-void leveldb_put(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    const char* key, size_t keylen,\n-    const char* val, size_t vallen,\n-    char** errptr) {\n+void leveldb_put(leveldb_t* db, const leveldb_writeoptions_t* options,\n+                 const char* key, size_t keylen, const char* val, size_t vallen,\n+                 char** errptr) {\n   SaveError(errptr,\n             db->rep->Put(options->rep, Slice(key, keylen), Slice(val, vallen)));\n }\n \n-void leveldb_delete(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    const char* key, size_t keylen,\n-    char** errptr) {\n+void leveldb_delete(leveldb_t* db, const leveldb_writeoptions_t* options,\n+                    const char* key, size_t keylen, char** errptr) {\n   SaveError(errptr, db->rep->Delete(options->rep, Slice(key, keylen)));\n }\n \n-\n-void leveldb_write(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    leveldb_writebatch_t* batch,\n-    char** errptr) {\n+void leveldb_write(leveldb_t* db, const leveldb_writeoptions_t* options,\n+                   leveldb_writebatch_t* batch, char** errptr) {\n   SaveError(errptr, db->rep->Write(options->rep, &batch->rep));\n }\n \n-char* leveldb_get(\n-    leveldb_t* db,\n-    const leveldb_readoptions_t* options,\n-    const char* key, size_t keylen,\n-    size_t* vallen,\n-    char** errptr) {\n-  char* result = NULL;\n+char* leveldb_get(leveldb_t* db, const leveldb_readoptions_t* options,\n+                  const char* key, size_t keylen, size_t* vallen,\n+                  char** errptr) {\n+  char* result = nullptr;\n   std::string tmp;\n   Status s = db->rep->Get(options->rep, Slice(key, keylen), &tmp);\n   if (s.ok()) {\n@@ -218,45 +214,40 @@ char* leveldb_get(\n }\n \n leveldb_iterator_t* leveldb_create_iterator(\n-    leveldb_t* db,\n-    const leveldb_readoptions_t* options) {\n+    leveldb_t* db, const leveldb_readoptions_t* options) {\n   leveldb_iterator_t* result = new leveldb_iterator_t;\n   result->rep = db->rep->NewIterator(options->rep);\n   return result;\n }\n \n-const leveldb_snapshot_t* leveldb_create_snapshot(\n-    leveldb_t* db) {\n+const leveldb_snapshot_t* leveldb_create_snapshot(leveldb_t* db) {\n   leveldb_snapshot_t* result = new leveldb_snapshot_t;\n   result->rep = db->rep->GetSnapshot();\n   return result;\n }\n \n-void leveldb_release_snapshot(\n-    leveldb_t* db,\n-    const leveldb_snapshot_t* snapshot) {\n+void leveldb_release_snapshot(leveldb_t* db,\n+                              const leveldb_snapshot_t* snapshot) {\n   db->rep->ReleaseSnapshot(snapshot->rep);\n   delete snapshot;\n }\n \n-char* leveldb_property_value(\n-    leveldb_t* db,\n-    const char* propname) {\n+char* leveldb_property_value(leveldb_t* db, const char* propname) {\n   std::string tmp;\n   if (db->rep->GetProperty(Slice(propname), &tmp)) {\n     // We use strdup() since we expect human readable output.\n     return strdup(tmp.c_str());\n   } else {\n-    return NULL;\n+    return nullptr;\n   }\n }\n \n-void leveldb_approximate_sizes(\n-    leveldb_t* db,\n-    int num_ranges,\n-    const char* const* range_start_key, const size_t* range_start_key_len,\n-    const char* const* range_limit_key, const size_t* range_limit_key_len,\n-    uint64_t* sizes) {\n+void leveldb_approximate_sizes(leveldb_t* db, int num_ranges,\n+                               const char* const* range_start_key,\n+                               const size_t* range_start_key_len,\n+                               const char* const* range_limit_key,\n+                               const size_t* range_limit_key_len,\n+                               uint64_t* sizes) {\n   Range* ranges = new Range[num_ranges];\n   for (int i = 0; i < num_ranges; i++) {\n     ranges[i].start = Slice(range_start_key[i], range_start_key_len[i]);\n@@ -266,28 +257,23 @@ void leveldb_approximate_sizes(\n   delete[] ranges;\n }\n \n-void leveldb_compact_range(\n-    leveldb_t* db,\n-    const char* start_key, size_t start_key_len,\n-    const char* limit_key, size_t limit_key_len) {\n+void leveldb_compact_range(leveldb_t* db, const char* start_key,\n+                           size_t start_key_len, const char* limit_key,\n+                           size_t limit_key_len) {\n   Slice a, b;\n   db->rep->CompactRange(\n-      // Pass NULL Slice if corresponding \"const char*\" is NULL\n-      (start_key ? (a = Slice(start_key, start_key_len), &a) : NULL),\n-      (limit_key ? (b = Slice(limit_key, limit_key_len), &b) : NULL));\n+      // Pass null Slice if corresponding \"const char*\" is null\n+      (start_key ? (a = Slice(start_key, start_key_len), &a) : nullptr),\n+      (limit_key ? (b = Slice(limit_key, limit_key_len), &b) : nullptr));\n }\n \n-void leveldb_destroy_db(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr) {\n+void leveldb_destroy_db(const leveldb_options_t* options, const char* name,\n+                        char** errptr) {\n   SaveError(errptr, DestroyDB(name, options->rep));\n }\n \n-void leveldb_repair_db(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr) {\n+void leveldb_repair_db(const leveldb_options_t* options, const char* name,\n+                       char** errptr) {\n   SaveError(errptr, RepairDB(name, options->rep));\n }\n \n@@ -296,7 +282,7 @@ void leveldb_iter_destroy(leveldb_iterator_t* iter) {\n   delete iter;\n }\n \n-unsigned char leveldb_iter_valid(const leveldb_iterator_t* iter) {\n+uint8_t leveldb_iter_valid(const leveldb_iterator_t* iter) {\n   return iter->rep->Valid();\n }\n \n@@ -312,13 +298,9 @@ void leveldb_iter_seek(leveldb_iterator_t* iter, const char* k, size_t klen) {\n   iter->rep->Seek(Slice(k, klen));\n }\n \n-void leveldb_iter_next(leveldb_iterator_t* iter) {\n-  iter->rep->Next();\n-}\n+void leveldb_iter_next(leveldb_iterator_t* iter) { iter->rep->Next(); }\n \n-void leveldb_iter_prev(leveldb_iterator_t* iter) {\n-  iter->rep->Prev();\n-}\n+void leveldb_iter_prev(leveldb_iterator_t* iter) { iter->rep->Prev(); }\n \n const char* leveldb_iter_key(const leveldb_iterator_t* iter, size_t* klen) {\n   Slice s = iter->rep->key();\n@@ -340,41 +322,34 @@ leveldb_writebatch_t* leveldb_writebatch_create() {\n   return new leveldb_writebatch_t;\n }\n \n-void leveldb_writebatch_destroy(leveldb_writebatch_t* b) {\n-  delete b;\n-}\n+void leveldb_writebatch_destroy(leveldb_writebatch_t* b) { delete b; }\n \n-void leveldb_writebatch_clear(leveldb_writebatch_t* b) {\n-  b->rep.Clear();\n-}\n+void leveldb_writebatch_clear(leveldb_writebatch_t* b) { b->rep.Clear(); }\n \n-void leveldb_writebatch_put(\n-    leveldb_writebatch_t* b,\n-    const char* key, size_t klen,\n-    const char* val, size_t vlen) {\n+void leveldb_writebatch_put(leveldb_writebatch_t* b, const char* key,\n+                            size_t klen, const char* val, size_t vlen) {\n   b->rep.Put(Slice(key, klen), Slice(val, vlen));\n }\n \n-void leveldb_writebatch_delete(\n-    leveldb_writebatch_t* b,\n-    const char* key, size_t klen) {\n+void leveldb_writebatch_delete(leveldb_writebatch_t* b, const char* key,\n+                               size_t klen) {\n   b->rep.Delete(Slice(key, klen));\n }\n \n-void leveldb_writebatch_iterate(\n-    leveldb_writebatch_t* b,\n-    void* state,\n-    void (*put)(void*, const char* k, size_t klen, const char* v, size_t vlen),\n-    void (*deleted)(void*, const char* k, size_t klen)) {\n+void leveldb_writebatch_iterate(const leveldb_writebatch_t* b, void* state,\n+                                void (*put)(void*, const char* k, size_t klen,\n+                                            const char* v, size_t vlen),\n+                                void (*deleted)(void*, const char* k,\n+                                                size_t klen)) {\n   class H : public WriteBatch::Handler {\n    public:\n     void* state_;\n     void (*put_)(void*, const char* k, size_t klen, const char* v, size_t vlen);\n     void (*deleted_)(void*, const char* k, size_t klen);\n-    virtual void Put(const Slice& key, const Slice& value) {\n+    void Put(const Slice& key, const Slice& value) override {\n       (*put_)(state_, key.data(), key.size(), value.data(), value.size());\n     }\n-    virtual void Delete(const Slice& key) {\n+    void Delete(const Slice& key) override {\n       (*deleted_)(state_, key.data(), key.size());\n     }\n   };\n@@ -385,47 +360,43 @@ void leveldb_writebatch_iterate(\n   b->rep.Iterate(&handler);\n }\n \n-leveldb_options_t* leveldb_options_create() {\n-  return new leveldb_options_t;\n+void leveldb_writebatch_append(leveldb_writebatch_t* destination,\n+                               const leveldb_writebatch_t* source) {\n+  destination->rep.Append(source->rep);\n }\n \n-void leveldb_options_destroy(leveldb_options_t* options) {\n-  delete options;\n-}\n+leveldb_options_t* leveldb_options_create() { return new leveldb_options_t; }\n+\n+void leveldb_options_destroy(leveldb_options_t* options) { delete options; }\n \n-void leveldb_options_set_comparator(\n-    leveldb_options_t* opt,\n-    leveldb_comparator_t* cmp) {\n+void leveldb_options_set_comparator(leveldb_options_t* opt,\n+                                    leveldb_comparator_t* cmp) {\n   opt->rep.comparator = cmp;\n }\n \n-void leveldb_options_set_filter_policy(\n-    leveldb_options_t* opt,\n-    leveldb_filterpolicy_t* policy) {\n+void leveldb_options_set_filter_policy(leveldb_options_t* opt,\n+                                       leveldb_filterpolicy_t* policy) {\n   opt->rep.filter_policy = policy;\n }\n \n-void leveldb_options_set_create_if_missing(\n-    leveldb_options_t* opt, unsigned char v) {\n+void leveldb_options_set_create_if_missing(leveldb_options_t* opt, uint8_t v) {\n   opt->rep.create_if_missing = v;\n }\n \n-void leveldb_options_set_error_if_exists(\n-    leveldb_options_t* opt, unsigned char v) {\n+void leveldb_options_set_error_if_exists(leveldb_options_t* opt, uint8_t v) {\n   opt->rep.error_if_exists = v;\n }\n \n-void leveldb_options_set_paranoid_checks(\n-    leveldb_options_t* opt, unsigned char v) {\n+void leveldb_options_set_paranoid_checks(leveldb_options_t* opt, uint8_t v) {\n   opt->rep.paranoid_checks = v;\n }\n \n void leveldb_options_set_env(leveldb_options_t* opt, leveldb_env_t* env) {\n-  opt->rep.env = (env ? env->rep : NULL);\n+  opt->rep.env = (env ? env->rep : nullptr);\n }\n \n void leveldb_options_set_info_log(leveldb_options_t* opt, leveldb_logger_t* l) {\n-  opt->rep.info_log = (l ? l->rep : NULL);\n+  opt->rep.info_log = (l ? l->rep : nullptr);\n }\n \n void leveldb_options_set_write_buffer_size(leveldb_options_t* opt, size_t s) {\n@@ -448,17 +419,18 @@ void leveldb_options_set_block_restart_interval(leveldb_options_t* opt, int n) {\n   opt->rep.block_restart_interval = n;\n }\n \n+void leveldb_options_set_max_file_size(leveldb_options_t* opt, size_t s) {\n+  opt->rep.max_file_size = s;\n+}\n+\n void leveldb_options_set_compression(leveldb_options_t* opt, int t) {\n   opt->rep.compression = static_cast<CompressionType>(t);\n }\n \n leveldb_comparator_t* leveldb_comparator_create(\n-    void* state,\n-    void (*destructor)(void*),\n-    int (*compare)(\n-        void*,\n-        const char* a, size_t alen,\n-        const char* b, size_t blen),\n+    void* state, void (*destructor)(void*),\n+    int (*compare)(void*, const char* a, size_t alen, const char* b,\n+                   size_t blen),\n     const char* (*name)(void*)) {\n   leveldb_comparator_t* result = new leveldb_comparator_t;\n   result->state_ = state;\n@@ -468,22 +440,15 @@ leveldb_comparator_t* leveldb_comparator_create(\n   return result;\n }\n \n-void leveldb_comparator_destroy(leveldb_comparator_t* cmp) {\n-  delete cmp;\n-}\n+void leveldb_comparator_destroy(leveldb_comparator_t* cmp) { delete cmp; }\n \n leveldb_filterpolicy_t* leveldb_filterpolicy_create(\n-    void* state,\n-    void (*destructor)(void*),\n-    char* (*create_filter)(\n-        void*,\n-        const char* const* key_array, const size_t* key_length_array,\n-        int num_keys,\n-        size_t* filter_length),\n-    unsigned char (*key_may_match)(\n-        void*,\n-        const char* key, size_t length,\n-        const char* filter, size_t filter_length),\n+    void* state, void (*destructor)(void*),\n+    char* (*create_filter)(void*, const char* const* key_array,\n+                           const size_t* key_length_array, int num_keys,\n+                           size_t* filter_length),\n+    uint8_t (*key_may_match)(void*, const char* key, size_t length,\n+                             const char* filter, size_t filter_length),\n     const char* (*name)(void*)) {\n   leveldb_filterpolicy_t* result = new leveldb_filterpolicy_t;\n   result->state_ = state;\n@@ -503,7 +468,8 @@ leveldb_filterpolicy_t* leveldb_filterpolicy_create_bloom(int bits_per_key) {\n   // they delegate to a NewBloomFilterPolicy() instead of user\n   // supplied C functions.\n   struct Wrapper : public leveldb_filterpolicy_t {\n-    const FilterPolicy* rep_;\n+    static void DoNothing(void*) {}\n+\n     ~Wrapper() { delete rep_; }\n     const char* Name() const { return rep_->Name(); }\n     void CreateFilter(const Slice* keys, int n, std::string* dst) const {\n@@ -512,11 +478,12 @@ leveldb_filterpolicy_t* leveldb_filterpolicy_create_bloom(int bits_per_key) {\n     bool KeyMayMatch(const Slice& key, const Slice& filter) const {\n       return rep_->KeyMayMatch(key, filter);\n     }\n-    static void DoNothing(void*) { }\n+\n+    const FilterPolicy* rep_;\n   };\n   Wrapper* wrapper = new Wrapper;\n   wrapper->rep_ = NewBloomFilterPolicy(bits_per_key);\n-  wrapper->state_ = NULL;\n+  wrapper->state_ = nullptr;\n   wrapper->destructor_ = &Wrapper::DoNothing;\n   return wrapper;\n }\n@@ -525,37 +492,29 @@ leveldb_readoptions_t* leveldb_readoptions_create() {\n   return new leveldb_readoptions_t;\n }\n \n-void leveldb_readoptions_destroy(leveldb_readoptions_t* opt) {\n-  delete opt;\n-}\n+void leveldb_readoptions_destroy(leveldb_readoptions_t* opt) { delete opt; }\n \n-void leveldb_readoptions_set_verify_checksums(\n-    leveldb_readoptions_t* opt,\n-    unsigned char v) {\n+void leveldb_readoptions_set_verify_checksums(leveldb_readoptions_t* opt,\n+                                              uint8_t v) {\n   opt->rep.verify_checksums = v;\n }\n \n-void leveldb_readoptions_set_fill_cache(\n-    leveldb_readoptions_t* opt, unsigned char v) {\n+void leveldb_readoptions_set_fill_cache(leveldb_readoptions_t* opt, uint8_t v) {\n   opt->rep.fill_cache = v;\n }\n \n-void leveldb_readoptions_set_snapshot(\n-    leveldb_readoptions_t* opt,\n-    const leveldb_snapshot_t* snap) {\n-  opt->rep.snapshot = (snap ? snap->rep : NULL);\n+void leveldb_readoptions_set_snapshot(leveldb_readoptions_t* opt,\n+                                      const leveldb_snapshot_t* snap) {\n+  opt->rep.snapshot = (snap ? snap->rep : nullptr);\n }\n \n leveldb_writeoptions_t* leveldb_writeoptions_create() {\n   return new leveldb_writeoptions_t;\n }\n \n-void leveldb_writeoptions_destroy(leveldb_writeoptions_t* opt) {\n-  delete opt;\n-}\n+void leveldb_writeoptions_destroy(leveldb_writeoptions_t* opt) { delete opt; }\n \n-void leveldb_writeoptions_set_sync(\n-    leveldb_writeoptions_t* opt, unsigned char v) {\n+void leveldb_writeoptions_set_sync(leveldb_writeoptions_t* opt, uint8_t v) {\n   opt->rep.sync = v;\n }\n \n@@ -582,16 +541,22 @@ void leveldb_env_destroy(leveldb_env_t* env) {\n   delete env;\n }\n \n-void leveldb_free(void* ptr) {\n-  free(ptr);\n-}\n+char* leveldb_env_get_test_directory(leveldb_env_t* env) {\n+  std::string result;\n+  if (!env->rep->GetTestDirectory(&result).ok()) {\n+    return nullptr;\n+  }\n \n-int leveldb_major_version() {\n-  return kMajorVersion;\n+  char* buffer = static_cast<char*>(malloc(result.size() + 1));\n+  memcpy(buffer, result.data(), result.size());\n+  buffer[result.size()] = '\\0';\n+  return buffer;\n }\n \n-int leveldb_minor_version() {\n-  return kMinorVersion;\n-}\n+void leveldb_free(void* ptr) { free(ptr); }\n+\n+int leveldb_major_version() { return kMajorVersion; }\n+\n+int leveldb_minor_version() { return kMinorVersion; }\n \n }  // end extern \"C\""
      },
      {
        "sha": "16c77eed6ad2a51445e93e31d3f52c78531c3c07",
        "filename": "src/leveldb/db/c_test.c",
        "status": "modified",
        "additions": 15,
        "deletions": 21,
        "changes": 36,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/c_test.c",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/c_test.c",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/c_test.c?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -8,24 +8,14 @@\n #include <stdio.h>\n #include <stdlib.h>\n #include <string.h>\n-#include <sys/types.h>\n-#include <unistd.h>\n \n const char* phase = \"\";\n-static char dbname[200];\n \n static void StartPhase(const char* name) {\n   fprintf(stderr, \"=== Test %s\\n\", name);\n   phase = name;\n }\n \n-static const char* GetTempDir(void) {\n-    const char* ret = getenv(\"TEST_TMPDIR\");\n-    if (ret == NULL || ret[0] == '\\0')\n-        ret = \"/tmp\";\n-    return ret;\n-}\n-\n #define CheckNoError(err)                                               \\\n   if ((err) != NULL) {                                                  \\\n     fprintf(stderr, \"%s:%d: %s: %s\\n\", __FILE__, __LINE__, phase, (err)); \\\n@@ -130,7 +120,7 @@ static const char* CmpName(void* arg) {\n }\n \n // Custom filter policy\n-static unsigned char fake_filter_result = 1;\n+static uint8_t fake_filter_result = 1;\n static void FilterDestroy(void* arg) { }\n static const char* FilterName(void* arg) {\n   return \"TestFilter\";\n@@ -145,10 +135,8 @@ static char* FilterCreate(\n   memcpy(result, \"fake\", 4);\n   return result;\n }\n-unsigned char FilterKeyMatch(\n-    void* arg,\n-    const char* key, size_t length,\n-    const char* filter, size_t filter_length) {\n+uint8_t FilterKeyMatch(void* arg, const char* key, size_t length,\n+                       const char* filter, size_t filter_length) {\n   CheckCondition(filter_length == 4);\n   CheckCondition(memcmp(filter, \"fake\", 4) == 0);\n   return fake_filter_result;\n@@ -162,21 +150,19 @@ int main(int argc, char** argv) {\n   leveldb_options_t* options;\n   leveldb_readoptions_t* roptions;\n   leveldb_writeoptions_t* woptions;\n+  char* dbname;\n   char* err = NULL;\n   int run = -1;\n \n   CheckCondition(leveldb_major_version() >= 1);\n   CheckCondition(leveldb_minor_version() >= 1);\n \n-  snprintf(dbname, sizeof(dbname),\n-           \"%s/leveldb_c_test-%d\",\n-           GetTempDir(),\n-           ((int) geteuid()));\n-\n   StartPhase(\"create_objects\");\n   cmp = leveldb_comparator_create(NULL, CmpDestroy, CmpCompare, CmpName);\n   env = leveldb_create_default_env();\n   cache = leveldb_cache_create_lru(100000);\n+  dbname = leveldb_env_get_test_directory(env);\n+  CheckCondition(dbname != NULL);\n \n   options = leveldb_options_create();\n   leveldb_options_set_comparator(options, cmp);\n@@ -189,6 +175,7 @@ int main(int argc, char** argv) {\n   leveldb_options_set_max_open_files(options, 10);\n   leveldb_options_set_block_size(options, 1024);\n   leveldb_options_set_block_restart_interval(options, 8);\n+  leveldb_options_set_max_file_size(options, 3 << 20);\n   leveldb_options_set_compression(options, leveldb_no_compression);\n \n   roptions = leveldb_readoptions_create();\n@@ -239,12 +226,18 @@ int main(int argc, char** argv) {\n     leveldb_writebatch_clear(wb);\n     leveldb_writebatch_put(wb, \"bar\", 3, \"b\", 1);\n     leveldb_writebatch_put(wb, \"box\", 3, \"c\", 1);\n-    leveldb_writebatch_delete(wb, \"bar\", 3);\n+\n+    leveldb_writebatch_t* wb2 = leveldb_writebatch_create();\n+    leveldb_writebatch_delete(wb2, \"bar\", 3);\n+    leveldb_writebatch_append(wb, wb2);\n+    leveldb_writebatch_destroy(wb2);\n+\n     leveldb_write(db, woptions, wb, &err);\n     CheckNoError(err);\n     CheckGet(db, roptions, \"foo\", \"hello\");\n     CheckGet(db, roptions, \"bar\", NULL);\n     CheckGet(db, roptions, \"box\", \"c\");\n+\n     int pos = 0;\n     leveldb_writebatch_iterate(wb, &pos, CheckPut, CheckDel);\n     CheckCondition(pos == 3);\n@@ -381,6 +374,7 @@ int main(int argc, char** argv) {\n   leveldb_options_destroy(options);\n   leveldb_readoptions_destroy(roptions);\n   leveldb_writeoptions_destroy(woptions);\n+  leveldb_free(dbname);\n   leveldb_cache_destroy(cache);\n   leveldb_comparator_destroy(cmp);\n   leveldb_env_destroy(env);"
      },
      {
        "sha": "42f5237c659e1c3dd45742152332a007f6f6bca6",
        "filename": "src/leveldb/db/corruption_test.cc",
        "status": "modified",
        "additions": 44,
        "deletions": 56,
        "changes": 100,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/corruption_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/corruption_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/corruption_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -2,20 +2,16 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include \"leveldb/db.h\"\n-\n-#include <errno.h>\n-#include <fcntl.h>\n-#include <sys/stat.h>\n #include <sys/types.h>\n-#include \"leveldb/cache.h\"\n-#include \"leveldb/env.h\"\n-#include \"leveldb/table.h\"\n-#include \"leveldb/write_batch.h\"\n+\n #include \"db/db_impl.h\"\n #include \"db/filename.h\"\n #include \"db/log_format.h\"\n #include \"db/version_set.h\"\n+#include \"leveldb/cache.h\"\n+#include \"leveldb/db.h\"\n+#include \"leveldb/table.h\"\n+#include \"leveldb/write_batch.h\"\n #include \"util/logging.h\"\n #include \"util/testharness.h\"\n #include \"util/testutil.h\"\n@@ -26,52 +22,43 @@ static const int kValueSize = 1000;\n \n class CorruptionTest {\n  public:\n-  test::ErrorEnv env_;\n-  std::string dbname_;\n-  Cache* tiny_cache_;\n-  Options options_;\n-  DB* db_;\n-\n-  CorruptionTest() {\n-    tiny_cache_ = NewLRUCache(100);\n+  CorruptionTest()\n+      : db_(nullptr),\n+        dbname_(\"/memenv/corruption_test\"),\n+        tiny_cache_(NewLRUCache(100)) {\n     options_.env = &env_;\n     options_.block_cache = tiny_cache_;\n-    dbname_ = test::TmpDir() + \"/corruption_test\";\n     DestroyDB(dbname_, options_);\n \n-    db_ = NULL;\n     options_.create_if_missing = true;\n     Reopen();\n     options_.create_if_missing = false;\n   }\n \n   ~CorruptionTest() {\n-     delete db_;\n-     DestroyDB(dbname_, Options());\n-     delete tiny_cache_;\n+    delete db_;\n+    delete tiny_cache_;\n   }\n \n   Status TryReopen() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     return DB::Open(options_, dbname_, &db_);\n   }\n \n-  void Reopen() {\n-    ASSERT_OK(TryReopen());\n-  }\n+  void Reopen() { ASSERT_OK(TryReopen()); }\n \n   void RepairDB() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     ASSERT_OK(::leveldb::RepairDB(dbname_, options_));\n   }\n \n   void Build(int n) {\n     std::string key_space, value_space;\n     WriteBatch batch;\n     for (int i = 0; i < n; i++) {\n-      //if ((i % 100) == 0) fprintf(stderr, \"@ %d of %d\\n\", i, n);\n+      // if ((i % 100) == 0) fprintf(stderr, \"@ %d of %d\\n\", i, n);\n       Slice key = Key(i, &key_space);\n       batch.Clear();\n       batch.Put(key, Value(i, &value_space));\n@@ -100,8 +87,7 @@ class CorruptionTest {\n         // Ignore boundary keys.\n         continue;\n       }\n-      if (!ConsumeDecimalNumber(&in, &key) ||\n-          !in.empty() ||\n+      if (!ConsumeDecimalNumber(&in, &key) || !in.empty() ||\n           key < next_expected) {\n         bad_keys++;\n         continue;\n@@ -126,50 +112,46 @@ class CorruptionTest {\n   void Corrupt(FileType filetype, int offset, int bytes_to_corrupt) {\n     // Pick file to corrupt\n     std::vector<std::string> filenames;\n-    ASSERT_OK(env_.GetChildren(dbname_, &filenames));\n+    ASSERT_OK(env_.target()->GetChildren(dbname_, &filenames));\n     uint64_t number;\n     FileType type;\n     std::string fname;\n     int picked_number = -1;\n     for (size_t i = 0; i < filenames.size(); i++) {\n-      if (ParseFileName(filenames[i], &number, &type) &&\n-          type == filetype &&\n+      if (ParseFileName(filenames[i], &number, &type) && type == filetype &&\n           int(number) > picked_number) {  // Pick latest file\n         fname = dbname_ + \"/\" + filenames[i];\n         picked_number = number;\n       }\n     }\n     ASSERT_TRUE(!fname.empty()) << filetype;\n \n-    struct stat sbuf;\n-    if (stat(fname.c_str(), &sbuf) != 0) {\n-      const char* msg = strerror(errno);\n-      ASSERT_TRUE(false) << fname << \": \" << msg;\n-    }\n+    uint64_t file_size;\n+    ASSERT_OK(env_.target()->GetFileSize(fname, &file_size));\n \n     if (offset < 0) {\n       // Relative to end of file; make it absolute\n-      if (-offset > sbuf.st_size) {\n+      if (-offset > file_size) {\n         offset = 0;\n       } else {\n-        offset = sbuf.st_size + offset;\n+        offset = file_size + offset;\n       }\n     }\n-    if (offset > sbuf.st_size) {\n-      offset = sbuf.st_size;\n+    if (offset > file_size) {\n+      offset = file_size;\n     }\n-    if (offset + bytes_to_corrupt > sbuf.st_size) {\n-      bytes_to_corrupt = sbuf.st_size - offset;\n+    if (offset + bytes_to_corrupt > file_size) {\n+      bytes_to_corrupt = file_size - offset;\n     }\n \n     // Do it\n     std::string contents;\n-    Status s = ReadFileToString(Env::Default(), fname, &contents);\n+    Status s = ReadFileToString(env_.target(), fname, &contents);\n     ASSERT_TRUE(s.ok()) << s.ToString();\n     for (int i = 0; i < bytes_to_corrupt; i++) {\n       contents[i + offset] ^= 0x80;\n     }\n-    s = WriteStringToFile(Env::Default(), contents, fname);\n+    s = WriteStringToFile(env_.target(), contents, fname);\n     ASSERT_TRUE(s.ok()) << s.ToString();\n   }\n \n@@ -197,12 +179,20 @@ class CorruptionTest {\n     Random r(k);\n     return test::RandomString(&r, kValueSize, storage);\n   }\n+\n+  test::ErrorEnv env_;\n+  Options options_;\n+  DB* db_;\n+\n+ private:\n+  std::string dbname_;\n+  Cache* tiny_cache_;\n };\n \n TEST(CorruptionTest, Recovery) {\n   Build(100);\n   Check(100, 100);\n-  Corrupt(kLogFile, 19, 1);      // WriteBatch tag for first record\n+  Corrupt(kLogFile, 19, 1);  // WriteBatch tag for first record\n   Corrupt(kLogFile, log::kBlockSize + 1000, 1);  // Somewhere in second block\n   Reopen();\n \n@@ -237,8 +227,8 @@ TEST(CorruptionTest, TableFile) {\n   Build(100);\n   DBImpl* dbi = reinterpret_cast<DBImpl*>(db_);\n   dbi->TEST_CompactMemTable();\n-  dbi->TEST_CompactRange(0, NULL, NULL);\n-  dbi->TEST_CompactRange(1, NULL, NULL);\n+  dbi->TEST_CompactRange(0, nullptr, nullptr);\n+  dbi->TEST_CompactRange(1, nullptr, nullptr);\n \n   Corrupt(kTableFile, 100, 1);\n   Check(90, 99);\n@@ -251,8 +241,8 @@ TEST(CorruptionTest, TableFileRepair) {\n   Build(100);\n   DBImpl* dbi = reinterpret_cast<DBImpl*>(db_);\n   dbi->TEST_CompactMemTable();\n-  dbi->TEST_CompactRange(0, NULL, NULL);\n-  dbi->TEST_CompactRange(1, NULL, NULL);\n+  dbi->TEST_CompactRange(0, nullptr, nullptr);\n+  dbi->TEST_CompactRange(1, nullptr, nullptr);\n \n   Corrupt(kTableFile, 100, 1);\n   RepairDB();\n@@ -302,7 +292,7 @@ TEST(CorruptionTest, CorruptedDescriptor) {\n   ASSERT_OK(db_->Put(WriteOptions(), \"foo\", \"hello\"));\n   DBImpl* dbi = reinterpret_cast<DBImpl*>(db_);\n   dbi->TEST_CompactMemTable();\n-  dbi->TEST_CompactRange(0, NULL, NULL);\n+  dbi->TEST_CompactRange(0, nullptr, nullptr);\n \n   Corrupt(kDescriptorFile, 0, 1000);\n   Status s = TryReopen();\n@@ -343,7 +333,7 @@ TEST(CorruptionTest, CompactionInputErrorParanoid) {\n     Corrupt(kTableFile, 100, 1);\n     env_.SleepForMicroseconds(100000);\n   }\n-  dbi->CompactRange(NULL, NULL);\n+  dbi->CompactRange(nullptr, nullptr);\n \n   // Write must fail because of corrupted table\n   std::string tmp1, tmp2;\n@@ -369,6 +359,4 @@ TEST(CorruptionTest, UnrelatedKeys) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "65e31724bcec1b6e80480d928f129b21be59fba1",
        "filename": "src/leveldb/db/db_impl.cc",
        "status": "modified",
        "additions": 267,
        "deletions": 280,
        "changes": 547,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/db_impl.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/db_impl.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/db_impl.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -4,12 +4,15 @@\n \n #include \"db/db_impl.h\"\n \n+#include <stdint.h>\n+#include <stdio.h>\n+\n #include <algorithm>\n+#include <atomic>\n #include <set>\n #include <string>\n-#include <stdint.h>\n-#include <stdio.h>\n #include <vector>\n+\n #include \"db/builder.h\"\n #include \"db/db_iter.h\"\n #include \"db/dbformat.h\"\n@@ -39,16 +42,33 @@ const int kNumNonTableCacheFiles = 10;\n \n // Information kept for every waiting writer\n struct DBImpl::Writer {\n+  explicit Writer(port::Mutex* mu)\n+      : batch(nullptr), sync(false), done(false), cv(mu) {}\n+\n   Status status;\n   WriteBatch* batch;\n   bool sync;\n   bool done;\n   port::CondVar cv;\n-\n-  explicit Writer(port::Mutex* mu) : cv(mu) { }\n };\n \n struct DBImpl::CompactionState {\n+  // Files produced by compaction\n+  struct Output {\n+    uint64_t number;\n+    uint64_t file_size;\n+    InternalKey smallest, largest;\n+  };\n+\n+  Output* current_output() { return &outputs[outputs.size() - 1]; }\n+\n+  explicit CompactionState(Compaction* c)\n+      : compaction(c),\n+        smallest_snapshot(0),\n+        outfile(nullptr),\n+        builder(nullptr),\n+        total_bytes(0) {}\n+\n   Compaction* const compaction;\n \n   // Sequence numbers < smallest_snapshot are not significant since we\n@@ -57,32 +77,17 @@ struct DBImpl::CompactionState {\n   // we can drop all entries for the same key with sequence numbers < S.\n   SequenceNumber smallest_snapshot;\n \n-  // Files produced by compaction\n-  struct Output {\n-    uint64_t number;\n-    uint64_t file_size;\n-    InternalKey smallest, largest;\n-  };\n   std::vector<Output> outputs;\n \n   // State kept for output being generated\n   WritableFile* outfile;\n   TableBuilder* builder;\n \n   uint64_t total_bytes;\n-\n-  Output* current_output() { return &outputs[outputs.size()-1]; }\n-\n-  explicit CompactionState(Compaction* c)\n-      : compaction(c),\n-        outfile(NULL),\n-        builder(NULL),\n-        total_bytes(0) {\n-  }\n };\n \n // Fix user-supplied options to be reasonable\n-template <class T,class V>\n+template <class T, class V>\n static void ClipToRange(T* ptr, V minvalue, V maxvalue) {\n   if (static_cast<V>(*ptr) > maxvalue) *ptr = maxvalue;\n   if (static_cast<V>(*ptr) < minvalue) *ptr = minvalue;\n@@ -93,27 +98,32 @@ Options SanitizeOptions(const std::string& dbname,\n                         const Options& src) {\n   Options result = src;\n   result.comparator = icmp;\n-  result.filter_policy = (src.filter_policy != NULL) ? ipolicy : NULL;\n-  ClipToRange(&result.max_open_files,    64 + kNumNonTableCacheFiles, 50000);\n-  ClipToRange(&result.write_buffer_size, 64<<10,                      1<<30);\n-  ClipToRange(&result.max_file_size,     1<<20,                       1<<30);\n-  ClipToRange(&result.block_size,        1<<10,                       4<<20);\n-  if (result.info_log == NULL) {\n+  result.filter_policy = (src.filter_policy != nullptr) ? ipolicy : nullptr;\n+  ClipToRange(&result.max_open_files, 64 + kNumNonTableCacheFiles, 50000);\n+  ClipToRange(&result.write_buffer_size, 64 << 10, 1 << 30);\n+  ClipToRange(&result.max_file_size, 1 << 20, 1 << 30);\n+  ClipToRange(&result.block_size, 1 << 10, 4 << 20);\n+  if (result.info_log == nullptr) {\n     // Open a log file in the same directory as the db\n     src.env->CreateDir(dbname);  // In case it does not exist\n     src.env->RenameFile(InfoLogFileName(dbname), OldInfoLogFileName(dbname));\n     Status s = src.env->NewLogger(InfoLogFileName(dbname), &result.info_log);\n     if (!s.ok()) {\n       // No place suitable for logging\n-      result.info_log = NULL;\n+      result.info_log = nullptr;\n     }\n   }\n-  if (result.block_cache == NULL) {\n+  if (result.block_cache == nullptr) {\n     result.block_cache = NewLRUCache(8 << 20);\n   }\n   return result;\n }\n \n+static int TableCacheSize(const Options& sanitized_options) {\n+  // Reserve ten files or so for other uses and give the rest to TableCache.\n+  return sanitized_options.max_open_files - kNumNonTableCacheFiles;\n+}\n+\n DBImpl::DBImpl(const Options& raw_options, const std::string& dbname)\n     : env_(raw_options.env),\n       internal_comparator_(raw_options.comparator),\n@@ -123,44 +133,39 @@ DBImpl::DBImpl(const Options& raw_options, const std::string& dbname)\n       owns_info_log_(options_.info_log != raw_options.info_log),\n       owns_cache_(options_.block_cache != raw_options.block_cache),\n       dbname_(dbname),\n-      db_lock_(NULL),\n-      shutting_down_(NULL),\n-      bg_cv_(&mutex_),\n-      mem_(NULL),\n-      imm_(NULL),\n-      logfile_(NULL),\n+      table_cache_(new TableCache(dbname_, options_, TableCacheSize(options_))),\n+      db_lock_(nullptr),\n+      shutting_down_(false),\n+      background_work_finished_signal_(&mutex_),\n+      mem_(nullptr),\n+      imm_(nullptr),\n+      has_imm_(false),\n+      logfile_(nullptr),\n       logfile_number_(0),\n-      log_(NULL),\n+      log_(nullptr),\n       seed_(0),\n       tmp_batch_(new WriteBatch),\n-      bg_compaction_scheduled_(false),\n-      manual_compaction_(NULL) {\n-  has_imm_.Release_Store(NULL);\n-\n-  // Reserve ten files or so for other uses and give the rest to TableCache.\n-  const int table_cache_size = options_.max_open_files - kNumNonTableCacheFiles;\n-  table_cache_ = new TableCache(dbname_, &options_, table_cache_size);\n-\n-  versions_ = new VersionSet(dbname_, &options_, table_cache_,\n-                             &internal_comparator_);\n-}\n+      background_compaction_scheduled_(false),\n+      manual_compaction_(nullptr),\n+      versions_(new VersionSet(dbname_, &options_, table_cache_,\n+                               &internal_comparator_)) {}\n \n DBImpl::~DBImpl() {\n-  // Wait for background work to finish\n+  // Wait for background work to finish.\n   mutex_.Lock();\n-  shutting_down_.Release_Store(this);  // Any non-NULL value is ok\n-  while (bg_compaction_scheduled_) {\n-    bg_cv_.Wait();\n+  shutting_down_.store(true, std::memory_order_release);\n+  while (background_compaction_scheduled_) {\n+    background_work_finished_signal_.Wait();\n   }\n   mutex_.Unlock();\n \n-  if (db_lock_ != NULL) {\n+  if (db_lock_ != nullptr) {\n     env_->UnlockFile(db_lock_);\n   }\n \n   delete versions_;\n-  if (mem_ != NULL) mem_->Unref();\n-  if (imm_ != NULL) imm_->Unref();\n+  if (mem_ != nullptr) mem_->Unref();\n+  if (imm_ != nullptr) imm_->Unref();\n   delete tmp_batch_;\n   delete log_;\n   delete logfile_;\n@@ -216,6 +221,8 @@ void DBImpl::MaybeIgnoreError(Status* s) const {\n }\n \n void DBImpl::DeleteObsoleteFiles() {\n+  mutex_.AssertHeld();\n+\n   if (!bg_error_.ok()) {\n     // After a background error, we don't know whether a new version may\n     // or may not have been committed, so we cannot safely garbage collect.\n@@ -227,11 +234,12 @@ void DBImpl::DeleteObsoleteFiles() {\n   versions_->AddLiveFiles(&live);\n \n   std::vector<std::string> filenames;\n-  env_->GetChildren(dbname_, &filenames); // Ignoring errors on purpose\n+  env_->GetChildren(dbname_, &filenames);  // Ignoring errors on purpose\n   uint64_t number;\n   FileType type;\n-  for (size_t i = 0; i < filenames.size(); i++) {\n-    if (ParseFileName(filenames[i], &number, &type)) {\n+  std::vector<std::string> files_to_delete;\n+  for (std::string& filename : filenames) {\n+    if (ParseFileName(filename, &number, &type)) {\n       bool keep = true;\n       switch (type) {\n         case kLogFile:\n@@ -259,26 +267,34 @@ void DBImpl::DeleteObsoleteFiles() {\n       }\n \n       if (!keep) {\n+        files_to_delete.push_back(std::move(filename));\n         if (type == kTableFile) {\n           table_cache_->Evict(number);\n         }\n-        Log(options_.info_log, \"Delete type=%d #%lld\\n\",\n-            int(type),\n+        Log(options_.info_log, \"Delete type=%d #%lld\\n\", static_cast<int>(type),\n             static_cast<unsigned long long>(number));\n-        env_->DeleteFile(dbname_ + \"/\" + filenames[i]);\n       }\n     }\n   }\n+\n+  // While deleting all files unblock other threads. All files being deleted\n+  // have unique names which will not collide with newly created files and\n+  // are therefore safe to delete while allowing other threads to proceed.\n+  mutex_.Unlock();\n+  for (const std::string& filename : files_to_delete) {\n+    env_->DeleteFile(dbname_ + \"/\" + filename);\n+  }\n+  mutex_.Lock();\n }\n \n-Status DBImpl::Recover(VersionEdit* edit, bool *save_manifest) {\n+Status DBImpl::Recover(VersionEdit* edit, bool* save_manifest) {\n   mutex_.AssertHeld();\n \n   // Ignore error from CreateDir since the creation of the DB is\n   // committed only when the descriptor is created, and this directory\n   // may already exist from a previous failed creation attempt.\n   env_->CreateDir(dbname_);\n-  assert(db_lock_ == NULL);\n+  assert(db_lock_ == nullptr);\n   Status s = env_->LockFile(LockFileName(dbname_), &db_lock_);\n   if (!s.ok()) {\n     return s;\n@@ -296,8 +312,8 @@ Status DBImpl::Recover(VersionEdit* edit, bool *save_manifest) {\n     }\n   } else {\n     if (options_.error_if_exists) {\n-      return Status::InvalidArgument(\n-          dbname_, \"exists (error_if_exists is true)\");\n+      return Status::InvalidArgument(dbname_,\n+                                     \"exists (error_if_exists is true)\");\n     }\n   }\n \n@@ -369,12 +385,12 @@ Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log,\n     Env* env;\n     Logger* info_log;\n     const char* fname;\n-    Status* status;  // NULL if options_.paranoid_checks==false\n-    virtual void Corruption(size_t bytes, const Status& s) {\n+    Status* status;  // null if options_.paranoid_checks==false\n+    void Corruption(size_t bytes, const Status& s) override {\n       Log(info_log, \"%s%s: dropping %d bytes; %s\",\n-          (this->status == NULL ? \"(ignoring error) \" : \"\"),\n-          fname, static_cast<int>(bytes), s.ToString().c_str());\n-      if (this->status != NULL && this->status->ok()) *this->status = s;\n+          (this->status == nullptr ? \"(ignoring error) \" : \"\"), fname,\n+          static_cast<int>(bytes), s.ToString().c_str());\n+      if (this->status != nullptr && this->status->ok()) *this->status = s;\n     }\n   };\n \n@@ -394,32 +410,30 @@ Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log,\n   reporter.env = env_;\n   reporter.info_log = options_.info_log;\n   reporter.fname = fname.c_str();\n-  reporter.status = (options_.paranoid_checks ? &status : NULL);\n+  reporter.status = (options_.paranoid_checks ? &status : nullptr);\n   // We intentionally make log::Reader do checksumming even if\n   // paranoid_checks==false so that corruptions cause entire commits\n   // to be skipped instead of propagating bad information (like overly\n   // large sequence numbers).\n-  log::Reader reader(file, &reporter, true/*checksum*/,\n-                     0/*initial_offset*/);\n+  log::Reader reader(file, &reporter, true /*checksum*/, 0 /*initial_offset*/);\n   Log(options_.info_log, \"Recovering log #%llu\",\n-      (unsigned long long) log_number);\n+      (unsigned long long)log_number);\n \n   // Read all the records and add to a memtable\n   std::string scratch;\n   Slice record;\n   WriteBatch batch;\n   int compactions = 0;\n-  MemTable* mem = NULL;\n-  while (reader.ReadRecord(&record, &scratch) &&\n-         status.ok()) {\n+  MemTable* mem = nullptr;\n+  while (reader.ReadRecord(&record, &scratch) && status.ok()) {\n     if (record.size() < 12) {\n-      reporter.Corruption(\n-          record.size(), Status::Corruption(\"log record too small\", fname));\n+      reporter.Corruption(record.size(),\n+                          Status::Corruption(\"log record too small\", fname));\n       continue;\n     }\n     WriteBatchInternal::SetContents(&batch, record);\n \n-    if (mem == NULL) {\n+    if (mem == nullptr) {\n       mem = new MemTable(internal_comparator_);\n       mem->Ref();\n     }\n@@ -428,19 +442,18 @@ Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log,\n     if (!status.ok()) {\n       break;\n     }\n-    const SequenceNumber last_seq =\n-        WriteBatchInternal::Sequence(&batch) +\n-        WriteBatchInternal::Count(&batch) - 1;\n+    const SequenceNumber last_seq = WriteBatchInternal::Sequence(&batch) +\n+                                    WriteBatchInternal::Count(&batch) - 1;\n     if (last_seq > *max_sequence) {\n       *max_sequence = last_seq;\n     }\n \n     if (mem->ApproximateMemoryUsage() > options_.write_buffer_size) {\n       compactions++;\n       *save_manifest = true;\n-      status = WriteLevel0Table(mem, edit, NULL);\n+      status = WriteLevel0Table(mem, edit, nullptr);\n       mem->Unref();\n-      mem = NULL;\n+      mem = nullptr;\n       if (!status.ok()) {\n         // Reflect errors immediately so that conditions like full\n         // file-systems cause the DB::Open() to fail.\n@@ -453,31 +466,31 @@ Status DBImpl::RecoverLogFile(uint64_t log_number, bool last_log,\n \n   // See if we should keep reusing the last log file.\n   if (status.ok() && options_.reuse_logs && last_log && compactions == 0) {\n-    assert(logfile_ == NULL);\n-    assert(log_ == NULL);\n-    assert(mem_ == NULL);\n+    assert(logfile_ == nullptr);\n+    assert(log_ == nullptr);\n+    assert(mem_ == nullptr);\n     uint64_t lfile_size;\n     if (env_->GetFileSize(fname, &lfile_size).ok() &&\n         env_->NewAppendableFile(fname, &logfile_).ok()) {\n       Log(options_.info_log, \"Reusing old log %s \\n\", fname.c_str());\n       log_ = new log::Writer(logfile_, lfile_size);\n       logfile_number_ = log_number;\n-      if (mem != NULL) {\n+      if (mem != nullptr) {\n         mem_ = mem;\n-        mem = NULL;\n+        mem = nullptr;\n       } else {\n-        // mem can be NULL if lognum exists but was empty.\n+        // mem can be nullptr if lognum exists but was empty.\n         mem_ = new MemTable(internal_comparator_);\n         mem_->Ref();\n       }\n     }\n   }\n \n-  if (mem != NULL) {\n+  if (mem != nullptr) {\n     // mem did not get reused; compact it.\n     if (status.ok()) {\n       *save_manifest = true;\n-      status = WriteLevel0Table(mem, edit, NULL);\n+      status = WriteLevel0Table(mem, edit, nullptr);\n     }\n     mem->Unref();\n   }\n@@ -494,7 +507,7 @@ Status DBImpl::WriteLevel0Table(MemTable* mem, VersionEdit* edit,\n   pending_outputs_.insert(meta.number);\n   Iterator* iter = mem->NewIterator();\n   Log(options_.info_log, \"Level-0 table #%llu: started\",\n-      (unsigned long long) meta.number);\n+      (unsigned long long)meta.number);\n \n   Status s;\n   {\n@@ -504,24 +517,22 @@ Status DBImpl::WriteLevel0Table(MemTable* mem, VersionEdit* edit,\n   }\n \n   Log(options_.info_log, \"Level-0 table #%llu: %lld bytes %s\",\n-      (unsigned long long) meta.number,\n-      (unsigned long long) meta.file_size,\n+      (unsigned long long)meta.number, (unsigned long long)meta.file_size,\n       s.ToString().c_str());\n   delete iter;\n   pending_outputs_.erase(meta.number);\n \n-\n   // Note that if file_size is zero, the file has been deleted and\n   // should not be added to the manifest.\n   int level = 0;\n   if (s.ok() && meta.file_size > 0) {\n     const Slice min_user_key = meta.smallest.user_key();\n     const Slice max_user_key = meta.largest.user_key();\n-    if (base != NULL) {\n+    if (base != nullptr) {\n       level = base->PickLevelForMemTableOutput(min_user_key, max_user_key);\n     }\n-    edit->AddFile(level, meta.number, meta.file_size,\n-                  meta.smallest, meta.largest);\n+    edit->AddFile(level, meta.number, meta.file_size, meta.smallest,\n+                  meta.largest);\n   }\n \n   CompactionStats stats;\n@@ -533,7 +544,7 @@ Status DBImpl::WriteLevel0Table(MemTable* mem, VersionEdit* edit,\n \n void DBImpl::CompactMemTable() {\n   mutex_.AssertHeld();\n-  assert(imm_ != NULL);\n+  assert(imm_ != nullptr);\n \n   // Save the contents of the memtable as a new Table\n   VersionEdit edit;\n@@ -542,7 +553,7 @@ void DBImpl::CompactMemTable() {\n   Status s = WriteLevel0Table(imm_, &edit, base);\n   base->Unref();\n \n-  if (s.ok() && shutting_down_.Acquire_Load()) {\n+  if (s.ok() && shutting_down_.load(std::memory_order_acquire)) {\n     s = Status::IOError(\"Deleting DB during memtable compaction\");\n   }\n \n@@ -556,8 +567,8 @@ void DBImpl::CompactMemTable() {\n   if (s.ok()) {\n     // Commit to the new state\n     imm_->Unref();\n-    imm_ = NULL;\n-    has_imm_.Release_Store(NULL);\n+    imm_ = nullptr;\n+    has_imm_.store(false, std::memory_order_release);\n     DeleteObsoleteFiles();\n   } else {\n     RecordBackgroundError(s);\n@@ -575,13 +586,14 @@ void DBImpl::CompactRange(const Slice* begin, const Slice* end) {\n       }\n     }\n   }\n-  TEST_CompactMemTable(); // TODO(sanjay): Skip if memtable does not overlap\n+  TEST_CompactMemTable();  // TODO(sanjay): Skip if memtable does not overlap\n   for (int level = 0; level < max_level_with_files; level++) {\n     TEST_CompactRange(level, begin, end);\n   }\n }\n \n-void DBImpl::TEST_CompactRange(int level, const Slice* begin,const Slice* end) {\n+void DBImpl::TEST_CompactRange(int level, const Slice* begin,\n+                               const Slice* end) {\n   assert(level >= 0);\n   assert(level + 1 < config::kNumLevels);\n \n@@ -590,44 +602,45 @@ void DBImpl::TEST_CompactRange(int level, const Slice* begin,const Slice* end) {\n   ManualCompaction manual;\n   manual.level = level;\n   manual.done = false;\n-  if (begin == NULL) {\n-    manual.begin = NULL;\n+  if (begin == nullptr) {\n+    manual.begin = nullptr;\n   } else {\n     begin_storage = InternalKey(*begin, kMaxSequenceNumber, kValueTypeForSeek);\n     manual.begin = &begin_storage;\n   }\n-  if (end == NULL) {\n-    manual.end = NULL;\n+  if (end == nullptr) {\n+    manual.end = nullptr;\n   } else {\n     end_storage = InternalKey(*end, 0, static_cast<ValueType>(0));\n     manual.end = &end_storage;\n   }\n \n   MutexLock l(&mutex_);\n-  while (!manual.done && !shutting_down_.Acquire_Load() && bg_error_.ok()) {\n-    if (manual_compaction_ == NULL) {  // Idle\n+  while (!manual.done && !shutting_down_.load(std::memory_order_acquire) &&\n+         bg_error_.ok()) {\n+    if (manual_compaction_ == nullptr) {  // Idle\n       manual_compaction_ = &manual;\n       MaybeScheduleCompaction();\n     } else {  // Running either my compaction or another compaction.\n-      bg_cv_.Wait();\n+      background_work_finished_signal_.Wait();\n     }\n   }\n   if (manual_compaction_ == &manual) {\n     // Cancel my manual compaction since we aborted early for some reason.\n-    manual_compaction_ = NULL;\n+    manual_compaction_ = nullptr;\n   }\n }\n \n Status DBImpl::TEST_CompactMemTable() {\n-  // NULL batch means just wait for earlier writes to be done\n-  Status s = Write(WriteOptions(), NULL);\n+  // nullptr batch means just wait for earlier writes to be done\n+  Status s = Write(WriteOptions(), nullptr);\n   if (s.ok()) {\n     // Wait until the compaction completes\n     MutexLock l(&mutex_);\n-    while (imm_ != NULL && bg_error_.ok()) {\n-      bg_cv_.Wait();\n+    while (imm_ != nullptr && bg_error_.ok()) {\n+      background_work_finished_signal_.Wait();\n     }\n-    if (imm_ != NULL) {\n+    if (imm_ != nullptr) {\n       s = bg_error_;\n     }\n   }\n@@ -638,24 +651,23 @@ void DBImpl::RecordBackgroundError(const Status& s) {\n   mutex_.AssertHeld();\n   if (bg_error_.ok()) {\n     bg_error_ = s;\n-    bg_cv_.SignalAll();\n+    background_work_finished_signal_.SignalAll();\n   }\n }\n \n void DBImpl::MaybeScheduleCompaction() {\n   mutex_.AssertHeld();\n-  if (bg_compaction_scheduled_) {\n+  if (background_compaction_scheduled_) {\n     // Already scheduled\n-  } else if (shutting_down_.Acquire_Load()) {\n+  } else if (shutting_down_.load(std::memory_order_acquire)) {\n     // DB is being deleted; no more background compactions\n   } else if (!bg_error_.ok()) {\n     // Already got an error; no more changes\n-  } else if (imm_ == NULL &&\n-             manual_compaction_ == NULL &&\n+  } else if (imm_ == nullptr && manual_compaction_ == nullptr &&\n              !versions_->NeedsCompaction()) {\n     // No work to be done\n   } else {\n-    bg_compaction_scheduled_ = true;\n+    background_compaction_scheduled_ = true;\n     env_->Schedule(&DBImpl::BGWork, this);\n   }\n }\n@@ -666,72 +678,69 @@ void DBImpl::BGWork(void* db) {\n \n void DBImpl::BackgroundCall() {\n   MutexLock l(&mutex_);\n-  assert(bg_compaction_scheduled_);\n-  if (shutting_down_.Acquire_Load()) {\n+  assert(background_compaction_scheduled_);\n+  if (shutting_down_.load(std::memory_order_acquire)) {\n     // No more background work when shutting down.\n   } else if (!bg_error_.ok()) {\n     // No more background work after a background error.\n   } else {\n     BackgroundCompaction();\n   }\n \n-  bg_compaction_scheduled_ = false;\n+  background_compaction_scheduled_ = false;\n \n   // Previous compaction may have produced too many files in a level,\n   // so reschedule another compaction if needed.\n   MaybeScheduleCompaction();\n-  bg_cv_.SignalAll();\n+  background_work_finished_signal_.SignalAll();\n }\n \n void DBImpl::BackgroundCompaction() {\n   mutex_.AssertHeld();\n \n-  if (imm_ != NULL) {\n+  if (imm_ != nullptr) {\n     CompactMemTable();\n     return;\n   }\n \n   Compaction* c;\n-  bool is_manual = (manual_compaction_ != NULL);\n+  bool is_manual = (manual_compaction_ != nullptr);\n   InternalKey manual_end;\n   if (is_manual) {\n     ManualCompaction* m = manual_compaction_;\n     c = versions_->CompactRange(m->level, m->begin, m->end);\n-    m->done = (c == NULL);\n-    if (c != NULL) {\n+    m->done = (c == nullptr);\n+    if (c != nullptr) {\n       manual_end = c->input(0, c->num_input_files(0) - 1)->largest;\n     }\n     Log(options_.info_log,\n         \"Manual compaction at level-%d from %s .. %s; will stop at %s\\n\",\n-        m->level,\n-        (m->begin ? m->begin->DebugString().c_str() : \"(begin)\"),\n+        m->level, (m->begin ? m->begin->DebugString().c_str() : \"(begin)\"),\n         (m->end ? m->end->DebugString().c_str() : \"(end)\"),\n         (m->done ? \"(end)\" : manual_end.DebugString().c_str()));\n   } else {\n     c = versions_->PickCompaction();\n   }\n \n   Status status;\n-  if (c == NULL) {\n+  if (c == nullptr) {\n     // Nothing to do\n   } else if (!is_manual && c->IsTrivialMove()) {\n     // Move file to next level\n     assert(c->num_input_files(0) == 1);\n     FileMetaData* f = c->input(0, 0);\n     c->edit()->DeleteFile(c->level(), f->number);\n-    c->edit()->AddFile(c->level() + 1, f->number, f->file_size,\n-                       f->smallest, f->largest);\n+    c->edit()->AddFile(c->level() + 1, f->number, f->file_size, f->smallest,\n+                       f->largest);\n     status = versions_->LogAndApply(c->edit(), &mutex_);\n     if (!status.ok()) {\n       RecordBackgroundError(status);\n     }\n     VersionSet::LevelSummaryStorage tmp;\n     Log(options_.info_log, \"Moved #%lld to level-%d %lld bytes %s: %s\\n\",\n-        static_cast<unsigned long long>(f->number),\n-        c->level() + 1,\n+        static_cast<unsigned long long>(f->number), c->level() + 1,\n         static_cast<unsigned long long>(f->file_size),\n-        status.ToString().c_str(),\n-        versions_->LevelSummary(&tmp));\n+        status.ToString().c_str(), versions_->LevelSummary(&tmp));\n   } else {\n     CompactionState* compact = new CompactionState(c);\n     status = DoCompactionWork(compact);\n@@ -746,11 +755,10 @@ void DBImpl::BackgroundCompaction() {\n \n   if (status.ok()) {\n     // Done\n-  } else if (shutting_down_.Acquire_Load()) {\n+  } else if (shutting_down_.load(std::memory_order_acquire)) {\n     // Ignore compaction errors found during shutting down\n   } else {\n-    Log(options_.info_log,\n-        \"Compaction error: %s\", status.ToString().c_str());\n+    Log(options_.info_log, \"Compaction error: %s\", status.ToString().c_str());\n   }\n \n   if (is_manual) {\n@@ -764,18 +772,18 @@ void DBImpl::BackgroundCompaction() {\n       m->tmp_storage = manual_end;\n       m->begin = &m->tmp_storage;\n     }\n-    manual_compaction_ = NULL;\n+    manual_compaction_ = nullptr;\n   }\n }\n \n void DBImpl::CleanupCompaction(CompactionState* compact) {\n   mutex_.AssertHeld();\n-  if (compact->builder != NULL) {\n+  if (compact->builder != nullptr) {\n     // May happen if we get a shutdown call in the middle of compaction\n     compact->builder->Abandon();\n     delete compact->builder;\n   } else {\n-    assert(compact->outfile == NULL);\n+    assert(compact->outfile == nullptr);\n   }\n   delete compact->outfile;\n   for (size_t i = 0; i < compact->outputs.size(); i++) {\n@@ -786,8 +794,8 @@ void DBImpl::CleanupCompaction(CompactionState* compact) {\n }\n \n Status DBImpl::OpenCompactionOutputFile(CompactionState* compact) {\n-  assert(compact != NULL);\n-  assert(compact->builder == NULL);\n+  assert(compact != nullptr);\n+  assert(compact->builder == nullptr);\n   uint64_t file_number;\n   {\n     mutex_.Lock();\n@@ -812,9 +820,9 @@ Status DBImpl::OpenCompactionOutputFile(CompactionState* compact) {\n \n Status DBImpl::FinishCompactionOutputFile(CompactionState* compact,\n                                           Iterator* input) {\n-  assert(compact != NULL);\n-  assert(compact->outfile != NULL);\n-  assert(compact->builder != NULL);\n+  assert(compact != nullptr);\n+  assert(compact->outfile != nullptr);\n+  assert(compact->builder != nullptr);\n \n   const uint64_t output_number = compact->current_output()->number;\n   assert(output_number != 0);\n@@ -831,7 +839,7 @@ Status DBImpl::FinishCompactionOutputFile(CompactionState* compact,\n   compact->current_output()->file_size = current_bytes;\n   compact->total_bytes += current_bytes;\n   delete compact->builder;\n-  compact->builder = NULL;\n+  compact->builder = nullptr;\n \n   // Finish and check for file errors\n   if (s.ok()) {\n@@ -841,45 +849,38 @@ Status DBImpl::FinishCompactionOutputFile(CompactionState* compact,\n     s = compact->outfile->Close();\n   }\n   delete compact->outfile;\n-  compact->outfile = NULL;\n+  compact->outfile = nullptr;\n \n   if (s.ok() && current_entries > 0) {\n     // Verify that the table is usable\n-    Iterator* iter = table_cache_->NewIterator(ReadOptions(),\n-                                               output_number,\n-                                               current_bytes);\n+    Iterator* iter =\n+        table_cache_->NewIterator(ReadOptions(), output_number, current_bytes);\n     s = iter->status();\n     delete iter;\n     if (s.ok()) {\n-      Log(options_.info_log,\n-          \"Generated table #%llu@%d: %lld keys, %lld bytes\",\n-          (unsigned long long) output_number,\n-          compact->compaction->level(),\n-          (unsigned long long) current_entries,\n-          (unsigned long long) current_bytes);\n+      Log(options_.info_log, \"Generated table #%llu@%d: %lld keys, %lld bytes\",\n+          (unsigned long long)output_number, compact->compaction->level(),\n+          (unsigned long long)current_entries,\n+          (unsigned long long)current_bytes);\n     }\n   }\n   return s;\n }\n \n-\n Status DBImpl::InstallCompactionResults(CompactionState* compact) {\n   mutex_.AssertHeld();\n-  Log(options_.info_log,  \"Compacted %d@%d + %d@%d files => %lld bytes\",\n-      compact->compaction->num_input_files(0),\n-      compact->compaction->level(),\n-      compact->compaction->num_input_files(1),\n-      compact->compaction->level() + 1,\n+  Log(options_.info_log, \"Compacted %d@%d + %d@%d files => %lld bytes\",\n+      compact->compaction->num_input_files(0), compact->compaction->level(),\n+      compact->compaction->num_input_files(1), compact->compaction->level() + 1,\n       static_cast<long long>(compact->total_bytes));\n \n   // Add compaction outputs\n   compact->compaction->AddInputDeletions(compact->compaction->edit());\n   const int level = compact->compaction->level();\n   for (size_t i = 0; i < compact->outputs.size(); i++) {\n     const CompactionState::Output& out = compact->outputs[i];\n-    compact->compaction->edit()->AddFile(\n-        level + 1,\n-        out.number, out.file_size, out.smallest, out.largest);\n+    compact->compaction->edit()->AddFile(level + 1, out.number, out.file_size,\n+                                         out.smallest, out.largest);\n   }\n   return versions_->LogAndApply(compact->compaction->edit(), &mutex_);\n }\n@@ -888,47 +889,48 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n   const uint64_t start_micros = env_->NowMicros();\n   int64_t imm_micros = 0;  // Micros spent doing imm_ compactions\n \n-  Log(options_.info_log,  \"Compacting %d@%d + %d@%d files\",\n-      compact->compaction->num_input_files(0),\n-      compact->compaction->level(),\n+  Log(options_.info_log, \"Compacting %d@%d + %d@%d files\",\n+      compact->compaction->num_input_files(0), compact->compaction->level(),\n       compact->compaction->num_input_files(1),\n       compact->compaction->level() + 1);\n \n   assert(versions_->NumLevelFiles(compact->compaction->level()) > 0);\n-  assert(compact->builder == NULL);\n-  assert(compact->outfile == NULL);\n+  assert(compact->builder == nullptr);\n+  assert(compact->outfile == nullptr);\n   if (snapshots_.empty()) {\n     compact->smallest_snapshot = versions_->LastSequence();\n   } else {\n-    compact->smallest_snapshot = snapshots_.oldest()->number_;\n+    compact->smallest_snapshot = snapshots_.oldest()->sequence_number();\n   }\n \n+  Iterator* input = versions_->MakeInputIterator(compact->compaction);\n+\n   // Release mutex while we're actually doing the compaction work\n   mutex_.Unlock();\n \n-  Iterator* input = versions_->MakeInputIterator(compact->compaction);\n   input->SeekToFirst();\n   Status status;\n   ParsedInternalKey ikey;\n   std::string current_user_key;\n   bool has_current_user_key = false;\n   SequenceNumber last_sequence_for_key = kMaxSequenceNumber;\n-  for (; input->Valid() && !shutting_down_.Acquire_Load(); ) {\n+  while (input->Valid() && !shutting_down_.load(std::memory_order_acquire)) {\n     // Prioritize immutable compaction work\n-    if (has_imm_.NoBarrier_Load() != NULL) {\n+    if (has_imm_.load(std::memory_order_relaxed)) {\n       const uint64_t imm_start = env_->NowMicros();\n       mutex_.Lock();\n-      if (imm_ != NULL) {\n+      if (imm_ != nullptr) {\n         CompactMemTable();\n-        bg_cv_.SignalAll();  // Wakeup MakeRoomForWrite() if necessary\n+        // Wake up MakeRoomForWrite() if necessary.\n+        background_work_finished_signal_.SignalAll();\n       }\n       mutex_.Unlock();\n       imm_micros += (env_->NowMicros() - imm_start);\n     }\n \n     Slice key = input->key();\n     if (compact->compaction->ShouldStopBefore(key) &&\n-        compact->builder != NULL) {\n+        compact->builder != nullptr) {\n       status = FinishCompactionOutputFile(compact, input);\n       if (!status.ok()) {\n         break;\n@@ -944,8 +946,8 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n       last_sequence_for_key = kMaxSequenceNumber;\n     } else {\n       if (!has_current_user_key ||\n-          user_comparator()->Compare(ikey.user_key,\n-                                     Slice(current_user_key)) != 0) {\n+          user_comparator()->Compare(ikey.user_key, Slice(current_user_key)) !=\n+              0) {\n         // First occurrence of this user key\n         current_user_key.assign(ikey.user_key.data(), ikey.user_key.size());\n         has_current_user_key = true;\n@@ -954,7 +956,7 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n \n       if (last_sequence_for_key <= compact->smallest_snapshot) {\n         // Hidden by an newer entry for same user key\n-        drop = true;    // (A)\n+        drop = true;  // (A)\n       } else if (ikey.type == kTypeDeletion &&\n                  ikey.sequence <= compact->smallest_snapshot &&\n                  compact->compaction->IsBaseLevelForKey(ikey.user_key)) {\n@@ -982,7 +984,7 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n \n     if (!drop) {\n       // Open output file if necessary\n-      if (compact->builder == NULL) {\n+      if (compact->builder == nullptr) {\n         status = OpenCompactionOutputFile(compact);\n         if (!status.ok()) {\n           break;\n@@ -1007,17 +1009,17 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n     input->Next();\n   }\n \n-  if (status.ok() && shutting_down_.Acquire_Load()) {\n+  if (status.ok() && shutting_down_.load(std::memory_order_acquire)) {\n     status = Status::IOError(\"Deleting DB during compaction\");\n   }\n-  if (status.ok() && compact->builder != NULL) {\n+  if (status.ok() && compact->builder != nullptr) {\n     status = FinishCompactionOutputFile(compact, input);\n   }\n   if (status.ok()) {\n     status = input->status();\n   }\n   delete input;\n-  input = NULL;\n+  input = nullptr;\n \n   CompactionStats stats;\n   stats.micros = env_->NowMicros() - start_micros - imm_micros;\n@@ -1040,42 +1042,45 @@ Status DBImpl::DoCompactionWork(CompactionState* compact) {\n     RecordBackgroundError(status);\n   }\n   VersionSet::LevelSummaryStorage tmp;\n-  Log(options_.info_log,\n-      \"compacted to: %s\", versions_->LevelSummary(&tmp));\n+  Log(options_.info_log, \"compacted to: %s\", versions_->LevelSummary(&tmp));\n   return status;\n }\n \n namespace {\n+\n struct IterState {\n-  port::Mutex* mu;\n-  Version* version;\n-  MemTable* mem;\n-  MemTable* imm;\n+  port::Mutex* const mu;\n+  Version* const version GUARDED_BY(mu);\n+  MemTable* const mem GUARDED_BY(mu);\n+  MemTable* const imm GUARDED_BY(mu);\n+\n+  IterState(port::Mutex* mutex, MemTable* mem, MemTable* imm, Version* version)\n+      : mu(mutex), version(version), mem(mem), imm(imm) {}\n };\n \n static void CleanupIteratorState(void* arg1, void* arg2) {\n   IterState* state = reinterpret_cast<IterState*>(arg1);\n   state->mu->Lock();\n   state->mem->Unref();\n-  if (state->imm != NULL) state->imm->Unref();\n+  if (state->imm != nullptr) state->imm->Unref();\n   state->version->Unref();\n   state->mu->Unlock();\n   delete state;\n }\n-}  // namespace\n+\n+}  // anonymous namespace\n \n Iterator* DBImpl::NewInternalIterator(const ReadOptions& options,\n                                       SequenceNumber* latest_snapshot,\n                                       uint32_t* seed) {\n-  IterState* cleanup = new IterState;\n   mutex_.Lock();\n   *latest_snapshot = versions_->LastSequence();\n \n   // Collect together all needed child iterators\n   std::vector<Iterator*> list;\n   list.push_back(mem_->NewIterator());\n   mem_->Ref();\n-  if (imm_ != NULL) {\n+  if (imm_ != nullptr) {\n     list.push_back(imm_->NewIterator());\n     imm_->Ref();\n   }\n@@ -1084,11 +1089,8 @@ Iterator* DBImpl::NewInternalIterator(const ReadOptions& options,\n       NewMergingIterator(&internal_comparator_, &list[0], list.size());\n   versions_->current()->Ref();\n \n-  cleanup->mu = &mutex_;\n-  cleanup->mem = mem_;\n-  cleanup->imm = imm_;\n-  cleanup->version = versions_->current();\n-  internal_iter->RegisterCleanup(CleanupIteratorState, cleanup, NULL);\n+  IterState* cleanup = new IterState(&mutex_, mem_, imm_, versions_->current());\n+  internal_iter->RegisterCleanup(CleanupIteratorState, cleanup, nullptr);\n \n   *seed = ++seed_;\n   mutex_.Unlock();\n@@ -1106,14 +1108,14 @@ int64_t DBImpl::TEST_MaxNextLevelOverlappingBytes() {\n   return versions_->MaxNextLevelOverlappingBytes();\n }\n \n-Status DBImpl::Get(const ReadOptions& options,\n-                   const Slice& key,\n+Status DBImpl::Get(const ReadOptions& options, const Slice& key,\n                    std::string* value) {\n   Status s;\n   MutexLock l(&mutex_);\n   SequenceNumber snapshot;\n-  if (options.snapshot != NULL) {\n-    snapshot = reinterpret_cast<const SnapshotImpl*>(options.snapshot)->number_;\n+  if (options.snapshot != nullptr) {\n+    snapshot =\n+        static_cast<const SnapshotImpl*>(options.snapshot)->sequence_number();\n   } else {\n     snapshot = versions_->LastSequence();\n   }\n@@ -1122,7 +1124,7 @@ Status DBImpl::Get(const ReadOptions& options,\n   MemTable* imm = imm_;\n   Version* current = versions_->current();\n   mem->Ref();\n-  if (imm != NULL) imm->Ref();\n+  if (imm != nullptr) imm->Ref();\n   current->Ref();\n \n   bool have_stat_update = false;\n@@ -1135,7 +1137,7 @@ Status DBImpl::Get(const ReadOptions& options,\n     LookupKey lkey(key, snapshot);\n     if (mem->Get(lkey, value, &s)) {\n       // Done\n-    } else if (imm != NULL && imm->Get(lkey, value, &s)) {\n+    } else if (imm != nullptr && imm->Get(lkey, value, &s)) {\n       // Done\n     } else {\n       s = current->Get(options, lkey, value, &stats);\n@@ -1148,7 +1150,7 @@ Status DBImpl::Get(const ReadOptions& options,\n     MaybeScheduleCompaction();\n   }\n   mem->Unref();\n-  if (imm != NULL) imm->Unref();\n+  if (imm != nullptr) imm->Unref();\n   current->Unref();\n   return s;\n }\n@@ -1157,12 +1159,12 @@ Iterator* DBImpl::NewIterator(const ReadOptions& options) {\n   SequenceNumber latest_snapshot;\n   uint32_t seed;\n   Iterator* iter = NewInternalIterator(options, &latest_snapshot, &seed);\n-  return NewDBIterator(\n-      this, user_comparator(), iter,\n-      (options.snapshot != NULL\n-       ? reinterpret_cast<const SnapshotImpl*>(options.snapshot)->number_\n-       : latest_snapshot),\n-      seed);\n+  return NewDBIterator(this, user_comparator(), iter,\n+                       (options.snapshot != nullptr\n+                            ? static_cast<const SnapshotImpl*>(options.snapshot)\n+                                  ->sequence_number()\n+                            : latest_snapshot),\n+                       seed);\n }\n \n void DBImpl::RecordReadSample(Slice key) {\n@@ -1177,9 +1179,9 @@ const Snapshot* DBImpl::GetSnapshot() {\n   return snapshots_.New(versions_->LastSequence());\n }\n \n-void DBImpl::ReleaseSnapshot(const Snapshot* s) {\n+void DBImpl::ReleaseSnapshot(const Snapshot* snapshot) {\n   MutexLock l(&mutex_);\n-  snapshots_.Delete(reinterpret_cast<const SnapshotImpl*>(s));\n+  snapshots_.Delete(static_cast<const SnapshotImpl*>(snapshot));\n }\n \n // Convenience methods\n@@ -1191,9 +1193,9 @@ Status DBImpl::Delete(const WriteOptions& options, const Slice& key) {\n   return DB::Delete(options, key);\n }\n \n-Status DBImpl::Write(const WriteOptions& options, WriteBatch* my_batch) {\n+Status DBImpl::Write(const WriteOptions& options, WriteBatch* updates) {\n   Writer w(&mutex_);\n-  w.batch = my_batch;\n+  w.batch = updates;\n   w.sync = options.sync;\n   w.done = false;\n \n@@ -1207,21 +1209,21 @@ Status DBImpl::Write(const WriteOptions& options, WriteBatch* my_batch) {\n   }\n \n   // May temporarily unlock and wait.\n-  Status status = MakeRoomForWrite(my_batch == NULL);\n+  Status status = MakeRoomForWrite(updates == nullptr);\n   uint64_t last_sequence = versions_->LastSequence();\n   Writer* last_writer = &w;\n-  if (status.ok() && my_batch != NULL) {  // NULL batch is for compactions\n-    WriteBatch* updates = BuildBatchGroup(&last_writer);\n-    WriteBatchInternal::SetSequence(updates, last_sequence + 1);\n-    last_sequence += WriteBatchInternal::Count(updates);\n+  if (status.ok() && updates != nullptr) {  // nullptr batch is for compactions\n+    WriteBatch* write_batch = BuildBatchGroup(&last_writer);\n+    WriteBatchInternal::SetSequence(write_batch, last_sequence + 1);\n+    last_sequence += WriteBatchInternal::Count(write_batch);\n \n     // Add to log and apply to memtable.  We can release the lock\n     // during this phase since &w is currently responsible for logging\n     // and protects against concurrent loggers and concurrent writes\n     // into mem_.\n     {\n       mutex_.Unlock();\n-      status = log_->AddRecord(WriteBatchInternal::Contents(updates));\n+      status = log_->AddRecord(WriteBatchInternal::Contents(write_batch));\n       bool sync_error = false;\n       if (status.ok() && options.sync) {\n         status = logfile_->Sync();\n@@ -1230,7 +1232,7 @@ Status DBImpl::Write(const WriteOptions& options, WriteBatch* my_batch) {\n         }\n       }\n       if (status.ok()) {\n-        status = WriteBatchInternal::InsertInto(updates, mem_);\n+        status = WriteBatchInternal::InsertInto(write_batch, mem_);\n       }\n       mutex_.Lock();\n       if (sync_error) {\n@@ -1240,7 +1242,7 @@ Status DBImpl::Write(const WriteOptions& options, WriteBatch* my_batch) {\n         RecordBackgroundError(status);\n       }\n     }\n-    if (updates == tmp_batch_) tmp_batch_->Clear();\n+    if (write_batch == tmp_batch_) tmp_batch_->Clear();\n \n     versions_->SetLastSequence(last_sequence);\n   }\n@@ -1265,21 +1267,22 @@ Status DBImpl::Write(const WriteOptions& options, WriteBatch* my_batch) {\n }\n \n // REQUIRES: Writer list must be non-empty\n-// REQUIRES: First writer must have a non-NULL batch\n+// REQUIRES: First writer must have a non-null batch\n WriteBatch* DBImpl::BuildBatchGroup(Writer** last_writer) {\n+  mutex_.AssertHeld();\n   assert(!writers_.empty());\n   Writer* first = writers_.front();\n   WriteBatch* result = first->batch;\n-  assert(result != NULL);\n+  assert(result != nullptr);\n \n   size_t size = WriteBatchInternal::ByteSize(first->batch);\n \n   // Allow the group to grow up to a maximum size, but if the\n   // original write is small, limit the growth so we do not slow\n   // down the small write too much.\n   size_t max_size = 1 << 20;\n-  if (size <= (128<<10)) {\n-    max_size = size + (128<<10);\n+  if (size <= (128 << 10)) {\n+    max_size = size + (128 << 10);\n   }\n \n   *last_writer = first;\n@@ -1292,7 +1295,7 @@ WriteBatch* DBImpl::BuildBatchGroup(Writer** last_writer) {\n       break;\n     }\n \n-    if (w->batch != NULL) {\n+    if (w->batch != nullptr) {\n       size += WriteBatchInternal::ByteSize(w->batch);\n       if (size > max_size) {\n         // Do not make batch too big\n@@ -1325,9 +1328,8 @@ Status DBImpl::MakeRoomForWrite(bool force) {\n       // Yield previous error\n       s = bg_error_;\n       break;\n-    } else if (\n-        allow_delay &&\n-        versions_->NumLevelFiles(0) >= config::kL0_SlowdownWritesTrigger) {\n+    } else if (allow_delay && versions_->NumLevelFiles(0) >=\n+                                  config::kL0_SlowdownWritesTrigger) {\n       // We are getting close to hitting a hard limit on the number of\n       // L0 files.  Rather than delaying a single write by several\n       // seconds when we hit the hard limit, start delaying each\n@@ -1342,20 +1344,20 @@ Status DBImpl::MakeRoomForWrite(bool force) {\n                (mem_->ApproximateMemoryUsage() <= options_.write_buffer_size)) {\n       // There is room in current memtable\n       break;\n-    } else if (imm_ != NULL) {\n+    } else if (imm_ != nullptr) {\n       // We have filled up the current memtable, but the previous\n       // one is still being compacted, so we wait.\n       Log(options_.info_log, \"Current memtable full; waiting...\\n\");\n-      bg_cv_.Wait();\n+      background_work_finished_signal_.Wait();\n     } else if (versions_->NumLevelFiles(0) >= config::kL0_StopWritesTrigger) {\n       // There are too many level-0 files.\n       Log(options_.info_log, \"Too many L0 files; waiting...\\n\");\n-      bg_cv_.Wait();\n+      background_work_finished_signal_.Wait();\n     } else {\n       // Attempt to switch to a new memtable and trigger compaction of old\n       assert(versions_->PrevLogNumber() == 0);\n       uint64_t new_log_number = versions_->NewFileNumber();\n-      WritableFile* lfile = NULL;\n+      WritableFile* lfile = nullptr;\n       s = env_->NewWritableFile(LogFileName(dbname_, new_log_number), &lfile);\n       if (!s.ok()) {\n         // Avoid chewing through file number space in a tight loop.\n@@ -1368,10 +1370,10 @@ Status DBImpl::MakeRoomForWrite(bool force) {\n       logfile_number_ = new_log_number;\n       log_ = new log::Writer(lfile);\n       imm_ = mem_;\n-      has_imm_.Release_Store(imm_);\n+      has_imm_.store(true, std::memory_order_release);\n       mem_ = new MemTable(internal_comparator_);\n       mem_->Ref();\n-      force = false;   // Do not force another compaction if have room\n+      force = false;  // Do not force another compaction if have room\n       MaybeScheduleCompaction();\n     }\n   }\n@@ -1405,21 +1407,16 @@ bool DBImpl::GetProperty(const Slice& property, std::string* value) {\n     snprintf(buf, sizeof(buf),\n              \"                               Compactions\\n\"\n              \"Level  Files Size(MB) Time(sec) Read(MB) Write(MB)\\n\"\n-             \"--------------------------------------------------\\n\"\n-             );\n+             \"--------------------------------------------------\\n\");\n     value->append(buf);\n     for (int level = 0; level < config::kNumLevels; level++) {\n       int files = versions_->NumLevelFiles(level);\n       if (stats_[level].micros > 0 || files > 0) {\n-        snprintf(\n-            buf, sizeof(buf),\n-            \"%3d %8d %8.0f %9.0f %8.0f %9.0f\\n\",\n-            level,\n-            files,\n-            versions_->NumLevelBytes(level) / 1048576.0,\n-            stats_[level].micros / 1e6,\n-            stats_[level].bytes_read / 1048576.0,\n-            stats_[level].bytes_written / 1048576.0);\n+        snprintf(buf, sizeof(buf), \"%3d %8d %8.0f %9.0f %8.0f %9.0f\\n\", level,\n+                 files, versions_->NumLevelBytes(level) / 1048576.0,\n+                 stats_[level].micros / 1e6,\n+                 stats_[level].bytes_read / 1048576.0,\n+                 stats_[level].bytes_written / 1048576.0);\n         value->append(buf);\n       }\n     }\n@@ -1445,16 +1442,11 @@ bool DBImpl::GetProperty(const Slice& property, std::string* value) {\n   return false;\n }\n \n-void DBImpl::GetApproximateSizes(\n-    const Range* range, int n,\n-    uint64_t* sizes) {\n+void DBImpl::GetApproximateSizes(const Range* range, int n, uint64_t* sizes) {\n   // TODO(opt): better implementation\n-  Version* v;\n-  {\n-    MutexLock l(&mutex_);\n-    versions_->current()->Ref();\n-    v = versions_->current();\n-  }\n+  MutexLock l(&mutex_);\n+  Version* v = versions_->current();\n+  v->Ref();\n \n   for (int i = 0; i < n; i++) {\n     // Convert user_key into a corresponding internal key.\n@@ -1465,10 +1457,7 @@ void DBImpl::GetApproximateSizes(\n     sizes[i] = (limit >= start ? limit - start : 0);\n   }\n \n-  {\n-    MutexLock l(&mutex_);\n-    v->Unref();\n-  }\n+  v->Unref();\n }\n \n // Default implementations of convenience methods that subclasses of DB\n@@ -1485,19 +1474,18 @@ Status DB::Delete(const WriteOptions& opt, const Slice& key) {\n   return Write(opt, &batch);\n }\n \n-DB::~DB() { }\n+DB::~DB() = default;\n \n-Status DB::Open(const Options& options, const std::string& dbname,\n-                DB** dbptr) {\n-  *dbptr = NULL;\n+Status DB::Open(const Options& options, const std::string& dbname, DB** dbptr) {\n+  *dbptr = nullptr;\n \n   DBImpl* impl = new DBImpl(options, dbname);\n   impl->mutex_.Lock();\n   VersionEdit edit;\n   // Recover handles create_if_missing, error_if_exists\n   bool save_manifest = false;\n   Status s = impl->Recover(&edit, &save_manifest);\n-  if (s.ok() && impl->mem_ == NULL) {\n+  if (s.ok() && impl->mem_ == nullptr) {\n     // Create new log and a corresponding memtable.\n     uint64_t new_log_number = impl->versions_->NewFileNumber();\n     WritableFile* lfile;\n@@ -1523,29 +1511,28 @@ Status DB::Open(const Options& options, const std::string& dbname,\n   }\n   impl->mutex_.Unlock();\n   if (s.ok()) {\n-    assert(impl->mem_ != NULL);\n+    assert(impl->mem_ != nullptr);\n     *dbptr = impl;\n   } else {\n     delete impl;\n   }\n   return s;\n }\n \n-Snapshot::~Snapshot() {\n-}\n+Snapshot::~Snapshot() = default;\n \n Status DestroyDB(const std::string& dbname, const Options& options) {\n   Env* env = options.env;\n   std::vector<std::string> filenames;\n-  // Ignore error in case directory does not exist\n-  env->GetChildren(dbname, &filenames);\n-  if (filenames.empty()) {\n+  Status result = env->GetChildren(dbname, &filenames);\n+  if (!result.ok()) {\n+    // Ignore error in case directory does not exist\n     return Status::OK();\n   }\n \n   FileLock* lock;\n   const std::string lockname = LockFileName(dbname);\n-  Status result = env->LockFile(lockname, &lock);\n+  result = env->LockFile(lockname, &lock);\n   if (result.ok()) {\n     uint64_t number;\n     FileType type;"
      },
      {
        "sha": "685735c733f9984386fc393cf2dbd85d5a988ade",
        "filename": "src/leveldb/db/db_impl.h",
        "status": "modified",
        "additions": 76,
        "deletions": 70,
        "changes": 146,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/db_impl.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/db_impl.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/db_impl.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -5,8 +5,11 @@\n #ifndef STORAGE_LEVELDB_DB_DB_IMPL_H_\n #define STORAGE_LEVELDB_DB_DB_IMPL_H_\n \n+#include <atomic>\n #include <deque>\n #include <set>\n+#include <string>\n+\n #include \"db/dbformat.h\"\n #include \"db/log_writer.h\"\n #include \"db/snapshot.h\"\n@@ -26,21 +29,25 @@ class VersionSet;\n class DBImpl : public DB {\n  public:\n   DBImpl(const Options& options, const std::string& dbname);\n-  virtual ~DBImpl();\n+\n+  DBImpl(const DBImpl&) = delete;\n+  DBImpl& operator=(const DBImpl&) = delete;\n+\n+  ~DBImpl() override;\n \n   // Implementations of the DB interface\n-  virtual Status Put(const WriteOptions&, const Slice& key, const Slice& value);\n-  virtual Status Delete(const WriteOptions&, const Slice& key);\n-  virtual Status Write(const WriteOptions& options, WriteBatch* updates);\n-  virtual Status Get(const ReadOptions& options,\n-                     const Slice& key,\n-                     std::string* value);\n-  virtual Iterator* NewIterator(const ReadOptions&);\n-  virtual const Snapshot* GetSnapshot();\n-  virtual void ReleaseSnapshot(const Snapshot* snapshot);\n-  virtual bool GetProperty(const Slice& property, std::string* value);\n-  virtual void GetApproximateSizes(const Range* range, int n, uint64_t* sizes);\n-  virtual void CompactRange(const Slice* begin, const Slice* end);\n+  Status Put(const WriteOptions&, const Slice& key,\n+             const Slice& value) override;\n+  Status Delete(const WriteOptions&, const Slice& key) override;\n+  Status Write(const WriteOptions& options, WriteBatch* updates) override;\n+  Status Get(const ReadOptions& options, const Slice& key,\n+             std::string* value) override;\n+  Iterator* NewIterator(const ReadOptions&) override;\n+  const Snapshot* GetSnapshot() override;\n+  void ReleaseSnapshot(const Snapshot* snapshot) override;\n+  bool GetProperty(const Slice& property, std::string* value) override;\n+  void GetApproximateSizes(const Range* range, int n, uint64_t* sizes) override;\n+  void CompactRange(const Slice* begin, const Slice* end) override;\n \n   // Extra methods (for testing) that are not in the public DB interface\n \n@@ -69,6 +76,31 @@ class DBImpl : public DB {\n   struct CompactionState;\n   struct Writer;\n \n+  // Information for a manual compaction\n+  struct ManualCompaction {\n+    int level;\n+    bool done;\n+    const InternalKey* begin;  // null means beginning of key range\n+    const InternalKey* end;    // null means end of key range\n+    InternalKey tmp_storage;   // Used to keep track of compaction progress\n+  };\n+\n+  // Per level compaction stats.  stats_[level] stores the stats for\n+  // compactions that produced data for the specified \"level\".\n+  struct CompactionStats {\n+    CompactionStats() : micros(0), bytes_read(0), bytes_written(0) {}\n+\n+    void Add(const CompactionStats& c) {\n+      this->micros += c.micros;\n+      this->bytes_read += c.bytes_read;\n+      this->bytes_written += c.bytes_written;\n+    }\n+\n+    int64_t micros;\n+    int64_t bytes_read;\n+    int64_t bytes_written;\n+  };\n+\n   Iterator* NewInternalIterator(const ReadOptions&,\n                                 SequenceNumber* latest_snapshot,\n                                 uint32_t* seed);\n@@ -84,7 +116,7 @@ class DBImpl : public DB {\n   void MaybeIgnoreError(Status* s) const;\n \n   // Delete any unneeded files and stale in-memory entries.\n-  void DeleteObsoleteFiles();\n+  void DeleteObsoleteFiles() EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n   // Compact the in-memory write buffer to disk.  Switches to a new\n   // log-file/memtable and writes a new descriptor iff successful.\n@@ -100,14 +132,15 @@ class DBImpl : public DB {\n \n   Status MakeRoomForWrite(bool force /* compact even if there is room? */)\n       EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n-  WriteBatch* BuildBatchGroup(Writer** last_writer);\n+  WriteBatch* BuildBatchGroup(Writer** last_writer)\n+      EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n   void RecordBackgroundError(const Status& s);\n \n   void MaybeScheduleCompaction() EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n   static void BGWork(void* db);\n   void BackgroundCall();\n-  void  BackgroundCompaction() EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n+  void BackgroundCompaction() EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n   void CleanupCompaction(CompactionState* compact)\n       EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n   Status DoCompactionWork(CompactionState* compact)\n@@ -118,93 +151,66 @@ class DBImpl : public DB {\n   Status InstallCompactionResults(CompactionState* compact)\n       EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n+  const Comparator* user_comparator() const {\n+    return internal_comparator_.user_comparator();\n+  }\n+\n   // Constant after construction\n   Env* const env_;\n   const InternalKeyComparator internal_comparator_;\n   const InternalFilterPolicy internal_filter_policy_;\n   const Options options_;  // options_.comparator == &internal_comparator_\n-  bool owns_info_log_;\n-  bool owns_cache_;\n+  const bool owns_info_log_;\n+  const bool owns_cache_;\n   const std::string dbname_;\n \n   // table_cache_ provides its own synchronization\n-  TableCache* table_cache_;\n+  TableCache* const table_cache_;\n \n-  // Lock over the persistent DB state.  Non-NULL iff successfully acquired.\n+  // Lock over the persistent DB state.  Non-null iff successfully acquired.\n   FileLock* db_lock_;\n \n   // State below is protected by mutex_\n   port::Mutex mutex_;\n-  port::AtomicPointer shutting_down_;\n-  port::CondVar bg_cv_;          // Signalled when background work finishes\n+  std::atomic<bool> shutting_down_;\n+  port::CondVar background_work_finished_signal_ GUARDED_BY(mutex_);\n   MemTable* mem_;\n-  MemTable* imm_;                // Memtable being compacted\n-  port::AtomicPointer has_imm_;  // So bg thread can detect non-NULL imm_\n+  MemTable* imm_ GUARDED_BY(mutex_);  // Memtable being compacted\n+  std::atomic<bool> has_imm_;         // So bg thread can detect non-null imm_\n   WritableFile* logfile_;\n-  uint64_t logfile_number_;\n+  uint64_t logfile_number_ GUARDED_BY(mutex_);\n   log::Writer* log_;\n-  uint32_t seed_;                // For sampling.\n+  uint32_t seed_ GUARDED_BY(mutex_);  // For sampling.\n \n   // Queue of writers.\n-  std::deque<Writer*> writers_;\n-  WriteBatch* tmp_batch_;\n+  std::deque<Writer*> writers_ GUARDED_BY(mutex_);\n+  WriteBatch* tmp_batch_ GUARDED_BY(mutex_);\n \n-  SnapshotList snapshots_;\n+  SnapshotList snapshots_ GUARDED_BY(mutex_);\n \n   // Set of table files to protect from deletion because they are\n   // part of ongoing compactions.\n-  std::set<uint64_t> pending_outputs_;\n+  std::set<uint64_t> pending_outputs_ GUARDED_BY(mutex_);\n \n   // Has a background compaction been scheduled or is running?\n-  bool bg_compaction_scheduled_;\n+  bool background_compaction_scheduled_ GUARDED_BY(mutex_);\n \n-  // Information for a manual compaction\n-  struct ManualCompaction {\n-    int level;\n-    bool done;\n-    const InternalKey* begin;   // NULL means beginning of key range\n-    const InternalKey* end;     // NULL means end of key range\n-    InternalKey tmp_storage;    // Used to keep track of compaction progress\n-  };\n-  ManualCompaction* manual_compaction_;\n+  ManualCompaction* manual_compaction_ GUARDED_BY(mutex_);\n \n-  VersionSet* versions_;\n+  VersionSet* const versions_ GUARDED_BY(mutex_);\n \n   // Have we encountered a background error in paranoid mode?\n-  Status bg_error_;\n-\n-  // Per level compaction stats.  stats_[level] stores the stats for\n-  // compactions that produced data for the specified \"level\".\n-  struct CompactionStats {\n-    int64_t micros;\n-    int64_t bytes_read;\n-    int64_t bytes_written;\n-\n-    CompactionStats() : micros(0), bytes_read(0), bytes_written(0) { }\n+  Status bg_error_ GUARDED_BY(mutex_);\n \n-    void Add(const CompactionStats& c) {\n-      this->micros += c.micros;\n-      this->bytes_read += c.bytes_read;\n-      this->bytes_written += c.bytes_written;\n-    }\n-  };\n-  CompactionStats stats_[config::kNumLevels];\n-\n-  // No copying allowed\n-  DBImpl(const DBImpl&);\n-  void operator=(const DBImpl&);\n-\n-  const Comparator* user_comparator() const {\n-    return internal_comparator_.user_comparator();\n-  }\n+  CompactionStats stats_[config::kNumLevels] GUARDED_BY(mutex_);\n };\n \n // Sanitize db options.  The caller should delete result.info_log if\n // it is not equal to src.info_log.\n-extern Options SanitizeOptions(const std::string& db,\n-                               const InternalKeyComparator* icmp,\n-                               const InternalFilterPolicy* ipolicy,\n-                               const Options& src);\n+Options SanitizeOptions(const std::string& db,\n+                        const InternalKeyComparator* icmp,\n+                        const InternalFilterPolicy* ipolicy,\n+                        const Options& src);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "98715a950235b506c9d752ce1be5f680f01cc601",
        "filename": "src/leveldb/db/db_iter.cc",
        "status": "modified",
        "additions": 47,
        "deletions": 46,
        "changes": 93,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/db_iter.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/db_iter.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/db_iter.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -4,9 +4,9 @@\n \n #include \"db/db_iter.h\"\n \n-#include \"db/filename.h\"\n #include \"db/db_impl.h\"\n #include \"db/dbformat.h\"\n+#include \"db/filename.h\"\n #include \"leveldb/env.h\"\n #include \"leveldb/iterator.h\"\n #include \"port/port.h\"\n@@ -36,17 +36,14 @@ namespace {\n // combines multiple entries for the same userkey found in the DB\n // representation into a single entry while accounting for sequence\n // numbers, deletion markers, overwrites, etc.\n-class DBIter: public Iterator {\n+class DBIter : public Iterator {\n  public:\n   // Which direction is the iterator currently moving?\n   // (1) When moving forward, the internal iterator is positioned at\n   //     the exact entry that yields this->key(), this->value()\n   // (2) When moving backwards, the internal iterator is positioned\n   //     just before all entries whose user key == this->key().\n-  enum Direction {\n-    kForward,\n-    kReverse\n-  };\n+  enum Direction { kForward, kReverse };\n \n   DBIter(DBImpl* db, const Comparator* cmp, Iterator* iter, SequenceNumber s,\n          uint32_t seed)\n@@ -57,33 +54,34 @@ class DBIter: public Iterator {\n         direction_(kForward),\n         valid_(false),\n         rnd_(seed),\n-        bytes_counter_(RandomPeriod()) {\n-  }\n-  virtual ~DBIter() {\n-    delete iter_;\n-  }\n-  virtual bool Valid() const { return valid_; }\n-  virtual Slice key() const {\n+        bytes_until_read_sampling_(RandomCompactionPeriod()) {}\n+\n+  DBIter(const DBIter&) = delete;\n+  DBIter& operator=(const DBIter&) = delete;\n+\n+  ~DBIter() override { delete iter_; }\n+  bool Valid() const override { return valid_; }\n+  Slice key() const override {\n     assert(valid_);\n     return (direction_ == kForward) ? ExtractUserKey(iter_->key()) : saved_key_;\n   }\n-  virtual Slice value() const {\n+  Slice value() const override {\n     assert(valid_);\n     return (direction_ == kForward) ? iter_->value() : saved_value_;\n   }\n-  virtual Status status() const {\n+  Status status() const override {\n     if (status_.ok()) {\n       return iter_->status();\n     } else {\n       return status_;\n     }\n   }\n \n-  virtual void Next();\n-  virtual void Prev();\n-  virtual void Seek(const Slice& target);\n-  virtual void SeekToFirst();\n-  virtual void SeekToLast();\n+  void Next() override;\n+  void Prev() override;\n+  void Seek(const Slice& target) override;\n+  void SeekToFirst() override;\n+  void SeekToLast() override;\n \n  private:\n   void FindNextUserEntry(bool skipping, std::string* skip);\n@@ -103,38 +101,35 @@ class DBIter: public Iterator {\n     }\n   }\n \n-  // Pick next gap with average value of config::kReadBytesPeriod.\n-  ssize_t RandomPeriod() {\n-    return rnd_.Uniform(2*config::kReadBytesPeriod);\n+  // Picks the number of bytes that can be read until a compaction is scheduled.\n+  size_t RandomCompactionPeriod() {\n+    return rnd_.Uniform(2 * config::kReadBytesPeriod);\n   }\n \n   DBImpl* db_;\n   const Comparator* const user_comparator_;\n   Iterator* const iter_;\n   SequenceNumber const sequence_;\n-\n   Status status_;\n-  std::string saved_key_;     // == current key when direction_==kReverse\n-  std::string saved_value_;   // == current raw value when direction_==kReverse\n+  std::string saved_key_;    // == current key when direction_==kReverse\n+  std::string saved_value_;  // == current raw value when direction_==kReverse\n   Direction direction_;\n   bool valid_;\n-\n   Random rnd_;\n-  ssize_t bytes_counter_;\n-\n-  // No copying allowed\n-  DBIter(const DBIter&);\n-  void operator=(const DBIter&);\n+  size_t bytes_until_read_sampling_;\n };\n \n inline bool DBIter::ParseKey(ParsedInternalKey* ikey) {\n   Slice k = iter_->key();\n-  ssize_t n = k.size() + iter_->value().size();\n-  bytes_counter_ -= n;\n-  while (bytes_counter_ < 0) {\n-    bytes_counter_ += RandomPeriod();\n+\n+  size_t bytes_read = k.size() + iter_->value().size();\n+  while (bytes_until_read_sampling_ < bytes_read) {\n+    bytes_until_read_sampling_ += RandomCompactionPeriod();\n     db_->RecordReadSample(k);\n   }\n+  assert(bytes_until_read_sampling_ >= bytes_read);\n+  bytes_until_read_sampling_ -= bytes_read;\n+\n   if (!ParseInternalKey(k, ikey)) {\n     status_ = Status::Corruption(\"corrupted internal key in DBIter\");\n     return false;\n@@ -165,6 +160,15 @@ void DBIter::Next() {\n   } else {\n     // Store in saved_key_ the current key so we skip it below.\n     SaveKey(ExtractUserKey(iter_->key()), &saved_key_);\n+\n+    // iter_ is pointing to current key. We can now safely move to the next to\n+    // avoid checking current key.\n+    iter_->Next();\n+    if (!iter_->Valid()) {\n+      valid_ = false;\n+      saved_key_.clear();\n+      return;\n+    }\n   }\n \n   FindNextUserEntry(true, &saved_key_);\n@@ -218,8 +222,8 @@ void DBIter::Prev() {\n         ClearSavedValue();\n         return;\n       }\n-      if (user_comparator_->Compare(ExtractUserKey(iter_->key()),\n-                                    saved_key_) < 0) {\n+      if (user_comparator_->Compare(ExtractUserKey(iter_->key()), saved_key_) <\n+          0) {\n         break;\n       }\n     }\n@@ -275,8 +279,8 @@ void DBIter::Seek(const Slice& target) {\n   direction_ = kForward;\n   ClearSavedValue();\n   saved_key_.clear();\n-  AppendInternalKey(\n-      &saved_key_, ParsedInternalKey(target, sequence_, kValueTypeForSeek));\n+  AppendInternalKey(&saved_key_,\n+                    ParsedInternalKey(target, sequence_, kValueTypeForSeek));\n   iter_->Seek(saved_key_);\n   if (iter_->Valid()) {\n     FindNextUserEntry(false, &saved_key_ /* temporary storage */);\n@@ -305,12 +309,9 @@ void DBIter::SeekToLast() {\n \n }  // anonymous namespace\n \n-Iterator* NewDBIterator(\n-    DBImpl* db,\n-    const Comparator* user_key_comparator,\n-    Iterator* internal_iter,\n-    SequenceNumber sequence,\n-    uint32_t seed) {\n+Iterator* NewDBIterator(DBImpl* db, const Comparator* user_key_comparator,\n+                        Iterator* internal_iter, SequenceNumber sequence,\n+                        uint32_t seed) {\n   return new DBIter(db, user_key_comparator, internal_iter, sequence, seed);\n }\n "
      },
      {
        "sha": "fd93e912a0de2e5c226474717758c45cca8ba21e",
        "filename": "src/leveldb/db/db_iter.h",
        "status": "modified",
        "additions": 5,
        "deletions": 7,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/db_iter.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/db_iter.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/db_iter.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -6,8 +6,9 @@\n #define STORAGE_LEVELDB_DB_DB_ITER_H_\n \n #include <stdint.h>\n-#include \"leveldb/db.h\"\n+\n #include \"db/dbformat.h\"\n+#include \"leveldb/db.h\"\n \n namespace leveldb {\n \n@@ -16,12 +17,9 @@ class DBImpl;\n // Return a new iterator that converts internal keys (yielded by\n // \"*internal_iter\") that were live at the specified \"sequence\" number\n // into appropriate user keys.\n-extern Iterator* NewDBIterator(\n-    DBImpl* db,\n-    const Comparator* user_key_comparator,\n-    Iterator* internal_iter,\n-    SequenceNumber sequence,\n-    uint32_t seed);\n+Iterator* NewDBIterator(DBImpl* db, const Comparator* user_key_comparator,\n+                        Iterator* internal_iter, SequenceNumber sequence,\n+                        uint32_t seed);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "beb1d3bdef61d6a885061c8eb95f1c2d13dd0d2a",
        "filename": "src/leveldb/db/db_test.cc",
        "status": "modified",
        "additions": 433,
        "deletions": 289,
        "changes": 722,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/db_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/db_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/db_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -3,14 +3,20 @@\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n #include \"leveldb/db.h\"\n-#include \"leveldb/filter_policy.h\"\n+\n+#include <atomic>\n+#include <string>\n+\n #include \"db/db_impl.h\"\n #include \"db/filename.h\"\n #include \"db/version_set.h\"\n #include \"db/write_batch_internal.h\"\n #include \"leveldb/cache.h\"\n #include \"leveldb/env.h\"\n+#include \"leveldb/filter_policy.h\"\n #include \"leveldb/table.h\"\n+#include \"port/port.h\"\n+#include \"port/thread_annotations.h\"\n #include \"util/hash.h\"\n #include \"util/logging.h\"\n #include \"util/mutexlock.h\"\n@@ -25,83 +31,116 @@ static std::string RandomString(Random* rnd, int len) {\n   return r;\n }\n \n+static std::string RandomKey(Random* rnd) {\n+  int len =\n+      (rnd->OneIn(3) ? 1  // Short sometimes to encourage collisions\n+                     : (rnd->OneIn(100) ? rnd->Skewed(10) : rnd->Uniform(10)));\n+  return test::RandomKey(rnd, len);\n+}\n+\n namespace {\n class AtomicCounter {\n- private:\n-  port::Mutex mu_;\n-  int count_;\n  public:\n-  AtomicCounter() : count_(0) { }\n-  void Increment() {\n-    IncrementBy(1);\n-  }\n-  void IncrementBy(int count) {\n+  AtomicCounter() : count_(0) {}\n+  void Increment() { IncrementBy(1); }\n+  void IncrementBy(int count) LOCKS_EXCLUDED(mu_) {\n     MutexLock l(&mu_);\n     count_ += count;\n   }\n-  int Read() {\n+  int Read() LOCKS_EXCLUDED(mu_) {\n     MutexLock l(&mu_);\n     return count_;\n   }\n-  void Reset() {\n+  void Reset() LOCKS_EXCLUDED(mu_) {\n     MutexLock l(&mu_);\n     count_ = 0;\n   }\n+\n+ private:\n+  port::Mutex mu_;\n+  int count_ GUARDED_BY(mu_);\n };\n \n void DelayMilliseconds(int millis) {\n   Env::Default()->SleepForMicroseconds(millis * 1000);\n }\n-}\n+}  // namespace\n+\n+// Test Env to override default Env behavior for testing.\n+class TestEnv : public EnvWrapper {\n+ public:\n+  explicit TestEnv(Env* base) : EnvWrapper(base), ignore_dot_files_(false) {}\n+\n+  void SetIgnoreDotFiles(bool ignored) { ignore_dot_files_ = ignored; }\n+\n+  Status GetChildren(const std::string& dir,\n+                     std::vector<std::string>* result) override {\n+    Status s = target()->GetChildren(dir, result);\n+    if (!s.ok() || !ignore_dot_files_) {\n+      return s;\n+    }\n+\n+    std::vector<std::string>::iterator it = result->begin();\n+    while (it != result->end()) {\n+      if ((*it == \".\") || (*it == \"..\")) {\n+        it = result->erase(it);\n+      } else {\n+        ++it;\n+      }\n+    }\n+\n+    return s;\n+  }\n+\n+ private:\n+  bool ignore_dot_files_;\n+};\n \n-// Special Env used to delay background operations\n+// Special Env used to delay background operations.\n class SpecialEnv : public EnvWrapper {\n  public:\n-  // sstable/log Sync() calls are blocked while this pointer is non-NULL.\n-  port::AtomicPointer delay_data_sync_;\n+  // sstable/log Sync() calls are blocked while this pointer is non-null.\n+  std::atomic<bool> delay_data_sync_;\n \n   // sstable/log Sync() calls return an error.\n-  port::AtomicPointer data_sync_error_;\n+  std::atomic<bool> data_sync_error_;\n \n-  // Simulate no-space errors while this pointer is non-NULL.\n-  port::AtomicPointer no_space_;\n+  // Simulate no-space errors while this pointer is non-null.\n+  std::atomic<bool> no_space_;\n \n-  // Simulate non-writable file system while this pointer is non-NULL\n-  port::AtomicPointer non_writable_;\n+  // Simulate non-writable file system while this pointer is non-null.\n+  std::atomic<bool> non_writable_;\n \n-  // Force sync of manifest files to fail while this pointer is non-NULL\n-  port::AtomicPointer manifest_sync_error_;\n+  // Force sync of manifest files to fail while this pointer is non-null.\n+  std::atomic<bool> manifest_sync_error_;\n \n-  // Force write to manifest files to fail while this pointer is non-NULL\n-  port::AtomicPointer manifest_write_error_;\n+  // Force write to manifest files to fail while this pointer is non-null.\n+  std::atomic<bool> manifest_write_error_;\n \n   bool count_random_reads_;\n   AtomicCounter random_read_counter_;\n \n-  explicit SpecialEnv(Env* base) : EnvWrapper(base) {\n-    delay_data_sync_.Release_Store(NULL);\n-    data_sync_error_.Release_Store(NULL);\n-    no_space_.Release_Store(NULL);\n-    non_writable_.Release_Store(NULL);\n-    count_random_reads_ = false;\n-    manifest_sync_error_.Release_Store(NULL);\n-    manifest_write_error_.Release_Store(NULL);\n-  }\n+  explicit SpecialEnv(Env* base)\n+      : EnvWrapper(base),\n+        delay_data_sync_(false),\n+        data_sync_error_(false),\n+        no_space_(false),\n+        non_writable_(false),\n+        manifest_sync_error_(false),\n+        manifest_write_error_(false),\n+        count_random_reads_(false) {}\n \n   Status NewWritableFile(const std::string& f, WritableFile** r) {\n     class DataFile : public WritableFile {\n      private:\n-      SpecialEnv* env_;\n-      WritableFile* base_;\n+      SpecialEnv* const env_;\n+      WritableFile* const base_;\n \n      public:\n-      DataFile(SpecialEnv* env, WritableFile* base)\n-          : env_(env),\n-            base_(base) {\n-      }\n+      DataFile(SpecialEnv* env, WritableFile* base) : env_(env), base_(base) {}\n       ~DataFile() { delete base_; }\n       Status Append(const Slice& data) {\n-        if (env_->no_space_.Acquire_Load() != NULL) {\n+        if (env_->no_space_.load(std::memory_order_acquire)) {\n           // Drop writes on the floor\n           return Status::OK();\n         } else {\n@@ -111,24 +150,26 @@ class SpecialEnv : public EnvWrapper {\n       Status Close() { return base_->Close(); }\n       Status Flush() { return base_->Flush(); }\n       Status Sync() {\n-        if (env_->data_sync_error_.Acquire_Load() != NULL) {\n+        if (env_->data_sync_error_.load(std::memory_order_acquire)) {\n           return Status::IOError(\"simulated data sync error\");\n         }\n-        while (env_->delay_data_sync_.Acquire_Load() != NULL) {\n+        while (env_->delay_data_sync_.load(std::memory_order_acquire)) {\n           DelayMilliseconds(100);\n         }\n         return base_->Sync();\n       }\n+      std::string GetName() const override { return \"\"; }\n     };\n     class ManifestFile : public WritableFile {\n      private:\n       SpecialEnv* env_;\n       WritableFile* base_;\n+\n      public:\n-      ManifestFile(SpecialEnv* env, WritableFile* b) : env_(env), base_(b) { }\n+      ManifestFile(SpecialEnv* env, WritableFile* b) : env_(env), base_(b) {}\n       ~ManifestFile() { delete base_; }\n       Status Append(const Slice& data) {\n-        if (env_->manifest_write_error_.Acquire_Load() != NULL) {\n+        if (env_->manifest_write_error_.load(std::memory_order_acquire)) {\n           return Status::IOError(\"simulated writer error\");\n         } else {\n           return base_->Append(data);\n@@ -137,24 +178,25 @@ class SpecialEnv : public EnvWrapper {\n       Status Close() { return base_->Close(); }\n       Status Flush() { return base_->Flush(); }\n       Status Sync() {\n-        if (env_->manifest_sync_error_.Acquire_Load() != NULL) {\n+        if (env_->manifest_sync_error_.load(std::memory_order_acquire)) {\n           return Status::IOError(\"simulated sync error\");\n         } else {\n           return base_->Sync();\n         }\n       }\n+      std::string GetName() const override { return \"\"; }\n     };\n \n-    if (non_writable_.Acquire_Load() != NULL) {\n+    if (non_writable_.load(std::memory_order_acquire)) {\n       return Status::IOError(\"simulated write error\");\n     }\n \n     Status s = target()->NewWritableFile(f, r);\n     if (s.ok()) {\n-      if (strstr(f.c_str(), \".ldb\") != NULL ||\n-          strstr(f.c_str(), \".log\") != NULL) {\n+      if (strstr(f.c_str(), \".ldb\") != nullptr ||\n+          strstr(f.c_str(), \".log\") != nullptr) {\n         *r = new DataFile(this, *r);\n-      } else if (strstr(f.c_str(), \"MANIFEST\") != NULL) {\n+      } else if (strstr(f.c_str(), \"MANIFEST\") != nullptr) {\n         *r = new ManifestFile(this, *r);\n       }\n     }\n@@ -166,16 +208,17 @@ class SpecialEnv : public EnvWrapper {\n      private:\n       RandomAccessFile* target_;\n       AtomicCounter* counter_;\n+\n      public:\n       CountingFile(RandomAccessFile* target, AtomicCounter* counter)\n-          : target_(target), counter_(counter) {\n-      }\n-      virtual ~CountingFile() { delete target_; }\n-      virtual Status Read(uint64_t offset, size_t n, Slice* result,\n-                          char* scratch) const {\n+          : target_(target), counter_(counter) {}\n+      ~CountingFile() override { delete target_; }\n+      Status Read(uint64_t offset, size_t n, Slice* result,\n+                  char* scratch) const override {\n         counter_->Increment();\n         return target_->Read(offset, n, result, scratch);\n       }\n+      std::string GetName() const override { return \"\"; }\n     };\n \n     Status s = target()->NewRandomAccessFile(f, r);\n@@ -187,32 +230,18 @@ class SpecialEnv : public EnvWrapper {\n };\n \n class DBTest {\n- private:\n-  const FilterPolicy* filter_policy_;\n-\n-  // Sequence of option configurations to try\n-  enum OptionConfig {\n-    kDefault,\n-    kReuse,\n-    kFilter,\n-    kUncompressed,\n-    kEnd\n-  };\n-  int option_config_;\n-\n  public:\n   std::string dbname_;\n   SpecialEnv* env_;\n   DB* db_;\n \n   Options last_options_;\n \n-  DBTest() : option_config_(kDefault),\n-             env_(new SpecialEnv(Env::Default())) {\n+  DBTest() : env_(new SpecialEnv(Env::Default())), option_config_(kDefault) {\n     filter_policy_ = NewBloomFilterPolicy(10);\n     dbname_ = test::TmpDir() + \"/db_test\";\n     DestroyDB(dbname_, Options());\n-    db_ = NULL;\n+    db_ = nullptr;\n     Reopen();\n   }\n \n@@ -255,31 +284,27 @@ class DBTest {\n     return options;\n   }\n \n-  DBImpl* dbfull() {\n-    return reinterpret_cast<DBImpl*>(db_);\n-  }\n+  DBImpl* dbfull() { return reinterpret_cast<DBImpl*>(db_); }\n \n-  void Reopen(Options* options = NULL) {\n-    ASSERT_OK(TryReopen(options));\n-  }\n+  void Reopen(Options* options = nullptr) { ASSERT_OK(TryReopen(options)); }\n \n   void Close() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n   }\n \n-  void DestroyAndReopen(Options* options = NULL) {\n+  void DestroyAndReopen(Options* options = nullptr) {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     DestroyDB(dbname_, Options());\n     ASSERT_OK(TryReopen(options));\n   }\n \n   Status TryReopen(Options* options) {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     Options opts;\n-    if (options != NULL) {\n+    if (options != nullptr) {\n       opts = *options;\n     } else {\n       opts = CurrentOptions();\n@@ -294,11 +319,9 @@ class DBTest {\n     return db_->Put(WriteOptions(), k, v);\n   }\n \n-  Status Delete(const std::string& k) {\n-    return db_->Delete(WriteOptions(), k);\n-  }\n+  Status Delete(const std::string& k) { return db_->Delete(WriteOptions(), k); }\n \n-  std::string Get(const std::string& k, const Snapshot* snapshot = NULL) {\n+  std::string Get(const std::string& k, const Snapshot* snapshot = nullptr) {\n     ReadOptions options;\n     options.snapshot = snapshot;\n     std::string result;\n@@ -382,10 +405,9 @@ class DBTest {\n \n   int NumTableFilesAtLevel(int level) {\n     std::string property;\n-    ASSERT_TRUE(\n-        db_->GetProperty(\"leveldb.num-files-at-level\" + NumberToString(level),\n-                         &property));\n-    return atoi(property.c_str());\n+    ASSERT_TRUE(db_->GetProperty(\n+        \"leveldb.num-files-at-level\" + NumberToString(level), &property));\n+    return std::stoi(property);\n   }\n \n   int TotalTableFiles() {\n@@ -431,11 +453,12 @@ class DBTest {\n   }\n \n   // Do n memtable compactions, each of which produces an sstable\n-  // covering the range [small,large].\n-  void MakeTables(int n, const std::string& small, const std::string& large) {\n+  // covering the range [small_key,large_key].\n+  void MakeTables(int n, const std::string& small_key,\n+                  const std::string& large_key) {\n     for (int i = 0; i < n; i++) {\n-      Put(small, \"begin\");\n-      Put(large, \"end\");\n+      Put(small_key, \"begin\");\n+      Put(large_key, \"end\");\n       dbfull()->TEST_CompactMemTable();\n     }\n   }\n@@ -448,9 +471,9 @@ class DBTest {\n \n   void DumpFileCounts(const char* label) {\n     fprintf(stderr, \"---\\n%s:\\n\", label);\n-    fprintf(stderr, \"maxoverlap: %lld\\n\",\n-            static_cast<long long>(\n-                dbfull()->TEST_MaxNextLevelOverlappingBytes()));\n+    fprintf(\n+        stderr, \"maxoverlap: %lld\\n\",\n+        static_cast<long long>(dbfull()->TEST_MaxNextLevelOverlappingBytes()));\n     for (int level = 0; level < config::kNumLevels; level++) {\n       int num = NumTableFilesAtLevel(level);\n       if (num > 0) {\n@@ -506,15 +529,42 @@ class DBTest {\n     }\n     return files_renamed;\n   }\n+\n+ private:\n+  // Sequence of option configurations to try\n+  enum OptionConfig { kDefault, kReuse, kFilter, kUncompressed, kEnd };\n+\n+  const FilterPolicy* filter_policy_;\n+  int option_config_;\n };\n \n TEST(DBTest, Empty) {\n   do {\n-    ASSERT_TRUE(db_ != NULL);\n+    ASSERT_TRUE(db_ != nullptr);\n     ASSERT_EQ(\"NOT_FOUND\", Get(\"foo\"));\n   } while (ChangeOptions());\n }\n \n+TEST(DBTest, EmptyKey) {\n+  do {\n+    ASSERT_OK(Put(\"\", \"v1\"));\n+    ASSERT_EQ(\"v1\", Get(\"\"));\n+    ASSERT_OK(Put(\"\", \"v2\"));\n+    ASSERT_EQ(\"v2\", Get(\"\"));\n+  } while (ChangeOptions());\n+}\n+\n+TEST(DBTest, EmptyValue) {\n+  do {\n+    ASSERT_OK(Put(\"key\", \"v1\"));\n+    ASSERT_EQ(\"v1\", Get(\"key\"));\n+    ASSERT_OK(Put(\"key\", \"\"));\n+    ASSERT_EQ(\"\", Get(\"key\"));\n+    ASSERT_OK(Put(\"key\", \"v2\"));\n+    ASSERT_EQ(\"v2\", Get(\"key\"));\n+  } while (ChangeOptions());\n+}\n+\n TEST(DBTest, ReadWrite) {\n   do {\n     ASSERT_OK(Put(\"foo\", \"v1\"));\n@@ -547,11 +597,13 @@ TEST(DBTest, GetFromImmutableLayer) {\n     ASSERT_OK(Put(\"foo\", \"v1\"));\n     ASSERT_EQ(\"v1\", Get(\"foo\"));\n \n-    env_->delay_data_sync_.Release_Store(env_);      // Block sync calls\n-    Put(\"k1\", std::string(100000, 'x'));             // Fill memtable\n-    Put(\"k2\", std::string(100000, 'y'));             // Trigger compaction\n+    // Block sync calls.\n+    env_->delay_data_sync_.store(true, std::memory_order_release);\n+    Put(\"k1\", std::string(100000, 'x'));  // Fill memtable.\n+    Put(\"k2\", std::string(100000, 'y'));  // Trigger compaction.\n     ASSERT_EQ(\"v1\", Get(\"foo\"));\n-    env_->delay_data_sync_.Release_Store(NULL);      // Release sync calls\n+    // Release sync calls.\n+    env_->delay_data_sync_.store(false, std::memory_order_release);\n   } while (ChangeOptions());\n }\n \n@@ -568,9 +620,9 @@ TEST(DBTest, GetMemUsage) {\n     ASSERT_OK(Put(\"foo\", \"v1\"));\n     std::string val;\n     ASSERT_TRUE(db_->GetProperty(\"leveldb.approximate-memory-usage\", &val));\n-    int mem_usage = atoi(val.c_str());\n+    int mem_usage = std::stoi(val);\n     ASSERT_GT(mem_usage, 0);\n-    ASSERT_LT(mem_usage, 5*1024*1024);\n+    ASSERT_LT(mem_usage, 5 * 1024 * 1024);\n   } while (ChangeOptions());\n }\n \n@@ -592,6 +644,55 @@ TEST(DBTest, GetSnapshot) {\n   } while (ChangeOptions());\n }\n \n+TEST(DBTest, GetIdenticalSnapshots) {\n+  do {\n+    // Try with both a short key and a long key\n+    for (int i = 0; i < 2; i++) {\n+      std::string key = (i == 0) ? std::string(\"foo\") : std::string(200, 'x');\n+      ASSERT_OK(Put(key, \"v1\"));\n+      const Snapshot* s1 = db_->GetSnapshot();\n+      const Snapshot* s2 = db_->GetSnapshot();\n+      const Snapshot* s3 = db_->GetSnapshot();\n+      ASSERT_OK(Put(key, \"v2\"));\n+      ASSERT_EQ(\"v2\", Get(key));\n+      ASSERT_EQ(\"v1\", Get(key, s1));\n+      ASSERT_EQ(\"v1\", Get(key, s2));\n+      ASSERT_EQ(\"v1\", Get(key, s3));\n+      db_->ReleaseSnapshot(s1);\n+      dbfull()->TEST_CompactMemTable();\n+      ASSERT_EQ(\"v2\", Get(key));\n+      ASSERT_EQ(\"v1\", Get(key, s2));\n+      db_->ReleaseSnapshot(s2);\n+      ASSERT_EQ(\"v1\", Get(key, s3));\n+      db_->ReleaseSnapshot(s3);\n+    }\n+  } while (ChangeOptions());\n+}\n+\n+TEST(DBTest, IterateOverEmptySnapshot) {\n+  do {\n+    const Snapshot* snapshot = db_->GetSnapshot();\n+    ReadOptions read_options;\n+    read_options.snapshot = snapshot;\n+    ASSERT_OK(Put(\"foo\", \"v1\"));\n+    ASSERT_OK(Put(\"foo\", \"v2\"));\n+\n+    Iterator* iterator1 = db_->NewIterator(read_options);\n+    iterator1->SeekToFirst();\n+    ASSERT_TRUE(!iterator1->Valid());\n+    delete iterator1;\n+\n+    dbfull()->TEST_CompactMemTable();\n+\n+    Iterator* iterator2 = db_->NewIterator(read_options);\n+    iterator2->SeekToFirst();\n+    ASSERT_TRUE(!iterator2->Valid());\n+    delete iterator2;\n+\n+    db_->ReleaseSnapshot(snapshot);\n+  } while (ChangeOptions());\n+}\n+\n TEST(DBTest, GetLevel0Ordering) {\n   do {\n     // Check that we process level-0 files in correct order.  The code\n@@ -646,8 +747,7 @@ TEST(DBTest, GetEncountersEmptyLevel) {\n \n     // Step 1: First place sstables in levels 0 and 2\n     int compaction_count = 0;\n-    while (NumTableFilesAtLevel(0) == 0 ||\n-           NumTableFilesAtLevel(2) == 0) {\n+    while (NumTableFilesAtLevel(0) == 0 || NumTableFilesAtLevel(2) == 0) {\n       ASSERT_LE(compaction_count, 100) << \"could not fill levels 0 and 2\";\n       compaction_count++;\n       Put(\"a\", \"begin\");\n@@ -656,7 +756,7 @@ TEST(DBTest, GetEncountersEmptyLevel) {\n     }\n \n     // Step 2: clear level 1 if necessary.\n-    dbfull()->TEST_CompactRange(1, NULL, NULL);\n+    dbfull()->TEST_CompactRange(1, nullptr, nullptr);\n     ASSERT_EQ(NumTableFilesAtLevel(0), 1);\n     ASSERT_EQ(NumTableFilesAtLevel(1), 0);\n     ASSERT_EQ(NumTableFilesAtLevel(2), 1);\n@@ -784,10 +884,10 @@ TEST(DBTest, IterMulti) {\n   ASSERT_EQ(IterStatus(iter), \"b->vb\");\n \n   // Make sure iter stays at snapshot\n-  ASSERT_OK(Put(\"a\",  \"va2\"));\n+  ASSERT_OK(Put(\"a\", \"va2\"));\n   ASSERT_OK(Put(\"a2\", \"va3\"));\n-  ASSERT_OK(Put(\"b\",  \"vb2\"));\n-  ASSERT_OK(Put(\"c\",  \"vc2\"));\n+  ASSERT_OK(Put(\"b\", \"vb2\"));\n+  ASSERT_OK(Put(\"c\", \"vc2\"));\n   ASSERT_OK(Delete(\"b\"));\n   iter->SeekToFirst();\n   ASSERT_EQ(IterStatus(iter), \"a->va\");\n@@ -978,7 +1078,7 @@ TEST(DBTest, RecoverWithLargeLog) {\n \n TEST(DBTest, CompactionsGenerateMultipleFiles) {\n   Options options = CurrentOptions();\n-  options.write_buffer_size = 100000000;        // Large write buffer\n+  options.write_buffer_size = 100000000;  // Large write buffer\n   Reopen(&options);\n \n   Random rnd(301);\n@@ -993,7 +1093,7 @@ TEST(DBTest, CompactionsGenerateMultipleFiles) {\n \n   // Reopening moves updates to level-0\n   Reopen(&options);\n-  dbfull()->TEST_CompactRange(0, NULL, NULL);\n+  dbfull()->TEST_CompactRange(0, nullptr, nullptr);\n \n   ASSERT_EQ(NumTableFilesAtLevel(0), 0);\n   ASSERT_GT(NumTableFilesAtLevel(1), 1);\n@@ -1017,7 +1117,7 @@ TEST(DBTest, RepeatedWritesToSameKey) {\n   for (int i = 0; i < 5 * kMaxFiles; i++) {\n     Put(\"key\", value);\n     ASSERT_LE(TotalTableFiles(), kMaxFiles);\n-    fprintf(stderr, \"after %d: %d files\\n\", int(i+1), TotalTableFiles());\n+    fprintf(stderr, \"after %d: %d files\\n\", i + 1, TotalTableFiles());\n   }\n }\n \n@@ -1044,29 +1144,28 @@ TEST(DBTest, SparseMerge) {\n   }\n   Put(\"C\", \"vc\");\n   dbfull()->TEST_CompactMemTable();\n-  dbfull()->TEST_CompactRange(0, NULL, NULL);\n+  dbfull()->TEST_CompactRange(0, nullptr, nullptr);\n \n   // Make sparse update\n-  Put(\"A\",    \"va2\");\n+  Put(\"A\", \"va2\");\n   Put(\"B100\", \"bvalue2\");\n-  Put(\"C\",    \"vc2\");\n+  Put(\"C\", \"vc2\");\n   dbfull()->TEST_CompactMemTable();\n \n   // Compactions should not cause us to create a situation where\n   // a file overlaps too much data at the next level.\n-  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20*1048576);\n-  dbfull()->TEST_CompactRange(0, NULL, NULL);\n-  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20*1048576);\n-  dbfull()->TEST_CompactRange(1, NULL, NULL);\n-  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20*1048576);\n+  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20 * 1048576);\n+  dbfull()->TEST_CompactRange(0, nullptr, nullptr);\n+  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20 * 1048576);\n+  dbfull()->TEST_CompactRange(1, nullptr, nullptr);\n+  ASSERT_LE(dbfull()->TEST_MaxNextLevelOverlappingBytes(), 20 * 1048576);\n }\n \n static bool Between(uint64_t val, uint64_t low, uint64_t high) {\n   bool result = (val >= low) && (val <= high);\n   if (!result) {\n     fprintf(stderr, \"Value %llu is not in range [%llu, %llu]\\n\",\n-            (unsigned long long)(val),\n-            (unsigned long long)(low),\n+            (unsigned long long)(val), (unsigned long long)(low),\n             (unsigned long long)(high));\n   }\n   return result;\n@@ -1075,7 +1174,7 @@ static bool Between(uint64_t val, uint64_t low, uint64_t high) {\n TEST(DBTest, ApproximateSizes) {\n   do {\n     Options options = CurrentOptions();\n-    options.write_buffer_size = 100000000;        // Large write buffer\n+    options.write_buffer_size = 100000000;  // Large write buffer\n     options.compression = kNoCompression;\n     DestroyAndReopen();\n \n@@ -1110,12 +1209,13 @@ TEST(DBTest, ApproximateSizes) {\n \n       for (int compact_start = 0; compact_start < N; compact_start += 10) {\n         for (int i = 0; i < N; i += 10) {\n-          ASSERT_TRUE(Between(Size(\"\", Key(i)), S1*i, S2*i));\n-          ASSERT_TRUE(Between(Size(\"\", Key(i)+\".suffix\"), S1*(i+1), S2*(i+1)));\n-          ASSERT_TRUE(Between(Size(Key(i), Key(i+10)), S1*10, S2*10));\n+          ASSERT_TRUE(Between(Size(\"\", Key(i)), S1 * i, S2 * i));\n+          ASSERT_TRUE(Between(Size(\"\", Key(i) + \".suffix\"), S1 * (i + 1),\n+                              S2 * (i + 1)));\n+          ASSERT_TRUE(Between(Size(Key(i), Key(i + 10)), S1 * 10, S2 * 10));\n         }\n-        ASSERT_TRUE(Between(Size(\"\", Key(50)), S1*50, S2*50));\n-        ASSERT_TRUE(Between(Size(\"\", Key(50)+\".suffix\"), S1*50, S2*50));\n+        ASSERT_TRUE(Between(Size(\"\", Key(50)), S1 * 50, S2 * 50));\n+        ASSERT_TRUE(Between(Size(\"\", Key(50) + \".suffix\"), S1 * 50, S2 * 50));\n \n         std::string cstart_str = Key(compact_start);\n         std::string cend_str = Key(compact_start + 9);\n@@ -1168,7 +1268,7 @@ TEST(DBTest, ApproximateSizes_MixOfSmallAndLarge) {\n \n       ASSERT_TRUE(Between(Size(Key(3), Key(5)), 110000, 111000));\n \n-      dbfull()->TEST_CompactRange(0, NULL, NULL);\n+      dbfull()->TEST_CompactRange(0, nullptr, nullptr);\n     }\n   } while (ChangeOptions());\n }\n@@ -1182,7 +1282,7 @@ TEST(DBTest, IteratorPinsRef) {\n   // Write to force compactions\n   Put(\"foo\", \"newvalue1\");\n   for (int i = 0; i < 100; i++) {\n-    ASSERT_OK(Put(Key(i), Key(i) + std::string(100000, 'v'))); // 100K values\n+    ASSERT_OK(Put(Key(i), Key(i) + std::string(100000, 'v')));  // 100K values\n   }\n   Put(\"foo\", \"newvalue2\");\n \n@@ -1234,7 +1334,7 @@ TEST(DBTest, HiddenValuesAreRemoved) {\n     Put(\"pastfoo\", \"v\");\n     const Snapshot* snapshot = db_->GetSnapshot();\n     Put(\"foo\", \"tiny\");\n-    Put(\"pastfoo2\", \"v2\");        // Advance sequence number one more\n+    Put(\"pastfoo2\", \"v2\");  // Advance sequence number one more\n \n     ASSERT_OK(dbfull()->TEST_CompactMemTable());\n     ASSERT_GT(NumTableFilesAtLevel(0), 0);\n@@ -1244,11 +1344,11 @@ TEST(DBTest, HiddenValuesAreRemoved) {\n     db_->ReleaseSnapshot(snapshot);\n     ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ tiny, \" + big + \" ]\");\n     Slice x(\"x\");\n-    dbfull()->TEST_CompactRange(0, NULL, &x);\n+    dbfull()->TEST_CompactRange(0, nullptr, &x);\n     ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ tiny ]\");\n     ASSERT_EQ(NumTableFilesAtLevel(0), 0);\n     ASSERT_GE(NumTableFilesAtLevel(1), 1);\n-    dbfull()->TEST_CompactRange(1, NULL, &x);\n+    dbfull()->TEST_CompactRange(1, nullptr, &x);\n     ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ tiny ]\");\n \n     ASSERT_TRUE(Between(Size(\"\", \"pastfoo\"), 0, 1000));\n@@ -1259,26 +1359,26 @@ TEST(DBTest, DeletionMarkers1) {\n   Put(\"foo\", \"v1\");\n   ASSERT_OK(dbfull()->TEST_CompactMemTable());\n   const int last = config::kMaxMemCompactLevel;\n-  ASSERT_EQ(NumTableFilesAtLevel(last), 1);   // foo => v1 is now in last level\n+  ASSERT_EQ(NumTableFilesAtLevel(last), 1);  // foo => v1 is now in last level\n \n   // Place a table at level last-1 to prevent merging with preceding mutation\n   Put(\"a\", \"begin\");\n   Put(\"z\", \"end\");\n   dbfull()->TEST_CompactMemTable();\n   ASSERT_EQ(NumTableFilesAtLevel(last), 1);\n-  ASSERT_EQ(NumTableFilesAtLevel(last-1), 1);\n+  ASSERT_EQ(NumTableFilesAtLevel(last - 1), 1);\n \n   Delete(\"foo\");\n   Put(\"foo\", \"v2\");\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ v2, DEL, v1 ]\");\n   ASSERT_OK(dbfull()->TEST_CompactMemTable());  // Moves to level last-2\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ v2, DEL, v1 ]\");\n   Slice z(\"z\");\n-  dbfull()->TEST_CompactRange(last-2, NULL, &z);\n+  dbfull()->TEST_CompactRange(last - 2, nullptr, &z);\n   // DEL eliminated, but v1 remains because we aren't compacting that level\n   // (DEL can be eliminated because v2 hides v1).\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ v2, v1 ]\");\n-  dbfull()->TEST_CompactRange(last-1, NULL, NULL);\n+  dbfull()->TEST_CompactRange(last - 1, nullptr, nullptr);\n   // Merging last-1 w/ last, so we are the base level for \"foo\", so\n   // DEL is removed.  (as is v1).\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ v2 ]\");\n@@ -1288,23 +1388,23 @@ TEST(DBTest, DeletionMarkers2) {\n   Put(\"foo\", \"v1\");\n   ASSERT_OK(dbfull()->TEST_CompactMemTable());\n   const int last = config::kMaxMemCompactLevel;\n-  ASSERT_EQ(NumTableFilesAtLevel(last), 1);   // foo => v1 is now in last level\n+  ASSERT_EQ(NumTableFilesAtLevel(last), 1);  // foo => v1 is now in last level\n \n   // Place a table at level last-1 to prevent merging with preceding mutation\n   Put(\"a\", \"begin\");\n   Put(\"z\", \"end\");\n   dbfull()->TEST_CompactMemTable();\n   ASSERT_EQ(NumTableFilesAtLevel(last), 1);\n-  ASSERT_EQ(NumTableFilesAtLevel(last-1), 1);\n+  ASSERT_EQ(NumTableFilesAtLevel(last - 1), 1);\n \n   Delete(\"foo\");\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ DEL, v1 ]\");\n   ASSERT_OK(dbfull()->TEST_CompactMemTable());  // Moves to level last-2\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ DEL, v1 ]\");\n-  dbfull()->TEST_CompactRange(last-2, NULL, NULL);\n+  dbfull()->TEST_CompactRange(last - 2, nullptr, nullptr);\n   // DEL kept: \"last\" file overlaps\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ DEL, v1 ]\");\n-  dbfull()->TEST_CompactRange(last-1, NULL, NULL);\n+  dbfull()->TEST_CompactRange(last - 1, nullptr, nullptr);\n   // Merging last-1 w/ last, so we are the base level for \"foo\", so\n   // DEL is removed.  (as is v1).\n   ASSERT_EQ(AllEntriesFor(\"foo\"), \"[ ]\");\n@@ -1314,7 +1414,8 @@ TEST(DBTest, OverlapInLevel0) {\n   do {\n     ASSERT_EQ(config::kMaxMemCompactLevel, 2) << \"Fix test to match config\";\n \n-    // Fill levels 1 and 2 to disable the pushing of new memtables to levels > 0.\n+    // Fill levels 1 and 2 to disable the pushing of new memtables to levels >\n+    // 0.\n     ASSERT_OK(Put(\"100\", \"v100\"));\n     ASSERT_OK(Put(\"999\", \"v999\"));\n     dbfull()->TEST_CompactMemTable();\n@@ -1337,8 +1438,8 @@ TEST(DBTest, OverlapInLevel0) {\n     ASSERT_EQ(\"2,1,1\", FilesPerLevel());\n \n     // Compact away the placeholder files we created initially\n-    dbfull()->TEST_CompactRange(1, NULL, NULL);\n-    dbfull()->TEST_CompactRange(2, NULL, NULL);\n+    dbfull()->TEST_CompactRange(1, nullptr, nullptr);\n+    dbfull()->TEST_CompactRange(2, nullptr, nullptr);\n     ASSERT_EQ(\"2\", FilesPerLevel());\n \n     // Do a memtable compaction.  Before bug-fix, the compaction would\n@@ -1370,21 +1471,21 @@ TEST(DBTest, L0_CompactionBug_Issue44_a) {\n \n TEST(DBTest, L0_CompactionBug_Issue44_b) {\n   Reopen();\n-  Put(\"\",\"\");\n+  Put(\"\", \"\");\n   Reopen();\n   Delete(\"e\");\n-  Put(\"\",\"\");\n+  Put(\"\", \"\");\n   Reopen();\n   Put(\"c\", \"cv\");\n   Reopen();\n-  Put(\"\",\"\");\n+  Put(\"\", \"\");\n   Reopen();\n-  Put(\"\",\"\");\n+  Put(\"\", \"\");\n   DelayMilliseconds(1000);  // Wait for compaction to finish\n   Reopen();\n-  Put(\"d\",\"dv\");\n+  Put(\"d\", \"dv\");\n   Reopen();\n-  Put(\"\",\"\");\n+  Put(\"\", \"\");\n   Reopen();\n   Delete(\"d\");\n   Delete(\"b\");\n@@ -1394,17 +1495,26 @@ TEST(DBTest, L0_CompactionBug_Issue44_b) {\n   ASSERT_EQ(\"(->)(c->cv)\", Contents());\n }\n \n+TEST(DBTest, Fflush_Issue474) {\n+  static const int kNum = 100000;\n+  Random rnd(test::RandomSeed());\n+  for (int i = 0; i < kNum; i++) {\n+    fflush(nullptr);\n+    ASSERT_OK(Put(RandomKey(&rnd), RandomString(&rnd, 100)));\n+  }\n+}\n+\n TEST(DBTest, ComparatorCheck) {\n   class NewComparator : public Comparator {\n    public:\n-    virtual const char* Name() const { return \"leveldb.NewComparator\"; }\n-    virtual int Compare(const Slice& a, const Slice& b) const {\n+    const char* Name() const override { return \"leveldb.NewComparator\"; }\n+    int Compare(const Slice& a, const Slice& b) const override {\n       return BytewiseComparator()->Compare(a, b);\n     }\n-    virtual void FindShortestSeparator(std::string* s, const Slice& l) const {\n+    void FindShortestSeparator(std::string* s, const Slice& l) const override {\n       BytewiseComparator()->FindShortestSeparator(s, l);\n     }\n-    virtual void FindShortSuccessor(std::string* key) const {\n+    void FindShortSuccessor(std::string* key) const override {\n       BytewiseComparator()->FindShortSuccessor(key);\n     }\n   };\n@@ -1420,21 +1530,22 @@ TEST(DBTest, ComparatorCheck) {\n TEST(DBTest, CustomComparator) {\n   class NumberComparator : public Comparator {\n    public:\n-    virtual const char* Name() const { return \"test.NumberComparator\"; }\n-    virtual int Compare(const Slice& a, const Slice& b) const {\n+    const char* Name() const override { return \"test.NumberComparator\"; }\n+    int Compare(const Slice& a, const Slice& b) const override {\n       return ToNumber(a) - ToNumber(b);\n     }\n-    virtual void FindShortestSeparator(std::string* s, const Slice& l) const {\n-      ToNumber(*s);     // Check format\n-      ToNumber(l);      // Check format\n+    void FindShortestSeparator(std::string* s, const Slice& l) const override {\n+      ToNumber(*s);  // Check format\n+      ToNumber(l);   // Check format\n     }\n-    virtual void FindShortSuccessor(std::string* key) const {\n-      ToNumber(*key);   // Check format\n+    void FindShortSuccessor(std::string* key) const override {\n+      ToNumber(*key);  // Check format\n     }\n+\n    private:\n     static int ToNumber(const Slice& x) {\n       // Check that there are no extra characters.\n-      ASSERT_TRUE(x.size() >= 2 && x[0] == '[' && x[x.size()-1] == ']')\n+      ASSERT_TRUE(x.size() >= 2 && x[0] == '[' && x[x.size() - 1] == ']')\n           << EscapeString(x);\n       int val;\n       char ignored;\n@@ -1447,7 +1558,7 @@ TEST(DBTest, CustomComparator) {\n   Options new_options = CurrentOptions();\n   new_options.create_if_missing = true;\n   new_options.comparator = &cmp;\n-  new_options.filter_policy = NULL;     // Cannot use bloom filters\n+  new_options.filter_policy = nullptr;   // Cannot use bloom filters\n   new_options.write_buffer_size = 1000;  // Compact more often\n   DestroyAndReopen(&new_options);\n   ASSERT_OK(Put(\"[10]\", \"ten\"));\n@@ -1465,7 +1576,7 @@ TEST(DBTest, CustomComparator) {\n   for (int run = 0; run < 2; run++) {\n     for (int i = 0; i < 1000; i++) {\n       char buf[100];\n-      snprintf(buf, sizeof(buf), \"[%d]\", i*10);\n+      snprintf(buf, sizeof(buf), \"[%d]\", i * 10);\n       ASSERT_OK(Put(buf, buf));\n     }\n     Compact(\"[0]\", \"[1000000]\");\n@@ -1502,7 +1613,7 @@ TEST(DBTest, ManualCompaction) {\n   // Compact all\n   MakeTables(1, \"a\", \"z\");\n   ASSERT_EQ(\"0,1,2\", FilesPerLevel());\n-  db_->CompactRange(NULL, NULL);\n+  db_->CompactRange(nullptr, nullptr);\n   ASSERT_EQ(\"0,0,1\", FilesPerLevel());\n }\n \n@@ -1511,42 +1622,94 @@ TEST(DBTest, DBOpen_Options) {\n   DestroyDB(dbname, Options());\n \n   // Does not exist, and create_if_missing == false: error\n-  DB* db = NULL;\n+  DB* db = nullptr;\n   Options opts;\n   opts.create_if_missing = false;\n   Status s = DB::Open(opts, dbname, &db);\n-  ASSERT_TRUE(strstr(s.ToString().c_str(), \"does not exist\") != NULL);\n-  ASSERT_TRUE(db == NULL);\n+  ASSERT_TRUE(strstr(s.ToString().c_str(), \"does not exist\") != nullptr);\n+  ASSERT_TRUE(db == nullptr);\n \n   // Does not exist, and create_if_missing == true: OK\n   opts.create_if_missing = true;\n   s = DB::Open(opts, dbname, &db);\n   ASSERT_OK(s);\n-  ASSERT_TRUE(db != NULL);\n+  ASSERT_TRUE(db != nullptr);\n \n   delete db;\n-  db = NULL;\n+  db = nullptr;\n \n   // Does exist, and error_if_exists == true: error\n   opts.create_if_missing = false;\n   opts.error_if_exists = true;\n   s = DB::Open(opts, dbname, &db);\n-  ASSERT_TRUE(strstr(s.ToString().c_str(), \"exists\") != NULL);\n-  ASSERT_TRUE(db == NULL);\n+  ASSERT_TRUE(strstr(s.ToString().c_str(), \"exists\") != nullptr);\n+  ASSERT_TRUE(db == nullptr);\n \n   // Does exist, and error_if_exists == false: OK\n   opts.create_if_missing = true;\n   opts.error_if_exists = false;\n   s = DB::Open(opts, dbname, &db);\n   ASSERT_OK(s);\n-  ASSERT_TRUE(db != NULL);\n+  ASSERT_TRUE(db != nullptr);\n+\n+  delete db;\n+  db = nullptr;\n+}\n+\n+TEST(DBTest, DestroyEmptyDir) {\n+  std::string dbname = test::TmpDir() + \"/db_empty_dir\";\n+  TestEnv env(Env::Default());\n+  env.DeleteDir(dbname);\n+  ASSERT_TRUE(!env.FileExists(dbname));\n+\n+  Options opts;\n+  opts.env = &env;\n+\n+  ASSERT_OK(env.CreateDir(dbname));\n+  ASSERT_TRUE(env.FileExists(dbname));\n+  std::vector<std::string> children;\n+  ASSERT_OK(env.GetChildren(dbname, &children));\n+  // The stock Env's do not filter out '.' and '..' special files.\n+  ASSERT_EQ(2, children.size());\n+  ASSERT_OK(DestroyDB(dbname, opts));\n+  ASSERT_TRUE(!env.FileExists(dbname));\n+\n+  // Should also be destroyed if Env is filtering out dot files.\n+  env.SetIgnoreDotFiles(true);\n+  ASSERT_OK(env.CreateDir(dbname));\n+  ASSERT_TRUE(env.FileExists(dbname));\n+  ASSERT_OK(env.GetChildren(dbname, &children));\n+  ASSERT_EQ(0, children.size());\n+  ASSERT_OK(DestroyDB(dbname, opts));\n+  ASSERT_TRUE(!env.FileExists(dbname));\n+}\n+\n+TEST(DBTest, DestroyOpenDB) {\n+  std::string dbname = test::TmpDir() + \"/open_db_dir\";\n+  env_->DeleteDir(dbname);\n+  ASSERT_TRUE(!env_->FileExists(dbname));\n+\n+  Options opts;\n+  opts.create_if_missing = true;\n+  DB* db = nullptr;\n+  ASSERT_OK(DB::Open(opts, dbname, &db));\n+  ASSERT_TRUE(db != nullptr);\n+\n+  // Must fail to destroy an open db.\n+  ASSERT_TRUE(env_->FileExists(dbname));\n+  ASSERT_TRUE(!DestroyDB(dbname, Options()).ok());\n+  ASSERT_TRUE(env_->FileExists(dbname));\n \n   delete db;\n-  db = NULL;\n+  db = nullptr;\n+\n+  // Should succeed destroying a closed db.\n+  ASSERT_OK(DestroyDB(dbname, Options()));\n+  ASSERT_TRUE(!env_->FileExists(dbname));\n }\n \n TEST(DBTest, Locking) {\n-  DB* db2 = NULL;\n+  DB* db2 = nullptr;\n   Status s = DB::Open(CurrentOptions(), dbname_, &db2);\n   ASSERT_TRUE(!s.ok()) << \"Locking did not prevent re-opening db\";\n }\n@@ -1561,13 +1724,14 @@ TEST(DBTest, NoSpace) {\n   ASSERT_EQ(\"v1\", Get(\"foo\"));\n   Compact(\"a\", \"z\");\n   const int num_files = CountFiles();\n-  env_->no_space_.Release_Store(env_);   // Force out-of-space errors\n+  // Force out-of-space errors.\n+  env_->no_space_.store(true, std::memory_order_release);\n   for (int i = 0; i < 10; i++) {\n-    for (int level = 0; level < config::kNumLevels-1; level++) {\n-      dbfull()->TEST_CompactRange(level, NULL, NULL);\n+    for (int level = 0; level < config::kNumLevels - 1; level++) {\n+      dbfull()->TEST_CompactRange(level, nullptr, nullptr);\n     }\n   }\n-  env_->no_space_.Release_Store(NULL);\n+  env_->no_space_.store(false, std::memory_order_release);\n   ASSERT_LT(CountFiles(), num_files + 3);\n }\n \n@@ -1577,7 +1741,8 @@ TEST(DBTest, NonWritableFileSystem) {\n   options.env = env_;\n   Reopen(&options);\n   ASSERT_OK(Put(\"foo\", \"v1\"));\n-  env_->non_writable_.Release_Store(env_);  // Force errors for new files\n+  // Force errors for new files.\n+  env_->non_writable_.store(true, std::memory_order_release);\n   std::string big(100000, 'x');\n   int errors = 0;\n   for (int i = 0; i < 20; i++) {\n@@ -1588,7 +1753,7 @@ TEST(DBTest, NonWritableFileSystem) {\n     }\n   }\n   ASSERT_GT(errors, 0);\n-  env_->non_writable_.Release_Store(NULL);\n+  env_->non_writable_.store(false, std::memory_order_release);\n }\n \n TEST(DBTest, WriteSyncError) {\n@@ -1598,7 +1763,7 @@ TEST(DBTest, WriteSyncError) {\n   Options options = CurrentOptions();\n   options.env = env_;\n   Reopen(&options);\n-  env_->data_sync_error_.Release_Store(env_);\n+  env_->data_sync_error_.store(true, std::memory_order_release);\n \n   // (b) Normal write should succeed\n   WriteOptions w;\n@@ -1612,7 +1777,7 @@ TEST(DBTest, WriteSyncError) {\n   ASSERT_EQ(\"NOT_FOUND\", Get(\"k2\"));\n \n   // (d) make sync behave normally\n-  env_->data_sync_error_.Release_Store(NULL);\n+  env_->data_sync_error_.store(false, std::memory_order_release);\n \n   // (e) Do a non-sync write; should fail\n   w.sync = false;\n@@ -1632,9 +1797,8 @@ TEST(DBTest, ManifestWriteError) {\n   // We iterate twice.  In the second iteration, everything is the\n   // same except the log record never makes it to the MANIFEST file.\n   for (int iter = 0; iter < 2; iter++) {\n-    port::AtomicPointer* error_type = (iter == 0)\n-        ? &env_->manifest_sync_error_\n-        : &env_->manifest_write_error_;\n+    std::atomic<bool>* error_type = (iter == 0) ? &env_->manifest_sync_error_\n+                                                : &env_->manifest_write_error_;\n \n     // Insert foo=>bar mapping\n     Options options = CurrentOptions();\n@@ -1649,15 +1813,15 @@ TEST(DBTest, ManifestWriteError) {\n     dbfull()->TEST_CompactMemTable();\n     ASSERT_EQ(\"bar\", Get(\"foo\"));\n     const int last = config::kMaxMemCompactLevel;\n-    ASSERT_EQ(NumTableFilesAtLevel(last), 1);   // foo=>bar is now in last level\n+    ASSERT_EQ(NumTableFilesAtLevel(last), 1);  // foo=>bar is now in last level\n \n     // Merging compaction (will fail)\n-    error_type->Release_Store(env_);\n-    dbfull()->TEST_CompactRange(last, NULL, NULL);  // Should fail\n+    error_type->store(true, std::memory_order_release);\n+    dbfull()->TEST_CompactRange(last, nullptr, nullptr);  // Should fail\n     ASSERT_EQ(\"bar\", Get(\"foo\"));\n \n     // Recovery: should not lose data\n-    error_type->Release_Store(NULL);\n+    error_type->store(false, std::memory_order_release);\n     Reopen(&options);\n     ASSERT_EQ(\"bar\", Get(\"foo\"));\n   }\n@@ -1677,8 +1841,7 @@ TEST(DBTest, MissingSSTFile) {\n   options.paranoid_checks = true;\n   Status s = TryReopen(&options);\n   ASSERT_TRUE(!s.ok());\n-  ASSERT_TRUE(s.ToString().find(\"issing\") != std::string::npos)\n-      << s.ToString();\n+  ASSERT_TRUE(s.ToString().find(\"issing\") != std::string::npos) << s.ToString();\n }\n \n TEST(DBTest, StillReadSST) {\n@@ -1728,7 +1891,7 @@ TEST(DBTest, BloomFilter) {\n   dbfull()->TEST_CompactMemTable();\n \n   // Prevent auto compactions triggered by seeks\n-  env_->delay_data_sync_.Release_Store(env_);\n+  env_->delay_data_sync_.store(true, std::memory_order_release);\n \n   // Lookup present keys.  Should rarely read from small sstable.\n   env_->random_read_counter_.Reset();\n@@ -1738,7 +1901,7 @@ TEST(DBTest, BloomFilter) {\n   int reads = env_->random_read_counter_.Read();\n   fprintf(stderr, \"%d present => %d reads\\n\", N, reads);\n   ASSERT_GE(reads, N);\n-  ASSERT_LE(reads, N + 2*N/100);\n+  ASSERT_LE(reads, N + 2 * N / 100);\n \n   // Lookup present keys.  Should rarely read from either sstable.\n   env_->random_read_counter_.Reset();\n@@ -1747,9 +1910,9 @@ TEST(DBTest, BloomFilter) {\n   }\n   reads = env_->random_read_counter_.Read();\n   fprintf(stderr, \"%d missing => %d reads\\n\", N, reads);\n-  ASSERT_LE(reads, 3*N/100);\n+  ASSERT_LE(reads, 3 * N / 100);\n \n-  env_->delay_data_sync_.Release_Store(NULL);\n+  env_->delay_data_sync_.store(false, std::memory_order_release);\n   Close();\n   delete options.block_cache;\n   delete options.filter_policy;\n@@ -1764,9 +1927,9 @@ static const int kNumKeys = 1000;\n \n struct MTState {\n   DBTest* test;\n-  port::AtomicPointer stop;\n-  port::AtomicPointer counter[kNumThreads];\n-  port::AtomicPointer thread_done[kNumThreads];\n+  std::atomic<bool> stop;\n+  std::atomic<int> counter[kNumThreads];\n+  std::atomic<bool> thread_done[kNumThreads];\n };\n \n struct MTThread {\n@@ -1778,13 +1941,13 @@ static void MTThreadBody(void* arg) {\n   MTThread* t = reinterpret_cast<MTThread*>(arg);\n   int id = t->id;\n   DB* db = t->state->test->db_;\n-  uintptr_t counter = 0;\n+  int counter = 0;\n   fprintf(stderr, \"... starting thread %d\\n\", id);\n   Random rnd(1000 + id);\n   std::string value;\n   char valbuf[1500];\n-  while (t->state->stop.Acquire_Load() == NULL) {\n-    t->state->counter[id].Release_Store(reinterpret_cast<void*>(counter));\n+  while (!t->state->stop.load(std::memory_order_acquire)) {\n+    t->state->counter[id].store(counter, std::memory_order_release);\n \n     int key = rnd.Uniform(kNumKeys);\n     char keybuf[20];\n@@ -1793,8 +1956,8 @@ static void MTThreadBody(void* arg) {\n     if (rnd.OneIn(2)) {\n       // Write values of the form <key, my id, counter>.\n       // We add some padding for force compactions.\n-      snprintf(valbuf, sizeof(valbuf), \"%d.%d.%-1000d\",\n-               key, id, static_cast<int>(counter));\n+      snprintf(valbuf, sizeof(valbuf), \"%d.%d.%-1000d\", key, id,\n+               static_cast<int>(counter));\n       ASSERT_OK(db->Put(WriteOptions(), Slice(keybuf), Slice(valbuf)));\n     } else {\n       // Read a value and verify that it matches the pattern written above.\n@@ -1809,14 +1972,13 @@ static void MTThreadBody(void* arg) {\n         ASSERT_EQ(k, key);\n         ASSERT_GE(w, 0);\n         ASSERT_LT(w, kNumThreads);\n-        ASSERT_LE(static_cast<uintptr_t>(c), reinterpret_cast<uintptr_t>(\n-            t->state->counter[w].Acquire_Load()));\n+        ASSERT_LE(c, t->state->counter[w].load(std::memory_order_acquire));\n       }\n     }\n     counter++;\n   }\n-  t->state->thread_done[id].Release_Store(t);\n-  fprintf(stderr, \"... stopping thread %d after %d ops\\n\", id, int(counter));\n+  t->state->thread_done[id].store(true, std::memory_order_release);\n+  fprintf(stderr, \"... stopping thread %d after %d ops\\n\", id, counter);\n }\n \n }  // namespace\n@@ -1826,10 +1988,10 @@ TEST(DBTest, MultiThreaded) {\n     // Initialize state\n     MTState mt;\n     mt.test = this;\n-    mt.stop.Release_Store(0);\n+    mt.stop.store(false, std::memory_order_release);\n     for (int id = 0; id < kNumThreads; id++) {\n-      mt.counter[id].Release_Store(0);\n-      mt.thread_done[id].Release_Store(0);\n+      mt.counter[id].store(false, std::memory_order_release);\n+      mt.thread_done[id].store(false, std::memory_order_release);\n     }\n \n     // Start threads\n@@ -1844,9 +2006,9 @@ TEST(DBTest, MultiThreaded) {\n     DelayMilliseconds(kTestSeconds * 1000);\n \n     // Stop the threads and wait for them to finish\n-    mt.stop.Release_Store(&mt);\n+    mt.stop.store(true, std::memory_order_release);\n     for (int id = 0; id < kNumThreads; id++) {\n-      while (mt.thread_done[id].Acquire_Load() == NULL) {\n+      while (!mt.thread_done[id].load(std::memory_order_acquire)) {\n         DelayMilliseconds(100);\n       }\n     }\n@@ -1857,28 +2019,28 @@ namespace {\n typedef std::map<std::string, std::string> KVMap;\n }\n \n-class ModelDB: public DB {\n+class ModelDB : public DB {\n  public:\n   class ModelSnapshot : public Snapshot {\n    public:\n     KVMap map_;\n   };\n \n-  explicit ModelDB(const Options& options): options_(options) { }\n-  ~ModelDB() { }\n-  virtual Status Put(const WriteOptions& o, const Slice& k, const Slice& v) {\n+  explicit ModelDB(const Options& options) : options_(options) {}\n+  ~ModelDB() override = default;\n+  Status Put(const WriteOptions& o, const Slice& k, const Slice& v) override {\n     return DB::Put(o, k, v);\n   }\n-  virtual Status Delete(const WriteOptions& o, const Slice& key) {\n+  Status Delete(const WriteOptions& o, const Slice& key) override {\n     return DB::Delete(o, key);\n   }\n-  virtual Status Get(const ReadOptions& options,\n-                     const Slice& key, std::string* value) {\n-    assert(false);      // Not implemented\n+  Status Get(const ReadOptions& options, const Slice& key,\n+             std::string* value) override {\n+    assert(false);  // Not implemented\n     return Status::NotFound(key);\n   }\n-  virtual Iterator* NewIterator(const ReadOptions& options) {\n-    if (options.snapshot == NULL) {\n+  Iterator* NewIterator(const ReadOptions& options) override {\n+    if (options.snapshot == nullptr) {\n       KVMap* saved = new KVMap;\n       *saved = map_;\n       return new ModelIter(saved, true);\n@@ -1888,68 +2050,65 @@ class ModelDB: public DB {\n       return new ModelIter(snapshot_state, false);\n     }\n   }\n-  virtual const Snapshot* GetSnapshot() {\n+  const Snapshot* GetSnapshot() override {\n     ModelSnapshot* snapshot = new ModelSnapshot;\n     snapshot->map_ = map_;\n     return snapshot;\n   }\n \n-  virtual void ReleaseSnapshot(const Snapshot* snapshot) {\n+  void ReleaseSnapshot(const Snapshot* snapshot) override {\n     delete reinterpret_cast<const ModelSnapshot*>(snapshot);\n   }\n-  virtual Status Write(const WriteOptions& options, WriteBatch* batch) {\n+  Status Write(const WriteOptions& options, WriteBatch* batch) override {\n     class Handler : public WriteBatch::Handler {\n      public:\n       KVMap* map_;\n-      virtual void Put(const Slice& key, const Slice& value) {\n+      void Put(const Slice& key, const Slice& value) override {\n         (*map_)[key.ToString()] = value.ToString();\n       }\n-      virtual void Delete(const Slice& key) {\n-        map_->erase(key.ToString());\n-      }\n+      void Delete(const Slice& key) override { map_->erase(key.ToString()); }\n     };\n     Handler handler;\n     handler.map_ = &map_;\n     return batch->Iterate(&handler);\n   }\n \n-  virtual bool GetProperty(const Slice& property, std::string* value) {\n+  bool GetProperty(const Slice& property, std::string* value) override {\n     return false;\n   }\n-  virtual void GetApproximateSizes(const Range* r, int n, uint64_t* sizes) {\n+  void GetApproximateSizes(const Range* r, int n, uint64_t* sizes) override {\n     for (int i = 0; i < n; i++) {\n       sizes[i] = 0;\n     }\n   }\n-  virtual void CompactRange(const Slice* start, const Slice* end) {\n-  }\n+  void CompactRange(const Slice* start, const Slice* end) override {}\n \n  private:\n-  class ModelIter: public Iterator {\n+  class ModelIter : public Iterator {\n    public:\n     ModelIter(const KVMap* map, bool owned)\n-        : map_(map), owned_(owned), iter_(map_->end()) {\n-    }\n-    ~ModelIter() {\n+        : map_(map), owned_(owned), iter_(map_->end()) {}\n+    ~ModelIter() override {\n       if (owned_) delete map_;\n     }\n-    virtual bool Valid() const { return iter_ != map_->end(); }\n-    virtual void SeekToFirst() { iter_ = map_->begin(); }\n-    virtual void SeekToLast() {\n+    bool Valid() const override { return iter_ != map_->end(); }\n+    void SeekToFirst() override { iter_ = map_->begin(); }\n+    void SeekToLast() override {\n       if (map_->empty()) {\n         iter_ = map_->end();\n       } else {\n         iter_ = map_->find(map_->rbegin()->first);\n       }\n     }\n-    virtual void Seek(const Slice& k) {\n+    void Seek(const Slice& k) override {\n       iter_ = map_->lower_bound(k.ToString());\n     }\n-    virtual void Next() { ++iter_; }\n-    virtual void Prev() { --iter_; }\n-    virtual Slice key() const { return iter_->first; }\n-    virtual Slice value() const { return iter_->second; }\n-    virtual Status status() const { return Status::OK(); }\n+    void Next() override { ++iter_; }\n+    void Prev() override { --iter_; }\n+    Slice key() const override { return iter_->first; }\n+    Slice value() const override { return iter_->second; }\n+    Status status() const override { return Status::OK(); }\n+\n    private:\n     const KVMap* const map_;\n     const bool owned_;  // Do we own map_\n@@ -1959,16 +2118,7 @@ class ModelDB: public DB {\n   KVMap map_;\n };\n \n-static std::string RandomKey(Random* rnd) {\n-  int len = (rnd->OneIn(3)\n-             ? 1                // Short sometimes to encourage collisions\n-             : (rnd->OneIn(100) ? rnd->Skewed(10) : rnd->Uniform(10)));\n-  return test::RandomKey(rnd, len);\n-}\n-\n-static bool CompareIterators(int step,\n-                             DB* model,\n-                             DB* db,\n+static bool CompareIterators(int step, DB* model, DB* db,\n                              const Snapshot* model_snap,\n                              const Snapshot* db_snap) {\n   ReadOptions options;\n@@ -1979,12 +2129,10 @@ static bool CompareIterators(int step,\n   bool ok = true;\n   int count = 0;\n   for (miter->SeekToFirst(), dbiter->SeekToFirst();\n-       ok && miter->Valid() && dbiter->Valid();\n-       miter->Next(), dbiter->Next()) {\n+       ok && miter->Valid() && dbiter->Valid(); miter->Next(), dbiter->Next()) {\n     count++;\n     if (miter->key().compare(dbiter->key()) != 0) {\n-      fprintf(stderr, \"step %d: Key mismatch: '%s' vs. '%s'\\n\",\n-              step,\n+      fprintf(stderr, \"step %d: Key mismatch: '%s' vs. '%s'\\n\", step,\n               EscapeString(miter->key()).c_str(),\n               EscapeString(dbiter->key()).c_str());\n       ok = false;\n@@ -1993,8 +2141,7 @@ static bool CompareIterators(int step,\n \n     if (miter->value().compare(dbiter->value()) != 0) {\n       fprintf(stderr, \"step %d: Value mismatch for key '%s': '%s' vs. '%s'\\n\",\n-              step,\n-              EscapeString(miter->key()).c_str(),\n+              step, EscapeString(miter->key()).c_str(),\n               EscapeString(miter->value()).c_str(),\n               EscapeString(miter->value()).c_str());\n       ok = false;\n@@ -2019,31 +2166,28 @@ TEST(DBTest, Randomized) {\n   do {\n     ModelDB model(CurrentOptions());\n     const int N = 10000;\n-    const Snapshot* model_snap = NULL;\n-    const Snapshot* db_snap = NULL;\n+    const Snapshot* model_snap = nullptr;\n+    const Snapshot* db_snap = nullptr;\n     std::string k, v;\n     for (int step = 0; step < N; step++) {\n       if (step % 100 == 0) {\n         fprintf(stderr, \"Step %d of %d\\n\", step, N);\n       }\n       // TODO(sanjay): Test Get() works\n       int p = rnd.Uniform(100);\n-      if (p < 45) {                               // Put\n+      if (p < 45) {  // Put\n         k = RandomKey(&rnd);\n-        v = RandomString(&rnd,\n-                         rnd.OneIn(20)\n-                         ? 100 + rnd.Uniform(100)\n-                         : rnd.Uniform(8));\n+        v = RandomString(\n+            &rnd, rnd.OneIn(20) ? 100 + rnd.Uniform(100) : rnd.Uniform(8));\n         ASSERT_OK(model.Put(WriteOptions(), k, v));\n         ASSERT_OK(db_->Put(WriteOptions(), k, v));\n \n-      } else if (p < 90) {                        // Delete\n+      } else if (p < 90) {  // Delete\n         k = RandomKey(&rnd);\n         ASSERT_OK(model.Delete(WriteOptions(), k));\n         ASSERT_OK(db_->Delete(WriteOptions(), k));\n \n-\n-      } else {                                    // Multi-element batch\n+      } else {  // Multi-element batch\n         WriteBatch b;\n         const int num = rnd.Uniform(8);\n         for (int i = 0; i < num; i++) {\n@@ -2065,23 +2209,23 @@ TEST(DBTest, Randomized) {\n       }\n \n       if ((step % 100) == 0) {\n-        ASSERT_TRUE(CompareIterators(step, &model, db_, NULL, NULL));\n+        ASSERT_TRUE(CompareIterators(step, &model, db_, nullptr, nullptr));\n         ASSERT_TRUE(CompareIterators(step, &model, db_, model_snap, db_snap));\n         // Save a snapshot from each DB this time that we'll use next\n         // time we compare things, to make sure the current state is\n         // preserved with the snapshot\n-        if (model_snap != NULL) model.ReleaseSnapshot(model_snap);\n-        if (db_snap != NULL) db_->ReleaseSnapshot(db_snap);\n+        if (model_snap != nullptr) model.ReleaseSnapshot(model_snap);\n+        if (db_snap != nullptr) db_->ReleaseSnapshot(db_snap);\n \n         Reopen();\n-        ASSERT_TRUE(CompareIterators(step, &model, db_, NULL, NULL));\n+        ASSERT_TRUE(CompareIterators(step, &model, db_, nullptr, nullptr));\n \n         model_snap = model.GetSnapshot();\n         db_snap = db_->GetSnapshot();\n       }\n     }\n-    if (model_snap != NULL) model.ReleaseSnapshot(model_snap);\n-    if (db_snap != NULL) db_->ReleaseSnapshot(db_snap);\n+    if (model_snap != nullptr) model.ReleaseSnapshot(model_snap);\n+    if (db_snap != nullptr) db_->ReleaseSnapshot(db_snap);\n   } while (ChangeOptions());\n }\n \n@@ -2095,15 +2239,15 @@ void BM_LogAndApply(int iters, int num_base_files) {\n   std::string dbname = test::TmpDir() + \"/leveldb_test_benchmark\";\n   DestroyDB(dbname, Options());\n \n-  DB* db = NULL;\n+  DB* db = nullptr;\n   Options opts;\n   opts.create_if_missing = true;\n   Status s = DB::Open(opts, dbname, &db);\n   ASSERT_OK(s);\n-  ASSERT_TRUE(db != NULL);\n+  ASSERT_TRUE(db != nullptr);\n \n   delete db;\n-  db = NULL;\n+  db = nullptr;\n \n   Env* env = Env::Default();\n \n@@ -2112,14 +2256,14 @@ void BM_LogAndApply(int iters, int num_base_files) {\n \n   InternalKeyComparator cmp(BytewiseComparator());\n   Options options;\n-  VersionSet vset(dbname, &options, NULL, &cmp);\n+  VersionSet vset(dbname, &options, nullptr, &cmp);\n   bool save_manifest;\n   ASSERT_OK(vset.Recover(&save_manifest));\n   VersionEdit vbase;\n   uint64_t fnum = 1;\n   for (int i = 0; i < num_base_files; i++) {\n-    InternalKey start(MakeKey(2*fnum), 1, kTypeValue);\n-    InternalKey limit(MakeKey(2*fnum+1), 1, kTypeDeletion);\n+    InternalKey start(MakeKey(2 * fnum), 1, kTypeValue);\n+    InternalKey limit(MakeKey(2 * fnum + 1), 1, kTypeDeletion);\n     vbase.AddFile(2, fnum++, 1 /* file size */, start, limit);\n   }\n   ASSERT_OK(vset.LogAndApply(&vbase, &mu));\n@@ -2129,8 +2273,8 @@ void BM_LogAndApply(int iters, int num_base_files) {\n   for (int i = 0; i < iters; i++) {\n     VersionEdit vedit;\n     vedit.DeleteFile(2, fnum);\n-    InternalKey start(MakeKey(2*fnum), 1, kTypeValue);\n-    InternalKey limit(MakeKey(2*fnum+1), 1, kTypeDeletion);\n+    InternalKey start(MakeKey(2 * fnum), 1, kTypeValue);\n+    InternalKey limit(MakeKey(2 * fnum + 1), 1, kTypeDeletion);\n     vedit.AddFile(2, fnum++, 1 /* file size */, start, limit);\n     vset.LogAndApply(&vedit, &mu);\n   }\n@@ -2139,8 +2283,8 @@ void BM_LogAndApply(int iters, int num_base_files) {\n   char buf[16];\n   snprintf(buf, sizeof(buf), \"%d\", num_base_files);\n   fprintf(stderr,\n-          \"BM_LogAndApply/%-6s   %8d iters : %9u us (%7.0f us / iter)\\n\",\n-          buf, iters, us, ((float)us) / iters);\n+          \"BM_LogAndApply/%-6s   %8d iters : %9u us (%7.0f us / iter)\\n\", buf,\n+          iters, us, ((float)us) / iters);\n }\n \n }  // namespace leveldb"
      },
      {
        "sha": "459eddf5b136f06876192b893a7b5cb0fea3800e",
        "filename": "src/leveldb/db/dbformat.cc",
        "status": "modified",
        "additions": 20,
        "deletions": 23,
        "changes": 43,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/dbformat.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/dbformat.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/dbformat.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -2,8 +2,12 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include <stdio.h>\n #include \"db/dbformat.h\"\n+\n+#include <stdio.h>\n+\n+#include <sstream>\n+\n #include \"port/port.h\"\n #include \"util/coding.h\"\n \n@@ -21,26 +25,20 @@ void AppendInternalKey(std::string* result, const ParsedInternalKey& key) {\n }\n \n std::string ParsedInternalKey::DebugString() const {\n-  char buf[50];\n-  snprintf(buf, sizeof(buf), \"' @ %llu : %d\",\n-           (unsigned long long) sequence,\n-           int(type));\n-  std::string result = \"'\";\n-  result += EscapeString(user_key.ToString());\n-  result += buf;\n-  return result;\n+  std::ostringstream ss;\n+  ss << '\\'' << EscapeString(user_key.ToString()) << \"' @ \" << sequence << \" : \"\n+     << static_cast<int>(type);\n+  return ss.str();\n }\n \n std::string InternalKey::DebugString() const {\n-  std::string result;\n   ParsedInternalKey parsed;\n   if (ParseInternalKey(rep_, &parsed)) {\n-    result = parsed.DebugString();\n-  } else {\n-    result = \"(bad)\";\n-    result.append(EscapeString(rep_));\n+    return parsed.DebugString();\n   }\n-  return result;\n+  std::ostringstream ss;\n+  ss << \"(bad)\" << EscapeString(rep_);\n+  return ss.str();\n }\n \n const char* InternalKeyComparator::Name() const {\n@@ -65,9 +63,8 @@ int InternalKeyComparator::Compare(const Slice& akey, const Slice& bkey) const {\n   return r;\n }\n \n-void InternalKeyComparator::FindShortestSeparator(\n-      std::string* start,\n-      const Slice& limit) const {\n+void InternalKeyComparator::FindShortestSeparator(std::string* start,\n+                                                  const Slice& limit) const {\n   // Attempt to shorten the user portion of the key\n   Slice user_start = ExtractUserKey(*start);\n   Slice user_limit = ExtractUserKey(limit);\n@@ -77,7 +74,8 @@ void InternalKeyComparator::FindShortestSeparator(\n       user_comparator_->Compare(user_start, tmp) < 0) {\n     // User key has become shorter physically, but larger logically.\n     // Tack on the earliest possible number to the shortened user key.\n-    PutFixed64(&tmp, PackSequenceAndType(kMaxSequenceNumber,kValueTypeForSeek));\n+    PutFixed64(&tmp,\n+               PackSequenceAndType(kMaxSequenceNumber, kValueTypeForSeek));\n     assert(this->Compare(*start, tmp) < 0);\n     assert(this->Compare(tmp, limit) < 0);\n     start->swap(tmp);\n@@ -92,15 +90,14 @@ void InternalKeyComparator::FindShortSuccessor(std::string* key) const {\n       user_comparator_->Compare(user_key, tmp) < 0) {\n     // User key has become shorter physically, but larger logically.\n     // Tack on the earliest possible number to the shortened user key.\n-    PutFixed64(&tmp, PackSequenceAndType(kMaxSequenceNumber,kValueTypeForSeek));\n+    PutFixed64(&tmp,\n+               PackSequenceAndType(kMaxSequenceNumber, kValueTypeForSeek));\n     assert(this->Compare(*key, tmp) < 0);\n     key->swap(tmp);\n   }\n }\n \n-const char* InternalFilterPolicy::Name() const {\n-  return user_policy_->Name();\n-}\n+const char* InternalFilterPolicy::Name() const { return user_policy_->Name(); }\n \n void InternalFilterPolicy::CreateFilter(const Slice* keys, int n,\n                                         std::string* dst) const {"
      },
      {
        "sha": "a1c30ed88c2c822e3d8f529649492d069156cfda",
        "filename": "src/leveldb/db/dbformat.h",
        "status": "modified",
        "additions": 37,
        "deletions": 43,
        "changes": 80,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/dbformat.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/dbformat.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/dbformat.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -5,7 +5,10 @@\n #ifndef STORAGE_LEVELDB_DB_DBFORMAT_H_\n #define STORAGE_LEVELDB_DB_DBFORMAT_H_\n \n-#include <stdio.h>\n+#include <cstddef>\n+#include <cstdint>\n+#include <string>\n+\n #include \"leveldb/comparator.h\"\n #include \"leveldb/db.h\"\n #include \"leveldb/filter_policy.h\"\n@@ -48,10 +51,7 @@ class InternalKey;\n // Value types encoded as the last component of internal keys.\n // DO NOT CHANGE THESE ENUM VALUES: they are embedded in the on-disk\n // data structures.\n-enum ValueType {\n-  kTypeDeletion = 0x0,\n-  kTypeValue = 0x1\n-};\n+enum ValueType { kTypeDeletion = 0x0, kTypeValue = 0x1 };\n // kValueTypeForSeek defines the ValueType that should be passed when\n // constructing a ParsedInternalKey object for seeking to a particular\n // sequence number (since we sort sequence numbers in decreasing order\n@@ -64,17 +64,16 @@ typedef uint64_t SequenceNumber;\n \n // We leave eight bits empty at the bottom so a type and sequence#\n // can be packed together into 64-bits.\n-static const SequenceNumber kMaxSequenceNumber =\n-    ((0x1ull << 56) - 1);\n+static const SequenceNumber kMaxSequenceNumber = ((0x1ull << 56) - 1);\n \n struct ParsedInternalKey {\n   Slice user_key;\n   SequenceNumber sequence;\n   ValueType type;\n \n-  ParsedInternalKey() { }  // Intentionally left uninitialized (for speed)\n+  ParsedInternalKey() {}  // Intentionally left uninitialized (for speed)\n   ParsedInternalKey(const Slice& u, const SequenceNumber& seq, ValueType t)\n-      : user_key(u), sequence(seq), type(t) { }\n+      : user_key(u), sequence(seq), type(t) {}\n   std::string DebugString() const;\n };\n \n@@ -84,43 +83,33 @@ inline size_t InternalKeyEncodingLength(const ParsedInternalKey& key) {\n }\n \n // Append the serialization of \"key\" to *result.\n-extern void AppendInternalKey(std::string* result,\n-                              const ParsedInternalKey& key);\n+void AppendInternalKey(std::string* result, const ParsedInternalKey& key);\n \n // Attempt to parse an internal key from \"internal_key\".  On success,\n // stores the parsed data in \"*result\", and returns true.\n //\n // On error, returns false, leaves \"*result\" in an undefined state.\n-extern bool ParseInternalKey(const Slice& internal_key,\n-                             ParsedInternalKey* result);\n+bool ParseInternalKey(const Slice& internal_key, ParsedInternalKey* result);\n \n // Returns the user key portion of an internal key.\n inline Slice ExtractUserKey(const Slice& internal_key) {\n   assert(internal_key.size() >= 8);\n   return Slice(internal_key.data(), internal_key.size() - 8);\n }\n \n-inline ValueType ExtractValueType(const Slice& internal_key) {\n-  assert(internal_key.size() >= 8);\n-  const size_t n = internal_key.size();\n-  uint64_t num = DecodeFixed64(internal_key.data() + n - 8);\n-  unsigned char c = num & 0xff;\n-  return static_cast<ValueType>(c);\n-}\n-\n // A comparator for internal keys that uses a specified comparator for\n // the user key portion and breaks ties by decreasing sequence number.\n class InternalKeyComparator : public Comparator {\n  private:\n   const Comparator* user_comparator_;\n+\n  public:\n-  explicit InternalKeyComparator(const Comparator* c) : user_comparator_(c) { }\n-  virtual const char* Name() const;\n-  virtual int Compare(const Slice& a, const Slice& b) const;\n-  virtual void FindShortestSeparator(\n-      std::string* start,\n-      const Slice& limit) const;\n-  virtual void FindShortSuccessor(std::string* key) const;\n+  explicit InternalKeyComparator(const Comparator* c) : user_comparator_(c) {}\n+  const char* Name() const override;\n+  int Compare(const Slice& a, const Slice& b) const override;\n+  void FindShortestSeparator(std::string* start,\n+                             const Slice& limit) const override;\n+  void FindShortSuccessor(std::string* key) const override;\n \n   const Comparator* user_comparator() const { return user_comparator_; }\n \n@@ -131,11 +120,12 @@ class InternalKeyComparator : public Comparator {\n class InternalFilterPolicy : public FilterPolicy {\n  private:\n   const FilterPolicy* const user_policy_;\n+\n  public:\n-  explicit InternalFilterPolicy(const FilterPolicy* p) : user_policy_(p) { }\n-  virtual const char* Name() const;\n-  virtual void CreateFilter(const Slice* keys, int n, std::string* dst) const;\n-  virtual bool KeyMayMatch(const Slice& key, const Slice& filter) const;\n+  explicit InternalFilterPolicy(const FilterPolicy* p) : user_policy_(p) {}\n+  const char* Name() const override;\n+  void CreateFilter(const Slice* keys, int n, std::string* dst) const override;\n+  bool KeyMayMatch(const Slice& key, const Slice& filter) const override;\n };\n \n // Modules in this directory should keep internal keys wrapped inside\n@@ -144,13 +134,18 @@ class InternalFilterPolicy : public FilterPolicy {\n class InternalKey {\n  private:\n   std::string rep_;\n+\n  public:\n-  InternalKey() { }   // Leave rep_ as empty to indicate it is invalid\n+  InternalKey() {}  // Leave rep_ as empty to indicate it is invalid\n   InternalKey(const Slice& user_key, SequenceNumber s, ValueType t) {\n     AppendInternalKey(&rep_, ParsedInternalKey(user_key, s, t));\n   }\n \n-  void DecodeFrom(const Slice& s) { rep_.assign(s.data(), s.size()); }\n+  bool DecodeFrom(const Slice& s) {\n+    rep_.assign(s.data(), s.size());\n+    return !rep_.empty();\n+  }\n+\n   Slice Encode() const {\n     assert(!rep_.empty());\n     return rep_;\n@@ -168,8 +163,8 @@ class InternalKey {\n   std::string DebugString() const;\n };\n \n-inline int InternalKeyComparator::Compare(\n-    const InternalKey& a, const InternalKey& b) const {\n+inline int InternalKeyComparator::Compare(const InternalKey& a,\n+                                          const InternalKey& b) const {\n   return Compare(a.Encode(), b.Encode());\n }\n \n@@ -178,11 +173,11 @@ inline bool ParseInternalKey(const Slice& internal_key,\n   const size_t n = internal_key.size();\n   if (n < 8) return false;\n   uint64_t num = DecodeFixed64(internal_key.data() + n - 8);\n-  unsigned char c = num & 0xff;\n+  uint8_t c = num & 0xff;\n   result->sequence = num >> 8;\n   result->type = static_cast<ValueType>(c);\n   result->user_key = Slice(internal_key.data(), n - 8);\n-  return (c <= static_cast<unsigned char>(kTypeValue));\n+  return (c <= static_cast<uint8_t>(kTypeValue));\n }\n \n // A helper class useful for DBImpl::Get()\n@@ -192,6 +187,9 @@ class LookupKey {\n   // the specified sequence number.\n   LookupKey(const Slice& user_key, SequenceNumber sequence);\n \n+  LookupKey(const LookupKey&) = delete;\n+  LookupKey& operator=(const LookupKey&) = delete;\n+\n   ~LookupKey();\n \n   // Return a key suitable for lookup in a MemTable.\n@@ -214,11 +212,7 @@ class LookupKey {\n   const char* start_;\n   const char* kstart_;\n   const char* end_;\n-  char space_[200];      // Avoid allocation for short keys\n-\n-  // No copying allowed\n-  LookupKey(const LookupKey&);\n-  void operator=(const LookupKey&);\n+  char space_[200];  // Avoid allocation for short keys\n };\n \n inline LookupKey::~LookupKey() {"
      },
      {
        "sha": "1209369c31a038ca1c895b213b509155a8d54a8f",
        "filename": "src/leveldb/db/dbformat_test.cc",
        "status": "modified",
        "additions": 57,
        "deletions": 38,
        "changes": 95,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/dbformat_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/dbformat_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/dbformat_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -8,8 +8,7 @@\n \n namespace leveldb {\n \n-static std::string IKey(const std::string& user_key,\n-                        uint64_t seq,\n+static std::string IKey(const std::string& user_key, uint64_t seq,\n                         ValueType vt) {\n   std::string encoded;\n   AppendInternalKey(&encoded, ParsedInternalKey(user_key, seq, vt));\n@@ -28,9 +27,7 @@ static std::string ShortSuccessor(const std::string& s) {\n   return result;\n }\n \n-static void TestKey(const std::string& key,\n-                    uint64_t seq,\n-                    ValueType vt) {\n+static void TestKey(const std::string& key, uint64_t seq, ValueType vt) {\n   std::string encoded = IKey(key, seq, vt);\n \n   Slice in(encoded);\n@@ -44,16 +41,22 @@ static void TestKey(const std::string& key,\n   ASSERT_TRUE(!ParseInternalKey(Slice(\"bar\"), &decoded));\n }\n \n-class FormatTest { };\n+class FormatTest {};\n \n TEST(FormatTest, InternalKey_EncodeDecode) {\n-  const char* keys[] = { \"\", \"k\", \"hello\", \"longggggggggggggggggggggg\" };\n-  const uint64_t seq[] = {\n-    1, 2, 3,\n-    (1ull << 8) - 1, 1ull << 8, (1ull << 8) + 1,\n-    (1ull << 16) - 1, 1ull << 16, (1ull << 16) + 1,\n-    (1ull << 32) - 1, 1ull << 32, (1ull << 32) + 1\n-  };\n+  const char* keys[] = {\"\", \"k\", \"hello\", \"longggggggggggggggggggggg\"};\n+  const uint64_t seq[] = {1,\n+                          2,\n+                          3,\n+                          (1ull << 8) - 1,\n+                          1ull << 8,\n+                          (1ull << 8) + 1,\n+                          (1ull << 16) - 1,\n+                          1ull << 16,\n+                          (1ull << 16) + 1,\n+                          (1ull << 32) - 1,\n+                          1ull << 32,\n+                          (1ull << 32) + 1};\n   for (int k = 0; k < sizeof(keys) / sizeof(keys[0]); k++) {\n     for (int s = 0; s < sizeof(seq) / sizeof(seq[0]); s++) {\n       TestKey(keys[k], seq[s], kTypeValue);\n@@ -62,40 +65,44 @@ TEST(FormatTest, InternalKey_EncodeDecode) {\n   }\n }\n \n+TEST(FormatTest, InternalKey_DecodeFromEmpty) {\n+  InternalKey internal_key;\n+\n+  ASSERT_TRUE(!internal_key.DecodeFrom(\"\"));\n+}\n+\n TEST(FormatTest, InternalKeyShortSeparator) {\n   // When user keys are same\n   ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"foo\", 99, kTypeValue)));\n-  ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"foo\", 101, kTypeValue)));\n-  ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"foo\", 100, kTypeValue)));\n-  ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"foo\", 100, kTypeDeletion)));\n+            Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"foo\", 99, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"foo\", 100, kTypeValue),\n+      Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"foo\", 101, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"foo\", 100, kTypeValue),\n+      Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"foo\", 100, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"foo\", 100, kTypeValue),\n+      Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"foo\", 100, kTypeDeletion)));\n \n   // When user keys are misordered\n   ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"bar\", 99, kTypeValue)));\n+            Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"bar\", 99, kTypeValue)));\n \n   // When user keys are different, but correctly ordered\n-  ASSERT_EQ(IKey(\"g\", kMaxSequenceNumber, kValueTypeForSeek),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"hello\", 200, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"g\", kMaxSequenceNumber, kValueTypeForSeek),\n+      Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"hello\", 200, kTypeValue)));\n \n   // When start user key is prefix of limit user key\n-  ASSERT_EQ(IKey(\"foo\", 100, kTypeValue),\n-            Shorten(IKey(\"foo\", 100, kTypeValue),\n-                    IKey(\"foobar\", 200, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"foo\", 100, kTypeValue),\n+      Shorten(IKey(\"foo\", 100, kTypeValue), IKey(\"foobar\", 200, kTypeValue)));\n \n   // When limit user key is prefix of start user key\n-  ASSERT_EQ(IKey(\"foobar\", 100, kTypeValue),\n-            Shorten(IKey(\"foobar\", 100, kTypeValue),\n-                    IKey(\"foo\", 200, kTypeValue)));\n+  ASSERT_EQ(\n+      IKey(\"foobar\", 100, kTypeValue),\n+      Shorten(IKey(\"foobar\", 100, kTypeValue), IKey(\"foo\", 200, kTypeValue)));\n }\n \n TEST(FormatTest, InternalKeyShortestSuccessor) {\n@@ -105,8 +112,20 @@ TEST(FormatTest, InternalKeyShortestSuccessor) {\n             ShortSuccessor(IKey(\"\\xff\\xff\", 100, kTypeValue)));\n }\n \n-}  // namespace leveldb\n+TEST(FormatTest, ParsedInternalKeyDebugString) {\n+  ParsedInternalKey key(\"The \\\"key\\\" in 'single quotes'\", 42, kTypeValue);\n+\n+  ASSERT_EQ(\"'The \\\"key\\\" in 'single quotes'' @ 42 : 1\", key.DebugString());\n+}\n+\n+TEST(FormatTest, InternalKeyDebugString) {\n+  InternalKey key(\"The \\\"key\\\" in 'single quotes'\", 42, kTypeValue);\n+  ASSERT_EQ(\"'The \\\"key\\\" in 'single quotes'' @ 42 : 1\", key.DebugString());\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n+  InternalKey invalid_key;\n+  ASSERT_EQ(\"(bad)\", invalid_key.DebugString());\n }\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "77d59003cf9696c9eba8728ffee67035cde5cd57",
        "filename": "src/leveldb/db/dumpfile.cc",
        "status": "modified",
        "additions": 18,
        "deletions": 11,
        "changes": 29,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/dumpfile.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/dumpfile.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/dumpfile.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -2,7 +2,10 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n+#include \"leveldb/dumpfile.h\"\n+\n #include <stdio.h>\n+\n #include \"db/dbformat.h\"\n #include \"db/filename.h\"\n #include \"db/log_reader.h\"\n@@ -35,15 +38,16 @@ bool GuessType(const std::string& fname, FileType* type) {\n // Notified when log reader encounters corruption.\n class CorruptionReporter : public log::Reader::Reporter {\n  public:\n-  WritableFile* dst_;\n-  virtual void Corruption(size_t bytes, const Status& status) {\n+  void Corruption(size_t bytes, const Status& status) override {\n     std::string r = \"corruption: \";\n     AppendNumberTo(&r, bytes);\n     r += \" bytes; \";\n     r += status.ToString();\n     r.push_back('\\n');\n     dst_->Append(r);\n   }\n+\n+  WritableFile* dst_;\n };\n \n // Print contents of a log file. (*func)() is called on every record.\n@@ -70,23 +74,23 @@ Status PrintLogContents(Env* env, const std::string& fname,\n // Called on every item found in a WriteBatch.\n class WriteBatchItemPrinter : public WriteBatch::Handler {\n  public:\n-  WritableFile* dst_;\n-  virtual void Put(const Slice& key, const Slice& value) {\n+  void Put(const Slice& key, const Slice& value) override {\n     std::string r = \"  put '\";\n     AppendEscapedStringTo(&r, key);\n     r += \"' '\";\n     AppendEscapedStringTo(&r, value);\n     r += \"'\\n\";\n     dst_->Append(r);\n   }\n-  virtual void Delete(const Slice& key) {\n+  void Delete(const Slice& key) override {\n     std::string r = \"  del '\";\n     AppendEscapedStringTo(&r, key);\n     r += \"'\\n\";\n     dst_->Append(r);\n   }\n-};\n \n+  WritableFile* dst_;\n+};\n \n // Called on every log record (each one of which is a WriteBatch)\n // found in a kLogFile.\n@@ -142,8 +146,8 @@ Status DumpDescriptor(Env* env, const std::string& fname, WritableFile* dst) {\n \n Status DumpTable(Env* env, const std::string& fname, WritableFile* dst) {\n   uint64_t file_size;\n-  RandomAccessFile* file = NULL;\n-  Table* table = NULL;\n+  RandomAccessFile* file = nullptr;\n+  Table* table = nullptr;\n   Status s = env->GetFileSize(fname, &file_size);\n   if (s.ok()) {\n     s = env->NewRandomAccessFile(fname, &file);\n@@ -213,9 +217,12 @@ Status DumpFile(Env* env, const std::string& fname, WritableFile* dst) {\n     return Status::InvalidArgument(fname + \": unknown file type\");\n   }\n   switch (ftype) {\n-    case kLogFile:         return DumpLog(env, fname, dst);\n-    case kDescriptorFile:  return DumpDescriptor(env, fname, dst);\n-    case kTableFile:       return DumpTable(env, fname, dst);\n+    case kLogFile:\n+      return DumpLog(env, fname, dst);\n+    case kDescriptorFile:\n+      return DumpDescriptor(env, fname, dst);\n+    case kTableFile:\n+      return DumpTable(env, fname, dst);\n     default:\n       break;\n   }"
      },
      {
        "sha": "bf705cb60f2431f8b6d163a5fd94656b47eda431",
        "filename": "src/leveldb/db/fault_injection_test.cc",
        "status": "modified",
        "additions": 65,
        "deletions": 67,
        "changes": 132,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/fault_injection_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/fault_injection_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/fault_injection_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -6,18 +6,20 @@\n // the last \"sync\". It then checks for data loss errors by purposely dropping\n // file data (or entire files) not protected by a \"sync\".\n \n-#include \"leveldb/db.h\"\n-\n #include <map>\n #include <set>\n+\n #include \"db/db_impl.h\"\n #include \"db/filename.h\"\n #include \"db/log_format.h\"\n #include \"db/version_set.h\"\n #include \"leveldb/cache.h\"\n+#include \"leveldb/db.h\"\n #include \"leveldb/env.h\"\n #include \"leveldb/table.h\"\n #include \"leveldb/write_batch.h\"\n+#include \"port/port.h\"\n+#include \"port/thread_annotations.h\"\n #include \"util/logging.h\"\n #include \"util/mutexlock.h\"\n #include \"util/testharness.h\"\n@@ -34,7 +36,7 @@ class FaultInjectionTestEnv;\n namespace {\n \n // Assume a filename, and not a directory name like \"/foo/bar/\"\n-static std::string GetDirName(const std::string filename) {\n+static std::string GetDirName(const std::string& filename) {\n   size_t found = filename.find_last_of(\"/\\\\\");\n   if (found == std::string::npos) {\n     return \"\";\n@@ -54,8 +56,7 @@ Status Truncate(const std::string& filename, uint64_t length) {\n \n   SequentialFile* orig_file;\n   Status s = env->NewSequentialFile(filename, &orig_file);\n-  if (!s.ok())\n-    return s;\n+  if (!s.ok()) return s;\n \n   char* scratch = new char[length];\n   leveldb::Slice result;\n@@ -83,15 +84,15 @@ Status Truncate(const std::string& filename, uint64_t length) {\n \n struct FileState {\n   std::string filename_;\n-  ssize_t pos_;\n-  ssize_t pos_at_last_sync_;\n-  ssize_t pos_at_last_flush_;\n+  int64_t pos_;\n+  int64_t pos_at_last_sync_;\n+  int64_t pos_at_last_flush_;\n \n   FileState(const std::string& filename)\n       : filename_(filename),\n         pos_(-1),\n         pos_at_last_sync_(-1),\n-        pos_at_last_flush_(-1) { }\n+        pos_at_last_flush_(-1) {}\n \n   FileState() : pos_(-1), pos_at_last_sync_(-1), pos_at_last_flush_(-1) {}\n \n@@ -106,14 +107,14 @@ struct FileState {\n // is written to or sync'ed.\n class TestWritableFile : public WritableFile {\n  public:\n-  TestWritableFile(const FileState& state,\n-                   WritableFile* f,\n+  TestWritableFile(const FileState& state, WritableFile* f,\n                    FaultInjectionTestEnv* env);\n-  virtual ~TestWritableFile();\n-  virtual Status Append(const Slice& data);\n-  virtual Status Close();\n-  virtual Status Flush();\n-  virtual Status Sync();\n+  ~TestWritableFile() override;\n+  Status Append(const Slice& data) override;\n+  Status Close() override;\n+  Status Flush() override;\n+  Status Sync() override;\n+  std::string GetName() const override { return \"\"; }\n \n  private:\n   FileState state_;\n@@ -126,14 +127,15 @@ class TestWritableFile : public WritableFile {\n \n class FaultInjectionTestEnv : public EnvWrapper {\n  public:\n-  FaultInjectionTestEnv() : EnvWrapper(Env::Default()), filesystem_active_(true) {}\n-  virtual ~FaultInjectionTestEnv() { }\n-  virtual Status NewWritableFile(const std::string& fname,\n-                                 WritableFile** result);\n-  virtual Status NewAppendableFile(const std::string& fname,\n-                                   WritableFile** result);\n-  virtual Status DeleteFile(const std::string& f);\n-  virtual Status RenameFile(const std::string& s, const std::string& t);\n+  FaultInjectionTestEnv()\n+      : EnvWrapper(Env::Default()), filesystem_active_(true) {}\n+  ~FaultInjectionTestEnv() override = default;\n+  Status NewWritableFile(const std::string& fname,\n+                         WritableFile** result) override;\n+  Status NewAppendableFile(const std::string& fname,\n+                           WritableFile** result) override;\n+  Status DeleteFile(const std::string& f) override;\n+  Status RenameFile(const std::string& s, const std::string& t) override;\n \n   void WritableFileClosed(const FileState& state);\n   Status DropUnsyncedFileData();\n@@ -146,24 +148,26 @@ class FaultInjectionTestEnv : public EnvWrapper {\n   // system reset. Setting to inactive will freeze our saved filesystem state so\n   // that it will stop being recorded. It can then be reset back to the state at\n   // the time of the reset.\n-  bool IsFilesystemActive() const { return filesystem_active_; }\n-  void SetFilesystemActive(bool active) { filesystem_active_ = active; }\n+  bool IsFilesystemActive() LOCKS_EXCLUDED(mutex_) {\n+    MutexLock l(&mutex_);\n+    return filesystem_active_;\n+  }\n+  void SetFilesystemActive(bool active) LOCKS_EXCLUDED(mutex_) {\n+    MutexLock l(&mutex_);\n+    filesystem_active_ = active;\n+  }\n \n  private:\n   port::Mutex mutex_;\n-  std::map<std::string, FileState> db_file_state_;\n-  std::set<std::string> new_files_since_last_dir_sync_;\n-  bool filesystem_active_;  // Record flushes, syncs, writes\n+  std::map<std::string, FileState> db_file_state_ GUARDED_BY(mutex_);\n+  std::set<std::string> new_files_since_last_dir_sync_ GUARDED_BY(mutex_);\n+  bool filesystem_active_ GUARDED_BY(mutex_);  // Record flushes, syncs, writes\n };\n \n-TestWritableFile::TestWritableFile(const FileState& state,\n-                                   WritableFile* f,\n+TestWritableFile::TestWritableFile(const FileState& state, WritableFile* f,\n                                    FaultInjectionTestEnv* env)\n-    : state_(state),\n-      target_(f),\n-      writable_file_opened_(true),\n-      env_(env) {\n-  assert(f != NULL);\n+    : state_(state), target_(f), writable_file_opened_(true), env_(env) {\n+  assert(f != nullptr);\n }\n \n TestWritableFile::~TestWritableFile() {\n@@ -265,10 +269,11 @@ Status FaultInjectionTestEnv::NewAppendableFile(const std::string& fname,\n Status FaultInjectionTestEnv::DropUnsyncedFileData() {\n   Status s;\n   MutexLock l(&mutex_);\n-  for (std::map<std::string, FileState>::const_iterator it =\n-           db_file_state_.begin();\n-       s.ok() && it != db_file_state_.end(); ++it) {\n-    const FileState& state = it->second;\n+  for (const auto& kvp : db_file_state_) {\n+    if (!s.ok()) {\n+      break;\n+    }\n+    const FileState& state = kvp.second;\n     if (!state.IsFullySynced()) {\n       s = state.DropUnsyncedData();\n     }\n@@ -328,7 +333,6 @@ void FaultInjectionTestEnv::ResetState() {\n   // Since we are not destroying the database, the existing files\n   // should keep their recorded synced/flushed state. Therefore\n   // we do not reset db_file_state_ and new_files_since_last_dir_sync_.\n-  MutexLock l(&mutex_);\n   SetFilesystemActive(true);\n }\n \n@@ -338,12 +342,14 @@ Status FaultInjectionTestEnv::DeleteFilesCreatedAfterLastDirSync() {\n   std::set<std::string> new_files(new_files_since_last_dir_sync_.begin(),\n                                   new_files_since_last_dir_sync_.end());\n   mutex_.Unlock();\n-  Status s;\n-  std::set<std::string>::const_iterator it;\n-  for (it = new_files.begin(); s.ok() && it != new_files.end(); ++it) {\n-    s = DeleteFile(*it);\n+  Status status;\n+  for (const auto& new_file : new_files) {\n+    Status delete_status = DeleteFile(new_file);\n+    if (!delete_status.ok() && status.ok()) {\n+      status = std::move(delete_status);\n+    }\n   }\n-  return s;\n+  return status;\n }\n \n void FaultInjectionTestEnv::WritableFileClosed(const FileState& state) {\n@@ -352,7 +358,7 @@ void FaultInjectionTestEnv::WritableFileClosed(const FileState& state) {\n }\n \n Status FileState::DropUnsyncedData() const {\n-  ssize_t sync_pos = pos_at_last_sync_ == -1 ? 0 : pos_at_last_sync_;\n+  int64_t sync_pos = pos_at_last_sync_ == -1 ? 0 : pos_at_last_sync_;\n   return Truncate(filename_, sync_pos);\n }\n \n@@ -370,7 +376,7 @@ class FaultInjectionTest {\n   FaultInjectionTest()\n       : env_(new FaultInjectionTestEnv),\n         tiny_cache_(NewLRUCache(100)),\n-        db_(NULL) {\n+        db_(nullptr) {\n     dbname_ = test::TmpDir() + \"/fault_test\";\n     DestroyDB(dbname_, Options());  // Destroy any db from earlier run\n     options_.reuse_logs = true;\n@@ -387,9 +393,7 @@ class FaultInjectionTest {\n     delete env_;\n   }\n \n-  void ReuseLogs(bool reuse) {\n-    options_.reuse_logs = reuse;\n-  }\n+  void ReuseLogs(bool reuse) { options_.reuse_logs = reuse; }\n \n   void Build(int start_idx, int num_vals) {\n     std::string key_space, value_space;\n@@ -449,19 +453,18 @@ class FaultInjectionTest {\n \n   Status OpenDB() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     env_->ResetState();\n     return DB::Open(options_, dbname_, &db_);\n   }\n \n   void CloseDB() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n   }\n \n   void DeleteAllData() {\n     Iterator* iter = db_->NewIterator(ReadOptions());\n-    WriteOptions options;\n     for (iter->SeekToFirst(); iter->Valid(); iter->Next()) {\n       ASSERT_OK(db_->Delete(WriteOptions(), iter->key()));\n     }\n@@ -485,23 +488,22 @@ class FaultInjectionTest {\n   void PartialCompactTestPreFault(int num_pre_sync, int num_post_sync) {\n     DeleteAllData();\n     Build(0, num_pre_sync);\n-    db_->CompactRange(NULL, NULL);\n+    db_->CompactRange(nullptr, nullptr);\n     Build(num_pre_sync, num_post_sync);\n   }\n \n   void PartialCompactTestReopenWithFault(ResetMethod reset_method,\n-                                         int num_pre_sync,\n-                                         int num_post_sync) {\n+                                         int num_pre_sync, int num_post_sync) {\n     env_->SetFilesystemActive(false);\n     CloseDB();\n     ResetDBState(reset_method);\n     ASSERT_OK(OpenDB());\n     ASSERT_OK(Verify(0, num_pre_sync, FaultInjectionTest::VAL_EXPECT_NO_ERROR));\n-    ASSERT_OK(Verify(num_pre_sync, num_post_sync, FaultInjectionTest::VAL_EXPECT_ERROR));\n+    ASSERT_OK(Verify(num_pre_sync, num_post_sync,\n+                     FaultInjectionTest::VAL_EXPECT_ERROR));\n   }\n \n-  void NoWriteTestPreFault() {\n-  }\n+  void NoWriteTestPreFault() {}\n \n   void NoWriteTestReopenWithFault(ResetMethod reset_method) {\n     CloseDB();\n@@ -517,8 +519,7 @@ class FaultInjectionTest {\n       int num_post_sync = rnd.Uniform(kMaxNumValues);\n \n       PartialCompactTestPreFault(num_pre_sync, num_post_sync);\n-      PartialCompactTestReopenWithFault(RESET_DROP_UNSYNCED_DATA,\n-                                        num_pre_sync,\n+      PartialCompactTestReopenWithFault(RESET_DROP_UNSYNCED_DATA, num_pre_sync,\n                                         num_post_sync);\n \n       NoWriteTestPreFault();\n@@ -528,8 +529,7 @@ class FaultInjectionTest {\n       // No new files created so we expect all values since no files will be\n       // dropped.\n       PartialCompactTestReopenWithFault(RESET_DELETE_UNSYNCED_FILES,\n-                                        num_pre_sync + num_post_sync,\n-                                        0);\n+                                        num_pre_sync + num_post_sync, 0);\n \n       NoWriteTestPreFault();\n       NoWriteTestReopenWithFault(RESET_DELETE_UNSYNCED_FILES);\n@@ -549,6 +549,4 @@ TEST(FaultInjectionTest, FaultTestWithLogReuse) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "85de45c507b78cc7040ba117b414f6a228d7554d",
        "filename": "src/leveldb/db/filename.cc",
        "status": "modified",
        "additions": 17,
        "deletions": 20,
        "changes": 37,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/filename.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/filename.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/filename.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -2,41 +2,42 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n+#include \"db/filename.h\"\n+\n #include <ctype.h>\n #include <stdio.h>\n-#include \"db/filename.h\"\n+\n #include \"db/dbformat.h\"\n #include \"leveldb/env.h\"\n #include \"util/logging.h\"\n \n namespace leveldb {\n \n // A utility routine: write \"data\" to the named file and Sync() it.\n-extern Status WriteStringToFileSync(Env* env, const Slice& data,\n-                                    const std::string& fname);\n+Status WriteStringToFileSync(Env* env, const Slice& data,\n+                             const std::string& fname);\n \n-static std::string MakeFileName(const std::string& name, uint64_t number,\n+static std::string MakeFileName(const std::string& dbname, uint64_t number,\n                                 const char* suffix) {\n   char buf[100];\n   snprintf(buf, sizeof(buf), \"/%06llu.%s\",\n-           static_cast<unsigned long long>(number),\n-           suffix);\n-  return name + buf;\n+           static_cast<unsigned long long>(number), suffix);\n+  return dbname + buf;\n }\n \n-std::string LogFileName(const std::string& name, uint64_t number) {\n+std::string LogFileName(const std::string& dbname, uint64_t number) {\n   assert(number > 0);\n-  return MakeFileName(name, number, \"log\");\n+  return MakeFileName(dbname, number, \"log\");\n }\n \n-std::string TableFileName(const std::string& name, uint64_t number) {\n+std::string TableFileName(const std::string& dbname, uint64_t number) {\n   assert(number > 0);\n-  return MakeFileName(name, number, \"ldb\");\n+  return MakeFileName(dbname, number, \"ldb\");\n }\n \n-std::string SSTTableFileName(const std::string& name, uint64_t number) {\n+std::string SSTTableFileName(const std::string& dbname, uint64_t number) {\n   assert(number > 0);\n-  return MakeFileName(name, number, \"sst\");\n+  return MakeFileName(dbname, number, \"sst\");\n }\n \n std::string DescriptorFileName(const std::string& dbname, uint64_t number) {\n@@ -51,9 +52,7 @@ std::string CurrentFileName(const std::string& dbname) {\n   return dbname + \"/CURRENT\";\n }\n \n-std::string LockFileName(const std::string& dbname) {\n-  return dbname + \"/LOCK\";\n-}\n+std::string LockFileName(const std::string& dbname) { return dbname + \"/LOCK\"; }\n \n std::string TempFileName(const std::string& dbname, uint64_t number) {\n   assert(number > 0);\n@@ -69,18 +68,16 @@ std::string OldInfoLogFileName(const std::string& dbname) {\n   return dbname + \"/LOG.old\";\n }\n \n-\n // Owned filenames have the form:\n //    dbname/CURRENT\n //    dbname/LOCK\n //    dbname/LOG\n //    dbname/LOG.old\n //    dbname/MANIFEST-[0-9]+\n //    dbname/[0-9]+.(log|sst|ldb)\n-bool ParseFileName(const std::string& fname,\n-                   uint64_t* number,\n+bool ParseFileName(const std::string& filename, uint64_t* number,\n                    FileType* type) {\n-  Slice rest(fname);\n+  Slice rest(filename);\n   if (rest == \"CURRENT\") {\n     *number = 0;\n     *type = kCurrentFile;"
      },
      {
        "sha": "524e813c06d2e5333881041fe50eae277d8f5382",
        "filename": "src/leveldb/db/filename.h",
        "status": "modified",
        "additions": 15,
        "deletions": 16,
        "changes": 31,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/filename.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/filename.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/filename.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -8,7 +8,9 @@\n #define STORAGE_LEVELDB_DB_FILENAME_H_\n \n #include <stdint.h>\n+\n #include <string>\n+\n #include \"leveldb/slice.h\"\n #include \"leveldb/status.h\"\n #include \"port/port.h\"\n@@ -30,55 +32,52 @@ enum FileType {\n // Return the name of the log file with the specified number\n // in the db named by \"dbname\".  The result will be prefixed with\n // \"dbname\".\n-extern std::string LogFileName(const std::string& dbname, uint64_t number);\n+std::string LogFileName(const std::string& dbname, uint64_t number);\n \n // Return the name of the sstable with the specified number\n // in the db named by \"dbname\".  The result will be prefixed with\n // \"dbname\".\n-extern std::string TableFileName(const std::string& dbname, uint64_t number);\n+std::string TableFileName(const std::string& dbname, uint64_t number);\n \n // Return the legacy file name for an sstable with the specified number\n // in the db named by \"dbname\". The result will be prefixed with\n // \"dbname\".\n-extern std::string SSTTableFileName(const std::string& dbname, uint64_t number);\n+std::string SSTTableFileName(const std::string& dbname, uint64_t number);\n \n // Return the name of the descriptor file for the db named by\n // \"dbname\" and the specified incarnation number.  The result will be\n // prefixed with \"dbname\".\n-extern std::string DescriptorFileName(const std::string& dbname,\n-                                      uint64_t number);\n+std::string DescriptorFileName(const std::string& dbname, uint64_t number);\n \n // Return the name of the current file.  This file contains the name\n // of the current manifest file.  The result will be prefixed with\n // \"dbname\".\n-extern std::string CurrentFileName(const std::string& dbname);\n+std::string CurrentFileName(const std::string& dbname);\n \n // Return the name of the lock file for the db named by\n // \"dbname\".  The result will be prefixed with \"dbname\".\n-extern std::string LockFileName(const std::string& dbname);\n+std::string LockFileName(const std::string& dbname);\n \n // Return the name of a temporary file owned by the db named \"dbname\".\n // The result will be prefixed with \"dbname\".\n-extern std::string TempFileName(const std::string& dbname, uint64_t number);\n+std::string TempFileName(const std::string& dbname, uint64_t number);\n \n // Return the name of the info log file for \"dbname\".\n-extern std::string InfoLogFileName(const std::string& dbname);\n+std::string InfoLogFileName(const std::string& dbname);\n \n // Return the name of the old info log file for \"dbname\".\n-extern std::string OldInfoLogFileName(const std::string& dbname);\n+std::string OldInfoLogFileName(const std::string& dbname);\n \n // If filename is a leveldb file, store the type of the file in *type.\n // The number encoded in the filename is stored in *number.  If the\n // filename was successfully parsed, returns true.  Else return false.\n-extern bool ParseFileName(const std::string& filename,\n-                          uint64_t* number,\n-                          FileType* type);\n+bool ParseFileName(const std::string& filename, uint64_t* number,\n+                   FileType* type);\n \n // Make the CURRENT file point to the descriptor file with the\n // specified number.\n-extern Status SetCurrentFile(Env* env, const std::string& dbname,\n-                             uint64_t descriptor_number);\n-\n+Status SetCurrentFile(Env* env, const std::string& dbname,\n+                      uint64_t descriptor_number);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "952f32008ed7ffeb01860d67812c905abbde9ff8",
        "filename": "src/leveldb/db/filename_test.cc",
        "status": "modified",
        "additions": 47,
        "deletions": 39,
        "changes": 86,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/filename_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/filename_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/filename_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -11,7 +11,7 @@\n \n namespace leveldb {\n \n-class FileNameTest { };\n+class FileNameTest {};\n \n TEST(FileNameTest, Parse) {\n   Slice db;\n@@ -24,17 +24,17 @@ TEST(FileNameTest, Parse) {\n     uint64_t number;\n     FileType type;\n   } cases[] = {\n-    { \"100.log\",            100,   kLogFile },\n-    { \"0.log\",              0,     kLogFile },\n-    { \"0.sst\",              0,     kTableFile },\n-    { \"0.ldb\",              0,     kTableFile },\n-    { \"CURRENT\",            0,     kCurrentFile },\n-    { \"LOCK\",               0,     kDBLockFile },\n-    { \"MANIFEST-2\",         2,     kDescriptorFile },\n-    { \"MANIFEST-7\",         7,     kDescriptorFile },\n-    { \"LOG\",                0,     kInfoLogFile },\n-    { \"LOG.old\",            0,     kInfoLogFile },\n-    { \"18446744073709551615.log\", 18446744073709551615ull, kLogFile },\n+      {\"100.log\", 100, kLogFile},\n+      {\"0.log\", 0, kLogFile},\n+      {\"0.sst\", 0, kTableFile},\n+      {\"0.ldb\", 0, kTableFile},\n+      {\"CURRENT\", 0, kCurrentFile},\n+      {\"LOCK\", 0, kDBLockFile},\n+      {\"MANIFEST-2\", 2, kDescriptorFile},\n+      {\"MANIFEST-7\", 7, kDescriptorFile},\n+      {\"LOG\", 0, kInfoLogFile},\n+      {\"LOG.old\", 0, kInfoLogFile},\n+      {\"18446744073709551615.log\", 18446744073709551615ull, kLogFile},\n   };\n   for (int i = 0; i < sizeof(cases) / sizeof(cases[0]); i++) {\n     std::string f = cases[i].fname;\n@@ -44,30 +44,28 @@ TEST(FileNameTest, Parse) {\n   }\n \n   // Errors\n-  static const char* errors[] = {\n-    \"\",\n-    \"foo\",\n-    \"foo-dx-100.log\",\n-    \".log\",\n-    \"\",\n-    \"manifest\",\n-    \"CURREN\",\n-    \"CURRENTX\",\n-    \"MANIFES\",\n-    \"MANIFEST\",\n-    \"MANIFEST-\",\n-    \"XMANIFEST-3\",\n-    \"MANIFEST-3x\",\n-    \"LOC\",\n-    \"LOCKx\",\n-    \"LO\",\n-    \"LOGx\",\n-    \"18446744073709551616.log\",\n-    \"184467440737095516150.log\",\n-    \"100\",\n-    \"100.\",\n-    \"100.lop\"\n-  };\n+  static const char* errors[] = {\"\",\n+                                 \"foo\",\n+                                 \"foo-dx-100.log\",\n+                                 \".log\",\n+                                 \"\",\n+                                 \"manifest\",\n+                                 \"CURREN\",\n+                                 \"CURRENTX\",\n+                                 \"MANIFES\",\n+                                 \"MANIFEST\",\n+                                 \"MANIFEST-\",\n+                                 \"XMANIFEST-3\",\n+                                 \"MANIFEST-3x\",\n+                                 \"LOC\",\n+                                 \"LOCKx\",\n+                                 \"LO\",\n+                                 \"LOGx\",\n+                                 \"18446744073709551616.log\",\n+                                 \"184467440737095516150.log\",\n+                                 \"100\",\n+                                 \"100.\",\n+                                 \"100.lop\"};\n   for (int i = 0; i < sizeof(errors) / sizeof(errors[0]); i++) {\n     std::string f = errors[i];\n     ASSERT_TRUE(!ParseFileName(f, &number, &type)) << f;\n@@ -114,10 +112,20 @@ TEST(FileNameTest, Construction) {\n   ASSERT_TRUE(ParseFileName(fname.c_str() + 4, &number, &type));\n   ASSERT_EQ(999, number);\n   ASSERT_EQ(kTempFile, type);\n+\n+  fname = InfoLogFileName(\"foo\");\n+  ASSERT_EQ(\"foo/\", std::string(fname.data(), 4));\n+  ASSERT_TRUE(ParseFileName(fname.c_str() + 4, &number, &type));\n+  ASSERT_EQ(0, number);\n+  ASSERT_EQ(kInfoLogFile, type);\n+\n+  fname = OldInfoLogFileName(\"foo\");\n+  ASSERT_EQ(\"foo/\", std::string(fname.data(), 4));\n+  ASSERT_TRUE(ParseFileName(fname.c_str() + 4, &number, &type));\n+  ASSERT_EQ(0, number);\n+  ASSERT_EQ(kInfoLogFile, type);\n }\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "9ed9667d376b3a8946166af399e271a22009c5d9",
        "filename": "src/leveldb/db/leveldbutil.cc",
        "status": "modified",
        "additions": 10,
        "deletions": 11,
        "changes": 21,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/leveldbutil.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/leveldbutil.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/leveldbutil.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -3,6 +3,7 @@\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n #include <stdio.h>\n+\n #include \"leveldb/dumpfile.h\"\n #include \"leveldb/env.h\"\n #include \"leveldb/status.h\"\n@@ -12,14 +13,14 @@ namespace {\n \n class StdoutPrinter : public WritableFile {\n  public:\n-  virtual Status Append(const Slice& data) {\n+  Status Append(const Slice& data) override {\n     fwrite(data.data(), 1, data.size(), stdout);\n     return Status::OK();\n   }\n-  virtual Status Close() { return Status::OK(); }\n-  virtual Status Flush() { return Status::OK(); }\n-  virtual Status Sync() { return Status::OK(); }\n-  virtual std::string GetName() const { return \"[stdout]\"; }\n+  Status Close() override { return Status::OK(); }\n+  Status Flush() override { return Status::OK(); }\n+  Status Sync() override { return Status::OK(); }\n+  std::string GetName() const override { return \"[stdout]\"; }\n };\n \n bool HandleDumpCommand(Env* env, char** files, int num) {\n@@ -39,11 +40,9 @@ bool HandleDumpCommand(Env* env, char** files, int num) {\n }  // namespace leveldb\n \n static void Usage() {\n-  fprintf(\n-      stderr,\n-      \"Usage: leveldbutil command...\\n\"\n-      \"   dump files...         -- dump contents of specified files\\n\"\n-      );\n+  fprintf(stderr,\n+          \"Usage: leveldbutil command...\\n\"\n+          \"   dump files...         -- dump contents of specified files\\n\");\n }\n \n int main(int argc, char** argv) {\n@@ -55,7 +54,7 @@ int main(int argc, char** argv) {\n   } else {\n     std::string command = argv[1];\n     if (command == \"dump\") {\n-      ok = leveldb::HandleDumpCommand(env, argv+2, argc-2);\n+      ok = leveldb::HandleDumpCommand(env, argv + 2, argc - 2);\n     } else {\n       Usage();\n       ok = false;"
      },
      {
        "sha": "1ccfb7b34aa85a6f37b5e515ff10e09b786c642a",
        "filename": "src/leveldb/db/log_reader.cc",
        "status": "modified",
        "additions": 9,
        "deletions": 19,
        "changes": 28,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/log_reader.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/log_reader.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/log_reader.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -5,15 +5,15 @@\n #include \"db/log_reader.h\"\n \n #include <stdio.h>\n+\n #include \"leveldb/env.h\"\n #include \"util/coding.h\"\n #include \"util/crc32c.h\"\n \n namespace leveldb {\n namespace log {\n \n-Reader::Reporter::~Reporter() {\n-}\n+Reader::Reporter::~Reporter() = default;\n \n Reader::Reader(SequentialFile* file, Reporter* reporter, bool checksum,\n                uint64_t initial_offset)\n@@ -26,20 +26,16 @@ Reader::Reader(SequentialFile* file, Reporter* reporter, bool checksum,\n       last_record_offset_(0),\n       end_of_buffer_offset_(0),\n       initial_offset_(initial_offset),\n-      resyncing_(initial_offset > 0) {\n-}\n+      resyncing_(initial_offset > 0) {}\n \n-Reader::~Reader() {\n-  delete[] backing_store_;\n-}\n+Reader::~Reader() { delete[] backing_store_; }\n \n bool Reader::SkipToInitialBlock() {\n-  size_t offset_in_block = initial_offset_ % kBlockSize;\n+  const size_t offset_in_block = initial_offset_ % kBlockSize;\n   uint64_t block_start_location = initial_offset_ - offset_in_block;\n \n   // Don't search a block if we'd be in the trailer\n   if (offset_in_block > kBlockSize - 6) {\n-    offset_in_block = 0;\n     block_start_location += kBlockSize;\n   }\n \n@@ -99,9 +95,7 @@ bool Reader::ReadRecord(Slice* record, std::string* scratch) {\n           // it could emit an empty kFirstType record at the tail end\n           // of a block followed by a kFullType or kFirstType record\n           // at the beginning of the next block.\n-          if (scratch->empty()) {\n-            in_fragmented_record = false;\n-          } else {\n+          if (!scratch->empty()) {\n             ReportCorruption(scratch->size(), \"partial record without end(1)\");\n           }\n         }\n@@ -117,9 +111,7 @@ bool Reader::ReadRecord(Slice* record, std::string* scratch) {\n           // it could emit an empty kFirstType record at the tail end\n           // of a block followed by a kFullType or kFirstType record\n           // at the beginning of the next block.\n-          if (scratch->empty()) {\n-            in_fragmented_record = false;\n-          } else {\n+          if (!scratch->empty()) {\n             ReportCorruption(scratch->size(), \"partial record without end(2)\");\n           }\n         }\n@@ -181,16 +173,14 @@ bool Reader::ReadRecord(Slice* record, std::string* scratch) {\n   return false;\n }\n \n-uint64_t Reader::LastRecordOffset() {\n-  return last_record_offset_;\n-}\n+uint64_t Reader::LastRecordOffset() { return last_record_offset_; }\n \n void Reader::ReportCorruption(uint64_t bytes, const char* reason) {\n   ReportDrop(bytes, Status::Corruption(reason, file_->GetName()));\n }\n \n void Reader::ReportDrop(uint64_t bytes, const Status& reason) {\n-  if (reporter_ != NULL &&\n+  if (reporter_ != nullptr &&\n       end_of_buffer_offset_ - buffer_.size() - bytes >= initial_offset_) {\n     reporter_->Corruption(static_cast<size_t>(bytes), reason);\n   }"
      },
      {
        "sha": "001da8948a12c9146b34f10a757c4382cd8a781e",
        "filename": "src/leveldb/db/log_reader.h",
        "status": "modified",
        "additions": 23,
        "deletions": 24,
        "changes": 47,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/log_reader.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/log_reader.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/log_reader.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -32,7 +32,7 @@ class Reader {\n   // Create a reader that will return log records from \"*file\".\n   // \"*file\" must remain live while this Reader is in use.\n   //\n-  // If \"reporter\" is non-NULL, it is notified whenever some data is\n+  // If \"reporter\" is non-null, it is notified whenever some data is\n   // dropped due to a detected corruption.  \"*reporter\" must remain\n   // live while this Reader is in use.\n   //\n@@ -43,6 +43,9 @@ class Reader {\n   Reader(SequentialFile* file, Reporter* reporter, bool checksum,\n          uint64_t initial_offset);\n \n+  Reader(const Reader&) = delete;\n+  Reader& operator=(const Reader&) = delete;\n+\n   ~Reader();\n \n   // Read the next record into *record.  Returns true if read\n@@ -58,26 +61,6 @@ class Reader {\n   uint64_t LastRecordOffset();\n \n  private:\n-  SequentialFile* const file_;\n-  Reporter* const reporter_;\n-  bool const checksum_;\n-  char* const backing_store_;\n-  Slice buffer_;\n-  bool eof_;   // Last Read() indicated EOF by returning < kBlockSize\n-\n-  // Offset of the last record returned by ReadRecord.\n-  uint64_t last_record_offset_;\n-  // Offset of the first location past the end of buffer_.\n-  uint64_t end_of_buffer_offset_;\n-\n-  // Offset at which to start looking for the first record to return\n-  uint64_t const initial_offset_;\n-\n-  // True if we are resynchronizing after a seek (initial_offset_ > 0). In\n-  // particular, a run of kMiddleType and kLastType records can be silently\n-  // skipped in this mode\n-  bool resyncing_;\n-\n   // Extend record types with the following special values\n   enum {\n     kEof = kMaxRecordType + 1,\n@@ -102,9 +85,25 @@ class Reader {\n   void ReportCorruption(uint64_t bytes, const char* reason);\n   void ReportDrop(uint64_t bytes, const Status& reason);\n \n-  // No copying allowed\n-  Reader(const Reader&);\n-  void operator=(const Reader&);\n+  SequentialFile* const file_;\n+  Reporter* const reporter_;\n+  bool const checksum_;\n+  char* const backing_store_;\n+  Slice buffer_;\n+  bool eof_;  // Last Read() indicated EOF by returning < kBlockSize\n+\n+  // Offset of the last record returned by ReadRecord.\n+  uint64_t last_record_offset_;\n+  // Offset of the first location past the end of buffer_.\n+  uint64_t end_of_buffer_offset_;\n+\n+  // Offset at which to start looking for the first record to return\n+  uint64_t const initial_offset_;\n+\n+  // True if we are resynchronizing after a seek (initial_offset_ > 0). In\n+  // particular, a run of kMiddleType and kLastType records can be silently\n+  // skipped in this mode\n+  bool resyncing_;\n };\n \n }  // namespace log"
      },
      {
        "sha": "41fc043068dcec4d587f36d80bff5013761e1149",
        "filename": "src/leveldb/db/log_test.cc",
        "status": "modified",
        "additions": 131,
        "deletions": 160,
        "changes": 291,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/log_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/log_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/log_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -37,87 +37,12 @@ static std::string RandomSkewedString(int i, Random* rnd) {\n }\n \n class LogTest {\n- private:\n-  class StringDest : public WritableFile {\n-   public:\n-    std::string contents_;\n-\n-    virtual Status Close() { return Status::OK(); }\n-    virtual Status Flush() { return Status::OK(); }\n-    virtual Status Sync() { return Status::OK(); }\n-    virtual Status Append(const Slice& slice) {\n-      contents_.append(slice.data(), slice.size());\n-      return Status::OK();\n-    }\n-  };\n-\n-  class StringSource : public SequentialFile {\n-   public:\n-    Slice contents_;\n-    bool force_error_;\n-    bool returned_partial_;\n-    StringSource() : force_error_(false), returned_partial_(false) { }\n-\n-    virtual Status Read(size_t n, Slice* result, char* scratch) {\n-      ASSERT_TRUE(!returned_partial_) << \"must not Read() after eof/error\";\n-\n-      if (force_error_) {\n-        force_error_ = false;\n-        returned_partial_ = true;\n-        return Status::Corruption(\"read error\");\n-      }\n-\n-      if (contents_.size() < n) {\n-        n = contents_.size();\n-        returned_partial_ = true;\n-      }\n-      *result = Slice(contents_.data(), n);\n-      contents_.remove_prefix(n);\n-      return Status::OK();\n-    }\n-\n-    virtual Status Skip(uint64_t n) {\n-      if (n > contents_.size()) {\n-        contents_.clear();\n-        return Status::NotFound(\"in-memory file skipped past end\");\n-      }\n-\n-      contents_.remove_prefix(n);\n-\n-      return Status::OK();\n-    }\n-  };\n-\n-  class ReportCollector : public Reader::Reporter {\n-   public:\n-    size_t dropped_bytes_;\n-    std::string message_;\n-\n-    ReportCollector() : dropped_bytes_(0) { }\n-    virtual void Corruption(size_t bytes, const Status& status) {\n-      dropped_bytes_ += bytes;\n-      message_.append(status.ToString());\n-    }\n-  };\n-\n-  StringDest dest_;\n-  StringSource source_;\n-  ReportCollector report_;\n-  bool reading_;\n-  Writer* writer_;\n-  Reader* reader_;\n-\n-  // Record metadata for testing initial offset functionality\n-  static size_t initial_offset_record_sizes_[];\n-  static uint64_t initial_offset_last_record_offsets_[];\n-  static int num_initial_offset_records_;\n-\n  public:\n-  LogTest() : reading_(false),\n-              writer_(new Writer(&dest_)),\n-              reader_(new Reader(&source_, &report_, true/*checksum*/,\n-                      0/*initial_offset*/)) {\n-  }\n+  LogTest()\n+      : reading_(false),\n+        writer_(new Writer(&dest_)),\n+        reader_(new Reader(&source_, &report_, true /*checksum*/,\n+                           0 /*initial_offset*/)) {}\n \n   ~LogTest() {\n     delete writer_;\n@@ -134,9 +59,7 @@ class LogTest {\n     writer_->AddRecord(Slice(msg));\n   }\n \n-  size_t WrittenBytes() const {\n-    return dest_.contents_.size();\n-  }\n+  size_t WrittenBytes() const { return dest_.contents_.size(); }\n \n   std::string Read() {\n     if (!reading_) {\n@@ -166,22 +89,16 @@ class LogTest {\n \n   void FixChecksum(int header_offset, int len) {\n     // Compute crc of type/len/data\n-    uint32_t crc = crc32c::Value(&dest_.contents_[header_offset+6], 1 + len);\n+    uint32_t crc = crc32c::Value(&dest_.contents_[header_offset + 6], 1 + len);\n     crc = crc32c::Mask(crc);\n     EncodeFixed32(&dest_.contents_[header_offset], crc);\n   }\n \n-  void ForceError() {\n-    source_.force_error_ = true;\n-  }\n+  void ForceError() { source_.force_error_ = true; }\n \n-  size_t DroppedBytes() const {\n-    return report_.dropped_bytes_;\n-  }\n+  size_t DroppedBytes() const { return report_.dropped_bytes_; }\n \n-  std::string ReportMessage() const {\n-    return report_.message_;\n-  }\n+  std::string ReportMessage() const { return report_.message_; }\n \n   // Returns OK iff recorded error message contains \"msg\"\n   std::string MatchError(const std::string& msg) const {\n@@ -202,14 +119,14 @@ class LogTest {\n \n   void StartReadingAt(uint64_t initial_offset) {\n     delete reader_;\n-    reader_ = new Reader(&source_, &report_, true/*checksum*/, initial_offset);\n+    reader_ = new Reader(&source_, &report_, true /*checksum*/, initial_offset);\n   }\n \n   void CheckOffsetPastEndReturnsNoRecords(uint64_t offset_past_end) {\n     WriteInitialOffsetLog();\n     reading_ = true;\n     source_.contents_ = Slice(dest_.contents_);\n-    Reader* offset_reader = new Reader(&source_, &report_, true/*checksum*/,\n+    Reader* offset_reader = new Reader(&source_, &report_, true /*checksum*/,\n                                        WrittenBytes() + offset_past_end);\n     Slice record;\n     std::string scratch;\n@@ -222,8 +139,8 @@ class LogTest {\n     WriteInitialOffsetLog();\n     reading_ = true;\n     source_.contents_ = Slice(dest_.contents_);\n-    Reader* offset_reader = new Reader(&source_, &report_, true/*checksum*/,\n-                                       initial_offset);\n+    Reader* offset_reader =\n+        new Reader(&source_, &report_, true /*checksum*/, initial_offset);\n \n     // Read all records from expected_record_offset through the last one.\n     ASSERT_LT(expected_record_offset, num_initial_offset_records_);\n@@ -240,36 +157,110 @@ class LogTest {\n     }\n     delete offset_reader;\n   }\n+\n+ private:\n+  class StringDest : public WritableFile {\n+   public:\n+    Status Close() override { return Status::OK(); }\n+    Status Flush() override { return Status::OK(); }\n+    Status Sync() override { return Status::OK(); }\n+    Status Append(const Slice& slice) override {\n+      contents_.append(slice.data(), slice.size());\n+      return Status::OK();\n+    }\n+    std::string GetName() const override { return \"\"; }\n+\n+    std::string contents_;\n+  };\n+\n+  class StringSource : public SequentialFile {\n+   public:\n+    StringSource() : force_error_(false), returned_partial_(false) {}\n+\n+    Status Read(size_t n, Slice* result, char* scratch) override {\n+      ASSERT_TRUE(!returned_partial_) << \"must not Read() after eof/error\";\n+\n+      if (force_error_) {\n+        force_error_ = false;\n+        returned_partial_ = true;\n+        return Status::Corruption(\"read error\");\n+      }\n+\n+      if (contents_.size() < n) {\n+        n = contents_.size();\n+        returned_partial_ = true;\n+      }\n+      *result = Slice(contents_.data(), n);\n+      contents_.remove_prefix(n);\n+      return Status::OK();\n+    }\n+\n+    Status Skip(uint64_t n) override {\n+      if (n > contents_.size()) {\n+        contents_.clear();\n+        return Status::NotFound(\"in-memory file skipped past end\");\n+      }\n+\n+      contents_.remove_prefix(n);\n+\n+      return Status::OK();\n+    }\n+    std::string GetName() const { return \"\"; }\n+\n+    Slice contents_;\n+    bool force_error_;\n+    bool returned_partial_;\n+  };\n+\n+  class ReportCollector : public Reader::Reporter {\n+   public:\n+    ReportCollector() : dropped_bytes_(0) {}\n+    void Corruption(size_t bytes, const Status& status) override {\n+      dropped_bytes_ += bytes;\n+      message_.append(status.ToString());\n+    }\n+\n+    size_t dropped_bytes_;\n+    std::string message_;\n+  };\n+\n+  // Record metadata for testing initial offset functionality\n+  static size_t initial_offset_record_sizes_[];\n+  static uint64_t initial_offset_last_record_offsets_[];\n+  static int num_initial_offset_records_;\n+\n+  StringDest dest_;\n+  StringSource source_;\n+  ReportCollector report_;\n+  bool reading_;\n+  Writer* writer_;\n+  Reader* reader_;\n+};\n+\n+size_t LogTest::initial_offset_record_sizes_[] = {\n+    10000,  // Two sizable records in first block\n+    10000,\n+    2 * log::kBlockSize - 1000,  // Span three blocks\n+    1,\n+    13716,                          // Consume all but two bytes of block 3.\n+    log::kBlockSize - kHeaderSize,  // Consume the entirety of block 4.\n };\n \n-size_t LogTest::initial_offset_record_sizes_[] =\n-    {10000,  // Two sizable records in first block\n-     10000,\n-     2 * log::kBlockSize - 1000,  // Span three blocks\n-     1,\n-     13716,  // Consume all but two bytes of block 3.\n-     log::kBlockSize - kHeaderSize, // Consume the entirety of block 4.\n-    };\n-\n-uint64_t LogTest::initial_offset_last_record_offsets_[] =\n-    {0,\n-     kHeaderSize + 10000,\n-     2 * (kHeaderSize + 10000),\n-     2 * (kHeaderSize + 10000) +\n-         (2 * log::kBlockSize - 1000) + 3 * kHeaderSize,\n-     2 * (kHeaderSize + 10000) +\n-         (2 * log::kBlockSize - 1000) + 3 * kHeaderSize\n-         + kHeaderSize + 1,\n-     3 * log::kBlockSize,\n-    };\n+uint64_t LogTest::initial_offset_last_record_offsets_[] = {\n+    0,\n+    kHeaderSize + 10000,\n+    2 * (kHeaderSize + 10000),\n+    2 * (kHeaderSize + 10000) + (2 * log::kBlockSize - 1000) + 3 * kHeaderSize,\n+    2 * (kHeaderSize + 10000) + (2 * log::kBlockSize - 1000) + 3 * kHeaderSize +\n+        kHeaderSize + 1,\n+    3 * log::kBlockSize,\n+};\n \n // LogTest::initial_offset_last_record_offsets_ must be defined before this.\n int LogTest::num_initial_offset_records_ =\n-    sizeof(LogTest::initial_offset_last_record_offsets_)/sizeof(uint64_t);\n+    sizeof(LogTest::initial_offset_last_record_offsets_) / sizeof(uint64_t);\n \n-TEST(LogTest, Empty) {\n-  ASSERT_EQ(\"EOF\", Read());\n-}\n+TEST(LogTest, Empty) { ASSERT_EQ(\"EOF\", Read()); }\n \n TEST(LogTest, ReadWrite) {\n   Write(\"foo\");\n@@ -306,7 +297,7 @@ TEST(LogTest, Fragmentation) {\n \n TEST(LogTest, MarginalTrailer) {\n   // Make a trailer that is exactly the same length as an empty record.\n-  const int n = kBlockSize - 2*kHeaderSize;\n+  const int n = kBlockSize - 2 * kHeaderSize;\n   Write(BigString(\"foo\", n));\n   ASSERT_EQ(kBlockSize - kHeaderSize, WrittenBytes());\n   Write(\"\");\n@@ -319,7 +310,7 @@ TEST(LogTest, MarginalTrailer) {\n \n TEST(LogTest, MarginalTrailer2) {\n   // Make a trailer that is exactly the same length as an empty record.\n-  const int n = kBlockSize - 2*kHeaderSize;\n+  const int n = kBlockSize - 2 * kHeaderSize;\n   Write(BigString(\"foo\", n));\n   ASSERT_EQ(kBlockSize - kHeaderSize, WrittenBytes());\n   Write(\"bar\");\n@@ -331,7 +322,7 @@ TEST(LogTest, MarginalTrailer2) {\n }\n \n TEST(LogTest, ShortTrailer) {\n-  const int n = kBlockSize - 2*kHeaderSize + 4;\n+  const int n = kBlockSize - 2 * kHeaderSize + 4;\n   Write(BigString(\"foo\", n));\n   ASSERT_EQ(kBlockSize - kHeaderSize + 4, WrittenBytes());\n   Write(\"\");\n@@ -343,7 +334,7 @@ TEST(LogTest, ShortTrailer) {\n }\n \n TEST(LogTest, AlignedEof) {\n-  const int n = kBlockSize - 2*kHeaderSize + 4;\n+  const int n = kBlockSize - 2 * kHeaderSize + 4;\n   Write(BigString(\"foo\", n));\n   ASSERT_EQ(kBlockSize - kHeaderSize + 4, WrittenBytes());\n   ASSERT_EQ(BigString(\"foo\", n), Read());\n@@ -394,7 +385,7 @@ TEST(LogTest, BadRecordType) {\n \n TEST(LogTest, TruncatedTrailingRecordIsIgnored) {\n   Write(\"foo\");\n-  ShrinkSize(4);   // Drop all payload as well as a header byte\n+  ShrinkSize(4);  // Drop all payload as well as a header byte\n   ASSERT_EQ(\"EOF\", Read());\n   // Truncated last record is ignored, not treated as an error.\n   ASSERT_EQ(0, DroppedBytes());\n@@ -492,7 +483,7 @@ TEST(LogTest, SkipIntoMultiRecord) {\n   // If initial_offset points to a record after first(R1) but before first(R2)\n   // incomplete fragment errors are not actual errors, and must be suppressed\n   // until a new first or full record is encountered.\n-  Write(BigString(\"foo\", 3*kBlockSize));\n+  Write(BigString(\"foo\", 3 * kBlockSize));\n   Write(\"correct\");\n   StartReadingAt(kBlockSize);\n \n@@ -514,44 +505,30 @@ TEST(LogTest, ErrorJoinsRecords) {\n   Write(\"correct\");\n \n   // Wipe the middle block\n-  for (int offset = kBlockSize; offset < 2*kBlockSize; offset++) {\n+  for (int offset = kBlockSize; offset < 2 * kBlockSize; offset++) {\n     SetByte(offset, 'x');\n   }\n \n   ASSERT_EQ(\"correct\", Read());\n   ASSERT_EQ(\"EOF\", Read());\n   const size_t dropped = DroppedBytes();\n-  ASSERT_LE(dropped, 2*kBlockSize + 100);\n-  ASSERT_GE(dropped, 2*kBlockSize);\n+  ASSERT_LE(dropped, 2 * kBlockSize + 100);\n+  ASSERT_GE(dropped, 2 * kBlockSize);\n }\n \n-TEST(LogTest, ReadStart) {\n-  CheckInitialOffsetRecord(0, 0);\n-}\n+TEST(LogTest, ReadStart) { CheckInitialOffsetRecord(0, 0); }\n \n-TEST(LogTest, ReadSecondOneOff) {\n-  CheckInitialOffsetRecord(1, 1);\n-}\n+TEST(LogTest, ReadSecondOneOff) { CheckInitialOffsetRecord(1, 1); }\n \n-TEST(LogTest, ReadSecondTenThousand) {\n-  CheckInitialOffsetRecord(10000, 1);\n-}\n+TEST(LogTest, ReadSecondTenThousand) { CheckInitialOffsetRecord(10000, 1); }\n \n-TEST(LogTest, ReadSecondStart) {\n-  CheckInitialOffsetRecord(10007, 1);\n-}\n+TEST(LogTest, ReadSecondStart) { CheckInitialOffsetRecord(10007, 1); }\n \n-TEST(LogTest, ReadThirdOneOff) {\n-  CheckInitialOffsetRecord(10008, 2);\n-}\n+TEST(LogTest, ReadThirdOneOff) { CheckInitialOffsetRecord(10008, 2); }\n \n-TEST(LogTest, ReadThirdStart) {\n-  CheckInitialOffsetRecord(20014, 2);\n-}\n+TEST(LogTest, ReadThirdStart) { CheckInitialOffsetRecord(20014, 2); }\n \n-TEST(LogTest, ReadFourthOneOff) {\n-  CheckInitialOffsetRecord(20015, 3);\n-}\n+TEST(LogTest, ReadFourthOneOff) { CheckInitialOffsetRecord(20015, 3); }\n \n TEST(LogTest, ReadFourthFirstBlockTrailer) {\n   CheckInitialOffsetRecord(log::kBlockSize - 4, 3);\n@@ -575,17 +552,11 @@ TEST(LogTest, ReadInitialOffsetIntoBlockPadding) {\n   CheckInitialOffsetRecord(3 * log::kBlockSize - 3, 5);\n }\n \n-TEST(LogTest, ReadEnd) {\n-  CheckOffsetPastEndReturnsNoRecords(0);\n-}\n+TEST(LogTest, ReadEnd) { CheckOffsetPastEndReturnsNoRecords(0); }\n \n-TEST(LogTest, ReadPastEnd) {\n-  CheckOffsetPastEndReturnsNoRecords(5);\n-}\n+TEST(LogTest, ReadPastEnd) { CheckOffsetPastEndReturnsNoRecords(5); }\n \n }  // namespace log\n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "bfb16fb486269e1b648c70693c18bd3e14d9ec63",
        "filename": "src/leveldb/db/log_writer.cc",
        "status": "modified",
        "additions": 14,
        "deletions": 15,
        "changes": 29,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/log_writer.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/log_writer.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/log_writer.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -5,6 +5,7 @@\n #include \"db/log_writer.h\"\n \n #include <stdint.h>\n+\n #include \"leveldb/env.h\"\n #include \"util/coding.h\"\n #include \"util/crc32c.h\"\n@@ -19,9 +20,7 @@ static void InitTypeCrc(uint32_t* type_crc) {\n   }\n }\n \n-Writer::Writer(WritableFile* dest)\n-    : dest_(dest),\n-      block_offset_(0) {\n+Writer::Writer(WritableFile* dest) : dest_(dest), block_offset_(0) {\n   InitTypeCrc(type_crc_);\n }\n \n@@ -30,8 +29,7 @@ Writer::Writer(WritableFile* dest, uint64_t dest_length)\n   InitTypeCrc(type_crc_);\n }\n \n-Writer::~Writer() {\n-}\n+Writer::~Writer() = default;\n \n Status Writer::AddRecord(const Slice& slice) {\n   const char* ptr = slice.data();\n@@ -49,7 +47,7 @@ Status Writer::AddRecord(const Slice& slice) {\n       // Switch to a new block\n       if (leftover > 0) {\n         // Fill the trailer (literal below relies on kHeaderSize being 7)\n-        assert(kHeaderSize == 7);\n+        static_assert(kHeaderSize == 7, \"\");\n         dest_->Append(Slice(\"\\x00\\x00\\x00\\x00\\x00\\x00\", leftover));\n       }\n       block_offset_ = 0;\n@@ -81,30 +79,31 @@ Status Writer::AddRecord(const Slice& slice) {\n   return s;\n }\n \n-Status Writer::EmitPhysicalRecord(RecordType t, const char* ptr, size_t n) {\n-  assert(n <= 0xffff);  // Must fit in two bytes\n-  assert(block_offset_ + kHeaderSize + n <= kBlockSize);\n+Status Writer::EmitPhysicalRecord(RecordType t, const char* ptr,\n+                                  size_t length) {\n+  assert(length <= 0xffff);  // Must fit in two bytes\n+  assert(block_offset_ + kHeaderSize + length <= kBlockSize);\n \n   // Format the header\n   char buf[kHeaderSize];\n-  buf[4] = static_cast<char>(n & 0xff);\n-  buf[5] = static_cast<char>(n >> 8);\n+  buf[4] = static_cast<char>(length & 0xff);\n+  buf[5] = static_cast<char>(length >> 8);\n   buf[6] = static_cast<char>(t);\n \n   // Compute the crc of the record type and the payload.\n-  uint32_t crc = crc32c::Extend(type_crc_[t], ptr, n);\n-  crc = crc32c::Mask(crc);                 // Adjust for storage\n+  uint32_t crc = crc32c::Extend(type_crc_[t], ptr, length);\n+  crc = crc32c::Mask(crc);  // Adjust for storage\n   EncodeFixed32(buf, crc);\n \n   // Write the header and the payload\n   Status s = dest_->Append(Slice(buf, kHeaderSize));\n   if (s.ok()) {\n-    s = dest_->Append(Slice(ptr, n));\n+    s = dest_->Append(Slice(ptr, length));\n     if (s.ok()) {\n       s = dest_->Flush();\n     }\n   }\n-  block_offset_ += kHeaderSize + n;\n+  block_offset_ += kHeaderSize + length;\n   return s;\n }\n "
      },
      {
        "sha": "c0a21147ee9cd7de674de47315b121050108628c",
        "filename": "src/leveldb/db/log_writer.h",
        "status": "modified",
        "additions": 7,
        "deletions": 7,
        "changes": 14,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/log_writer.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/log_writer.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/log_writer.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -6,6 +6,7 @@\n #define STORAGE_LEVELDB_DB_LOG_WRITER_H_\n \n #include <stdint.h>\n+\n #include \"db/log_format.h\"\n #include \"leveldb/slice.h\"\n #include \"leveldb/status.h\"\n@@ -28,24 +29,23 @@ class Writer {\n   // \"*dest\" must remain live while this Writer is in use.\n   Writer(WritableFile* dest, uint64_t dest_length);\n \n+  Writer(const Writer&) = delete;\n+  Writer& operator=(const Writer&) = delete;\n+\n   ~Writer();\n \n   Status AddRecord(const Slice& slice);\n \n  private:\n+  Status EmitPhysicalRecord(RecordType type, const char* ptr, size_t length);\n+\n   WritableFile* dest_;\n-  int block_offset_;       // Current offset in block\n+  int block_offset_;  // Current offset in block\n \n   // crc32c values for all supported record types.  These are\n   // pre-computed to reduce the overhead of computing the crc of the\n   // record type stored in the header.\n   uint32_t type_crc_[kMaxRecordType + 1];\n-\n-  Status EmitPhysicalRecord(RecordType type, const char* ptr, size_t length);\n-\n-  // No copying allowed\n-  Writer(const Writer&);\n-  void operator=(const Writer&);\n };\n \n }  // namespace log"
      },
      {
        "sha": "00931d4671b0630d71483a02850a754f7f5fb99b",
        "filename": "src/leveldb/db/memtable.cc",
        "status": "modified",
        "additions": 30,
        "deletions": 38,
        "changes": 68,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/memtable.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/memtable.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/memtable.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -18,20 +18,15 @@ static Slice GetLengthPrefixedSlice(const char* data) {\n   return Slice(p, len);\n }\n \n-MemTable::MemTable(const InternalKeyComparator& cmp)\n-    : comparator_(cmp),\n-      refs_(0),\n-      table_(comparator_, &arena_) {\n-}\n+MemTable::MemTable(const InternalKeyComparator& comparator)\n+    : comparator_(comparator), refs_(0), table_(comparator_, &arena_) {}\n \n-MemTable::~MemTable() {\n-  assert(refs_ == 0);\n-}\n+MemTable::~MemTable() { assert(refs_ == 0); }\n \n size_t MemTable::ApproximateMemoryUsage() { return arena_.MemoryUsage(); }\n \n-int MemTable::KeyComparator::operator()(const char* aptr, const char* bptr)\n-    const {\n+int MemTable::KeyComparator::operator()(const char* aptr,\n+                                        const char* bptr) const {\n   // Internal keys are encoded as length-prefixed strings.\n   Slice a = GetLengthPrefixedSlice(aptr);\n   Slice b = GetLengthPrefixedSlice(bptr);\n@@ -48,39 +43,37 @@ static const char* EncodeKey(std::string* scratch, const Slice& target) {\n   return scratch->data();\n }\n \n-class MemTableIterator: public Iterator {\n+class MemTableIterator : public Iterator {\n  public:\n-  explicit MemTableIterator(MemTable::Table* table) : iter_(table) { }\n-\n-  virtual bool Valid() const { return iter_.Valid(); }\n-  virtual void Seek(const Slice& k) { iter_.Seek(EncodeKey(&tmp_, k)); }\n-  virtual void SeekToFirst() { iter_.SeekToFirst(); }\n-  virtual void SeekToLast() { iter_.SeekToLast(); }\n-  virtual void Next() { iter_.Next(); }\n-  virtual void Prev() { iter_.Prev(); }\n-  virtual Slice key() const { return GetLengthPrefixedSlice(iter_.key()); }\n-  virtual Slice value() const {\n+  explicit MemTableIterator(MemTable::Table* table) : iter_(table) {}\n+\n+  MemTableIterator(const MemTableIterator&) = delete;\n+  MemTableIterator& operator=(const MemTableIterator&) = delete;\n+\n+  ~MemTableIterator() override = default;\n+\n+  bool Valid() const override { return iter_.Valid(); }\n+  void Seek(const Slice& k) override { iter_.Seek(EncodeKey(&tmp_, k)); }\n+  void SeekToFirst() override { iter_.SeekToFirst(); }\n+  void SeekToLast() override { iter_.SeekToLast(); }\n+  void Next() override { iter_.Next(); }\n+  void Prev() override { iter_.Prev(); }\n+  Slice key() const override { return GetLengthPrefixedSlice(iter_.key()); }\n+  Slice value() const override {\n     Slice key_slice = GetLengthPrefixedSlice(iter_.key());\n     return GetLengthPrefixedSlice(key_slice.data() + key_slice.size());\n   }\n \n-  virtual Status status() const { return Status::OK(); }\n+  Status status() const override { return Status::OK(); }\n \n  private:\n   MemTable::Table::Iterator iter_;\n-  std::string tmp_;       // For passing to EncodeKey\n-\n-  // No copying allowed\n-  MemTableIterator(const MemTableIterator&);\n-  void operator=(const MemTableIterator&);\n+  std::string tmp_;  // For passing to EncodeKey\n };\n \n-Iterator* MemTable::NewIterator() {\n-  return new MemTableIterator(&table_);\n-}\n+Iterator* MemTable::NewIterator() { return new MemTableIterator(&table_); }\n \n-void MemTable::Add(SequenceNumber s, ValueType type,\n-                   const Slice& key,\n+void MemTable::Add(SequenceNumber s, ValueType type, const Slice& key,\n                    const Slice& value) {\n   // Format of an entry is concatenation of:\n   //  key_size     : varint32 of internal_key.size()\n@@ -90,9 +83,9 @@ void MemTable::Add(SequenceNumber s, ValueType type,\n   size_t key_size = key.size();\n   size_t val_size = value.size();\n   size_t internal_key_size = key_size + 8;\n-  const size_t encoded_len =\n-      VarintLength(internal_key_size) + internal_key_size +\n-      VarintLength(val_size) + val_size;\n+  const size_t encoded_len = VarintLength(internal_key_size) +\n+                             internal_key_size + VarintLength(val_size) +\n+                             val_size;\n   char* buf = arena_.Allocate(encoded_len);\n   char* p = EncodeVarint32(buf, internal_key_size);\n   memcpy(p, key.data(), key_size);\n@@ -121,10 +114,9 @@ bool MemTable::Get(const LookupKey& key, std::string* value, Status* s) {\n     // all entries with overly large sequence numbers.\n     const char* entry = iter.key();\n     uint32_t key_length;\n-    const char* key_ptr = GetVarint32Ptr(entry, entry+5, &key_length);\n+    const char* key_ptr = GetVarint32Ptr(entry, entry + 5, &key_length);\n     if (comparator_.comparator.user_comparator()->Compare(\n-            Slice(key_ptr, key_length - 8),\n-            key.user_key()) == 0) {\n+            Slice(key_ptr, key_length - 8), key.user_key()) == 0) {\n       // Correct user key\n       const uint64_t tag = DecodeFixed64(key_ptr + key_length - 8);\n       switch (static_cast<ValueType>(tag & 0xff)) {"
      },
      {
        "sha": "9d986b1070203243854e9e6d2479b89c1fb3f96a",
        "filename": "src/leveldb/db/memtable.h",
        "status": "modified",
        "additions": 11,
        "deletions": 12,
        "changes": 23,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/memtable.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/memtable.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/memtable.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -6,15 +6,15 @@\n #define STORAGE_LEVELDB_DB_MEMTABLE_H_\n \n #include <string>\n-#include \"leveldb/db.h\"\n+\n #include \"db/dbformat.h\"\n #include \"db/skiplist.h\"\n+#include \"leveldb/db.h\"\n #include \"util/arena.h\"\n \n namespace leveldb {\n \n class InternalKeyComparator;\n-class Mutex;\n class MemTableIterator;\n \n class MemTable {\n@@ -23,6 +23,9 @@ class MemTable {\n   // is zero and the caller must call Ref() at least once.\n   explicit MemTable(const InternalKeyComparator& comparator);\n \n+  MemTable(const MemTable&) = delete;\n+  MemTable& operator=(const MemTable&) = delete;\n+\n   // Increase reference count.\n   void Ref() { ++refs_; }\n \n@@ -50,8 +53,7 @@ class MemTable {\n   // Add an entry into memtable that maps key to value at the\n   // specified sequence number and with the specified type.\n   // Typically value will be empty if type==kTypeDeletion.\n-  void Add(SequenceNumber seq, ValueType type,\n-           const Slice& key,\n+  void Add(SequenceNumber seq, ValueType type, const Slice& key,\n            const Slice& value);\n \n   // If memtable contains a value for key, store it in *value and return true.\n@@ -61,26 +63,23 @@ class MemTable {\n   bool Get(const LookupKey& key, std::string* value, Status* s);\n \n  private:\n-  ~MemTable();  // Private since only Unref() should be used to delete it\n+  friend class MemTableIterator;\n+  friend class MemTableBackwardIterator;\n \n   struct KeyComparator {\n     const InternalKeyComparator comparator;\n-    explicit KeyComparator(const InternalKeyComparator& c) : comparator(c) { }\n+    explicit KeyComparator(const InternalKeyComparator& c) : comparator(c) {}\n     int operator()(const char* a, const char* b) const;\n   };\n-  friend class MemTableIterator;\n-  friend class MemTableBackwardIterator;\n \n   typedef SkipList<const char*, KeyComparator> Table;\n \n+  ~MemTable();  // Private since only Unref() should be used to delete it\n+\n   KeyComparator comparator_;\n   int refs_;\n   Arena arena_;\n   Table table_;\n-\n-  // No copying allowed\n-  MemTable(const MemTable&);\n-  void operator=(const MemTable&);\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "547a9591ea067d03ce6fbb15ed17c51a399315ad",
        "filename": "src/leveldb/db/recovery_test.cc",
        "status": "modified",
        "additions": 39,
        "deletions": 33,
        "changes": 72,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/recovery_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/recovery_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/recovery_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -17,7 +17,7 @@ namespace leveldb {\n \n class RecoveryTest {\n  public:\n-  RecoveryTest() : env_(Env::Default()), db_(NULL) {\n+  RecoveryTest() : env_(Env::Default()), db_(nullptr) {\n     dbname_ = test::TmpDir() + \"/recovery_test\";\n     DestroyDB(dbname_, Options());\n     Open();\n@@ -44,30 +44,34 @@ class RecoveryTest {\n \n   void Close() {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n   }\n \n-  void Open(Options* options = NULL) {\n+  Status OpenWithStatus(Options* options = nullptr) {\n     Close();\n     Options opts;\n-    if (options != NULL) {\n+    if (options != nullptr) {\n       opts = *options;\n     } else {\n       opts.reuse_logs = true;  // TODO(sanjay): test both ways\n       opts.create_if_missing = true;\n     }\n-    if (opts.env == NULL) {\n+    if (opts.env == nullptr) {\n       opts.env = env_;\n     }\n-    ASSERT_OK(DB::Open(opts, dbname_, &db_));\n+    return DB::Open(opts, dbname_, &db_);\n+  }\n+\n+  void Open(Options* options = nullptr) {\n+    ASSERT_OK(OpenWithStatus(options));\n     ASSERT_EQ(1, NumLogs());\n   }\n \n   Status Put(const std::string& k, const std::string& v) {\n     return db_->Put(WriteOptions(), k, v);\n   }\n \n-  std::string Get(const std::string& k, const Snapshot* snapshot = NULL) {\n+  std::string Get(const std::string& k, const Snapshot* snapshot = nullptr) {\n     std::string result;\n     Status s = db_->Get(ReadOptions(), k, &result);\n     if (s.IsNotFound()) {\n@@ -82,27 +86,28 @@ class RecoveryTest {\n     std::string current;\n     ASSERT_OK(ReadFileToString(env_, CurrentFileName(dbname_), &current));\n     size_t len = current.size();\n-    if (len > 0 && current[len-1] == '\\n') {\n+    if (len > 0 && current[len - 1] == '\\n') {\n       current.resize(len - 1);\n     }\n     return dbname_ + \"/\" + current;\n   }\n \n-  std::string LogName(uint64_t number) {\n-    return LogFileName(dbname_, number);\n-  }\n+  std::string LogName(uint64_t number) { return LogFileName(dbname_, number); }\n \n   size_t DeleteLogFiles() {\n+    // Linux allows unlinking open files, but Windows does not.\n+    // Closing the db allows for file deletion.\n+    Close();\n     std::vector<uint64_t> logs = GetFiles(kLogFile);\n     for (size_t i = 0; i < logs.size(); i++) {\n       ASSERT_OK(env_->DeleteFile(LogName(logs[i]))) << LogName(logs[i]);\n     }\n     return logs.size();\n   }\n \n-  uint64_t FirstLogFile() {\n-    return GetFiles(kLogFile)[0];\n-  }\n+  void DeleteManifestFile() { ASSERT_OK(env_->DeleteFile(ManifestFileName())); }\n+\n+  uint64_t FirstLogFile() { return GetFiles(kLogFile)[0]; }\n \n   std::vector<uint64_t> GetFiles(FileType t) {\n     std::vector<std::string> filenames;\n@@ -118,23 +123,17 @@ class RecoveryTest {\n     return result;\n   }\n \n-  int NumLogs() {\n-    return GetFiles(kLogFile).size();\n-  }\n+  int NumLogs() { return GetFiles(kLogFile).size(); }\n \n-  int NumTables() {\n-    return GetFiles(kTableFile).size();\n-  }\n+  int NumTables() { return GetFiles(kTableFile).size(); }\n \n   uint64_t FileSize(const std::string& fname) {\n     uint64_t result;\n     ASSERT_OK(env_->GetFileSize(fname, &result)) << fname;\n     return result;\n   }\n \n-  void CompactMemTable() {\n-    dbfull()->TEST_CompactMemTable();\n-  }\n+  void CompactMemTable() { dbfull()->TEST_CompactMemTable(); }\n \n   // Directly construct a log file that sets key to val.\n   void MakeLogFile(uint64_t lognum, SequenceNumber seq, Slice key, Slice val) {\n@@ -186,7 +185,7 @@ TEST(RecoveryTest, LargeManifestCompacted) {\n     uint64_t len = FileSize(old_manifest);\n     WritableFile* file;\n     ASSERT_OK(env()->NewAppendableFile(old_manifest, &file));\n-    std::string zeroes(3*1048576 - static_cast<size_t>(len), 0);\n+    std::string zeroes(3 * 1048576 - static_cast<size_t>(len), 0);\n     ASSERT_OK(file->Append(zeroes));\n     ASSERT_OK(file->Flush());\n     delete file;\n@@ -259,7 +258,7 @@ TEST(RecoveryTest, MultipleMemTables) {\n   // Force creation of multiple memtables by reducing the write buffer size.\n   Options opt;\n   opt.reuse_logs = true;\n-  opt.write_buffer_size = (kNum*100) / 2;\n+  opt.write_buffer_size = (kNum * 100) / 2;\n   Open(&opt);\n   ASSERT_LE(2, NumTables());\n   ASSERT_EQ(1, NumLogs());\n@@ -278,16 +277,16 @@ TEST(RecoveryTest, MultipleLogFiles) {\n \n   // Make a bunch of uncompacted log files.\n   uint64_t old_log = FirstLogFile();\n-  MakeLogFile(old_log+1, 1000, \"hello\", \"world\");\n-  MakeLogFile(old_log+2, 1001, \"hi\", \"there\");\n-  MakeLogFile(old_log+3, 1002, \"foo\", \"bar2\");\n+  MakeLogFile(old_log + 1, 1000, \"hello\", \"world\");\n+  MakeLogFile(old_log + 2, 1001, \"hi\", \"there\");\n+  MakeLogFile(old_log + 3, 1002, \"foo\", \"bar2\");\n \n   // Recover and check that all log files were processed.\n   Open();\n   ASSERT_LE(1, NumTables());\n   ASSERT_EQ(1, NumLogs());\n   uint64_t new_log = FirstLogFile();\n-  ASSERT_LE(old_log+3, new_log);\n+  ASSERT_LE(old_log + 3, new_log);\n   ASSERT_EQ(\"bar2\", Get(\"foo\"));\n   ASSERT_EQ(\"world\", Get(\"hello\"));\n   ASSERT_EQ(\"there\", Get(\"hi\"));\n@@ -305,7 +304,7 @@ TEST(RecoveryTest, MultipleLogFiles) {\n \n   // Check that introducing an older log file does not cause it to be re-read.\n   Close();\n-  MakeLogFile(old_log+1, 2000, \"hello\", \"stale write\");\n+  MakeLogFile(old_log + 1, 2000, \"hello\", \"stale write\");\n   Open();\n   ASSERT_LE(1, NumTables());\n   ASSERT_EQ(1, NumLogs());\n@@ -317,8 +316,15 @@ TEST(RecoveryTest, MultipleLogFiles) {\n   ASSERT_EQ(\"there\", Get(\"hi\"));\n }\n \n-}  // namespace leveldb\n+TEST(RecoveryTest, ManifestMissing) {\n+  ASSERT_OK(Put(\"foo\", \"bar\"));\n+  Close();\n+  DeleteManifestFile();\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n+  Status status = OpenWithStatus();\n+  ASSERT_TRUE(status.IsCorruption());\n }\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "04847c3bbfb73d40f3c2ebb90ef701fd957ea3b1",
        "filename": "src/leveldb/db/repair.cc",
        "status": "modified",
        "additions": 42,
        "deletions": 53,
        "changes": 95,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/repair.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/repair.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/repair.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -54,7 +54,7 @@ class Repairer {\n         owns_cache_(options_.block_cache != options.block_cache),\n         next_file_number_(1) {\n     // TableCache can be small since we expect each table to be opened once.\n-    table_cache_ = new TableCache(dbname_, &options_, 10);\n+    table_cache_ = new TableCache(dbname_, options_, 10);\n   }\n \n   ~Repairer() {\n@@ -84,9 +84,7 @@ class Repairer {\n           \"recovered %d files; %llu bytes. \"\n           \"Some data may have been lost. \"\n           \"****\",\n-          dbname_.c_str(),\n-          static_cast<int>(tables_.size()),\n-          bytes);\n+          dbname_.c_str(), static_cast<int>(tables_.size()), bytes);\n     }\n     return status;\n   }\n@@ -97,22 +95,6 @@ class Repairer {\n     SequenceNumber max_sequence;\n   };\n \n-  std::string const dbname_;\n-  Env* const env_;\n-  InternalKeyComparator const icmp_;\n-  InternalFilterPolicy const ipolicy_;\n-  Options const options_;\n-  bool owns_info_log_;\n-  bool owns_cache_;\n-  TableCache* table_cache_;\n-  VersionEdit edit_;\n-\n-  std::vector<std::string> manifests_;\n-  std::vector<uint64_t> table_numbers_;\n-  std::vector<uint64_t> logs_;\n-  std::vector<TableInfo> tables_;\n-  uint64_t next_file_number_;\n-\n   Status FindFiles() {\n     std::vector<std::string> filenames;\n     Status status = env_->GetChildren(dbname_, &filenames);\n@@ -152,8 +134,7 @@ class Repairer {\n       Status status = ConvertLogToTable(logs_[i]);\n       if (!status.ok()) {\n         Log(options_.info_log, \"Log #%llu: ignoring conversion error: %s\",\n-            (unsigned long long) logs_[i],\n-            status.ToString().c_str());\n+            (unsigned long long)logs_[i], status.ToString().c_str());\n       }\n       ArchiveFile(logname);\n     }\n@@ -164,11 +145,10 @@ class Repairer {\n       Env* env;\n       Logger* info_log;\n       uint64_t lognum;\n-      virtual void Corruption(size_t bytes, const Status& s) {\n+      void Corruption(size_t bytes, const Status& s) override {\n         // We print error messages for corruption, but continue repairing.\n         Log(info_log, \"Log #%llu: dropping %d bytes; %s\",\n-            (unsigned long long) lognum,\n-            static_cast<int>(bytes),\n+            (unsigned long long)lognum, static_cast<int>(bytes),\n             s.ToString().c_str());\n       }\n     };\n@@ -190,8 +170,8 @@ class Repairer {\n     // corruptions cause entire commits to be skipped instead of\n     // propagating bad information (like overly large sequence\n     // numbers).\n-    log::Reader reader(lfile, &reporter, false/*do not checksum*/,\n-                       0/*initial_offset*/);\n+    log::Reader reader(lfile, &reporter, false /*do not checksum*/,\n+                       0 /*initial_offset*/);\n \n     // Read all the records and add to a memtable\n     std::string scratch;\n@@ -202,8 +182,8 @@ class Repairer {\n     int counter = 0;\n     while (reader.ReadRecord(&record, &scratch)) {\n       if (record.size() < 12) {\n-        reporter.Corruption(\n-            record.size(), Status::Corruption(\"log record too small\", logname));\n+        reporter.Corruption(record.size(),\n+                            Status::Corruption(\"log record too small\", logname));\n         continue;\n       }\n       WriteBatchInternal::SetContents(&batch, record);\n@@ -212,8 +192,7 @@ class Repairer {\n         counter += WriteBatchInternal::Count(&batch);\n       } else {\n         Log(options_.info_log, \"Log #%llu: ignoring %s\",\n-            (unsigned long long) log,\n-            status.ToString().c_str());\n+            (unsigned long long)log, status.ToString().c_str());\n         status = Status::OK();  // Keep going with rest of file\n       }\n     }\n@@ -227,16 +206,14 @@ class Repairer {\n     status = BuildTable(dbname_, env_, options_, table_cache_, iter, &meta);\n     delete iter;\n     mem->Unref();\n-    mem = NULL;\n+    mem = nullptr;\n     if (status.ok()) {\n       if (meta.file_size > 0) {\n         table_numbers_.push_back(meta.number);\n       }\n     }\n     Log(options_.info_log, \"Log #%llu: %d ops saved to Table #%llu %s\",\n-        (unsigned long long) log,\n-        counter,\n-        (unsigned long long) meta.number,\n+        (unsigned long long)log, counter, (unsigned long long)meta.number,\n         status.ToString().c_str());\n     return status;\n   }\n@@ -272,8 +249,7 @@ class Repairer {\n       ArchiveFile(TableFileName(dbname_, number));\n       ArchiveFile(SSTTableFileName(dbname_, number));\n       Log(options_.info_log, \"Table #%llu: dropped: %s\",\n-          (unsigned long long) t.meta.number,\n-          status.ToString().c_str());\n+          (unsigned long long)t.meta.number, status.ToString().c_str());\n       return;\n     }\n \n@@ -287,8 +263,7 @@ class Repairer {\n       Slice key = iter->key();\n       if (!ParseInternalKey(key, &parsed)) {\n         Log(options_.info_log, \"Table #%llu: unparsable key %s\",\n-            (unsigned long long) t.meta.number,\n-            EscapeString(key).c_str());\n+            (unsigned long long)t.meta.number, EscapeString(key).c_str());\n         continue;\n       }\n \n@@ -307,9 +282,7 @@ class Repairer {\n     }\n     delete iter;\n     Log(options_.info_log, \"Table #%llu: %d entries %s\",\n-        (unsigned long long) t.meta.number,\n-        counter,\n-        status.ToString().c_str());\n+        (unsigned long long)t.meta.number, counter, status.ToString().c_str());\n \n     if (status.ok()) {\n       tables_.push_back(t);\n@@ -350,20 +323,20 @@ class Repairer {\n       }\n     }\n     delete builder;\n-    builder = NULL;\n+    builder = nullptr;\n \n     if (s.ok()) {\n       s = file->Close();\n     }\n     delete file;\n-    file = NULL;\n+    file = nullptr;\n \n     if (counter > 0 && s.ok()) {\n       std::string orig = TableFileName(dbname_, t.meta.number);\n       s = env_->RenameFile(copy, orig);\n       if (s.ok()) {\n         Log(options_.info_log, \"Table #%llu: %d entries repaired\",\n-            (unsigned long long) t.meta.number, counter);\n+            (unsigned long long)t.meta.number, counter);\n         tables_.push_back(t);\n       }\n     }\n@@ -395,11 +368,11 @@ class Repairer {\n     for (size_t i = 0; i < tables_.size(); i++) {\n       // TODO(opt): separate out into multiple levels\n       const TableInfo& t = tables_[i];\n-      edit_.AddFile(0, t.meta.number, t.meta.file_size,\n-                    t.meta.smallest, t.meta.largest);\n+      edit_.AddFile(0, t.meta.number, t.meta.file_size, t.meta.smallest,\n+                    t.meta.largest);\n     }\n \n-    //fprintf(stderr, \"NewDescriptor:\\n%s\\n\", edit_.DebugString().c_str());\n+    // fprintf(stderr, \"NewDescriptor:\\n%s\\n\", edit_.DebugString().c_str());\n     {\n       log::Writer log(file);\n       std::string record;\n@@ -410,7 +383,7 @@ class Repairer {\n       status = file->Close();\n     }\n     delete file;\n-    file = NULL;\n+    file = nullptr;\n \n     if (!status.ok()) {\n       env_->DeleteFile(tmp);\n@@ -438,18 +411,34 @@ class Repairer {\n     //    dir/lost/foo\n     const char* slash = strrchr(fname.c_str(), '/');\n     std::string new_dir;\n-    if (slash != NULL) {\n+    if (slash != nullptr) {\n       new_dir.assign(fname.data(), slash - fname.data());\n     }\n     new_dir.append(\"/lost\");\n     env_->CreateDir(new_dir);  // Ignore error\n     std::string new_file = new_dir;\n     new_file.append(\"/\");\n-    new_file.append((slash == NULL) ? fname.c_str() : slash + 1);\n+    new_file.append((slash == nullptr) ? fname.c_str() : slash + 1);\n     Status s = env_->RenameFile(fname, new_file);\n-    Log(options_.info_log, \"Archiving %s: %s\\n\",\n-        fname.c_str(), s.ToString().c_str());\n+    Log(options_.info_log, \"Archiving %s: %s\\n\", fname.c_str(),\n+        s.ToString().c_str());\n   }\n+\n+  const std::string dbname_;\n+  Env* const env_;\n+  InternalKeyComparator const icmp_;\n+  InternalFilterPolicy const ipolicy_;\n+  const Options options_;\n+  bool owns_info_log_;\n+  bool owns_cache_;\n+  TableCache* table_cache_;\n+  VersionEdit edit_;\n+\n+  std::vector<std::string> manifests_;\n+  std::vector<uint64_t> table_numbers_;\n+  std::vector<uint64_t> logs_;\n+  std::vector<TableInfo> tables_;\n+  uint64_t next_file_number_;\n };\n }  // namespace\n "
      },
      {
        "sha": "a59b45b3800574a3b70f151ed611be577399baf9",
        "filename": "src/leveldb/db/skiplist.h",
        "status": "modified",
        "additions": 90,
        "deletions": 92,
        "changes": 182,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/skiplist.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/skiplist.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/skiplist.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -27,17 +27,18 @@\n //\n // ... prev vs. next pointer ordering ...\n \n-#include <assert.h>\n-#include <stdlib.h>\n-#include \"port/port.h\"\n+#include <atomic>\n+#include <cassert>\n+#include <cstdlib>\n+\n #include \"util/arena.h\"\n #include \"util/random.h\"\n \n namespace leveldb {\n \n class Arena;\n \n-template<typename Key, class Comparator>\n+template <typename Key, class Comparator>\n class SkipList {\n  private:\n   struct Node;\n@@ -48,6 +49,9 @@ class SkipList {\n   // must remain allocated for the lifetime of the skiplist object.\n   explicit SkipList(Comparator cmp, Arena* arena);\n \n+  SkipList(const SkipList&) = delete;\n+  SkipList& operator=(const SkipList&) = delete;\n+\n   // Insert key into the list.\n   // REQUIRES: nothing that compares equal to key is currently in the list.\n   void Insert(const Key& key);\n@@ -97,24 +101,10 @@ class SkipList {\n  private:\n   enum { kMaxHeight = 12 };\n \n-  // Immutable after construction\n-  Comparator const compare_;\n-  Arena* const arena_;    // Arena used for allocations of nodes\n-\n-  Node* const head_;\n-\n-  // Modified only by Insert().  Read racily by readers, but stale\n-  // values are ok.\n-  port::AtomicPointer max_height_;   // Height of the entire list\n-\n   inline int GetMaxHeight() const {\n-    return static_cast<int>(\n-        reinterpret_cast<intptr_t>(max_height_.NoBarrier_Load()));\n+    return max_height_.load(std::memory_order_relaxed);\n   }\n \n-  // Read/written only by Insert().\n-  Random rnd_;\n-\n   Node* NewNode(const Key& key, int height);\n   int RandomHeight();\n   bool Equal(const Key& a, const Key& b) const { return (compare_(a, b) == 0); }\n@@ -123,9 +113,9 @@ class SkipList {\n   bool KeyIsAfterNode(const Key& key, Node* n) const;\n \n   // Return the earliest node that comes at or after key.\n-  // Return NULL if there is no such node.\n+  // Return nullptr if there is no such node.\n   //\n-  // If prev is non-NULL, fills prev[level] with pointer to previous\n+  // If prev is non-null, fills prev[level] with pointer to previous\n   // node at \"level\" for every level in [0..max_height_-1].\n   Node* FindGreaterOrEqual(const Key& key, Node** prev) const;\n \n@@ -137,15 +127,24 @@ class SkipList {\n   // Return head_ if list is empty.\n   Node* FindLast() const;\n \n-  // No copying allowed\n-  SkipList(const SkipList&);\n-  void operator=(const SkipList&);\n+  // Immutable after construction\n+  Comparator const compare_;\n+  Arena* const arena_;  // Arena used for allocations of nodes\n+\n+  Node* const head_;\n+\n+  // Modified only by Insert().  Read racily by readers, but stale\n+  // values are ok.\n+  std::atomic<int> max_height_;  // Height of the entire list\n+\n+  // Read/written only by Insert().\n+  Random rnd_;\n };\n \n // Implementation details follow\n-template<typename Key, class Comparator>\n-struct SkipList<Key,Comparator>::Node {\n-  explicit Node(const Key& k) : key(k) { }\n+template <typename Key, class Comparator>\n+struct SkipList<Key, Comparator>::Node {\n+  explicit Node(const Key& k) : key(k) {}\n \n   Key const key;\n \n@@ -155,92 +154,92 @@ struct SkipList<Key,Comparator>::Node {\n     assert(n >= 0);\n     // Use an 'acquire load' so that we observe a fully initialized\n     // version of the returned Node.\n-    return reinterpret_cast<Node*>(next_[n].Acquire_Load());\n+    return next_[n].load(std::memory_order_acquire);\n   }\n   void SetNext(int n, Node* x) {\n     assert(n >= 0);\n     // Use a 'release store' so that anybody who reads through this\n     // pointer observes a fully initialized version of the inserted node.\n-    next_[n].Release_Store(x);\n+    next_[n].store(x, std::memory_order_release);\n   }\n \n   // No-barrier variants that can be safely used in a few locations.\n   Node* NoBarrier_Next(int n) {\n     assert(n >= 0);\n-    return reinterpret_cast<Node*>(next_[n].NoBarrier_Load());\n+    return next_[n].load(std::memory_order_relaxed);\n   }\n   void NoBarrier_SetNext(int n, Node* x) {\n     assert(n >= 0);\n-    next_[n].NoBarrier_Store(x);\n+    next_[n].store(x, std::memory_order_relaxed);\n   }\n \n  private:\n   // Array of length equal to the node height.  next_[0] is lowest level link.\n-  port::AtomicPointer next_[1];\n+  std::atomic<Node*> next_[1];\n };\n \n-template<typename Key, class Comparator>\n-typename SkipList<Key,Comparator>::Node*\n-SkipList<Key,Comparator>::NewNode(const Key& key, int height) {\n-  char* mem = arena_->AllocateAligned(\n-      sizeof(Node) + sizeof(port::AtomicPointer) * (height - 1));\n-  return new (mem) Node(key);\n+template <typename Key, class Comparator>\n+typename SkipList<Key, Comparator>::Node* SkipList<Key, Comparator>::NewNode(\n+    const Key& key, int height) {\n+  char* const node_memory = arena_->AllocateAligned(\n+      sizeof(Node) + sizeof(std::atomic<Node*>) * (height - 1));\n+  return new (node_memory) Node(key);\n }\n \n-template<typename Key, class Comparator>\n-inline SkipList<Key,Comparator>::Iterator::Iterator(const SkipList* list) {\n+template <typename Key, class Comparator>\n+inline SkipList<Key, Comparator>::Iterator::Iterator(const SkipList* list) {\n   list_ = list;\n-  node_ = NULL;\n+  node_ = nullptr;\n }\n \n-template<typename Key, class Comparator>\n-inline bool SkipList<Key,Comparator>::Iterator::Valid() const {\n-  return node_ != NULL;\n+template <typename Key, class Comparator>\n+inline bool SkipList<Key, Comparator>::Iterator::Valid() const {\n+  return node_ != nullptr;\n }\n \n-template<typename Key, class Comparator>\n-inline const Key& SkipList<Key,Comparator>::Iterator::key() const {\n+template <typename Key, class Comparator>\n+inline const Key& SkipList<Key, Comparator>::Iterator::key() const {\n   assert(Valid());\n   return node_->key;\n }\n \n-template<typename Key, class Comparator>\n-inline void SkipList<Key,Comparator>::Iterator::Next() {\n+template <typename Key, class Comparator>\n+inline void SkipList<Key, Comparator>::Iterator::Next() {\n   assert(Valid());\n   node_ = node_->Next(0);\n }\n \n-template<typename Key, class Comparator>\n-inline void SkipList<Key,Comparator>::Iterator::Prev() {\n+template <typename Key, class Comparator>\n+inline void SkipList<Key, Comparator>::Iterator::Prev() {\n   // Instead of using explicit \"prev\" links, we just search for the\n   // last node that falls before key.\n   assert(Valid());\n   node_ = list_->FindLessThan(node_->key);\n   if (node_ == list_->head_) {\n-    node_ = NULL;\n+    node_ = nullptr;\n   }\n }\n \n-template<typename Key, class Comparator>\n-inline void SkipList<Key,Comparator>::Iterator::Seek(const Key& target) {\n-  node_ = list_->FindGreaterOrEqual(target, NULL);\n+template <typename Key, class Comparator>\n+inline void SkipList<Key, Comparator>::Iterator::Seek(const Key& target) {\n+  node_ = list_->FindGreaterOrEqual(target, nullptr);\n }\n \n-template<typename Key, class Comparator>\n-inline void SkipList<Key,Comparator>::Iterator::SeekToFirst() {\n+template <typename Key, class Comparator>\n+inline void SkipList<Key, Comparator>::Iterator::SeekToFirst() {\n   node_ = list_->head_->Next(0);\n }\n \n-template<typename Key, class Comparator>\n-inline void SkipList<Key,Comparator>::Iterator::SeekToLast() {\n+template <typename Key, class Comparator>\n+inline void SkipList<Key, Comparator>::Iterator::SeekToLast() {\n   node_ = list_->FindLast();\n   if (node_ == list_->head_) {\n-    node_ = NULL;\n+    node_ = nullptr;\n   }\n }\n \n-template<typename Key, class Comparator>\n-int SkipList<Key,Comparator>::RandomHeight() {\n+template <typename Key, class Comparator>\n+int SkipList<Key, Comparator>::RandomHeight() {\n   // Increase height with probability 1 in kBranching\n   static const unsigned int kBranching = 4;\n   int height = 1;\n@@ -252,15 +251,16 @@ int SkipList<Key,Comparator>::RandomHeight() {\n   return height;\n }\n \n-template<typename Key, class Comparator>\n-bool SkipList<Key,Comparator>::KeyIsAfterNode(const Key& key, Node* n) const {\n-  // NULL n is considered infinite\n-  return (n != NULL) && (compare_(n->key, key) < 0);\n+template <typename Key, class Comparator>\n+bool SkipList<Key, Comparator>::KeyIsAfterNode(const Key& key, Node* n) const {\n+  // null n is considered infinite\n+  return (n != nullptr) && (compare_(n->key, key) < 0);\n }\n \n-template<typename Key, class Comparator>\n-typename SkipList<Key,Comparator>::Node* SkipList<Key,Comparator>::FindGreaterOrEqual(const Key& key, Node** prev)\n-    const {\n+template <typename Key, class Comparator>\n+typename SkipList<Key, Comparator>::Node*\n+SkipList<Key, Comparator>::FindGreaterOrEqual(const Key& key,\n+                                              Node** prev) const {\n   Node* x = head_;\n   int level = GetMaxHeight() - 1;\n   while (true) {\n@@ -269,7 +269,7 @@ typename SkipList<Key,Comparator>::Node* SkipList<Key,Comparator>::FindGreaterOr\n       // Keep searching in this list\n       x = next;\n     } else {\n-      if (prev != NULL) prev[level] = x;\n+      if (prev != nullptr) prev[level] = x;\n       if (level == 0) {\n         return next;\n       } else {\n@@ -280,15 +280,15 @@ typename SkipList<Key,Comparator>::Node* SkipList<Key,Comparator>::FindGreaterOr\n   }\n }\n \n-template<typename Key, class Comparator>\n-typename SkipList<Key,Comparator>::Node*\n-SkipList<Key,Comparator>::FindLessThan(const Key& key) const {\n+template <typename Key, class Comparator>\n+typename SkipList<Key, Comparator>::Node*\n+SkipList<Key, Comparator>::FindLessThan(const Key& key) const {\n   Node* x = head_;\n   int level = GetMaxHeight() - 1;\n   while (true) {\n     assert(x == head_ || compare_(x->key, key) < 0);\n     Node* next = x->Next(level);\n-    if (next == NULL || compare_(next->key, key) >= 0) {\n+    if (next == nullptr || compare_(next->key, key) >= 0) {\n       if (level == 0) {\n         return x;\n       } else {\n@@ -301,14 +301,14 @@ SkipList<Key,Comparator>::FindLessThan(const Key& key) const {\n   }\n }\n \n-template<typename Key, class Comparator>\n-typename SkipList<Key,Comparator>::Node* SkipList<Key,Comparator>::FindLast()\n+template <typename Key, class Comparator>\n+typename SkipList<Key, Comparator>::Node* SkipList<Key, Comparator>::FindLast()\n     const {\n   Node* x = head_;\n   int level = GetMaxHeight() - 1;\n   while (true) {\n     Node* next = x->Next(level);\n-    if (next == NULL) {\n+    if (next == nullptr) {\n       if (level == 0) {\n         return x;\n       } else {\n@@ -321,43 +321,41 @@ typename SkipList<Key,Comparator>::Node* SkipList<Key,Comparator>::FindLast()\n   }\n }\n \n-template<typename Key, class Comparator>\n-SkipList<Key,Comparator>::SkipList(Comparator cmp, Arena* arena)\n+template <typename Key, class Comparator>\n+SkipList<Key, Comparator>::SkipList(Comparator cmp, Arena* arena)\n     : compare_(cmp),\n       arena_(arena),\n       head_(NewNode(0 /* any key will do */, kMaxHeight)),\n-      max_height_(reinterpret_cast<void*>(1)),\n+      max_height_(1),\n       rnd_(0xdeadbeef) {\n   for (int i = 0; i < kMaxHeight; i++) {\n-    head_->SetNext(i, NULL);\n+    head_->SetNext(i, nullptr);\n   }\n }\n \n-template<typename Key, class Comparator>\n-void SkipList<Key,Comparator>::Insert(const Key& key) {\n+template <typename Key, class Comparator>\n+void SkipList<Key, Comparator>::Insert(const Key& key) {\n   // TODO(opt): We can use a barrier-free variant of FindGreaterOrEqual()\n   // here since Insert() is externally synchronized.\n   Node* prev[kMaxHeight];\n   Node* x = FindGreaterOrEqual(key, prev);\n \n   // Our data structure does not allow duplicate insertion\n-  assert(x == NULL || !Equal(key, x->key));\n+  assert(x == nullptr || !Equal(key, x->key));\n \n   int height = RandomHeight();\n   if (height > GetMaxHeight()) {\n     for (int i = GetMaxHeight(); i < height; i++) {\n       prev[i] = head_;\n     }\n-    //fprintf(stderr, \"Change height from %d to %d\\n\", max_height_, height);\n-\n     // It is ok to mutate max_height_ without any synchronization\n     // with concurrent readers.  A concurrent reader that observes\n     // the new value of max_height_ will see either the old value of\n-    // new level pointers from head_ (NULL), or a new value set in\n+    // new level pointers from head_ (nullptr), or a new value set in\n     // the loop below.  In the former case the reader will\n-    // immediately drop to the next level since NULL sorts after all\n+    // immediately drop to the next level since nullptr sorts after all\n     // keys.  In the latter case the reader will use the new node.\n-    max_height_.NoBarrier_Store(reinterpret_cast<void*>(height));\n+    max_height_.store(height, std::memory_order_relaxed);\n   }\n \n   x = NewNode(key, height);\n@@ -369,10 +367,10 @@ void SkipList<Key,Comparator>::Insert(const Key& key) {\n   }\n }\n \n-template<typename Key, class Comparator>\n-bool SkipList<Key,Comparator>::Contains(const Key& key) const {\n-  Node* x = FindGreaterOrEqual(key, NULL);\n-  if (x != NULL && Equal(key, x->key)) {\n+template <typename Key, class Comparator>\n+bool SkipList<Key, Comparator>::Contains(const Key& key) const {\n+  Node* x = FindGreaterOrEqual(key, nullptr);\n+  if (x != nullptr && Equal(key, x->key)) {\n     return true;\n   } else {\n     return false;"
      },
      {
        "sha": "9fa2d968291d67b465c2cd733f7d16d35aceb950",
        "filename": "src/leveldb/db/skiplist_test.cc",
        "status": "modified",
        "additions": 28,
        "deletions": 37,
        "changes": 65,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/skiplist_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/skiplist_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/skiplist_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -3,8 +3,13 @@\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n #include \"db/skiplist.h\"\n+\n+#include <atomic>\n #include <set>\n+\n #include \"leveldb/env.h\"\n+#include \"port/port.h\"\n+#include \"port/thread_annotations.h\"\n #include \"util/arena.h\"\n #include \"util/hash.h\"\n #include \"util/random.h\"\n@@ -26,7 +31,7 @@ struct Comparator {\n   }\n };\n \n-class SkipTest { };\n+class SkipTest {};\n \n TEST(SkipTest, Empty) {\n   Arena arena;\n@@ -112,8 +117,7 @@ TEST(SkipTest, InsertAndLookup) {\n \n     // Compare against model iterator\n     for (std::set<Key>::reverse_iterator model_iter = keys.rbegin();\n-         model_iter != keys.rend();\n-         ++model_iter) {\n+         model_iter != keys.rend(); ++model_iter) {\n       ASSERT_TRUE(iter.Valid());\n       ASSERT_EQ(*model_iter, iter.key());\n       iter.Prev();\n@@ -126,7 +130,7 @@ TEST(SkipTest, InsertAndLookup) {\n // concurrent readers (with no synchronization other than when a\n // reader's iterator is created), the reader always observes all the\n // data that was present in the skip list when the iterator was\n-// constructor.  Because insertions are happening concurrently, we may\n+// constructed.  Because insertions are happening concurrently, we may\n // also observe new values that were inserted since the iterator was\n // constructed, but we should never miss any values that were present\n // at iterator construction time.\n@@ -155,12 +159,12 @@ class ConcurrentTest {\n   static uint64_t hash(Key key) { return key & 0xff; }\n \n   static uint64_t HashNumbers(uint64_t k, uint64_t g) {\n-    uint64_t data[2] = { k, g };\n+    uint64_t data[2] = {k, g};\n     return Hash(reinterpret_cast<char*>(data), sizeof(data), 0);\n   }\n \n   static Key MakeKey(uint64_t k, uint64_t g) {\n-    assert(sizeof(Key) == sizeof(uint64_t));\n+    static_assert(sizeof(Key) == sizeof(uint64_t), \"\");\n     assert(k <= K);  // We sometimes pass K to seek to the end of the skiplist\n     assert(g <= 0xffffffffu);\n     return ((k << 40) | (g << 8) | (HashNumbers(k, g) & 0xff));\n@@ -186,13 +190,11 @@ class ConcurrentTest {\n \n   // Per-key generation\n   struct State {\n-    port::AtomicPointer generation[K];\n-    void Set(int k, intptr_t v) {\n-      generation[k].Release_Store(reinterpret_cast<void*>(v));\n-    }\n-    intptr_t Get(int k) {\n-      return reinterpret_cast<intptr_t>(generation[k].Acquire_Load());\n+    std::atomic<int> generation[K];\n+    void Set(int k, int v) {\n+      generation[k].store(v, std::memory_order_release);\n     }\n+    int Get(int k) { return generation[k].load(std::memory_order_acquire); }\n \n     State() {\n       for (int k = 0; k < K; k++) {\n@@ -211,7 +213,7 @@ class ConcurrentTest {\n   SkipList<Key, Comparator> list_;\n \n  public:\n-  ConcurrentTest() : list_(Comparator(), &arena_) { }\n+  ConcurrentTest() : list_(Comparator(), &arena_) {}\n \n   // REQUIRES: External synchronization\n   void WriteStep(Random* rnd) {\n@@ -250,11 +252,9 @@ class ConcurrentTest {\n         // Note that generation 0 is never inserted, so it is ok if\n         // <*,0,*> is missing.\n         ASSERT_TRUE((gen(pos) == 0) ||\n-                    (gen(pos) > static_cast<Key>(initial_state.Get(key(pos))))\n-                    ) << \"key: \" << key(pos)\n-                      << \"; gen: \" << gen(pos)\n-                      << \"; initgen: \"\n-                      << initial_state.Get(key(pos));\n+                    (gen(pos) > static_cast<Key>(initial_state.Get(key(pos)))))\n+            << \"key: \" << key(pos) << \"; gen: \" << gen(pos)\n+            << \"; initgen: \" << initial_state.Get(key(pos));\n \n         // Advance to next key in the valid key space\n         if (key(pos) < key(current)) {\n@@ -298,29 +298,22 @@ class TestState {\n  public:\n   ConcurrentTest t_;\n   int seed_;\n-  port::AtomicPointer quit_flag_;\n+  std::atomic<bool> quit_flag_;\n \n-  enum ReaderState {\n-    STARTING,\n-    RUNNING,\n-    DONE\n-  };\n+  enum ReaderState { STARTING, RUNNING, DONE };\n \n   explicit TestState(int s)\n-      : seed_(s),\n-        quit_flag_(NULL),\n-        state_(STARTING),\n-        state_cv_(&mu_) {}\n+      : seed_(s), quit_flag_(false), state_(STARTING), state_cv_(&mu_) {}\n \n-  void Wait(ReaderState s) {\n+  void Wait(ReaderState s) LOCKS_EXCLUDED(mu_) {\n     mu_.Lock();\n     while (state_ != s) {\n       state_cv_.Wait();\n     }\n     mu_.Unlock();\n   }\n \n-  void Change(ReaderState s) {\n+  void Change(ReaderState s) LOCKS_EXCLUDED(mu_) {\n     mu_.Lock();\n     state_ = s;\n     state_cv_.Signal();\n@@ -329,16 +322,16 @@ class TestState {\n \n  private:\n   port::Mutex mu_;\n-  ReaderState state_;\n-  port::CondVar state_cv_;\n+  ReaderState state_ GUARDED_BY(mu_);\n+  port::CondVar state_cv_ GUARDED_BY(mu_);\n };\n \n static void ConcurrentReader(void* arg) {\n   TestState* state = reinterpret_cast<TestState*>(arg);\n   Random rnd(state->seed_);\n   int64_t reads = 0;\n   state->Change(TestState::RUNNING);\n-  while (!state->quit_flag_.Acquire_Load()) {\n+  while (!state->quit_flag_.load(std::memory_order_acquire)) {\n     state->t_.ReadStep(&rnd);\n     ++reads;\n   }\n@@ -360,7 +353,7 @@ static void RunConcurrent(int run) {\n     for (int i = 0; i < kSize; i++) {\n       state.t_.WriteStep(&rnd);\n     }\n-    state.quit_flag_.Release_Store(&state);  // Any non-NULL arg will do\n+    state.quit_flag_.store(true, std::memory_order_release);\n     state.Wait(TestState::DONE);\n   }\n }\n@@ -373,6 +366,4 @@ TEST(SkipTest, Concurrent5) { RunConcurrent(5); }\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "9f1d66491d32f4d000a399391925751301bb7eec",
        "filename": "src/leveldb/db/snapshot.h",
        "status": "modified",
        "additions": 53,
        "deletions": 25,
        "changes": 78,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/snapshot.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/snapshot.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/snapshot.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -16,50 +16,78 @@ class SnapshotList;\n // Each SnapshotImpl corresponds to a particular sequence number.\n class SnapshotImpl : public Snapshot {\n  public:\n-  SequenceNumber number_;  // const after creation\n+  SnapshotImpl(SequenceNumber sequence_number)\n+      : sequence_number_(sequence_number) {}\n+\n+  SequenceNumber sequence_number() const { return sequence_number_; }\n \n  private:\n   friend class SnapshotList;\n \n-  // SnapshotImpl is kept in a doubly-linked circular list\n+  // SnapshotImpl is kept in a doubly-linked circular list. The SnapshotList\n+  // implementation operates on the next/previous fields direcly.\n   SnapshotImpl* prev_;\n   SnapshotImpl* next_;\n \n-  SnapshotList* list_;                 // just for sanity checks\n+  const SequenceNumber sequence_number_;\n+\n+#if !defined(NDEBUG)\n+  SnapshotList* list_ = nullptr;\n+#endif  // !defined(NDEBUG)\n };\n \n class SnapshotList {\n  public:\n-  SnapshotList() {\n-    list_.prev_ = &list_;\n-    list_.next_ = &list_;\n+  SnapshotList() : head_(0) {\n+    head_.prev_ = &head_;\n+    head_.next_ = &head_;\n+  }\n+\n+  bool empty() const { return head_.next_ == &head_; }\n+  SnapshotImpl* oldest() const {\n+    assert(!empty());\n+    return head_.next_;\n   }\n+  SnapshotImpl* newest() const {\n+    assert(!empty());\n+    return head_.prev_;\n+  }\n+\n+  // Creates a SnapshotImpl and appends it to the end of the list.\n+  SnapshotImpl* New(SequenceNumber sequence_number) {\n+    assert(empty() || newest()->sequence_number_ <= sequence_number);\n+\n+    SnapshotImpl* snapshot = new SnapshotImpl(sequence_number);\n \n-  bool empty() const { return list_.next_ == &list_; }\n-  SnapshotImpl* oldest() const { assert(!empty()); return list_.next_; }\n-  SnapshotImpl* newest() const { assert(!empty()); return list_.prev_; }\n-\n-  const SnapshotImpl* New(SequenceNumber seq) {\n-    SnapshotImpl* s = new SnapshotImpl;\n-    s->number_ = seq;\n-    s->list_ = this;\n-    s->next_ = &list_;\n-    s->prev_ = list_.prev_;\n-    s->prev_->next_ = s;\n-    s->next_->prev_ = s;\n-    return s;\n+#if !defined(NDEBUG)\n+    snapshot->list_ = this;\n+#endif  // !defined(NDEBUG)\n+    snapshot->next_ = &head_;\n+    snapshot->prev_ = head_.prev_;\n+    snapshot->prev_->next_ = snapshot;\n+    snapshot->next_->prev_ = snapshot;\n+    return snapshot;\n   }\n \n-  void Delete(const SnapshotImpl* s) {\n-    assert(s->list_ == this);\n-    s->prev_->next_ = s->next_;\n-    s->next_->prev_ = s->prev_;\n-    delete s;\n+  // Removes a SnapshotImpl from this list.\n+  //\n+  // The snapshot must have been created by calling New() on this list.\n+  //\n+  // The snapshot pointer should not be const, because its memory is\n+  // deallocated. However, that would force us to change DB::ReleaseSnapshot(),\n+  // which is in the API, and currently takes a const Snapshot.\n+  void Delete(const SnapshotImpl* snapshot) {\n+#if !defined(NDEBUG)\n+    assert(snapshot->list_ == this);\n+#endif  // !defined(NDEBUG)\n+    snapshot->prev_->next_ = snapshot->next_;\n+    snapshot->next_->prev_ = snapshot->prev_;\n+    delete snapshot;\n   }\n \n  private:\n   // Dummy head of doubly-linked list of snapshots\n-  SnapshotImpl list_;\n+  SnapshotImpl head_;\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "73f05fd7b1e7943ecca5eb0ea87c64475049644d",
        "filename": "src/leveldb/db/table_cache.cc",
        "status": "modified",
        "additions": 20,
        "deletions": 27,
        "changes": 47,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/table_cache.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/table_cache.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/table_cache.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -29,18 +29,14 @@ static void UnrefEntry(void* arg1, void* arg2) {\n   cache->Release(h);\n }\n \n-TableCache::TableCache(const std::string& dbname,\n-                       const Options* options,\n+TableCache::TableCache(const std::string& dbname, const Options& options,\n                        int entries)\n-    : env_(options->env),\n+    : env_(options.env),\n       dbname_(dbname),\n       options_(options),\n-      cache_(NewLRUCache(entries)) {\n-}\n+      cache_(NewLRUCache(entries)) {}\n \n-TableCache::~TableCache() {\n-  delete cache_;\n-}\n+TableCache::~TableCache() { delete cache_; }\n \n Status TableCache::FindTable(uint64_t file_number, uint64_t file_size,\n                              Cache::Handle** handle) {\n@@ -49,10 +45,10 @@ Status TableCache::FindTable(uint64_t file_number, uint64_t file_size,\n   EncodeFixed64(buf, file_number);\n   Slice key(buf, sizeof(buf));\n   *handle = cache_->Lookup(key);\n-  if (*handle == NULL) {\n+  if (*handle == nullptr) {\n     std::string fname = TableFileName(dbname_, file_number);\n-    RandomAccessFile* file = NULL;\n-    Table* table = NULL;\n+    RandomAccessFile* file = nullptr;\n+    Table* table = nullptr;\n     s = env_->NewRandomAccessFile(fname, &file);\n     if (!s.ok()) {\n       std::string old_fname = SSTTableFileName(dbname_, file_number);\n@@ -61,11 +57,11 @@ Status TableCache::FindTable(uint64_t file_number, uint64_t file_size,\n       }\n     }\n     if (s.ok()) {\n-      s = Table::Open(*options_, file, file_size, &table);\n+      s = Table::Open(options_, file, file_size, &table);\n     }\n \n     if (!s.ok()) {\n-      assert(table == NULL);\n+      assert(table == nullptr);\n       delete file;\n       // We do not cache error results so that if the error is transient,\n       // or somebody repairs the file, we recover automatically.\n@@ -80,14 +76,13 @@ Status TableCache::FindTable(uint64_t file_number, uint64_t file_size,\n }\n \n Iterator* TableCache::NewIterator(const ReadOptions& options,\n-                                  uint64_t file_number,\n-                                  uint64_t file_size,\n+                                  uint64_t file_number, uint64_t file_size,\n                                   Table** tableptr) {\n-  if (tableptr != NULL) {\n-    *tableptr = NULL;\n+  if (tableptr != nullptr) {\n+    *tableptr = nullptr;\n   }\n \n-  Cache::Handle* handle = NULL;\n+  Cache::Handle* handle = nullptr;\n   Status s = FindTable(file_number, file_size, &handle);\n   if (!s.ok()) {\n     return NewErrorIterator(s);\n@@ -96,23 +91,21 @@ Iterator* TableCache::NewIterator(const ReadOptions& options,\n   Table* table = reinterpret_cast<TableAndFile*>(cache_->Value(handle))->table;\n   Iterator* result = table->NewIterator(options);\n   result->RegisterCleanup(&UnrefEntry, cache_, handle);\n-  if (tableptr != NULL) {\n+  if (tableptr != nullptr) {\n     *tableptr = table;\n   }\n   return result;\n }\n \n-Status TableCache::Get(const ReadOptions& options,\n-                       uint64_t file_number,\n-                       uint64_t file_size,\n-                       const Slice& k,\n-                       void* arg,\n-                       void (*saver)(void*, const Slice&, const Slice&)) {\n-  Cache::Handle* handle = NULL;\n+Status TableCache::Get(const ReadOptions& options, uint64_t file_number,\n+                       uint64_t file_size, const Slice& k, void* arg,\n+                       void (*handle_result)(void*, const Slice&,\n+                                             const Slice&)) {\n+  Cache::Handle* handle = nullptr;\n   Status s = FindTable(file_number, file_size, &handle);\n   if (s.ok()) {\n     Table* t = reinterpret_cast<TableAndFile*>(cache_->Value(handle))->table;\n-    s = t->InternalGet(options, k, arg, saver);\n+    s = t->InternalGet(options, k, arg, handle_result);\n     cache_->Release(handle);\n   }\n   return s;"
      },
      {
        "sha": "93069c88442627690329fa302d4c9076c1914083",
        "filename": "src/leveldb/db/table_cache.h",
        "status": "modified",
        "additions": 15,
        "deletions": 18,
        "changes": 33,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/table_cache.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/table_cache.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/table_cache.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -7,8 +7,10 @@\n #ifndef STORAGE_LEVELDB_DB_TABLE_CACHE_H_\n #define STORAGE_LEVELDB_DB_TABLE_CACHE_H_\n \n-#include <string>\n #include <stdint.h>\n+\n+#include <string>\n+\n #include \"db/dbformat.h\"\n #include \"leveldb/cache.h\"\n #include \"leveldb/table.h\"\n@@ -20,40 +22,35 @@ class Env;\n \n class TableCache {\n  public:\n-  TableCache(const std::string& dbname, const Options* options, int entries);\n+  TableCache(const std::string& dbname, const Options& options, int entries);\n   ~TableCache();\n \n   // Return an iterator for the specified file number (the corresponding\n   // file length must be exactly \"file_size\" bytes).  If \"tableptr\" is\n-  // non-NULL, also sets \"*tableptr\" to point to the Table object\n-  // underlying the returned iterator, or NULL if no Table object underlies\n-  // the returned iterator.  The returned \"*tableptr\" object is owned by\n-  // the cache and should not be deleted, and is valid for as long as the\n+  // non-null, also sets \"*tableptr\" to point to the Table object\n+  // underlying the returned iterator, or to nullptr if no Table object\n+  // underlies the returned iterator.  The returned \"*tableptr\" object is owned\n+  // by the cache and should not be deleted, and is valid for as long as the\n   // returned iterator is live.\n-  Iterator* NewIterator(const ReadOptions& options,\n-                        uint64_t file_number,\n-                        uint64_t file_size,\n-                        Table** tableptr = NULL);\n+  Iterator* NewIterator(const ReadOptions& options, uint64_t file_number,\n+                        uint64_t file_size, Table** tableptr = nullptr);\n \n   // If a seek to internal key \"k\" in specified file finds an entry,\n   // call (*handle_result)(arg, found_key, found_value).\n-  Status Get(const ReadOptions& options,\n-             uint64_t file_number,\n-             uint64_t file_size,\n-             const Slice& k,\n-             void* arg,\n+  Status Get(const ReadOptions& options, uint64_t file_number,\n+             uint64_t file_size, const Slice& k, void* arg,\n              void (*handle_result)(void*, const Slice&, const Slice&));\n \n   // Evict any entry for the specified file number\n   void Evict(uint64_t file_number);\n \n  private:\n+  Status FindTable(uint64_t file_number, uint64_t file_size, Cache::Handle**);\n+\n   Env* const env_;\n   const std::string dbname_;\n-  const Options* options_;\n+  const Options& options_;\n   Cache* cache_;\n-\n-  Status FindTable(uint64_t file_number, uint64_t file_size, Cache::Handle**);\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "cd770ef12d842da25c622f1bf5eb649884321f18",
        "filename": "src/leveldb/db/version_edit.cc",
        "status": "modified",
        "additions": 23,
        "deletions": 32,
        "changes": 55,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_edit.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_edit.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/version_edit.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -12,15 +12,15 @@ namespace leveldb {\n // Tag numbers for serialized VersionEdit.  These numbers are written to\n // disk and should not be changed.\n enum Tag {\n-  kComparator           = 1,\n-  kLogNumber            = 2,\n-  kNextFileNumber       = 3,\n-  kLastSequence         = 4,\n-  kCompactPointer       = 5,\n-  kDeletedFile          = 6,\n-  kNewFile              = 7,\n+  kComparator = 1,\n+  kLogNumber = 2,\n+  kNextFileNumber = 3,\n+  kLastSequence = 4,\n+  kCompactPointer = 5,\n+  kDeletedFile = 6,\n+  kNewFile = 7,\n   // 8 was used for large value refs\n-  kPrevLogNumber        = 9\n+  kPrevLogNumber = 9\n };\n \n void VersionEdit::Clear() {\n@@ -66,12 +66,10 @@ void VersionEdit::EncodeTo(std::string* dst) const {\n     PutLengthPrefixedSlice(dst, compact_pointers_[i].second.Encode());\n   }\n \n-  for (DeletedFileSet::const_iterator iter = deleted_files_.begin();\n-       iter != deleted_files_.end();\n-       ++iter) {\n+  for (const auto& deleted_file_kvp : deleted_files_) {\n     PutVarint32(dst, kDeletedFile);\n-    PutVarint32(dst, iter->first);   // level\n-    PutVarint64(dst, iter->second);  // file number\n+    PutVarint32(dst, deleted_file_kvp.first);   // level\n+    PutVarint64(dst, deleted_file_kvp.second);  // file number\n   }\n \n   for (size_t i = 0; i < new_files_.size(); i++) {\n@@ -88,17 +86,15 @@ void VersionEdit::EncodeTo(std::string* dst) const {\n static bool GetInternalKey(Slice* input, InternalKey* dst) {\n   Slice str;\n   if (GetLengthPrefixedSlice(input, &str)) {\n-    dst->DecodeFrom(str);\n-    return true;\n+    return dst->DecodeFrom(str);\n   } else {\n     return false;\n   }\n }\n \n static bool GetLevel(Slice* input, int* level) {\n   uint32_t v;\n-  if (GetVarint32(input, &v) &&\n-      v < config::kNumLevels) {\n+  if (GetVarint32(input, &v) && v < config::kNumLevels) {\n     *level = v;\n     return true;\n   } else {\n@@ -109,7 +105,7 @@ static bool GetLevel(Slice* input, int* level) {\n Status VersionEdit::DecodeFrom(const Slice& src) {\n   Clear();\n   Slice input = src;\n-  const char* msg = NULL;\n+  const char* msg = nullptr;\n   uint32_t tag;\n \n   // Temporary storage for parsing\n@@ -119,7 +115,7 @@ Status VersionEdit::DecodeFrom(const Slice& src) {\n   Slice str;\n   InternalKey key;\n \n-  while (msg == NULL && GetVarint32(&input, &tag)) {\n+  while (msg == nullptr && GetVarint32(&input, &tag)) {\n     switch (tag) {\n       case kComparator:\n         if (GetLengthPrefixedSlice(&input, &str)) {\n@@ -163,26 +159,23 @@ Status VersionEdit::DecodeFrom(const Slice& src) {\n         break;\n \n       case kCompactPointer:\n-        if (GetLevel(&input, &level) &&\n-            GetInternalKey(&input, &key)) {\n+        if (GetLevel(&input, &level) && GetInternalKey(&input, &key)) {\n           compact_pointers_.push_back(std::make_pair(level, key));\n         } else {\n           msg = \"compaction pointer\";\n         }\n         break;\n \n       case kDeletedFile:\n-        if (GetLevel(&input, &level) &&\n-            GetVarint64(&input, &number)) {\n+        if (GetLevel(&input, &level) && GetVarint64(&input, &number)) {\n           deleted_files_.insert(std::make_pair(level, number));\n         } else {\n           msg = \"deleted file\";\n         }\n         break;\n \n       case kNewFile:\n-        if (GetLevel(&input, &level) &&\n-            GetVarint64(&input, &f.number) &&\n+        if (GetLevel(&input, &level) && GetVarint64(&input, &f.number) &&\n             GetVarint64(&input, &f.file_size) &&\n             GetInternalKey(&input, &f.smallest) &&\n             GetInternalKey(&input, &f.largest)) {\n@@ -198,12 +191,12 @@ Status VersionEdit::DecodeFrom(const Slice& src) {\n     }\n   }\n \n-  if (msg == NULL && !input.empty()) {\n+  if (msg == nullptr && !input.empty()) {\n     msg = \"invalid tag\";\n   }\n \n   Status result;\n-  if (msg != NULL) {\n+  if (msg != nullptr) {\n     result = Status::Corruption(\"VersionEdit\", msg);\n   }\n   return result;\n@@ -238,13 +231,11 @@ std::string VersionEdit::DebugString() const {\n     r.append(\" \");\n     r.append(compact_pointers_[i].second.DebugString());\n   }\n-  for (DeletedFileSet::const_iterator iter = deleted_files_.begin();\n-       iter != deleted_files_.end();\n-       ++iter) {\n+  for (const auto& deleted_files_kvp : deleted_files_) {\n     r.append(\"\\n  DeleteFile: \");\n-    AppendNumberTo(&r, iter->first);\n+    AppendNumberTo(&r, deleted_files_kvp.first);\n     r.append(\" \");\n-    AppendNumberTo(&r, iter->second);\n+    AppendNumberTo(&r, deleted_files_kvp.second);\n   }\n   for (size_t i = 0; i < new_files_.size(); i++) {\n     const FileMetaData& f = new_files_[i].second;"
      },
      {
        "sha": "0de4531773883813820de74be034c1c2c0a66c99",
        "filename": "src/leveldb/db/version_edit.h",
        "status": "modified",
        "additions": 13,
        "deletions": 14,
        "changes": 27,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_edit.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_edit.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/version_edit.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -8,27 +8,28 @@\n #include <set>\n #include <utility>\n #include <vector>\n+\n #include \"db/dbformat.h\"\n \n namespace leveldb {\n \n class VersionSet;\n \n struct FileMetaData {\n+  FileMetaData() : refs(0), allowed_seeks(1 << 30), file_size(0) {}\n+\n   int refs;\n-  int allowed_seeks;          // Seeks allowed until compaction\n+  int allowed_seeks;  // Seeks allowed until compaction\n   uint64_t number;\n-  uint64_t file_size;         // File size in bytes\n-  InternalKey smallest;       // Smallest internal key served by table\n-  InternalKey largest;        // Largest internal key served by table\n-\n-  FileMetaData() : refs(0), allowed_seeks(1 << 30), file_size(0) { }\n+  uint64_t file_size;    // File size in bytes\n+  InternalKey smallest;  // Smallest internal key served by table\n+  InternalKey largest;   // Largest internal key served by table\n };\n \n class VersionEdit {\n  public:\n   VersionEdit() { Clear(); }\n-  ~VersionEdit() { }\n+  ~VersionEdit() = default;\n \n   void Clear();\n \n@@ -59,10 +60,8 @@ class VersionEdit {\n   // Add the specified file at the specified number.\n   // REQUIRES: This version has not been saved (see VersionSet::SaveTo)\n   // REQUIRES: \"smallest\" and \"largest\" are smallest and largest keys in file\n-  void AddFile(int level, uint64_t file,\n-               uint64_t file_size,\n-               const InternalKey& smallest,\n-               const InternalKey& largest) {\n+  void AddFile(int level, uint64_t file, uint64_t file_size,\n+               const InternalKey& smallest, const InternalKey& largest) {\n     FileMetaData f;\n     f.number = file;\n     f.file_size = file_size;\n@@ -84,7 +83,7 @@ class VersionEdit {\n  private:\n   friend class VersionSet;\n \n-  typedef std::set< std::pair<int, uint64_t> > DeletedFileSet;\n+  typedef std::set<std::pair<int, uint64_t>> DeletedFileSet;\n \n   std::string comparator_;\n   uint64_t log_number_;\n@@ -97,9 +96,9 @@ class VersionEdit {\n   bool has_next_file_number_;\n   bool has_last_sequence_;\n \n-  std::vector< std::pair<int, InternalKey> > compact_pointers_;\n+  std::vector<std::pair<int, InternalKey>> compact_pointers_;\n   DeletedFileSet deleted_files_;\n-  std::vector< std::pair<int, FileMetaData> > new_files_;\n+  std::vector<std::pair<int, FileMetaData>> new_files_;\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "0b7cda8854825d97c83fcb598a62d4c311becb0f",
        "filename": "src/leveldb/db/version_edit_test.cc",
        "status": "modified",
        "additions": 2,
        "deletions": 4,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_edit_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_edit_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/version_edit_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -17,7 +17,7 @@ static void TestEncodeDecode(const VersionEdit& edit) {\n   ASSERT_EQ(encoded, encoded2);\n }\n \n-class VersionEditTest { };\n+class VersionEditTest {};\n \n TEST(VersionEditTest, EncodeDecode) {\n   static const uint64_t kBig = 1ull << 50;\n@@ -41,6 +41,4 @@ TEST(VersionEditTest, EncodeDecode) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "cd07346ea8a029bdc57dc9ca7339f79060369521",
        "filename": "src/leveldb/db/version_set.cc",
        "status": "modified",
        "additions": 272,
        "deletions": 245,
        "changes": 517,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_set.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_set.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/version_set.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -4,8 +4,10 @@\n \n #include \"db/version_set.h\"\n \n-#include <algorithm>\n #include <stdio.h>\n+\n+#include <algorithm>\n+\n #include \"db/filename.h\"\n #include \"db/log_reader.h\"\n #include \"db/log_writer.h\"\n@@ -84,8 +86,7 @@ Version::~Version() {\n }\n \n int FindFile(const InternalKeyComparator& icmp,\n-             const std::vector<FileMetaData*>& files,\n-             const Slice& key) {\n+             const std::vector<FileMetaData*>& files, const Slice& key) {\n   uint32_t left = 0;\n   uint32_t right = files.size();\n   while (left < right) {\n@@ -104,26 +105,25 @@ int FindFile(const InternalKeyComparator& icmp,\n   return right;\n }\n \n-static bool AfterFile(const Comparator* ucmp,\n-                      const Slice* user_key, const FileMetaData* f) {\n-  // NULL user_key occurs before all keys and is therefore never after *f\n-  return (user_key != NULL &&\n+static bool AfterFile(const Comparator* ucmp, const Slice* user_key,\n+                      const FileMetaData* f) {\n+  // null user_key occurs before all keys and is therefore never after *f\n+  return (user_key != nullptr &&\n           ucmp->Compare(*user_key, f->largest.user_key()) > 0);\n }\n \n-static bool BeforeFile(const Comparator* ucmp,\n-                       const Slice* user_key, const FileMetaData* f) {\n-  // NULL user_key occurs after all keys and is therefore never before *f\n-  return (user_key != NULL &&\n+static bool BeforeFile(const Comparator* ucmp, const Slice* user_key,\n+                       const FileMetaData* f) {\n+  // null user_key occurs after all keys and is therefore never before *f\n+  return (user_key != nullptr &&\n           ucmp->Compare(*user_key, f->smallest.user_key()) < 0);\n }\n \n-bool SomeFileOverlapsRange(\n-    const InternalKeyComparator& icmp,\n-    bool disjoint_sorted_files,\n-    const std::vector<FileMetaData*>& files,\n-    const Slice* smallest_user_key,\n-    const Slice* largest_user_key) {\n+bool SomeFileOverlapsRange(const InternalKeyComparator& icmp,\n+                           bool disjoint_sorted_files,\n+                           const std::vector<FileMetaData*>& files,\n+                           const Slice* smallest_user_key,\n+                           const Slice* largest_user_key) {\n   const Comparator* ucmp = icmp.user_comparator();\n   if (!disjoint_sorted_files) {\n     // Need to check against all files\n@@ -141,10 +141,11 @@ bool SomeFileOverlapsRange(\n \n   // Binary search over file list\n   uint32_t index = 0;\n-  if (smallest_user_key != NULL) {\n+  if (smallest_user_key != nullptr) {\n     // Find the earliest possible internal key for smallest_user_key\n-    InternalKey small(*smallest_user_key, kMaxSequenceNumber,kValueTypeForSeek);\n-    index = FindFile(icmp, files, small.Encode());\n+    InternalKey small_key(*smallest_user_key, kMaxSequenceNumber,\n+                          kValueTypeForSeek);\n+    index = FindFile(icmp, files, small_key.Encode());\n   }\n \n   if (index >= files.size()) {\n@@ -164,43 +165,40 @@ class Version::LevelFileNumIterator : public Iterator {\n  public:\n   LevelFileNumIterator(const InternalKeyComparator& icmp,\n                        const std::vector<FileMetaData*>* flist)\n-      : icmp_(icmp),\n-        flist_(flist),\n-        index_(flist->size()) {        // Marks as invalid\n-  }\n-  virtual bool Valid() const {\n-    return index_ < flist_->size();\n+      : icmp_(icmp), flist_(flist), index_(flist->size()) {  // Marks as invalid\n   }\n-  virtual void Seek(const Slice& target) {\n+  bool Valid() const override { return index_ < flist_->size(); }\n+  void Seek(const Slice& target) override {\n     index_ = FindFile(icmp_, *flist_, target);\n   }\n-  virtual void SeekToFirst() { index_ = 0; }\n-  virtual void SeekToLast() {\n+  void SeekToFirst() override { index_ = 0; }\n+  void SeekToLast() override {\n     index_ = flist_->empty() ? 0 : flist_->size() - 1;\n   }\n-  virtual void Next() {\n+  void Next() override {\n     assert(Valid());\n     index_++;\n   }\n-  virtual void Prev() {\n+  void Prev() override {\n     assert(Valid());\n     if (index_ == 0) {\n       index_ = flist_->size();  // Marks as invalid\n     } else {\n       index_--;\n     }\n   }\n-  Slice key() const {\n+  Slice key() const override {\n     assert(Valid());\n     return (*flist_)[index_]->largest.Encode();\n   }\n-  Slice value() const {\n+  Slice value() const override {\n     assert(Valid());\n     EncodeFixed64(value_buf_, (*flist_)[index_]->number);\n-    EncodeFixed64(value_buf_+8, (*flist_)[index_]->file_size);\n+    EncodeFixed64(value_buf_ + 8, (*flist_)[index_]->file_size);\n     return Slice(value_buf_, sizeof(value_buf_));\n   }\n-  virtual Status status() const { return Status::OK(); }\n+  Status status() const override { return Status::OK(); }\n+\n  private:\n   const InternalKeyComparator icmp_;\n   const std::vector<FileMetaData*>* const flist_;\n@@ -210,34 +208,31 @@ class Version::LevelFileNumIterator : public Iterator {\n   mutable char value_buf_[16];\n };\n \n-static Iterator* GetFileIterator(void* arg,\n-                                 const ReadOptions& options,\n+static Iterator* GetFileIterator(void* arg, const ReadOptions& options,\n                                  const Slice& file_value) {\n   TableCache* cache = reinterpret_cast<TableCache*>(arg);\n   if (file_value.size() != 16) {\n     return NewErrorIterator(\n         Status::Corruption(\"FileReader invoked with unexpected value\"));\n   } else {\n-    return cache->NewIterator(options,\n-                              DecodeFixed64(file_value.data()),\n+    return cache->NewIterator(options, DecodeFixed64(file_value.data()),\n                               DecodeFixed64(file_value.data() + 8));\n   }\n }\n \n Iterator* Version::NewConcatenatingIterator(const ReadOptions& options,\n                                             int level) const {\n   return NewTwoLevelIterator(\n-      new LevelFileNumIterator(vset_->icmp_, &files_[level]),\n-      &GetFileIterator, vset_->table_cache_, options);\n+      new LevelFileNumIterator(vset_->icmp_, &files_[level]), &GetFileIterator,\n+      vset_->table_cache_, options);\n }\n \n void Version::AddIterators(const ReadOptions& options,\n                            std::vector<Iterator*>* iters) {\n   // Merge all level zero files together since they may overlap\n   for (size_t i = 0; i < files_[0].size(); i++) {\n-    iters->push_back(\n-        vset_->table_cache_->NewIterator(\n-            options, files_[0][i]->number, files_[0][i]->file_size));\n+    iters->push_back(vset_->table_cache_->NewIterator(\n+        options, files_[0][i]->number, files_[0][i]->file_size));\n   }\n \n   // For levels > 0, we can use a concatenating iterator that sequentially\n@@ -264,7 +259,7 @@ struct Saver {\n   Slice user_key;\n   std::string* value;\n };\n-}\n+}  // namespace\n static void SaveValue(void* arg, const Slice& ikey, const Slice& v) {\n   Saver* s = reinterpret_cast<Saver*>(arg);\n   ParsedInternalKey parsed_key;\n@@ -284,10 +279,8 @@ static bool NewestFirst(FileMetaData* a, FileMetaData* b) {\n   return a->number > b->number;\n }\n \n-void Version::ForEachOverlapping(Slice user_key, Slice internal_key,\n-                                 void* arg,\n+void Version::ForEachOverlapping(Slice user_key, Slice internal_key, void* arg,\n                                  bool (*func)(void*, int, FileMetaData*)) {\n-  // TODO(sanjay): Change Version::Get() to use this function.\n   const Comparator* ucmp = vset_->icmp_.user_comparator();\n \n   // Search level-0 in order from newest to oldest.\n@@ -329,110 +322,89 @@ void Version::ForEachOverlapping(Slice user_key, Slice internal_key,\n   }\n }\n \n-Status Version::Get(const ReadOptions& options,\n-                    const LookupKey& k,\n-                    std::string* value,\n-                    GetStats* stats) {\n-  Slice ikey = k.internal_key();\n-  Slice user_key = k.user_key();\n-  const Comparator* ucmp = vset_->icmp_.user_comparator();\n-  Status s;\n-\n-  stats->seek_file = NULL;\n+Status Version::Get(const ReadOptions& options, const LookupKey& k,\n+                    std::string* value, GetStats* stats) {\n+  stats->seek_file = nullptr;\n   stats->seek_file_level = -1;\n-  FileMetaData* last_file_read = NULL;\n-  int last_file_read_level = -1;\n \n-  // We can search level-by-level since entries never hop across\n-  // levels.  Therefore we are guaranteed that if we find data\n-  // in an smaller level, later levels are irrelevant.\n-  std::vector<FileMetaData*> tmp;\n-  FileMetaData* tmp2;\n-  for (int level = 0; level < config::kNumLevels; level++) {\n-    size_t num_files = files_[level].size();\n-    if (num_files == 0) continue;\n+  struct State {\n+    Saver saver;\n+    GetStats* stats;\n+    const ReadOptions* options;\n+    Slice ikey;\n+    FileMetaData* last_file_read;\n+    int last_file_read_level;\n \n-    // Get the list of files to search in this level\n-    FileMetaData* const* files = &files_[level][0];\n-    if (level == 0) {\n-      // Level-0 files may overlap each other.  Find all files that\n-      // overlap user_key and process them in order from newest to oldest.\n-      tmp.reserve(num_files);\n-      for (uint32_t i = 0; i < num_files; i++) {\n-        FileMetaData* f = files[i];\n-        if (ucmp->Compare(user_key, f->smallest.user_key()) >= 0 &&\n-            ucmp->Compare(user_key, f->largest.user_key()) <= 0) {\n-          tmp.push_back(f);\n-        }\n-      }\n-      if (tmp.empty()) continue;\n+    VersionSet* vset;\n+    Status s;\n+    bool found;\n \n-      std::sort(tmp.begin(), tmp.end(), NewestFirst);\n-      files = &tmp[0];\n-      num_files = tmp.size();\n-    } else {\n-      // Binary search to find earliest index whose largest key >= ikey.\n-      uint32_t index = FindFile(vset_->icmp_, files_[level], ikey);\n-      if (index >= num_files) {\n-        files = NULL;\n-        num_files = 0;\n-      } else {\n-        tmp2 = files[index];\n-        if (ucmp->Compare(user_key, tmp2->smallest.user_key()) < 0) {\n-          // All of \"tmp2\" is past any data for user_key\n-          files = NULL;\n-          num_files = 0;\n-        } else {\n-          files = &tmp2;\n-          num_files = 1;\n-        }\n-      }\n-    }\n+    static bool Match(void* arg, int level, FileMetaData* f) {\n+      State* state = reinterpret_cast<State*>(arg);\n \n-    for (uint32_t i = 0; i < num_files; ++i) {\n-      if (last_file_read != NULL && stats->seek_file == NULL) {\n+      if (state->stats->seek_file == nullptr &&\n+          state->last_file_read != nullptr) {\n         // We have had more than one seek for this read.  Charge the 1st file.\n-        stats->seek_file = last_file_read;\n-        stats->seek_file_level = last_file_read_level;\n+        state->stats->seek_file = state->last_file_read;\n+        state->stats->seek_file_level = state->last_file_read_level;\n       }\n \n-      FileMetaData* f = files[i];\n-      last_file_read = f;\n-      last_file_read_level = level;\n-\n-      Saver saver;\n-      saver.state = kNotFound;\n-      saver.ucmp = ucmp;\n-      saver.user_key = user_key;\n-      saver.value = value;\n-      s = vset_->table_cache_->Get(options, f->number, f->file_size,\n-                                   ikey, &saver, SaveValue);\n-      if (!s.ok()) {\n-        return s;\n+      state->last_file_read = f;\n+      state->last_file_read_level = level;\n+\n+      state->s = state->vset->table_cache_->Get(*state->options, f->number,\n+                                                f->file_size, state->ikey,\n+                                                &state->saver, SaveValue);\n+      if (!state->s.ok()) {\n+        state->found = true;\n+        return false;\n       }\n-      switch (saver.state) {\n+      switch (state->saver.state) {\n         case kNotFound:\n-          break;      // Keep searching in other files\n+          return true;  // Keep searching in other files\n         case kFound:\n-          return s;\n+          state->found = true;\n+          return false;\n         case kDeleted:\n-          s = Status::NotFound(Slice());  // Use empty error message for speed\n-          return s;\n+          return false;\n         case kCorrupt:\n-          s = Status::Corruption(\"corrupted key for \", user_key);\n-          return s;\n+          state->s =\n+              Status::Corruption(\"corrupted key for \", state->saver.user_key);\n+          state->found = true;\n+          return false;\n       }\n+\n+      // Not reached. Added to avoid false compilation warnings of\n+      // \"control reaches end of non-void function\".\n+      return false;\n     }\n-  }\n+  };\n+\n+  State state;\n+  state.found = false;\n+  state.stats = stats;\n+  state.last_file_read = nullptr;\n+  state.last_file_read_level = -1;\n \n-  return Status::NotFound(Slice());  // Use an empty error message for speed\n+  state.options = &options;\n+  state.ikey = k.internal_key();\n+  state.vset = vset_;\n+\n+  state.saver.state = kNotFound;\n+  state.saver.ucmp = vset_->icmp_.user_comparator();\n+  state.saver.user_key = k.user_key();\n+  state.saver.value = value;\n+\n+  ForEachOverlapping(state.saver.user_key, state.ikey, &state, &State::Match);\n+\n+  return state.found ? state.s : Status::NotFound(Slice());\n }\n \n bool Version::UpdateStats(const GetStats& stats) {\n   FileMetaData* f = stats.seek_file;\n-  if (f != NULL) {\n+  if (f != nullptr) {\n     f->allowed_seeks--;\n-    if (f->allowed_seeks <= 0 && file_to_compact_ == NULL) {\n+    if (f->allowed_seeks <= 0 && file_to_compact_ == nullptr) {\n       file_to_compact_ = f;\n       file_to_compact_level_ = stats.seek_file_level;\n       return true;\n@@ -479,9 +451,7 @@ bool Version::RecordReadSample(Slice internal_key) {\n   return false;\n }\n \n-void Version::Ref() {\n-  ++refs_;\n-}\n+void Version::Ref() { ++refs_; }\n \n void Version::Unref() {\n   assert(this != &vset_->dummy_versions_);\n@@ -492,16 +462,14 @@ void Version::Unref() {\n   }\n }\n \n-bool Version::OverlapInLevel(int level,\n-                             const Slice* smallest_user_key,\n+bool Version::OverlapInLevel(int level, const Slice* smallest_user_key,\n                              const Slice* largest_user_key) {\n   return SomeFileOverlapsRange(vset_->icmp_, (level > 0), files_[level],\n                                smallest_user_key, largest_user_key);\n }\n \n-int Version::PickLevelForMemTableOutput(\n-    const Slice& smallest_user_key,\n-    const Slice& largest_user_key) {\n+int Version::PickLevelForMemTableOutput(const Slice& smallest_user_key,\n+                                        const Slice& largest_user_key) {\n   int level = 0;\n   if (!OverlapInLevel(0, &smallest_user_key, &largest_user_key)) {\n     // Push to next level if there is no overlap in next level,\n@@ -528,40 +496,39 @@ int Version::PickLevelForMemTableOutput(\n }\n \n // Store in \"*inputs\" all files in \"level\" that overlap [begin,end]\n-void Version::GetOverlappingInputs(\n-    int level,\n-    const InternalKey* begin,\n-    const InternalKey* end,\n-    std::vector<FileMetaData*>* inputs) {\n+void Version::GetOverlappingInputs(int level, const InternalKey* begin,\n+                                   const InternalKey* end,\n+                                   std::vector<FileMetaData*>* inputs) {\n   assert(level >= 0);\n   assert(level < config::kNumLevels);\n   inputs->clear();\n   Slice user_begin, user_end;\n-  if (begin != NULL) {\n+  if (begin != nullptr) {\n     user_begin = begin->user_key();\n   }\n-  if (end != NULL) {\n+  if (end != nullptr) {\n     user_end = end->user_key();\n   }\n   const Comparator* user_cmp = vset_->icmp_.user_comparator();\n-  for (size_t i = 0; i < files_[level].size(); ) {\n+  for (size_t i = 0; i < files_[level].size();) {\n     FileMetaData* f = files_[level][i++];\n     const Slice file_start = f->smallest.user_key();\n     const Slice file_limit = f->largest.user_key();\n-    if (begin != NULL && user_cmp->Compare(file_limit, user_begin) < 0) {\n+    if (begin != nullptr && user_cmp->Compare(file_limit, user_begin) < 0) {\n       // \"f\" is completely before specified range; skip it\n-    } else if (end != NULL && user_cmp->Compare(file_start, user_end) > 0) {\n+    } else if (end != nullptr && user_cmp->Compare(file_start, user_end) > 0) {\n       // \"f\" is completely after specified range; skip it\n     } else {\n       inputs->push_back(f);\n       if (level == 0) {\n         // Level-0 files may overlap each other.  So check if the newly\n         // added file has expanded the range.  If so, restart search.\n-        if (begin != NULL && user_cmp->Compare(file_start, user_begin) < 0) {\n+        if (begin != nullptr && user_cmp->Compare(file_start, user_begin) < 0) {\n           user_begin = file_start;\n           inputs->clear();\n           i = 0;\n-        } else if (end != NULL && user_cmp->Compare(file_limit, user_end) > 0) {\n+        } else if (end != nullptr &&\n+                   user_cmp->Compare(file_limit, user_end) > 0) {\n           user_end = file_limit;\n           inputs->clear();\n           i = 0;\n@@ -629,9 +596,7 @@ class VersionSet::Builder {\n \n  public:\n   // Initialize a builder with the files from *base and other info from *vset\n-  Builder(VersionSet* vset, Version* base)\n-      : vset_(vset),\n-        base_(base) {\n+  Builder(VersionSet* vset, Version* base) : vset_(vset), base_(base) {\n     base_->Ref();\n     BySmallestKey cmp;\n     cmp.internal_comparator = &vset_->icmp_;\n@@ -645,8 +610,8 @@ class VersionSet::Builder {\n       const FileSet* added = levels_[level].added_files;\n       std::vector<FileMetaData*> to_unref;\n       to_unref.reserve(added->size());\n-      for (FileSet::const_iterator it = added->begin();\n-          it != added->end(); ++it) {\n+      for (FileSet::const_iterator it = added->begin(); it != added->end();\n+           ++it) {\n         to_unref.push_back(*it);\n       }\n       delete added;\n@@ -671,12 +636,9 @@ class VersionSet::Builder {\n     }\n \n     // Delete files\n-    const VersionEdit::DeletedFileSet& del = edit->deleted_files_;\n-    for (VersionEdit::DeletedFileSet::const_iterator iter = del.begin();\n-         iter != del.end();\n-         ++iter) {\n-      const int level = iter->first;\n-      const uint64_t number = iter->second;\n+    for (const auto& deleted_file_set_kvp : edit->deleted_files_) {\n+      const int level = deleted_file_set_kvp.first;\n+      const uint64_t number = deleted_file_set_kvp.second;\n       levels_[level].deleted_files.insert(number);\n     }\n \n@@ -699,7 +661,7 @@ class VersionSet::Builder {\n       // same as the compaction of 40KB of data.  We are a little\n       // conservative and allow approximately one seek for every 16KB\n       // of data before triggering a compaction.\n-      f->allowed_seeks = (f->file_size / 16384);\n+      f->allowed_seeks = static_cast<int>((f->file_size / 16384U));\n       if (f->allowed_seeks < 100) f->allowed_seeks = 100;\n \n       levels_[level].deleted_files.erase(f->number);\n@@ -717,20 +679,17 @@ class VersionSet::Builder {\n       const std::vector<FileMetaData*>& base_files = base_->files_[level];\n       std::vector<FileMetaData*>::const_iterator base_iter = base_files.begin();\n       std::vector<FileMetaData*>::const_iterator base_end = base_files.end();\n-      const FileSet* added = levels_[level].added_files;\n-      v->files_[level].reserve(base_files.size() + added->size());\n-      for (FileSet::const_iterator added_iter = added->begin();\n-           added_iter != added->end();\n-           ++added_iter) {\n+      const FileSet* added_files = levels_[level].added_files;\n+      v->files_[level].reserve(base_files.size() + added_files->size());\n+      for (const auto& added_file : *added_files) {\n         // Add all smaller files listed in base_\n-        for (std::vector<FileMetaData*>::const_iterator bpos\n-                 = std::upper_bound(base_iter, base_end, *added_iter, cmp);\n-             base_iter != bpos;\n-             ++base_iter) {\n+        for (std::vector<FileMetaData*>::const_iterator bpos =\n+                 std::upper_bound(base_iter, base_end, added_file, cmp);\n+             base_iter != bpos; ++base_iter) {\n           MaybeAddFile(v, level, *base_iter);\n         }\n \n-        MaybeAddFile(v, level, *added_iter);\n+        MaybeAddFile(v, level, added_file);\n       }\n \n       // Add remaining base files\n@@ -742,7 +701,7 @@ class VersionSet::Builder {\n       // Make sure there is no overlap in levels > 0\n       if (level > 0) {\n         for (uint32_t i = 1; i < v->files_[level].size(); i++) {\n-          const InternalKey& prev_end = v->files_[level][i-1]->largest;\n+          const InternalKey& prev_end = v->files_[level][i - 1]->largest;\n           const InternalKey& this_begin = v->files_[level][i]->smallest;\n           if (vset_->icmp_.Compare(prev_end, this_begin) >= 0) {\n             fprintf(stderr, \"overlapping ranges in same level %s vs. %s\\n\",\n@@ -763,7 +722,7 @@ class VersionSet::Builder {\n       std::vector<FileMetaData*>* files = &v->files_[level];\n       if (level > 0 && !files->empty()) {\n         // Must not overlap\n-        assert(vset_->icmp_.Compare((*files)[files->size()-1]->largest,\n+        assert(vset_->icmp_.Compare((*files)[files->size() - 1]->largest,\n                                     f->smallest) < 0);\n       }\n       f->refs++;\n@@ -772,8 +731,7 @@ class VersionSet::Builder {\n   }\n };\n \n-VersionSet::VersionSet(const std::string& dbname,\n-                       const Options* options,\n+VersionSet::VersionSet(const std::string& dbname, const Options* options,\n                        TableCache* table_cache,\n                        const InternalKeyComparator* cmp)\n     : env_(options->env),\n@@ -786,10 +744,10 @@ VersionSet::VersionSet(const std::string& dbname,\n       last_sequence_(0),\n       log_number_(0),\n       prev_log_number_(0),\n-      descriptor_file_(NULL),\n-      descriptor_log_(NULL),\n+      descriptor_file_(nullptr),\n+      descriptor_log_(nullptr),\n       dummy_versions_(this),\n-      current_(NULL) {\n+      current_(nullptr) {\n   AppendVersion(new Version(this));\n }\n \n@@ -804,7 +762,7 @@ void VersionSet::AppendVersion(Version* v) {\n   // Make \"v\" current\n   assert(v->refs_ == 0);\n   assert(v != current_);\n-  if (current_ != NULL) {\n+  if (current_ != nullptr) {\n     current_->Unref();\n   }\n   current_ = v;\n@@ -844,10 +802,10 @@ Status VersionSet::LogAndApply(VersionEdit* edit, port::Mutex* mu) {\n   // a temporary file that contains a snapshot of the current version.\n   std::string new_manifest_file;\n   Status s;\n-  if (descriptor_log_ == NULL) {\n+  if (descriptor_log_ == nullptr) {\n     // No reason to unlock *mu here since we only hit this path in the\n     // first call to LogAndApply (when opening the database).\n-    assert(descriptor_file_ == NULL);\n+    assert(descriptor_file_ == nullptr);\n     new_manifest_file = DescriptorFileName(dbname_, manifest_file_number_);\n     edit->SetNextFile(next_file_number_);\n     s = env_->NewWritableFile(new_manifest_file, &descriptor_file_);\n@@ -893,19 +851,19 @@ Status VersionSet::LogAndApply(VersionEdit* edit, port::Mutex* mu) {\n     if (!new_manifest_file.empty()) {\n       delete descriptor_log_;\n       delete descriptor_file_;\n-      descriptor_log_ = NULL;\n-      descriptor_file_ = NULL;\n+      descriptor_log_ = nullptr;\n+      descriptor_file_ = nullptr;\n       env_->DeleteFile(new_manifest_file);\n     }\n   }\n \n   return s;\n }\n \n-Status VersionSet::Recover(bool *save_manifest) {\n+Status VersionSet::Recover(bool* save_manifest) {\n   struct LogReporter : public log::Reader::Reporter {\n     Status* status;\n-    virtual void Corruption(size_t bytes, const Status& s) {\n+    void Corruption(size_t bytes, const Status& s) override {\n       if (this->status->ok()) *this->status = s;\n     }\n   };\n@@ -916,7 +874,7 @@ Status VersionSet::Recover(bool *save_manifest) {\n   if (!s.ok()) {\n     return s;\n   }\n-  if (current.empty() || current[current.size()-1] != '\\n') {\n+  if (current.empty() || current[current.size() - 1] != '\\n') {\n     return Status::Corruption(\"CURRENT file does not end with newline\");\n   }\n   current.resize(current.size() - 1);\n@@ -925,6 +883,10 @@ Status VersionSet::Recover(bool *save_manifest) {\n   SequentialFile* file;\n   s = env_->NewSequentialFile(dscname, &file);\n   if (!s.ok()) {\n+    if (s.IsNotFound()) {\n+      return Status::Corruption(\"CURRENT points to a non-existent file\",\n+                                s.ToString());\n+    }\n     return s;\n   }\n \n@@ -941,7 +903,8 @@ Status VersionSet::Recover(bool *save_manifest) {\n   {\n     LogReporter reporter;\n     reporter.status = &s;\n-    log::Reader reader(file, &reporter, true/*checksum*/, 0/*initial_offset*/);\n+    log::Reader reader(file, &reporter, true /*checksum*/,\n+                       0 /*initial_offset*/);\n     Slice record;\n     std::string scratch;\n     while (reader.ReadRecord(&record, &scratch) && s.ok()) {\n@@ -982,7 +945,7 @@ Status VersionSet::Recover(bool *save_manifest) {\n     }\n   }\n   delete file;\n-  file = NULL;\n+  file = nullptr;\n \n   if (s.ok()) {\n     if (!have_next_file) {\n@@ -1040,12 +1003,12 @@ bool VersionSet::ReuseManifest(const std::string& dscname,\n     return false;\n   }\n \n-  assert(descriptor_file_ == NULL);\n-  assert(descriptor_log_ == NULL);\n+  assert(descriptor_file_ == nullptr);\n+  assert(descriptor_log_ == nullptr);\n   Status r = env_->NewAppendableFile(dscname, &descriptor_file_);\n   if (!r.ok()) {\n     Log(options_->info_log, \"Reuse MANIFEST: %s\\n\", r.ToString().c_str());\n-    assert(descriptor_file_ == NULL);\n+    assert(descriptor_file_ == nullptr);\n     return false;\n   }\n \n@@ -1066,7 +1029,7 @@ void VersionSet::Finalize(Version* v) {\n   int best_level = -1;\n   double best_score = -1;\n \n-  for (int level = 0; level < config::kNumLevels-1; level++) {\n+  for (int level = 0; level < config::kNumLevels - 1; level++) {\n     double score;\n     if (level == 0) {\n       // We treat level-0 specially by bounding the number of files\n@@ -1081,7 +1044,7 @@ void VersionSet::Finalize(Version* v) {\n       // setting, or very high compression ratios, or lots of\n       // overwrites/deletions).\n       score = v->files_[level].size() /\n-          static_cast<double>(config::kL0_CompactionTrigger);\n+              static_cast<double>(config::kL0_CompactionTrigger);\n     } else {\n       // Compute the ratio of current size to size limit.\n       const uint64_t level_bytes = TotalFileSize(v->files_[level]);\n@@ -1137,16 +1100,12 @@ int VersionSet::NumLevelFiles(int level) const {\n \n const char* VersionSet::LevelSummary(LevelSummaryStorage* scratch) const {\n   // Update code if kNumLevels changes\n-  assert(config::kNumLevels == 7);\n+  static_assert(config::kNumLevels == 7, \"\");\n   snprintf(scratch->buffer, sizeof(scratch->buffer),\n-           \"files[ %d %d %d %d %d %d %d ]\",\n-           int(current_->files_[0].size()),\n-           int(current_->files_[1].size()),\n-           int(current_->files_[2].size()),\n-           int(current_->files_[3].size()),\n-           int(current_->files_[4].size()),\n-           int(current_->files_[5].size()),\n-           int(current_->files_[6].size()));\n+           \"files[ %d %d %d %d %d %d %d ]\", int(current_->files_[0].size()),\n+           int(current_->files_[1].size()), int(current_->files_[2].size()),\n+           int(current_->files_[3].size()), int(current_->files_[4].size()),\n+           int(current_->files_[5].size()), int(current_->files_[6].size()));\n   return scratch->buffer;\n }\n \n@@ -1172,7 +1131,7 @@ uint64_t VersionSet::ApproximateOffsetOf(Version* v, const InternalKey& ikey) {\n         Table* tableptr;\n         Iterator* iter = table_cache_->NewIterator(\n             ReadOptions(), files[i]->number, files[i]->file_size, &tableptr);\n-        if (tableptr != NULL) {\n+        if (tableptr != nullptr) {\n           result += tableptr->ApproximateOffsetOf(ikey.Encode());\n         }\n         delete iter;\n@@ -1183,8 +1142,7 @@ uint64_t VersionSet::ApproximateOffsetOf(Version* v, const InternalKey& ikey) {\n }\n \n void VersionSet::AddLiveFiles(std::set<uint64_t>* live) {\n-  for (Version* v = dummy_versions_.next_;\n-       v != &dummy_versions_;\n+  for (Version* v = dummy_versions_.next_; v != &dummy_versions_;\n        v = v->next_) {\n     for (int level = 0; level < config::kNumLevels; level++) {\n       const std::vector<FileMetaData*>& files = v->files_[level];\n@@ -1207,7 +1165,7 @@ int64_t VersionSet::MaxNextLevelOverlappingBytes() {\n   for (int level = 1; level < config::kNumLevels - 1; level++) {\n     for (size_t i = 0; i < current_->files_[level].size(); i++) {\n       const FileMetaData* f = current_->files_[level][i];\n-      current_->GetOverlappingInputs(level+1, &f->smallest, &f->largest,\n+      current_->GetOverlappingInputs(level + 1, &f->smallest, &f->largest,\n                                      &overlaps);\n       const int64_t sum = TotalFileSize(overlaps);\n       if (sum > result) {\n@@ -1222,8 +1180,7 @@ int64_t VersionSet::MaxNextLevelOverlappingBytes() {\n // *smallest, *largest.\n // REQUIRES: inputs is not empty\n void VersionSet::GetRange(const std::vector<FileMetaData*>& inputs,\n-                          InternalKey* smallest,\n-                          InternalKey* largest) {\n+                          InternalKey* smallest, InternalKey* largest) {\n   assert(!inputs.empty());\n   smallest->Clear();\n   largest->Clear();\n@@ -1248,8 +1205,7 @@ void VersionSet::GetRange(const std::vector<FileMetaData*>& inputs,\n // REQUIRES: inputs is not empty\n void VersionSet::GetRange2(const std::vector<FileMetaData*>& inputs1,\n                            const std::vector<FileMetaData*>& inputs2,\n-                           InternalKey* smallest,\n-                           InternalKey* largest) {\n+                           InternalKey* smallest, InternalKey* largest) {\n   std::vector<FileMetaData*> all = inputs1;\n   all.insert(all.end(), inputs2.begin(), inputs2.end());\n   GetRange(all, smallest, largest);\n@@ -1271,8 +1227,8 @@ Iterator* VersionSet::MakeInputIterator(Compaction* c) {\n       if (c->level() + which == 0) {\n         const std::vector<FileMetaData*>& files = c->inputs_[which];\n         for (size_t i = 0; i < files.size(); i++) {\n-          list[num++] = table_cache_->NewIterator(\n-              options, files[i]->number, files[i]->file_size);\n+          list[num++] = table_cache_->NewIterator(options, files[i]->number,\n+                                                  files[i]->file_size);\n         }\n       } else {\n         // Create concatenating iterator for the files from this level\n@@ -1295,11 +1251,11 @@ Compaction* VersionSet::PickCompaction() {\n   // We prefer compactions triggered by too much data in a level over\n   // the compactions triggered by seeks.\n   const bool size_compaction = (current_->compaction_score_ >= 1);\n-  const bool seek_compaction = (current_->file_to_compact_ != NULL);\n+  const bool seek_compaction = (current_->file_to_compact_ != nullptr);\n   if (size_compaction) {\n     level = current_->compaction_level_;\n     assert(level >= 0);\n-    assert(level+1 < config::kNumLevels);\n+    assert(level + 1 < config::kNumLevels);\n     c = new Compaction(options_, level);\n \n     // Pick the first file that comes after compact_pointer_[level]\n@@ -1320,7 +1276,7 @@ Compaction* VersionSet::PickCompaction() {\n     c = new Compaction(options_, level);\n     c->inputs_[0].push_back(current_->file_to_compact_);\n   } else {\n-    return NULL;\n+    return nullptr;\n   }\n \n   c->input_version_ = current_;\n@@ -1342,12 +1298,94 @@ Compaction* VersionSet::PickCompaction() {\n   return c;\n }\n \n+// Finds the largest key in a vector of files. Returns true if files it not\n+// empty.\n+bool FindLargestKey(const InternalKeyComparator& icmp,\n+                    const std::vector<FileMetaData*>& files,\n+                    InternalKey* largest_key) {\n+  if (files.empty()) {\n+    return false;\n+  }\n+  *largest_key = files[0]->largest;\n+  for (size_t i = 1; i < files.size(); ++i) {\n+    FileMetaData* f = files[i];\n+    if (icmp.Compare(f->largest, *largest_key) > 0) {\n+      *largest_key = f->largest;\n+    }\n+  }\n+  return true;\n+}\n+\n+// Finds minimum file b2=(l2, u2) in level file for which l2 > u1 and\n+// user_key(l2) = user_key(u1)\n+FileMetaData* FindSmallestBoundaryFile(\n+    const InternalKeyComparator& icmp,\n+    const std::vector<FileMetaData*>& level_files,\n+    const InternalKey& largest_key) {\n+  const Comparator* user_cmp = icmp.user_comparator();\n+  FileMetaData* smallest_boundary_file = nullptr;\n+  for (size_t i = 0; i < level_files.size(); ++i) {\n+    FileMetaData* f = level_files[i];\n+    if (icmp.Compare(f->smallest, largest_key) > 0 &&\n+        user_cmp->Compare(f->smallest.user_key(), largest_key.user_key()) ==\n+            0) {\n+      if (smallest_boundary_file == nullptr ||\n+          icmp.Compare(f->smallest, smallest_boundary_file->smallest) < 0) {\n+        smallest_boundary_file = f;\n+      }\n+    }\n+  }\n+  return smallest_boundary_file;\n+}\n+\n+// Extracts the largest file b1 from |compaction_files| and then searches for a\n+// b2 in |level_files| for which user_key(u1) = user_key(l2). If it finds such a\n+// file b2 (known as a boundary file) it adds it to |compaction_files| and then\n+// searches again using this new upper bound.\n+//\n+// If there are two blocks, b1=(l1, u1) and b2=(l2, u2) and\n+// user_key(u1) = user_key(l2), and if we compact b1 but not b2 then a\n+// subsequent get operation will yield an incorrect result because it will\n+// return the record from b2 in level i rather than from b1 because it searches\n+// level by level for records matching the supplied user key.\n+//\n+// parameters:\n+//   in     level_files:      List of files to search for boundary files.\n+//   in/out compaction_files: List of files to extend by adding boundary files.\n+void AddBoundaryInputs(const InternalKeyComparator& icmp,\n+                       const std::vector<FileMetaData*>& level_files,\n+                       std::vector<FileMetaData*>* compaction_files) {\n+  InternalKey largest_key;\n+\n+  // Quick return if compaction_files is empty.\n+  if (!FindLargestKey(icmp, *compaction_files, &largest_key)) {\n+    return;\n+  }\n+\n+  bool continue_searching = true;\n+  while (continue_searching) {\n+    FileMetaData* smallest_boundary_file =\n+        FindSmallestBoundaryFile(icmp, level_files, largest_key);\n+\n+    // If a boundary file was found advance largest_key, otherwise we're done.\n+    if (smallest_boundary_file != NULL) {\n+      compaction_files->push_back(smallest_boundary_file);\n+      largest_key = smallest_boundary_file->largest;\n+    } else {\n+      continue_searching = false;\n+    }\n+  }\n+}\n+\n void VersionSet::SetupOtherInputs(Compaction* c) {\n   const int level = c->level();\n   InternalKey smallest, largest;\n+\n+  AddBoundaryInputs(icmp_, current_->files_[level], &c->inputs_[0]);\n   GetRange(c->inputs_[0], &smallest, &largest);\n \n-  current_->GetOverlappingInputs(level+1, &smallest, &largest, &c->inputs_[1]);\n+  current_->GetOverlappingInputs(level + 1, &smallest, &largest,\n+                                 &c->inputs_[1]);\n \n   // Get entire range covered by compaction\n   InternalKey all_start, all_limit;\n@@ -1358,6 +1396,7 @@ void VersionSet::SetupOtherInputs(Compaction* c) {\n   if (!c->inputs_[1].empty()) {\n     std::vector<FileMetaData*> expanded0;\n     current_->GetOverlappingInputs(level, &all_start, &all_limit, &expanded0);\n+    AddBoundaryInputs(icmp_, current_->files_[level], &expanded0);\n     const int64_t inputs0_size = TotalFileSize(c->inputs_[0]);\n     const int64_t inputs1_size = TotalFileSize(c->inputs_[1]);\n     const int64_t expanded0_size = TotalFileSize(expanded0);\n@@ -1367,18 +1406,14 @@ void VersionSet::SetupOtherInputs(Compaction* c) {\n       InternalKey new_start, new_limit;\n       GetRange(expanded0, &new_start, &new_limit);\n       std::vector<FileMetaData*> expanded1;\n-      current_->GetOverlappingInputs(level+1, &new_start, &new_limit,\n+      current_->GetOverlappingInputs(level + 1, &new_start, &new_limit,\n                                      &expanded1);\n       if (expanded1.size() == c->inputs_[1].size()) {\n         Log(options_->info_log,\n             \"Expanding@%d %d+%d (%ld+%ld bytes) to %d+%d (%ld+%ld bytes)\\n\",\n-            level,\n-            int(c->inputs_[0].size()),\n-            int(c->inputs_[1].size()),\n-            long(inputs0_size), long(inputs1_size),\n-            int(expanded0.size()),\n-            int(expanded1.size()),\n-            long(expanded0_size), long(inputs1_size));\n+            level, int(c->inputs_[0].size()), int(c->inputs_[1].size()),\n+            long(inputs0_size), long(inputs1_size), int(expanded0.size()),\n+            int(expanded1.size()), long(expanded0_size), long(inputs1_size));\n         smallest = new_start;\n         largest = new_limit;\n         c->inputs_[0] = expanded0;\n@@ -1395,13 +1430,6 @@ void VersionSet::SetupOtherInputs(Compaction* c) {\n                                    &c->grandparents_);\n   }\n \n-  if (false) {\n-    Log(options_->info_log, \"Compacting %d '%s' .. '%s'\",\n-        level,\n-        smallest.DebugString().c_str(),\n-        largest.DebugString().c_str());\n-  }\n-\n   // Update the place where we will do the next compaction for this level.\n   // We update this immediately instead of waiting for the VersionEdit\n   // to be applied so that if the compaction fails, we will try a different\n@@ -1410,14 +1438,12 @@ void VersionSet::SetupOtherInputs(Compaction* c) {\n   c->edit_.SetCompactPointer(level, largest);\n }\n \n-Compaction* VersionSet::CompactRange(\n-    int level,\n-    const InternalKey* begin,\n-    const InternalKey* end) {\n+Compaction* VersionSet::CompactRange(int level, const InternalKey* begin,\n+                                     const InternalKey* end) {\n   std::vector<FileMetaData*> inputs;\n   current_->GetOverlappingInputs(level, begin, end, &inputs);\n   if (inputs.empty()) {\n-    return NULL;\n+    return nullptr;\n   }\n \n   // Avoid compacting too much in one shot in case the range is large.\n@@ -1448,7 +1474,7 @@ Compaction* VersionSet::CompactRange(\n Compaction::Compaction(const Options* options, int level)\n     : level_(level),\n       max_output_file_size_(MaxFileSizeForLevel(options, level)),\n-      input_version_(NULL),\n+      input_version_(nullptr),\n       grandparent_index_(0),\n       seen_key_(false),\n       overlapped_bytes_(0) {\n@@ -1458,7 +1484,7 @@ Compaction::Compaction(const Options* options, int level)\n }\n \n Compaction::~Compaction() {\n-  if (input_version_ != NULL) {\n+  if (input_version_ != nullptr) {\n     input_version_->Unref();\n   }\n }\n@@ -1486,7 +1512,7 @@ bool Compaction::IsBaseLevelForKey(const Slice& user_key) {\n   const Comparator* user_cmp = input_version_->vset_->icmp_.user_comparator();\n   for (int lvl = level_ + 2; lvl < config::kNumLevels; lvl++) {\n     const std::vector<FileMetaData*>& files = input_version_->files_[lvl];\n-    for (; level_ptrs_[lvl] < files.size(); ) {\n+    while (level_ptrs_[lvl] < files.size()) {\n       FileMetaData* f = files[level_ptrs_[lvl]];\n       if (user_cmp->Compare(user_key, f->largest.user_key()) <= 0) {\n         // We've advanced far enough\n@@ -1507,8 +1533,9 @@ bool Compaction::ShouldStopBefore(const Slice& internal_key) {\n   // Scan to find earliest grandparent file that contains key.\n   const InternalKeyComparator* icmp = &vset->icmp_;\n   while (grandparent_index_ < grandparents_.size() &&\n-      icmp->Compare(internal_key,\n-                    grandparents_[grandparent_index_]->largest.Encode()) > 0) {\n+         icmp->Compare(internal_key,\n+                       grandparents_[grandparent_index_]->largest.Encode()) >\n+             0) {\n     if (seen_key_) {\n       overlapped_bytes_ += grandparents_[grandparent_index_]->file_size;\n     }\n@@ -1526,9 +1553,9 @@ bool Compaction::ShouldStopBefore(const Slice& internal_key) {\n }\n \n void Compaction::ReleaseInputs() {\n-  if (input_version_ != NULL) {\n+  if (input_version_ != nullptr) {\n     input_version_->Unref();\n-    input_version_ = NULL;\n+    input_version_ = nullptr;\n   }\n }\n "
      },
      {
        "sha": "69f3d701330f0967f1b04e4daae6f513dca9af85",
        "filename": "src/leveldb/db/version_set.h",
        "status": "modified",
        "additions": 59,
        "deletions": 64,
        "changes": 123,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_set.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_set.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/version_set.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -18,14 +18,17 @@\n #include <map>\n #include <set>\n #include <vector>\n+\n #include \"db/dbformat.h\"\n #include \"db/version_edit.h\"\n #include \"port/port.h\"\n #include \"port/thread_annotations.h\"\n \n namespace leveldb {\n \n-namespace log { class Writer; }\n+namespace log {\n+class Writer;\n+}\n \n class Compaction;\n class Iterator;\n@@ -39,37 +42,36 @@ class WritableFile;\n // Return the smallest index i such that files[i]->largest >= key.\n // Return files.size() if there is no such file.\n // REQUIRES: \"files\" contains a sorted list of non-overlapping files.\n-extern int FindFile(const InternalKeyComparator& icmp,\n-                    const std::vector<FileMetaData*>& files,\n-                    const Slice& key);\n+int FindFile(const InternalKeyComparator& icmp,\n+             const std::vector<FileMetaData*>& files, const Slice& key);\n \n // Returns true iff some file in \"files\" overlaps the user key range\n // [*smallest,*largest].\n-// smallest==NULL represents a key smaller than all keys in the DB.\n-// largest==NULL represents a key largest than all keys in the DB.\n+// smallest==nullptr represents a key smaller than all keys in the DB.\n+// largest==nullptr represents a key largest than all keys in the DB.\n // REQUIRES: If disjoint_sorted_files, files[] contains disjoint ranges\n //           in sorted order.\n-extern bool SomeFileOverlapsRange(\n-    const InternalKeyComparator& icmp,\n-    bool disjoint_sorted_files,\n-    const std::vector<FileMetaData*>& files,\n-    const Slice* smallest_user_key,\n-    const Slice* largest_user_key);\n+bool SomeFileOverlapsRange(const InternalKeyComparator& icmp,\n+                           bool disjoint_sorted_files,\n+                           const std::vector<FileMetaData*>& files,\n+                           const Slice* smallest_user_key,\n+                           const Slice* largest_user_key);\n \n class Version {\n  public:\n-  // Append to *iters a sequence of iterators that will\n-  // yield the contents of this Version when merged together.\n-  // REQUIRES: This version has been saved (see VersionSet::SaveTo)\n-  void AddIterators(const ReadOptions&, std::vector<Iterator*>* iters);\n-\n   // Lookup the value for key.  If found, store it in *val and\n   // return OK.  Else return a non-OK status.  Fills *stats.\n   // REQUIRES: lock is not held\n   struct GetStats {\n     FileMetaData* seek_file;\n     int seek_file_level;\n   };\n+\n+  // Append to *iters a sequence of iterators that will\n+  // yield the contents of this Version when merged together.\n+  // REQUIRES: This version has been saved (see VersionSet::SaveTo)\n+  void AddIterators(const ReadOptions&, std::vector<Iterator*>* iters);\n+\n   Status Get(const ReadOptions&, const LookupKey& key, std::string* val,\n              GetStats* stats);\n \n@@ -91,16 +93,15 @@ class Version {\n \n   void GetOverlappingInputs(\n       int level,\n-      const InternalKey* begin,         // NULL means before all keys\n-      const InternalKey* end,           // NULL means after all keys\n+      const InternalKey* begin,  // nullptr means before all keys\n+      const InternalKey* end,    // nullptr means after all keys\n       std::vector<FileMetaData*>* inputs);\n \n   // Returns true iff some file in the specified level overlaps\n   // some part of [*smallest_user_key,*largest_user_key].\n-  // smallest_user_key==NULL represents a key smaller than all keys in the DB.\n-  // largest_user_key==NULL represents a key largest than all keys in the DB.\n-  bool OverlapInLevel(int level,\n-                      const Slice* smallest_user_key,\n+  // smallest_user_key==nullptr represents a key smaller than all the DB's keys.\n+  // largest_user_key==nullptr represents a key largest than all the DB's keys.\n+  bool OverlapInLevel(int level, const Slice* smallest_user_key,\n                       const Slice* largest_user_key);\n \n   // Return the level at which we should place a new memtable compaction\n@@ -118,21 +119,36 @@ class Version {\n   friend class VersionSet;\n \n   class LevelFileNumIterator;\n+\n+  explicit Version(VersionSet* vset)\n+      : vset_(vset),\n+        next_(this),\n+        prev_(this),\n+        refs_(0),\n+        file_to_compact_(nullptr),\n+        file_to_compact_level_(-1),\n+        compaction_score_(-1),\n+        compaction_level_(-1) {}\n+\n+  Version(const Version&) = delete;\n+  Version& operator=(const Version&) = delete;\n+\n+  ~Version();\n+\n   Iterator* NewConcatenatingIterator(const ReadOptions&, int level) const;\n \n   // Call func(arg, level, f) for every file that overlaps user_key in\n   // order from newest to oldest.  If an invocation of func returns\n   // false, makes no more calls.\n   //\n   // REQUIRES: user portion of internal_key == user_key.\n-  void ForEachOverlapping(Slice user_key, Slice internal_key,\n-                          void* arg,\n+  void ForEachOverlapping(Slice user_key, Slice internal_key, void* arg,\n                           bool (*func)(void*, int, FileMetaData*));\n \n-  VersionSet* vset_;            // VersionSet to which this Version belongs\n-  Version* next_;               // Next version in linked list\n-  Version* prev_;               // Previous version in linked list\n-  int refs_;                    // Number of live refs to this version\n+  VersionSet* vset_;  // VersionSet to which this Version belongs\n+  Version* next_;     // Next version in linked list\n+  Version* prev_;     // Previous version in linked list\n+  int refs_;          // Number of live refs to this version\n \n   // List of files per level\n   std::vector<FileMetaData*> files_[config::kNumLevels];\n@@ -146,28 +162,15 @@ class Version {\n   // are initialized by Finalize().\n   double compaction_score_;\n   int compaction_level_;\n-\n-  explicit Version(VersionSet* vset)\n-      : vset_(vset), next_(this), prev_(this), refs_(0),\n-        file_to_compact_(NULL),\n-        file_to_compact_level_(-1),\n-        compaction_score_(-1),\n-        compaction_level_(-1) {\n-  }\n-\n-  ~Version();\n-\n-  // No copying allowed\n-  Version(const Version&);\n-  void operator=(const Version&);\n };\n \n class VersionSet {\n  public:\n-  VersionSet(const std::string& dbname,\n-             const Options* options,\n-             TableCache* table_cache,\n-             const InternalKeyComparator*);\n+  VersionSet(const std::string& dbname, const Options* options,\n+             TableCache* table_cache, const InternalKeyComparator*);\n+  VersionSet(const VersionSet&) = delete;\n+  VersionSet& operator=(const VersionSet&) = delete;\n+\n   ~VersionSet();\n \n   // Apply *edit to the current version to form a new descriptor that\n@@ -179,7 +182,7 @@ class VersionSet {\n       EXCLUSIVE_LOCKS_REQUIRED(mu);\n \n   // Recover the last saved descriptor from persistent storage.\n-  Status Recover(bool *save_manifest);\n+  Status Recover(bool* save_manifest);\n \n   // Return the current version.\n   Version* current() const { return current_; }\n@@ -225,19 +228,17 @@ class VersionSet {\n   uint64_t PrevLogNumber() const { return prev_log_number_; }\n \n   // Pick level and inputs for a new compaction.\n-  // Returns NULL if there is no compaction to be done.\n+  // Returns nullptr if there is no compaction to be done.\n   // Otherwise returns a pointer to a heap-allocated object that\n   // describes the compaction.  Caller should delete the result.\n   Compaction* PickCompaction();\n \n   // Return a compaction object for compacting the range [begin,end] in\n-  // the specified level.  Returns NULL if there is nothing in that\n+  // the specified level.  Returns nullptr if there is nothing in that\n   // level that overlaps the specified range.  Caller should delete\n   // the result.\n-  Compaction* CompactRange(\n-      int level,\n-      const InternalKey* begin,\n-      const InternalKey* end);\n+  Compaction* CompactRange(int level, const InternalKey* begin,\n+                           const InternalKey* end);\n \n   // Return the maximum overlapping data (in bytes) at next level for any\n   // file at a level >= 1.\n@@ -250,7 +251,7 @@ class VersionSet {\n   // Returns true iff some level needs a compaction.\n   bool NeedsCompaction() const {\n     Version* v = current_;\n-    return (v->compaction_score_ >= 1) || (v->file_to_compact_ != NULL);\n+    return (v->compaction_score_ >= 1) || (v->file_to_compact_ != nullptr);\n   }\n \n   // Add all files listed in any live version to *live.\n@@ -278,14 +279,12 @@ class VersionSet {\n \n   void Finalize(Version* v);\n \n-  void GetRange(const std::vector<FileMetaData*>& inputs,\n-                InternalKey* smallest,\n+  void GetRange(const std::vector<FileMetaData*>& inputs, InternalKey* smallest,\n                 InternalKey* largest);\n \n   void GetRange2(const std::vector<FileMetaData*>& inputs1,\n                  const std::vector<FileMetaData*>& inputs2,\n-                 InternalKey* smallest,\n-                 InternalKey* largest);\n+                 InternalKey* smallest, InternalKey* largest);\n \n   void SetupOtherInputs(Compaction* c);\n \n@@ -314,10 +313,6 @@ class VersionSet {\n   // Per-level key at which the next compaction at that level should start.\n   // Either an empty string, or a valid InternalKey.\n   std::string compact_pointer_[config::kNumLevels];\n-\n-  // No copying allowed\n-  VersionSet(const VersionSet&);\n-  void operator=(const VersionSet&);\n };\n \n // A Compaction encapsulates information about a compaction.\n@@ -374,7 +369,7 @@ class Compaction {\n   VersionEdit edit_;\n \n   // Each compaction reads inputs from \"level_\" and \"level_+1\"\n-  std::vector<FileMetaData*> inputs_[2];      // The two sets of inputs\n+  std::vector<FileMetaData*> inputs_[2];  // The two sets of inputs\n \n   // State used to check for number of overlapping grandparent files\n   // (parent == level_ + 1, grandparent == level_ + 2)"
      },
      {
        "sha": "c1056a1e7de40960afb5d58861d2145790865b8a",
        "filename": "src/leveldb/db/version_set_test.cc",
        "status": "modified",
        "additions": 198,
        "deletions": 45,
        "changes": 243,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_set_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/version_set_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/version_set_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -11,10 +11,7 @@ namespace leveldb {\n \n class FindFileTest {\n  public:\n-  std::vector<FileMetaData*> files_;\n-  bool disjoint_sorted_files_;\n-\n-  FindFileTest() : disjoint_sorted_files_(true) { }\n+  FindFileTest() : disjoint_sorted_files_(true) {}\n \n   ~FindFileTest() {\n     for (int i = 0; i < files_.size(); i++) {\n@@ -40,20 +37,25 @@ class FindFileTest {\n \n   bool Overlaps(const char* smallest, const char* largest) {\n     InternalKeyComparator cmp(BytewiseComparator());\n-    Slice s(smallest != NULL ? smallest : \"\");\n-    Slice l(largest != NULL ? largest : \"\");\n+    Slice s(smallest != nullptr ? smallest : \"\");\n+    Slice l(largest != nullptr ? largest : \"\");\n     return SomeFileOverlapsRange(cmp, disjoint_sorted_files_, files_,\n-                                 (smallest != NULL ? &s : NULL),\n-                                 (largest != NULL ? &l : NULL));\n+                                 (smallest != nullptr ? &s : nullptr),\n+                                 (largest != nullptr ? &l : nullptr));\n   }\n+\n+  bool disjoint_sorted_files_;\n+\n+ private:\n+  std::vector<FileMetaData*> files_;\n };\n \n TEST(FindFileTest, Empty) {\n   ASSERT_EQ(0, Find(\"foo\"));\n-  ASSERT_TRUE(! Overlaps(\"a\", \"z\"));\n-  ASSERT_TRUE(! Overlaps(NULL, \"z\"));\n-  ASSERT_TRUE(! Overlaps(\"a\", NULL));\n-  ASSERT_TRUE(! Overlaps(NULL, NULL));\n+  ASSERT_TRUE(!Overlaps(\"a\", \"z\"));\n+  ASSERT_TRUE(!Overlaps(nullptr, \"z\"));\n+  ASSERT_TRUE(!Overlaps(\"a\", nullptr));\n+  ASSERT_TRUE(!Overlaps(nullptr, nullptr));\n }\n \n TEST(FindFileTest, Single) {\n@@ -65,8 +67,8 @@ TEST(FindFileTest, Single) {\n   ASSERT_EQ(1, Find(\"q1\"));\n   ASSERT_EQ(1, Find(\"z\"));\n \n-  ASSERT_TRUE(! Overlaps(\"a\", \"b\"));\n-  ASSERT_TRUE(! Overlaps(\"z1\", \"z2\"));\n+  ASSERT_TRUE(!Overlaps(\"a\", \"b\"));\n+  ASSERT_TRUE(!Overlaps(\"z1\", \"z2\"));\n   ASSERT_TRUE(Overlaps(\"a\", \"p\"));\n   ASSERT_TRUE(Overlaps(\"a\", \"q\"));\n   ASSERT_TRUE(Overlaps(\"a\", \"z\"));\n@@ -78,15 +80,14 @@ TEST(FindFileTest, Single) {\n   ASSERT_TRUE(Overlaps(\"q\", \"q\"));\n   ASSERT_TRUE(Overlaps(\"q\", \"q1\"));\n \n-  ASSERT_TRUE(! Overlaps(NULL, \"j\"));\n-  ASSERT_TRUE(! Overlaps(\"r\", NULL));\n-  ASSERT_TRUE(Overlaps(NULL, \"p\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"p1\"));\n-  ASSERT_TRUE(Overlaps(\"q\", NULL));\n-  ASSERT_TRUE(Overlaps(NULL, NULL));\n+  ASSERT_TRUE(!Overlaps(nullptr, \"j\"));\n+  ASSERT_TRUE(!Overlaps(\"r\", nullptr));\n+  ASSERT_TRUE(Overlaps(nullptr, \"p\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"p1\"));\n+  ASSERT_TRUE(Overlaps(\"q\", nullptr));\n+  ASSERT_TRUE(Overlaps(nullptr, nullptr));\n }\n \n-\n TEST(FindFileTest, Multiple) {\n   Add(\"150\", \"200\");\n   Add(\"200\", \"250\");\n@@ -110,10 +111,10 @@ TEST(FindFileTest, Multiple) {\n   ASSERT_EQ(3, Find(\"450\"));\n   ASSERT_EQ(4, Find(\"451\"));\n \n-  ASSERT_TRUE(! Overlaps(\"100\", \"149\"));\n-  ASSERT_TRUE(! Overlaps(\"251\", \"299\"));\n-  ASSERT_TRUE(! Overlaps(\"451\", \"500\"));\n-  ASSERT_TRUE(! Overlaps(\"351\", \"399\"));\n+  ASSERT_TRUE(!Overlaps(\"100\", \"149\"));\n+  ASSERT_TRUE(!Overlaps(\"251\", \"299\"));\n+  ASSERT_TRUE(!Overlaps(\"451\", \"500\"));\n+  ASSERT_TRUE(!Overlaps(\"351\", \"399\"));\n \n   ASSERT_TRUE(Overlaps(\"100\", \"150\"));\n   ASSERT_TRUE(Overlaps(\"100\", \"200\"));\n@@ -130,25 +131,25 @@ TEST(FindFileTest, MultipleNullBoundaries) {\n   Add(\"200\", \"250\");\n   Add(\"300\", \"350\");\n   Add(\"400\", \"450\");\n-  ASSERT_TRUE(! Overlaps(NULL, \"149\"));\n-  ASSERT_TRUE(! Overlaps(\"451\", NULL));\n-  ASSERT_TRUE(Overlaps(NULL, NULL));\n-  ASSERT_TRUE(Overlaps(NULL, \"150\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"199\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"200\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"201\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"400\"));\n-  ASSERT_TRUE(Overlaps(NULL, \"800\"));\n-  ASSERT_TRUE(Overlaps(\"100\", NULL));\n-  ASSERT_TRUE(Overlaps(\"200\", NULL));\n-  ASSERT_TRUE(Overlaps(\"449\", NULL));\n-  ASSERT_TRUE(Overlaps(\"450\", NULL));\n+  ASSERT_TRUE(!Overlaps(nullptr, \"149\"));\n+  ASSERT_TRUE(!Overlaps(\"451\", nullptr));\n+  ASSERT_TRUE(Overlaps(nullptr, nullptr));\n+  ASSERT_TRUE(Overlaps(nullptr, \"150\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"199\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"200\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"201\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"400\"));\n+  ASSERT_TRUE(Overlaps(nullptr, \"800\"));\n+  ASSERT_TRUE(Overlaps(\"100\", nullptr));\n+  ASSERT_TRUE(Overlaps(\"200\", nullptr));\n+  ASSERT_TRUE(Overlaps(\"449\", nullptr));\n+  ASSERT_TRUE(Overlaps(\"450\", nullptr));\n }\n \n TEST(FindFileTest, OverlapSequenceChecks) {\n   Add(\"200\", \"200\", 5000, 3000);\n-  ASSERT_TRUE(! Overlaps(\"199\", \"199\"));\n-  ASSERT_TRUE(! Overlaps(\"201\", \"300\"));\n+  ASSERT_TRUE(!Overlaps(\"199\", \"199\"));\n+  ASSERT_TRUE(!Overlaps(\"201\", \"300\"));\n   ASSERT_TRUE(Overlaps(\"200\", \"200\"));\n   ASSERT_TRUE(Overlaps(\"190\", \"200\"));\n   ASSERT_TRUE(Overlaps(\"200\", \"210\"));\n@@ -158,8 +159,8 @@ TEST(FindFileTest, OverlappingFiles) {\n   Add(\"150\", \"600\");\n   Add(\"400\", \"500\");\n   disjoint_sorted_files_ = false;\n-  ASSERT_TRUE(! Overlaps(\"100\", \"149\"));\n-  ASSERT_TRUE(! Overlaps(\"601\", \"700\"));\n+  ASSERT_TRUE(!Overlaps(\"100\", \"149\"));\n+  ASSERT_TRUE(!Overlaps(\"601\", \"700\"));\n   ASSERT_TRUE(Overlaps(\"100\", \"150\"));\n   ASSERT_TRUE(Overlaps(\"100\", \"200\"));\n   ASSERT_TRUE(Overlaps(\"100\", \"300\"));\n@@ -172,8 +173,160 @@ TEST(FindFileTest, OverlappingFiles) {\n   ASSERT_TRUE(Overlaps(\"600\", \"700\"));\n }\n \n-}  // namespace leveldb\n+void AddBoundaryInputs(const InternalKeyComparator& icmp,\n+                       const std::vector<FileMetaData*>& level_files,\n+                       std::vector<FileMetaData*>* compaction_files);\n+\n+class AddBoundaryInputsTest {\n+ public:\n+  std::vector<FileMetaData*> level_files_;\n+  std::vector<FileMetaData*> compaction_files_;\n+  std::vector<FileMetaData*> all_files_;\n+  InternalKeyComparator icmp_;\n+\n+  AddBoundaryInputsTest() : icmp_(BytewiseComparator()) {}\n+\n+  ~AddBoundaryInputsTest() {\n+    for (size_t i = 0; i < all_files_.size(); ++i) {\n+      delete all_files_[i];\n+    }\n+    all_files_.clear();\n+  }\n+\n+  FileMetaData* CreateFileMetaData(uint64_t number, InternalKey smallest,\n+                                   InternalKey largest) {\n+    FileMetaData* f = new FileMetaData();\n+    f->number = number;\n+    f->smallest = smallest;\n+    f->largest = largest;\n+    all_files_.push_back(f);\n+    return f;\n+  }\n+};\n+\n+TEST(AddBoundaryInputsTest, TestEmptyFileSets) {\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_TRUE(compaction_files_.empty());\n+  ASSERT_TRUE(level_files_.empty());\n+}\n+\n+TEST(AddBoundaryInputsTest, TestEmptyLevelFiles) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 1, kTypeValue)));\n+  compaction_files_.push_back(f1);\n+\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_EQ(1, compaction_files_.size());\n+  ASSERT_EQ(f1, compaction_files_[0]);\n+  ASSERT_TRUE(level_files_.empty());\n+}\n+\n+TEST(AddBoundaryInputsTest, TestEmptyCompactionFiles) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 1, kTypeValue)));\n+  level_files_.push_back(f1);\n+\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_TRUE(compaction_files_.empty());\n+  ASSERT_EQ(1, level_files_.size());\n+  ASSERT_EQ(f1, level_files_[0]);\n+}\n+\n+TEST(AddBoundaryInputsTest, TestNoBoundaryFiles) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 1, kTypeValue)));\n+  FileMetaData* f2 =\n+      CreateFileMetaData(1, InternalKey(\"200\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"200\", 1, kTypeValue)));\n+  FileMetaData* f3 =\n+      CreateFileMetaData(1, InternalKey(\"300\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"300\", 1, kTypeValue)));\n+\n+  level_files_.push_back(f3);\n+  level_files_.push_back(f2);\n+  level_files_.push_back(f1);\n+  compaction_files_.push_back(f2);\n+  compaction_files_.push_back(f3);\n+\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_EQ(2, compaction_files_.size());\n+}\n+\n+TEST(AddBoundaryInputsTest, TestOneBoundaryFiles) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 3, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 2, kTypeValue)));\n+  FileMetaData* f2 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 1, kTypeValue),\n+                         InternalKey(InternalKey(\"200\", 3, kTypeValue)));\n+  FileMetaData* f3 =\n+      CreateFileMetaData(1, InternalKey(\"300\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"300\", 1, kTypeValue)));\n+\n+  level_files_.push_back(f3);\n+  level_files_.push_back(f2);\n+  level_files_.push_back(f1);\n+  compaction_files_.push_back(f1);\n+\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_EQ(2, compaction_files_.size());\n+  ASSERT_EQ(f1, compaction_files_[0]);\n+  ASSERT_EQ(f2, compaction_files_[1]);\n+}\n+\n+TEST(AddBoundaryInputsTest, TestTwoBoundaryFiles) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 6, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 5, kTypeValue)));\n+  FileMetaData* f2 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"300\", 1, kTypeValue)));\n+  FileMetaData* f3 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 4, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 3, kTypeValue)));\n+\n+  level_files_.push_back(f2);\n+  level_files_.push_back(f3);\n+  level_files_.push_back(f1);\n+  compaction_files_.push_back(f1);\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_EQ(3, compaction_files_.size());\n+  ASSERT_EQ(f1, compaction_files_[0]);\n+  ASSERT_EQ(f3, compaction_files_[1]);\n+  ASSERT_EQ(f2, compaction_files_[2]);\n }\n+\n+TEST(AddBoundaryInputsTest, TestDisjoinFilePointers) {\n+  FileMetaData* f1 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 6, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 5, kTypeValue)));\n+  FileMetaData* f2 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 6, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 5, kTypeValue)));\n+  FileMetaData* f3 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 2, kTypeValue),\n+                         InternalKey(InternalKey(\"300\", 1, kTypeValue)));\n+  FileMetaData* f4 =\n+      CreateFileMetaData(1, InternalKey(\"100\", 4, kTypeValue),\n+                         InternalKey(InternalKey(\"100\", 3, kTypeValue)));\n+\n+  level_files_.push_back(f2);\n+  level_files_.push_back(f3);\n+  level_files_.push_back(f4);\n+\n+  compaction_files_.push_back(f1);\n+\n+  AddBoundaryInputs(icmp_, level_files_, &compaction_files_);\n+  ASSERT_EQ(3, compaction_files_.size());\n+  ASSERT_EQ(f1, compaction_files_[0]);\n+  ASSERT_EQ(f4, compaction_files_[1]);\n+  ASSERT_EQ(f3, compaction_files_[2]);\n+}\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "b54313c35e9370e49e53e07349d6475d680c3cfe",
        "filename": "src/leveldb/db/write_batch.cc",
        "status": "modified",
        "additions": 13,
        "deletions": 10,
        "changes": 23,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/write_batch.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/write_batch.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/write_batch.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -15,30 +15,30 @@\n \n #include \"leveldb/write_batch.h\"\n \n-#include \"leveldb/db.h\"\n #include \"db/dbformat.h\"\n #include \"db/memtable.h\"\n #include \"db/write_batch_internal.h\"\n+#include \"leveldb/db.h\"\n #include \"util/coding.h\"\n \n namespace leveldb {\n \n // WriteBatch header has an 8-byte sequence number followed by a 4-byte count.\n static const size_t kHeader = 12;\n \n-WriteBatch::WriteBatch() {\n-  Clear();\n-}\n+WriteBatch::WriteBatch() { Clear(); }\n \n-WriteBatch::~WriteBatch() { }\n+WriteBatch::~WriteBatch() = default;\n \n-WriteBatch::Handler::~Handler() { }\n+WriteBatch::Handler::~Handler() = default;\n \n void WriteBatch::Clear() {\n   rep_.clear();\n   rep_.resize(kHeader);\n }\n \n+size_t WriteBatch::ApproximateSize() const { return rep_.size(); }\n+\n Status WriteBatch::Iterate(Handler* handler) const {\n   Slice input(rep_);\n   if (input.size() < kHeader) {\n@@ -108,25 +108,28 @@ void WriteBatch::Delete(const Slice& key) {\n   PutLengthPrefixedSlice(&rep_, key);\n }\n \n+void WriteBatch::Append(const WriteBatch& source) {\n+  WriteBatchInternal::Append(this, &source);\n+}\n+\n namespace {\n class MemTableInserter : public WriteBatch::Handler {\n  public:\n   SequenceNumber sequence_;\n   MemTable* mem_;\n \n-  virtual void Put(const Slice& key, const Slice& value) {\n+  void Put(const Slice& key, const Slice& value) override {\n     mem_->Add(sequence_, kTypeValue, key, value);\n     sequence_++;\n   }\n-  virtual void Delete(const Slice& key) {\n+  void Delete(const Slice& key) override {\n     mem_->Add(sequence_, kTypeDeletion, key, Slice());\n     sequence_++;\n   }\n };\n }  // namespace\n \n-Status WriteBatchInternal::InsertInto(const WriteBatch* b,\n-                                      MemTable* memtable) {\n+Status WriteBatchInternal::InsertInto(const WriteBatch* b, MemTable* memtable) {\n   MemTableInserter inserter;\n   inserter.sequence_ = WriteBatchInternal::Sequence(b);\n   inserter.mem_ = memtable;"
      },
      {
        "sha": "fce86e3f1f192cb9b30703a669f650aacb0ebd32",
        "filename": "src/leveldb/db/write_batch_internal.h",
        "status": "modified",
        "additions": 2,
        "deletions": 7,
        "changes": 9,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/write_batch_internal.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/write_batch_internal.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/write_batch_internal.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -29,13 +29,9 @@ class WriteBatchInternal {\n   // this batch.\n   static void SetSequence(WriteBatch* batch, SequenceNumber seq);\n \n-  static Slice Contents(const WriteBatch* batch) {\n-    return Slice(batch->rep_);\n-  }\n+  static Slice Contents(const WriteBatch* batch) { return Slice(batch->rep_); }\n \n-  static size_t ByteSize(const WriteBatch* batch) {\n-    return batch->rep_.size();\n-  }\n+  static size_t ByteSize(const WriteBatch* batch) { return batch->rep_.size(); }\n \n   static void SetContents(WriteBatch* batch, const Slice& contents);\n \n@@ -46,5 +42,4 @@ class WriteBatchInternal {\n \n }  // namespace leveldb\n \n-\n #endif  // STORAGE_LEVELDB_DB_WRITE_BATCH_INTERNAL_H_"
      },
      {
        "sha": "c32317fb5e80a8f6813e5663a5916cbccaca2c51",
        "filename": "src/leveldb/db/write_batch_test.cc",
        "status": "modified",
        "additions": 45,
        "deletions": 28,
        "changes": 73,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/write_batch_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/db/write_batch_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/db/write_batch_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -52,7 +52,7 @@ static std::string PrintContents(WriteBatch* b) {\n   return state;\n }\n \n-class WriteBatchTest { };\n+class WriteBatchTest {};\n \n TEST(WriteBatchTest, Empty) {\n   WriteBatch batch;\n@@ -68,10 +68,11 @@ TEST(WriteBatchTest, Multiple) {\n   WriteBatchInternal::SetSequence(&batch, 100);\n   ASSERT_EQ(100, WriteBatchInternal::Sequence(&batch));\n   ASSERT_EQ(3, WriteBatchInternal::Count(&batch));\n-  ASSERT_EQ(\"Put(baz, boo)@102\"\n-            \"Delete(box)@101\"\n-            \"Put(foo, bar)@100\",\n-            PrintContents(&batch));\n+  ASSERT_EQ(\n+      \"Put(baz, boo)@102\"\n+      \"Delete(box)@101\"\n+      \"Put(foo, bar)@100\",\n+      PrintContents(&batch));\n }\n \n TEST(WriteBatchTest, Corruption) {\n@@ -81,40 +82,56 @@ TEST(WriteBatchTest, Corruption) {\n   WriteBatchInternal::SetSequence(&batch, 200);\n   Slice contents = WriteBatchInternal::Contents(&batch);\n   WriteBatchInternal::SetContents(&batch,\n-                                  Slice(contents.data(),contents.size()-1));\n-  ASSERT_EQ(\"Put(foo, bar)@200\"\n-            \"ParseError()\",\n-            PrintContents(&batch));\n+                                  Slice(contents.data(), contents.size() - 1));\n+  ASSERT_EQ(\n+      \"Put(foo, bar)@200\"\n+      \"ParseError()\",\n+      PrintContents(&batch));\n }\n \n TEST(WriteBatchTest, Append) {\n   WriteBatch b1, b2;\n   WriteBatchInternal::SetSequence(&b1, 200);\n   WriteBatchInternal::SetSequence(&b2, 300);\n-  WriteBatchInternal::Append(&b1, &b2);\n-  ASSERT_EQ(\"\",\n-            PrintContents(&b1));\n+  b1.Append(b2);\n+  ASSERT_EQ(\"\", PrintContents(&b1));\n   b2.Put(\"a\", \"va\");\n-  WriteBatchInternal::Append(&b1, &b2);\n-  ASSERT_EQ(\"Put(a, va)@200\",\n-            PrintContents(&b1));\n+  b1.Append(b2);\n+  ASSERT_EQ(\"Put(a, va)@200\", PrintContents(&b1));\n   b2.Clear();\n   b2.Put(\"b\", \"vb\");\n-  WriteBatchInternal::Append(&b1, &b2);\n-  ASSERT_EQ(\"Put(a, va)@200\"\n-            \"Put(b, vb)@201\",\n-            PrintContents(&b1));\n+  b1.Append(b2);\n+  ASSERT_EQ(\n+      \"Put(a, va)@200\"\n+      \"Put(b, vb)@201\",\n+      PrintContents(&b1));\n   b2.Delete(\"foo\");\n-  WriteBatchInternal::Append(&b1, &b2);\n-  ASSERT_EQ(\"Put(a, va)@200\"\n-            \"Put(b, vb)@202\"\n-            \"Put(b, vb)@201\"\n-            \"Delete(foo)@203\",\n-            PrintContents(&b1));\n+  b1.Append(b2);\n+  ASSERT_EQ(\n+      \"Put(a, va)@200\"\n+      \"Put(b, vb)@202\"\n+      \"Put(b, vb)@201\"\n+      \"Delete(foo)@203\",\n+      PrintContents(&b1));\n }\n \n-}  // namespace leveldb\n+TEST(WriteBatchTest, ApproximateSize) {\n+  WriteBatch batch;\n+  size_t empty_size = batch.ApproximateSize();\n+\n+  batch.Put(Slice(\"foo\"), Slice(\"bar\"));\n+  size_t one_key_size = batch.ApproximateSize();\n+  ASSERT_LT(empty_size, one_key_size);\n+\n+  batch.Put(Slice(\"baz\"), Slice(\"boo\"));\n+  size_t two_keys_size = batch.ApproximateSize();\n+  ASSERT_LT(one_key_size, two_keys_size);\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n+  batch.Delete(Slice(\"box\"));\n+  size_t post_delete_size = batch.ApproximateSize();\n+  ASSERT_LT(two_keys_size, post_delete_size);\n }\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "f3fd77144c35258e8c55d0ef939b4def424ae989",
        "filename": "src/leveldb/doc/benchmark.html",
        "status": "modified",
        "additions": 3,
        "deletions": 3,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/doc/benchmark.html",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/doc/benchmark.html",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/doc/benchmark.html?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -90,9 +90,9 @@ <h1>LevelDB Benchmarks</h1>\n <h4>Benchmark Source Code</h4>\n <p>We wrote benchmark tools for SQLite and Kyoto TreeDB based on LevelDB's <span class=\"code\">db_bench</span>. The code for each of the benchmarks resides here:</p>\n <ul>\n-\t<li> <b>LevelDB:</b> <a href=\"http://code.google.com/p/leveldb/source/browse/trunk/db/db_bench.cc\">db/db_bench.cc</a>.</li>\n-\t<li> <b>SQLite:</b> <a href=\"http://code.google.com/p/leveldb/source/browse/#svn%2Ftrunk%2Fdoc%2Fbench%2Fdb_bench_sqlite3.cc\">doc/bench/db_bench_sqlite3.cc</a>.</li>\n-\t<li> <b>Kyoto TreeDB:</b> <a href=\"http://code.google.com/p/leveldb/source/browse/#svn%2Ftrunk%2Fdoc%2Fbench%2Fdb_bench_tree_db.cc\">doc/bench/db_bench_tree_db.cc</a>.</li>\n+\t<li> <b>LevelDB:</b> <a href=\"https://github.com/google/leveldb/blob/master/benchmarks/db_bench.cc\">benchmarks/db_bench.cc</a>.</li>\n+\t<li> <b>SQLite:</b> <a href=\"https://github.com/google/leveldb/blob/master/benchmarks/db_bench_sqlite3.cc\">benchmarks/db_bench_sqlite3.cc</a>.</li>\n+\t<li> <b>Kyoto TreeDB:</b> <a href=\"https://github.com/google/leveldb/blob/master/benchmarks/db_bench_tree_db.cc\">benchmarks/db_bench_tree_db.cc</a>.</li>\n </ul>\n \n <h4>Custom Build Specifications</h4>"
      },
      {
        "sha": "cacabb96fc70e63b845b50bf85219254d8142288",
        "filename": "src/leveldb/doc/impl.md",
        "status": "modified",
        "additions": 8,
        "deletions": 6,
        "changes": 14,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/doc/impl.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/doc/impl.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/doc/impl.md?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -64,13 +64,15 @@ Other files used for miscellaneous purposes may also be present (LOCK, *.dbtmp).\n \n ## Level 0\n \n-When the log file grows above a certain size (1MB by default):\n-Create a brand new memtable and log file and direct future updates here\n+When the log file grows above a certain size (4MB by default):\n+Create a brand new memtable and log file and direct future updates here.\n+\n In the background:\n-Write the contents of the previous memtable to an sstable\n-Discard the memtable\n-Delete the old log file and the old memtable\n-Add the new sstable to the young (level-0) level.\n+\n+1. Write the contents of the previous memtable to an sstable.\n+2. Discard the memtable.\n+3. Delete the old log file and the old memtable.\n+4. Add the new sstable to the young (level-0) level.\n \n ## Compactions\n "
      },
      {
        "sha": "3d9a25805b7bffae11648cd573fd4d3fa4ed0282",
        "filename": "src/leveldb/doc/index.md",
        "status": "modified",
        "additions": 5,
        "deletions": 5,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/doc/index.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/doc/index.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/doc/index.md?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -307,7 +307,7 @@ version numbers found in the keys to decide how to interpret them.\n ## Performance\n \n Performance can be tuned by changing the default values of the types defined in\n-`include/leveldb/options.h`.\n+`include/options.h`.\n \n ### Block size\n \n@@ -338,19 +338,19 @@ options.compression = leveldb::kNoCompression;\n ### Cache\n \n The contents of the database are stored in a set of files in the filesystem and\n-each file stores a sequence of compressed blocks. If options.cache is non-NULL,\n-it is used to cache frequently used uncompressed block contents.\n+each file stores a sequence of compressed blocks. If options.block_cache is\n+non-NULL, it is used to cache frequently used uncompressed block contents.\n \n ```c++\n #include \"leveldb/cache.h\"\n \n leveldb::Options options;\n-options.cache = leveldb::NewLRUCache(100 * 1048576);  // 100MB cache\n+options.block_cache = leveldb::NewLRUCache(100 * 1048576);  // 100MB cache\n leveldb::DB* db;\n leveldb::DB::Open(options, name, &db);\n ... use the db ...\n delete db\n-delete options.cache;\n+delete options.block_cache;\n ```\n \n Note that the cache holds uncompressed data, and therefore it should be sized"
      },
      {
        "sha": "47e4481f7c55ef33ce26c0ca9bf4f30c9f0ef629",
        "filename": "src/leveldb/helpers/memenv/memenv.cc",
        "status": "modified",
        "additions": 98,
        "deletions": 105,
        "changes": 203,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/helpers/memenv/memenv.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/helpers/memenv/memenv.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/helpers/memenv/memenv.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -4,14 +4,18 @@\n \n #include \"helpers/memenv/memenv.h\"\n \n+#include <string.h>\n+\n+#include <limits>\n+#include <map>\n+#include <string>\n+#include <vector>\n+\n #include \"leveldb/env.h\"\n #include \"leveldb/status.h\"\n #include \"port/port.h\"\n+#include \"port/thread_annotations.h\"\n #include \"util/mutexlock.h\"\n-#include <map>\n-#include <string.h>\n-#include <string>\n-#include <vector>\n \n namespace leveldb {\n \n@@ -23,6 +27,10 @@ class FileState {\n   // and the caller must call Ref() at least once.\n   FileState() : refs_(0), size_(0) {}\n \n+  // No copying allowed.\n+  FileState(const FileState&) = delete;\n+  FileState& operator=(const FileState&) = delete;\n+\n   // Increase the reference count.\n   void Ref() {\n     MutexLock lock(&refs_mutex_);\n@@ -47,9 +55,22 @@ class FileState {\n     }\n   }\n \n-  uint64_t Size() const { return size_; }\n+  uint64_t Size() const {\n+    MutexLock lock(&blocks_mutex_);\n+    return size_;\n+  }\n+\n+  void Truncate() {\n+    MutexLock lock(&blocks_mutex_);\n+    for (char*& block : blocks_) {\n+      delete[] block;\n+    }\n+    blocks_.clear();\n+    size_ = 0;\n+  }\n \n   Status Read(uint64_t offset, size_t n, Slice* result, char* scratch) const {\n+    MutexLock lock(&blocks_mutex_);\n     if (offset > size_) {\n       return Status::IOError(\"Offset greater than file size.\");\n     }\n@@ -62,16 +83,9 @@ class FileState {\n       return Status::OK();\n     }\n \n-    assert(offset / kBlockSize <= SIZE_MAX);\n+    assert(offset / kBlockSize <= std::numeric_limits<size_t>::max());\n     size_t block = static_cast<size_t>(offset / kBlockSize);\n     size_t block_offset = offset % kBlockSize;\n-\n-    if (n <= kBlockSize - block_offset) {\n-      // The requested bytes are all in the first block.\n-      *result = Slice(blocks_[block] + block_offset, n);\n-      return Status::OK();\n-    }\n-\n     size_t bytes_to_copy = n;\n     char* dst = scratch;\n \n@@ -96,6 +110,7 @@ class FileState {\n     const char* src = data.data();\n     size_t src_len = data.size();\n \n+    MutexLock lock(&blocks_mutex_);\n     while (src_len > 0) {\n       size_t avail;\n       size_t offset = size_ % kBlockSize;\n@@ -122,28 +137,17 @@ class FileState {\n   }\n \n  private:\n-  // Private since only Unref() should be used to delete it.\n-  ~FileState() {\n-    for (std::vector<char*>::iterator i = blocks_.begin(); i != blocks_.end();\n-         ++i) {\n-      delete [] *i;\n-    }\n-  }\n+  enum { kBlockSize = 8 * 1024 };\n \n-  // No copying allowed.\n-  FileState(const FileState&);\n-  void operator=(const FileState&);\n+  // Private since only Unref() should be used to delete it.\n+  ~FileState() { Truncate(); }\n \n   port::Mutex refs_mutex_;\n-  int refs_;  // Protected by refs_mutex_;\n+  int refs_ GUARDED_BY(refs_mutex_);\n \n-  // The following fields are not protected by any mutex. They are only mutable\n-  // while the file is being written, and concurrent access is not allowed\n-  // to writable files.\n-  std::vector<char*> blocks_;\n-  uint64_t size_;\n-\n-  enum { kBlockSize = 8 * 1024 };\n+  mutable port::Mutex blocks_mutex_;\n+  std::vector<char*> blocks_ GUARDED_BY(blocks_mutex_);\n+  uint64_t size_ GUARDED_BY(blocks_mutex_);\n };\n \n class SequentialFileImpl : public SequentialFile {\n@@ -152,19 +156,17 @@ class SequentialFileImpl : public SequentialFile {\n     file_->Ref();\n   }\n \n-  ~SequentialFileImpl() {\n-    file_->Unref();\n-  }\n+  ~SequentialFileImpl() override { file_->Unref(); }\n \n-  virtual Status Read(size_t n, Slice* result, char* scratch) {\n+  Status Read(size_t n, Slice* result, char* scratch) override {\n     Status s = file_->Read(pos_, n, result, scratch);\n     if (s.ok()) {\n       pos_ += result->size();\n     }\n     return s;\n   }\n \n-  virtual Status Skip(uint64_t n) {\n+  Status Skip(uint64_t n) override {\n     if (pos_ > file_->Size()) {\n       return Status::IOError(\"pos_ > file_->Size()\");\n     }\n@@ -176,135 +178,130 @@ class SequentialFileImpl : public SequentialFile {\n     return Status::OK();\n   }\n \n-  virtual std::string GetName() const { return \"[memenv]\"; }\n+  virtual std::string GetName() const override { return \"[memenv]\"; }\n  private:\n   FileState* file_;\n   uint64_t pos_;\n };\n \n class RandomAccessFileImpl : public RandomAccessFile {\n  public:\n-  explicit RandomAccessFileImpl(FileState* file) : file_(file) {\n-    file_->Ref();\n-  }\n+  explicit RandomAccessFileImpl(FileState* file) : file_(file) { file_->Ref(); }\n \n-  ~RandomAccessFileImpl() {\n-    file_->Unref();\n-  }\n+  ~RandomAccessFileImpl() override { file_->Unref(); }\n \n-  virtual Status Read(uint64_t offset, size_t n, Slice* result,\n-                      char* scratch) const {\n+  Status Read(uint64_t offset, size_t n, Slice* result,\n+              char* scratch) const override {\n     return file_->Read(offset, n, result, scratch);\n   }\n \n-  virtual std::string GetName() const { return \"[memenv]\"; }\n+  virtual std::string GetName() const override { return \"[memenv]\"; }\n  private:\n   FileState* file_;\n };\n \n class WritableFileImpl : public WritableFile {\n  public:\n-  WritableFileImpl(FileState* file) : file_(file) {\n-    file_->Ref();\n-  }\n+  WritableFileImpl(FileState* file) : file_(file) { file_->Ref(); }\n \n-  ~WritableFileImpl() {\n-    file_->Unref();\n-  }\n+  ~WritableFileImpl() override { file_->Unref(); }\n \n-  virtual Status Append(const Slice& data) {\n-    return file_->Append(data);\n-  }\n+  Status Append(const Slice& data) override { return file_->Append(data); }\n \n-  virtual Status Close() { return Status::OK(); }\n-  virtual Status Flush() { return Status::OK(); }\n-  virtual Status Sync() { return Status::OK(); }\n+  Status Close() override { return Status::OK(); }\n+  Status Flush() override { return Status::OK(); }\n+  Status Sync() override { return Status::OK(); }\n \n-  virtual std::string GetName() const { return \"[memenv]\"; }\n+  virtual std::string GetName() const override { return \"[memenv]\"; }\n  private:\n   FileState* file_;\n };\n \n class NoOpLogger : public Logger {\n  public:\n-  virtual void Logv(const char* format, va_list ap) { }\n+  void Logv(const char* format, va_list ap) override {}\n };\n \n class InMemoryEnv : public EnvWrapper {\n  public:\n-  explicit InMemoryEnv(Env* base_env) : EnvWrapper(base_env) { }\n+  explicit InMemoryEnv(Env* base_env) : EnvWrapper(base_env) {}\n \n-  virtual ~InMemoryEnv() {\n-    for (FileSystem::iterator i = file_map_.begin(); i != file_map_.end(); ++i){\n-      i->second->Unref();\n+  ~InMemoryEnv() override {\n+    for (const auto& kvp : file_map_) {\n+      kvp.second->Unref();\n     }\n   }\n \n   // Partial implementation of the Env interface.\n-  virtual Status NewSequentialFile(const std::string& fname,\n-                                   SequentialFile** result) {\n+  Status NewSequentialFile(const std::string& fname,\n+                           SequentialFile** result) override {\n     MutexLock lock(&mutex_);\n     if (file_map_.find(fname) == file_map_.end()) {\n-      *result = NULL;\n+      *result = nullptr;\n       return Status::IOError(fname, \"File not found\");\n     }\n \n     *result = new SequentialFileImpl(file_map_[fname]);\n     return Status::OK();\n   }\n \n-  virtual Status NewRandomAccessFile(const std::string& fname,\n-                                     RandomAccessFile** result) {\n+  Status NewRandomAccessFile(const std::string& fname,\n+                             RandomAccessFile** result) override {\n     MutexLock lock(&mutex_);\n     if (file_map_.find(fname) == file_map_.end()) {\n-      *result = NULL;\n+      *result = nullptr;\n       return Status::IOError(fname, \"File not found\");\n     }\n \n     *result = new RandomAccessFileImpl(file_map_[fname]);\n     return Status::OK();\n   }\n \n-  virtual Status NewWritableFile(const std::string& fname,\n-                                 WritableFile** result) {\n+  Status NewWritableFile(const std::string& fname,\n+                         WritableFile** result) override {\n     MutexLock lock(&mutex_);\n-    if (file_map_.find(fname) != file_map_.end()) {\n-      DeleteFileInternal(fname);\n-    }\n+    FileSystem::iterator it = file_map_.find(fname);\n \n-    FileState* file = new FileState();\n-    file->Ref();\n-    file_map_[fname] = file;\n+    FileState* file;\n+    if (it == file_map_.end()) {\n+      // File is not currently open.\n+      file = new FileState();\n+      file->Ref();\n+      file_map_[fname] = file;\n+    } else {\n+      file = it->second;\n+      file->Truncate();\n+    }\n \n     *result = new WritableFileImpl(file);\n     return Status::OK();\n   }\n \n-  virtual Status NewAppendableFile(const std::string& fname,\n-                                   WritableFile** result) {\n+  Status NewAppendableFile(const std::string& fname,\n+                           WritableFile** result) override {\n     MutexLock lock(&mutex_);\n     FileState** sptr = &file_map_[fname];\n     FileState* file = *sptr;\n-    if (file == NULL) {\n+    if (file == nullptr) {\n       file = new FileState();\n       file->Ref();\n     }\n     *result = new WritableFileImpl(file);\n     return Status::OK();\n   }\n \n-  virtual bool FileExists(const std::string& fname) {\n+  bool FileExists(const std::string& fname) override {\n     MutexLock lock(&mutex_);\n     return file_map_.find(fname) != file_map_.end();\n   }\n \n-  virtual Status GetChildren(const std::string& dir,\n-                             std::vector<std::string>* result) {\n+  Status GetChildren(const std::string& dir,\n+                     std::vector<std::string>* result) override {\n     MutexLock lock(&mutex_);\n     result->clear();\n \n-    for (FileSystem::iterator i = file_map_.begin(); i != file_map_.end(); ++i){\n-      const std::string& filename = i->first;\n+    for (const auto& kvp : file_map_) {\n+      const std::string& filename = kvp.first;\n \n       if (filename.size() >= dir.size() + 1 && filename[dir.size()] == '/' &&\n           Slice(filename).starts_with(Slice(dir))) {\n@@ -315,7 +312,8 @@ class InMemoryEnv : public EnvWrapper {\n     return Status::OK();\n   }\n \n-  void DeleteFileInternal(const std::string& fname) {\n+  void DeleteFileInternal(const std::string& fname)\n+      EXCLUSIVE_LOCKS_REQUIRED(mutex_) {\n     if (file_map_.find(fname) == file_map_.end()) {\n       return;\n     }\n@@ -324,7 +322,7 @@ class InMemoryEnv : public EnvWrapper {\n     file_map_.erase(fname);\n   }\n \n-  virtual Status DeleteFile(const std::string& fname) {\n+  Status DeleteFile(const std::string& fname) override {\n     MutexLock lock(&mutex_);\n     if (file_map_.find(fname) == file_map_.end()) {\n       return Status::IOError(fname, \"File not found\");\n@@ -334,15 +332,11 @@ class InMemoryEnv : public EnvWrapper {\n     return Status::OK();\n   }\n \n-  virtual Status CreateDir(const std::string& dirname) {\n-    return Status::OK();\n-  }\n+  Status CreateDir(const std::string& dirname) override { return Status::OK(); }\n \n-  virtual Status DeleteDir(const std::string& dirname) {\n-    return Status::OK();\n-  }\n+  Status DeleteDir(const std::string& dirname) override { return Status::OK(); }\n \n-  virtual Status GetFileSize(const std::string& fname, uint64_t* file_size) {\n+  Status GetFileSize(const std::string& fname, uint64_t* file_size) override {\n     MutexLock lock(&mutex_);\n     if (file_map_.find(fname) == file_map_.end()) {\n       return Status::IOError(fname, \"File not found\");\n@@ -352,8 +346,8 @@ class InMemoryEnv : public EnvWrapper {\n     return Status::OK();\n   }\n \n-  virtual Status RenameFile(const std::string& src,\n-                            const std::string& target) {\n+  Status RenameFile(const std::string& src,\n+                    const std::string& target) override {\n     MutexLock lock(&mutex_);\n     if (file_map_.find(src) == file_map_.end()) {\n       return Status::IOError(src, \"File not found\");\n@@ -365,37 +359,36 @@ class InMemoryEnv : public EnvWrapper {\n     return Status::OK();\n   }\n \n-  virtual Status LockFile(const std::string& fname, FileLock** lock) {\n+  Status LockFile(const std::string& fname, FileLock** lock) override {\n     *lock = new FileLock;\n     return Status::OK();\n   }\n \n-  virtual Status UnlockFile(FileLock* lock) {\n+  Status UnlockFile(FileLock* lock) override {\n     delete lock;\n     return Status::OK();\n   }\n \n-  virtual Status GetTestDirectory(std::string* path) {\n+  Status GetTestDirectory(std::string* path) override {\n     *path = \"/test\";\n     return Status::OK();\n   }\n \n-  virtual Status NewLogger(const std::string& fname, Logger** result) {\n+  Status NewLogger(const std::string& fname, Logger** result) override {\n     *result = new NoOpLogger;\n     return Status::OK();\n   }\n \n  private:\n   // Map from filenames to FileState objects, representing a simple file system.\n   typedef std::map<std::string, FileState*> FileSystem;\n+\n   port::Mutex mutex_;\n-  FileSystem file_map_;  // Protected by mutex_.\n+  FileSystem file_map_ GUARDED_BY(mutex_);\n };\n \n }  // namespace\n \n-Env* NewMemEnv(Env* base_env) {\n-  return new InMemoryEnv(base_env);\n-}\n+Env* NewMemEnv(Env* base_env) { return new InMemoryEnv(base_env); }\n \n }  // namespace leveldb"
      },
      {
        "sha": "3d929e4c4e564d6d2d981328465b1e65fc2cea59",
        "filename": "src/leveldb/helpers/memenv/memenv.h",
        "status": "modified",
        "additions": 3,
        "deletions": 1,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/helpers/memenv/memenv.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/helpers/memenv/memenv.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/helpers/memenv/memenv.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -5,6 +5,8 @@\n #ifndef STORAGE_LEVELDB_HELPERS_MEMENV_MEMENV_H_\n #define STORAGE_LEVELDB_HELPERS_MEMENV_MEMENV_H_\n \n+#include \"leveldb/export.h\"\n+\n namespace leveldb {\n \n class Env;\n@@ -13,7 +15,7 @@ class Env;\n // all non-file-storage tasks to base_env. The caller must delete the result\n // when it is no longer needed.\n // *base_env must remain live while the result is in use.\n-Env* NewMemEnv(Env* base_env);\n+LEVELDB_EXPORT Env* NewMemEnv(Env* base_env);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "94ad06be6817406f7f1624174931af442ee679f6",
        "filename": "src/leveldb/helpers/memenv/memenv_test.cc",
        "status": "modified",
        "additions": 39,
        "deletions": 21,
        "changes": 60,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/helpers/memenv/memenv_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/helpers/memenv/memenv_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/helpers/memenv/memenv_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -4,25 +4,22 @@\n \n #include \"helpers/memenv/memenv.h\"\n \n+#include <string>\n+#include <vector>\n+\n #include \"db/db_impl.h\"\n #include \"leveldb/db.h\"\n #include \"leveldb/env.h\"\n #include \"util/testharness.h\"\n-#include <string>\n-#include <vector>\n \n namespace leveldb {\n \n class MemEnvTest {\n  public:\n-  Env* env_;\n+  MemEnvTest() : env_(NewMemEnv(Env::Default())) {}\n+  ~MemEnvTest() { delete env_; }\n \n-  MemEnvTest()\n-      : env_(NewMemEnv(Env::Default())) {\n-  }\n-  ~MemEnvTest() {\n-    delete env_;\n-  }\n+  Env* env_;\n };\n \n TEST(MemEnvTest, Basics) {\n@@ -109,25 +106,25 @@ TEST(MemEnvTest, ReadWrite) {\n \n   // Read sequentially.\n   ASSERT_OK(env_->NewSequentialFile(\"/dir/f\", &seq_file));\n-  ASSERT_OK(seq_file->Read(5, &result, scratch)); // Read \"hello\".\n+  ASSERT_OK(seq_file->Read(5, &result, scratch));  // Read \"hello\".\n   ASSERT_EQ(0, result.compare(\"hello\"));\n   ASSERT_OK(seq_file->Skip(1));\n-  ASSERT_OK(seq_file->Read(1000, &result, scratch)); // Read \"world\".\n+  ASSERT_OK(seq_file->Read(1000, &result, scratch));  // Read \"world\".\n   ASSERT_EQ(0, result.compare(\"world\"));\n-  ASSERT_OK(seq_file->Read(1000, &result, scratch)); // Try reading past EOF.\n+  ASSERT_OK(seq_file->Read(1000, &result, scratch));  // Try reading past EOF.\n   ASSERT_EQ(0, result.size());\n-  ASSERT_OK(seq_file->Skip(100)); // Try to skip past end of file.\n+  ASSERT_OK(seq_file->Skip(100));  // Try to skip past end of file.\n   ASSERT_OK(seq_file->Read(1000, &result, scratch));\n   ASSERT_EQ(0, result.size());\n   delete seq_file;\n \n   // Random reads.\n   ASSERT_OK(env_->NewRandomAccessFile(\"/dir/f\", &rand_file));\n-  ASSERT_OK(rand_file->Read(6, 5, &result, scratch)); // Read \"world\".\n+  ASSERT_OK(rand_file->Read(6, 5, &result, scratch));  // Read \"world\".\n   ASSERT_EQ(0, result.compare(\"world\"));\n-  ASSERT_OK(rand_file->Read(0, 5, &result, scratch)); // Read \"hello\".\n+  ASSERT_OK(rand_file->Read(0, 5, &result, scratch));  // Read \"hello\".\n   ASSERT_EQ(0, result.compare(\"hello\"));\n-  ASSERT_OK(rand_file->Read(10, 100, &result, scratch)); // Read \"d\".\n+  ASSERT_OK(rand_file->Read(10, 100, &result, scratch));  // Read \"d\".\n   ASSERT_EQ(0, result.compare(\"d\"));\n \n   // Too high offset.\n@@ -176,7 +173,7 @@ TEST(MemEnvTest, LargeWrite) {\n   SequentialFile* seq_file;\n   Slice result;\n   ASSERT_OK(env_->NewSequentialFile(\"/dir/f\", &seq_file));\n-  ASSERT_OK(seq_file->Read(3, &result, scratch)); // Read \"foo\".\n+  ASSERT_OK(seq_file->Read(3, &result, scratch));  // Read \"foo\".\n   ASSERT_EQ(0, result.compare(\"foo\"));\n \n   size_t read = 0;\n@@ -188,7 +185,30 @@ TEST(MemEnvTest, LargeWrite) {\n   }\n   ASSERT_TRUE(write_data == read_data);\n   delete seq_file;\n-  delete [] scratch;\n+  delete[] scratch;\n+}\n+\n+TEST(MemEnvTest, OverwriteOpenFile) {\n+  const char kWrite1Data[] = \"Write #1 data\";\n+  const size_t kFileDataLen = sizeof(kWrite1Data) - 1;\n+  const std::string kTestFileName = test::TmpDir() + \"/leveldb-TestFile.dat\";\n+\n+  ASSERT_OK(WriteStringToFile(env_, kWrite1Data, kTestFileName));\n+\n+  RandomAccessFile* rand_file;\n+  ASSERT_OK(env_->NewRandomAccessFile(kTestFileName, &rand_file));\n+\n+  const char kWrite2Data[] = \"Write #2 data\";\n+  ASSERT_OK(WriteStringToFile(env_, kWrite2Data, kTestFileName));\n+\n+  // Verify that overwriting an open file will result in the new file data\n+  // being read from files opened before the write.\n+  Slice result;\n+  char scratch[kFileDataLen];\n+  ASSERT_OK(rand_file->Read(0, kFileDataLen, &result, scratch));\n+  ASSERT_EQ(0, result.compare(kWrite2Data));\n+\n+  delete rand_file;\n }\n \n TEST(MemEnvTest, DBTest) {\n@@ -236,6 +256,4 @@ TEST(MemEnvTest, DBTest) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "02c79ba72e0919ddec530b936fb75f5fd98b4f15",
        "filename": "src/leveldb/include/leveldb/c.h",
        "status": "modified",
        "additions": 150,
        "deletions": 170,
        "changes": 320,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/c.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/c.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/c.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -32,7 +32,7 @@\n   On failure, leveldb frees the old value of *errptr and\n   set *errptr to a malloc()ed error message.\n \n-  (4) Bools have the type unsigned char (0 == false; rest == true)\n+  (4) Bools have the type uint8_t (0 == false; rest == true)\n \n   (5) All of the pointer arguments must be non-NULL.\n */\n@@ -48,225 +48,205 @@ extern \"C\" {\n #include <stddef.h>\n #include <stdint.h>\n \n+#include \"leveldb/export.h\"\n+\n /* Exported types */\n \n-typedef struct leveldb_t               leveldb_t;\n-typedef struct leveldb_cache_t         leveldb_cache_t;\n-typedef struct leveldb_comparator_t    leveldb_comparator_t;\n-typedef struct leveldb_env_t           leveldb_env_t;\n-typedef struct leveldb_filelock_t      leveldb_filelock_t;\n-typedef struct leveldb_filterpolicy_t  leveldb_filterpolicy_t;\n-typedef struct leveldb_iterator_t      leveldb_iterator_t;\n-typedef struct leveldb_logger_t        leveldb_logger_t;\n-typedef struct leveldb_options_t       leveldb_options_t;\n-typedef struct leveldb_randomfile_t    leveldb_randomfile_t;\n-typedef struct leveldb_readoptions_t   leveldb_readoptions_t;\n-typedef struct leveldb_seqfile_t       leveldb_seqfile_t;\n-typedef struct leveldb_snapshot_t      leveldb_snapshot_t;\n-typedef struct leveldb_writablefile_t  leveldb_writablefile_t;\n-typedef struct leveldb_writebatch_t    leveldb_writebatch_t;\n-typedef struct leveldb_writeoptions_t  leveldb_writeoptions_t;\n+typedef struct leveldb_t leveldb_t;\n+typedef struct leveldb_cache_t leveldb_cache_t;\n+typedef struct leveldb_comparator_t leveldb_comparator_t;\n+typedef struct leveldb_env_t leveldb_env_t;\n+typedef struct leveldb_filelock_t leveldb_filelock_t;\n+typedef struct leveldb_filterpolicy_t leveldb_filterpolicy_t;\n+typedef struct leveldb_iterator_t leveldb_iterator_t;\n+typedef struct leveldb_logger_t leveldb_logger_t;\n+typedef struct leveldb_options_t leveldb_options_t;\n+typedef struct leveldb_randomfile_t leveldb_randomfile_t;\n+typedef struct leveldb_readoptions_t leveldb_readoptions_t;\n+typedef struct leveldb_seqfile_t leveldb_seqfile_t;\n+typedef struct leveldb_snapshot_t leveldb_snapshot_t;\n+typedef struct leveldb_writablefile_t leveldb_writablefile_t;\n+typedef struct leveldb_writebatch_t leveldb_writebatch_t;\n+typedef struct leveldb_writeoptions_t leveldb_writeoptions_t;\n \n /* DB operations */\n \n-extern leveldb_t* leveldb_open(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr);\n+LEVELDB_EXPORT leveldb_t* leveldb_open(const leveldb_options_t* options,\n+                                       const char* name, char** errptr);\n \n-extern void leveldb_close(leveldb_t* db);\n+LEVELDB_EXPORT void leveldb_close(leveldb_t* db);\n \n-extern void leveldb_put(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    const char* key, size_t keylen,\n-    const char* val, size_t vallen,\n-    char** errptr);\n+LEVELDB_EXPORT void leveldb_put(leveldb_t* db,\n+                                const leveldb_writeoptions_t* options,\n+                                const char* key, size_t keylen, const char* val,\n+                                size_t vallen, char** errptr);\n \n-extern void leveldb_delete(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    const char* key, size_t keylen,\n-    char** errptr);\n+LEVELDB_EXPORT void leveldb_delete(leveldb_t* db,\n+                                   const leveldb_writeoptions_t* options,\n+                                   const char* key, size_t keylen,\n+                                   char** errptr);\n \n-extern void leveldb_write(\n-    leveldb_t* db,\n-    const leveldb_writeoptions_t* options,\n-    leveldb_writebatch_t* batch,\n-    char** errptr);\n+LEVELDB_EXPORT void leveldb_write(leveldb_t* db,\n+                                  const leveldb_writeoptions_t* options,\n+                                  leveldb_writebatch_t* batch, char** errptr);\n \n /* Returns NULL if not found.  A malloc()ed array otherwise.\n    Stores the length of the array in *vallen. */\n-extern char* leveldb_get(\n-    leveldb_t* db,\n-    const leveldb_readoptions_t* options,\n-    const char* key, size_t keylen,\n-    size_t* vallen,\n-    char** errptr);\n+LEVELDB_EXPORT char* leveldb_get(leveldb_t* db,\n+                                 const leveldb_readoptions_t* options,\n+                                 const char* key, size_t keylen, size_t* vallen,\n+                                 char** errptr);\n \n-extern leveldb_iterator_t* leveldb_create_iterator(\n-    leveldb_t* db,\n-    const leveldb_readoptions_t* options);\n+LEVELDB_EXPORT leveldb_iterator_t* leveldb_create_iterator(\n+    leveldb_t* db, const leveldb_readoptions_t* options);\n \n-extern const leveldb_snapshot_t* leveldb_create_snapshot(\n-    leveldb_t* db);\n+LEVELDB_EXPORT const leveldb_snapshot_t* leveldb_create_snapshot(leveldb_t* db);\n \n-extern void leveldb_release_snapshot(\n-    leveldb_t* db,\n-    const leveldb_snapshot_t* snapshot);\n+LEVELDB_EXPORT void leveldb_release_snapshot(\n+    leveldb_t* db, const leveldb_snapshot_t* snapshot);\n \n /* Returns NULL if property name is unknown.\n    Else returns a pointer to a malloc()-ed null-terminated value. */\n-extern char* leveldb_property_value(\n-    leveldb_t* db,\n-    const char* propname);\n-\n-extern void leveldb_approximate_sizes(\n-    leveldb_t* db,\n-    int num_ranges,\n-    const char* const* range_start_key, const size_t* range_start_key_len,\n-    const char* const* range_limit_key, const size_t* range_limit_key_len,\n-    uint64_t* sizes);\n-\n-extern void leveldb_compact_range(\n-    leveldb_t* db,\n-    const char* start_key, size_t start_key_len,\n-    const char* limit_key, size_t limit_key_len);\n+LEVELDB_EXPORT char* leveldb_property_value(leveldb_t* db,\n+                                            const char* propname);\n+\n+LEVELDB_EXPORT void leveldb_approximate_sizes(\n+    leveldb_t* db, int num_ranges, const char* const* range_start_key,\n+    const size_t* range_start_key_len, const char* const* range_limit_key,\n+    const size_t* range_limit_key_len, uint64_t* sizes);\n+\n+LEVELDB_EXPORT void leveldb_compact_range(leveldb_t* db, const char* start_key,\n+                                          size_t start_key_len,\n+                                          const char* limit_key,\n+                                          size_t limit_key_len);\n \n /* Management operations */\n \n-extern void leveldb_destroy_db(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr);\n+LEVELDB_EXPORT void leveldb_destroy_db(const leveldb_options_t* options,\n+                                       const char* name, char** errptr);\n \n-extern void leveldb_repair_db(\n-    const leveldb_options_t* options,\n-    const char* name,\n-    char** errptr);\n+LEVELDB_EXPORT void leveldb_repair_db(const leveldb_options_t* options,\n+                                      const char* name, char** errptr);\n \n /* Iterator */\n \n-extern void leveldb_iter_destroy(leveldb_iterator_t*);\n-extern unsigned char leveldb_iter_valid(const leveldb_iterator_t*);\n-extern void leveldb_iter_seek_to_first(leveldb_iterator_t*);\n-extern void leveldb_iter_seek_to_last(leveldb_iterator_t*);\n-extern void leveldb_iter_seek(leveldb_iterator_t*, const char* k, size_t klen);\n-extern void leveldb_iter_next(leveldb_iterator_t*);\n-extern void leveldb_iter_prev(leveldb_iterator_t*);\n-extern const char* leveldb_iter_key(const leveldb_iterator_t*, size_t* klen);\n-extern const char* leveldb_iter_value(const leveldb_iterator_t*, size_t* vlen);\n-extern void leveldb_iter_get_error(const leveldb_iterator_t*, char** errptr);\n+LEVELDB_EXPORT void leveldb_iter_destroy(leveldb_iterator_t*);\n+LEVELDB_EXPORT uint8_t leveldb_iter_valid(const leveldb_iterator_t*);\n+LEVELDB_EXPORT void leveldb_iter_seek_to_first(leveldb_iterator_t*);\n+LEVELDB_EXPORT void leveldb_iter_seek_to_last(leveldb_iterator_t*);\n+LEVELDB_EXPORT void leveldb_iter_seek(leveldb_iterator_t*, const char* k,\n+                                      size_t klen);\n+LEVELDB_EXPORT void leveldb_iter_next(leveldb_iterator_t*);\n+LEVELDB_EXPORT void leveldb_iter_prev(leveldb_iterator_t*);\n+LEVELDB_EXPORT const char* leveldb_iter_key(const leveldb_iterator_t*,\n+                                            size_t* klen);\n+LEVELDB_EXPORT const char* leveldb_iter_value(const leveldb_iterator_t*,\n+                                              size_t* vlen);\n+LEVELDB_EXPORT void leveldb_iter_get_error(const leveldb_iterator_t*,\n+                                           char** errptr);\n \n /* Write batch */\n \n-extern leveldb_writebatch_t* leveldb_writebatch_create();\n-extern void leveldb_writebatch_destroy(leveldb_writebatch_t*);\n-extern void leveldb_writebatch_clear(leveldb_writebatch_t*);\n-extern void leveldb_writebatch_put(\n-    leveldb_writebatch_t*,\n-    const char* key, size_t klen,\n-    const char* val, size_t vlen);\n-extern void leveldb_writebatch_delete(\n-    leveldb_writebatch_t*,\n-    const char* key, size_t klen);\n-extern void leveldb_writebatch_iterate(\n-    leveldb_writebatch_t*,\n-    void* state,\n+LEVELDB_EXPORT leveldb_writebatch_t* leveldb_writebatch_create(void);\n+LEVELDB_EXPORT void leveldb_writebatch_destroy(leveldb_writebatch_t*);\n+LEVELDB_EXPORT void leveldb_writebatch_clear(leveldb_writebatch_t*);\n+LEVELDB_EXPORT void leveldb_writebatch_put(leveldb_writebatch_t*,\n+                                           const char* key, size_t klen,\n+                                           const char* val, size_t vlen);\n+LEVELDB_EXPORT void leveldb_writebatch_delete(leveldb_writebatch_t*,\n+                                              const char* key, size_t klen);\n+LEVELDB_EXPORT void leveldb_writebatch_iterate(\n+    const leveldb_writebatch_t*, void* state,\n     void (*put)(void*, const char* k, size_t klen, const char* v, size_t vlen),\n     void (*deleted)(void*, const char* k, size_t klen));\n+LEVELDB_EXPORT void leveldb_writebatch_append(\n+    leveldb_writebatch_t* destination, const leveldb_writebatch_t* source);\n \n /* Options */\n \n-extern leveldb_options_t* leveldb_options_create();\n-extern void leveldb_options_destroy(leveldb_options_t*);\n-extern void leveldb_options_set_comparator(\n-    leveldb_options_t*,\n-    leveldb_comparator_t*);\n-extern void leveldb_options_set_filter_policy(\n-    leveldb_options_t*,\n-    leveldb_filterpolicy_t*);\n-extern void leveldb_options_set_create_if_missing(\n-    leveldb_options_t*, unsigned char);\n-extern void leveldb_options_set_error_if_exists(\n-    leveldb_options_t*, unsigned char);\n-extern void leveldb_options_set_paranoid_checks(\n-    leveldb_options_t*, unsigned char);\n-extern void leveldb_options_set_env(leveldb_options_t*, leveldb_env_t*);\n-extern void leveldb_options_set_info_log(leveldb_options_t*, leveldb_logger_t*);\n-extern void leveldb_options_set_write_buffer_size(leveldb_options_t*, size_t);\n-extern void leveldb_options_set_max_open_files(leveldb_options_t*, int);\n-extern void leveldb_options_set_cache(leveldb_options_t*, leveldb_cache_t*);\n-extern void leveldb_options_set_block_size(leveldb_options_t*, size_t);\n-extern void leveldb_options_set_block_restart_interval(leveldb_options_t*, int);\n-\n-enum {\n-  leveldb_no_compression = 0,\n-  leveldb_snappy_compression = 1\n-};\n-extern void leveldb_options_set_compression(leveldb_options_t*, int);\n+LEVELDB_EXPORT leveldb_options_t* leveldb_options_create(void);\n+LEVELDB_EXPORT void leveldb_options_destroy(leveldb_options_t*);\n+LEVELDB_EXPORT void leveldb_options_set_comparator(leveldb_options_t*,\n+                                                   leveldb_comparator_t*);\n+LEVELDB_EXPORT void leveldb_options_set_filter_policy(leveldb_options_t*,\n+                                                      leveldb_filterpolicy_t*);\n+LEVELDB_EXPORT void leveldb_options_set_create_if_missing(leveldb_options_t*,\n+                                                          uint8_t);\n+LEVELDB_EXPORT void leveldb_options_set_error_if_exists(leveldb_options_t*,\n+                                                        uint8_t);\n+LEVELDB_EXPORT void leveldb_options_set_paranoid_checks(leveldb_options_t*,\n+                                                        uint8_t);\n+LEVELDB_EXPORT void leveldb_options_set_env(leveldb_options_t*, leveldb_env_t*);\n+LEVELDB_EXPORT void leveldb_options_set_info_log(leveldb_options_t*,\n+                                                 leveldb_logger_t*);\n+LEVELDB_EXPORT void leveldb_options_set_write_buffer_size(leveldb_options_t*,\n+                                                          size_t);\n+LEVELDB_EXPORT void leveldb_options_set_max_open_files(leveldb_options_t*, int);\n+LEVELDB_EXPORT void leveldb_options_set_cache(leveldb_options_t*,\n+                                              leveldb_cache_t*);\n+LEVELDB_EXPORT void leveldb_options_set_block_size(leveldb_options_t*, size_t);\n+LEVELDB_EXPORT void leveldb_options_set_block_restart_interval(\n+    leveldb_options_t*, int);\n+LEVELDB_EXPORT void leveldb_options_set_max_file_size(leveldb_options_t*,\n+                                                      size_t);\n+\n+enum { leveldb_no_compression = 0, leveldb_snappy_compression = 1 };\n+LEVELDB_EXPORT void leveldb_options_set_compression(leveldb_options_t*, int);\n \n /* Comparator */\n \n-extern leveldb_comparator_t* leveldb_comparator_create(\n-    void* state,\n-    void (*destructor)(void*),\n-    int (*compare)(\n-        void*,\n-        const char* a, size_t alen,\n-        const char* b, size_t blen),\n+LEVELDB_EXPORT leveldb_comparator_t* leveldb_comparator_create(\n+    void* state, void (*destructor)(void*),\n+    int (*compare)(void*, const char* a, size_t alen, const char* b,\n+                   size_t blen),\n     const char* (*name)(void*));\n-extern void leveldb_comparator_destroy(leveldb_comparator_t*);\n+LEVELDB_EXPORT void leveldb_comparator_destroy(leveldb_comparator_t*);\n \n /* Filter policy */\n \n-extern leveldb_filterpolicy_t* leveldb_filterpolicy_create(\n-    void* state,\n-    void (*destructor)(void*),\n-    char* (*create_filter)(\n-        void*,\n-        const char* const* key_array, const size_t* key_length_array,\n-        int num_keys,\n-        size_t* filter_length),\n-    unsigned char (*key_may_match)(\n-        void*,\n-        const char* key, size_t length,\n-        const char* filter, size_t filter_length),\n+LEVELDB_EXPORT leveldb_filterpolicy_t* leveldb_filterpolicy_create(\n+    void* state, void (*destructor)(void*),\n+    char* (*create_filter)(void*, const char* const* key_array,\n+                           const size_t* key_length_array, int num_keys,\n+                           size_t* filter_length),\n+    uint8_t (*key_may_match)(void*, const char* key, size_t length,\n+                             const char* filter, size_t filter_length),\n     const char* (*name)(void*));\n-extern void leveldb_filterpolicy_destroy(leveldb_filterpolicy_t*);\n+LEVELDB_EXPORT void leveldb_filterpolicy_destroy(leveldb_filterpolicy_t*);\n \n-extern leveldb_filterpolicy_t* leveldb_filterpolicy_create_bloom(\n+LEVELDB_EXPORT leveldb_filterpolicy_t* leveldb_filterpolicy_create_bloom(\n     int bits_per_key);\n \n /* Read options */\n \n-extern leveldb_readoptions_t* leveldb_readoptions_create();\n-extern void leveldb_readoptions_destroy(leveldb_readoptions_t*);\n-extern void leveldb_readoptions_set_verify_checksums(\n-    leveldb_readoptions_t*,\n-    unsigned char);\n-extern void leveldb_readoptions_set_fill_cache(\n-    leveldb_readoptions_t*, unsigned char);\n-extern void leveldb_readoptions_set_snapshot(\n-    leveldb_readoptions_t*,\n-    const leveldb_snapshot_t*);\n+LEVELDB_EXPORT leveldb_readoptions_t* leveldb_readoptions_create(void);\n+LEVELDB_EXPORT void leveldb_readoptions_destroy(leveldb_readoptions_t*);\n+LEVELDB_EXPORT void leveldb_readoptions_set_verify_checksums(\n+    leveldb_readoptions_t*, uint8_t);\n+LEVELDB_EXPORT void leveldb_readoptions_set_fill_cache(leveldb_readoptions_t*,\n+                                                       uint8_t);\n+LEVELDB_EXPORT void leveldb_readoptions_set_snapshot(leveldb_readoptions_t*,\n+                                                     const leveldb_snapshot_t*);\n \n /* Write options */\n \n-extern leveldb_writeoptions_t* leveldb_writeoptions_create();\n-extern void leveldb_writeoptions_destroy(leveldb_writeoptions_t*);\n-extern void leveldb_writeoptions_set_sync(\n-    leveldb_writeoptions_t*, unsigned char);\n+LEVELDB_EXPORT leveldb_writeoptions_t* leveldb_writeoptions_create(void);\n+LEVELDB_EXPORT void leveldb_writeoptions_destroy(leveldb_writeoptions_t*);\n+LEVELDB_EXPORT void leveldb_writeoptions_set_sync(leveldb_writeoptions_t*,\n+                                                  uint8_t);\n \n /* Cache */\n \n-extern leveldb_cache_t* leveldb_cache_create_lru(size_t capacity);\n-extern void leveldb_cache_destroy(leveldb_cache_t* cache);\n+LEVELDB_EXPORT leveldb_cache_t* leveldb_cache_create_lru(size_t capacity);\n+LEVELDB_EXPORT void leveldb_cache_destroy(leveldb_cache_t* cache);\n \n /* Env */\n \n-extern leveldb_env_t* leveldb_create_default_env();\n-extern void leveldb_env_destroy(leveldb_env_t*);\n+LEVELDB_EXPORT leveldb_env_t* leveldb_create_default_env(void);\n+LEVELDB_EXPORT void leveldb_env_destroy(leveldb_env_t*);\n+\n+/* If not NULL, the returned buffer must be released using leveldb_free(). */\n+LEVELDB_EXPORT char* leveldb_env_get_test_directory(leveldb_env_t*);\n \n /* Utility */\n \n@@ -275,16 +255,16 @@ extern void leveldb_env_destroy(leveldb_env_t*);\n    in this file.  Note that in certain cases (typically on Windows), you\n    may need to call this routine instead of free(ptr) to dispose of\n    malloc()-ed memory returned by this library. */\n-extern void leveldb_free(void* ptr);\n+LEVELDB_EXPORT void leveldb_free(void* ptr);\n \n /* Return the major version number for this release. */\n-extern int leveldb_major_version();\n+LEVELDB_EXPORT int leveldb_major_version(void);\n \n /* Return the minor version number for this release. */\n-extern int leveldb_minor_version();\n+LEVELDB_EXPORT int leveldb_minor_version(void);\n \n #ifdef __cplusplus\n-}  /* end extern \"C\" */\n+} /* end extern \"C\" */\n #endif\n \n-#endif  /* STORAGE_LEVELDB_INCLUDE_C_H_ */\n+#endif /* STORAGE_LEVELDB_INCLUDE_C_H_ */"
      },
      {
        "sha": "7d1a221193f6dd9a605991065a31cacfc3ab305d",
        "filename": "src/leveldb/include/leveldb/cache.h",
        "status": "modified",
        "additions": 11,
        "deletions": 10,
        "changes": 21,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/cache.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/cache.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/cache.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -19,26 +19,31 @@\n #define STORAGE_LEVELDB_INCLUDE_CACHE_H_\n \n #include <stdint.h>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/slice.h\"\n \n namespace leveldb {\n \n-class Cache;\n+class LEVELDB_EXPORT Cache;\n \n // Create a new cache with a fixed size capacity.  This implementation\n // of Cache uses a least-recently-used eviction policy.\n-extern Cache* NewLRUCache(size_t capacity);\n+LEVELDB_EXPORT Cache* NewLRUCache(size_t capacity);\n \n-class Cache {\n+class LEVELDB_EXPORT Cache {\n  public:\n-  Cache() { }\n+  Cache() = default;\n+\n+  Cache(const Cache&) = delete;\n+  Cache& operator=(const Cache&) = delete;\n \n   // Destroys all existing entries by calling the \"deleter\"\n   // function that was passed to the constructor.\n   virtual ~Cache();\n \n   // Opaque handle to an entry stored in the cache.\n-  struct Handle { };\n+  struct Handle {};\n \n   // Insert a mapping from key->value into the cache and assign it\n   // the specified charge against the total cache capacity.\n@@ -52,7 +57,7 @@ class Cache {\n   virtual Handle* Insert(const Slice& key, void* value, size_t charge,\n                          void (*deleter)(const Slice& key, void* value)) = 0;\n \n-  // If the cache has no mapping for \"key\", returns NULL.\n+  // If the cache has no mapping for \"key\", returns nullptr.\n   //\n   // Else return a handle that corresponds to the mapping.  The caller\n   // must call this->Release(handle) when the returned mapping is no\n@@ -99,10 +104,6 @@ class Cache {\n \n   struct Rep;\n   Rep* rep_;\n-\n-  // No copying allowed\n-  Cache(const Cache&);\n-  void operator=(const Cache&);\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "a85b51ebd886aeb675423e2cbc7afe2fcb5a1023",
        "filename": "src/leveldb/include/leveldb/comparator.h",
        "status": "modified",
        "additions": 6,
        "deletions": 5,
        "changes": 11,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/comparator.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/comparator.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/comparator.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -7,6 +7,8 @@\n \n #include <string>\n \n+#include \"leveldb/export.h\"\n+\n namespace leveldb {\n \n class Slice;\n@@ -15,7 +17,7 @@ class Slice;\n // used as keys in an sstable or a database.  A Comparator implementation\n // must be thread-safe since leveldb may invoke its methods concurrently\n // from multiple threads.\n-class Comparator {\n+class LEVELDB_EXPORT Comparator {\n  public:\n   virtual ~Comparator();\n \n@@ -43,9 +45,8 @@ class Comparator {\n   // If *start < limit, changes *start to a short string in [start,limit).\n   // Simple comparator implementations may return with *start unchanged,\n   // i.e., an implementation of this method that does nothing is correct.\n-  virtual void FindShortestSeparator(\n-      std::string* start,\n-      const Slice& limit) const = 0;\n+  virtual void FindShortestSeparator(std::string* start,\n+                                     const Slice& limit) const = 0;\n \n   // Changes *key to a short string >= *key.\n   // Simple comparator implementations may return with *key unchanged,\n@@ -56,7 +57,7 @@ class Comparator {\n // Return a builtin comparator that uses lexicographic byte-wise\n // ordering.  The result remains the property of this module and\n // must not be deleted.\n-extern const Comparator* BytewiseComparator();\n+LEVELDB_EXPORT const Comparator* BytewiseComparator();\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "b73014a2214ae67c52d8bc8f1589fe1a76b1eabe",
        "filename": "src/leveldb/include/leveldb/db.h",
        "status": "modified",
        "additions": 31,
        "deletions": 27,
        "changes": 58,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/db.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/db.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/db.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -7,14 +7,16 @@\n \n #include <stdint.h>\n #include <stdio.h>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/iterator.h\"\n #include \"leveldb/options.h\"\n \n namespace leveldb {\n \n-// Update Makefile if you change these\n+// Update CMakeLists.txt if you change these\n static const int kMajorVersion = 1;\n-static const int kMinorVersion = 20;\n+static const int kMinorVersion = 22;\n \n struct Options;\n struct ReadOptions;\n@@ -24,42 +26,44 @@ class WriteBatch;\n // Abstract handle to particular state of a DB.\n // A Snapshot is an immutable object and can therefore be safely\n // accessed from multiple threads without any external synchronization.\n-class Snapshot {\n+class LEVELDB_EXPORT Snapshot {\n  protected:\n   virtual ~Snapshot();\n };\n \n // A range of keys\n-struct Range {\n-  Slice start;          // Included in the range\n-  Slice limit;          // Not included in the range\n+struct LEVELDB_EXPORT Range {\n+  Range() = default;\n+  Range(const Slice& s, const Slice& l) : start(s), limit(l) {}\n \n-  Range() { }\n-  Range(const Slice& s, const Slice& l) : start(s), limit(l) { }\n+  Slice start;  // Included in the range\n+  Slice limit;  // Not included in the range\n };\n \n // A DB is a persistent ordered map from keys to values.\n // A DB is safe for concurrent access from multiple threads without\n // any external synchronization.\n-class DB {\n+class LEVELDB_EXPORT DB {\n  public:\n   // Open the database with the specified \"name\".\n   // Stores a pointer to a heap-allocated database in *dbptr and returns\n   // OK on success.\n-  // Stores NULL in *dbptr and returns a non-OK status on error.\n+  // Stores nullptr in *dbptr and returns a non-OK status on error.\n   // Caller should delete *dbptr when it is no longer needed.\n-  static Status Open(const Options& options,\n-                     const std::string& name,\n+  static Status Open(const Options& options, const std::string& name,\n                      DB** dbptr);\n \n-  DB() { }\n+  DB() = default;\n+\n+  DB(const DB&) = delete;\n+  DB& operator=(const DB&) = delete;\n+\n   virtual ~DB();\n \n   // Set the database entry for \"key\" to \"value\".  Returns OK on success,\n   // and a non-OK status on error.\n   // Note: consider setting options.sync = true.\n-  virtual Status Put(const WriteOptions& options,\n-                     const Slice& key,\n+  virtual Status Put(const WriteOptions& options, const Slice& key,\n                      const Slice& value) = 0;\n \n   // Remove the database entry (if any) for \"key\".  Returns OK on\n@@ -80,8 +84,8 @@ class DB {\n   // a status for which Status::IsNotFound() returns true.\n   //\n   // May return some other Status on an error.\n-  virtual Status Get(const ReadOptions& options,\n-                     const Slice& key, std::string* value) = 0;\n+  virtual Status Get(const ReadOptions& options, const Slice& key,\n+                     std::string* value) = 0;\n \n   // Return a heap-allocated iterator over the contents of the database.\n   // The result of NewIterator() is initially invalid (caller must\n@@ -136,27 +140,27 @@ class DB {\n   // needed to access the data.  This operation should typically only\n   // be invoked by users who understand the underlying implementation.\n   //\n-  // begin==NULL is treated as a key before all keys in the database.\n-  // end==NULL is treated as a key after all keys in the database.\n+  // begin==nullptr is treated as a key before all keys in the database.\n+  // end==nullptr is treated as a key after all keys in the database.\n   // Therefore the following call will compact the entire database:\n-  //    db->CompactRange(NULL, NULL);\n+  //    db->CompactRange(nullptr, nullptr);\n   virtual void CompactRange(const Slice* begin, const Slice* end) = 0;\n-\n- private:\n-  // No copying allowed\n-  DB(const DB&);\n-  void operator=(const DB&);\n };\n \n // Destroy the contents of the specified database.\n // Be very careful using this method.\n-Status DestroyDB(const std::string& name, const Options& options);\n+//\n+// Note: For backwards compatibility, if DestroyDB is unable to list the\n+// database files, Status::OK() will still be returned masking this failure.\n+LEVELDB_EXPORT Status DestroyDB(const std::string& name,\n+                                const Options& options);\n \n // If a DB cannot be opened, you may attempt to call this method to\n // resurrect as much of the contents of the database as possible.\n // Some data may be lost, so be careful when calling this function\n // on a database that contains important information.\n-Status RepairDB(const std::string& dbname, const Options& options);\n+LEVELDB_EXPORT Status RepairDB(const std::string& dbname,\n+                               const Options& options);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "a58bc6b36c16d764dd3738d49078c648d7e1003d",
        "filename": "src/leveldb/include/leveldb/dumpfile.h",
        "status": "modified",
        "additions": 4,
        "deletions": 1,
        "changes": 5,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/dumpfile.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/dumpfile.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/dumpfile.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -6,7 +6,9 @@\n #define STORAGE_LEVELDB_INCLUDE_DUMPFILE_H_\n \n #include <string>\n+\n #include \"leveldb/env.h\"\n+#include \"leveldb/export.h\"\n #include \"leveldb/status.h\"\n \n namespace leveldb {\n@@ -18,7 +20,8 @@ namespace leveldb {\n //\n // Returns a non-OK result if fname does not name a leveldb storage\n // file, or if the file cannot be read.\n-Status DumpFile(Env* env, const std::string& fname, WritableFile* dst);\n+LEVELDB_EXPORT Status DumpFile(Env* env, const std::string& fname,\n+                               WritableFile* dst);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "96c21b3966c4c35a6012450474f12868dc4e006b",
        "filename": "src/leveldb/include/leveldb/env.h",
        "status": "modified",
        "additions": 128,
        "deletions": 92,
        "changes": 220,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/env.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/env.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/env.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -13,12 +13,36 @@\n #ifndef STORAGE_LEVELDB_INCLUDE_ENV_H_\n #define STORAGE_LEVELDB_INCLUDE_ENV_H_\n \n-#include <string>\n-#include <vector>\n #include <stdarg.h>\n #include <stdint.h>\n+\n+#include <string>\n+#include <vector>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/status.h\"\n \n+#if defined(_WIN32)\n+// The leveldb::Env class below contains a DeleteFile method.\n+// At the same time, <windows.h>, a fairly popular header\n+// file for Windows applications, defines a DeleteFile macro.\n+//\n+// Without any intervention on our part, the result of this\n+// unfortunate coincidence is that the name of the\n+// leveldb::Env::DeleteFile method seen by the compiler depends on\n+// whether <windows.h> was included before or after the LevelDB\n+// headers.\n+//\n+// To avoid headaches, we undefined DeleteFile (if defined) and\n+// redefine it at the bottom of this file. This way <windows.h>\n+// can be included before this file (or not at all) and the\n+// exported method will always be leveldb::Env::DeleteFile.\n+#if defined(DeleteFile)\n+#undef DeleteFile\n+#define LEVELDB_DELETEFILE_UNDEFINED\n+#endif  // defined(DeleteFile)\n+#endif  // defined(_WIN32)\n+\n namespace leveldb {\n \n class FileLock;\n@@ -28,9 +52,13 @@ class SequentialFile;\n class Slice;\n class WritableFile;\n \n-class Env {\n+class LEVELDB_EXPORT Env {\n  public:\n-  Env() { }\n+  Env() = default;\n+\n+  Env(const Env&) = delete;\n+  Env& operator=(const Env&) = delete;\n+\n   virtual ~Env();\n \n   // Return a default environment suitable for the current operating\n@@ -40,20 +68,22 @@ class Env {\n   // The result of Default() belongs to leveldb and must never be deleted.\n   static Env* Default();\n \n-  // Create a brand new sequentially-readable file with the specified name.\n+  // Create an object that sequentially reads the file with the specified name.\n   // On success, stores a pointer to the new file in *result and returns OK.\n-  // On failure stores NULL in *result and returns non-OK.  If the file does\n-  // not exist, returns a non-OK status.\n+  // On failure stores nullptr in *result and returns non-OK.  If the file does\n+  // not exist, returns a non-OK status.  Implementations should return a\n+  // NotFound status when the file does not exist.\n   //\n   // The returned file will only be accessed by one thread at a time.\n   virtual Status NewSequentialFile(const std::string& fname,\n                                    SequentialFile** result) = 0;\n \n-  // Create a brand new random access read-only file with the\n+  // Create an object supporting random-access reads from the file with the\n   // specified name.  On success, stores a pointer to the new file in\n-  // *result and returns OK.  On failure stores NULL in *result and\n+  // *result and returns OK.  On failure stores nullptr in *result and\n   // returns non-OK.  If the file does not exist, returns a non-OK\n-  // status.\n+  // status.  Implementations should return a NotFound status when the file does\n+  // not exist.\n   //\n   // The returned file may be concurrently accessed by multiple threads.\n   virtual Status NewRandomAccessFile(const std::string& fname,\n@@ -62,7 +92,7 @@ class Env {\n   // Create an object that writes to a new file with the specified\n   // name.  Deletes any existing file with the same name and creates a\n   // new file.  On success, stores a pointer to the new file in\n-  // *result and returns OK.  On failure stores NULL in *result and\n+  // *result and returns OK.  On failure stores nullptr in *result and\n   // returns non-OK.\n   //\n   // The returned file will only be accessed by one thread at a time.\n@@ -72,7 +102,7 @@ class Env {\n   // Create an object that either appends to an existing file, or\n   // writes to a new file (if the file does not exist to begin with).\n   // On success, stores a pointer to the new file in *result and\n-  // returns OK.  On failure stores NULL in *result and returns\n+  // returns OK.  On failure stores nullptr in *result and returns\n   // non-OK.\n   //\n   // The returned file will only be accessed by one thread at a time.\n@@ -110,7 +140,7 @@ class Env {\n                             const std::string& target) = 0;\n \n   // Lock the specified file.  Used to prevent concurrent access to\n-  // the same db by multiple processes.  On failure, stores NULL in\n+  // the same db by multiple processes.  On failure, stores nullptr in\n   // *lock and returns non-OK.\n   //\n   // On success, stores a pointer to the object that represents the\n@@ -136,16 +166,14 @@ class Env {\n   // added to the same Env may run concurrently in different threads.\n   // I.e., the caller may not assume that background work items are\n   // serialized.\n-  virtual void Schedule(\n-      void (*function)(void* arg),\n-      void* arg) = 0;\n+  virtual void Schedule(void (*function)(void* arg), void* arg) = 0;\n \n   // Start a new thread, invoking \"function(arg)\" within the new thread.\n   // When \"function(arg)\" returns, the thread will be destroyed.\n   virtual void StartThread(void (*function)(void* arg), void* arg) = 0;\n \n   // *path is set to a temporary directory that can be used for testing. It may\n-  // or many not have just been created. The directory may or may not differ\n+  // or may not have just been created. The directory may or may not differ\n   // between runs of the same process, but subsequent calls will return the\n   // same directory.\n   virtual Status GetTestDirectory(std::string* path) = 0;\n@@ -159,17 +187,16 @@ class Env {\n \n   // Sleep/delay the thread for the prescribed number of micro-seconds.\n   virtual void SleepForMicroseconds(int micros) = 0;\n-\n- private:\n-  // No copying allowed\n-  Env(const Env&);\n-  void operator=(const Env&);\n };\n \n // A file abstraction for reading sequentially through a file\n-class SequentialFile {\n+class LEVELDB_EXPORT SequentialFile {\n  public:\n-  SequentialFile() { }\n+  SequentialFile() = default;\n+\n+  SequentialFile(const SequentialFile&) = delete;\n+  SequentialFile& operator=(const SequentialFile&) = delete;\n+\n   virtual ~SequentialFile();\n \n   // Read up to \"n\" bytes from the file.  \"scratch[0..n-1]\" may be\n@@ -193,17 +220,16 @@ class SequentialFile {\n \n   // Get a name for the file, only for error reporting\n   virtual std::string GetName() const = 0;\n-\n- private:\n-  // No copying allowed\n-  SequentialFile(const SequentialFile&);\n-  void operator=(const SequentialFile&);\n };\n \n // A file abstraction for randomly reading the contents of a file.\n-class RandomAccessFile {\n+class LEVELDB_EXPORT RandomAccessFile {\n  public:\n-  RandomAccessFile() { }\n+  RandomAccessFile() = default;\n+\n+  RandomAccessFile(const RandomAccessFile&) = delete;\n+  RandomAccessFile& operator=(const RandomAccessFile&) = delete;\n+\n   virtual ~RandomAccessFile();\n \n   // Read up to \"n\" bytes from the file starting at \"offset\".\n@@ -220,19 +246,18 @@ class RandomAccessFile {\n \n   // Get a name for the file, only for error reporting\n   virtual std::string GetName() const = 0;\n-\n- private:\n-  // No copying allowed\n-  RandomAccessFile(const RandomAccessFile&);\n-  void operator=(const RandomAccessFile&);\n };\n \n // A file abstraction for sequential writing.  The implementation\n // must provide buffering since callers may append small fragments\n // at a time to the file.\n-class WritableFile {\n+class LEVELDB_EXPORT WritableFile {\n  public:\n-  WritableFile() { }\n+  WritableFile() = default;\n+\n+  WritableFile(const WritableFile&) = delete;\n+  WritableFile& operator=(const WritableFile&) = delete;\n+\n   virtual ~WritableFile();\n \n   virtual Status Append(const Slice& data) = 0;\n@@ -242,119 +267,130 @@ class WritableFile {\n \n   // Get a name for the file, only for error reporting\n   virtual std::string GetName() const = 0;\n-\n- private:\n-  // No copying allowed\n-  WritableFile(const WritableFile&);\n-  void operator=(const WritableFile&);\n };\n \n // An interface for writing log messages.\n-class Logger {\n+class LEVELDB_EXPORT Logger {\n  public:\n-  Logger() { }\n+  Logger() = default;\n+\n+  Logger(const Logger&) = delete;\n+  Logger& operator=(const Logger&) = delete;\n+\n   virtual ~Logger();\n \n   // Write an entry to the log file with the specified format.\n   virtual void Logv(const char* format, va_list ap) = 0;\n-\n- private:\n-  // No copying allowed\n-  Logger(const Logger&);\n-  void operator=(const Logger&);\n };\n \n-\n // Identifies a locked file.\n-class FileLock {\n+class LEVELDB_EXPORT FileLock {\n  public:\n-  FileLock() { }\n+  FileLock() = default;\n+\n+  FileLock(const FileLock&) = delete;\n+  FileLock& operator=(const FileLock&) = delete;\n+\n   virtual ~FileLock();\n- private:\n-  // No copying allowed\n-  FileLock(const FileLock&);\n-  void operator=(const FileLock&);\n };\n \n-// Log the specified data to *info_log if info_log is non-NULL.\n-extern void Log(Logger* info_log, const char* format, ...)\n-#   if defined(__GNUC__) || defined(__clang__)\n-    __attribute__((__format__ (__printf__, 2, 3)))\n-#   endif\n+// Log the specified data to *info_log if info_log is non-null.\n+void Log(Logger* info_log, const char* format, ...)\n+#if defined(__GNUC__) || defined(__clang__)\n+    __attribute__((__format__(__printf__, 2, 3)))\n+#endif\n     ;\n \n // A utility routine: write \"data\" to the named file.\n-extern Status WriteStringToFile(Env* env, const Slice& data,\n-                                const std::string& fname);\n+LEVELDB_EXPORT Status WriteStringToFile(Env* env, const Slice& data,\n+                                        const std::string& fname);\n \n // A utility routine: read contents of named file into *data\n-extern Status ReadFileToString(Env* env, const std::string& fname,\n-                               std::string* data);\n+LEVELDB_EXPORT Status ReadFileToString(Env* env, const std::string& fname,\n+                                       std::string* data);\n \n // An implementation of Env that forwards all calls to another Env.\n // May be useful to clients who wish to override just part of the\n // functionality of another Env.\n-class EnvWrapper : public Env {\n+class LEVELDB_EXPORT EnvWrapper : public Env {\n  public:\n-  // Initialize an EnvWrapper that delegates all calls to *t\n-  explicit EnvWrapper(Env* t) : target_(t) { }\n+  // Initialize an EnvWrapper that delegates all calls to *t.\n+  explicit EnvWrapper(Env* t) : target_(t) {}\n   virtual ~EnvWrapper();\n \n-  // Return the target to which this Env forwards all calls\n+  // Return the target to which this Env forwards all calls.\n   Env* target() const { return target_; }\n \n-  // The following text is boilerplate that forwards all methods to target()\n-  Status NewSequentialFile(const std::string& f, SequentialFile** r) {\n+  // The following text is boilerplate that forwards all methods to target().\n+  Status NewSequentialFile(const std::string& f, SequentialFile** r) override {\n     return target_->NewSequentialFile(f, r);\n   }\n-  Status NewRandomAccessFile(const std::string& f, RandomAccessFile** r) {\n+  Status NewRandomAccessFile(const std::string& f,\n+                             RandomAccessFile** r) override {\n     return target_->NewRandomAccessFile(f, r);\n   }\n-  Status NewWritableFile(const std::string& f, WritableFile** r) {\n+  Status NewWritableFile(const std::string& f, WritableFile** r) override {\n     return target_->NewWritableFile(f, r);\n   }\n-  Status NewAppendableFile(const std::string& f, WritableFile** r) {\n+  Status NewAppendableFile(const std::string& f, WritableFile** r) override {\n     return target_->NewAppendableFile(f, r);\n   }\n-  bool FileExists(const std::string& f) { return target_->FileExists(f); }\n-  Status GetChildren(const std::string& dir, std::vector<std::string>* r) {\n+  bool FileExists(const std::string& f) override {\n+    return target_->FileExists(f);\n+  }\n+  Status GetChildren(const std::string& dir,\n+                     std::vector<std::string>* r) override {\n     return target_->GetChildren(dir, r);\n   }\n-  Status DeleteFile(const std::string& f) { return target_->DeleteFile(f); }\n-  Status CreateDir(const std::string& d) { return target_->CreateDir(d); }\n-  Status DeleteDir(const std::string& d) { return target_->DeleteDir(d); }\n-  Status GetFileSize(const std::string& f, uint64_t* s) {\n+  Status DeleteFile(const std::string& f) override {\n+    return target_->DeleteFile(f);\n+  }\n+  Status CreateDir(const std::string& d) override {\n+    return target_->CreateDir(d);\n+  }\n+  Status DeleteDir(const std::string& d) override {\n+    return target_->DeleteDir(d);\n+  }\n+  Status GetFileSize(const std::string& f, uint64_t* s) override {\n     return target_->GetFileSize(f, s);\n   }\n-  Status RenameFile(const std::string& s, const std::string& t) {\n+  Status RenameFile(const std::string& s, const std::string& t) override {\n     return target_->RenameFile(s, t);\n   }\n-  Status LockFile(const std::string& f, FileLock** l) {\n+  Status LockFile(const std::string& f, FileLock** l) override {\n     return target_->LockFile(f, l);\n   }\n-  Status UnlockFile(FileLock* l) { return target_->UnlockFile(l); }\n-  void Schedule(void (*f)(void*), void* a) {\n+  Status UnlockFile(FileLock* l) override { return target_->UnlockFile(l); }\n+  void Schedule(void (*f)(void*), void* a) override {\n     return target_->Schedule(f, a);\n   }\n-  void StartThread(void (*f)(void*), void* a) {\n+  void StartThread(void (*f)(void*), void* a) override {\n     return target_->StartThread(f, a);\n   }\n-  virtual Status GetTestDirectory(std::string* path) {\n+  Status GetTestDirectory(std::string* path) override {\n     return target_->GetTestDirectory(path);\n   }\n-  virtual Status NewLogger(const std::string& fname, Logger** result) {\n+  Status NewLogger(const std::string& fname, Logger** result) override {\n     return target_->NewLogger(fname, result);\n   }\n-  uint64_t NowMicros() {\n-    return target_->NowMicros();\n-  }\n-  void SleepForMicroseconds(int micros) {\n+  uint64_t NowMicros() override { return target_->NowMicros(); }\n+  void SleepForMicroseconds(int micros) override {\n     target_->SleepForMicroseconds(micros);\n   }\n+\n  private:\n   Env* target_;\n };\n \n }  // namespace leveldb\n \n+// Redefine DeleteFile if necessary.\n+#if defined(_WIN32) && defined(LEVELDB_DELETEFILE_UNDEFINED)\n+#if defined(UNICODE)\n+#define DeleteFile DeleteFileW\n+#else\n+#define DeleteFile DeleteFileA\n+#endif  // defined(UNICODE)\n+#endif  // defined(_WIN32) && defined(LEVELDB_DELETEFILE_UNDEFINED)\n+\n #endif  // STORAGE_LEVELDB_INCLUDE_ENV_H_"
      },
      {
        "sha": "6ba9b183da49e96603aec7d8c4e6b01442ff3c2a",
        "filename": "src/leveldb/include/leveldb/export.h",
        "status": "added",
        "additions": 33,
        "deletions": 0,
        "changes": 33,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/export.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/export.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/export.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -0,0 +1,33 @@\n+// Copyright (c) 2017 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef STORAGE_LEVELDB_INCLUDE_EXPORT_H_\n+#define STORAGE_LEVELDB_INCLUDE_EXPORT_H_\n+\n+#if !defined(LEVELDB_EXPORT)\n+\n+#if defined(LEVELDB_SHARED_LIBRARY)\n+#if defined(_WIN32)\n+\n+#if defined(LEVELDB_COMPILE_LIBRARY)\n+#define LEVELDB_EXPORT __declspec(dllexport)\n+#else\n+#define LEVELDB_EXPORT __declspec(dllimport)\n+#endif  // defined(LEVELDB_COMPILE_LIBRARY)\n+\n+#else  // defined(_WIN32)\n+#if defined(LEVELDB_COMPILE_LIBRARY)\n+#define LEVELDB_EXPORT __attribute__((visibility(\"default\")))\n+#else\n+#define LEVELDB_EXPORT\n+#endif\n+#endif  // defined(_WIN32)\n+\n+#else  // defined(LEVELDB_SHARED_LIBRARY)\n+#define LEVELDB_EXPORT\n+#endif\n+\n+#endif  // !defined(LEVELDB_EXPORT)\n+\n+#endif  // STORAGE_LEVELDB_INCLUDE_EXPORT_H_"
      },
      {
        "sha": "49c8eda7768ad342d6d53054cd6595ceaf355b73",
        "filename": "src/leveldb/include/leveldb/filter_policy.h",
        "status": "modified",
        "additions": 7,
        "deletions": 5,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/filter_policy.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/filter_policy.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/filter_policy.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -18,11 +18,13 @@\n \n #include <string>\n \n+#include \"leveldb/export.h\"\n+\n namespace leveldb {\n \n class Slice;\n \n-class FilterPolicy {\n+class LEVELDB_EXPORT FilterPolicy {\n  public:\n   virtual ~FilterPolicy();\n \n@@ -38,8 +40,8 @@ class FilterPolicy {\n   //\n   // Warning: do not change the initial contents of *dst.  Instead,\n   // append the newly constructed filter to *dst.\n-  virtual void CreateFilter(const Slice* keys, int n, std::string* dst)\n-      const = 0;\n+  virtual void CreateFilter(const Slice* keys, int n,\n+                            std::string* dst) const = 0;\n \n   // \"filter\" contains the data appended by a preceding call to\n   // CreateFilter() on this class.  This method must return true if\n@@ -63,8 +65,8 @@ class FilterPolicy {\n // ignores trailing spaces, it would be incorrect to use a\n // FilterPolicy (like NewBloomFilterPolicy) that does not ignore\n // trailing spaces in keys.\n-extern const FilterPolicy* NewBloomFilterPolicy(int bits_per_key);\n+LEVELDB_EXPORT const FilterPolicy* NewBloomFilterPolicy(int bits_per_key);\n \n-}\n+}  // namespace leveldb\n \n #endif  // STORAGE_LEVELDB_INCLUDE_FILTER_POLICY_H_"
      },
      {
        "sha": "bb9a5df8f54a798654b82fdd2bd0bae61620eb61",
        "filename": "src/leveldb/include/leveldb/iterator.h",
        "status": "modified",
        "additions": 23,
        "deletions": 11,
        "changes": 34,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/iterator.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/iterator.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/iterator.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -15,14 +15,19 @@\n #ifndef STORAGE_LEVELDB_INCLUDE_ITERATOR_H_\n #define STORAGE_LEVELDB_INCLUDE_ITERATOR_H_\n \n+#include \"leveldb/export.h\"\n #include \"leveldb/slice.h\"\n #include \"leveldb/status.h\"\n \n namespace leveldb {\n \n-class Iterator {\n+class LEVELDB_EXPORT Iterator {\n  public:\n   Iterator();\n+\n+  Iterator(const Iterator&) = delete;\n+  Iterator& operator=(const Iterator&) = delete;\n+\n   virtual ~Iterator();\n \n   // An iterator is either positioned at a key/value pair, or\n@@ -72,28 +77,35 @@ class Iterator {\n   //\n   // Note that unlike all of the preceding methods, this method is\n   // not abstract and therefore clients should not override it.\n-  typedef void (*CleanupFunction)(void* arg1, void* arg2);\n+  using CleanupFunction = void (*)(void* arg1, void* arg2);\n   void RegisterCleanup(CleanupFunction function, void* arg1, void* arg2);\n \n  private:\n-  struct Cleanup {\n+  // Cleanup functions are stored in a single-linked list.\n+  // The list's head node is inlined in the iterator.\n+  struct CleanupNode {\n+    // True if the node is not used. Only head nodes might be unused.\n+    bool IsEmpty() const { return function == nullptr; }\n+    // Invokes the cleanup function.\n+    void Run() {\n+      assert(function != nullptr);\n+      (*function)(arg1, arg2);\n+    }\n+\n+    // The head node is used if the function pointer is not null.\n     CleanupFunction function;\n     void* arg1;\n     void* arg2;\n-    Cleanup* next;\n+    CleanupNode* next;\n   };\n-  Cleanup cleanup_;\n-\n-  // No copying allowed\n-  Iterator(const Iterator&);\n-  void operator=(const Iterator&);\n+  CleanupNode cleanup_head_;\n };\n \n // Return an empty iterator (yields nothing).\n-extern Iterator* NewEmptyIterator();\n+LEVELDB_EXPORT Iterator* NewEmptyIterator();\n \n // Return an empty iterator with the specified status.\n-extern Iterator* NewErrorIterator(const Status& status);\n+LEVELDB_EXPORT Iterator* NewErrorIterator(const Status& status);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "b7487726bcac7929d4c2a591cd1c1c5c06ea4ab0",
        "filename": "src/leveldb/include/leveldb/options.h",
        "status": "modified",
        "additions": 37,
        "deletions": 63,
        "changes": 100,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/options.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/options.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/options.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -7,6 +7,8 @@\n \n #include <stddef.h>\n \n+#include \"leveldb/export.h\"\n+\n namespace leveldb {\n \n class Cache;\n@@ -23,12 +25,15 @@ class Snapshot;\n enum CompressionType {\n   // NOTE: do not change the values of existing entries, as these are\n   // part of the persistent format on disk.\n-  kNoCompression     = 0x0,\n+  kNoCompression = 0x0,\n   kSnappyCompression = 0x1\n };\n \n // Options to control the behavior of a database (passed to DB::Open)\n-struct Options {\n+struct LEVELDB_EXPORT Options {\n+  // Create an Options object with default values for all fields.\n+  Options();\n+\n   // -------------------\n   // Parameters that affect behavior\n \n@@ -41,31 +46,27 @@ struct Options {\n   const Comparator* comparator;\n \n   // If true, the database will be created if it is missing.\n-  // Default: false\n-  bool create_if_missing;\n+  bool create_if_missing = false;\n \n   // If true, an error is raised if the database already exists.\n-  // Default: false\n-  bool error_if_exists;\n+  bool error_if_exists = false;\n \n   // If true, the implementation will do aggressive checking of the\n   // data it is processing and will stop early if it detects any\n   // errors.  This may have unforeseen ramifications: for example, a\n   // corruption of one DB entry may cause a large number of entries to\n   // become unreadable or for the entire DB to become unopenable.\n-  // Default: false\n-  bool paranoid_checks;\n+  bool paranoid_checks = false;\n \n   // Use the specified object to interact with the environment,\n   // e.g. to read/write files, schedule background work, etc.\n   // Default: Env::Default()\n   Env* env;\n \n   // Any internal progress/error information generated by the db will\n-  // be written to info_log if it is non-NULL, or to a file stored\n-  // in the same directory as the DB contents if info_log is NULL.\n-  // Default: NULL\n-  Logger* info_log;\n+  // be written to info_log if it is non-null, or to a file stored\n+  // in the same directory as the DB contents if info_log is null.\n+  Logger* info_log = nullptr;\n \n   // -------------------\n   // Parameters that affect performance\n@@ -78,39 +79,30 @@ struct Options {\n   // so you may wish to adjust this parameter to control memory usage.\n   // Also, a larger write buffer will result in a longer recovery time\n   // the next time the database is opened.\n-  //\n-  // Default: 4MB\n-  size_t write_buffer_size;\n+  size_t write_buffer_size = 4 * 1024 * 1024;\n \n   // Number of open files that can be used by the DB.  You may need to\n   // increase this if your database has a large working set (budget\n   // one open file per 2MB of working set).\n-  //\n-  // Default: 1000\n-  int max_open_files;\n+  int max_open_files = 1000;\n \n   // Control over blocks (user data is stored in a set of blocks, and\n   // a block is the unit of reading from disk).\n \n-  // If non-NULL, use the specified cache for blocks.\n-  // If NULL, leveldb will automatically create and use an 8MB internal cache.\n-  // Default: NULL\n-  Cache* block_cache;\n+  // If non-null, use the specified cache for blocks.\n+  // If null, leveldb will automatically create and use an 8MB internal cache.\n+  Cache* block_cache = nullptr;\n \n   // Approximate size of user data packed per block.  Note that the\n   // block size specified here corresponds to uncompressed data.  The\n   // actual size of the unit read from disk may be smaller if\n   // compression is enabled.  This parameter can be changed dynamically.\n-  //\n-  // Default: 4K\n-  size_t block_size;\n+  size_t block_size = 4 * 1024;\n \n   // Number of keys between restart points for delta encoding of keys.\n   // This parameter can be changed dynamically.  Most clients should\n   // leave this parameter alone.\n-  //\n-  // Default: 16\n-  int block_restart_interval;\n+  int block_restart_interval = 16;\n \n   // Leveldb will write up to this amount of bytes to a file before\n   // switching to a new one.\n@@ -120,9 +112,7 @@ struct Options {\n   // compactions and hence longer latency/performance hiccups.\n   // Another reason to increase this parameter might be when you are\n   // initially populating a large database.\n-  //\n-  // Default: 2MB\n-  size_t max_file_size;\n+  size_t max_file_size = 2 * 1024 * 1024;\n \n   // Compress blocks using the specified compression algorithm.  This\n   // parameter can be changed dynamically.\n@@ -138,53 +128,43 @@ struct Options {\n   // worth switching to kNoCompression.  Even if the input data is\n   // incompressible, the kSnappyCompression implementation will\n   // efficiently detect that and will switch to uncompressed mode.\n-  CompressionType compression;\n+  CompressionType compression = kSnappyCompression;\n \n   // EXPERIMENTAL: If true, append to existing MANIFEST and log files\n   // when a database is opened.  This can significantly speed up open.\n   //\n   // Default: currently false, but may become true later.\n-  bool reuse_logs;\n+  bool reuse_logs = false;\n \n-  // If non-NULL, use the specified filter policy to reduce disk reads.\n+  // If non-null, use the specified filter policy to reduce disk reads.\n   // Many applications will benefit from passing the result of\n   // NewBloomFilterPolicy() here.\n-  //\n-  // Default: NULL\n-  const FilterPolicy* filter_policy;\n-\n-  // Create an Options object with default values for all fields.\n-  Options();\n+  const FilterPolicy* filter_policy = nullptr;\n };\n \n // Options that control read operations\n-struct ReadOptions {\n+struct LEVELDB_EXPORT ReadOptions {\n+  ReadOptions() = default;\n+\n   // If true, all data read from underlying storage will be\n   // verified against corresponding checksums.\n-  // Default: false\n-  bool verify_checksums;\n+  bool verify_checksums = false;\n \n   // Should the data read for this iteration be cached in memory?\n   // Callers may wish to set this field to false for bulk scans.\n-  // Default: true\n-  bool fill_cache;\n+  bool fill_cache = true;\n \n-  // If \"snapshot\" is non-NULL, read as of the supplied snapshot\n+  // If \"snapshot\" is non-null, read as of the supplied snapshot\n   // (which must belong to the DB that is being read and which must\n-  // not have been released).  If \"snapshot\" is NULL, use an implicit\n+  // not have been released).  If \"snapshot\" is null, use an implicit\n   // snapshot of the state at the beginning of this read operation.\n-  // Default: NULL\n-  const Snapshot* snapshot;\n-\n-  ReadOptions()\n-      : verify_checksums(false),\n-        fill_cache(true),\n-        snapshot(NULL) {\n-  }\n+  const Snapshot* snapshot = nullptr;\n };\n \n // Options that control write operations\n-struct WriteOptions {\n+struct LEVELDB_EXPORT WriteOptions {\n+  WriteOptions() = default;\n+\n   // If true, the write will be flushed from the operating system\n   // buffer cache (by calling WritableFile::Sync()) before the write\n   // is considered complete.  If this flag is true, writes will be\n@@ -199,13 +179,7 @@ struct WriteOptions {\n   // crash semantics as the \"write()\" system call.  A DB write\n   // with sync==true has similar crash semantics to a \"write()\"\n   // system call followed by \"fsync()\".\n-  //\n-  // Default: false\n-  bool sync;\n-\n-  WriteOptions()\n-      : sync(false) {\n-  }\n+  bool sync = false;\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "2df417dc3135865ee267ce30d72fad6e8bf00908",
        "filename": "src/leveldb/include/leveldb/slice.h",
        "status": "modified",
        "additions": 22,
        "deletions": 16,
        "changes": 38,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/slice.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/slice.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/slice.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -18,23 +18,30 @@\n #include <assert.h>\n #include <stddef.h>\n #include <string.h>\n+\n #include <string>\n \n+#include \"leveldb/export.h\"\n+\n namespace leveldb {\n \n-class Slice {\n+class LEVELDB_EXPORT Slice {\n  public:\n   // Create an empty slice.\n-  Slice() : data_(\"\"), size_(0) { }\n+  Slice() : data_(\"\"), size_(0) {}\n \n   // Create a slice that refers to d[0,n-1].\n-  Slice(const char* d, size_t n) : data_(d), size_(n) { }\n+  Slice(const char* d, size_t n) : data_(d), size_(n) {}\n \n   // Create a slice that refers to the contents of \"s\"\n-  Slice(const std::string& s) : data_(s.data()), size_(s.size()) { }\n+  Slice(const std::string& s) : data_(s.data()), size_(s.size()) {}\n \n   // Create a slice that refers to s[0,strlen(s)-1]\n-  Slice(const char* s) : data_(s), size_(strlen(s)) { }\n+  Slice(const char* s) : data_(s), size_(strlen(s)) {}\n+\n+  // Intentionally copyable.\n+  Slice(const Slice&) = default;\n+  Slice& operator=(const Slice&) = default;\n \n   // Return a pointer to the beginning of the referenced data\n   const char* data() const { return data_; }\n@@ -53,7 +60,10 @@ class Slice {\n   }\n \n   // Change this slice to refer to an empty array\n-  void clear() { data_ = \"\"; size_ = 0; }\n+  void clear() {\n+    data_ = \"\";\n+    size_ = 0;\n+  }\n \n   // Drop the first \"n\" bytes from this slice.\n   void remove_prefix(size_t n) {\n@@ -73,37 +83,33 @@ class Slice {\n \n   // Return true iff \"x\" is a prefix of \"*this\"\n   bool starts_with(const Slice& x) const {\n-    return ((size_ >= x.size_) &&\n-            (memcmp(data_, x.data_, x.size_) == 0));\n+    return ((size_ >= x.size_) && (memcmp(data_, x.data_, x.size_) == 0));\n   }\n \n  private:\n   const char* data_;\n   size_t size_;\n-\n-  // Intentionally copyable\n };\n \n inline bool operator==(const Slice& x, const Slice& y) {\n   return ((x.size() == y.size()) &&\n           (memcmp(x.data(), y.data(), x.size()) == 0));\n }\n \n-inline bool operator!=(const Slice& x, const Slice& y) {\n-  return !(x == y);\n-}\n+inline bool operator!=(const Slice& x, const Slice& y) { return !(x == y); }\n \n inline int Slice::compare(const Slice& b) const {\n   const size_t min_len = (size_ < b.size_) ? size_ : b.size_;\n   int r = memcmp(data_, b.data_, min_len);\n   if (r == 0) {\n-    if (size_ < b.size_) r = -1;\n-    else if (size_ > b.size_) r = +1;\n+    if (size_ < b.size_)\n+      r = -1;\n+    else if (size_ > b.size_)\n+      r = +1;\n   }\n   return r;\n }\n \n }  // namespace leveldb\n \n-\n #endif  // STORAGE_LEVELDB_INCLUDE_SLICE_H_"
      },
      {
        "sha": "e3273144e481174cee99c1db73bef9ca6925f46a",
        "filename": "src/leveldb/include/leveldb/status.h",
        "status": "modified",
        "additions": 31,
        "deletions": 21,
        "changes": 52,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/status.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/status.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/status.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -13,20 +13,25 @@\n #ifndef STORAGE_LEVELDB_INCLUDE_STATUS_H_\n #define STORAGE_LEVELDB_INCLUDE_STATUS_H_\n \n+#include <algorithm>\n #include <string>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/slice.h\"\n \n namespace leveldb {\n \n-class Status {\n+class LEVELDB_EXPORT Status {\n  public:\n   // Create a success status.\n-  Status() : state_(NULL) { }\n+  Status() noexcept : state_(nullptr) {}\n   ~Status() { delete[] state_; }\n \n-  // Copy the specified status.\n-  Status(const Status& s);\n-  void operator=(const Status& s);\n+  Status(const Status& rhs);\n+  Status& operator=(const Status& rhs);\n+\n+  Status(Status&& rhs) noexcept : state_(rhs.state_) { rhs.state_ = nullptr; }\n+  Status& operator=(Status&& rhs) noexcept;\n \n   // Return a success status.\n   static Status OK() { return Status(); }\n@@ -49,7 +54,7 @@ class Status {\n   }\n \n   // Returns true iff the status indicates success.\n-  bool ok() const { return (state_ == NULL); }\n+  bool ok() const { return (state_ == nullptr); }\n \n   // Returns true iff the status indicates a NotFound error.\n   bool IsNotFound() const { return code() == kNotFound; }\n@@ -71,13 +76,6 @@ class Status {\n   std::string ToString() const;\n \n  private:\n-  // OK status has a NULL state_.  Otherwise, state_ is a new[] array\n-  // of the following form:\n-  //    state_[0..3] == length of message\n-  //    state_[4]    == code\n-  //    state_[5..]  == message\n-  const char* state_;\n-\n   enum Code {\n     kOk = 0,\n     kNotFound = 1,\n@@ -88,23 +86,35 @@ class Status {\n   };\n \n   Code code() const {\n-    return (state_ == NULL) ? kOk : static_cast<Code>(state_[4]);\n+    return (state_ == nullptr) ? kOk : static_cast<Code>(state_[4]);\n   }\n \n   Status(Code code, const Slice& msg, const Slice& msg2);\n   static const char* CopyState(const char* s);\n+\n+  // OK status has a null state_.  Otherwise, state_ is a new[] array\n+  // of the following form:\n+  //    state_[0..3] == length of message\n+  //    state_[4]    == code\n+  //    state_[5..]  == message\n+  const char* state_;\n };\n \n-inline Status::Status(const Status& s) {\n-  state_ = (s.state_ == NULL) ? NULL : CopyState(s.state_);\n+inline Status::Status(const Status& rhs) {\n+  state_ = (rhs.state_ == nullptr) ? nullptr : CopyState(rhs.state_);\n }\n-inline void Status::operator=(const Status& s) {\n-  // The following condition catches both aliasing (when this == &s),\n-  // and the common case where both s and *this are ok.\n-  if (state_ != s.state_) {\n+inline Status& Status::operator=(const Status& rhs) {\n+  // The following condition catches both aliasing (when this == &rhs),\n+  // and the common case where both rhs and *this are ok.\n+  if (state_ != rhs.state_) {\n     delete[] state_;\n-    state_ = (s.state_ == NULL) ? NULL : CopyState(s.state_);\n+    state_ = (rhs.state_ == nullptr) ? nullptr : CopyState(rhs.state_);\n   }\n+  return *this;\n+}\n+inline Status& Status::operator=(Status&& rhs) noexcept {\n+  std::swap(state_, rhs.state_);\n+  return *this;\n }\n \n }  // namespace leveldb"
      },
      {
        "sha": "25c601311648b40842b268b3dd27e409c45908f4",
        "filename": "src/leveldb/include/leveldb/table.h",
        "status": "modified",
        "additions": 16,
        "deletions": 17,
        "changes": 33,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/table.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/table.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/table.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -6,6 +6,8 @@\n #define STORAGE_LEVELDB_INCLUDE_TABLE_H_\n \n #include <stdint.h>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/iterator.h\"\n \n namespace leveldb {\n@@ -21,7 +23,7 @@ class TableCache;\n // A Table is a sorted map from strings to strings.  Tables are\n // immutable and persistent.  A Table may be safely accessed from\n // multiple threads without external synchronization.\n-class Table {\n+class LEVELDB_EXPORT Table {\n  public:\n   // Attempt to open the table that is stored in bytes [0..file_size)\n   // of \"file\", and read the metadata entries necessary to allow\n@@ -30,15 +32,16 @@ class Table {\n   // If successful, returns ok and sets \"*table\" to the newly opened\n   // table.  The client should delete \"*table\" when no longer needed.\n   // If there was an error while initializing the table, sets \"*table\"\n-  // to NULL and returns a non-ok status.  Does not take ownership of\n+  // to nullptr and returns a non-ok status.  Does not take ownership of\n   // \"*source\", but the client must ensure that \"source\" remains live\n   // for the duration of the returned table's lifetime.\n   //\n   // *file must remain live while this Table is in use.\n-  static Status Open(const Options& options,\n-                     RandomAccessFile* file,\n-                     uint64_t file_size,\n-                     Table** table);\n+  static Status Open(const Options& options, RandomAccessFile* file,\n+                     uint64_t file_size, Table** table);\n+\n+  Table(const Table&) = delete;\n+  Table& operator=(const Table&) = delete;\n \n   ~Table();\n \n@@ -56,28 +59,24 @@ class Table {\n   uint64_t ApproximateOffsetOf(const Slice& key) const;\n \n  private:\n+  friend class TableCache;\n   struct Rep;\n-  Rep* rep_;\n \n-  explicit Table(Rep* rep) { rep_ = rep; }\n   static Iterator* BlockReader(void*, const ReadOptions&, const Slice&);\n \n+  explicit Table(Rep* rep) : rep_(rep) {}\n+\n   // Calls (*handle_result)(arg, ...) with the entry found after a call\n   // to Seek(key).  May not make such a call if filter policy says\n   // that key is not present.\n-  friend class TableCache;\n-  Status InternalGet(\n-      const ReadOptions&, const Slice& key,\n-      void* arg,\n-      void (*handle_result)(void* arg, const Slice& k, const Slice& v));\n-\n+  Status InternalGet(const ReadOptions&, const Slice& key, void* arg,\n+                     void (*handle_result)(void* arg, const Slice& k,\n+                                           const Slice& v));\n \n   void ReadMeta(const Footer& footer);\n   void ReadFilter(const Slice& filter_handle_value);\n \n-  // No copying allowed\n-  Table(const Table&);\n-  void operator=(const Table&);\n+  Rep* const rep_;\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "7d8896bb89c4a0f8ba24bc18314af4a37fde18ac",
        "filename": "src/leveldb/include/leveldb/table_builder.h",
        "status": "modified",
        "additions": 6,
        "deletions": 5,
        "changes": 11,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/table_builder.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/table_builder.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/table_builder.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -14,6 +14,8 @@\n #define STORAGE_LEVELDB_INCLUDE_TABLE_BUILDER_H_\n \n #include <stdint.h>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/options.h\"\n #include \"leveldb/status.h\"\n \n@@ -23,13 +25,16 @@ class BlockBuilder;\n class BlockHandle;\n class WritableFile;\n \n-class TableBuilder {\n+class LEVELDB_EXPORT TableBuilder {\n  public:\n   // Create a builder that will store the contents of the table it is\n   // building in *file.  Does not close the file.  It is up to the\n   // caller to close the file after calling Finish().\n   TableBuilder(const Options& options, WritableFile* file);\n \n+  TableBuilder(const TableBuilder&) = delete;\n+  TableBuilder& operator=(const TableBuilder&) = delete;\n+\n   // REQUIRES: Either Finish() or Abandon() has been called.\n   ~TableBuilder();\n \n@@ -81,10 +86,6 @@ class TableBuilder {\n \n   struct Rep;\n   Rep* rep_;\n-\n-  // No copying allowed\n-  TableBuilder(const TableBuilder&);\n-  void operator=(const TableBuilder&);\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "94d4115fed5a2dccc6450d84d0df53bcac7624e3",
        "filename": "src/leveldb/include/leveldb/write_batch.h",
        "status": "modified",
        "additions": 28,
        "deletions": 9,
        "changes": 37,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/write_batch.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/include/leveldb/write_batch.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/include/leveldb/write_batch.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -22,15 +22,29 @@\n #define STORAGE_LEVELDB_INCLUDE_WRITE_BATCH_H_\n \n #include <string>\n+\n+#include \"leveldb/export.h\"\n #include \"leveldb/status.h\"\n \n namespace leveldb {\n \n class Slice;\n \n-class WriteBatch {\n+class LEVELDB_EXPORT WriteBatch {\n  public:\n+  class LEVELDB_EXPORT Handler {\n+   public:\n+    virtual ~Handler();\n+    virtual void Put(const Slice& key, const Slice& value) = 0;\n+    virtual void Delete(const Slice& key) = 0;\n+  };\n+\n   WriteBatch();\n+\n+  // Intentionally copyable.\n+  WriteBatch(const WriteBatch&) = default;\n+  WriteBatch& operator=(const WriteBatch&) = default;\n+\n   ~WriteBatch();\n \n   // Store the mapping \"key->value\" in the database.\n@@ -42,21 +56,26 @@ class WriteBatch {\n   // Clear all updates buffered in this batch.\n   void Clear();\n \n+  // The size of the database changes caused by this batch.\n+  //\n+  // This number is tied to implementation details, and may change across\n+  // releases. It is intended for LevelDB usage metrics.\n+  size_t ApproximateSize() const;\n+\n+  // Copies the operations in \"source\" to this batch.\n+  //\n+  // This runs in O(source size) time. However, the constant factor is better\n+  // than calling Iterate() over the source batch with a Handler that replicates\n+  // the operations into this batch.\n+  void Append(const WriteBatch& source);\n+\n   // Support for iterating over the contents of a batch.\n-  class Handler {\n-   public:\n-    virtual ~Handler();\n-    virtual void Put(const Slice& key, const Slice& value) = 0;\n-    virtual void Delete(const Slice& key) = 0;\n-  };\n   Status Iterate(Handler* handler) const;\n \n  private:\n   friend class WriteBatchInternal;\n \n   std::string rep_;  // See comment in write_batch.cc for the format of rep_\n-\n-  // Intentionally copyable\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "d50ffeb9d4185de40801404007821f0193ca6a2e",
        "filename": "src/leveldb/issues/issue178_test.cc",
        "status": "modified",
        "additions": 4,
        "deletions": 8,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/issues/issue178_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/issues/issue178_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/issues/issue178_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -3,9 +3,9 @@\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n // Test for issue 178: a manual compaction causes deleted data to reappear.\n+#include <cstdlib>\n #include <iostream>\n #include <sstream>\n-#include <cstdlib>\n \n #include \"leveldb/db.h\"\n #include \"leveldb/write_batch.h\"\n@@ -21,11 +21,9 @@ std::string Key1(int i) {\n   return buf;\n }\n \n-std::string Key2(int i) {\n-  return Key1(i) + \"_xxx\";\n-}\n+std::string Key2(int i) { return Key1(i) + \"_xxx\"; }\n \n-class Issue178 { };\n+class Issue178 {};\n \n TEST(Issue178, Test) {\n   // Get rid of any state from an old run.\n@@ -87,6 +85,4 @@ TEST(Issue178, Test) {\n \n }  // anonymous namespace\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "877b2afc47458147ebc0c8342001f9c8f53f8573",
        "filename": "src/leveldb/issues/issue200_test.cc",
        "status": "modified",
        "additions": 4,
        "deletions": 6,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/issues/issue200_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/issues/issue200_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/issues/issue200_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -11,14 +11,14 @@\n \n namespace leveldb {\n \n-class Issue200 { };\n+class Issue200 {};\n \n TEST(Issue200, Test) {\n   // Get rid of any state from an old run.\n   std::string dbpath = test::TmpDir() + \"/leveldb_issue200_test\";\n   DestroyDB(dbpath, Options());\n \n-  DB *db;\n+  DB* db;\n   Options options;\n   options.create_if_missing = true;\n   ASSERT_OK(DB::Open(options, dbpath, &db));\n@@ -31,7 +31,7 @@ TEST(Issue200, Test) {\n   ASSERT_OK(db->Put(write_options, \"5\", \"f\"));\n \n   ReadOptions read_options;\n-  Iterator *iter = db->NewIterator(read_options);\n+  Iterator* iter = db->NewIterator(read_options);\n \n   // Add an element that should not be reflected in the iterator.\n   ASSERT_OK(db->Put(write_options, \"25\", \"cd\"));\n@@ -54,6 +54,4 @@ TEST(Issue200, Test) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "c5fcbfc6e76492e6fe38bfc3eda6db12476f98a0",
        "filename": "src/leveldb/issues/issue320_test.cc",
        "status": "added",
        "additions": 128,
        "deletions": 0,
        "changes": 128,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/issues/issue320_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/issues/issue320_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/issues/issue320_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -0,0 +1,128 @@\n+// Copyright (c) 2019 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include <cstdint>\n+#include <cstdlib>\n+#include <iostream>\n+#include <memory>\n+#include <string>\n+#include <vector>\n+\n+#include \"leveldb/db.h\"\n+#include \"leveldb/write_batch.h\"\n+#include \"util/testharness.h\"\n+\n+namespace leveldb {\n+\n+namespace {\n+\n+// Creates a random number in the range of [0, max).\n+int GenerateRandomNumber(int max) { return std::rand() % max; }\n+\n+std::string CreateRandomString(int32_t index) {\n+  static const size_t len = 1024;\n+  char bytes[len];\n+  size_t i = 0;\n+  while (i < 8) {\n+    bytes[i] = 'a' + ((index >> (4 * i)) & 0xf);\n+    ++i;\n+  }\n+  while (i < sizeof(bytes)) {\n+    bytes[i] = 'a' + GenerateRandomNumber(26);\n+    ++i;\n+  }\n+  return std::string(bytes, sizeof(bytes));\n+}\n+\n+}  // namespace\n+\n+class Issue320 {};\n+\n+TEST(Issue320, Test) {\n+  std::srand(0);\n+\n+  bool delete_before_put = false;\n+  bool keep_snapshots = true;\n+\n+  std::vector<std::unique_ptr<std::pair<std::string, std::string>>> test_map(\n+      10000);\n+  std::vector<Snapshot const*> snapshots(100, nullptr);\n+\n+  DB* db;\n+  Options options;\n+  options.create_if_missing = true;\n+\n+  std::string dbpath = test::TmpDir() + \"/leveldb_issue320_test\";\n+  ASSERT_OK(DB::Open(options, dbpath, &db));\n+\n+  uint32_t target_size = 10000;\n+  uint32_t num_items = 0;\n+  uint32_t count = 0;\n+  std::string key;\n+  std::string value, old_value;\n+\n+  WriteOptions writeOptions;\n+  ReadOptions readOptions;\n+  while (count < 200000) {\n+    if ((++count % 1000) == 0) {\n+      std::cout << \"count: \" << count << std::endl;\n+    }\n+\n+    int index = GenerateRandomNumber(test_map.size());\n+    WriteBatch batch;\n+\n+    if (test_map[index] == nullptr) {\n+      num_items++;\n+      test_map[index].reset(new std::pair<std::string, std::string>(\n+          CreateRandomString(index), CreateRandomString(index)));\n+      batch.Put(test_map[index]->first, test_map[index]->second);\n+    } else {\n+      ASSERT_OK(db->Get(readOptions, test_map[index]->first, &old_value));\n+      if (old_value != test_map[index]->second) {\n+        std::cout << \"ERROR incorrect value returned by Get\" << std::endl;\n+        std::cout << \"  count=\" << count << std::endl;\n+        std::cout << \"  old value=\" << old_value << std::endl;\n+        std::cout << \"  test_map[index]->second=\" << test_map[index]->second\n+                  << std::endl;\n+        std::cout << \"  test_map[index]->first=\" << test_map[index]->first\n+                  << std::endl;\n+        std::cout << \"  index=\" << index << std::endl;\n+        ASSERT_EQ(old_value, test_map[index]->second);\n+      }\n+\n+      if (num_items >= target_size && GenerateRandomNumber(100) > 30) {\n+        batch.Delete(test_map[index]->first);\n+        test_map[index] = nullptr;\n+        --num_items;\n+      } else {\n+        test_map[index]->second = CreateRandomString(index);\n+        if (delete_before_put) batch.Delete(test_map[index]->first);\n+        batch.Put(test_map[index]->first, test_map[index]->second);\n+      }\n+    }\n+\n+    ASSERT_OK(db->Write(writeOptions, &batch));\n+\n+    if (keep_snapshots && GenerateRandomNumber(10) == 0) {\n+      int i = GenerateRandomNumber(snapshots.size());\n+      if (snapshots[i] != nullptr) {\n+        db->ReleaseSnapshot(snapshots[i]);\n+      }\n+      snapshots[i] = db->GetSnapshot();\n+    }\n+  }\n+\n+  for (Snapshot const* snapshot : snapshots) {\n+    if (snapshot) {\n+      db->ReleaseSnapshot(snapshot);\n+    }\n+  }\n+\n+  delete db;\n+  DestroyDB(dbpath, options);\n+}\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "8b171532e153e072f131152ab03c7e5a2a232e9f",
        "filename": "src/leveldb/port/README.md",
        "status": "renamed",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/README.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/README.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/README.md?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -5,6 +5,6 @@ Code in the rest of the package includes \"port.h\" from this directory.\n \"port.h\" in turn includes a platform specific \"port_<platform>.h\" file\n that provides the platform specific implementation.\n \n-See port_posix.h for an example of what must be provided in a platform\n+See port_stdcxx.h for an example of what must be provided in a platform\n specific header file.\n ",
        "previous_filename": "src/leveldb/port/README"
      },
      {
        "sha": "d79a02230d57fe085949936b26b9a7af413e07b8",
        "filename": "src/leveldb/port/atomic_pointer.h",
        "status": "removed",
        "additions": 0,
        "deletions": 245,
        "changes": 245,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/atomic_pointer.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/atomic_pointer.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/atomic_pointer.h?ref=2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "patch": "@@ -1,245 +0,0 @@\n-// Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-\n-// AtomicPointer provides storage for a lock-free pointer.\n-// Platform-dependent implementation of AtomicPointer:\n-// - If the platform provides a cheap barrier, we use it with raw pointers\n-// - If <atomic> is present (on newer versions of gcc, it is), we use\n-//   a <atomic>-based AtomicPointer.  However we prefer the memory\n-//   barrier based version, because at least on a gcc 4.4 32-bit build\n-//   on linux, we have encountered a buggy <atomic> implementation.\n-//   Also, some <atomic> implementations are much slower than a memory-barrier\n-//   based implementation (~16ns for <atomic> based acquire-load vs. ~1ns for\n-//   a barrier based acquire-load).\n-// This code is based on atomicops-internals-* in Google's perftools:\n-// http://code.google.com/p/google-perftools/source/browse/#svn%2Ftrunk%2Fsrc%2Fbase\n-\n-#ifndef PORT_ATOMIC_POINTER_H_\n-#define PORT_ATOMIC_POINTER_H_\n-\n-#include <stdint.h>\n-#ifdef LEVELDB_ATOMIC_PRESENT\n-#include <atomic>\n-#endif\n-#ifdef OS_WIN\n-#include <windows.h>\n-#endif\n-#ifdef OS_MACOSX\n-#include <libkern/OSAtomic.h>\n-#endif\n-\n-#if defined(_M_X64) || defined(__x86_64__)\n-#define ARCH_CPU_X86_FAMILY 1\n-#elif defined(_M_IX86) || defined(__i386__) || defined(__i386)\n-#define ARCH_CPU_X86_FAMILY 1\n-#elif defined(__ARMEL__)\n-#define ARCH_CPU_ARM_FAMILY 1\n-#elif defined(__aarch64__)\n-#define ARCH_CPU_ARM64_FAMILY 1\n-#elif defined(__ppc__) || defined(__powerpc__) || defined(__powerpc64__)\n-#define ARCH_CPU_PPC_FAMILY 1\n-#elif defined(__mips__)\n-#define ARCH_CPU_MIPS_FAMILY 1\n-#endif\n-\n-namespace leveldb {\n-namespace port {\n-\n-// AtomicPointer based on <cstdatomic> if available\n-#if defined(LEVELDB_ATOMIC_PRESENT)\n-class AtomicPointer {\n- private:\n-  std::atomic<void*> rep_;\n- public:\n-  AtomicPointer() { }\n-  explicit AtomicPointer(void* v) : rep_(v) { }\n-  inline void* Acquire_Load() const {\n-    return rep_.load(std::memory_order_acquire);\n-  }\n-  inline void Release_Store(void* v) {\n-    rep_.store(v, std::memory_order_release);\n-  }\n-  inline void* NoBarrier_Load() const {\n-    return rep_.load(std::memory_order_relaxed);\n-  }\n-  inline void NoBarrier_Store(void* v) {\n-    rep_.store(v, std::memory_order_relaxed);\n-  }\n-};\n-\n-#else\n-\n-// Define MemoryBarrier() if available\n-// Windows on x86\n-#if defined(OS_WIN) && defined(COMPILER_MSVC) && defined(ARCH_CPU_X86_FAMILY)\n-// windows.h already provides a MemoryBarrier(void) macro\n-// http://msdn.microsoft.com/en-us/library/ms684208(v=vs.85).aspx\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// Mac OS\n-#elif defined(OS_MACOSX)\n-inline void MemoryBarrier() {\n-  OSMemoryBarrier();\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// Gcc on x86\n-#elif defined(ARCH_CPU_X86_FAMILY) && defined(__GNUC__)\n-inline void MemoryBarrier() {\n-  // See http://gcc.gnu.org/ml/gcc/2003-04/msg01180.html for a discussion on\n-  // this idiom. Also see http://en.wikipedia.org/wiki/Memory_ordering.\n-  __asm__ __volatile__(\"\" : : : \"memory\");\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// Sun Studio\n-#elif defined(ARCH_CPU_X86_FAMILY) && defined(__SUNPRO_CC)\n-inline void MemoryBarrier() {\n-  // See http://gcc.gnu.org/ml/gcc/2003-04/msg01180.html for a discussion on\n-  // this idiom. Also see http://en.wikipedia.org/wiki/Memory_ordering.\n-  asm volatile(\"\" : : : \"memory\");\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// ARM Linux\n-#elif defined(ARCH_CPU_ARM_FAMILY) && defined(__linux__)\n-typedef void (*LinuxKernelMemoryBarrierFunc)(void);\n-// The Linux ARM kernel provides a highly optimized device-specific memory\n-// barrier function at a fixed memory address that is mapped in every\n-// user-level process.\n-//\n-// This beats using CPU-specific instructions which are, on single-core\n-// devices, un-necessary and very costly (e.g. ARMv7-A \"dmb\" takes more\n-// than 180ns on a Cortex-A8 like the one on a Nexus One). Benchmarking\n-// shows that the extra function call cost is completely negligible on\n-// multi-core devices.\n-//\n-inline void MemoryBarrier() {\n-  (*(LinuxKernelMemoryBarrierFunc)0xffff0fa0)();\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// ARM64\n-#elif defined(ARCH_CPU_ARM64_FAMILY)\n-inline void MemoryBarrier() {\n-  asm volatile(\"dmb sy\" : : : \"memory\");\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// PPC\n-#elif defined(ARCH_CPU_PPC_FAMILY) && defined(__GNUC__)\n-inline void MemoryBarrier() {\n-  // TODO for some powerpc expert: is there a cheaper suitable variant?\n-  // Perhaps by having separate barriers for acquire and release ops.\n-  asm volatile(\"sync\" : : : \"memory\");\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-// MIPS\n-#elif defined(ARCH_CPU_MIPS_FAMILY) && defined(__GNUC__)\n-inline void MemoryBarrier() {\n-  __asm__ __volatile__(\"sync\" : : : \"memory\");\n-}\n-#define LEVELDB_HAVE_MEMORY_BARRIER\n-\n-#endif\n-\n-// AtomicPointer built using platform-specific MemoryBarrier()\n-#if defined(LEVELDB_HAVE_MEMORY_BARRIER)\n-class AtomicPointer {\n- private:\n-  void* rep_;\n- public:\n-  AtomicPointer() { }\n-  explicit AtomicPointer(void* p) : rep_(p) {}\n-  inline void* NoBarrier_Load() const { return rep_; }\n-  inline void NoBarrier_Store(void* v) { rep_ = v; }\n-  inline void* Acquire_Load() const {\n-    void* result = rep_;\n-    MemoryBarrier();\n-    return result;\n-  }\n-  inline void Release_Store(void* v) {\n-    MemoryBarrier();\n-    rep_ = v;\n-  }\n-};\n-\n-// Atomic pointer based on sparc memory barriers\n-#elif defined(__sparcv9) && defined(__GNUC__)\n-class AtomicPointer {\n- private:\n-  void* rep_;\n- public:\n-  AtomicPointer() { }\n-  explicit AtomicPointer(void* v) : rep_(v) { }\n-  inline void* Acquire_Load() const {\n-    void* val;\n-    __asm__ __volatile__ (\n-        \"ldx [%[rep_]], %[val] \\n\\t\"\n-         \"membar #LoadLoad|#LoadStore \\n\\t\"\n-        : [val] \"=r\" (val)\n-        : [rep_] \"r\" (&rep_)\n-        : \"memory\");\n-    return val;\n-  }\n-  inline void Release_Store(void* v) {\n-    __asm__ __volatile__ (\n-        \"membar #LoadStore|#StoreStore \\n\\t\"\n-        \"stx %[v], [%[rep_]] \\n\\t\"\n-        :\n-        : [rep_] \"r\" (&rep_), [v] \"r\" (v)\n-        : \"memory\");\n-  }\n-  inline void* NoBarrier_Load() const { return rep_; }\n-  inline void NoBarrier_Store(void* v) { rep_ = v; }\n-};\n-\n-// Atomic pointer based on ia64 acq/rel\n-#elif defined(__ia64) && defined(__GNUC__)\n-class AtomicPointer {\n- private:\n-  void* rep_;\n- public:\n-  AtomicPointer() { }\n-  explicit AtomicPointer(void* v) : rep_(v) { }\n-  inline void* Acquire_Load() const {\n-    void* val    ;\n-    __asm__ __volatile__ (\n-        \"ld8.acq %[val] = [%[rep_]] \\n\\t\"\n-        : [val] \"=r\" (val)\n-        : [rep_] \"r\" (&rep_)\n-        : \"memory\"\n-        );\n-    return val;\n-  }\n-  inline void Release_Store(void* v) {\n-    __asm__ __volatile__ (\n-        \"st8.rel [%[rep_]] = %[v]  \\n\\t\"\n-        :\n-        : [rep_] \"r\" (&rep_), [v] \"r\" (v)\n-        : \"memory\"\n-        );\n-  }\n-  inline void* NoBarrier_Load() const { return rep_; }\n-  inline void NoBarrier_Store(void* v) { rep_ = v; }\n-};\n-\n-// We have neither MemoryBarrier(), nor <atomic>\n-#else\n-#error Please implement AtomicPointer for this platform.\n-\n-#endif\n-#endif\n-\n-#undef LEVELDB_HAVE_MEMORY_BARRIER\n-#undef ARCH_CPU_X86_FAMILY\n-#undef ARCH_CPU_ARM_FAMILY\n-#undef ARCH_CPU_ARM64_FAMILY\n-#undef ARCH_CPU_PPC_FAMILY\n-\n-}  // namespace port\n-}  // namespace leveldb\n-\n-#endif  // PORT_ATOMIC_POINTER_H_"
      },
      {
        "sha": "4b247f74f9f5b848a5cc3225c23be0dd7726b53e",
        "filename": "src/leveldb/port/port.h",
        "status": "modified",
        "additions": 3,
        "deletions": 5,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/port.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/port.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/port.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -10,12 +10,10 @@\n // Include the appropriate platform specific file below.  If you are\n // porting to a new platform, see \"port_example.h\" for documentation\n // of what the new port_<platform>.h file must provide.\n-#if defined(LEVELDB_PLATFORM_POSIX)\n-#  include \"port/port_posix.h\"\n+#if defined(LEVELDB_PLATFORM_POSIX) || defined(LEVELDB_PLATFORM_WINDOWS)\n+#include \"port/port_stdcxx.h\"\n #elif defined(LEVELDB_PLATFORM_CHROMIUM)\n-#  include \"port/port_chromium.h\"\n-#elif defined(LEVELDB_PLATFORM_WINDOWS)\n-#  include \"port/port_win.h\"\n+#include \"port/port_chromium.h\"\n #endif\n \n #endif  // STORAGE_LEVELDB_PORT_PORT_H_"
      },
      {
        "sha": "21273153a3fed2ef47ef11f89398e5c09fdd06a0",
        "filename": "src/leveldb/port/port_config.h.in",
        "status": "added",
        "additions": 39,
        "deletions": 0,
        "changes": 39,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/port_config.h.in",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/port_config.h.in",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/port_config.h.in?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -0,0 +1,39 @@\n+// Copyright 2017 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef STORAGE_LEVELDB_PORT_PORT_CONFIG_H_\n+#define STORAGE_LEVELDB_PORT_PORT_CONFIG_H_\n+\n+// Define to 1 if you have a definition for fdatasync() in <unistd.h>.\n+#if !defined(HAVE_FDATASYNC)\n+#cmakedefine01 HAVE_FDATASYNC\n+#endif  // !defined(HAVE_FDATASYNC)\n+\n+// Define to 1 if you have a definition for F_FULLFSYNC in <fcntl.h>.\n+#if !defined(HAVE_FULLFSYNC)\n+#cmakedefine01 HAVE_FULLFSYNC\n+#endif  // !defined(HAVE_FULLFSYNC)\n+\n+// Define to 1 if you have a definition for O_CLOEXEC in <fcntl.h>.\n+#if !defined(HAVE_O_CLOEXEC)\n+#cmakedefine01 HAVE_O_CLOEXEC\n+#endif  // !defined(HAVE_O_CLOEXEC)\n+\n+// Define to 1 if you have Google CRC32C.\n+#if !defined(HAVE_CRC32C)\n+#cmakedefine01 HAVE_CRC32C\n+#endif  // !defined(HAVE_CRC32C)\n+\n+// Define to 1 if you have Google Snappy.\n+#if !defined(HAVE_SNAPPY)\n+#cmakedefine01 HAVE_SNAPPY\n+#endif  // !defined(HAVE_SNAPPY)\n+\n+// Define to 1 if your processor stores words with the most significant byte\n+// first (like Motorola and SPARC, unlike Intel and VAX).\n+#if !defined(LEVELDB_IS_BIG_ENDIAN)\n+#cmakedefine01 LEVELDB_IS_BIG_ENDIAN\n+#endif  // !defined(LEVELDB_IS_BIG_ENDIAN)\n+\n+#endif  // STORAGE_LEVELDB_PORT_PORT_CONFIG_H_\n\\ No newline at end of file"
      },
      {
        "sha": "1a8fca24b36cbdcae7dadabd6f19d21a5240cf95",
        "filename": "src/leveldb/port/port_example.h",
        "status": "modified",
        "additions": 13,
        "deletions": 54,
        "changes": 67,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/port_example.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/port_example.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/port_example.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -10,6 +10,8 @@\n #ifndef STORAGE_LEVELDB_PORT_PORT_EXAMPLE_H_\n #define STORAGE_LEVELDB_PORT_PORT_EXAMPLE_H_\n \n+#include \"port/thread_annotations.h\"\n+\n namespace leveldb {\n namespace port {\n \n@@ -23,23 +25,23 @@ static const bool kLittleEndian = true /* or some other expression */;\n // ------------------ Threading -------------------\n \n // A Mutex represents an exclusive lock.\n-class Mutex {\n+class LOCKABLE Mutex {\n  public:\n   Mutex();\n   ~Mutex();\n \n   // Lock the mutex.  Waits until other lockers have exited.\n   // Will deadlock if the mutex is already locked by this thread.\n-  void Lock();\n+  void Lock() EXCLUSIVE_LOCK_FUNCTION();\n \n   // Unlock the mutex.\n   // REQUIRES: This mutex was locked by this thread.\n-  void Unlock();\n+  void Unlock() UNLOCK_FUNCTION();\n \n   // Optionally crash if this thread does not hold this mutex.\n   // The implementation must be fast, especially if NDEBUG is\n   // defined.  The implementation is allowed to skip all checks.\n-  void AssertHeld();\n+  void AssertHeld() ASSERT_EXCLUSIVE_LOCK();\n };\n \n class CondVar {\n@@ -60,57 +62,18 @@ class CondVar {\n   void SignallAll();\n };\n \n-// Thread-safe initialization.\n-// Used as follows:\n-//      static port::OnceType init_control = LEVELDB_ONCE_INIT;\n-//      static void Initializer() { ... do something ...; }\n-//      ...\n-//      port::InitOnce(&init_control, &Initializer);\n-typedef intptr_t OnceType;\n-#define LEVELDB_ONCE_INIT 0\n-extern void InitOnce(port::OnceType*, void (*initializer)());\n-\n-// A type that holds a pointer that can be read or written atomically\n-// (i.e., without word-tearing.)\n-class AtomicPointer {\n- private:\n-  intptr_t rep_;\n- public:\n-  // Initialize to arbitrary value\n-  AtomicPointer();\n-\n-  // Initialize to hold v\n-  explicit AtomicPointer(void* v) : rep_(v) { }\n-\n-  // Read and return the stored pointer with the guarantee that no\n-  // later memory access (read or write) by this thread can be\n-  // reordered ahead of this read.\n-  void* Acquire_Load() const;\n-\n-  // Set v as the stored pointer with the guarantee that no earlier\n-  // memory access (read or write) by this thread can be reordered\n-  // after this store.\n-  void Release_Store(void* v);\n-\n-  // Read the stored pointer with no ordering guarantees.\n-  void* NoBarrier_Load() const;\n-\n-  // Set va as the stored pointer with no ordering guarantees.\n-  void NoBarrier_Store(void* v);\n-};\n-\n // ------------------ Compression -------------------\n \n // Store the snappy compression of \"input[0,input_length-1]\" in *output.\n // Returns false if snappy is not supported by this port.\n-extern bool Snappy_Compress(const char* input, size_t input_length,\n-                            std::string* output);\n+bool Snappy_Compress(const char* input, size_t input_length,\n+                     std::string* output);\n \n // If input[0,input_length-1] looks like a valid snappy compressed\n // buffer, store the size of the uncompressed data in *result and\n // return true.  Else return false.\n-extern bool Snappy_GetUncompressedLength(const char* input, size_t length,\n-                                         size_t* result);\n+bool Snappy_GetUncompressedLength(const char* input, size_t length,\n+                                  size_t* result);\n \n // Attempt to snappy uncompress input[0,input_length-1] into *output.\n // Returns true if successful, false if the input is invalid lightweight\n@@ -119,19 +82,15 @@ extern bool Snappy_GetUncompressedLength(const char* input, size_t length,\n // REQUIRES: at least the first \"n\" bytes of output[] must be writable\n // where \"n\" is the result of a successful call to\n // Snappy_GetUncompressedLength.\n-extern bool Snappy_Uncompress(const char* input_data, size_t input_length,\n-                              char* output);\n+bool Snappy_Uncompress(const char* input_data, size_t input_length,\n+                       char* output);\n \n // ------------------ Miscellaneous -------------------\n \n // If heap profiling is not supported, returns false.\n // Else repeatedly calls (*func)(arg, data, n) and then returns true.\n // The concatenation of all \"data[0,n-1]\" fragments is the heap profile.\n-extern bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg);\n-\n-// Determine whether a working accelerated crc32 implementation exists\n-// Returns true if AcceleratedCRC32C is safe to call\n-bool HasAcceleratedCRC32C();\n+bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg);\n \n // Extend the CRC to include the first n bytes of buf.\n //"
      },
      {
        "sha": "ec39e921957f6507e3eb5f5ed5b6e15fea69e527",
        "filename": "src/leveldb/port/port_posix.cc",
        "status": "removed",
        "additions": 0,
        "deletions": 67,
        "changes": 67,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/port_posix.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/port_posix.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/port_posix.cc?ref=2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "patch": "@@ -1,67 +0,0 @@\n-// Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-\n-#include \"port/port_posix.h\"\n-\n-#include <cstdlib>\n-#include <stdio.h>\n-#include <string.h>\n-\n-#if (defined(__x86_64__) || defined(__i386__)) && defined(__GNUC__)\n-#include <cpuid.h>\n-#endif\n-\n-namespace leveldb {\n-namespace port {\n-\n-static void PthreadCall(const char* label, int result) {\n-  if (result != 0) {\n-    fprintf(stderr, \"pthread %s: %s\\n\", label, strerror(result));\n-    abort();\n-  }\n-}\n-\n-Mutex::Mutex() { PthreadCall(\"init mutex\", pthread_mutex_init(&mu_, NULL)); }\n-\n-Mutex::~Mutex() { PthreadCall(\"destroy mutex\", pthread_mutex_destroy(&mu_)); }\n-\n-void Mutex::Lock() { PthreadCall(\"lock\", pthread_mutex_lock(&mu_)); }\n-\n-void Mutex::Unlock() { PthreadCall(\"unlock\", pthread_mutex_unlock(&mu_)); }\n-\n-CondVar::CondVar(Mutex* mu)\n-    : mu_(mu) {\n-    PthreadCall(\"init cv\", pthread_cond_init(&cv_, NULL));\n-}\n-\n-CondVar::~CondVar() { PthreadCall(\"destroy cv\", pthread_cond_destroy(&cv_)); }\n-\n-void CondVar::Wait() {\n-  PthreadCall(\"wait\", pthread_cond_wait(&cv_, &mu_->mu_));\n-}\n-\n-void CondVar::Signal() {\n-  PthreadCall(\"signal\", pthread_cond_signal(&cv_));\n-}\n-\n-void CondVar::SignalAll() {\n-  PthreadCall(\"broadcast\", pthread_cond_broadcast(&cv_));\n-}\n-\n-void InitOnce(OnceType* once, void (*initializer)()) {\n-  PthreadCall(\"once\", pthread_once(once, initializer));\n-}\n-\n-bool HasAcceleratedCRC32C() {\n-#if (defined(__x86_64__) || defined(__i386__)) && defined(__GNUC__)\n-  unsigned int eax, ebx, ecx, edx;\n-  __get_cpuid(1, &eax, &ebx, &ecx, &edx);\n-  return (ecx & (1 << 20)) != 0;\n-#else\n-  return false;\n-#endif\n-}\n-\n-}  // namespace port\n-}  // namespace leveldb"
      },
      {
        "sha": "d85fa5d63fe0fc593cb2c9c12471d884622189b6",
        "filename": "src/leveldb/port/port_posix.h",
        "status": "removed",
        "additions": 0,
        "deletions": 161,
        "changes": 161,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/port_posix.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/port_posix.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/port_posix.h?ref=2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "patch": "@@ -1,161 +0,0 @@\n-// Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-//\n-// See port_example.h for documentation for the following types/functions.\n-\n-#ifndef STORAGE_LEVELDB_PORT_PORT_POSIX_H_\n-#define STORAGE_LEVELDB_PORT_PORT_POSIX_H_\n-\n-#undef PLATFORM_IS_LITTLE_ENDIAN\n-#if defined(OS_MACOSX)\n-  #include <machine/endian.h>\n-  #if defined(__DARWIN_LITTLE_ENDIAN) && defined(__DARWIN_BYTE_ORDER)\n-    #define PLATFORM_IS_LITTLE_ENDIAN \\\n-        (__DARWIN_BYTE_ORDER == __DARWIN_LITTLE_ENDIAN)\n-  #endif\n-#elif defined(OS_SOLARIS)\n-  #include <sys/isa_defs.h>\n-  #ifdef _LITTLE_ENDIAN\n-    #define PLATFORM_IS_LITTLE_ENDIAN true\n-  #else\n-    #define PLATFORM_IS_LITTLE_ENDIAN false\n-  #endif\n-#elif defined(OS_FREEBSD) || defined(OS_OPENBSD) ||\\\n-      defined(OS_NETBSD) || defined(OS_DRAGONFLYBSD)\n-  #include <sys/types.h>\n-  #include <sys/endian.h>\n-  #define PLATFORM_IS_LITTLE_ENDIAN (_BYTE_ORDER == _LITTLE_ENDIAN)\n-#elif defined(OS_HPUX)\n-  #define PLATFORM_IS_LITTLE_ENDIAN false\n-#elif defined(OS_ANDROID)\n-  // Due to a bug in the NDK x86 <sys/endian.h> definition,\n-  // _BYTE_ORDER must be used instead of __BYTE_ORDER on Android.\n-  // See http://code.google.com/p/android/issues/detail?id=39824\n-  #include <endian.h>\n-  #define PLATFORM_IS_LITTLE_ENDIAN  (_BYTE_ORDER == _LITTLE_ENDIAN)\n-#else\n-  #include <endian.h>\n-#endif\n-\n-#include <pthread.h>\n-#ifdef SNAPPY\n-#include <snappy.h>\n-#endif\n-#include <stdint.h>\n-#include <string>\n-#include \"port/atomic_pointer.h\"\n-\n-#ifndef PLATFORM_IS_LITTLE_ENDIAN\n-#define PLATFORM_IS_LITTLE_ENDIAN (__BYTE_ORDER == __LITTLE_ENDIAN)\n-#endif\n-\n-#if defined(OS_MACOSX) || defined(OS_SOLARIS) || defined(OS_FREEBSD) ||\\\n-    defined(OS_NETBSD) || defined(OS_OPENBSD) || defined(OS_DRAGONFLYBSD) ||\\\n-    defined(OS_ANDROID) || defined(OS_HPUX) || defined(CYGWIN)\n-// Use fread/fwrite/fflush on platforms without _unlocked variants\n-#define fread_unlocked fread\n-#define fwrite_unlocked fwrite\n-#define fflush_unlocked fflush\n-#endif\n-\n-#if defined(OS_FREEBSD) ||\\\n-    defined(OS_OPENBSD) || defined(OS_DRAGONFLYBSD)\n-// Use fsync() on platforms without fdatasync()\n-#define fdatasync fsync\n-#endif\n-\n-#if defined(OS_MACOSX)\n-#define fdatasync(fd) fcntl(fd, F_FULLFSYNC, 0)\n-#endif\n-\n-#if defined(OS_ANDROID) && __ANDROID_API__ < 9\n-// fdatasync() was only introduced in API level 9 on Android. Use fsync()\n-// when targetting older platforms.\n-#define fdatasync fsync\n-#endif\n-\n-namespace leveldb {\n-namespace port {\n-\n-static const bool kLittleEndian = PLATFORM_IS_LITTLE_ENDIAN;\n-#undef PLATFORM_IS_LITTLE_ENDIAN\n-\n-class CondVar;\n-\n-class Mutex {\n- public:\n-  Mutex();\n-  ~Mutex();\n-\n-  void Lock();\n-  void Unlock();\n-  void AssertHeld() { }\n-\n- private:\n-  friend class CondVar;\n-  pthread_mutex_t mu_;\n-\n-  // No copying\n-  Mutex(const Mutex&);\n-  void operator=(const Mutex&);\n-};\n-\n-class CondVar {\n- public:\n-  explicit CondVar(Mutex* mu);\n-  ~CondVar();\n-  void Wait();\n-  void Signal();\n-  void SignalAll();\n- private:\n-  pthread_cond_t cv_;\n-  Mutex* mu_;\n-};\n-\n-typedef pthread_once_t OnceType;\n-#define LEVELDB_ONCE_INIT PTHREAD_ONCE_INIT\n-extern void InitOnce(OnceType* once, void (*initializer)());\n-\n-inline bool Snappy_Compress(const char* input, size_t length,\n-                            ::std::string* output) {\n-#ifdef SNAPPY\n-  output->resize(snappy::MaxCompressedLength(length));\n-  size_t outlen;\n-  snappy::RawCompress(input, length, &(*output)[0], &outlen);\n-  output->resize(outlen);\n-  return true;\n-#endif\n-\n-  return false;\n-}\n-\n-inline bool Snappy_GetUncompressedLength(const char* input, size_t length,\n-                                         size_t* result) {\n-#ifdef SNAPPY\n-  return snappy::GetUncompressedLength(input, length, result);\n-#else\n-  return false;\n-#endif\n-}\n-\n-inline bool Snappy_Uncompress(const char* input, size_t length,\n-                              char* output) {\n-#ifdef SNAPPY\n-  return snappy::RawUncompress(input, length, output);\n-#else\n-  return false;\n-#endif\n-}\n-\n-inline bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg) {\n-  return false;\n-}\n-\n-bool HasAcceleratedCRC32C();\n-uint32_t AcceleratedCRC32C(uint32_t crc, const char* buf, size_t size);\n-\n-} // namespace port\n-} // namespace leveldb\n-\n-#endif  // STORAGE_LEVELDB_PORT_PORT_POSIX_H_"
      },
      {
        "sha": "2d49c21dd8b0eb08fa0fd33411c50f2d277c94d6",
        "filename": "src/leveldb/port/port_posix_sse.cc",
        "status": "removed",
        "additions": 0,
        "deletions": 110,
        "changes": 110,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/port_posix_sse.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/port_posix_sse.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/port_posix_sse.cc?ref=2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "patch": "@@ -1,110 +0,0 @@\n-// Copyright 2016 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-//\n-// A portable implementation of crc32c, optimized to handle\n-// four bytes at a time.\n-//\n-// In a separate source file to allow this accelerated CRC32C function to be\n-// compiled with the appropriate compiler flags to enable x86 SSE 4.2\n-// instructions.\n-\n-#include <stdint.h>\n-#include <string.h>\n-#include \"port/port.h\"\n-\n-#if defined(LEVELDB_PLATFORM_POSIX_SSE)\n-\n-#if defined(_MSC_VER)\n-#include <intrin.h>\n-#elif defined(__GNUC__) && defined(__SSE4_2__)\n-#include <nmmintrin.h>\n-#endif\n-\n-#endif  // defined(LEVELDB_PLATFORM_POSIX_SSE)\n-\n-namespace leveldb {\n-namespace port {\n-\n-#if defined(LEVELDB_PLATFORM_POSIX_SSE)\n-\n-// Used to fetch a naturally-aligned 32-bit word in little endian byte-order\n-static inline uint32_t LE_LOAD32(const uint8_t *p) {\n-  // SSE is x86 only, so ensured that |p| is always little-endian.\n-  uint32_t word;\n-  memcpy(&word, p, sizeof(word));\n-  return word;\n-}\n-\n-#if defined(_M_X64) || defined(__x86_64__)  // LE_LOAD64 is only used on x64.\n-\n-// Used to fetch a naturally-aligned 64-bit word in little endian byte-order\n-static inline uint64_t LE_LOAD64(const uint8_t *p) {\n-  uint64_t dword;\n-  memcpy(&dword, p, sizeof(dword));\n-  return dword;\n-}\n-\n-#endif  // defined(_M_X64) || defined(__x86_64__)\n-\n-#endif  // defined(LEVELDB_PLATFORM_POSIX_SSE)\n-\n-// For further improvements see Intel publication at:\n-// http://download.intel.com/design/intarch/papers/323405.pdf\n-uint32_t AcceleratedCRC32C(uint32_t crc, const char* buf, size_t size) {\n-#if !defined(LEVELDB_PLATFORM_POSIX_SSE)\n-  return 0;\n-#else\n-\n-  const uint8_t *p = reinterpret_cast<const uint8_t *>(buf);\n-  const uint8_t *e = p + size;\n-  uint32_t l = crc ^ 0xffffffffu;\n-\n-#define STEP1 do {                              \\\n-    l = _mm_crc32_u8(l, *p++);                  \\\n-} while (0)\n-#define STEP4 do {                              \\\n-    l = _mm_crc32_u32(l, LE_LOAD32(p));         \\\n-    p += 4;                                     \\\n-} while (0)\n-#define STEP8 do {                              \\\n-    l = _mm_crc32_u64(l, LE_LOAD64(p));         \\\n-    p += 8;                                     \\\n-} while (0)\n-\n-  if (size > 16) {\n-    // Process unaligned bytes\n-    for (unsigned int i = reinterpret_cast<uintptr_t>(p) % 8; i; --i) {\n-      STEP1;\n-    }\n-\n-    // _mm_crc32_u64 is only available on x64.\n-#if defined(_M_X64) || defined(__x86_64__)\n-    // Process 8 bytes at a time\n-    while ((e-p) >= 8) {\n-      STEP8;\n-    }\n-    // Process 4 bytes at a time\n-    if ((e-p) >= 4) {\n-      STEP4;\n-    }\n-#else  // !(defined(_M_X64) || defined(__x86_64__))\n-    // Process 4 bytes at a time\n-    while ((e-p) >= 4) {\n-      STEP4;\n-    }\n-#endif  // defined(_M_X64) || defined(__x86_64__)\n-  }\n-  // Process the last few bytes\n-  while (p != e) {\n-    STEP1;\n-  }\n-#undef STEP8\n-#undef STEP4\n-#undef STEP1\n-  return l ^ 0xffffffffu;\n-#endif  // defined(LEVELDB_PLATFORM_POSIX_SSE)\n-}\n-\n-}  // namespace port\n-}  // namespace leveldb"
      },
      {
        "sha": "e9cb0e53afdbefd56b0932272e27717680866be3",
        "filename": "src/leveldb/port/port_stdcxx.h",
        "status": "added",
        "additions": 153,
        "deletions": 0,
        "changes": 153,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/port_stdcxx.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/port_stdcxx.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/port_stdcxx.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -0,0 +1,153 @@\n+// Copyright (c) 2018 The LevelDB Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef STORAGE_LEVELDB_PORT_PORT_STDCXX_H_\n+#define STORAGE_LEVELDB_PORT_PORT_STDCXX_H_\n+\n+// port/port_config.h availability is automatically detected via __has_include\n+// in newer compilers. If LEVELDB_HAS_PORT_CONFIG_H is defined, it overrides the\n+// configuration detection.\n+#if defined(LEVELDB_HAS_PORT_CONFIG_H)\n+\n+#if LEVELDB_HAS_PORT_CONFIG_H\n+#include \"port/port_config.h\"\n+#endif  // LEVELDB_HAS_PORT_CONFIG_H\n+\n+#elif defined(__has_include)\n+\n+#if __has_include(\"port/port_config.h\")\n+#include \"port/port_config.h\"\n+#endif  // __has_include(\"port/port_config.h\")\n+\n+#endif  // defined(LEVELDB_HAS_PORT_CONFIG_H)\n+\n+#if HAVE_CRC32C\n+#include <crc32c/crc32c.h>\n+#endif  // HAVE_CRC32C\n+#if HAVE_SNAPPY\n+#include <snappy.h>\n+#endif  // HAVE_SNAPPY\n+\n+#include <cassert>\n+#include <condition_variable>  // NOLINT\n+#include <cstddef>\n+#include <cstdint>\n+#include <mutex>  // NOLINT\n+#include <string>\n+\n+#include \"port/thread_annotations.h\"\n+\n+namespace leveldb {\n+namespace port {\n+\n+static const bool kLittleEndian = !LEVELDB_IS_BIG_ENDIAN;\n+\n+class CondVar;\n+\n+// Thinly wraps std::mutex.\n+class LOCKABLE Mutex {\n+ public:\n+  Mutex() = default;\n+  ~Mutex() = default;\n+\n+  Mutex(const Mutex&) = delete;\n+  Mutex& operator=(const Mutex&) = delete;\n+\n+  void Lock() EXCLUSIVE_LOCK_FUNCTION() { mu_.lock(); }\n+  void Unlock() UNLOCK_FUNCTION() { mu_.unlock(); }\n+  void AssertHeld() ASSERT_EXCLUSIVE_LOCK() {}\n+\n+ private:\n+  friend class CondVar;\n+  std::mutex mu_;\n+};\n+\n+// Thinly wraps std::condition_variable.\n+class CondVar {\n+ public:\n+  explicit CondVar(Mutex* mu) : mu_(mu) { assert(mu != nullptr); }\n+  ~CondVar() = default;\n+\n+  CondVar(const CondVar&) = delete;\n+  CondVar& operator=(const CondVar&) = delete;\n+\n+  void Wait() {\n+    std::unique_lock<std::mutex> lock(mu_->mu_, std::adopt_lock);\n+    cv_.wait(lock);\n+    lock.release();\n+  }\n+  void Signal() { cv_.notify_one(); }\n+  void SignalAll() { cv_.notify_all(); }\n+\n+ private:\n+  std::condition_variable cv_;\n+  Mutex* const mu_;\n+};\n+\n+inline bool Snappy_Compress(const char* input, size_t length,\n+                            std::string* output) {\n+#if HAVE_SNAPPY\n+  output->resize(snappy::MaxCompressedLength(length));\n+  size_t outlen;\n+  snappy::RawCompress(input, length, &(*output)[0], &outlen);\n+  output->resize(outlen);\n+  return true;\n+#else\n+  // Silence compiler warnings about unused arguments.\n+  (void)input;\n+  (void)length;\n+  (void)output;\n+#endif  // HAVE_SNAPPY\n+\n+  return false;\n+}\n+\n+inline bool Snappy_GetUncompressedLength(const char* input, size_t length,\n+                                         size_t* result) {\n+#if HAVE_SNAPPY\n+  return snappy::GetUncompressedLength(input, length, result);\n+#else\n+  // Silence compiler warnings about unused arguments.\n+  (void)input;\n+  (void)length;\n+  (void)result;\n+  return false;\n+#endif  // HAVE_SNAPPY\n+}\n+\n+inline bool Snappy_Uncompress(const char* input, size_t length, char* output) {\n+#if HAVE_SNAPPY\n+  return snappy::RawUncompress(input, length, output);\n+#else\n+  // Silence compiler warnings about unused arguments.\n+  (void)input;\n+  (void)length;\n+  (void)output;\n+  return false;\n+#endif  // HAVE_SNAPPY\n+}\n+\n+inline bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg) {\n+  // Silence compiler warnings about unused arguments.\n+  (void)func;\n+  (void)arg;\n+  return false;\n+}\n+\n+inline uint32_t AcceleratedCRC32C(uint32_t crc, const char* buf, size_t size) {\n+#if HAVE_CRC32C\n+  return ::crc32c::Extend(crc, reinterpret_cast<const uint8_t*>(buf), size);\n+#else\n+  // Silence compiler warnings about unused arguments.\n+  (void)crc;\n+  (void)buf;\n+  (void)size;\n+  return 0;\n+#endif  // HAVE_CRC32C\n+}\n+\n+}  // namespace port\n+}  // namespace leveldb\n+\n+#endif  // STORAGE_LEVELDB_PORT_PORT_STDCXX_H_"
      },
      {
        "sha": "1be9e8d5b0b41ea458b42bb17f2e3a18eefac315",
        "filename": "src/leveldb/port/port_win.cc",
        "status": "removed",
        "additions": 0,
        "deletions": 158,
        "changes": 158,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/port_win.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/port_win.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/port_win.cc?ref=2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "patch": "@@ -1,158 +0,0 @@\n-// LevelDB Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-//\n-// See port_example.h for documentation for the following types/functions.\n-\n-// Redistribution and use in source and binary forms, with or without\n-// modification, are permitted provided that the following conditions are met:\n-// \n-//  * Redistributions of source code must retain the above copyright\n-//    notice, this list of conditions and the following disclaimer.\n-//  * Redistributions in binary form must reproduce the above copyright\n-//    notice, this list of conditions and the following disclaimer in the\n-//    documentation and/or other materials provided with the distribution.\n-//  * Neither the name of the University of California, Berkeley nor the\n-//    names of its contributors may be used to endorse or promote products\n-//    derived from this software without specific prior written permission.\n-// \n-// THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND ANY\n-// EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n-// WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n-// DISCLAIMED. IN NO EVENT SHALL THE REGENTS AND CONTRIBUTORS BE LIABLE FOR ANY\n-// DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n-// (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n-// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n-// ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n-//\n-\n-#include \"port/port_win.h\"\n-\n-#include <windows.h>\n-#include <cassert>\n-#include <intrin.h>\n-\n-namespace leveldb {\n-namespace port {\n-\n-Mutex::Mutex() :\n-    cs_(NULL) {\n-  assert(!cs_);\n-  cs_ = static_cast<void *>(new CRITICAL_SECTION());\n-  ::InitializeCriticalSection(static_cast<CRITICAL_SECTION *>(cs_));\n-  assert(cs_);\n-}\n-\n-Mutex::~Mutex() {\n-  assert(cs_);\n-  ::DeleteCriticalSection(static_cast<CRITICAL_SECTION *>(cs_));\n-  delete static_cast<CRITICAL_SECTION *>(cs_);\n-  cs_ = NULL;\n-  assert(!cs_);\n-}\n-\n-void Mutex::Lock() {\n-  assert(cs_);\n-  ::EnterCriticalSection(static_cast<CRITICAL_SECTION *>(cs_));\n-}\n-\n-void Mutex::Unlock() {\n-  assert(cs_);\n-  ::LeaveCriticalSection(static_cast<CRITICAL_SECTION *>(cs_));\n-}\n-\n-void Mutex::AssertHeld() {\n-  assert(cs_);\n-  assert(1);\n-}\n-\n-CondVar::CondVar(Mutex* mu) :\n-    waiting_(0), \n-    mu_(mu), \n-    sem1_(::CreateSemaphore(NULL, 0, 10000, NULL)), \n-    sem2_(::CreateSemaphore(NULL, 0, 10000, NULL)) {\n-  assert(mu_);\n-}\n-\n-CondVar::~CondVar() {\n-  ::CloseHandle(sem1_);\n-  ::CloseHandle(sem2_);\n-}\n-\n-void CondVar::Wait() {\n-  mu_->AssertHeld();\n-\n-  wait_mtx_.Lock();\n-  ++waiting_;\n-  wait_mtx_.Unlock();\n-\n-  mu_->Unlock();\n-\n-  // initiate handshake\n-  ::WaitForSingleObject(sem1_, INFINITE);\n-  ::ReleaseSemaphore(sem2_, 1, NULL);\n-  mu_->Lock();\n-}\n-\n-void CondVar::Signal() {\n-  wait_mtx_.Lock();\n-  if (waiting_ > 0) {\n-    --waiting_;\n-\n-    // finalize handshake\n-    ::ReleaseSemaphore(sem1_, 1, NULL);\n-    ::WaitForSingleObject(sem2_, INFINITE);\n-  }\n-  wait_mtx_.Unlock();\n-}\n-\n-void CondVar::SignalAll() {\n-  wait_mtx_.Lock();\n-  ::ReleaseSemaphore(sem1_, waiting_, NULL);\n-  while(waiting_ > 0) {\n-    --waiting_;\n-    ::WaitForSingleObject(sem2_, INFINITE);\n-  }\n-  wait_mtx_.Unlock();\n-}\n-\n-AtomicPointer::AtomicPointer(void* v) {\n-  Release_Store(v);\n-}\n-\n-void InitOnce(OnceType* once, void (*initializer)()) {\n-  once->InitOnce(initializer);\n-}\n-\n-void* AtomicPointer::Acquire_Load() const {\n-  void * p = NULL;\n-  InterlockedExchangePointer(&p, rep_);\n-  return p;\n-}\n-\n-void AtomicPointer::Release_Store(void* v) {\n-  InterlockedExchangePointer(&rep_, v);\n-}\n-\n-void* AtomicPointer::NoBarrier_Load() const {\n-  return rep_;\n-}\n-\n-void AtomicPointer::NoBarrier_Store(void* v) {\n-  rep_ = v;\n-}\n-\n-bool HasAcceleratedCRC32C() {\n-#if defined(__x86_64__) || defined(__i386__)\n-  int cpu_info[4];\n-  __cpuid(cpu_info, 1);\n-  return (cpu_info[2] & (1 << 20)) != 0;\n-#else\n-  return false;\n-#endif\n-}\n-\n-}\n-}"
      },
      {
        "sha": "989c15cd91d05713a42c22d92c1be0edacb47bb3",
        "filename": "src/leveldb/port/port_win.h",
        "status": "removed",
        "additions": 0,
        "deletions": 184,
        "changes": 184,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/port_win.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/port_win.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/port_win.h?ref=2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "patch": "@@ -1,184 +0,0 @@\n-// LevelDB Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-//\n-// See port_example.h for documentation for the following types/functions.\n-\n-// Redistribution and use in source and binary forms, with or without\n-// modification, are permitted provided that the following conditions are met:\n-// \n-//  * Redistributions of source code must retain the above copyright\n-//    notice, this list of conditions and the following disclaimer.\n-//  * Redistributions in binary form must reproduce the above copyright\n-//    notice, this list of conditions and the following disclaimer in the\n-//    documentation and/or other materials provided with the distribution.\n-//  * Neither the name of the University of California, Berkeley nor the\n-//    names of its contributors may be used to endorse or promote products\n-//    derived from this software without specific prior written permission.\n-// \n-// THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND ANY\n-// EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n-// WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n-// DISCLAIMED. IN NO EVENT SHALL THE REGENTS AND CONTRIBUTORS BE LIABLE FOR ANY\n-// DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n-// (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n-// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n-// ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n-// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n-// SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n-//\n-\n-#ifndef STORAGE_LEVELDB_PORT_PORT_WIN_H_\n-#define STORAGE_LEVELDB_PORT_PORT_WIN_H_\n-\n-#ifdef _MSC_VER\n-#if !(_MSC_VER >= 1900)\n-#define snprintf _snprintf\n-#endif\n-#define close _close\n-#define fread_unlocked _fread_nolock\n-#ifdef _WIN64\n-#define ssize_t int64_t\n-#else\n-#define ssize_t int32_t\n-#endif\n-#endif\n-\n-#include <string>\n-#include <stdint.h>\n-#ifdef SNAPPY\n-#include <snappy.h>\n-#endif\n-\n-namespace leveldb {\n-namespace port {\n-\n-// Windows is little endian (for now :p)\n-static const bool kLittleEndian = true;\n-\n-class CondVar;\n-\n-class Mutex {\n- public:\n-  Mutex();\n-  ~Mutex();\n-\n-  void Lock();\n-  void Unlock();\n-  void AssertHeld();\n-\n- private:\n-  friend class CondVar;\n-  // critical sections are more efficient than mutexes\n-  // but they are not recursive and can only be used to synchronize threads within the same process\n-  // we use opaque void * to avoid including windows.h in port_win.h\n-  void * cs_;\n-\n-  // No copying\n-  Mutex(const Mutex&);\n-  void operator=(const Mutex&);\n-};\n-\n-// the Win32 API offers a dependable condition variable mechanism, but only starting with\n-// Windows 2008 and Vista\n-// no matter what we will implement our own condition variable with a semaphore\n-// implementation as described in a paper written by Andrew D. Birrell in 2003\n-class CondVar {\n- public:\n-  explicit CondVar(Mutex* mu);\n-  ~CondVar();\n-  void Wait();\n-  void Signal();\n-  void SignalAll();\n- private:\n-  Mutex* mu_;\n-  \n-  Mutex wait_mtx_;\n-  long waiting_;\n-  \n-  void * sem1_;\n-  void * sem2_;\n-  \n-  \n-};\n-\n-class OnceType {\n-public:\n-//    OnceType() : init_(false) {}\n-    OnceType(const OnceType &once) : init_(once.init_) {}\n-    OnceType(bool f) : init_(f) {}\n-    void InitOnce(void (*initializer)()) {\n-        mutex_.Lock();\n-        if (!init_) {\n-            init_ = true;\n-            initializer();\n-        }\n-        mutex_.Unlock();\n-    }\n-\n-private:\n-    bool init_;\n-    Mutex mutex_;\n-};\n-\n-#define LEVELDB_ONCE_INIT false\n-extern void InitOnce(port::OnceType*, void (*initializer)());\n-\n-// Storage for a lock-free pointer\n-class AtomicPointer {\n- private:\n-  void * rep_;\n- public:\n-  AtomicPointer() : rep_(NULL) { }\n-  explicit AtomicPointer(void* v); \n-  void* Acquire_Load() const;\n-\n-  void Release_Store(void* v);\n-\n-  void* NoBarrier_Load() const;\n-\n-  void NoBarrier_Store(void* v);\n-};\n-\n-inline bool Snappy_Compress(const char* input, size_t length,\n-                            ::std::string* output) {\n-#ifdef SNAPPY\n-  output->resize(snappy::MaxCompressedLength(length));\n-  size_t outlen;\n-  snappy::RawCompress(input, length, &(*output)[0], &outlen);\n-  output->resize(outlen);\n-  return true;\n-#endif\n-\n-  return false;\n-}\n-\n-inline bool Snappy_GetUncompressedLength(const char* input, size_t length,\n-                                         size_t* result) {\n-#ifdef SNAPPY\n-  return snappy::GetUncompressedLength(input, length, result);\n-#else\n-  return false;\n-#endif\n-}\n-\n-inline bool Snappy_Uncompress(const char* input, size_t length,\n-                              char* output) {\n-#ifdef SNAPPY\n-  return snappy::RawUncompress(input, length, output);\n-#else\n-  return false;\n-#endif\n-}\n-\n-inline bool GetHeapProfile(void (*func)(void*, const char*, int), void* arg) {\n-  return false;\n-}\n-\n-bool HasAcceleratedCRC32C();\n-uint32_t AcceleratedCRC32C(uint32_t crc, const char* buf, size_t size);\n-\n-}\n-}\n-\n-#endif  // STORAGE_LEVELDB_PORT_PORT_WIN_H_"
      },
      {
        "sha": "1547df908fb629f2dc29d705f2d4cb1d46b89ea2",
        "filename": "src/leveldb/port/thread_annotations.h",
        "status": "modified",
        "additions": 63,
        "deletions": 15,
        "changes": 78,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/thread_annotations.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/port/thread_annotations.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/thread_annotations.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -5,56 +5,104 @@\n #ifndef STORAGE_LEVELDB_PORT_THREAD_ANNOTATIONS_H_\n #define STORAGE_LEVELDB_PORT_THREAD_ANNOTATIONS_H_\n \n-// Some environments provide custom macros to aid in static thread-safety\n-// analysis.  Provide empty definitions of such macros unless they are already\n-// defined.\n+// Use Clang's thread safety analysis annotations when available. In other\n+// environments, the macros receive empty definitions.\n+// Usage documentation: https://clang.llvm.org/docs/ThreadSafetyAnalysis.html\n+\n+#if !defined(THREAD_ANNOTATION_ATTRIBUTE__)\n+\n+#if defined(__clang__)\n+\n+#define THREAD_ANNOTATION_ATTRIBUTE__(x) __attribute__((x))\n+#else\n+#define THREAD_ANNOTATION_ATTRIBUTE__(x)  // no-op\n+#endif\n+\n+#endif  // !defined(THREAD_ANNOTATION_ATTRIBUTE__)\n+\n+#ifndef GUARDED_BY\n+#define GUARDED_BY(x) THREAD_ANNOTATION_ATTRIBUTE__(guarded_by(x))\n+#endif\n+\n+#ifndef PT_GUARDED_BY\n+#define PT_GUARDED_BY(x) THREAD_ANNOTATION_ATTRIBUTE__(pt_guarded_by(x))\n+#endif\n+\n+#ifndef ACQUIRED_AFTER\n+#define ACQUIRED_AFTER(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(acquired_after(__VA_ARGS__))\n+#endif\n+\n+#ifndef ACQUIRED_BEFORE\n+#define ACQUIRED_BEFORE(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(acquired_before(__VA_ARGS__))\n+#endif\n \n #ifndef EXCLUSIVE_LOCKS_REQUIRED\n-#define EXCLUSIVE_LOCKS_REQUIRED(...)\n+#define EXCLUSIVE_LOCKS_REQUIRED(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(exclusive_locks_required(__VA_ARGS__))\n #endif\n \n #ifndef SHARED_LOCKS_REQUIRED\n-#define SHARED_LOCKS_REQUIRED(...)\n+#define SHARED_LOCKS_REQUIRED(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(shared_locks_required(__VA_ARGS__))\n #endif\n \n #ifndef LOCKS_EXCLUDED\n-#define LOCKS_EXCLUDED(...)\n+#define LOCKS_EXCLUDED(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(locks_excluded(__VA_ARGS__))\n #endif\n \n #ifndef LOCK_RETURNED\n-#define LOCK_RETURNED(x)\n+#define LOCK_RETURNED(x) THREAD_ANNOTATION_ATTRIBUTE__(lock_returned(x))\n #endif\n \n #ifndef LOCKABLE\n-#define LOCKABLE\n+#define LOCKABLE THREAD_ANNOTATION_ATTRIBUTE__(lockable)\n #endif\n \n #ifndef SCOPED_LOCKABLE\n-#define SCOPED_LOCKABLE\n+#define SCOPED_LOCKABLE THREAD_ANNOTATION_ATTRIBUTE__(scoped_lockable)\n #endif\n \n #ifndef EXCLUSIVE_LOCK_FUNCTION\n-#define EXCLUSIVE_LOCK_FUNCTION(...)\n+#define EXCLUSIVE_LOCK_FUNCTION(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(exclusive_lock_function(__VA_ARGS__))\n #endif\n \n #ifndef SHARED_LOCK_FUNCTION\n-#define SHARED_LOCK_FUNCTION(...)\n+#define SHARED_LOCK_FUNCTION(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(shared_lock_function(__VA_ARGS__))\n #endif\n \n #ifndef EXCLUSIVE_TRYLOCK_FUNCTION\n-#define EXCLUSIVE_TRYLOCK_FUNCTION(...)\n+#define EXCLUSIVE_TRYLOCK_FUNCTION(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(exclusive_trylock_function(__VA_ARGS__))\n #endif\n \n #ifndef SHARED_TRYLOCK_FUNCTION\n-#define SHARED_TRYLOCK_FUNCTION(...)\n+#define SHARED_TRYLOCK_FUNCTION(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(shared_trylock_function(__VA_ARGS__))\n #endif\n \n #ifndef UNLOCK_FUNCTION\n-#define UNLOCK_FUNCTION(...)\n+#define UNLOCK_FUNCTION(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(unlock_function(__VA_ARGS__))\n #endif\n \n #ifndef NO_THREAD_SAFETY_ANALYSIS\n-#define NO_THREAD_SAFETY_ANALYSIS\n+#define NO_THREAD_SAFETY_ANALYSIS \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(no_thread_safety_analysis)\n+#endif\n+\n+#ifndef ASSERT_EXCLUSIVE_LOCK\n+#define ASSERT_EXCLUSIVE_LOCK(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(assert_exclusive_lock(__VA_ARGS__))\n+#endif\n+\n+#ifndef ASSERT_SHARED_LOCK\n+#define ASSERT_SHARED_LOCK(...) \\\n+  THREAD_ANNOTATION_ATTRIBUTE__(assert_shared_lock(__VA_ARGS__))\n #endif\n \n #endif  // STORAGE_LEVELDB_PORT_THREAD_ANNOTATIONS_H_"
      },
      {
        "sha": "39edd0db13f436dc57dd28ed4013ab4d55a28a31",
        "filename": "src/leveldb/port/win/stdint.h",
        "status": "removed",
        "additions": 0,
        "deletions": 24,
        "changes": 24,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/win/stdint.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/port/win/stdint.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/port/win/stdint.h?ref=2755b2b1092d0286022cf3cc3028e96f6bee2b34",
        "patch": "@@ -1,24 +0,0 @@\n-// Copyright (c) 2011 The LevelDB Authors. All rights reserved.\n-// Use of this source code is governed by a BSD-style license that can be\n-// found in the LICENSE file. See the AUTHORS file for names of contributors.\n-\n-// MSVC didn't ship with this file until the 2010 version.\n-\n-#ifndef STORAGE_LEVELDB_PORT_WIN_STDINT_H_\n-#define STORAGE_LEVELDB_PORT_WIN_STDINT_H_\n-\n-#if !defined(_MSC_VER)\n-#error This file should only be included when compiling with MSVC.\n-#endif\n-\n-// Define C99 equivalent types.\n-typedef signed char           int8_t;\n-typedef signed short          int16_t;\n-typedef signed int            int32_t;\n-typedef signed long long      int64_t;\n-typedef unsigned char         uint8_t;\n-typedef unsigned short        uint16_t;\n-typedef unsigned int          uint32_t;\n-typedef unsigned long long    uint64_t;\n-\n-#endif  // STORAGE_LEVELDB_PORT_WIN_STDINT_H_"
      },
      {
        "sha": "2fe89eaa4593d328db2bea5456ecbfc0e797b1b9",
        "filename": "src/leveldb/table/block.cc",
        "status": "modified",
        "additions": 34,
        "deletions": 35,
        "changes": 69,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/block.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/block.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/block.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -6,8 +6,10 @@\n \n #include \"table/block.h\"\n \n-#include <vector>\n #include <algorithm>\n+#include <cstdint>\n+#include <vector>\n+\n #include \"leveldb/comparator.h\"\n #include \"table/format.h\"\n #include \"util/coding.h\"\n@@ -27,7 +29,7 @@ Block::Block(const BlockContents& contents)\n   if (size_ < sizeof(uint32_t)) {\n     size_ = 0;  // Error marker\n   } else {\n-    size_t max_restarts_allowed = (size_-sizeof(uint32_t)) / sizeof(uint32_t);\n+    size_t max_restarts_allowed = (size_ - sizeof(uint32_t)) / sizeof(uint32_t);\n     if (NumRestarts() > max_restarts_allowed) {\n       // The size is too small for NumRestarts()\n       size_ = 0;\n@@ -48,37 +50,36 @@ Block::~Block() {\n // and the length of the value in \"*shared\", \"*non_shared\", and\n // \"*value_length\", respectively.  Will not dereference past \"limit\".\n //\n-// If any errors are detected, returns NULL.  Otherwise, returns a\n+// If any errors are detected, returns nullptr.  Otherwise, returns a\n // pointer to the key delta (just past the three decoded values).\n static inline const char* DecodeEntry(const char* p, const char* limit,\n-                                      uint32_t* shared,\n-                                      uint32_t* non_shared,\n+                                      uint32_t* shared, uint32_t* non_shared,\n                                       uint32_t* value_length) {\n-  if (limit - p < 3) return NULL;\n-  *shared = reinterpret_cast<const unsigned char*>(p)[0];\n-  *non_shared = reinterpret_cast<const unsigned char*>(p)[1];\n-  *value_length = reinterpret_cast<const unsigned char*>(p)[2];\n+  if (limit - p < 3) return nullptr;\n+  *shared = reinterpret_cast<const uint8_t*>(p)[0];\n+  *non_shared = reinterpret_cast<const uint8_t*>(p)[1];\n+  *value_length = reinterpret_cast<const uint8_t*>(p)[2];\n   if ((*shared | *non_shared | *value_length) < 128) {\n     // Fast path: all three values are encoded in one byte each\n     p += 3;\n   } else {\n-    if ((p = GetVarint32Ptr(p, limit, shared)) == NULL) return NULL;\n-    if ((p = GetVarint32Ptr(p, limit, non_shared)) == NULL) return NULL;\n-    if ((p = GetVarint32Ptr(p, limit, value_length)) == NULL) return NULL;\n+    if ((p = GetVarint32Ptr(p, limit, shared)) == nullptr) return nullptr;\n+    if ((p = GetVarint32Ptr(p, limit, non_shared)) == nullptr) return nullptr;\n+    if ((p = GetVarint32Ptr(p, limit, value_length)) == nullptr) return nullptr;\n   }\n \n   if (static_cast<uint32_t>(limit - p) < (*non_shared + *value_length)) {\n-    return NULL;\n+    return nullptr;\n   }\n   return p;\n }\n \n class Block::Iter : public Iterator {\n  private:\n   const Comparator* const comparator_;\n-  const char* const data_;      // underlying block contents\n-  uint32_t const restarts_;     // Offset of restart array (list of fixed32)\n-  uint32_t const num_restarts_; // Number of uint32_t entries in restart array\n+  const char* const data_;       // underlying block contents\n+  uint32_t const restarts_;      // Offset of restart array (list of fixed32)\n+  uint32_t const num_restarts_;  // Number of uint32_t entries in restart array\n \n   // current_ is offset in data_ of current entry.  >= restarts_ if !Valid\n   uint32_t current_;\n@@ -112,9 +113,7 @@ class Block::Iter : public Iterator {\n   }\n \n  public:\n-  Iter(const Comparator* comparator,\n-       const char* data,\n-       uint32_t restarts,\n+  Iter(const Comparator* comparator, const char* data, uint32_t restarts,\n        uint32_t num_restarts)\n       : comparator_(comparator),\n         data_(data),\n@@ -125,23 +124,23 @@ class Block::Iter : public Iterator {\n     assert(num_restarts_ > 0);\n   }\n \n-  virtual bool Valid() const { return current_ < restarts_; }\n-  virtual Status status() const { return status_; }\n-  virtual Slice key() const {\n+  bool Valid() const override { return current_ < restarts_; }\n+  Status status() const override { return status_; }\n+  Slice key() const override {\n     assert(Valid());\n     return key_;\n   }\n-  virtual Slice value() const {\n+  Slice value() const override {\n     assert(Valid());\n     return value_;\n   }\n \n-  virtual void Next() {\n+  void Next() override {\n     assert(Valid());\n     ParseNextKey();\n   }\n \n-  virtual void Prev() {\n+  void Prev() override {\n     assert(Valid());\n \n     // Scan backwards to a restart point before current_\n@@ -162,7 +161,7 @@ class Block::Iter : public Iterator {\n     } while (ParseNextKey() && NextEntryOffset() < original);\n   }\n \n-  virtual void Seek(const Slice& target) {\n+  void Seek(const Slice& target) override {\n     // Binary search in restart array to find the last restart point\n     // with a key < target\n     uint32_t left = 0;\n@@ -171,10 +170,10 @@ class Block::Iter : public Iterator {\n       uint32_t mid = (left + right + 1) / 2;\n       uint32_t region_offset = GetRestartPoint(mid);\n       uint32_t shared, non_shared, value_length;\n-      const char* key_ptr = DecodeEntry(data_ + region_offset,\n-                                        data_ + restarts_,\n-                                        &shared, &non_shared, &value_length);\n-      if (key_ptr == NULL || (shared != 0)) {\n+      const char* key_ptr =\n+          DecodeEntry(data_ + region_offset, data_ + restarts_, &shared,\n+                      &non_shared, &value_length);\n+      if (key_ptr == nullptr || (shared != 0)) {\n         CorruptionError();\n         return;\n       }\n@@ -202,12 +201,12 @@ class Block::Iter : public Iterator {\n     }\n   }\n \n-  virtual void SeekToFirst() {\n+  void SeekToFirst() override {\n     SeekToRestartPoint(0);\n     ParseNextKey();\n   }\n \n-  virtual void SeekToLast() {\n+  void SeekToLast() override {\n     SeekToRestartPoint(num_restarts_ - 1);\n     while (ParseNextKey() && NextEntryOffset() < restarts_) {\n       // Keep skipping\n@@ -237,7 +236,7 @@ class Block::Iter : public Iterator {\n     // Decode next entry\n     uint32_t shared, non_shared, value_length;\n     p = DecodeEntry(p, limit, &shared, &non_shared, &value_length);\n-    if (p == NULL || key_.size() < shared) {\n+    if (p == nullptr || key_.size() < shared) {\n       CorruptionError();\n       return false;\n     } else {\n@@ -253,15 +252,15 @@ class Block::Iter : public Iterator {\n   }\n };\n \n-Iterator* Block::NewIterator(const Comparator* cmp) {\n+Iterator* Block::NewIterator(const Comparator* comparator) {\n   if (size_ < sizeof(uint32_t)) {\n     return NewErrorIterator(Status::Corruption(\"bad block contents\"));\n   }\n   const uint32_t num_restarts = NumRestarts();\n   if (num_restarts == 0) {\n     return NewEmptyIterator();\n   } else {\n-    return new Iter(cmp, data_, restart_offset_, num_restarts);\n+    return new Iter(comparator, data_, restart_offset_, num_restarts);\n   }\n }\n "
      },
      {
        "sha": "c8f1f7b436a3c1743a22cf09e7f5c93a66b655fa",
        "filename": "src/leveldb/table/block.h",
        "status": "modified",
        "additions": 8,
        "deletions": 8,
        "changes": 16,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/block.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/block.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/block.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -7,6 +7,7 @@\n \n #include <stddef.h>\n #include <stdint.h>\n+\n #include \"leveldb/iterator.h\"\n \n namespace leveldb {\n@@ -19,24 +20,23 @@ class Block {\n   // Initialize the block with the specified contents.\n   explicit Block(const BlockContents& contents);\n \n+  Block(const Block&) = delete;\n+  Block& operator=(const Block&) = delete;\n+\n   ~Block();\n \n   size_t size() const { return size_; }\n   Iterator* NewIterator(const Comparator* comparator);\n \n  private:\n+  class Iter;\n+\n   uint32_t NumRestarts() const;\n \n   const char* data_;\n   size_t size_;\n-  uint32_t restart_offset_;     // Offset in data_ of restart array\n-  bool owned_;                  // Block owns data_[]\n-\n-  // No copying allowed\n-  Block(const Block&);\n-  void operator=(const Block&);\n-\n-  class Iter;\n+  uint32_t restart_offset_;  // Offset in data_ of restart array\n+  bool owned_;               // Block owns data_[]\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "919cff5c9322df8dd8f016bed383a15a6b51754e",
        "filename": "src/leveldb/table/block_builder.cc",
        "status": "modified",
        "additions": 11,
        "deletions": 12,
        "changes": 23,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/block_builder.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/block_builder.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/block_builder.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -28,36 +28,35 @@\n \n #include \"table/block_builder.h\"\n \n-#include <algorithm>\n #include <assert.h>\n+\n+#include <algorithm>\n+\n #include \"leveldb/comparator.h\"\n-#include \"leveldb/table_builder.h\"\n+#include \"leveldb/options.h\"\n #include \"util/coding.h\"\n \n namespace leveldb {\n \n BlockBuilder::BlockBuilder(const Options* options)\n-    : options_(options),\n-      restarts_(),\n-      counter_(0),\n-      finished_(false) {\n+    : options_(options), restarts_(), counter_(0), finished_(false) {\n   assert(options->block_restart_interval >= 1);\n-  restarts_.push_back(0);       // First restart point is at offset 0\n+  restarts_.push_back(0);  // First restart point is at offset 0\n }\n \n void BlockBuilder::Reset() {\n   buffer_.clear();\n   restarts_.clear();\n-  restarts_.push_back(0);       // First restart point is at offset 0\n+  restarts_.push_back(0);  // First restart point is at offset 0\n   counter_ = 0;\n   finished_ = false;\n   last_key_.clear();\n }\n \n size_t BlockBuilder::CurrentSizeEstimate() const {\n-  return (buffer_.size() +                        // Raw data buffer\n-          restarts_.size() * sizeof(uint32_t) +   // Restart array\n-          sizeof(uint32_t));                      // Restart array length\n+  return (buffer_.size() +                       // Raw data buffer\n+          restarts_.size() * sizeof(uint32_t) +  // Restart array\n+          sizeof(uint32_t));                     // Restart array length\n }\n \n Slice BlockBuilder::Finish() {\n@@ -74,7 +73,7 @@ void BlockBuilder::Add(const Slice& key, const Slice& value) {\n   Slice last_key_piece(last_key_);\n   assert(!finished_);\n   assert(counter_ <= options_->block_restart_interval);\n-  assert(buffer_.empty() // No values yet?\n+  assert(buffer_.empty()  // No values yet?\n          || options_->comparator->Compare(key, last_key_piece) > 0);\n   size_t shared = 0;\n   if (counter_ < options_->block_restart_interval) {"
      },
      {
        "sha": "f91f5e6d47e363c9292827b4ffda809d3f160274",
        "filename": "src/leveldb/table/block_builder.h",
        "status": "modified",
        "additions": 12,
        "deletions": 14,
        "changes": 26,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/block_builder.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/block_builder.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/block_builder.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -5,9 +5,10 @@\n #ifndef STORAGE_LEVELDB_TABLE_BLOCK_BUILDER_H_\n #define STORAGE_LEVELDB_TABLE_BLOCK_BUILDER_H_\n \n+#include <stdint.h>\n+\n #include <vector>\n \n-#include <stdint.h>\n #include \"leveldb/slice.h\"\n \n namespace leveldb {\n@@ -18,6 +19,9 @@ class BlockBuilder {\n  public:\n   explicit BlockBuilder(const Options* options);\n \n+  BlockBuilder(const BlockBuilder&) = delete;\n+  BlockBuilder& operator=(const BlockBuilder&) = delete;\n+\n   // Reset the contents as if the BlockBuilder was just constructed.\n   void Reset();\n \n@@ -35,21 +39,15 @@ class BlockBuilder {\n   size_t CurrentSizeEstimate() const;\n \n   // Return true iff no entries have been added since the last Reset()\n-  bool empty() const {\n-    return buffer_.empty();\n-  }\n+  bool empty() const { return buffer_.empty(); }\n \n  private:\n-  const Options*        options_;\n-  std::string           buffer_;      // Destination buffer\n-  std::vector<uint32_t> restarts_;    // Restart points\n-  int                   counter_;     // Number of entries emitted since restart\n-  bool                  finished_;    // Has Finish() been called?\n-  std::string           last_key_;\n-\n-  // No copying allowed\n-  BlockBuilder(const BlockBuilder&);\n-  void operator=(const BlockBuilder&);\n+  const Options* options_;\n+  std::string buffer_;              // Destination buffer\n+  std::vector<uint32_t> restarts_;  // Restart points\n+  int counter_;                     // Number of entries emitted since restart\n+  bool finished_;                   // Has Finish() been called?\n+  std::string last_key_;\n };\n \n }  // namespace leveldb"
      },
      {
        "sha": "09ec0094bd8b4b788c3d21079ec4a317e3a9808d",
        "filename": "src/leveldb/table/filter_block.cc",
        "status": "modified",
        "additions": 7,
        "deletions": 12,
        "changes": 19,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/filter_block.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/filter_block.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/filter_block.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -16,8 +16,7 @@ static const size_t kFilterBaseLg = 11;\n static const size_t kFilterBase = 1 << kFilterBaseLg;\n \n FilterBlockBuilder::FilterBlockBuilder(const FilterPolicy* policy)\n-    : policy_(policy) {\n-}\n+    : policy_(policy) {}\n \n void FilterBlockBuilder::StartBlock(uint64_t block_offset) {\n   uint64_t filter_index = (block_offset / kFilterBase);\n@@ -62,7 +61,7 @@ void FilterBlockBuilder::GenerateFilter() {\n   tmp_keys_.resize(num_keys);\n   for (size_t i = 0; i < num_keys; i++) {\n     const char* base = keys_.data() + start_[i];\n-    size_t length = start_[i+1] - start_[i];\n+    size_t length = start_[i + 1] - start_[i];\n     tmp_keys_[i] = Slice(base, length);\n   }\n \n@@ -77,14 +76,10 @@ void FilterBlockBuilder::GenerateFilter() {\n \n FilterBlockReader::FilterBlockReader(const FilterPolicy* policy,\n                                      const Slice& contents)\n-    : policy_(policy),\n-      data_(NULL),\n-      offset_(NULL),\n-      num_(0),\n-      base_lg_(0) {\n+    : policy_(policy), data_(nullptr), offset_(nullptr), num_(0), base_lg_(0) {\n   size_t n = contents.size();\n   if (n < 5) return;  // 1 byte for base_lg_ and 4 for start of offset array\n-  base_lg_ = contents[n-1];\n+  base_lg_ = contents[n - 1];\n   uint32_t last_word = DecodeFixed32(contents.data() + n - 5);\n   if (last_word > n - 5) return;\n   data_ = contents.data();\n@@ -95,8 +90,8 @@ FilterBlockReader::FilterBlockReader(const FilterPolicy* policy,\n bool FilterBlockReader::KeyMayMatch(uint64_t block_offset, const Slice& key) {\n   uint64_t index = block_offset >> base_lg_;\n   if (index < num_) {\n-    uint32_t start = DecodeFixed32(offset_ + index*4);\n-    uint32_t limit = DecodeFixed32(offset_ + index*4 + 4);\n+    uint32_t start = DecodeFixed32(offset_ + index * 4);\n+    uint32_t limit = DecodeFixed32(offset_ + index * 4 + 4);\n     if (start <= limit && limit <= static_cast<size_t>(offset_ - data_)) {\n       Slice filter = Slice(data_ + start, limit - start);\n       return policy_->KeyMayMatch(key, filter);\n@@ -108,4 +103,4 @@ bool FilterBlockReader::KeyMayMatch(uint64_t block_offset, const Slice& key) {\n   return true;  // Errors are treated as potential matches\n }\n \n-}\n+}  // namespace leveldb"
      },
      {
        "sha": "73b5399249666dc99518dfbc54e508f9c29dbe2e",
        "filename": "src/leveldb/table/filter_block.h",
        "status": "modified",
        "additions": 11,
        "deletions": 10,
        "changes": 21,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/filter_block.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/filter_block.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/filter_block.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -11,8 +11,10 @@\n \n #include <stddef.h>\n #include <stdint.h>\n+\n #include <string>\n #include <vector>\n+\n #include \"leveldb/slice.h\"\n #include \"util/hash.h\"\n \n@@ -30,6 +32,9 @@ class FilterBlockBuilder {\n  public:\n   explicit FilterBlockBuilder(const FilterPolicy*);\n \n+  FilterBlockBuilder(const FilterBlockBuilder&) = delete;\n+  FilterBlockBuilder& operator=(const FilterBlockBuilder&) = delete;\n+\n   void StartBlock(uint64_t block_offset);\n   void AddKey(const Slice& key);\n   Slice Finish();\n@@ -38,20 +43,16 @@ class FilterBlockBuilder {\n   void GenerateFilter();\n \n   const FilterPolicy* policy_;\n-  std::string keys_;              // Flattened key contents\n-  std::vector<size_t> start_;     // Starting index in keys_ of each key\n-  std::string result_;            // Filter data computed so far\n-  std::vector<Slice> tmp_keys_;   // policy_->CreateFilter() argument\n+  std::string keys_;             // Flattened key contents\n+  std::vector<size_t> start_;    // Starting index in keys_ of each key\n+  std::string result_;           // Filter data computed so far\n+  std::vector<Slice> tmp_keys_;  // policy_->CreateFilter() argument\n   std::vector<uint32_t> filter_offsets_;\n-\n-  // No copying allowed\n-  FilterBlockBuilder(const FilterBlockBuilder&);\n-  void operator=(const FilterBlockBuilder&);\n };\n \n class FilterBlockReader {\n  public:\n- // REQUIRES: \"contents\" and *policy must stay live while *this is live.\n+  // REQUIRES: \"contents\" and *policy must stay live while *this is live.\n   FilterBlockReader(const FilterPolicy* policy, const Slice& contents);\n   bool KeyMayMatch(uint64_t block_offset, const Slice& key);\n \n@@ -63,6 +64,6 @@ class FilterBlockReader {\n   size_t base_lg_;      // Encoding parameter (see kFilterBaseLg in .cc file)\n };\n \n-}\n+}  // namespace leveldb\n \n #endif  // STORAGE_LEVELDB_TABLE_FILTER_BLOCK_H_"
      },
      {
        "sha": "8b33bbdd181331f4bb2e81c4108753f0258d6198",
        "filename": "src/leveldb/table/filter_block_test.cc",
        "status": "modified",
        "additions": 17,
        "deletions": 21,
        "changes": 38,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/filter_block_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/filter_block_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/filter_block_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -16,18 +16,16 @@ namespace leveldb {\n // For testing: emit an array with one hash value per key\n class TestHashFilter : public FilterPolicy {\n  public:\n-  virtual const char* Name() const {\n-    return \"TestHashFilter\";\n-  }\n+  const char* Name() const override { return \"TestHashFilter\"; }\n \n-  virtual void CreateFilter(const Slice* keys, int n, std::string* dst) const {\n+  void CreateFilter(const Slice* keys, int n, std::string* dst) const override {\n     for (int i = 0; i < n; i++) {\n       uint32_t h = Hash(keys[i].data(), keys[i].size(), 1);\n       PutFixed32(dst, h);\n     }\n   }\n \n-  virtual bool KeyMayMatch(const Slice& key, const Slice& filter) const {\n+  bool KeyMayMatch(const Slice& key, const Slice& filter) const override {\n     uint32_t h = Hash(key.data(), key.size(), 1);\n     for (size_t i = 0; i + 4 <= filter.size(); i += 4) {\n       if (h == DecodeFixed32(filter.data() + i)) {\n@@ -69,8 +67,8 @@ TEST(FilterBlockTest, SingleChunk) {\n   ASSERT_TRUE(reader.KeyMayMatch(100, \"box\"));\n   ASSERT_TRUE(reader.KeyMayMatch(100, \"hello\"));\n   ASSERT_TRUE(reader.KeyMayMatch(100, \"foo\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(100, \"missing\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(100, \"other\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(100, \"missing\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(100, \"other\"));\n }\n \n TEST(FilterBlockTest, MultiChunk) {\n@@ -99,30 +97,28 @@ TEST(FilterBlockTest, MultiChunk) {\n   // Check first filter\n   ASSERT_TRUE(reader.KeyMayMatch(0, \"foo\"));\n   ASSERT_TRUE(reader.KeyMayMatch(2000, \"bar\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(0, \"box\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(0, \"hello\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(0, \"box\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(0, \"hello\"));\n \n   // Check second filter\n   ASSERT_TRUE(reader.KeyMayMatch(3100, \"box\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(3100, \"foo\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(3100, \"bar\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(3100, \"hello\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(3100, \"foo\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(3100, \"bar\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(3100, \"hello\"));\n \n   // Check third filter (empty)\n-  ASSERT_TRUE(! reader.KeyMayMatch(4100, \"foo\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(4100, \"bar\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(4100, \"box\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(4100, \"hello\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(4100, \"foo\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(4100, \"bar\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(4100, \"box\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(4100, \"hello\"));\n \n   // Check last filter\n   ASSERT_TRUE(reader.KeyMayMatch(9000, \"box\"));\n   ASSERT_TRUE(reader.KeyMayMatch(9000, \"hello\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(9000, \"foo\"));\n-  ASSERT_TRUE(! reader.KeyMayMatch(9000, \"bar\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(9000, \"foo\"));\n+  ASSERT_TRUE(!reader.KeyMayMatch(9000, \"bar\"));\n }\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "a3d67de2e41d4ffa16e927432ee389568cfda32f",
        "filename": "src/leveldb/table/format.cc",
        "status": "modified",
        "additions": 4,
        "deletions": 7,
        "changes": 11,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/format.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/format.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/format.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -21,8 +21,7 @@ void BlockHandle::EncodeTo(std::string* dst) const {\n }\n \n Status BlockHandle::DecodeFrom(Slice* input) {\n-  if (GetVarint64(input, &offset_) &&\n-      GetVarint64(input, &size_)) {\n+  if (GetVarint64(input, &offset_) && GetVarint64(input, &size_)) {\n     return Status::OK();\n   } else {\n     return Status::Corruption(\"bad block handle\");\n@@ -62,10 +61,8 @@ Status Footer::DecodeFrom(Slice* input) {\n   return result;\n }\n \n-Status ReadBlock(RandomAccessFile* file,\n-                 const ReadOptions& options,\n-                 const BlockHandle& handle,\n-                 BlockContents* result) {\n+Status ReadBlock(RandomAccessFile* file, const ReadOptions& options,\n+                 const BlockHandle& handle, BlockContents* result) {\n   result->data = Slice();\n   result->cachable = false;\n   result->heap_allocated = false;\n@@ -86,7 +83,7 @@ Status ReadBlock(RandomAccessFile* file,\n   }\n \n   // Check the crc of the type and the block contents\n-  const char* data = contents.data();    // Pointer to where Read put the data\n+  const char* data = contents.data();  // Pointer to where Read put the data\n   if (options.verify_checksums) {\n     const uint32_t crc = crc32c::Unmask(DecodeFixed32(data + n + 1));\n     const uint32_t actual = crc32c::Value(data, n + 1);"
      },
      {
        "sha": "e49dfdc0477f340710810d6391b0f83605ba8787",
        "filename": "src/leveldb/table/format.h",
        "status": "modified",
        "additions": 17,
        "deletions": 25,
        "changes": 42,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/format.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/format.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/format.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -5,8 +5,10 @@\n #ifndef STORAGE_LEVELDB_TABLE_FORMAT_H_\n #define STORAGE_LEVELDB_TABLE_FORMAT_H_\n \n-#include <string>\n #include <stdint.h>\n+\n+#include <string>\n+\n #include \"leveldb/slice.h\"\n #include \"leveldb/status.h\"\n #include \"leveldb/table_builder.h\"\n@@ -21,6 +23,9 @@ struct ReadOptions;\n // block or a meta block.\n class BlockHandle {\n  public:\n+  // Maximum encoding length of a BlockHandle\n+  enum { kMaxEncodedLength = 10 + 10 };\n+\n   BlockHandle();\n \n   // The offset of the block in the file.\n@@ -34,9 +39,6 @@ class BlockHandle {\n   void EncodeTo(std::string* dst) const;\n   Status DecodeFrom(Slice* input);\n \n-  // Maximum encoding length of a BlockHandle\n-  enum { kMaxEncodedLength = 10 + 10 };\n-\n  private:\n   uint64_t offset_;\n   uint64_t size_;\n@@ -46,30 +48,24 @@ class BlockHandle {\n // end of every table file.\n class Footer {\n  public:\n-  Footer() { }\n+  // Encoded length of a Footer.  Note that the serialization of a\n+  // Footer will always occupy exactly this many bytes.  It consists\n+  // of two block handles and a magic number.\n+  enum { kEncodedLength = 2 * BlockHandle::kMaxEncodedLength + 8 };\n+\n+  Footer() = default;\n \n   // The block handle for the metaindex block of the table\n   const BlockHandle& metaindex_handle() const { return metaindex_handle_; }\n   void set_metaindex_handle(const BlockHandle& h) { metaindex_handle_ = h; }\n \n   // The block handle for the index block of the table\n-  const BlockHandle& index_handle() const {\n-    return index_handle_;\n-  }\n-  void set_index_handle(const BlockHandle& h) {\n-    index_handle_ = h;\n-  }\n+  const BlockHandle& index_handle() const { return index_handle_; }\n+  void set_index_handle(const BlockHandle& h) { index_handle_ = h; }\n \n   void EncodeTo(std::string* dst) const;\n   Status DecodeFrom(Slice* input);\n \n-  // Encoded length of a Footer.  Note that the serialization of a\n-  // Footer will always occupy exactly this many bytes.  It consists\n-  // of two block handles and a magic number.\n-  enum {\n-    kEncodedLength = 2*BlockHandle::kMaxEncodedLength + 8\n-  };\n-\n  private:\n   BlockHandle metaindex_handle_;\n   BlockHandle index_handle_;\n@@ -91,17 +87,13 @@ struct BlockContents {\n \n // Read the block identified by \"handle\" from \"file\".  On failure\n // return non-OK.  On success fill *result and return OK.\n-extern Status ReadBlock(RandomAccessFile* file,\n-                        const ReadOptions& options,\n-                        const BlockHandle& handle,\n-                        BlockContents* result);\n+Status ReadBlock(RandomAccessFile* file, const ReadOptions& options,\n+                 const BlockHandle& handle, BlockContents* result);\n \n // Implementation details follow.  Clients should ignore,\n \n inline BlockHandle::BlockHandle()\n-    : offset_(~static_cast<uint64_t>(0)),\n-      size_(~static_cast<uint64_t>(0)) {\n-}\n+    : offset_(~static_cast<uint64_t>(0)), size_(~static_cast<uint64_t>(0)) {}\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "dfef083d4d756069b5c16d5684b3bd741b0ff814",
        "filename": "src/leveldb/table/iterator.cc",
        "status": "modified",
        "additions": 42,
        "deletions": 33,
        "changes": 75,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/iterator.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/iterator.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/iterator.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -7,58 +7,67 @@\n namespace leveldb {\n \n Iterator::Iterator() {\n-  cleanup_.function = NULL;\n-  cleanup_.next = NULL;\n+  cleanup_head_.function = nullptr;\n+  cleanup_head_.next = nullptr;\n }\n \n Iterator::~Iterator() {\n-  if (cleanup_.function != NULL) {\n-    (*cleanup_.function)(cleanup_.arg1, cleanup_.arg2);\n-    for (Cleanup* c = cleanup_.next; c != NULL; ) {\n-      (*c->function)(c->arg1, c->arg2);\n-      Cleanup* next = c->next;\n-      delete c;\n-      c = next;\n+  if (!cleanup_head_.IsEmpty()) {\n+    cleanup_head_.Run();\n+    for (CleanupNode* node = cleanup_head_.next; node != nullptr;) {\n+      node->Run();\n+      CleanupNode* next_node = node->next;\n+      delete node;\n+      node = next_node;\n     }\n   }\n }\n \n void Iterator::RegisterCleanup(CleanupFunction func, void* arg1, void* arg2) {\n-  assert(func != NULL);\n-  Cleanup* c;\n-  if (cleanup_.function == NULL) {\n-    c = &cleanup_;\n+  assert(func != nullptr);\n+  CleanupNode* node;\n+  if (cleanup_head_.IsEmpty()) {\n+    node = &cleanup_head_;\n   } else {\n-    c = new Cleanup;\n-    c->next = cleanup_.next;\n-    cleanup_.next = c;\n+    node = new CleanupNode();\n+    node->next = cleanup_head_.next;\n+    cleanup_head_.next = node;\n   }\n-  c->function = func;\n-  c->arg1 = arg1;\n-  c->arg2 = arg2;\n+  node->function = func;\n+  node->arg1 = arg1;\n+  node->arg2 = arg2;\n }\n \n namespace {\n+\n class EmptyIterator : public Iterator {\n  public:\n-  EmptyIterator(const Status& s) : status_(s) { }\n-  virtual bool Valid() const { return false; }\n-  virtual void Seek(const Slice& target) { }\n-  virtual void SeekToFirst() { }\n-  virtual void SeekToLast() { }\n-  virtual void Next() { assert(false); }\n-  virtual void Prev() { assert(false); }\n-  Slice key() const { assert(false); return Slice(); }\n-  Slice value() const { assert(false); return Slice(); }\n-  virtual Status status() const { return status_; }\n+  EmptyIterator(const Status& s) : status_(s) {}\n+  ~EmptyIterator() override = default;\n+\n+  bool Valid() const override { return false; }\n+  void Seek(const Slice& target) override {}\n+  void SeekToFirst() override {}\n+  void SeekToLast() override {}\n+  void Next() override { assert(false); }\n+  void Prev() override { assert(false); }\n+  Slice key() const override {\n+    assert(false);\n+    return Slice();\n+  }\n+  Slice value() const override {\n+    assert(false);\n+    return Slice();\n+  }\n+  Status status() const override { return status_; }\n+\n  private:\n   Status status_;\n };\n-}  // namespace\n \n-Iterator* NewEmptyIterator() {\n-  return new EmptyIterator(Status::OK());\n-}\n+}  // anonymous namespace\n+\n+Iterator* NewEmptyIterator() { return new EmptyIterator(Status::OK()); }\n \n Iterator* NewErrorIterator(const Status& status) {\n   return new EmptyIterator(status);"
      },
      {
        "sha": "c230572529ce5394887fd48a926b4afbaba060f7",
        "filename": "src/leveldb/table/iterator_wrapper.h",
        "status": "modified",
        "additions": 42,
        "deletions": 16,
        "changes": 58,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/iterator_wrapper.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/iterator_wrapper.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/iterator_wrapper.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -16,10 +16,8 @@ namespace leveldb {\n // cache locality.\n class IteratorWrapper {\n  public:\n-  IteratorWrapper(): iter_(NULL), valid_(false) { }\n-  explicit IteratorWrapper(Iterator* iter): iter_(NULL) {\n-    Set(iter);\n-  }\n+  IteratorWrapper() : iter_(nullptr), valid_(false) {}\n+  explicit IteratorWrapper(Iterator* iter) : iter_(nullptr) { Set(iter); }\n   ~IteratorWrapper() { delete iter_; }\n   Iterator* iter() const { return iter_; }\n \n@@ -28,25 +26,53 @@ class IteratorWrapper {\n   void Set(Iterator* iter) {\n     delete iter_;\n     iter_ = iter;\n-    if (iter_ == NULL) {\n+    if (iter_ == nullptr) {\n       valid_ = false;\n     } else {\n       Update();\n     }\n   }\n \n-\n   // Iterator interface methods\n-  bool Valid() const        { return valid_; }\n-  Slice key() const         { assert(Valid()); return key_; }\n-  Slice value() const       { assert(Valid()); return iter_->value(); }\n-  // Methods below require iter() != NULL\n-  Status status() const     { assert(iter_); return iter_->status(); }\n-  void Next()               { assert(iter_); iter_->Next();        Update(); }\n-  void Prev()               { assert(iter_); iter_->Prev();        Update(); }\n-  void Seek(const Slice& k) { assert(iter_); iter_->Seek(k);       Update(); }\n-  void SeekToFirst()        { assert(iter_); iter_->SeekToFirst(); Update(); }\n-  void SeekToLast()         { assert(iter_); iter_->SeekToLast();  Update(); }\n+  bool Valid() const { return valid_; }\n+  Slice key() const {\n+    assert(Valid());\n+    return key_;\n+  }\n+  Slice value() const {\n+    assert(Valid());\n+    return iter_->value();\n+  }\n+  // Methods below require iter() != nullptr\n+  Status status() const {\n+    assert(iter_);\n+    return iter_->status();\n+  }\n+  void Next() {\n+    assert(iter_);\n+    iter_->Next();\n+    Update();\n+  }\n+  void Prev() {\n+    assert(iter_);\n+    iter_->Prev();\n+    Update();\n+  }\n+  void Seek(const Slice& k) {\n+    assert(iter_);\n+    iter_->Seek(k);\n+    Update();\n+  }\n+  void SeekToFirst() {\n+    assert(iter_);\n+    iter_->SeekToFirst();\n+    Update();\n+  }\n+  void SeekToLast() {\n+    assert(iter_);\n+    iter_->SeekToLast();\n+    Update();\n+  }\n \n  private:\n   void Update() {"
      },
      {
        "sha": "76441b1cc21747bacd41bc8e02cd03ca3ac970d9",
        "filename": "src/leveldb/table/merger.cc",
        "status": "modified",
        "additions": 23,
        "deletions": 29,
        "changes": 52,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/merger.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/merger.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/merger.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -17,46 +17,42 @@ class MergingIterator : public Iterator {\n       : comparator_(comparator),\n         children_(new IteratorWrapper[n]),\n         n_(n),\n-        current_(NULL),\n+        current_(nullptr),\n         direction_(kForward) {\n     for (int i = 0; i < n; i++) {\n       children_[i].Set(children[i]);\n     }\n   }\n \n-  virtual ~MergingIterator() {\n-    delete[] children_;\n-  }\n+  ~MergingIterator() override { delete[] children_; }\n \n-  virtual bool Valid() const {\n-    return (current_ != NULL);\n-  }\n+  bool Valid() const override { return (current_ != nullptr); }\n \n-  virtual void SeekToFirst() {\n+  void SeekToFirst() override {\n     for (int i = 0; i < n_; i++) {\n       children_[i].SeekToFirst();\n     }\n     FindSmallest();\n     direction_ = kForward;\n   }\n \n-  virtual void SeekToLast() {\n+  void SeekToLast() override {\n     for (int i = 0; i < n_; i++) {\n       children_[i].SeekToLast();\n     }\n     FindLargest();\n     direction_ = kReverse;\n   }\n \n-  virtual void Seek(const Slice& target) {\n+  void Seek(const Slice& target) override {\n     for (int i = 0; i < n_; i++) {\n       children_[i].Seek(target);\n     }\n     FindSmallest();\n     direction_ = kForward;\n   }\n \n-  virtual void Next() {\n+  void Next() override {\n     assert(Valid());\n \n     // Ensure that all children are positioned after key().\n@@ -82,7 +78,7 @@ class MergingIterator : public Iterator {\n     FindSmallest();\n   }\n \n-  virtual void Prev() {\n+  void Prev() override {\n     assert(Valid());\n \n     // Ensure that all children are positioned before key().\n@@ -111,17 +107,17 @@ class MergingIterator : public Iterator {\n     FindLargest();\n   }\n \n-  virtual Slice key() const {\n+  Slice key() const override {\n     assert(Valid());\n     return current_->key();\n   }\n \n-  virtual Slice value() const {\n+  Slice value() const override {\n     assert(Valid());\n     return current_->value();\n   }\n \n-  virtual Status status() const {\n+  Status status() const override {\n     Status status;\n     for (int i = 0; i < n_; i++) {\n       status = children_[i].status();\n@@ -133,6 +129,9 @@ class MergingIterator : public Iterator {\n   }\n \n  private:\n+  // Which direction is the iterator moving?\n+  enum Direction { kForward, kReverse };\n+\n   void FindSmallest();\n   void FindLargest();\n \n@@ -143,21 +142,15 @@ class MergingIterator : public Iterator {\n   IteratorWrapper* children_;\n   int n_;\n   IteratorWrapper* current_;\n-\n-  // Which direction is the iterator moving?\n-  enum Direction {\n-    kForward,\n-    kReverse\n-  };\n   Direction direction_;\n };\n \n void MergingIterator::FindSmallest() {\n-  IteratorWrapper* smallest = NULL;\n+  IteratorWrapper* smallest = nullptr;\n   for (int i = 0; i < n_; i++) {\n     IteratorWrapper* child = &children_[i];\n     if (child->Valid()) {\n-      if (smallest == NULL) {\n+      if (smallest == nullptr) {\n         smallest = child;\n       } else if (comparator_->Compare(child->key(), smallest->key()) < 0) {\n         smallest = child;\n@@ -168,11 +161,11 @@ void MergingIterator::FindSmallest() {\n }\n \n void MergingIterator::FindLargest() {\n-  IteratorWrapper* largest = NULL;\n-  for (int i = n_-1; i >= 0; i--) {\n+  IteratorWrapper* largest = nullptr;\n+  for (int i = n_ - 1; i >= 0; i--) {\n     IteratorWrapper* child = &children_[i];\n     if (child->Valid()) {\n-      if (largest == NULL) {\n+      if (largest == nullptr) {\n         largest = child;\n       } else if (comparator_->Compare(child->key(), largest->key()) > 0) {\n         largest = child;\n@@ -183,14 +176,15 @@ void MergingIterator::FindLargest() {\n }\n }  // namespace\n \n-Iterator* NewMergingIterator(const Comparator* cmp, Iterator** list, int n) {\n+Iterator* NewMergingIterator(const Comparator* comparator, Iterator** children,\n+                             int n) {\n   assert(n >= 0);\n   if (n == 0) {\n     return NewEmptyIterator();\n   } else if (n == 1) {\n-    return list[0];\n+    return children[0];\n   } else {\n-    return new MergingIterator(cmp, list, n);\n+    return new MergingIterator(comparator, children, n);\n   }\n }\n "
      },
      {
        "sha": "41cedc525448a6597662590d3642f0898f704816",
        "filename": "src/leveldb/table/merger.h",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/merger.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/merger.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/merger.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -18,8 +18,8 @@ class Iterator;\n // key is present in K child iterators, it will be yielded K times.\n //\n // REQUIRES: n >= 0\n-extern Iterator* NewMergingIterator(\n-    const Comparator* comparator, Iterator** children, int n);\n+Iterator* NewMergingIterator(const Comparator* comparator, Iterator** children,\n+                             int n);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "b07bc88c7eb4d7166ef2bd30af215a14a554718f",
        "filename": "src/leveldb/table/table.cc",
        "status": "modified",
        "additions": 28,
        "deletions": 40,
        "changes": 68,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/table.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/table.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/table.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -20,7 +20,7 @@ namespace leveldb {\n struct Table::Rep {\n   ~Rep() {\n     delete filter;\n-    delete [] filter_data;\n+    delete[] filter_data;\n     delete index_block;\n   }\n \n@@ -35,11 +35,9 @@ struct Table::Rep {\n   Block* index_block;\n };\n \n-Status Table::Open(const Options& options,\n-                   RandomAccessFile* file,\n-                   uint64_t size,\n-                   Table** table) {\n-  *table = NULL;\n+Status Table::Open(const Options& options, RandomAccessFile* file,\n+                   uint64_t size, Table** table) {\n+  *table = nullptr;\n   if (size < Footer::kEncodedLength) {\n     return Status::Corruption(\"file is too short to be an sstable\");\n   }\n@@ -55,41 +53,36 @@ Status Table::Open(const Options& options,\n   if (!s.ok()) return s;\n \n   // Read the index block\n-  BlockContents contents;\n-  Block* index_block = NULL;\n+  BlockContents index_block_contents;\n   if (s.ok()) {\n     ReadOptions opt;\n     if (options.paranoid_checks) {\n       opt.verify_checksums = true;\n     }\n-    s = ReadBlock(file, opt, footer.index_handle(), &contents);\n-    if (s.ok()) {\n-      index_block = new Block(contents);\n-    }\n+    s = ReadBlock(file, opt, footer.index_handle(), &index_block_contents);\n   }\n \n   if (s.ok()) {\n     // We've successfully read the footer and the index block: we're\n     // ready to serve requests.\n+    Block* index_block = new Block(index_block_contents);\n     Rep* rep = new Table::Rep;\n     rep->options = options;\n     rep->file = file;\n     rep->metaindex_handle = footer.metaindex_handle();\n     rep->index_block = index_block;\n     rep->cache_id = (options.block_cache ? options.block_cache->NewId() : 0);\n-    rep->filter_data = NULL;\n-    rep->filter = NULL;\n+    rep->filter_data = nullptr;\n+    rep->filter = nullptr;\n     *table = new Table(rep);\n     (*table)->ReadMeta(footer);\n-  } else {\n-    delete index_block;\n   }\n \n   return s;\n }\n \n void Table::ReadMeta(const Footer& footer) {\n-  if (rep_->options.filter_policy == NULL) {\n+  if (rep_->options.filter_policy == nullptr) {\n     return;  // Do not need any metadata\n   }\n \n@@ -135,14 +128,12 @@ void Table::ReadFilter(const Slice& filter_handle_value) {\n     return;\n   }\n   if (block.heap_allocated) {\n-    rep_->filter_data = block.data.data();     // Will need to delete later\n+    rep_->filter_data = block.data.data();  // Will need to delete later\n   }\n   rep_->filter = new FilterBlockReader(rep_->options.filter_policy, block.data);\n }\n \n-Table::~Table() {\n-  delete rep_;\n-}\n+Table::~Table() { delete rep_; }\n \n static void DeleteBlock(void* arg, void* ignored) {\n   delete reinterpret_cast<Block*>(arg);\n@@ -161,13 +152,12 @@ static void ReleaseBlock(void* arg, void* h) {\n \n // Convert an index iterator value (i.e., an encoded BlockHandle)\n // into an iterator over the contents of the corresponding block.\n-Iterator* Table::BlockReader(void* arg,\n-                             const ReadOptions& options,\n+Iterator* Table::BlockReader(void* arg, const ReadOptions& options,\n                              const Slice& index_value) {\n   Table* table = reinterpret_cast<Table*>(arg);\n   Cache* block_cache = table->rep_->options.block_cache;\n-  Block* block = NULL;\n-  Cache::Handle* cache_handle = NULL;\n+  Block* block = nullptr;\n+  Cache::Handle* cache_handle = nullptr;\n \n   BlockHandle handle;\n   Slice input = index_value;\n@@ -177,21 +167,21 @@ Iterator* Table::BlockReader(void* arg,\n \n   if (s.ok()) {\n     BlockContents contents;\n-    if (block_cache != NULL) {\n+    if (block_cache != nullptr) {\n       char cache_key_buffer[16];\n       EncodeFixed64(cache_key_buffer, table->rep_->cache_id);\n-      EncodeFixed64(cache_key_buffer+8, handle.offset());\n+      EncodeFixed64(cache_key_buffer + 8, handle.offset());\n       Slice key(cache_key_buffer, sizeof(cache_key_buffer));\n       cache_handle = block_cache->Lookup(key);\n-      if (cache_handle != NULL) {\n+      if (cache_handle != nullptr) {\n         block = reinterpret_cast<Block*>(block_cache->Value(cache_handle));\n       } else {\n         s = ReadBlock(table->rep_->file, options, handle, &contents);\n         if (s.ok()) {\n           block = new Block(contents);\n           if (contents.cachable && options.fill_cache) {\n-            cache_handle = block_cache->Insert(\n-                key, block, block->size(), &DeleteCachedBlock);\n+            cache_handle = block_cache->Insert(key, block, block->size(),\n+                                               &DeleteCachedBlock);\n           }\n         }\n       }\n@@ -204,10 +194,10 @@ Iterator* Table::BlockReader(void* arg,\n   }\n \n   Iterator* iter;\n-  if (block != NULL) {\n+  if (block != nullptr) {\n     iter = block->NewIterator(table->rep_->options.comparator);\n-    if (cache_handle == NULL) {\n-      iter->RegisterCleanup(&DeleteBlock, block, NULL);\n+    if (cache_handle == nullptr) {\n+      iter->RegisterCleanup(&DeleteBlock, block, nullptr);\n     } else {\n       iter->RegisterCleanup(&ReleaseBlock, block_cache, cache_handle);\n     }\n@@ -223,25 +213,24 @@ Iterator* Table::NewIterator(const ReadOptions& options) const {\n       &Table::BlockReader, const_cast<Table*>(this), options);\n }\n \n-Status Table::InternalGet(const ReadOptions& options, const Slice& k,\n-                          void* arg,\n-                          void (*saver)(void*, const Slice&, const Slice&)) {\n+Status Table::InternalGet(const ReadOptions& options, const Slice& k, void* arg,\n+                          void (*handle_result)(void*, const Slice&,\n+                                                const Slice&)) {\n   Status s;\n   Iterator* iiter = rep_->index_block->NewIterator(rep_->options.comparator);\n   iiter->Seek(k);\n   if (iiter->Valid()) {\n     Slice handle_value = iiter->value();\n     FilterBlockReader* filter = rep_->filter;\n     BlockHandle handle;\n-    if (filter != NULL &&\n-        handle.DecodeFrom(&handle_value).ok() &&\n+    if (filter != nullptr && handle.DecodeFrom(&handle_value).ok() &&\n         !filter->KeyMayMatch(handle.offset(), k)) {\n       // Not found\n     } else {\n       Iterator* block_iter = BlockReader(this, options, iiter->value());\n       block_iter->Seek(k);\n       if (block_iter->Valid()) {\n-        (*saver)(arg, block_iter->key(), block_iter->value());\n+        (*handle_result)(arg, block_iter->key(), block_iter->value());\n       }\n       s = block_iter->status();\n       delete block_iter;\n@@ -254,7 +243,6 @@ Status Table::InternalGet(const ReadOptions& options, const Slice& k,\n   return s;\n }\n \n-\n uint64_t Table::ApproximateOffsetOf(const Slice& key) const {\n   Iterator* index_iter =\n       rep_->index_block->NewIterator(rep_->options.comparator);"
      },
      {
        "sha": "278febf94f197ee8ee711c992ce6fd62d5ce88be",
        "filename": "src/leveldb/table/table_builder.cc",
        "status": "modified",
        "additions": 28,
        "deletions": 33,
        "changes": 61,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/table_builder.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/table_builder.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/table_builder.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -5,6 +5,7 @@\n #include \"leveldb/table_builder.h\"\n \n #include <assert.h>\n+\n #include \"leveldb/comparator.h\"\n #include \"leveldb/env.h\"\n #include \"leveldb/filter_policy.h\"\n@@ -18,6 +19,22 @@\n namespace leveldb {\n \n struct TableBuilder::Rep {\n+  Rep(const Options& opt, WritableFile* f)\n+      : options(opt),\n+        index_block_options(opt),\n+        file(f),\n+        offset(0),\n+        data_block(&options),\n+        index_block(&index_block_options),\n+        num_entries(0),\n+        closed(false),\n+        filter_block(opt.filter_policy == nullptr\n+                         ? nullptr\n+                         : new FilterBlockBuilder(opt.filter_policy)),\n+        pending_index_entry(false) {\n+    index_block_options.block_restart_interval = 1;\n+  }\n+\n   Options options;\n   Options index_block_options;\n   WritableFile* file;\n@@ -27,7 +44,7 @@ struct TableBuilder::Rep {\n   BlockBuilder index_block;\n   std::string last_key;\n   int64_t num_entries;\n-  bool closed;          // Either Finish() or Abandon() has been called.\n+  bool closed;  // Either Finish() or Abandon() has been called.\n   FilterBlockBuilder* filter_block;\n \n   // We do not emit the index entry for a block until we have seen the\n@@ -43,26 +60,11 @@ struct TableBuilder::Rep {\n   BlockHandle pending_handle;  // Handle to add to index block\n \n   std::string compressed_output;\n-\n-  Rep(const Options& opt, WritableFile* f)\n-      : options(opt),\n-        index_block_options(opt),\n-        file(f),\n-        offset(0),\n-        data_block(&options),\n-        index_block(&index_block_options),\n-        num_entries(0),\n-        closed(false),\n-        filter_block(opt.filter_policy == NULL ? NULL\n-                     : new FilterBlockBuilder(opt.filter_policy)),\n-        pending_index_entry(false) {\n-    index_block_options.block_restart_interval = 1;\n-  }\n };\n \n TableBuilder::TableBuilder(const Options& options, WritableFile* file)\n     : rep_(new Rep(options, file)) {\n-  if (rep_->filter_block != NULL) {\n+  if (rep_->filter_block != nullptr) {\n     rep_->filter_block->StartBlock(0);\n   }\n }\n@@ -106,7 +108,7 @@ void TableBuilder::Add(const Slice& key, const Slice& value) {\n     r->pending_index_entry = false;\n   }\n \n-  if (r->filter_block != NULL) {\n+  if (r->filter_block != nullptr) {\n     r->filter_block->AddKey(key);\n   }\n \n@@ -131,7 +133,7 @@ void TableBuilder::Flush() {\n     r->pending_index_entry = true;\n     r->status = r->file->Flush();\n   }\n-  if (r->filter_block != NULL) {\n+  if (r->filter_block != nullptr) {\n     r->filter_block->StartBlock(r->offset);\n   }\n }\n@@ -173,8 +175,7 @@ void TableBuilder::WriteBlock(BlockBuilder* block, BlockHandle* handle) {\n }\n \n void TableBuilder::WriteRawBlock(const Slice& block_contents,\n-                                 CompressionType type,\n-                                 BlockHandle* handle) {\n+                                 CompressionType type, BlockHandle* handle) {\n   Rep* r = rep_;\n   handle->set_offset(r->offset);\n   handle->set_size(block_contents.size());\n@@ -184,17 +185,15 @@ void TableBuilder::WriteRawBlock(const Slice& block_contents,\n     trailer[0] = type;\n     uint32_t crc = crc32c::Value(block_contents.data(), block_contents.size());\n     crc = crc32c::Extend(crc, trailer, 1);  // Extend crc to cover block type\n-    EncodeFixed32(trailer+1, crc32c::Mask(crc));\n+    EncodeFixed32(trailer + 1, crc32c::Mask(crc));\n     r->status = r->file->Append(Slice(trailer, kBlockTrailerSize));\n     if (r->status.ok()) {\n       r->offset += block_contents.size() + kBlockTrailerSize;\n     }\n   }\n }\n \n-Status TableBuilder::status() const {\n-  return rep_->status;\n-}\n+Status TableBuilder::status() const { return rep_->status; }\n \n Status TableBuilder::Finish() {\n   Rep* r = rep_;\n@@ -205,15 +204,15 @@ Status TableBuilder::Finish() {\n   BlockHandle filter_block_handle, metaindex_block_handle, index_block_handle;\n \n   // Write filter block\n-  if (ok() && r->filter_block != NULL) {\n+  if (ok() && r->filter_block != nullptr) {\n     WriteRawBlock(r->filter_block->Finish(), kNoCompression,\n                   &filter_block_handle);\n   }\n \n   // Write metaindex block\n   if (ok()) {\n     BlockBuilder meta_index_block(&r->options);\n-    if (r->filter_block != NULL) {\n+    if (r->filter_block != nullptr) {\n       // Add mapping from \"filter.Name\" to location of filter data\n       std::string key = \"filter.\";\n       key.append(r->options.filter_policy->Name());\n@@ -259,12 +258,8 @@ void TableBuilder::Abandon() {\n   r->closed = true;\n }\n \n-uint64_t TableBuilder::NumEntries() const {\n-  return rep_->num_entries;\n-}\n+uint64_t TableBuilder::NumEntries() const { return rep_->num_entries; }\n \n-uint64_t TableBuilder::FileSize() const {\n-  return rep_->offset;\n-}\n+uint64_t TableBuilder::FileSize() const { return rep_->offset; }\n \n }  // namespace leveldb"
      },
      {
        "sha": "17aaea2f9e8b48484c4ba129a656854e4681596d",
        "filename": "src/leveldb/table/table_test.cc",
        "status": "modified",
        "additions": 138,
        "deletions": 177,
        "changes": 315,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/table_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/table_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/table_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -6,6 +6,7 @@\n \n #include <map>\n #include <string>\n+\n #include \"db/dbformat.h\"\n #include \"db/memtable.h\"\n #include \"db/write_batch_internal.h\"\n@@ -27,8 +28,8 @@ namespace leveldb {\n static std::string Reverse(const Slice& key) {\n   std::string str(key.ToString());\n   std::string rev(\"\");\n-  for (std::string::reverse_iterator rit = str.rbegin();\n-       rit != str.rend(); ++rit) {\n+  for (std::string::reverse_iterator rit = str.rbegin(); rit != str.rend();\n+       ++rit) {\n     rev.push_back(*rit);\n   }\n   return rev;\n@@ -37,24 +38,23 @@ static std::string Reverse(const Slice& key) {\n namespace {\n class ReverseKeyComparator : public Comparator {\n  public:\n-  virtual const char* Name() const {\n+  const char* Name() const override {\n     return \"leveldb.ReverseBytewiseComparator\";\n   }\n \n-  virtual int Compare(const Slice& a, const Slice& b) const {\n+  int Compare(const Slice& a, const Slice& b) const override {\n     return BytewiseComparator()->Compare(Reverse(a), Reverse(b));\n   }\n \n-  virtual void FindShortestSeparator(\n-      std::string* start,\n-      const Slice& limit) const {\n+  void FindShortestSeparator(std::string* start,\n+                             const Slice& limit) const override {\n     std::string s = Reverse(*start);\n     std::string l = Reverse(limit);\n     BytewiseComparator()->FindShortestSeparator(&s, l);\n     *start = Reverse(s);\n   }\n \n-  virtual void FindShortSuccessor(std::string* key) const {\n+  void FindShortSuccessor(std::string* key) const override {\n     std::string s = Reverse(*key);\n     BytewiseComparator()->FindShortSuccessor(&s);\n     *key = Reverse(s);\n@@ -79,47 +79,46 @@ namespace {\n struct STLLessThan {\n   const Comparator* cmp;\n \n-  STLLessThan() : cmp(BytewiseComparator()) { }\n-  STLLessThan(const Comparator* c) : cmp(c) { }\n+  STLLessThan() : cmp(BytewiseComparator()) {}\n+  STLLessThan(const Comparator* c) : cmp(c) {}\n   bool operator()(const std::string& a, const std::string& b) const {\n     return cmp->Compare(Slice(a), Slice(b)) < 0;\n   }\n };\n }  // namespace\n \n-class StringSink: public WritableFile {\n+class StringSink : public WritableFile {\n  public:\n-  ~StringSink() { }\n+  ~StringSink() override = default;\n \n   const std::string& contents() const { return contents_; }\n \n-  virtual Status Close() { return Status::OK(); }\n-  virtual Status Flush() { return Status::OK(); }\n-  virtual Status Sync() { return Status::OK(); }\n+  Status Close() override { return Status::OK(); }\n+  Status Flush() override { return Status::OK(); }\n+  Status Sync() override { return Status::OK(); }\n \n-  virtual Status Append(const Slice& data) {\n+  Status Append(const Slice& data) override {\n     contents_.append(data.data(), data.size());\n     return Status::OK();\n   }\n \n+  std::string GetName() const override { return \"\"; }\n  private:\n   std::string contents_;\n };\n \n-\n-class StringSource: public RandomAccessFile {\n+class StringSource : public RandomAccessFile {\n  public:\n   StringSource(const Slice& contents)\n-      : contents_(contents.data(), contents.size()) {\n-  }\n+      : contents_(contents.data(), contents.size()) {}\n \n-  virtual ~StringSource() { }\n+  ~StringSource() override = default;\n \n   uint64_t Size() const { return contents_.size(); }\n \n-  virtual Status Read(uint64_t offset, size_t n, Slice* result,\n-                       char* scratch) const {\n-    if (offset > contents_.size()) {\n+  Status Read(uint64_t offset, size_t n, Slice* result,\n+              char* scratch) const override {\n+    if (offset >= contents_.size()) {\n       return Status::InvalidArgument(\"invalid Read offset\");\n     }\n     if (offset + n > contents_.size()) {\n@@ -130,6 +129,7 @@ class StringSource: public RandomAccessFile {\n     return Status::OK();\n   }\n \n+  std::string GetName() const { return \"\"; }\n  private:\n   std::string contents_;\n };\n@@ -140,8 +140,8 @@ typedef std::map<std::string, std::string, STLLessThan> KVMap;\n // BlockBuilder/TableBuilder and Block/Table.\n class Constructor {\n  public:\n-  explicit Constructor(const Comparator* cmp) : data_(STLLessThan(cmp)) { }\n-  virtual ~Constructor() { }\n+  explicit Constructor(const Comparator* cmp) : data_(STLLessThan(cmp)) {}\n+  virtual ~Constructor() = default;\n \n   void Add(const std::string& key, const Slice& value) {\n     data_[key] = value.ToString();\n@@ -150,15 +150,12 @@ class Constructor {\n   // Finish constructing the data structure with all the keys that have\n   // been added so far.  Returns the keys in sorted order in \"*keys\"\n   // and stores the key/value pairs in \"*kvmap\"\n-  void Finish(const Options& options,\n-              std::vector<std::string>* keys,\n+  void Finish(const Options& options, std::vector<std::string>* keys,\n               KVMap* kvmap) {\n     *kvmap = data_;\n     keys->clear();\n-    for (KVMap::const_iterator it = data_.begin();\n-         it != data_.end();\n-         ++it) {\n-      keys->push_back(it->first);\n+    for (const auto& kvp : data_) {\n+      keys->push_back(kvp.first);\n     }\n     data_.clear();\n     Status s = FinishImpl(options, *kvmap);\n@@ -170,32 +167,26 @@ class Constructor {\n \n   virtual Iterator* NewIterator() const = 0;\n \n-  virtual const KVMap& data() { return data_; }\n+  const KVMap& data() const { return data_; }\n \n-  virtual DB* db() const { return NULL; }  // Overridden in DBConstructor\n+  virtual DB* db() const { return nullptr; }  // Overridden in DBConstructor\n \n  private:\n   KVMap data_;\n };\n \n-class BlockConstructor: public Constructor {\n+class BlockConstructor : public Constructor {\n  public:\n   explicit BlockConstructor(const Comparator* cmp)\n-      : Constructor(cmp),\n-        comparator_(cmp),\n-        block_(NULL) { }\n-  ~BlockConstructor() {\n+      : Constructor(cmp), comparator_(cmp), block_(nullptr) {}\n+  ~BlockConstructor() override { delete block_; }\n+  Status FinishImpl(const Options& options, const KVMap& data) override {\n     delete block_;\n-  }\n-  virtual Status FinishImpl(const Options& options, const KVMap& data) {\n-    delete block_;\n-    block_ = NULL;\n+    block_ = nullptr;\n     BlockBuilder builder(&options);\n \n-    for (KVMap::const_iterator it = data.begin();\n-         it != data.end();\n-         ++it) {\n-      builder.Add(it->first, it->second);\n+    for (const auto& kvp : data) {\n+      builder.Add(kvp.first, kvp.second);\n     }\n     // Open the block\n     data_ = builder.Finish().ToString();\n@@ -206,36 +197,30 @@ class BlockConstructor: public Constructor {\n     block_ = new Block(contents);\n     return Status::OK();\n   }\n-  virtual Iterator* NewIterator() const {\n+  Iterator* NewIterator() const override {\n     return block_->NewIterator(comparator_);\n   }\n \n  private:\n-  const Comparator* comparator_;\n+  const Comparator* const comparator_;\n   std::string data_;\n   Block* block_;\n \n   BlockConstructor();\n };\n \n-class TableConstructor: public Constructor {\n+class TableConstructor : public Constructor {\n  public:\n   TableConstructor(const Comparator* cmp)\n-      : Constructor(cmp),\n-        source_(NULL), table_(NULL) {\n-  }\n-  ~TableConstructor() {\n-    Reset();\n-  }\n-  virtual Status FinishImpl(const Options& options, const KVMap& data) {\n+      : Constructor(cmp), source_(nullptr), table_(nullptr) {}\n+  ~TableConstructor() override { Reset(); }\n+  Status FinishImpl(const Options& options, const KVMap& data) override {\n     Reset();\n     StringSink sink;\n     TableBuilder builder(options, &sink);\n \n-    for (KVMap::const_iterator it = data.begin();\n-         it != data.end();\n-         ++it) {\n-      builder.Add(it->first, it->second);\n+    for (const auto& kvp : data) {\n+      builder.Add(kvp.first, kvp.second);\n       ASSERT_TRUE(builder.status().ok());\n     }\n     Status s = builder.Finish();\n@@ -250,7 +235,7 @@ class TableConstructor: public Constructor {\n     return Table::Open(table_options, source_, sink.contents().size(), &table_);\n   }\n \n-  virtual Iterator* NewIterator() const {\n+  Iterator* NewIterator() const override {\n     return table_->NewIterator(ReadOptions());\n   }\n \n@@ -262,8 +247,8 @@ class TableConstructor: public Constructor {\n   void Reset() {\n     delete table_;\n     delete source_;\n-    table_ = NULL;\n-    source_ = NULL;\n+    table_ = nullptr;\n+    source_ = nullptr;\n   }\n \n   StringSource* source_;\n@@ -273,23 +258,28 @@ class TableConstructor: public Constructor {\n };\n \n // A helper class that converts internal format keys into user keys\n-class KeyConvertingIterator: public Iterator {\n+class KeyConvertingIterator : public Iterator {\n  public:\n-  explicit KeyConvertingIterator(Iterator* iter) : iter_(iter) { }\n-  virtual ~KeyConvertingIterator() { delete iter_; }\n-  virtual bool Valid() const { return iter_->Valid(); }\n-  virtual void Seek(const Slice& target) {\n+  explicit KeyConvertingIterator(Iterator* iter) : iter_(iter) {}\n+\n+  KeyConvertingIterator(const KeyConvertingIterator&) = delete;\n+  KeyConvertingIterator& operator=(const KeyConvertingIterator&) = delete;\n+\n+  ~KeyConvertingIterator() override { delete iter_; }\n+\n+  bool Valid() const override { return iter_->Valid(); }\n+  void Seek(const Slice& target) override {\n     ParsedInternalKey ikey(target, kMaxSequenceNumber, kTypeValue);\n     std::string encoded;\n     AppendInternalKey(&encoded, ikey);\n     iter_->Seek(encoded);\n   }\n-  virtual void SeekToFirst() { iter_->SeekToFirst(); }\n-  virtual void SeekToLast() { iter_->SeekToLast(); }\n-  virtual void Next() { iter_->Next(); }\n-  virtual void Prev() { iter_->Prev(); }\n+  void SeekToFirst() override { iter_->SeekToFirst(); }\n+  void SeekToLast() override { iter_->SeekToLast(); }\n+  void Next() override { iter_->Next(); }\n+  void Prev() override { iter_->Prev(); }\n \n-  virtual Slice key() const {\n+  Slice key() const override {\n     assert(Valid());\n     ParsedInternalKey key;\n     if (!ParseInternalKey(iter_->key(), &key)) {\n@@ -299,82 +289,68 @@ class KeyConvertingIterator: public Iterator {\n     return key.user_key;\n   }\n \n-  virtual Slice value() const { return iter_->value(); }\n-  virtual Status status() const {\n+  Slice value() const override { return iter_->value(); }\n+  Status status() const override {\n     return status_.ok() ? iter_->status() : status_;\n   }\n \n  private:\n   mutable Status status_;\n   Iterator* iter_;\n-\n-  // No copying allowed\n-  KeyConvertingIterator(const KeyConvertingIterator&);\n-  void operator=(const KeyConvertingIterator&);\n };\n \n-class MemTableConstructor: public Constructor {\n+class MemTableConstructor : public Constructor {\n  public:\n   explicit MemTableConstructor(const Comparator* cmp)\n-      : Constructor(cmp),\n-        internal_comparator_(cmp) {\n+      : Constructor(cmp), internal_comparator_(cmp) {\n     memtable_ = new MemTable(internal_comparator_);\n     memtable_->Ref();\n   }\n-  ~MemTableConstructor() {\n-    memtable_->Unref();\n-  }\n-  virtual Status FinishImpl(const Options& options, const KVMap& data) {\n+  ~MemTableConstructor() override { memtable_->Unref(); }\n+  Status FinishImpl(const Options& options, const KVMap& data) override {\n     memtable_->Unref();\n     memtable_ = new MemTable(internal_comparator_);\n     memtable_->Ref();\n     int seq = 1;\n-    for (KVMap::const_iterator it = data.begin();\n-         it != data.end();\n-         ++it) {\n-      memtable_->Add(seq, kTypeValue, it->first, it->second);\n+    for (const auto& kvp : data) {\n+      memtable_->Add(seq, kTypeValue, kvp.first, kvp.second);\n       seq++;\n     }\n     return Status::OK();\n   }\n-  virtual Iterator* NewIterator() const {\n+  Iterator* NewIterator() const override {\n     return new KeyConvertingIterator(memtable_->NewIterator());\n   }\n \n  private:\n-  InternalKeyComparator internal_comparator_;\n+  const InternalKeyComparator internal_comparator_;\n   MemTable* memtable_;\n };\n \n-class DBConstructor: public Constructor {\n+class DBConstructor : public Constructor {\n  public:\n   explicit DBConstructor(const Comparator* cmp)\n-      : Constructor(cmp),\n-        comparator_(cmp) {\n-    db_ = NULL;\n+      : Constructor(cmp), comparator_(cmp) {\n+    db_ = nullptr;\n     NewDB();\n   }\n-  ~DBConstructor() {\n-    delete db_;\n-  }\n-  virtual Status FinishImpl(const Options& options, const KVMap& data) {\n+  ~DBConstructor() override { delete db_; }\n+  Status FinishImpl(const Options& options, const KVMap& data) override {\n     delete db_;\n-    db_ = NULL;\n+    db_ = nullptr;\n     NewDB();\n-    for (KVMap::const_iterator it = data.begin();\n-         it != data.end();\n-         ++it) {\n+    for (const auto& kvp : data) {\n       WriteBatch batch;\n-      batch.Put(it->first, it->second);\n+      batch.Put(kvp.first, kvp.second);\n       ASSERT_TRUE(db_->Write(WriteOptions(), &batch).ok());\n     }\n     return Status::OK();\n   }\n-  virtual Iterator* NewIterator() const {\n+  Iterator* NewIterator() const override {\n     return db_->NewIterator(ReadOptions());\n   }\n \n-  virtual DB* db() const { return db_; }\n+  DB* db() const override { return db_; }\n \n  private:\n   void NewDB() {\n@@ -392,16 +368,11 @@ class DBConstructor: public Constructor {\n     ASSERT_TRUE(status.ok()) << status.ToString();\n   }\n \n-  const Comparator* comparator_;\n+  const Comparator* const comparator_;\n   DB* db_;\n };\n \n-enum TestType {\n-  TABLE_TEST,\n-  BLOCK_TEST,\n-  MEMTABLE_TEST,\n-  DB_TEST\n-};\n+enum TestType { TABLE_TEST, BLOCK_TEST, MEMTABLE_TEST, DB_TEST };\n \n struct TestArgs {\n   TestType type;\n@@ -410,37 +381,37 @@ struct TestArgs {\n };\n \n static const TestArgs kTestArgList[] = {\n-  { TABLE_TEST, false, 16 },\n-  { TABLE_TEST, false, 1 },\n-  { TABLE_TEST, false, 1024 },\n-  { TABLE_TEST, true, 16 },\n-  { TABLE_TEST, true, 1 },\n-  { TABLE_TEST, true, 1024 },\n-\n-  { BLOCK_TEST, false, 16 },\n-  { BLOCK_TEST, false, 1 },\n-  { BLOCK_TEST, false, 1024 },\n-  { BLOCK_TEST, true, 16 },\n-  { BLOCK_TEST, true, 1 },\n-  { BLOCK_TEST, true, 1024 },\n-\n-  // Restart interval does not matter for memtables\n-  { MEMTABLE_TEST, false, 16 },\n-  { MEMTABLE_TEST, true, 16 },\n-\n-  // Do not bother with restart interval variations for DB\n-  { DB_TEST, false, 16 },\n-  { DB_TEST, true, 16 },\n+    {TABLE_TEST, false, 16},\n+    {TABLE_TEST, false, 1},\n+    {TABLE_TEST, false, 1024},\n+    {TABLE_TEST, true, 16},\n+    {TABLE_TEST, true, 1},\n+    {TABLE_TEST, true, 1024},\n+\n+    {BLOCK_TEST, false, 16},\n+    {BLOCK_TEST, false, 1},\n+    {BLOCK_TEST, false, 1024},\n+    {BLOCK_TEST, true, 16},\n+    {BLOCK_TEST, true, 1},\n+    {BLOCK_TEST, true, 1024},\n+\n+    // Restart interval does not matter for memtables\n+    {MEMTABLE_TEST, false, 16},\n+    {MEMTABLE_TEST, true, 16},\n+\n+    // Do not bother with restart interval variations for DB\n+    {DB_TEST, false, 16},\n+    {DB_TEST, true, 16},\n };\n static const int kNumTestArgs = sizeof(kTestArgList) / sizeof(kTestArgList[0]);\n \n class Harness {\n  public:\n-  Harness() : constructor_(NULL) { }\n+  Harness() : constructor_(nullptr) {}\n \n   void Init(const TestArgs& args) {\n     delete constructor_;\n-    constructor_ = NULL;\n+    constructor_ = nullptr;\n     options_ = Options();\n \n     options_.block_restart_interval = args.restart_interval;\n@@ -466,9 +437,7 @@ class Harness {\n     }\n   }\n \n-  ~Harness() {\n-    delete constructor_;\n-  }\n+  ~Harness() { delete constructor_; }\n \n   void Add(const std::string& key, const std::string& value) {\n     constructor_->Add(key, value);\n@@ -490,8 +459,7 @@ class Harness {\n     ASSERT_TRUE(!iter->Valid());\n     iter->SeekToFirst();\n     for (KVMap::const_iterator model_iter = data.begin();\n-         model_iter != data.end();\n-         ++model_iter) {\n+         model_iter != data.end(); ++model_iter) {\n       ASSERT_EQ(ToString(data, model_iter), ToString(iter));\n       iter->Next();\n     }\n@@ -505,17 +473,15 @@ class Harness {\n     ASSERT_TRUE(!iter->Valid());\n     iter->SeekToLast();\n     for (KVMap::const_reverse_iterator model_iter = data.rbegin();\n-         model_iter != data.rend();\n-         ++model_iter) {\n+         model_iter != data.rend(); ++model_iter) {\n       ASSERT_EQ(ToString(data, model_iter), ToString(iter));\n       iter->Prev();\n     }\n     ASSERT_TRUE(!iter->Valid());\n     delete iter;\n   }\n \n-  void TestRandomAccess(Random* rnd,\n-                        const std::vector<std::string>& keys,\n+  void TestRandomAccess(Random* rnd, const std::vector<std::string>& keys,\n                         const KVMap& data) {\n     static const bool kVerbose = false;\n     Iterator* iter = constructor_->NewIterator();\n@@ -546,8 +512,8 @@ class Harness {\n         case 2: {\n           std::string key = PickRandomKey(rnd, keys);\n           model_iter = data.lower_bound(key);\n-          if (kVerbose) fprintf(stderr, \"Seek '%s'\\n\",\n-                                EscapeString(key).c_str());\n+          if (kVerbose)\n+            fprintf(stderr, \"Seek '%s'\\n\", EscapeString(key).c_str());\n           iter->Seek(Slice(key));\n           ASSERT_EQ(ToString(data, model_iter), ToString(iter));\n           break;\n@@ -558,7 +524,7 @@ class Harness {\n             if (kVerbose) fprintf(stderr, \"Prev\\n\");\n             iter->Prev();\n             if (model_iter == data.begin()) {\n-              model_iter = data.end();   // Wrap around to invalid value\n+              model_iter = data.end();  // Wrap around to invalid value\n             } else {\n               --model_iter;\n             }\n@@ -621,8 +587,8 @@ class Harness {\n           break;\n         case 1: {\n           // Attempt to return something smaller than an existing key\n-          if (result.size() > 0 && result[result.size()-1] > '\\0') {\n-            result[result.size()-1]--;\n+          if (!result.empty() && result[result.size() - 1] > '\\0') {\n+            result[result.size() - 1]--;\n           }\n           break;\n         }\n@@ -636,7 +602,7 @@ class Harness {\n     }\n   }\n \n-  // Returns NULL if not running against a DB\n+  // Returns nullptr if not running against a DB\n   DB* db() const { return constructor_->db(); }\n \n  private:\n@@ -720,8 +686,8 @@ TEST(Harness, Randomized) {\n     for (int num_entries = 0; num_entries < 2000;\n          num_entries += (num_entries < 50 ? 1 : 200)) {\n       if ((num_entries % 10) == 0) {\n-        fprintf(stderr, \"case %d of %d: num_entries = %d\\n\",\n-                (i + 1), int(kNumTestArgs), num_entries);\n+        fprintf(stderr, \"case %d of %d: num_entries = %d\\n\", (i + 1),\n+                int(kNumTestArgs), num_entries);\n       }\n       for (int e = 0; e < num_entries; e++) {\n         std::string v;\n@@ -735,7 +701,7 @@ TEST(Harness, Randomized) {\n \n TEST(Harness, RandomizedLongDB) {\n   Random rnd(test::RandomSeed());\n-  TestArgs args = { DB_TEST, false, 16 };\n+  TestArgs args = {DB_TEST, false, 16};\n   Init(args);\n   int num_entries = 100000;\n   for (int e = 0; e < num_entries; e++) {\n@@ -757,7 +723,7 @@ TEST(Harness, RandomizedLongDB) {\n   ASSERT_GT(files, 0);\n }\n \n-class MemTableTest { };\n+class MemTableTest {};\n \n TEST(MemTableTest, Simple) {\n   InternalKeyComparator cmp(BytewiseComparator());\n@@ -774,8 +740,7 @@ TEST(MemTableTest, Simple) {\n   Iterator* iter = memtable->NewIterator();\n   iter->SeekToFirst();\n   while (iter->Valid()) {\n-    fprintf(stderr, \"key: '%s' -> '%s'\\n\",\n-            iter->key().ToString().c_str(),\n+    fprintf(stderr, \"key: '%s' -> '%s'\\n\", iter->key().ToString().c_str(),\n             iter->value().ToString().c_str());\n     iter->Next();\n   }\n@@ -788,14 +753,13 @@ static bool Between(uint64_t val, uint64_t low, uint64_t high) {\n   bool result = (val >= low) && (val <= high);\n   if (!result) {\n     fprintf(stderr, \"Value %llu is not in range [%llu, %llu]\\n\",\n-            (unsigned long long)(val),\n-            (unsigned long long)(low),\n+            (unsigned long long)(val), (unsigned long long)(low),\n             (unsigned long long)(high));\n   }\n   return result;\n }\n \n-class TableTest { };\n+class TableTest {};\n \n TEST(TableTest, ApproximateOffsetOfPlain) {\n   TableConstructor c(BytewiseComparator());\n@@ -813,18 +777,17 @@ TEST(TableTest, ApproximateOffsetOfPlain) {\n   options.compression = kNoCompression;\n   c.Finish(options, &keys, &kvmap);\n \n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"abc\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01a\"),      0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k02\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k03\"),       0,      0));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k04\"),   10000,  11000));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"abc\"), 0, 0));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01\"), 0, 0));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k01a\"), 0, 0));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k02\"), 0, 0));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k03\"), 0, 0));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k04\"), 10000, 11000));\n   ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k04a\"), 210000, 211000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k05\"),  210000, 211000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k06\"),  510000, 511000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k07\"),  510000, 511000));\n-  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"xyz\"),  610000, 612000));\n-\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k05\"), 210000, 211000));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k06\"), 510000, 511000));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"k07\"), 510000, 511000));\n+  ASSERT_TRUE(Between(c.ApproximateOffsetOf(\"xyz\"), 610000, 612000));\n }\n \n static bool SnappyCompressionSupported() {\n@@ -855,7 +818,7 @@ TEST(TableTest, ApproximateOffsetOfCompressed) {\n \n   // Expected upper and lower bounds of space used by compressible strings.\n   static const int kSlop = 1000;  // Compressor effectiveness varies.\n-  const int expected = 2500;  // 10000 * compression ratio (0.25)\n+  const int expected = 2500;      // 10000 * compression ratio (0.25)\n   const int min_z = expected - kSlop;\n   const int max_z = expected + kSlop;\n \n@@ -871,6 +834,4 @@ TEST(TableTest, ApproximateOffsetOfCompressed) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "144790dd973f7afe6e350932a98844e34c735f96",
        "filename": "src/leveldb/table/two_level_iterator.cc",
        "status": "modified",
        "additions": 40,
        "deletions": 51,
        "changes": 91,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/two_level_iterator.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/two_level_iterator.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/two_level_iterator.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -15,38 +15,33 @@ namespace {\n \n typedef Iterator* (*BlockFunction)(void*, const ReadOptions&, const Slice&);\n \n-class TwoLevelIterator: public Iterator {\n+class TwoLevelIterator : public Iterator {\n  public:\n-  TwoLevelIterator(\n-    Iterator* index_iter,\n-    BlockFunction block_function,\n-    void* arg,\n-    const ReadOptions& options);\n-\n-  virtual ~TwoLevelIterator();\n-\n-  virtual void Seek(const Slice& target);\n-  virtual void SeekToFirst();\n-  virtual void SeekToLast();\n-  virtual void Next();\n-  virtual void Prev();\n-\n-  virtual bool Valid() const {\n-    return data_iter_.Valid();\n-  }\n-  virtual Slice key() const {\n+  TwoLevelIterator(Iterator* index_iter, BlockFunction block_function,\n+                   void* arg, const ReadOptions& options);\n+\n+  ~TwoLevelIterator() override;\n+\n+  void Seek(const Slice& target) override;\n+  void SeekToFirst() override;\n+  void SeekToLast() override;\n+  void Next() override;\n+  void Prev() override;\n+\n+  bool Valid() const override { return data_iter_.Valid(); }\n+  Slice key() const override {\n     assert(Valid());\n     return data_iter_.key();\n   }\n-  virtual Slice value() const {\n+  Slice value() const override {\n     assert(Valid());\n     return data_iter_.value();\n   }\n-  virtual Status status() const {\n+  Status status() const override {\n     // It'd be nice if status() returned a const Status& instead of a Status\n     if (!index_iter_.status().ok()) {\n       return index_iter_.status();\n-    } else if (data_iter_.iter() != NULL && !data_iter_.status().ok()) {\n+    } else if (data_iter_.iter() != nullptr && !data_iter_.status().ok()) {\n       return data_iter_.status();\n     } else {\n       return status_;\n@@ -67,45 +62,41 @@ class TwoLevelIterator: public Iterator {\n   const ReadOptions options_;\n   Status status_;\n   IteratorWrapper index_iter_;\n-  IteratorWrapper data_iter_; // May be NULL\n-  // If data_iter_ is non-NULL, then \"data_block_handle_\" holds the\n+  IteratorWrapper data_iter_;  // May be nullptr\n+  // If data_iter_ is non-null, then \"data_block_handle_\" holds the\n   // \"index_value\" passed to block_function_ to create the data_iter_.\n   std::string data_block_handle_;\n };\n \n-TwoLevelIterator::TwoLevelIterator(\n-    Iterator* index_iter,\n-    BlockFunction block_function,\n-    void* arg,\n-    const ReadOptions& options)\n+TwoLevelIterator::TwoLevelIterator(Iterator* index_iter,\n+                                   BlockFunction block_function, void* arg,\n+                                   const ReadOptions& options)\n     : block_function_(block_function),\n       arg_(arg),\n       options_(options),\n       index_iter_(index_iter),\n-      data_iter_(NULL) {\n-}\n+      data_iter_(nullptr) {}\n \n-TwoLevelIterator::~TwoLevelIterator() {\n-}\n+TwoLevelIterator::~TwoLevelIterator() = default;\n \n void TwoLevelIterator::Seek(const Slice& target) {\n   index_iter_.Seek(target);\n   InitDataBlock();\n-  if (data_iter_.iter() != NULL) data_iter_.Seek(target);\n+  if (data_iter_.iter() != nullptr) data_iter_.Seek(target);\n   SkipEmptyDataBlocksForward();\n }\n \n void TwoLevelIterator::SeekToFirst() {\n   index_iter_.SeekToFirst();\n   InitDataBlock();\n-  if (data_iter_.iter() != NULL) data_iter_.SeekToFirst();\n+  if (data_iter_.iter() != nullptr) data_iter_.SeekToFirst();\n   SkipEmptyDataBlocksForward();\n }\n \n void TwoLevelIterator::SeekToLast() {\n   index_iter_.SeekToLast();\n   InitDataBlock();\n-  if (data_iter_.iter() != NULL) data_iter_.SeekToLast();\n+  if (data_iter_.iter() != nullptr) data_iter_.SeekToLast();\n   SkipEmptyDataBlocksBackward();\n }\n \n@@ -121,44 +112,44 @@ void TwoLevelIterator::Prev() {\n   SkipEmptyDataBlocksBackward();\n }\n \n-\n void TwoLevelIterator::SkipEmptyDataBlocksForward() {\n-  while (data_iter_.iter() == NULL || !data_iter_.Valid()) {\n+  while (data_iter_.iter() == nullptr || !data_iter_.Valid()) {\n     // Move to next block\n     if (!index_iter_.Valid()) {\n-      SetDataIterator(NULL);\n+      SetDataIterator(nullptr);\n       return;\n     }\n     index_iter_.Next();\n     InitDataBlock();\n-    if (data_iter_.iter() != NULL) data_iter_.SeekToFirst();\n+    if (data_iter_.iter() != nullptr) data_iter_.SeekToFirst();\n   }\n }\n \n void TwoLevelIterator::SkipEmptyDataBlocksBackward() {\n-  while (data_iter_.iter() == NULL || !data_iter_.Valid()) {\n+  while (data_iter_.iter() == nullptr || !data_iter_.Valid()) {\n     // Move to next block\n     if (!index_iter_.Valid()) {\n-      SetDataIterator(NULL);\n+      SetDataIterator(nullptr);\n       return;\n     }\n     index_iter_.Prev();\n     InitDataBlock();\n-    if (data_iter_.iter() != NULL) data_iter_.SeekToLast();\n+    if (data_iter_.iter() != nullptr) data_iter_.SeekToLast();\n   }\n }\n \n void TwoLevelIterator::SetDataIterator(Iterator* data_iter) {\n-  if (data_iter_.iter() != NULL) SaveError(data_iter_.status());\n+  if (data_iter_.iter() != nullptr) SaveError(data_iter_.status());\n   data_iter_.Set(data_iter);\n }\n \n void TwoLevelIterator::InitDataBlock() {\n   if (!index_iter_.Valid()) {\n-    SetDataIterator(NULL);\n+    SetDataIterator(nullptr);\n   } else {\n     Slice handle = index_iter_.value();\n-    if (data_iter_.iter() != NULL && handle.compare(data_block_handle_) == 0) {\n+    if (data_iter_.iter() != nullptr &&\n+        handle.compare(data_block_handle_) == 0) {\n       // data_iter_ is already constructed with this iterator, so\n       // no need to change anything\n     } else {\n@@ -171,11 +162,9 @@ void TwoLevelIterator::InitDataBlock() {\n \n }  // namespace\n \n-Iterator* NewTwoLevelIterator(\n-    Iterator* index_iter,\n-    BlockFunction block_function,\n-    void* arg,\n-    const ReadOptions& options) {\n+Iterator* NewTwoLevelIterator(Iterator* index_iter,\n+                              BlockFunction block_function, void* arg,\n+                              const ReadOptions& options) {\n   return new TwoLevelIterator(index_iter, block_function, arg, options);\n }\n "
      },
      {
        "sha": "81ffe809ac77ba52703df5ead573ecb00dcd9983",
        "filename": "src/leveldb/table/two_level_iterator.h",
        "status": "modified",
        "additions": 4,
        "deletions": 7,
        "changes": 11,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/two_level_iterator.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/table/two_level_iterator.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/table/two_level_iterator.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -20,14 +20,11 @@ struct ReadOptions;\n //\n // Uses a supplied function to convert an index_iter value into\n // an iterator over the contents of the corresponding block.\n-extern Iterator* NewTwoLevelIterator(\n+Iterator* NewTwoLevelIterator(\n     Iterator* index_iter,\n-    Iterator* (*block_function)(\n-        void* arg,\n-        const ReadOptions& options,\n-        const Slice& index_value),\n-    void* arg,\n-    const ReadOptions& options);\n+    Iterator* (*block_function)(void* arg, const ReadOptions& options,\n+                                const Slice& index_value),\n+    void* arg, const ReadOptions& options);\n \n }  // namespace leveldb\n "
      },
      {
        "sha": "46e3b2eb8f63b0075d6119699018acf24103b42a",
        "filename": "src/leveldb/util/arena.cc",
        "status": "modified",
        "additions": 8,
        "deletions": 10,
        "changes": 18,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/arena.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/arena.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/arena.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -3,16 +3,13 @@\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n #include \"util/arena.h\"\n-#include <assert.h>\n \n namespace leveldb {\n \n static const int kBlockSize = 4096;\n \n-Arena::Arena() : memory_usage_(0) {\n-  alloc_ptr_ = NULL;  // First allocation will allocate a block\n-  alloc_bytes_remaining_ = 0;\n-}\n+Arena::Arena()\n+    : alloc_ptr_(nullptr), alloc_bytes_remaining_(0), memory_usage_(0) {}\n \n Arena::~Arena() {\n   for (size_t i = 0; i < blocks_.size(); i++) {\n@@ -40,8 +37,9 @@ char* Arena::AllocateFallback(size_t bytes) {\n \n char* Arena::AllocateAligned(size_t bytes) {\n   const int align = (sizeof(void*) > 8) ? sizeof(void*) : 8;\n-  assert((align & (align-1)) == 0);   // Pointer size should be a power of 2\n-  size_t current_mod = reinterpret_cast<uintptr_t>(alloc_ptr_) & (align-1);\n+  static_assert((align & (align - 1)) == 0,\n+                \"Pointer size should be a power of 2\");\n+  size_t current_mod = reinterpret_cast<uintptr_t>(alloc_ptr_) & (align - 1);\n   size_t slop = (current_mod == 0 ? 0 : align - current_mod);\n   size_t needed = bytes + slop;\n   char* result;\n@@ -53,15 +51,15 @@ char* Arena::AllocateAligned(size_t bytes) {\n     // AllocateFallback always returned aligned memory\n     result = AllocateFallback(bytes);\n   }\n-  assert((reinterpret_cast<uintptr_t>(result) & (align-1)) == 0);\n+  assert((reinterpret_cast<uintptr_t>(result) & (align - 1)) == 0);\n   return result;\n }\n \n char* Arena::AllocateNewBlock(size_t block_bytes) {\n   char* result = new char[block_bytes];\n   blocks_.push_back(result);\n-  memory_usage_.NoBarrier_Store(\n-      reinterpret_cast<void*>(MemoryUsage() + block_bytes + sizeof(char*)));\n+  memory_usage_.fetch_add(block_bytes + sizeof(char*),\n+                          std::memory_order_relaxed);\n   return result;\n }\n "
      },
      {
        "sha": "68fc55d4dda7742362e93974725ec36a102a3f6a",
        "filename": "src/leveldb/util/arena.h",
        "status": "modified",
        "additions": 14,
        "deletions": 11,
        "changes": 25,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/arena.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/arena.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/arena.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -5,29 +5,33 @@\n #ifndef STORAGE_LEVELDB_UTIL_ARENA_H_\n #define STORAGE_LEVELDB_UTIL_ARENA_H_\n \n+#include <atomic>\n+#include <cassert>\n+#include <cstddef>\n+#include <cstdint>\n #include <vector>\n-#include <assert.h>\n-#include <stddef.h>\n-#include <stdint.h>\n-#include \"port/port.h\"\n \n namespace leveldb {\n \n class Arena {\n  public:\n   Arena();\n+\n+  Arena(const Arena&) = delete;\n+  Arena& operator=(const Arena&) = delete;\n+\n   ~Arena();\n \n   // Return a pointer to a newly allocated memory block of \"bytes\" bytes.\n   char* Allocate(size_t bytes);\n \n-  // Allocate memory with the normal alignment guarantees provided by malloc\n+  // Allocate memory with the normal alignment guarantees provided by malloc.\n   char* AllocateAligned(size_t bytes);\n \n   // Returns an estimate of the total memory usage of data allocated\n   // by the arena.\n   size_t MemoryUsage() const {\n-    return reinterpret_cast<uintptr_t>(memory_usage_.NoBarrier_Load());\n+    return memory_usage_.load(std::memory_order_relaxed);\n   }\n \n  private:\n@@ -42,11 +46,10 @@ class Arena {\n   std::vector<char*> blocks_;\n \n   // Total memory usage of the arena.\n-  port::AtomicPointer memory_usage_;\n-\n-  // No copying allowed\n-  Arena(const Arena&);\n-  void operator=(const Arena&);\n+  //\n+  // TODO(costan): This member is accessed via atomics, but the others are\n+  //               accessed without any locking. Is this OK?\n+  std::atomic<size_t> memory_usage_;\n };\n \n inline char* Arena::Allocate(size_t bytes) {"
      },
      {
        "sha": "e917228f420729919186465e29531cdc39163e9c",
        "filename": "src/leveldb/util/arena_test.cc",
        "status": "modified",
        "additions": 8,
        "deletions": 11,
        "changes": 19,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/arena_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/arena_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/arena_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -9,14 +9,12 @@\n \n namespace leveldb {\n \n-class ArenaTest { };\n+class ArenaTest {};\n \n-TEST(ArenaTest, Empty) {\n-  Arena arena;\n-}\n+TEST(ArenaTest, Empty) { Arena arena; }\n \n TEST(ArenaTest, Simple) {\n-  std::vector<std::pair<size_t, char*> > allocated;\n+  std::vector<std::pair<size_t, char*>> allocated;\n   Arena arena;\n   const int N = 100000;\n   size_t bytes = 0;\n@@ -26,8 +24,9 @@ TEST(ArenaTest, Simple) {\n     if (i % (N / 10) == 0) {\n       s = i;\n     } else {\n-      s = rnd.OneIn(4000) ? rnd.Uniform(6000) :\n-          (rnd.OneIn(10) ? rnd.Uniform(100) : rnd.Uniform(20));\n+      s = rnd.OneIn(4000)\n+              ? rnd.Uniform(6000)\n+              : (rnd.OneIn(10) ? rnd.Uniform(100) : rnd.Uniform(20));\n     }\n     if (s == 0) {\n       // Our arena disallows size 0 allocations.\n@@ -47,7 +46,7 @@ TEST(ArenaTest, Simple) {\n     bytes += s;\n     allocated.push_back(std::make_pair(s, r));\n     ASSERT_GE(arena.MemoryUsage(), bytes);\n-    if (i > N/10) {\n+    if (i > N / 10) {\n       ASSERT_LE(arena.MemoryUsage(), bytes * 1.10);\n     }\n   }\n@@ -63,6 +62,4 @@ TEST(ArenaTest, Simple) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "87547a7e62cdf9f73a99dde32e2bb9a5b1228f68",
        "filename": "src/leveldb/util/bloom.cc",
        "status": "modified",
        "additions": 12,
        "deletions": 15,
        "changes": 27,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/bloom.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/bloom.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/bloom.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -15,24 +15,17 @@ static uint32_t BloomHash(const Slice& key) {\n }\n \n class BloomFilterPolicy : public FilterPolicy {\n- private:\n-  size_t bits_per_key_;\n-  size_t k_;\n-\n  public:\n-  explicit BloomFilterPolicy(int bits_per_key)\n-      : bits_per_key_(bits_per_key) {\n+  explicit BloomFilterPolicy(int bits_per_key) : bits_per_key_(bits_per_key) {\n     // We intentionally round down to reduce probing cost a little bit\n     k_ = static_cast<size_t>(bits_per_key * 0.69);  // 0.69 =~ ln(2)\n     if (k_ < 1) k_ = 1;\n     if (k_ > 30) k_ = 30;\n   }\n \n-  virtual const char* Name() const {\n-    return \"leveldb.BuiltinBloomFilter2\";\n-  }\n+  const char* Name() const override { return \"leveldb.BuiltinBloomFilter2\"; }\n \n-  virtual void CreateFilter(const Slice* keys, int n, std::string* dst) const {\n+  void CreateFilter(const Slice* keys, int n, std::string* dst) const override {\n     // Compute bloom filter size (in both bits and bytes)\n     size_t bits = n * bits_per_key_;\n \n@@ -54,13 +47,13 @@ class BloomFilterPolicy : public FilterPolicy {\n       const uint32_t delta = (h >> 17) | (h << 15);  // Rotate right 17 bits\n       for (size_t j = 0; j < k_; j++) {\n         const uint32_t bitpos = h % bits;\n-        array[bitpos/8] |= (1 << (bitpos % 8));\n+        array[bitpos / 8] |= (1 << (bitpos % 8));\n         h += delta;\n       }\n     }\n   }\n \n-  virtual bool KeyMayMatch(const Slice& key, const Slice& bloom_filter) const {\n+  bool KeyMayMatch(const Slice& key, const Slice& bloom_filter) const override {\n     const size_t len = bloom_filter.size();\n     if (len < 2) return false;\n \n@@ -69,7 +62,7 @@ class BloomFilterPolicy : public FilterPolicy {\n \n     // Use the encoded k so that we can read filters generated by\n     // bloom filters created using different parameters.\n-    const size_t k = array[len-1];\n+    const size_t k = array[len - 1];\n     if (k > 30) {\n       // Reserved for potentially new encodings for short bloom filters.\n       // Consider it a match.\n@@ -80,13 +73,17 @@ class BloomFilterPolicy : public FilterPolicy {\n     const uint32_t delta = (h >> 17) | (h << 15);  // Rotate right 17 bits\n     for (size_t j = 0; j < k; j++) {\n       const uint32_t bitpos = h % bits;\n-      if ((array[bitpos/8] & (1 << (bitpos % 8))) == 0) return false;\n+      if ((array[bitpos / 8] & (1 << (bitpos % 8))) == 0) return false;\n       h += delta;\n     }\n     return true;\n   }\n+\n+ private:\n+  size_t bits_per_key_;\n+  size_t k_;\n };\n-}\n+}  // namespace\n \n const FilterPolicy* NewBloomFilterPolicy(int bits_per_key) {\n   return new BloomFilterPolicy(bits_per_key);"
      },
      {
        "sha": "436daa9e995738e84ffdf11af9d19e5412fe563b",
        "filename": "src/leveldb/util/bloom_test.cc",
        "status": "modified",
        "additions": 25,
        "deletions": 31,
        "changes": 56,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/bloom_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/bloom_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/bloom_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -19,26 +19,17 @@ static Slice Key(int i, char* buffer) {\n }\n \n class BloomTest {\n- private:\n-  const FilterPolicy* policy_;\n-  std::string filter_;\n-  std::vector<std::string> keys_;\n-\n  public:\n-  BloomTest() : policy_(NewBloomFilterPolicy(10)) { }\n+  BloomTest() : policy_(NewBloomFilterPolicy(10)) {}\n \n-  ~BloomTest() {\n-    delete policy_;\n-  }\n+  ~BloomTest() { delete policy_; }\n \n   void Reset() {\n     keys_.clear();\n     filter_.clear();\n   }\n \n-  void Add(const Slice& s) {\n-    keys_.push_back(s.ToString());\n-  }\n+  void Add(const Slice& s) { keys_.push_back(s.ToString()); }\n \n   void Build() {\n     std::vector<Slice> key_slices;\n@@ -52,16 +43,14 @@ class BloomTest {\n     if (kVerbose >= 2) DumpFilter();\n   }\n \n-  size_t FilterSize() const {\n-    return filter_.size();\n-  }\n+  size_t FilterSize() const { return filter_.size(); }\n \n   void DumpFilter() {\n     fprintf(stderr, \"F(\");\n-    for (size_t i = 0; i+1 < filter_.size(); i++) {\n+    for (size_t i = 0; i + 1 < filter_.size(); i++) {\n       const unsigned int c = static_cast<unsigned int>(filter_[i]);\n       for (int j = 0; j < 8; j++) {\n-        fprintf(stderr, \"%c\", (c & (1 <<j)) ? '1' : '.');\n+        fprintf(stderr, \"%c\", (c & (1 << j)) ? '1' : '.');\n       }\n     }\n     fprintf(stderr, \")\\n\");\n@@ -84,20 +73,25 @@ class BloomTest {\n     }\n     return result / 10000.0;\n   }\n+\n+ private:\n+  const FilterPolicy* policy_;\n+  std::string filter_;\n+  std::vector<std::string> keys_;\n };\n \n TEST(BloomTest, EmptyFilter) {\n-  ASSERT_TRUE(! Matches(\"hello\"));\n-  ASSERT_TRUE(! Matches(\"world\"));\n+  ASSERT_TRUE(!Matches(\"hello\"));\n+  ASSERT_TRUE(!Matches(\"world\"));\n }\n \n TEST(BloomTest, Small) {\n   Add(\"hello\");\n   Add(\"world\");\n   ASSERT_TRUE(Matches(\"hello\"));\n   ASSERT_TRUE(Matches(\"world\"));\n-  ASSERT_TRUE(! Matches(\"x\"));\n-  ASSERT_TRUE(! Matches(\"foo\"));\n+  ASSERT_TRUE(!Matches(\"x\"));\n+  ASSERT_TRUE(!Matches(\"foo\"));\n }\n \n static int NextLength(int length) {\n@@ -140,23 +134,23 @@ TEST(BloomTest, VaryingLengths) {\n     double rate = FalsePositiveRate();\n     if (kVerbose >= 1) {\n       fprintf(stderr, \"False positives: %5.2f%% @ length = %6d ; bytes = %6d\\n\",\n-              rate*100.0, length, static_cast<int>(FilterSize()));\n+              rate * 100.0, length, static_cast<int>(FilterSize()));\n     }\n-    ASSERT_LE(rate, 0.02);   // Must not be over 2%\n-    if (rate > 0.0125) mediocre_filters++;  // Allowed, but not too often\n-    else good_filters++;\n+    ASSERT_LE(rate, 0.02);  // Must not be over 2%\n+    if (rate > 0.0125)\n+      mediocre_filters++;  // Allowed, but not too often\n+    else\n+      good_filters++;\n   }\n   if (kVerbose >= 1) {\n-    fprintf(stderr, \"Filters: %d good, %d mediocre\\n\",\n-            good_filters, mediocre_filters);\n+    fprintf(stderr, \"Filters: %d good, %d mediocre\\n\", good_filters,\n+            mediocre_filters);\n   }\n-  ASSERT_LE(mediocre_filters, good_filters/5);\n+  ASSERT_LE(mediocre_filters, good_filters / 5);\n }\n \n // Different bits-per-byte\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "12de306cad25a675d51f7e8ffd63fbea0fac0690",
        "filename": "src/leveldb/util/cache.cc",
        "status": "modified",
        "additions": 59,
        "deletions": 64,
        "changes": 123,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/cache.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/cache.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/cache.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -8,13 +8,13 @@\n \n #include \"leveldb/cache.h\"\n #include \"port/port.h\"\n+#include \"port/thread_annotations.h\"\n #include \"util/hash.h\"\n #include \"util/mutexlock.h\"\n \n namespace leveldb {\n \n-Cache::~Cache() {\n-}\n+Cache::~Cache() {}\n \n namespace {\n \n@@ -45,21 +45,19 @@ struct LRUHandle {\n   LRUHandle* next_hash;\n   LRUHandle* next;\n   LRUHandle* prev;\n-  size_t charge;      // TODO(opt): Only allow uint32_t?\n+  size_t charge;  // TODO(opt): Only allow uint32_t?\n   size_t key_length;\n-  bool in_cache;      // Whether entry is in the cache.\n-  uint32_t refs;      // References, including cache reference, if present.\n-  uint32_t hash;      // Hash of key(); used for fast sharding and comparisons\n-  char key_data[1];   // Beginning of key\n+  bool in_cache;     // Whether entry is in the cache.\n+  uint32_t refs;     // References, including cache reference, if present.\n+  uint32_t hash;     // Hash of key(); used for fast sharding and comparisons\n+  char key_data[1];  // Beginning of key\n \n   Slice key() const {\n-    // For cheaper lookups, we allow a temporary Handle object\n-    // to store a pointer to a key in \"value\".\n-    if (next == this) {\n-      return *(reinterpret_cast<Slice*>(value));\n-    } else {\n-      return Slice(key_data, key_length);\n-    }\n+    // next_ is only equal to this if the LRU handle is the list head of an\n+    // empty list. List heads never have meaningful keys.\n+    assert(next != this);\n+\n+    return Slice(key_data, key_length);\n   }\n };\n \n@@ -70,7 +68,7 @@ struct LRUHandle {\n // 4.4.3's builtin hashtable.\n class HandleTable {\n  public:\n-  HandleTable() : length_(0), elems_(0), list_(NULL) { Resize(); }\n+  HandleTable() : length_(0), elems_(0), list_(nullptr) { Resize(); }\n   ~HandleTable() { delete[] list_; }\n \n   LRUHandle* Lookup(const Slice& key, uint32_t hash) {\n@@ -80,9 +78,9 @@ class HandleTable {\n   LRUHandle* Insert(LRUHandle* h) {\n     LRUHandle** ptr = FindPointer(h->key(), h->hash);\n     LRUHandle* old = *ptr;\n-    h->next_hash = (old == NULL ? NULL : old->next_hash);\n+    h->next_hash = (old == nullptr ? nullptr : old->next_hash);\n     *ptr = h;\n-    if (old == NULL) {\n+    if (old == nullptr) {\n       ++elems_;\n       if (elems_ > length_) {\n         // Since each cache entry is fairly large, we aim for a small\n@@ -96,7 +94,7 @@ class HandleTable {\n   LRUHandle* Remove(const Slice& key, uint32_t hash) {\n     LRUHandle** ptr = FindPointer(key, hash);\n     LRUHandle* result = *ptr;\n-    if (result != NULL) {\n+    if (result != nullptr) {\n       *ptr = result->next_hash;\n       --elems_;\n     }\n@@ -115,8 +113,7 @@ class HandleTable {\n   // pointer to the trailing slot in the corresponding linked list.\n   LRUHandle** FindPointer(const Slice& key, uint32_t hash) {\n     LRUHandle** ptr = &list_[hash & (length_ - 1)];\n-    while (*ptr != NULL &&\n-           ((*ptr)->hash != hash || key != (*ptr)->key())) {\n+    while (*ptr != nullptr && ((*ptr)->hash != hash || key != (*ptr)->key())) {\n       ptr = &(*ptr)->next_hash;\n     }\n     return ptr;\n@@ -132,7 +129,7 @@ class HandleTable {\n     uint32_t count = 0;\n     for (uint32_t i = 0; i < length_; i++) {\n       LRUHandle* h = list_[i];\n-      while (h != NULL) {\n+      while (h != nullptr) {\n         LRUHandle* next = h->next_hash;\n         uint32_t hash = h->hash;\n         LRUHandle** ptr = &new_list[hash & (new_length - 1)];\n@@ -159,8 +156,8 @@ class LRUCache {\n   void SetCapacity(size_t capacity) { capacity_ = capacity; }\n \n   // Like Cache methods, but with an extra \"hash\" parameter.\n-  Cache::Handle* Insert(const Slice& key, uint32_t hash,\n-                        void* value, size_t charge,\n+  Cache::Handle* Insert(const Slice& key, uint32_t hash, void* value,\n+                        size_t charge,\n                         void (*deleter)(const Slice& key, void* value));\n   Cache::Handle* Lookup(const Slice& key, uint32_t hash);\n   void Release(Cache::Handle* handle);\n@@ -173,32 +170,31 @@ class LRUCache {\n \n  private:\n   void LRU_Remove(LRUHandle* e);\n-  void LRU_Append(LRUHandle*list, LRUHandle* e);\n+  void LRU_Append(LRUHandle* list, LRUHandle* e);\n   void Ref(LRUHandle* e);\n   void Unref(LRUHandle* e);\n-  bool FinishErase(LRUHandle* e);\n+  bool FinishErase(LRUHandle* e) EXCLUSIVE_LOCKS_REQUIRED(mutex_);\n \n   // Initialized before use.\n   size_t capacity_;\n \n   // mutex_ protects the following state.\n   mutable port::Mutex mutex_;\n-  size_t usage_;\n+  size_t usage_ GUARDED_BY(mutex_);\n \n   // Dummy head of LRU list.\n   // lru.prev is newest entry, lru.next is oldest entry.\n   // Entries have refs==1 and in_cache==true.\n-  LRUHandle lru_;\n+  LRUHandle lru_ GUARDED_BY(mutex_);\n \n   // Dummy head of in-use list.\n   // Entries are in use by clients, and have refs >= 2 and in_cache==true.\n-  LRUHandle in_use_;\n+  LRUHandle in_use_ GUARDED_BY(mutex_);\n \n-  HandleTable table_;\n+  HandleTable table_ GUARDED_BY(mutex_);\n };\n \n-LRUCache::LRUCache()\n-    : usage_(0) {\n+LRUCache::LRUCache() : capacity_(0), usage_(0) {\n   // Make empty circular linked lists.\n   lru_.next = &lru_;\n   lru_.prev = &lru_;\n@@ -208,7 +204,7 @@ LRUCache::LRUCache()\n \n LRUCache::~LRUCache() {\n   assert(in_use_.next == &in_use_);  // Error if caller has an unreleased handle\n-  for (LRUHandle* e = lru_.next; e != &lru_; ) {\n+  for (LRUHandle* e = lru_.next; e != &lru_;) {\n     LRUHandle* next = e->next;\n     assert(e->in_cache);\n     e->in_cache = false;\n@@ -229,11 +225,12 @@ void LRUCache::Ref(LRUHandle* e) {\n void LRUCache::Unref(LRUHandle* e) {\n   assert(e->refs > 0);\n   e->refs--;\n-  if (e->refs == 0) { // Deallocate.\n+  if (e->refs == 0) {  // Deallocate.\n     assert(!e->in_cache);\n     (*e->deleter)(e->key(), e->value);\n     free(e);\n-  } else if (e->in_cache && e->refs == 1) {  // No longer in use; move to lru_ list.\n+  } else if (e->in_cache && e->refs == 1) {\n+    // No longer in use; move to lru_ list.\n     LRU_Remove(e);\n     LRU_Append(&lru_, e);\n   }\n@@ -255,7 +252,7 @@ void LRUCache::LRU_Append(LRUHandle* list, LRUHandle* e) {\n Cache::Handle* LRUCache::Lookup(const Slice& key, uint32_t hash) {\n   MutexLock l(&mutex_);\n   LRUHandle* e = table_.Lookup(key, hash);\n-  if (e != NULL) {\n+  if (e != nullptr) {\n     Ref(e);\n   }\n   return reinterpret_cast<Cache::Handle*>(e);\n@@ -266,13 +263,14 @@ void LRUCache::Release(Cache::Handle* handle) {\n   Unref(reinterpret_cast<LRUHandle*>(handle));\n }\n \n-Cache::Handle* LRUCache::Insert(\n-    const Slice& key, uint32_t hash, void* value, size_t charge,\n-    void (*deleter)(const Slice& key, void* value)) {\n+Cache::Handle* LRUCache::Insert(const Slice& key, uint32_t hash, void* value,\n+                                size_t charge,\n+                                void (*deleter)(const Slice& key,\n+                                                void* value)) {\n   MutexLock l(&mutex_);\n \n-  LRUHandle* e = reinterpret_cast<LRUHandle*>(\n-      malloc(sizeof(LRUHandle)-1 + key.size()));\n+  LRUHandle* e =\n+      reinterpret_cast<LRUHandle*>(malloc(sizeof(LRUHandle) - 1 + key.size()));\n   e->value = value;\n   e->deleter = deleter;\n   e->charge = charge;\n@@ -288,8 +286,10 @@ Cache::Handle* LRUCache::Insert(\n     LRU_Append(&in_use_, e);\n     usage_ += charge;\n     FinishErase(table_.Insert(e));\n-  } // else don't cache.  (Tests use capacity_==0 to turn off caching.)\n-\n+  } else {  // don't cache. (capacity_==0 is supported and turns off caching.)\n+    // next is read by key() in an assert, so it must be initialized\n+    e->next = nullptr;\n+  }\n   while (usage_ > capacity_ && lru_.next != &lru_) {\n     LRUHandle* old = lru_.next;\n     assert(old->refs == 1);\n@@ -302,17 +302,17 @@ Cache::Handle* LRUCache::Insert(\n   return reinterpret_cast<Cache::Handle*>(e);\n }\n \n-// If e != NULL, finish removing *e from the cache; it has already been removed\n-// from the hash table.  Return whether e != NULL.  Requires mutex_ held.\n+// If e != nullptr, finish removing *e from the cache; it has already been\n+// removed from the hash table.  Return whether e != nullptr.\n bool LRUCache::FinishErase(LRUHandle* e) {\n-  if (e != NULL) {\n+  if (e != nullptr) {\n     assert(e->in_cache);\n     LRU_Remove(e);\n     e->in_cache = false;\n     usage_ -= e->charge;\n     Unref(e);\n   }\n-  return e != NULL;\n+  return e != nullptr;\n }\n \n void LRUCache::Erase(const Slice& key, uint32_t hash) {\n@@ -345,49 +345,46 @@ class ShardedLRUCache : public Cache {\n     return Hash(s.data(), s.size(), 0);\n   }\n \n-  static uint32_t Shard(uint32_t hash) {\n-    return hash >> (32 - kNumShardBits);\n-  }\n+  static uint32_t Shard(uint32_t hash) { return hash >> (32 - kNumShardBits); }\n \n  public:\n-  explicit ShardedLRUCache(size_t capacity)\n-      : last_id_(0) {\n+  explicit ShardedLRUCache(size_t capacity) : last_id_(0) {\n     const size_t per_shard = (capacity + (kNumShards - 1)) / kNumShards;\n     for (int s = 0; s < kNumShards; s++) {\n       shard_[s].SetCapacity(per_shard);\n     }\n   }\n-  virtual ~ShardedLRUCache() { }\n-  virtual Handle* Insert(const Slice& key, void* value, size_t charge,\n-                         void (*deleter)(const Slice& key, void* value)) {\n+  ~ShardedLRUCache() override {}\n+  Handle* Insert(const Slice& key, void* value, size_t charge,\n+                 void (*deleter)(const Slice& key, void* value)) override {\n     const uint32_t hash = HashSlice(key);\n     return shard_[Shard(hash)].Insert(key, hash, value, charge, deleter);\n   }\n-  virtual Handle* Lookup(const Slice& key) {\n+  Handle* Lookup(const Slice& key) override {\n     const uint32_t hash = HashSlice(key);\n     return shard_[Shard(hash)].Lookup(key, hash);\n   }\n-  virtual void Release(Handle* handle) {\n+  void Release(Handle* handle) override {\n     LRUHandle* h = reinterpret_cast<LRUHandle*>(handle);\n     shard_[Shard(h->hash)].Release(handle);\n   }\n-  virtual void Erase(const Slice& key) {\n+  void Erase(const Slice& key) override {\n     const uint32_t hash = HashSlice(key);\n     shard_[Shard(hash)].Erase(key, hash);\n   }\n-  virtual void* Value(Handle* handle) {\n+  void* Value(Handle* handle) override {\n     return reinterpret_cast<LRUHandle*>(handle)->value;\n   }\n-  virtual uint64_t NewId() {\n+  uint64_t NewId() override {\n     MutexLock l(&id_mutex_);\n     return ++(last_id_);\n   }\n-  virtual void Prune() {\n+  void Prune() override {\n     for (int s = 0; s < kNumShards; s++) {\n       shard_[s].Prune();\n     }\n   }\n-  virtual size_t TotalCharge() const {\n+  size_t TotalCharge() const override {\n     size_t total = 0;\n     for (int s = 0; s < kNumShards; s++) {\n       total += shard_[s].TotalCharge();\n@@ -398,8 +395,6 @@ class ShardedLRUCache : public Cache {\n \n }  // end anonymous namespace\n \n-Cache* NewLRUCache(size_t capacity) {\n-  return new ShardedLRUCache(capacity);\n-}\n+Cache* NewLRUCache(size_t capacity) { return new ShardedLRUCache(capacity); }\n \n }  // namespace leveldb"
      },
      {
        "sha": "974334b9f8e805ddf03197571696d6536047c8ee",
        "filename": "src/leveldb/util/cache_test.cc",
        "status": "modified",
        "additions": 30,
        "deletions": 30,
        "changes": 60,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/cache_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/cache_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/cache_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -25,8 +25,6 @@ static int DecodeValue(void* v) { return reinterpret_cast<uintptr_t>(v); }\n \n class CacheTest {\n  public:\n-  static CacheTest* current_;\n-\n   static void Deleter(const Slice& key, void* v) {\n     current_->deleted_keys_.push_back(DecodeKey(key));\n     current_->deleted_values_.push_back(DecodeValue(v));\n@@ -37,18 +35,14 @@ class CacheTest {\n   std::vector<int> deleted_values_;\n   Cache* cache_;\n \n-  CacheTest() : cache_(NewLRUCache(kCacheSize)) {\n-    current_ = this;\n-  }\n+  CacheTest() : cache_(NewLRUCache(kCacheSize)) { current_ = this; }\n \n-  ~CacheTest() {\n-    delete cache_;\n-  }\n+  ~CacheTest() { delete cache_; }\n \n   int Lookup(int key) {\n     Cache::Handle* handle = cache_->Lookup(EncodeKey(key));\n-    const int r = (handle == NULL) ? -1 : DecodeValue(cache_->Value(handle));\n-    if (handle != NULL) {\n+    const int r = (handle == nullptr) ? -1 : DecodeValue(cache_->Value(handle));\n+    if (handle != nullptr) {\n       cache_->Release(handle);\n     }\n     return r;\n@@ -64,9 +58,9 @@ class CacheTest {\n                           &CacheTest::Deleter);\n   }\n \n-  void Erase(int key) {\n-    cache_->Erase(EncodeKey(key));\n-  }\n+  void Erase(int key) { cache_->Erase(EncodeKey(key)); }\n+\n+  static CacheTest* current_;\n };\n CacheTest* CacheTest::current_;\n \n@@ -75,18 +69,18 @@ TEST(CacheTest, HitAndMiss) {\n \n   Insert(100, 101);\n   ASSERT_EQ(101, Lookup(100));\n-  ASSERT_EQ(-1,  Lookup(200));\n-  ASSERT_EQ(-1,  Lookup(300));\n+  ASSERT_EQ(-1, Lookup(200));\n+  ASSERT_EQ(-1, Lookup(300));\n \n   Insert(200, 201);\n   ASSERT_EQ(101, Lookup(100));\n   ASSERT_EQ(201, Lookup(200));\n-  ASSERT_EQ(-1,  Lookup(300));\n+  ASSERT_EQ(-1, Lookup(300));\n \n   Insert(100, 102);\n   ASSERT_EQ(102, Lookup(100));\n   ASSERT_EQ(201, Lookup(200));\n-  ASSERT_EQ(-1,  Lookup(300));\n+  ASSERT_EQ(-1, Lookup(300));\n \n   ASSERT_EQ(1, deleted_keys_.size());\n   ASSERT_EQ(100, deleted_keys_[0]);\n@@ -100,14 +94,14 @@ TEST(CacheTest, Erase) {\n   Insert(100, 101);\n   Insert(200, 201);\n   Erase(100);\n-  ASSERT_EQ(-1,  Lookup(100));\n+  ASSERT_EQ(-1, Lookup(100));\n   ASSERT_EQ(201, Lookup(200));\n   ASSERT_EQ(1, deleted_keys_.size());\n   ASSERT_EQ(100, deleted_keys_[0]);\n   ASSERT_EQ(101, deleted_values_[0]);\n \n   Erase(100);\n-  ASSERT_EQ(-1,  Lookup(100));\n+  ASSERT_EQ(-1, Lookup(100));\n   ASSERT_EQ(201, Lookup(200));\n   ASSERT_EQ(1, deleted_keys_.size());\n }\n@@ -146,8 +140,8 @@ TEST(CacheTest, EvictionPolicy) {\n   // Frequently used entry must be kept around,\n   // as must things that are still in use.\n   for (int i = 0; i < kCacheSize + 100; i++) {\n-    Insert(1000+i, 2000+i);\n-    ASSERT_EQ(2000+i, Lookup(1000+i));\n+    Insert(1000 + i, 2000 + i);\n+    ASSERT_EQ(2000 + i, Lookup(1000 + i));\n     ASSERT_EQ(101, Lookup(100));\n   }\n   ASSERT_EQ(101, Lookup(100));\n@@ -160,12 +154,12 @@ TEST(CacheTest, UseExceedsCacheSize) {\n   // Overfill the cache, keeping handles on all inserted entries.\n   std::vector<Cache::Handle*> h;\n   for (int i = 0; i < kCacheSize + 100; i++) {\n-    h.push_back(InsertAndReturnHandle(1000+i, 2000+i));\n+    h.push_back(InsertAndReturnHandle(1000 + i, 2000 + i));\n   }\n \n   // Check that all the entries can be found in the cache.\n   for (int i = 0; i < h.size(); i++) {\n-    ASSERT_EQ(2000+i, Lookup(1000+i));\n+    ASSERT_EQ(2000 + i, Lookup(1000 + i));\n   }\n \n   for (int i = 0; i < h.size(); i++) {\n@@ -181,9 +175,9 @@ TEST(CacheTest, HeavyEntries) {\n   const int kHeavy = 10;\n   int added = 0;\n   int index = 0;\n-  while (added < 2*kCacheSize) {\n+  while (added < 2 * kCacheSize) {\n     const int weight = (index & 1) ? kLight : kHeavy;\n-    Insert(index, 1000+index, weight);\n+    Insert(index, 1000 + index, weight);\n     added += weight;\n     index++;\n   }\n@@ -194,10 +188,10 @@ TEST(CacheTest, HeavyEntries) {\n     int r = Lookup(i);\n     if (r >= 0) {\n       cached_weight += weight;\n-      ASSERT_EQ(1000+i, r);\n+      ASSERT_EQ(1000 + i, r);\n     }\n   }\n-  ASSERT_LE(cached_weight, kCacheSize + kCacheSize/10);\n+  ASSERT_LE(cached_weight, kCacheSize + kCacheSize / 10);\n }\n \n TEST(CacheTest, NewId) {\n@@ -219,8 +213,14 @@ TEST(CacheTest, Prune) {\n   ASSERT_EQ(-1, Lookup(2));\n }\n \n-}  // namespace leveldb\n+TEST(CacheTest, ZeroSizeCache) {\n+  delete cache_;\n+  cache_ = NewLRUCache(0);\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n+  Insert(1, 100);\n+  ASSERT_EQ(-1, Lookup(1));\n }\n+\n+}  // namespace leveldb\n+\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "df3fa10f0da9c9a7fef69c5577e5c9519dbbfd3c",
        "filename": "src/leveldb/util/coding.cc",
        "status": "modified",
        "additions": 28,
        "deletions": 56,
        "changes": 84,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/coding.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/coding.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/coding.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -6,32 +6,6 @@\n \n namespace leveldb {\n \n-void EncodeFixed32(char* buf, uint32_t value) {\n-  if (port::kLittleEndian) {\n-    memcpy(buf, &value, sizeof(value));\n-  } else {\n-    buf[0] = value & 0xff;\n-    buf[1] = (value >> 8) & 0xff;\n-    buf[2] = (value >> 16) & 0xff;\n-    buf[3] = (value >> 24) & 0xff;\n-  }\n-}\n-\n-void EncodeFixed64(char* buf, uint64_t value) {\n-  if (port::kLittleEndian) {\n-    memcpy(buf, &value, sizeof(value));\n-  } else {\n-    buf[0] = value & 0xff;\n-    buf[1] = (value >> 8) & 0xff;\n-    buf[2] = (value >> 16) & 0xff;\n-    buf[3] = (value >> 24) & 0xff;\n-    buf[4] = (value >> 32) & 0xff;\n-    buf[5] = (value >> 40) & 0xff;\n-    buf[6] = (value >> 48) & 0xff;\n-    buf[7] = (value >> 56) & 0xff;\n-  }\n-}\n-\n void PutFixed32(std::string* dst, uint32_t value) {\n   char buf[sizeof(value)];\n   EncodeFixed32(buf, value);\n@@ -46,28 +20,28 @@ void PutFixed64(std::string* dst, uint64_t value) {\n \n char* EncodeVarint32(char* dst, uint32_t v) {\n   // Operate on characters as unsigneds\n-  unsigned char* ptr = reinterpret_cast<unsigned char*>(dst);\n+  uint8_t* ptr = reinterpret_cast<uint8_t*>(dst);\n   static const int B = 128;\n-  if (v < (1<<7)) {\n+  if (v < (1 << 7)) {\n     *(ptr++) = v;\n-  } else if (v < (1<<14)) {\n+  } else if (v < (1 << 14)) {\n     *(ptr++) = v | B;\n-    *(ptr++) = v>>7;\n-  } else if (v < (1<<21)) {\n+    *(ptr++) = v >> 7;\n+  } else if (v < (1 << 21)) {\n     *(ptr++) = v | B;\n-    *(ptr++) = (v>>7) | B;\n-    *(ptr++) = v>>14;\n-  } else if (v < (1<<28)) {\n+    *(ptr++) = (v >> 7) | B;\n+    *(ptr++) = v >> 14;\n+  } else if (v < (1 << 28)) {\n     *(ptr++) = v | B;\n-    *(ptr++) = (v>>7) | B;\n-    *(ptr++) = (v>>14) | B;\n-    *(ptr++) = v>>21;\n+    *(ptr++) = (v >> 7) | B;\n+    *(ptr++) = (v >> 14) | B;\n+    *(ptr++) = v >> 21;\n   } else {\n     *(ptr++) = v | B;\n-    *(ptr++) = (v>>7) | B;\n-    *(ptr++) = (v>>14) | B;\n-    *(ptr++) = (v>>21) | B;\n-    *(ptr++) = v>>28;\n+    *(ptr++) = (v >> 7) | B;\n+    *(ptr++) = (v >> 14) | B;\n+    *(ptr++) = (v >> 21) | B;\n+    *(ptr++) = v >> 28;\n   }\n   return reinterpret_cast<char*>(ptr);\n }\n@@ -80,12 +54,12 @@ void PutVarint32(std::string* dst, uint32_t v) {\n \n char* EncodeVarint64(char* dst, uint64_t v) {\n   static const int B = 128;\n-  unsigned char* ptr = reinterpret_cast<unsigned char*>(dst);\n+  uint8_t* ptr = reinterpret_cast<uint8_t*>(dst);\n   while (v >= B) {\n-    *(ptr++) = (v & (B-1)) | B;\n+    *(ptr++) = v | B;\n     v >>= 7;\n   }\n-  *(ptr++) = static_cast<unsigned char>(v);\n+  *(ptr++) = static_cast<uint8_t>(v);\n   return reinterpret_cast<char*>(ptr);\n }\n \n@@ -109,12 +83,11 @@ int VarintLength(uint64_t v) {\n   return len;\n }\n \n-const char* GetVarint32PtrFallback(const char* p,\n-                                   const char* limit,\n+const char* GetVarint32PtrFallback(const char* p, const char* limit,\n                                    uint32_t* value) {\n   uint32_t result = 0;\n   for (uint32_t shift = 0; shift <= 28 && p < limit; shift += 7) {\n-    uint32_t byte = *(reinterpret_cast<const unsigned char*>(p));\n+    uint32_t byte = *(reinterpret_cast<const uint8_t*>(p));\n     p++;\n     if (byte & 128) {\n       // More bytes are present\n@@ -125,14 +98,14 @@ const char* GetVarint32PtrFallback(const char* p,\n       return reinterpret_cast<const char*>(p);\n     }\n   }\n-  return NULL;\n+  return nullptr;\n }\n \n bool GetVarint32(Slice* input, uint32_t* value) {\n   const char* p = input->data();\n   const char* limit = p + input->size();\n   const char* q = GetVarint32Ptr(p, limit, value);\n-  if (q == NULL) {\n+  if (q == nullptr) {\n     return false;\n   } else {\n     *input = Slice(q, limit - q);\n@@ -143,7 +116,7 @@ bool GetVarint32(Slice* input, uint32_t* value) {\n const char* GetVarint64Ptr(const char* p, const char* limit, uint64_t* value) {\n   uint64_t result = 0;\n   for (uint32_t shift = 0; shift <= 63 && p < limit; shift += 7) {\n-    uint64_t byte = *(reinterpret_cast<const unsigned char*>(p));\n+    uint64_t byte = *(reinterpret_cast<const uint8_t*>(p));\n     p++;\n     if (byte & 128) {\n       // More bytes are present\n@@ -154,14 +127,14 @@ const char* GetVarint64Ptr(const char* p, const char* limit, uint64_t* value) {\n       return reinterpret_cast<const char*>(p);\n     }\n   }\n-  return NULL;\n+  return nullptr;\n }\n \n bool GetVarint64(Slice* input, uint64_t* value) {\n   const char* p = input->data();\n   const char* limit = p + input->size();\n   const char* q = GetVarint64Ptr(p, limit, value);\n-  if (q == NULL) {\n+  if (q == nullptr) {\n     return false;\n   } else {\n     *input = Slice(q, limit - q);\n@@ -173,16 +146,15 @@ const char* GetLengthPrefixedSlice(const char* p, const char* limit,\n                                    Slice* result) {\n   uint32_t len;\n   p = GetVarint32Ptr(p, limit, &len);\n-  if (p == NULL) return NULL;\n-  if (p + len > limit) return NULL;\n+  if (p == nullptr) return nullptr;\n+  if (p + len > limit) return nullptr;\n   *result = Slice(p, len);\n   return p + len;\n }\n \n bool GetLengthPrefixedSlice(Slice* input, Slice* result) {\n   uint32_t len;\n-  if (GetVarint32(input, &len) &&\n-      input->size() >= len) {\n+  if (GetVarint32(input, &len) && input->size() >= len) {\n     *result = Slice(input->data(), len);\n     input->remove_prefix(len);\n     return true;"
      },
      {
        "sha": "1983ae71730dd0a407352e22a34092376c84178a",
        "filename": "src/leveldb/util/coding.h",
        "status": "modified",
        "additions": 98,
        "deletions": 38,
        "changes": 136,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/coding.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/coding.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/coding.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -10,87 +10,147 @@\n #ifndef STORAGE_LEVELDB_UTIL_CODING_H_\n #define STORAGE_LEVELDB_UTIL_CODING_H_\n \n-#include <stdint.h>\n-#include <string.h>\n+#include <cstdint>\n+#include <cstring>\n #include <string>\n+\n #include \"leveldb/slice.h\"\n #include \"port/port.h\"\n \n namespace leveldb {\n \n // Standard Put... routines append to a string\n-extern void PutFixed32(std::string* dst, uint32_t value);\n-extern void PutFixed64(std::string* dst, uint64_t value);\n-extern void PutVarint32(std::string* dst, uint32_t value);\n-extern void PutVarint64(std::string* dst, uint64_t value);\n-extern void PutLengthPrefixedSlice(std::string* dst, const Slice& value);\n+void PutFixed32(std::string* dst, uint32_t value);\n+void PutFixed64(std::string* dst, uint64_t value);\n+void PutVarint32(std::string* dst, uint32_t value);\n+void PutVarint64(std::string* dst, uint64_t value);\n+void PutLengthPrefixedSlice(std::string* dst, const Slice& value);\n \n // Standard Get... routines parse a value from the beginning of a Slice\n // and advance the slice past the parsed value.\n-extern bool GetVarint32(Slice* input, uint32_t* value);\n-extern bool GetVarint64(Slice* input, uint64_t* value);\n-extern bool GetLengthPrefixedSlice(Slice* input, Slice* result);\n+bool GetVarint32(Slice* input, uint32_t* value);\n+bool GetVarint64(Slice* input, uint64_t* value);\n+bool GetLengthPrefixedSlice(Slice* input, Slice* result);\n \n // Pointer-based variants of GetVarint...  These either store a value\n // in *v and return a pointer just past the parsed value, or return\n-// NULL on error.  These routines only look at bytes in the range\n+// nullptr on error.  These routines only look at bytes in the range\n // [p..limit-1]\n-extern const char* GetVarint32Ptr(const char* p,const char* limit, uint32_t* v);\n-extern const char* GetVarint64Ptr(const char* p,const char* limit, uint64_t* v);\n+const char* GetVarint32Ptr(const char* p, const char* limit, uint32_t* v);\n+const char* GetVarint64Ptr(const char* p, const char* limit, uint64_t* v);\n \n // Returns the length of the varint32 or varint64 encoding of \"v\"\n-extern int VarintLength(uint64_t v);\n+int VarintLength(uint64_t v);\n \n // Lower-level versions of Put... that write directly into a character buffer\n+// and return a pointer just past the last byte written.\n // REQUIRES: dst has enough space for the value being written\n-extern void EncodeFixed32(char* dst, uint32_t value);\n-extern void EncodeFixed64(char* dst, uint64_t value);\n+char* EncodeVarint32(char* dst, uint32_t value);\n+char* EncodeVarint64(char* dst, uint64_t value);\n+\n+// TODO(costan): Remove port::kLittleEndian and the fast paths based on\n+//               std::memcpy when clang learns to optimize the generic code, as\n+//               described in https://bugs.llvm.org/show_bug.cgi?id=41761\n+//\n+// The platform-independent code in DecodeFixed{32,64}() gets optimized to mov\n+// on x86 and ldr on ARM64, by both clang and gcc. However, only gcc optimizes\n+// the platform-independent code in EncodeFixed{32,64}() to mov / str.\n \n // Lower-level versions of Put... that write directly into a character buffer\n-// and return a pointer just past the last byte written.\n // REQUIRES: dst has enough space for the value being written\n-extern char* EncodeVarint32(char* dst, uint32_t value);\n-extern char* EncodeVarint64(char* dst, uint64_t value);\n+\n+inline void EncodeFixed32(char* dst, uint32_t value) {\n+  uint8_t* const buffer = reinterpret_cast<uint8_t*>(dst);\n+\n+  if (port::kLittleEndian) {\n+    // Fast path for little-endian CPUs. All major compilers optimize this to a\n+    // single mov (x86_64) / str (ARM) instruction.\n+    std::memcpy(buffer, &value, sizeof(uint32_t));\n+    return;\n+  }\n+\n+  // Platform-independent code.\n+  // Currently, only gcc optimizes this to a single mov / str instruction.\n+  buffer[0] = static_cast<uint8_t>(value);\n+  buffer[1] = static_cast<uint8_t>(value >> 8);\n+  buffer[2] = static_cast<uint8_t>(value >> 16);\n+  buffer[3] = static_cast<uint8_t>(value >> 24);\n+}\n+\n+inline void EncodeFixed64(char* dst, uint64_t value) {\n+  uint8_t* const buffer = reinterpret_cast<uint8_t*>(dst);\n+\n+  if (port::kLittleEndian) {\n+    // Fast path for little-endian CPUs. All major compilers optimize this to a\n+    // single mov (x86_64) / str (ARM) instruction.\n+    std::memcpy(buffer, &value, sizeof(uint64_t));\n+    return;\n+  }\n+\n+  // Platform-independent code.\n+  // Currently, only gcc optimizes this to a single mov / str instruction.\n+  buffer[0] = static_cast<uint8_t>(value);\n+  buffer[1] = static_cast<uint8_t>(value >> 8);\n+  buffer[2] = static_cast<uint8_t>(value >> 16);\n+  buffer[3] = static_cast<uint8_t>(value >> 24);\n+  buffer[4] = static_cast<uint8_t>(value >> 32);\n+  buffer[5] = static_cast<uint8_t>(value >> 40);\n+  buffer[6] = static_cast<uint8_t>(value >> 48);\n+  buffer[7] = static_cast<uint8_t>(value >> 56);\n+}\n \n // Lower-level versions of Get... that read directly from a character buffer\n // without any bounds checking.\n \n inline uint32_t DecodeFixed32(const char* ptr) {\n+  const uint8_t* const buffer = reinterpret_cast<const uint8_t*>(ptr);\n+\n   if (port::kLittleEndian) {\n-    // Load the raw bytes\n+    // Fast path for little-endian CPUs. All major compilers optimize this to a\n+    // single mov (x86_64) / ldr (ARM) instruction.\n     uint32_t result;\n-    memcpy(&result, ptr, sizeof(result));  // gcc optimizes this to a plain load\n+    std::memcpy(&result, buffer, sizeof(uint32_t));\n     return result;\n-  } else {\n-    return ((static_cast<uint32_t>(static_cast<unsigned char>(ptr[0])))\n-        | (static_cast<uint32_t>(static_cast<unsigned char>(ptr[1])) << 8)\n-        | (static_cast<uint32_t>(static_cast<unsigned char>(ptr[2])) << 16)\n-        | (static_cast<uint32_t>(static_cast<unsigned char>(ptr[3])) << 24));\n   }\n+\n+  // Platform-independent code.\n+  // Clang and gcc optimize this to a single mov / ldr instruction.\n+  return (static_cast<uint32_t>(buffer[0])) |\n+         (static_cast<uint32_t>(buffer[1]) << 8) |\n+         (static_cast<uint32_t>(buffer[2]) << 16) |\n+         (static_cast<uint32_t>(buffer[3]) << 24);\n }\n \n inline uint64_t DecodeFixed64(const char* ptr) {\n+  const uint8_t* const buffer = reinterpret_cast<const uint8_t*>(ptr);\n+\n   if (port::kLittleEndian) {\n-    // Load the raw bytes\n+    // Fast path for little-endian CPUs. All major compilers optimize this to a\n+    // single mov (x86_64) / ldr (ARM) instruction.\n     uint64_t result;\n-    memcpy(&result, ptr, sizeof(result));  // gcc optimizes this to a plain load\n+    std::memcpy(&result, buffer, sizeof(uint64_t));\n     return result;\n-  } else {\n-    uint64_t lo = DecodeFixed32(ptr);\n-    uint64_t hi = DecodeFixed32(ptr + 4);\n-    return (hi << 32) | lo;\n   }\n+\n+  // Platform-independent code.\n+  // Clang and gcc optimize this to a single mov / ldr instruction.\n+  return (static_cast<uint64_t>(buffer[0])) |\n+         (static_cast<uint64_t>(buffer[1]) << 8) |\n+         (static_cast<uint64_t>(buffer[2]) << 16) |\n+         (static_cast<uint64_t>(buffer[3]) << 24) |\n+         (static_cast<uint64_t>(buffer[4]) << 32) |\n+         (static_cast<uint64_t>(buffer[5]) << 40) |\n+         (static_cast<uint64_t>(buffer[6]) << 48) |\n+         (static_cast<uint64_t>(buffer[7]) << 56);\n }\n \n // Internal routine for use by fallback path of GetVarint32Ptr\n-extern const char* GetVarint32PtrFallback(const char* p,\n-                                          const char* limit,\n-                                          uint32_t* value);\n-inline const char* GetVarint32Ptr(const char* p,\n-                                  const char* limit,\n+const char* GetVarint32PtrFallback(const char* p, const char* limit,\n+                                   uint32_t* value);\n+inline const char* GetVarint32Ptr(const char* p, const char* limit,\n                                   uint32_t* value) {\n   if (p < limit) {\n-    uint32_t result = *(reinterpret_cast<const unsigned char*>(p));\n+    uint32_t result = *(reinterpret_cast<const uint8_t*>(p));\n     if ((result & 128) == 0) {\n       *value = result;\n       return p + 1;"
      },
      {
        "sha": "0d2a0c51f69e094e146844d97c94a7306e24a676",
        "filename": "src/leveldb/util/coding_test.cc",
        "status": "modified",
        "additions": 21,
        "deletions": 21,
        "changes": 42,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/coding_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/coding_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/coding_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -2,13 +2,14 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include \"util/coding.h\"\n+#include <vector>\n \n+#include \"util/coding.h\"\n #include \"util/testharness.h\"\n \n namespace leveldb {\n \n-class Coding { };\n+class Coding {};\n \n TEST(Coding, Fixed32) {\n   std::string s;\n@@ -38,15 +39,15 @@ TEST(Coding, Fixed64) {\n     uint64_t v = static_cast<uint64_t>(1) << power;\n     uint64_t actual;\n     actual = DecodeFixed64(p);\n-    ASSERT_EQ(v-1, actual);\n+    ASSERT_EQ(v - 1, actual);\n     p += sizeof(uint64_t);\n \n     actual = DecodeFixed64(p);\n-    ASSERT_EQ(v+0, actual);\n+    ASSERT_EQ(v + 0, actual);\n     p += sizeof(uint64_t);\n \n     actual = DecodeFixed64(p);\n-    ASSERT_EQ(v+1, actual);\n+    ASSERT_EQ(v + 1, actual);\n     p += sizeof(uint64_t);\n   }\n }\n@@ -88,7 +89,7 @@ TEST(Coding, Varint32) {\n     uint32_t actual;\n     const char* start = p;\n     p = GetVarint32Ptr(p, limit, &actual);\n-    ASSERT_TRUE(p != NULL);\n+    ASSERT_TRUE(p != nullptr);\n     ASSERT_EQ(expected, actual);\n     ASSERT_EQ(VarintLength(actual), p - start);\n   }\n@@ -107,8 +108,8 @@ TEST(Coding, Varint64) {\n     // Test values near powers of two\n     const uint64_t power = 1ull << k;\n     values.push_back(power);\n-    values.push_back(power-1);\n-    values.push_back(power+1);\n+    values.push_back(power - 1);\n+    values.push_back(power + 1);\n   }\n \n   std::string s;\n@@ -123,19 +124,18 @@ TEST(Coding, Varint64) {\n     uint64_t actual;\n     const char* start = p;\n     p = GetVarint64Ptr(p, limit, &actual);\n-    ASSERT_TRUE(p != NULL);\n+    ASSERT_TRUE(p != nullptr);\n     ASSERT_EQ(values[i], actual);\n     ASSERT_EQ(VarintLength(actual), p - start);\n   }\n   ASSERT_EQ(p, limit);\n-\n }\n \n TEST(Coding, Varint32Overflow) {\n   uint32_t result;\n   std::string input(\"\\x81\\x82\\x83\\x84\\x85\\x11\");\n-  ASSERT_TRUE(GetVarint32Ptr(input.data(), input.data() + input.size(), &result)\n-              == NULL);\n+  ASSERT_TRUE(GetVarint32Ptr(input.data(), input.data() + input.size(),\n+                             &result) == nullptr);\n }\n \n TEST(Coding, Varint32Truncation) {\n@@ -144,17 +144,18 @@ TEST(Coding, Varint32Truncation) {\n   PutVarint32(&s, large_value);\n   uint32_t result;\n   for (size_t len = 0; len < s.size() - 1; len++) {\n-    ASSERT_TRUE(GetVarint32Ptr(s.data(), s.data() + len, &result) == NULL);\n+    ASSERT_TRUE(GetVarint32Ptr(s.data(), s.data() + len, &result) == nullptr);\n   }\n-  ASSERT_TRUE(GetVarint32Ptr(s.data(), s.data() + s.size(), &result) != NULL);\n+  ASSERT_TRUE(GetVarint32Ptr(s.data(), s.data() + s.size(), &result) !=\n+              nullptr);\n   ASSERT_EQ(large_value, result);\n }\n \n TEST(Coding, Varint64Overflow) {\n   uint64_t result;\n   std::string input(\"\\x81\\x82\\x83\\x84\\x85\\x81\\x82\\x83\\x84\\x85\\x11\");\n-  ASSERT_TRUE(GetVarint64Ptr(input.data(), input.data() + input.size(), &result)\n-              == NULL);\n+  ASSERT_TRUE(GetVarint64Ptr(input.data(), input.data() + input.size(),\n+                             &result) == nullptr);\n }\n \n TEST(Coding, Varint64Truncation) {\n@@ -163,9 +164,10 @@ TEST(Coding, Varint64Truncation) {\n   PutVarint64(&s, large_value);\n   uint64_t result;\n   for (size_t len = 0; len < s.size() - 1; len++) {\n-    ASSERT_TRUE(GetVarint64Ptr(s.data(), s.data() + len, &result) == NULL);\n+    ASSERT_TRUE(GetVarint64Ptr(s.data(), s.data() + len, &result) == nullptr);\n   }\n-  ASSERT_TRUE(GetVarint64Ptr(s.data(), s.data() + s.size(), &result) != NULL);\n+  ASSERT_TRUE(GetVarint64Ptr(s.data(), s.data() + s.size(), &result) !=\n+              nullptr);\n   ASSERT_EQ(large_value, result);\n }\n \n@@ -191,6 +193,4 @@ TEST(Coding, Strings) {\n \n }  // namespace leveldb\n \n-int main(int argc, char** argv) {\n-  return leveldb::test::RunAllTests();\n-}\n+int main(int argc, char** argv) { return leveldb::test::RunAllTests(); }"
      },
      {
        "sha": "c5766e9462f4e8466756e83a5b986767fd2566a2",
        "filename": "src/leveldb/util/comparator.cc",
        "status": "modified",
        "additions": 17,
        "deletions": 23,
        "changes": 40,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/comparator.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/comparator.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/comparator.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853",
        "patch": "@@ -2,33 +2,34 @@\n // Use of this source code is governed by a BSD-style license that can be\n // found in the LICENSE file. See the AUTHORS file for names of contributors.\n \n-#include <algorithm>\n-#include <stdint.h>\n #include \"leveldb/comparator.h\"\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <string>\n+#include <type_traits>\n+\n #include \"leveldb/slice.h\"\n-#include \"port/port.h\"\n #include \"util/logging.h\"\n+#include \"util/no_destructor.h\"\n \n namespace leveldb {\n \n-Comparator::~Comparator() { }\n+Comparator::~Comparator() = default;\n \n namespace {\n class BytewiseComparatorImpl : public Comparator {\n  public:\n-  BytewiseComparatorImpl() { }\n+  BytewiseComparatorImpl() = default;\n \n-  virtual const char* Name() const {\n-    return \"leveldb.BytewiseComparator\";\n-  }\n+  const char* Name() const override { return \"leveldb.BytewiseComparator\"; }\n \n-  virtual int Compare(const Slice& a, const Slice& b) const {\n+  int Compare(const Slice& a, const Slice& b) const override {\n     return a.compare(b);\n   }\n \n-  virtual void FindShortestSeparator(\n-      std::string* start,\n-      const Slice& limit) const {\n+  void FindShortestSeparator(std::string* start,\n+                             const Slice& limit) const override {\n     // Find length of common prefix\n     size_t min_length = std::min(start->size(), limit.size());\n     size_t diff_index = 0;\n@@ -50,14 +51,14 @@ class BytewiseComparatorImpl : public Comparator {\n     }\n   }\n \n-  virtual void FindShortSuccessor(std::string* key) const {\n+  void FindShortSuccessor(std::string* key) const override {\n     // Find first character that can be incremented\n     size_t n = key->size();\n     for (size_t i = 0; i < n; i++) {\n       const uint8_t byte = (*key)[i];\n       if (byte != static_cast<uint8_t>(0xff)) {\n         (*key)[i] = byte + 1;\n-        key->resize(i+1);\n+        key->resize(i + 1);\n         return;\n       }\n     }\n@@ -66,16 +67,9 @@ class BytewiseComparatorImpl : public Comparator {\n };\n }  // namespace\n \n-static port::OnceType once = LEVELDB_ONCE_INIT;\n-static const Comparator* bytewise;\n-\n-static void InitModule() {\n-  bytewise = new BytewiseComparatorImpl;\n-}\n-\n const Comparator* BytewiseComparator() {\n-  port::InitOnce(&once, InitModule);\n-  return bytewise;\n+  static NoDestructor<BytewiseComparatorImpl> singleton;\n+  return singleton.get();\n }\n \n }  // namespace leveldb"
      },
      {
        "sha": "c2e61f7dbac5089b41acd1208dbb495de06d10f8",
        "filename": "src/leveldb/util/crc32c.cc",
        "status": "modified",
        "additions": 0,
        "deletions": 0,
        "changes": 0,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/crc32c.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/crc32c.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/crc32c.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "98fabb0d2f33b624ffae236b050a4f7ee2af9548",
        "filename": "src/leveldb/util/crc32c.h",
        "status": "modified",
        "additions": 2,
        "deletions": 4,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/crc32c.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/crc32c.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/crc32c.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "18a8494824d34690df6f4795017206392a0c8005",
        "filename": "src/leveldb/util/crc32c_test.cc",
        "status": "modified",
        "additions": 9,
        "deletions": 22,
        "changes": 31,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/crc32c_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/crc32c_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/crc32c_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "d2f0aef3268bb7d5c4bdea235c97e4a69d25334b",
        "filename": "src/leveldb/util/env.cc",
        "status": "modified",
        "additions": 9,
        "deletions": 17,
        "changes": 26,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/env.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "9f5863a0f35abdfe5c702fd0df2100dcab0ce70a",
        "filename": "src/leveldb/util/env_posix.cc",
        "status": "modified",
        "additions": 661,
        "deletions": 461,
        "changes": 1122,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_posix.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_posix.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/env_posix.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "9675d739adad0adc24ec38e3d4b4f010abfea414",
        "filename": "src/leveldb/util/env_posix_test.cc",
        "status": "modified",
        "additions": 292,
        "deletions": 8,
        "changes": 300,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_posix_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_posix_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/env_posix_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "7db03fc11c083c569d4924e7c9d5230ba99d9c80",
        "filename": "src/leveldb/util/env_test.cc",
        "status": "modified",
        "additions": 183,
        "deletions": 52,
        "changes": 235,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/env_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "830332abe9b32f2af88f463e26cb5288919a59b1",
        "filename": "src/leveldb/util/env_win.cc",
        "status": "removed",
        "additions": 0,
        "deletions": 902,
        "changes": 902,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/util/env_win.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2755b2b1092d0286022cf3cc3028e96f6bee2b34/src/leveldb/util/env_win.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/env_win.cc?ref=2755b2b1092d0286022cf3cc3028e96f6bee2b34"
      },
      {
        "sha": "1834206562cbd44456d2c14ad345d7f95b509d4d",
        "filename": "src/leveldb/util/env_windows.cc",
        "status": "added",
        "additions": 849,
        "deletions": 0,
        "changes": 849,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_windows.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_windows.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/env_windows.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "3c22133891e53b0c1878261b22a52d005a5db992",
        "filename": "src/leveldb/util/env_windows_test.cc",
        "status": "added",
        "additions": 64,
        "deletions": 0,
        "changes": 64,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_windows_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_windows_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/env_windows_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "e6f6020561ac919b38413eb3e34f4234107fa4ec",
        "filename": "src/leveldb/util/env_windows_test_helper.h",
        "status": "added",
        "additions": 25,
        "deletions": 0,
        "changes": 25,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_windows_test_helper.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/env_windows_test_helper.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/env_windows_test_helper.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "90fd754d64a577fa22180f29dbf7388ab8a8ded1",
        "filename": "src/leveldb/util/filter_policy.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/filter_policy.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/filter_policy.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/filter_policy.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "dd47c110ee9219bce9462084ac1bb79f23e9bd76",
        "filename": "src/leveldb/util/hash.cc",
        "status": "modified",
        "additions": 9,
        "deletions": 6,
        "changes": 15,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/hash.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/hash.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/hash.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "74bdb6e7b20a28bc4f02149f72c2a91a439fbd90",
        "filename": "src/leveldb/util/hash.h",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/hash.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/hash.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/hash.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "21f8171da6c94b3ab0a27e55f1fee0a3ddfb4286",
        "filename": "src/leveldb/util/hash_test.cc",
        "status": "modified",
        "additions": 11,
        "deletions": 21,
        "changes": 32,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/hash_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/hash_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/hash_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "65092c88f2e3add68ef230be409d698f0140400f",
        "filename": "src/leveldb/util/histogram.cc",
        "status": "modified",
        "additions": 170,
        "deletions": 37,
        "changes": 207,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/histogram.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/histogram.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/histogram.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "4da60fba4509b246ee56f6ea5f65156833d0d4e2",
        "filename": "src/leveldb/util/histogram.h",
        "status": "modified",
        "additions": 11,
        "deletions": 9,
        "changes": 20,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/histogram.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/histogram.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/histogram.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "75e9d037d3f9ebeadc9bd78185aa9e100b0e42b8",
        "filename": "src/leveldb/util/logging.cc",
        "status": "modified",
        "additions": 32,
        "deletions": 20,
        "changes": 52,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/logging.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/logging.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/logging.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "8ff2da86b4960a645fbdcec1a717aa8a87973f46",
        "filename": "src/leveldb/util/logging.h",
        "status": "modified",
        "additions": 8,
        "deletions": 6,
        "changes": 14,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/logging.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/logging.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/logging.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "389cbeb14f74520563a2cf8f10389409d30bbdf5",
        "filename": "src/leveldb/util/logging_test.cc",
        "status": "added",
        "additions": 143,
        "deletions": 0,
        "changes": 143,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/logging_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/logging_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/logging_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "0cb2e250fb5a1731f99a73453c2d8c2333914809",
        "filename": "src/leveldb/util/mutexlock.h",
        "status": "modified",
        "additions": 5,
        "deletions": 7,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/mutexlock.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/mutexlock.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/mutexlock.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "a0d3b8703d750f8e3ea85a1f7269908fb842a910",
        "filename": "src/leveldb/util/no_destructor.h",
        "status": "added",
        "additions": 46,
        "deletions": 0,
        "changes": 46,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/no_destructor.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/no_destructor.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/no_destructor.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "b41caca694544f01a800f56f65148ed7b3f4f48c",
        "filename": "src/leveldb/util/no_destructor_test.cc",
        "status": "added",
        "additions": 47,
        "deletions": 0,
        "changes": 47,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/no_destructor_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/no_destructor_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/no_destructor_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "62de5bf0d2f7ea06741fda57b5a5cc94ce569a76",
        "filename": "src/leveldb/util/options.cc",
        "status": "modified",
        "additions": 1,
        "deletions": 17,
        "changes": 18,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/options.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/options.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/options.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "28e15d10b4d60ffa4dbcf935124f9adbd04fba42",
        "filename": "src/leveldb/util/posix_logger.h",
        "status": "modified",
        "additions": 100,
        "deletions": 68,
        "changes": 168,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/posix_logger.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/posix_logger.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/posix_logger.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "76f7daf52a001105dc28a620f62191a1c022dbb6",
        "filename": "src/leveldb/util/random.h",
        "status": "modified",
        "additions": 4,
        "deletions": 5,
        "changes": 9,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/random.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/random.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/random.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "15ce747d80ace4893fa134c3b1b61589fc27565c",
        "filename": "src/leveldb/util/status.cc",
        "status": "modified",
        "additions": 8,
        "deletions": 6,
        "changes": 14,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/status.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/status.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/status.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "2842319fbdb13616a674c00f216c8eab4da3a55c",
        "filename": "src/leveldb/util/status_test.cc",
        "status": "added",
        "additions": 40,
        "deletions": 0,
        "changes": 40,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/status_test.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/status_test.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/status_test.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "318ecfa3b7d91c8fc1d9b5d473f0a1bec2d57c61",
        "filename": "src/leveldb/util/testharness.cc",
        "status": "modified",
        "additions": 11,
        "deletions": 7,
        "changes": 18,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/testharness.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/testharness.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/testharness.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "72cd1629eb5bf5172ecd073ee2b793d8dbb21543",
        "filename": "src/leveldb/util/testharness.h",
        "status": "modified",
        "additions": 44,
        "deletions": 41,
        "changes": 85,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/testharness.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/testharness.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/testharness.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "6b151b9e643f918f6196ed398564d7eb6d2b267a",
        "filename": "src/leveldb/util/testutil.cc",
        "status": "modified",
        "additions": 5,
        "deletions": 7,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/testutil.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/testutil.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/testutil.cc?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "bb4051ba076a3250a6d3a82f374ce2a1cd33d169",
        "filename": "src/leveldb/util/testutil.h",
        "status": "modified",
        "additions": 16,
        "deletions": 13,
        "changes": 29,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/testutil.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/testutil.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/testutil.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "92960638d179529e5d10f4cb35d3c0f692878996",
        "filename": "src/leveldb/util/windows_logger.h",
        "status": "added",
        "additions": 124,
        "deletions": 0,
        "changes": 124,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/windows_logger.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/20a6babfa9a66f5432ef19c6c433b4357560f853/src/leveldb/util/windows_logger.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/leveldb/util/windows_logger.h?ref=20a6babfa9a66f5432ef19c6c433b4357560f853"
      }
    ]
  },
  {
    "sha": "2e1819311a59fb5cb26e3ca50a510bfe01358350",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzoyZTE4MTkzMTFhNTlmYjVjYjI2ZTNjYTUwYTUxMGJmZTAxMzU4MzUw",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T15:59:58Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T15:59:58Z"
      },
      "message": "Squashed 'src/crc32c/' content from commit 224988680f7673cd7c769963d4035cb315aa3388\n\ngit-subtree-dir: src/crc32c\ngit-subtree-split: 224988680f7673cd7c769963d4035cb315aa3388",
      "tree": {
        "sha": "f70e4b8e3585d605a4c473342b8bb0545aee1824",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/f70e4b8e3585d605a4c473342b8bb0545aee1824"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/2e1819311a59fb5cb26e3ca50a510bfe01358350",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/2e1819311a59fb5cb26e3ca50a510bfe01358350",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/2e1819311a59fb5cb26e3ca50a510bfe01358350",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/2e1819311a59fb5cb26e3ca50a510bfe01358350/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [],
    "stats": {
      "total": 2730,
      "additions": 2730,
      "deletions": 0
    },
    "files": [
      {
        "sha": "7345746750a77a35c971d26329b8b404c3c4493f",
        "filename": ".appveyor.yml",
        "status": "added",
        "additions": 37,
        "deletions": 0,
        "changes": 37,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/.appveyor.yml",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/.appveyor.yml",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.appveyor.yml?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,37 @@\n+# Build matrix / environment variables are explained on:\n+# https://www.appveyor.com/docs/appveyor-yml/\n+# This file can be validated on: https://ci.appveyor.com/tools/validate-yaml\n+\n+version: \"{build}\"\n+\n+environment:\n+  matrix:\n+    # AppVeyor currently has no custom job name feature.\n+    # http://help.appveyor.com/discussions/questions/1623-can-i-provide-a-friendly-name-for-jobs\n+    - JOB: Visual Studio 2017\n+      APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2017\n+      CMAKE_GENERATOR: Visual Studio 15 2017\n+\n+platform:\n+  - x86\n+  - x64\n+\n+configuration:\n+  - RelWithDebInfo\n+  - Debug\n+\n+build_script:\n+  - git submodule update --init --recursive\n+  - mkdir build\n+  - cd build\n+  - if \"%platform%\"==\"x64\" set CMAKE_GENERATOR=%CMAKE_GENERATOR% Win64\n+  - cmake --version\n+  - cmake .. -G \"%CMAKE_GENERATOR%\" -DCRC32C_USE_GLOG=0\n+      -DCMAKE_CONFIGURATION_TYPES=\"%CONFIGURATION%\"\n+  - cmake --build . --config \"%CONFIGURATION%\"\n+  - cd ..\n+\n+test_script:\n+  - build\\%CONFIGURATION%\\crc32c_tests.exe\n+  - build\\%CONFIGURATION%\\crc32c_capi_tests.exe\n+  - build\\%CONFIGURATION%\\crc32c_bench.exe"
      },
      {
        "sha": "be9b80799fa0244e283f8e0a072498dc373a43de",
        "filename": ".clang-format",
        "status": "added",
        "additions": 3,
        "deletions": 0,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/.clang-format",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/.clang-format",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.clang-format?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,3 @@\n+---\n+Language:      Cpp\n+BasedOnStyle:  Google"
      },
      {
        "sha": "fa6757c6f36413b987db6af737b140e0360030c1",
        "filename": ".clang_complete",
        "status": "added",
        "additions": 8,
        "deletions": 0,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/.clang_complete",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/.clang_complete",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.clang_complete?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,8 @@\n+-Ibuild/include/\n+-Ibuild/third_party/glog/\n+-Iinclude/\n+-Ithird_party/benchmark/include/\n+-Ithird_party/googletest/googletest/include/\n+-Ithird_party/googletest/googlemock/include/\n+-Ithird_party/glog/src/\n+-std=c++11"
      },
      {
        "sha": "61769727e318e7f0d867f549309e4345b5c183f1",
        "filename": ".gitignore",
        "status": "added",
        "additions": 8,
        "deletions": 0,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/.gitignore",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/.gitignore",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.gitignore?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,8 @@\n+# Editors.\n+*.sw*\n+.DS_Store\n+/.vscode\n+\n+# Build directory.\n+build/\n+out/"
      },
      {
        "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
        "filename": ".gitmodules",
        "status": "added",
        "additions": 0,
        "deletions": 0,
        "changes": 0,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/.gitmodules",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/.gitmodules",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.gitmodules?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350"
      },
      {
        "sha": "d990a89f0750d283e59de4f045a07422d677ea48",
        "filename": ".travis.yml",
        "status": "added",
        "additions": 76,
        "deletions": 0,
        "changes": 76,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/.travis.yml",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/.travis.yml",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.travis.yml?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,76 @@\n+# Build matrix / environment variables are explained on:\n+# http://about.travis-ci.org/docs/user/build-configuration/\n+# This file can be validated on: http://lint.travis-ci.org/\n+\n+language: cpp\n+dist: bionic\n+osx_image: xcode10.3\n+\n+compiler:\n+- gcc\n+- clang\n+os:\n+- linux\n+- osx\n+\n+env:\n+- GLOG=1 SHARED_LIB=0 BUILD_TYPE=Debug\n+- GLOG=1 SHARED_LIB=0 BUILD_TYPE=RelWithDebInfo\n+- GLOG=0 SHARED_LIB=0 BUILD_TYPE=Debug\n+- GLOG=0 SHARED_LIB=0 BUILD_TYPE=RelWithDebInfo\n+- GLOG=0 SHARED_LIB=1 BUILD_TYPE=Debug\n+- GLOG=0 SHARED_LIB=1 BUILD_TYPE=RelWithDebInfo\n+\n+addons:\n+  apt:\n+    sources:\n+    - sourceline: 'deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-9 main'\n+      key_url: 'https://apt.llvm.org/llvm-snapshot.gpg.key'\n+    - sourceline: 'ppa:ubuntu-toolchain-r/test'\n+    packages:\n+    - clang-9\n+    - cmake\n+    - gcc-9\n+    - g++-9\n+    - ninja-build\n+  homebrew:\n+    packages:\n+    - cmake\n+    - gcc@9\n+    - llvm@9\n+    - ninja\n+    update: true\n+\n+install:\n+# The following Homebrew packages aren't linked by default, and need to be\n+# prepended to the path explicitly.\n+- if [ \"$TRAVIS_OS_NAME\" = \"osx\" ]; then\n+    export PATH=\"$(brew --prefix llvm)/bin:$PATH\";\n+  fi\n+# /usr/bin/gcc points to an older compiler on both Linux and macOS.\n+- if [ \"$CXX\" = \"g++\" ]; then export CXX=\"g++-9\" CC=\"gcc-9\"; fi\n+# /usr/bin/clang points to an older compiler on both Linux and macOS.\n+#\n+# Homebrew's llvm package doesn't ship a versioned clang++ binary, so the values\n+# below don't work on macOS. Fortunately, the path change above makes the\n+# default values (clang and clang++) resolve to the correct compiler on macOS.\n+- if [ \"$TRAVIS_OS_NAME\" = \"linux\" ]; then\n+    if [ \"$CXX\" = \"clang++\" ]; then export CXX=\"clang++-9\" CC=\"clang-9\"; fi;\n+  fi\n+- echo ${CC}\n+- echo ${CXX}\n+- ${CXX} --version\n+- cmake --version\n+\n+before_script:\n+- mkdir -p build && cd build\n+- cmake .. -G Ninja -DCRC32C_USE_GLOG=$GLOG -DCMAKE_BUILD_TYPE=$BUILD_TYPE\n+           -DBUILD_SHARED_LIBS=$SHARED_LIB -DCMAKE_INSTALL_PREFIX=$HOME/.local\n+- cmake --build .\n+- cd ..\n+\n+script:\n+- build/crc32c_tests\n+- build/crc32c_capi_tests\n+- build/crc32c_bench\n+- cd build && cmake --build . --target install"
      },
      {
        "sha": "536aadcec8cf65894e66701180e3cd45b95157a3",
        "filename": ".ycm_extra_conf.py",
        "status": "added",
        "additions": 142,
        "deletions": 0,
        "changes": 142,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/.ycm_extra_conf.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/.ycm_extra_conf.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/.ycm_extra_conf.py?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,142 @@\n+# Copyright 2017 The CRC32C Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file.\n+\"\"\"YouCompleteMe configuration that interprets a .clang_complete file.\n+\n+This module implementes the YouCompleteMe configuration API documented at:\n+https://github.com/Valloric/ycmd#ycm_extra_confpy-specification\n+\n+The implementation loads and processes a .clang_complete file, documented at:\n+https://github.com/Rip-Rip/clang_complete/blob/master/README.md\n+\"\"\"\n+\n+import os\n+\n+# Flags added to the list in .clang_complete.\n+BASE_FLAGS = [\n+    '-Werror',  # Unlike clang_complete, YCM can also be used as a linter.\n+    '-DUSE_CLANG_COMPLETER',  # YCM needs this.\n+    '-xc++',  # YCM needs this to avoid compiling headers as C code.\n+]\n+\n+# Clang flags that take in paths.\n+# See https://clang.llvm.org/docs/ClangCommandLineReference.html\n+PATH_FLAGS = [\n+    '-isystem',\n+    '-I',\n+    '-iquote',\n+    '--sysroot='\n+]\n+\n+\n+def DirectoryOfThisScript():\n+  \"\"\"Returns the absolute path to the directory containing this script.\"\"\"\n+  return os.path.dirname(os.path.abspath(__file__))\n+\n+\n+def MakeRelativePathsInFlagsAbsolute(flags, build_root):\n+  \"\"\"Expands relative paths in a list of Clang command-line flags.\n+\n+  Args:\n+    flags: The list of flags passed to Clang.\n+    build_root: The current directory when running the Clang compiler. Should be\n+        an absolute path.\n+\n+  Returns:\n+    A list of flags with relative paths replaced by absolute paths.\n+  \"\"\"\n+  new_flags = []\n+  make_next_absolute = False\n+  for flag in flags:\n+    new_flag = flag\n+\n+    if make_next_absolute:\n+      make_next_absolute = False\n+      if not flag.startswith('/'):\n+        new_flag = os.path.join(build_root, flag)\n+\n+    for path_flag in PATH_FLAGS:\n+      if flag == path_flag:\n+        make_next_absolute = True\n+        break\n+\n+      if flag.startswith(path_flag):\n+        path = flag[len(path_flag):]\n+        new_flag = path_flag + os.path.join(build_root, path)\n+        break\n+\n+    if new_flag:\n+      new_flags.append(new_flag)\n+  return new_flags\n+\n+\n+def FindNearest(target, path, build_root):\n+  \"\"\"Looks for a file with a specific name closest to a project path.\n+\n+  This is similar to the logic used by a version-control system (like git) to\n+  find its configuration directory (.git) based on the current directory when a\n+  command is invoked.\n+\n+  Args:\n+    target: The file name to search for.\n+    path: The directory where the search starts. The search will explore the\n+        given directory's ascendants using the parent relationship. Should be an\n+        absolute path.\n+    build_root: A directory that acts as a fence for the search. If the search\n+        reaches this directory, it will not advance to its parent. Should be an\n+        absolute path.\n+\n+  Returns:\n+    The path to a file with the desired name. None if the search failed.\n+  \"\"\"\n+  candidate = os.path.join(path, target)\n+  if os.path.isfile(candidate):\n+    return candidate\n+\n+  if path == build_root:\n+    return None\n+\n+  parent = os.path.dirname(path)\n+  if parent == path:\n+    return None\n+\n+  return FindNearest(target, parent, build_root)\n+\n+\n+def FlagsForClangComplete(file_path, build_root):\n+  \"\"\"Reads the .clang_complete flags for a source file.\n+\n+  Args:\n+    file_path: The path to the source file. Should be inside the project. Used\n+      to locate the relevant .clang_complete file.\n+    build_root: The current directory when running the Clang compiler for this\n+        file. Should be an absolute path.\n+\n+  Returns:\n+    A list of strings, where each element is a Clang command-line flag.\n+  \"\"\"\n+  clang_complete_path = FindNearest('.clang_complete', file_path, build_root)\n+  if clang_complete_path is None:\n+    return None\n+  clang_complete_flags = open(clang_complete_path, 'r').read().splitlines()\n+  return clang_complete_flags\n+\n+\n+def FlagsForFile(filename, **kwargs):\n+  \"\"\"Implements the YouCompleteMe API.\"\"\"\n+\n+  # kwargs can be used to pass 'client_data' to the YCM configuration. This\n+  # configuration script does not need any extra information, so\n+  # pylint: disable=unused-argument\n+\n+  build_root = DirectoryOfThisScript()\n+  file_path = os.path.realpath(filename)\n+\n+  flags = BASE_FLAGS\n+  clang_flags = FlagsForClangComplete(file_path, build_root)\n+  if clang_flags:\n+    flags += clang_flags\n+\n+  final_flags = MakeRelativePathsInFlagsAbsolute(flags, build_root)\n+\n+  return {'flags': final_flags}"
      },
      {
        "sha": "6f1f6871a6b665e5b28db7154a629b5a620d2e63",
        "filename": "AUTHORS",
        "status": "added",
        "additions": 9,
        "deletions": 0,
        "changes": 9,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/AUTHORS",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/AUTHORS",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/AUTHORS?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,9 @@\n+# This is the list of CRC32C authors for copyright purposes.\n+#\n+# This does not necessarily list everyone who has contributed code, since in\n+# some cases, their employer may be the copyright holder.  To see the full list\n+# of contributors, see the revision history in source control.\n+Google Inc.\n+\n+Fangming Fang <Fangming.Fang@arm.com>\n+Vadim Skipin <vadim.skipin@gmail.com>"
      },
      {
        "sha": "111a3e36144b916e99077440c24c769a8feed59e",
        "filename": "CMakeLists.txt",
        "status": "added",
        "additions": 423,
        "deletions": 0,
        "changes": 423,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/CMakeLists.txt",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/CMakeLists.txt",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/CMakeLists.txt?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,423 @@\n+# Copyright 2017 The CRC32C Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+cmake_minimum_required(VERSION 3.1)\n+project(Crc32c VERSION 1.1.0 LANGUAGES C CXX)\n+\n+# This project can use C11, but will gracefully decay down to C89.\n+set(CMAKE_C_STANDARD 11)\n+set(CMAKE_C_STANDARD_REQUIRED OFF)\n+set(CMAKE_C_EXTENSIONS OFF)\n+\n+# This project requires C++11.\n+set(CMAKE_CXX_STANDARD 11)\n+set(CMAKE_CXX_STANDARD_REQUIRED ON)\n+set(CMAKE_CXX_EXTENSIONS OFF)\n+\n+# https://github.com/izenecloud/cmake/blob/master/SetCompilerWarningAll.cmake\n+if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  # Use the highest warning level for Visual Studio.\n+  set(CMAKE_CXX_WARNING_LEVEL 4)\n+  if(CMAKE_CXX_FLAGS MATCHES \"/W[0-4]\")\n+    string(REGEX REPLACE \"/W[0-4]\" \"/W4\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  else(CMAKE_CXX_FLAGS MATCHES \"/W[0-4]\")\n+    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /W4\")\n+  endif(CMAKE_CXX_FLAGS MATCHES \"/W[0-4]\")\n+\n+  # Disable C++ exceptions.\n+  string(REGEX REPLACE \"/EH[a-z]+\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /EHs-c-\")\n+  add_definitions(-D_HAS_EXCEPTIONS=0)\n+\n+  # Disable RTTI.\n+  string(REGEX REPLACE \"/GR\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /GR-\")\n+else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  # Use -Wall for clang and gcc.\n+  if(NOT CMAKE_CXX_FLAGS MATCHES \"-Wall\")\n+    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wall\")\n+  endif(NOT CMAKE_CXX_FLAGS MATCHES \"-Wall\")\n+\n+  # Use -Wextra for clang and gcc.\n+  if(NOT CMAKE_CXX_FLAGS MATCHES \"-Wextra\")\n+    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wextra\")\n+  endif(NOT CMAKE_CXX_FLAGS MATCHES \"-Wextra\")\n+\n+  # Use -Werror for clang and gcc.\n+  if(NOT CMAKE_CXX_FLAGS MATCHES \"-Werror\")\n+    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Werror\")\n+  endif(NOT CMAKE_CXX_FLAGS MATCHES \"-Werror\")\n+\n+  # Disable C++ exceptions.\n+  string(REGEX REPLACE \"-fexceptions\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fno-exceptions\")\n+\n+  # Disable RTTI.\n+  string(REGEX REPLACE \"-frtti\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fno-rtti\")\n+endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+\n+option(CRC32C_BUILD_TESTS \"Build CRC32C's unit tests\" ON)\n+option(CRC32C_BUILD_BENCHMARKS \"Build CRC32C's benchmarks\" ON)\n+option(CRC32C_USE_GLOG \"Build CRC32C's tests with Google Logging\" ON)\n+option(CRC32C_INSTALL \"Install CRC32C's header and library\" ON)\n+\n+include(TestBigEndian)\n+test_big_endian(BYTE_ORDER_BIG_ENDIAN)\n+\n+include(CheckCXXCompilerFlag)\n+# Used by glog.\n+check_cxx_compiler_flag(-Wno-deprecated CRC32C_HAVE_NO_DEPRECATED)\n+# Used by glog.\n+check_cxx_compiler_flag(-Wno-sign-compare CRC32C_HAVE_NO_SIGN_COMPARE)\n+# Used by glog.\n+check_cxx_compiler_flag(-Wno-unused-parameter CRC32C_HAVE_NO_UNUSED_PARAMETER)\n+# Used by googletest.\n+check_cxx_compiler_flag(-Wno-missing-field-initializers\n+                        CRC32C_HAVE_NO_MISSING_FIELD_INITIALIZERS)\n+\n+# Check for __builtin_prefetch support in the compiler.\n+include(CheckCXXSourceCompiles)\n+check_cxx_source_compiles(\"\n+int main() {\n+  char data = 0;\n+  const char* address = &data;\n+  __builtin_prefetch(address, 0, 0);\n+  return 0;\n+}\n+\"  HAVE_BUILTIN_PREFETCH)\n+\n+# Check for _mm_prefetch support in the compiler.\n+include(CheckCXXSourceCompiles)\n+check_cxx_source_compiles(\"\n+#if defined(_MSC_VER)\n+#include <intrin.h>\n+#else  // !defined(_MSC_VER)\n+#include <xmmintrin.h>\n+#endif  // defined(_MSC_VER)\n+\n+int main() {\n+  char data = 0;\n+  const char* address = &data;\n+  _mm_prefetch(address, _MM_HINT_NTA);\n+  return 0;\n+}\n+\"  HAVE_MM_PREFETCH)\n+\n+# Check for SSE4.2 support in the compiler.\n+set(OLD_CMAKE_REQURED_FLAGS ${CMAKE_REQUIRED_FLAGS})\n+if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  set(CMAKE_REQUIRED_FLAGS \"${CMAKE_REQUIRED_FLAGS} /arch:AVX\")\n+else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  set(CMAKE_REQUIRED_FLAGS \"${CMAKE_REQUIRED_FLAGS} -msse4.2\")\n+endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+check_cxx_source_compiles(\"\n+#if defined(_MSC_VER)\n+#include <intrin.h>\n+#else  // !defined(_MSC_VER)\n+#include <cpuid.h>\n+#include <nmmintrin.h>\n+#endif  // defined(_MSC_VER)\n+\n+int main() {\n+  _mm_crc32_u8(0, 0); _mm_crc32_u32(0, 0);\n+#if defined(_M_X64) || defined(__x86_64__)\n+   _mm_crc32_u64(0, 0);\n+#endif // defined(_M_X64) || defined(__x86_64__)\n+  return 0;\n+}\n+\"  HAVE_SSE42)\n+set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQURED_FLAGS})\n+\n+# Check for ARMv8 w/ CRC and CRYPTO extensions support in the compiler.\n+set(OLD_CMAKE_REQURED_FLAGS ${CMAKE_REQUIRED_FLAGS})\n+if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  # TODO(pwnall): Insert correct flag when VS gets ARM CRC32C support.\n+  set(CMAKE_REQUIRED_FLAGS \"${CMAKE_REQUIRED_FLAGS} /arch:NOTYET\")\n+else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  set(CMAKE_REQUIRED_FLAGS \"${CMAKE_REQUIRED_FLAGS} -march=armv8-a+crc+crypto\")\n+endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+check_cxx_source_compiles(\"\n+#include <arm_acle.h>\n+#include <arm_neon.h>\n+\n+int main() {\n+  __crc32cb(0, 0); __crc32ch(0, 0); __crc32cw(0, 0); __crc32cd(0, 0);\n+  vmull_p64(0, 0);\n+  return 0;\n+}\n+\" HAVE_ARM64_CRC32C)\n+set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQURED_FLAGS})\n+\n+# Check for strong getauxval() support in the system headers.\n+check_cxx_source_compiles(\"\n+#include <arm_acle.h>\n+#include <arm_neon.h>\n+#include <sys/auxv.h>\n+\n+int main() {\n+  getauxval(AT_HWCAP);\n+  return 0;\n+}\n+\" HAVE_STRONG_GETAUXVAL)\n+\n+# Check for weak getauxval() support in the compiler.\n+check_cxx_source_compiles(\"\n+unsigned long getauxval(unsigned long type) __attribute__((weak));\n+#define AT_HWCAP 16\n+\n+int main() {\n+  getauxval(AT_HWCAP);\n+  return 0;\n+}\n+\" HAVE_WEAK_GETAUXVAL)\n+\n+if(CRC32C_USE_GLOG)\n+  # glog requires this setting to avoid using dynamic_cast.\n+  set(DISABLE_RTTI ON CACHE BOOL \"\" FORCE)\n+\n+  # glog's test targets trigger deprecation warnings, and compiling them burns\n+  # CPU cycles on the CI.\n+  set(BUILD_TESTING_SAVED \"${BUILD_TESTING}\")\n+  set(BUILD_TESTING OFF CACHE BOOL \"\" FORCE)\n+  add_subdirectory(\"third_party/glog\" EXCLUDE_FROM_ALL)\n+  set(BUILD_TESTING \"${BUILD_TESTING_SAVED}\" CACHE BOOL \"\" FORCE)\n+\n+  # glog triggers deprecation warnings on OSX.\n+  # https://github.com/google/glog/issues/185\n+  if(CRC32C_HAVE_NO_DEPRECATED)\n+    set_property(TARGET glog APPEND PROPERTY COMPILE_OPTIONS -Wno-deprecated)\n+  endif(CRC32C_HAVE_NO_DEPRECATED)\n+\n+  # glog triggers sign comparison warnings on gcc.\n+  if(CRC32C_HAVE_NO_SIGN_COMPARE)\n+    set_property(TARGET glog APPEND PROPERTY COMPILE_OPTIONS -Wno-sign-compare)\n+  endif(CRC32C_HAVE_NO_SIGN_COMPARE)\n+\n+  # glog triggers unused parameter warnings on clang.\n+  if(CRC32C_HAVE_NO_UNUSED_PARAMETER)\n+    set_property(TARGET glog\n+                 APPEND PROPERTY COMPILE_OPTIONS -Wno-unused-parameter)\n+  endif(CRC32C_HAVE_NO_UNUSED_PARAMETER)\n+\n+  set(CRC32C_TESTS_BUILT_WITH_GLOG 1)\n+endif(CRC32C_USE_GLOG)\n+\n+configure_file(\n+  \"src/crc32c_config.h.in\"\n+  \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+)\n+\n+include_directories(\"${PROJECT_BINARY_DIR}/include\")\n+\n+# ARM64 CRC32C code is built separately, so we don't accidentally compile\n+# unsupported instructions into code that gets run without ARM32 support.\n+add_library(crc32c_arm64 OBJECT \"\")\n+target_sources(crc32c_arm64\n+  PRIVATE\n+    \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+    \"src/crc32c_arm64.cc\"\n+    \"src/crc32c_arm64.h\"\n+)\n+if(HAVE_ARM64_CRC32C)\n+  if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    # TODO(pwnall): Insert correct flag when VS gets ARM64 CRC32C support.\n+    target_compile_options(crc32c_arm64 PRIVATE \"/arch:NOTYET\")\n+  else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    target_compile_options(crc32c_arm64 PRIVATE \"-march=armv8-a+crc+crypto\")\n+  endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+endif(HAVE_ARM64_CRC32C)\n+\n+# CMake only enables PIC by default in SHARED and MODULE targets.\n+if(BUILD_SHARED_LIBS)\n+  set_property(TARGET crc32c_arm64 PROPERTY POSITION_INDEPENDENT_CODE TRUE)\n+endif(BUILD_SHARED_LIBS)\n+\n+# SSE4.2 code is built separately, so we don't accidentally compile unsupported\n+# instructions into code that gets run without SSE4.2 support.\n+add_library(crc32c_sse42 OBJECT \"\")\n+target_sources(crc32c_sse42\n+  PRIVATE\n+    \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+    \"src/crc32c_sse42.cc\"\n+    \"src/crc32c_sse42.h\"\n+)\n+if(HAVE_SSE42)\n+  if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    target_compile_options(crc32c_sse42 PRIVATE \"/arch:AVX\")\n+  else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    target_compile_options(crc32c_sse42 PRIVATE \"-msse4.2\")\n+  endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+endif(HAVE_SSE42)\n+\n+# CMake only enables PIC by default in SHARED and MODULE targets.\n+if(BUILD_SHARED_LIBS)\n+  set_property(TARGET crc32c_sse42 PROPERTY POSITION_INDEPENDENT_CODE TRUE)\n+endif(BUILD_SHARED_LIBS)\n+\n+# Must be included before CMAKE_INSTALL_INCLUDEDIR is used.\n+include(GNUInstallDirs)\n+\n+add_library(crc32c \"\"\n+  # TODO(pwnall): Move the TARGET_OBJECTS generator expressions to the PRIVATE\n+  # section of target_sources when cmake_minimum_required becomes 3.9 or above.\n+  $<TARGET_OBJECTS:crc32c_arm64>\n+  $<TARGET_OBJECTS:crc32c_sse42>\n+)\n+target_sources(crc32c\n+  PRIVATE\n+    \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+    \"src/crc32c_arm64.h\"\n+    \"src/crc32c_arm64_linux_check.h\"\n+    \"src/crc32c_internal.h\"\n+    \"src/crc32c_portable.cc\"\n+    \"src/crc32c_prefetch.h\"\n+    \"src/crc32c_read_le.h\"\n+    \"src/crc32c_round_up.h\"\n+    \"src/crc32c_sse42.h\"\n+    \"src/crc32c_sse42_check.h\"\n+    \"src/crc32c.cc\"\n+\n+  # Only CMake 3.3+ supports PUBLIC sources in targets exported by \"install\".\n+  $<$<VERSION_GREATER:CMAKE_VERSION,3.2>:PUBLIC>\n+    \"include/crc32c/crc32c.h\"\n+)\n+\n+target_include_directories(crc32c\n+  PUBLIC\n+    $<BUILD_INTERFACE:${PROJECT_SOURCE_DIR}/include>\n+    $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>\n+)\n+\n+target_compile_definitions(crc32c\n+PRIVATE\n+  CRC32C_HAVE_CONFIG_H=1\n+)\n+\n+set_target_properties(crc32c\n+  PROPERTIES VERSION ${PROJECT_VERSION} SOVERSION ${PROJECT_VERSION_MAJOR})\n+\n+# Warnings as errors in Visual Studio for this project's targets.\n+if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  set_property(TARGET crc32c APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+  set_property(TARGET crc32c_arm64 APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+  set_property(TARGET crc32c_sse42 APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+\n+if(CRC32C_BUILD_TESTS)\n+  enable_testing()\n+\n+  # Prevent overriding the parent project's compiler/linker settings on Windows.\n+  set(gtest_force_shared_crt ON CACHE BOOL \"\" FORCE)\n+  set(install_gtest OFF)\n+  set(install_gmock OFF)\n+\n+  # This project is tested using GoogleTest.\n+  add_subdirectory(\"third_party/googletest\")\n+\n+  # GoogleTest triggers a missing field initializers warning.\n+  if(CRC32C_HAVE_NO_MISSING_FIELD_INITIALIZERS)\n+    set_property(TARGET gtest\n+        APPEND PROPERTY COMPILE_OPTIONS -Wno-missing-field-initializers)\n+    set_property(TARGET gmock\n+        APPEND PROPERTY COMPILE_OPTIONS -Wno-missing-field-initializers)\n+  endif(CRC32C_HAVE_NO_MISSING_FIELD_INITIALIZERS)\n+\n+  add_executable(crc32c_tests \"\")\n+  target_sources(crc32c_tests\n+    PRIVATE\n+      \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+      \"src/crc32c_arm64_unittest.cc\"\n+      \"src/crc32c_extend_unittests.h\"\n+      \"src/crc32c_portable_unittest.cc\"\n+      \"src/crc32c_prefetch_unittest.cc\"\n+      \"src/crc32c_read_le_unittest.cc\"\n+      \"src/crc32c_round_up_unittest.cc\"\n+      \"src/crc32c_sse42_unittest.cc\"\n+      \"src/crc32c_unittest.cc\"\n+      \"src/crc32c_test_main.cc\"\n+  )\n+  target_link_libraries(crc32c_tests crc32c gtest)\n+\n+  # Warnings as errors in Visual Studio for this project's targets.\n+  if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    set_property(TARGET crc32c_tests APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+  endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+\n+  if(CRC32C_USE_GLOG)\n+    target_link_libraries(crc32c_tests glog)\n+  endif(CRC32C_USE_GLOG)\n+\n+  add_test(NAME crc32c_tests COMMAND crc32c_tests)\n+\n+  add_executable(crc32c_capi_tests \"\")\n+  target_sources(crc32c_capi_tests\n+    PRIVATE\n+      \"src/crc32c_capi_unittest.c\"\n+  )\n+  target_link_libraries(crc32c_capi_tests crc32c)\n+\n+  # Warnings as errors in Visual Studio for this project's targets.\n+  if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    set_property(TARGET crc32c_capi_tests APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+  endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+\n+  add_test(NAME crc32c_capi_tests COMMAND crc32c_capi_tests)\n+endif(CRC32C_BUILD_TESTS)\n+\n+if(CRC32C_BUILD_BENCHMARKS)\n+  add_executable(crc32c_bench \"\")\n+  target_sources(crc32c_bench\n+    PRIVATE\n+      \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+      \"src/crc32c_benchmark.cc\"\n+  )\n+  target_link_libraries(crc32c_bench crc32c)\n+\n+  # This project uses Google benchmark for benchmarking.\n+  set(BENCHMARK_ENABLE_TESTING OFF CACHE BOOL \"\" FORCE)\n+  set(BENCHMARK_ENABLE_EXCEPTIONS OFF CACHE BOOL \"\" FORCE)\n+  add_subdirectory(\"third_party/benchmark\")\n+  target_link_libraries(crc32c_bench benchmark)\n+\n+  if(CRC32C_USE_GLOG)\n+    target_link_libraries(crc32c_bench glog)\n+  endif(CRC32C_USE_GLOG)\n+\n+  # Warnings as errors in Visual Studio for this project's targets.\n+  if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    set_property(TARGET crc32c_bench APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+  endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+endif(CRC32C_BUILD_BENCHMARKS)\n+\n+if(CRC32C_INSTALL)\n+  install(TARGETS crc32c\n+    EXPORT Crc32cTargets\n+    RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR}\n+    LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n+    ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}\n+  )\n+  install(\n+    FILES\n+      \"include/crc32c/crc32c.h\"\n+    DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/crc32c\"\n+  )\n+\n+  include(CMakePackageConfigHelpers)\n+  write_basic_package_version_file(\n+      \"${PROJECT_BINARY_DIR}/Crc32cConfigVersion.cmake\"\n+      COMPATIBILITY SameMajorVersion\n+  )\n+  install(\n+    EXPORT Crc32cTargets\n+    NAMESPACE Crc32c::\n+    DESTINATION \"${CMAKE_INSTALL_LIBDIR}/cmake/Crc32c\"\n+  )\n+  install(\n+    FILES\n+      \"Crc32cConfig.cmake\"\n+      \"${PROJECT_BINARY_DIR}/Crc32cConfigVersion.cmake\"\n+    DESTINATION \"${CMAKE_INSTALL_LIBDIR}/cmake/Crc32c\"\n+  )\n+endif(CRC32C_INSTALL)"
      },
      {
        "sha": "ae319c70aca8c8b148045aa1fd0c3ecfae85cb8a",
        "filename": "CONTRIBUTING.md",
        "status": "added",
        "additions": 23,
        "deletions": 0,
        "changes": 23,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/CONTRIBUTING.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/CONTRIBUTING.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/CONTRIBUTING.md?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,23 @@\n+# How to Contribute\n+\n+We'd love to accept your patches and contributions to this project. There are\n+just a few small guidelines you need to follow.\n+\n+## Contributor License Agreement\n+\n+Contributions to this project must be accompanied by a Contributor License\n+Agreement. You (or your employer) retain the copyright to your contribution,\n+this simply gives us permission to use and redistribute your contributions as\n+part of the project. Head over to <https://cla.developers.google.com/> to see\n+your current agreements on file or to sign a new one.\n+\n+You generally only need to submit a CLA once, so if you've already submitted one\n+(even if it was for a different project), you probably don't need to do it\n+again.\n+\n+## Code reviews\n+\n+All submissions, including submissions by project members, require review. We\n+use GitHub pull requests for this purpose. Consult\n+[GitHub Help](https://help.github.com/articles/about-pull-requests/) for more\n+information on using pull requests."
      },
      {
        "sha": "4d6057ec26f3bc04c5eb9df97d51cd8e5d90ae40",
        "filename": "Crc32cConfig.cmake",
        "status": "added",
        "additions": 5,
        "deletions": 0,
        "changes": 5,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/Crc32cConfig.cmake",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/Crc32cConfig.cmake",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/Crc32cConfig.cmake?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,5 @@\n+# Copyright 2017 The CRC32C Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+include(\"${CMAKE_CURRENT_LIST_DIR}/Crc32cTargets.cmake\")"
      },
      {
        "sha": "8c8735cf123cee0e410583fe9af785cb424b835b",
        "filename": "LICENSE",
        "status": "added",
        "additions": 28,
        "deletions": 0,
        "changes": 28,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/LICENSE",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/LICENSE",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/LICENSE?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,28 @@\n+Copyright 2017, The CRC32C Authors.\n+\n+Redistribution and use in source and binary forms, with or without\n+modification, are permitted provided that the following conditions are\n+met:\n+\n+   * Redistributions of source code must retain the above copyright\n+notice, this list of conditions and the following disclaimer.\n+   * Redistributions in binary form must reproduce the above\n+copyright notice, this list of conditions and the following disclaimer\n+in the documentation and/or other materials provided with the\n+distribution.\n+\n+   * Neither the name of Google Inc. nor the names of its\n+contributors may be used to endorse or promote products derived from\n+this software without specific prior written permission.\n+\n+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n+\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n+OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
      },
      {
        "sha": "0bd69f7f097e2f6be002809b9097fe210af60fac",
        "filename": "README.md",
        "status": "added",
        "additions": 125,
        "deletions": 0,
        "changes": 125,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/README.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/README.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/README.md?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,125 @@\n+# CRC32C\n+\n+[![Build Status](https://travis-ci.org/google/crc32c.svg?branch=master)](https://travis-ci.org/google/crc32c)\n+[![Build Status](https://ci.appveyor.com/api/projects/status/moiq7331pett4xuj/branch/master?svg=true)](https://ci.appveyor.com/project/pwnall/crc32c)\n+\n+New file format authors should consider\n+[HighwayHash](https://github.com/google/highwayhash). The initial version of\n+this code was extracted from [LevelDB](https://github.com/google/leveldb), which\n+is a stable key-value store that is widely used at Google.\n+\n+This project collects a few CRC32C implementations under an umbrella that\n+dispatches to a suitable implementation based on the host computer's hardware\n+capabilities.\n+\n+CRC32C is specified as the CRC that uses the iSCSI polynomial in\n+[RFC 3720](https://tools.ietf.org/html/rfc3720#section-12.1). The polynomial was\n+introduced by G. Castagnoli, S. Braeuer and M. Herrmann. CRC32C is used in\n+software such as Btrfs, ext4, Ceph and leveldb.\n+\n+\n+## Usage\n+\n+```cpp\n+#include \"crc32c/crc32c.h\"\n+\n+int main() {\n+  const std::uint8_t buffer[] = {0, 0, 0, 0};\n+  std::uint32_t result;\n+\n+  // Process a raw buffer.\n+  result = crc32c::Crc32c(buffer, 4);\n+\n+  // Process a std::string.\n+  std::string string;\n+  string.resize(4);\n+  result = crc32c::Crc32c(string);\n+\n+  // If you have C++17 support, process a std::string_view.\n+  std::string_view string_view(string);\n+  result = crc32c::Crc32c(string_view);\n+\n+  return 0;\n+}\n+```\n+\n+\n+## Prerequisites\n+\n+This project uses [CMake](https://cmake.org/) for building and testing. CMake is\n+available in all popular Linux distributions, as well as in\n+[Homebrew](https://brew.sh/).\n+\n+This project uses submodules for dependency management.\n+\n+```bash\n+git submodule update --init --recursive\n+```\n+\n+If you're using [Atom](https://atom.io/), the following packages can help.\n+\n+```bash\n+apm install autocomplete-clang build build-cmake clang-format language-cmake \\\n+    linter linter-clang\n+```\n+\n+If you don't mind more setup in return for more speed, replace\n+`autocomplete-clang` and `linter-clang` with `you-complete-me`. This requires\n+[setting up ycmd](https://github.com/Valloric/ycmd#building).\n+\n+```bash\n+apm install autocomplete-plus build build-cmake clang-format language-cmake \\\n+    linter you-complete-me\n+```\n+\n+## Building\n+\n+The following commands build and install the project.\n+\n+```bash\n+mkdir build\n+cd build\n+cmake -DCRC32C_BUILD_TESTS=0 -DCRC32C_BUILD_BENCHMARKS=0 .. && make all install\n+```\n+\n+\n+## Development\n+\n+The following command (when executed from `build/`) (re)builds the project and\n+runs the tests.\n+\n+```bash\n+cmake .. && cmake --build . && ctest --output-on-failure\n+```\n+\n+\n+### Android testing\n+\n+The following command builds the project against the Android NDK, which is\n+useful for benchmarking against ARM processors.\n+\n+```bash\n+cmake .. -DCMAKE_SYSTEM_NAME=Android -DCMAKE_ANDROID_ARCH_ABI=arm64-v8a \\\n+    -DCMAKE_ANDROID_NDK=$HOME/Library/Android/sdk/ndk-bundle \\\n+    -DCMAKE_ANDROID_NDK_TOOLCHAIN_VERSION=clang \\\n+    -DCMAKE_ANDROID_STL_TYPE=c++_static -DCRC32C_USE_GLOG=0 \\\n+    -DCMAKE_BUILD_TYPE=Release && cmake --build .\n+```\n+\n+The following commands install and run the benchmarks.\n+\n+```bash\n+adb push crc32c_bench /data/local/tmp\n+adb shell chmod +x /data/local/tmp/crc32c_bench\n+adb shell 'cd /data/local/tmp && ./crc32c_bench'\n+adb shell rm /data/local/tmp/crc32c_bench\n+```\n+\n+The following commands install and run the tests.\n+\n+```bash\n+adb push crc32c_tests /data/local/tmp\n+adb shell chmod +x /data/local/tmp/crc32c_tests\n+adb shell 'cd /data/local/tmp && ./crc32c_tests'\n+adb shell rm /data/local/tmp/crc32c_tests\n+```"
      },
      {
        "sha": "e8a78170a91cb69b5b00ae97fa398a373188c716",
        "filename": "include/crc32c/crc32c.h",
        "status": "added",
        "additions": 89,
        "deletions": 0,
        "changes": 89,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/include/crc32c/crc32c.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/include/crc32c/crc32c.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/include/crc32c/crc32c.h?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,89 @@\n+/* Copyright 2017 The CRC32C Authors. All rights reserved.\n+   Use of this source code is governed by a BSD-style license that can be\n+   found in the LICENSE file. See the AUTHORS file for names of contributors. */\n+\n+#ifndef CRC32C_CRC32C_H_\n+#define CRC32C_CRC32C_H_\n+\n+/* The API exported by the CRC32C project. */\n+\n+#if defined(__cplusplus)\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <string>\n+\n+#else  /* !defined(__cplusplus) */\n+\n+#include <stddef.h>\n+#include <stdint.h>\n+\n+#endif  /* !defined(__cplusplus) */\n+\n+\n+/* The C API. */\n+\n+#if defined(__cplusplus)\n+extern \"C\" {\n+#endif  /* defined(__cplusplus) */\n+\n+/* Extends \"crc\" with the CRC32C of \"count\" bytes in the buffer pointed by\n+   \"data\" */\n+uint32_t crc32c_extend(uint32_t crc, const uint8_t* data, size_t count);\n+\n+/* Computes the CRC32C of \"count\" bytes in the buffer pointed by \"data\". */\n+uint32_t crc32c_value(const uint8_t* data, size_t count);\n+\n+#ifdef __cplusplus\n+}  /* end extern \"C\" */\n+#endif  /* defined(__cplusplus) */\n+\n+\n+/* The C++ API. */\n+\n+#if defined(__cplusplus)\n+\n+namespace crc32c {\n+\n+// Extends \"crc\" with the CRC32C of \"count\" bytes in the buffer pointed by\n+// \"data\".\n+uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count);\n+\n+// Computes the CRC32C of \"count\" bytes in the buffer pointed by \"data\".\n+inline uint32_t Crc32c(const uint8_t* data, size_t count) {\n+  return Extend(0, data, count);\n+}\n+\n+// Computes the CRC32C of \"count\" bytes in the buffer pointed by \"data\".\n+inline uint32_t Crc32c(const char* data, size_t count) {\n+  return Extend(0, reinterpret_cast<const uint8_t*>(data), count);\n+}\n+\n+// Computes the CRC32C of the string's content.\n+inline uint32_t Crc32c(const std::string& string) {\n+  return Crc32c(reinterpret_cast<const uint8_t*>(string.data()),\n+                string.size());\n+}\n+\n+}  // namespace crc32c\n+\n+#if __cplusplus > 201402L\n+#if __has_include(<string_view>)\n+#include <string_view>\n+\n+namespace crc32c {\n+\n+// Computes the CRC32C of the bytes in the string_view.\n+inline uint32_t Crc32c(const std::string_view& string_view) {\n+  return Crc32c(reinterpret_cast<const uint8_t*>(string_view.data()),\n+                string_view.size());\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // __has_include(<string_view>)\n+#endif  // __cplusplus > 201402L\n+\n+#endif  /* defined(__cplusplus) */\n+\n+#endif  // CRC32C_CRC32C_H_"
      },
      {
        "sha": "4d3018af477d9281b872e1251f9650d8a89fd33c",
        "filename": "src/crc32c.cc",
        "status": "added",
        "additions": 39,
        "deletions": 0,
        "changes": 39,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,39 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"crc32c/crc32c.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"./crc32c_arm64.h\"\n+#include \"./crc32c_arm64_linux_check.h\"\n+#include \"./crc32c_internal.h\"\n+#include \"./crc32c_sse42.h\"\n+#include \"./crc32c_sse42_check.h\"\n+\n+namespace crc32c {\n+\n+uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count) {\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+  static bool can_use_sse42 = CanUseSse42();\n+  if (can_use_sse42) return ExtendSse42(crc, data, count);\n+#elif HAVE_ARM64_CRC32C\n+  static bool can_use_arm_linux = CanUseArm64Linux();\n+  if (can_use_arm_linux) return ExtendArm64(crc, data, count);\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+  return ExtendPortable(crc, data, count);\n+}\n+\n+extern \"C\" uint32_t crc32c_extend(uint32_t crc, const uint8_t* data,\n+                                  size_t count) {\n+  return crc32c::Extend(crc, data, count);\n+}\n+\n+extern \"C\" uint32_t crc32c_value(const uint8_t* data, size_t count) {\n+  return crc32c::Crc32c(data, count);\n+}\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "b872245f95b052f84e0c49fcc40ee1ca34e36e8e",
        "filename": "src/crc32c_arm64.cc",
        "status": "added",
        "additions": 126,
        "deletions": 0,
        "changes": 126,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_arm64.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_arm64.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_arm64.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,126 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_arm64.h\"\n+\n+// In a separate source file to allow this accelerated CRC32C function to be\n+// compiled with the appropriate compiler flags to enable ARM NEON CRC32C\n+// instructions.\n+\n+// This implementation is based on https://github.com/google/leveldb/pull/490.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"./crc32c_internal.h\"\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_ARM64_CRC32C\n+\n+#include <arm_acle.h>\n+#include <arm_neon.h>\n+\n+#define KBYTES 1032\n+#define SEGMENTBYTES 256\n+\n+// compute 8bytes for each segment parallelly\n+#define CRC32C32BYTES(P, IND)                                             \\\n+  do {                                                                    \\\n+    crc1 = __crc32cd(                                                     \\\n+        crc1, *((const uint64_t *)(P) + (SEGMENTBYTES / 8) * 1 + (IND))); \\\n+    crc2 = __crc32cd(                                                     \\\n+        crc2, *((const uint64_t *)(P) + (SEGMENTBYTES / 8) * 2 + (IND))); \\\n+    crc3 = __crc32cd(                                                     \\\n+        crc3, *((const uint64_t *)(P) + (SEGMENTBYTES / 8) * 3 + (IND))); \\\n+    crc0 = __crc32cd(                                                     \\\n+        crc0, *((const uint64_t *)(P) + (SEGMENTBYTES / 8) * 0 + (IND))); \\\n+  } while (0);\n+\n+// compute 8*8 bytes for each segment parallelly\n+#define CRC32C256BYTES(P, IND)      \\\n+  do {                              \\\n+    CRC32C32BYTES((P), (IND)*8 + 0) \\\n+    CRC32C32BYTES((P), (IND)*8 + 1) \\\n+    CRC32C32BYTES((P), (IND)*8 + 2) \\\n+    CRC32C32BYTES((P), (IND)*8 + 3) \\\n+    CRC32C32BYTES((P), (IND)*8 + 4) \\\n+    CRC32C32BYTES((P), (IND)*8 + 5) \\\n+    CRC32C32BYTES((P), (IND)*8 + 6) \\\n+    CRC32C32BYTES((P), (IND)*8 + 7) \\\n+  } while (0);\n+\n+// compute 4*8*8 bytes for each segment parallelly\n+#define CRC32C1024BYTES(P)   \\\n+  do {                       \\\n+    CRC32C256BYTES((P), 0)   \\\n+    CRC32C256BYTES((P), 1)   \\\n+    CRC32C256BYTES((P), 2)   \\\n+    CRC32C256BYTES((P), 3)   \\\n+    (P) += 4 * SEGMENTBYTES; \\\n+  } while (0)\n+\n+namespace crc32c {\n+\n+uint32_t ExtendArm64(uint32_t crc, const uint8_t *buf, size_t size) {\n+  int64_t length = size;\n+  uint32_t crc0, crc1, crc2, crc3;\n+  uint64_t t0, t1, t2;\n+\n+  // k0=CRC(x^(3*SEGMENTBYTES*8)), k1=CRC(x^(2*SEGMENTBYTES*8)),\n+  // k2=CRC(x^(SEGMENTBYTES*8))\n+  const poly64_t k0 = 0x8d96551c, k1 = 0xbd6f81f8, k2 = 0xdcb17aa4;\n+\n+  crc = crc ^ kCRC32Xor;\n+  const uint8_t *p = reinterpret_cast<const uint8_t *>(buf);\n+\n+  while (length >= KBYTES) {\n+    crc0 = crc;\n+    crc1 = 0;\n+    crc2 = 0;\n+    crc3 = 0;\n+\n+    // Process 1024 bytes in parallel.\n+    CRC32C1024BYTES(p);\n+\n+    // Merge the 4 partial CRC32C values.\n+    t2 = (uint64_t)vmull_p64(crc2, k2);\n+    t1 = (uint64_t)vmull_p64(crc1, k1);\n+    t0 = (uint64_t)vmull_p64(crc0, k0);\n+    crc = __crc32cd(crc3, *(uint64_t *)p);\n+    p += sizeof(uint64_t);\n+    crc ^= __crc32cd(0, t2);\n+    crc ^= __crc32cd(0, t1);\n+    crc ^= __crc32cd(0, t0);\n+\n+    length -= KBYTES;\n+  }\n+\n+  while (length >= 8) {\n+    crc = __crc32cd(crc, *(uint64_t *)p);\n+    p += 8;\n+    length -= 8;\n+  }\n+\n+  if (length & 4) {\n+    crc = __crc32cw(crc, *(uint32_t *)p);\n+    p += 4;\n+  }\n+\n+  if (length & 2) {\n+    crc = __crc32ch(crc, *(uint16_t *)p);\n+    p += 2;\n+  }\n+\n+  if (length & 1) {\n+    crc = __crc32cb(crc, *p);\n+  }\n+\n+  return crc ^ kCRC32Xor;\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // HAVE_ARM64_CRC32C"
      },
      {
        "sha": "100cd56ec84cc1c18219503c7fc942e05155f5ec",
        "filename": "src/crc32c_arm64.h",
        "status": "added",
        "additions": 27,
        "deletions": 0,
        "changes": 27,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_arm64.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_arm64.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_arm64.h?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,27 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+// Linux-specific code checking the availability for ARM CRC32C instructions.\n+\n+#ifndef CRC32C_CRC32C_ARM_LINUX_H_\n+#define CRC32C_CRC32C_ARM_LINUX_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_ARM64_CRC32C\n+\n+namespace crc32c {\n+\n+uint32_t ExtendArm64(uint32_t crc, const uint8_t* data, size_t count);\n+\n+}  // namespace crc32c\n+\n+#endif  // HAVE_ARM64_CRC32C\n+\n+#endif  // CRC32C_CRC32C_ARM_LINUX_H_"
      },
      {
        "sha": "1a20a757bb0fb1578da7a6c17505496f286d4ec1",
        "filename": "src/crc32c_arm64_linux_check.h",
        "status": "added",
        "additions": 50,
        "deletions": 0,
        "changes": 50,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_arm64_linux_check.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_arm64_linux_check.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_arm64_linux_check.h?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,50 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+// ARM Linux-specific code checking for the availability of CRC32C instructions.\n+\n+#ifndef CRC32C_CRC32C_ARM_LINUX_CHECK_H_\n+#define CRC32C_CRC32C_ARM_LINUX_CHECK_H_\n+\n+// X86-specific code checking for the availability of SSE4.2 instructions.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_ARM64_CRC32C\n+\n+#if HAVE_STRONG_GETAUXVAL\n+#include <sys/auxv.h>\n+#elif HAVE_WEAK_GETAUXVAL\n+// getauxval() is not available on Android until API level 20. Link it as a weak\n+// symbol.\n+extern \"C\" unsigned long getauxval(unsigned long type) __attribute__((weak));\n+\n+#define AT_HWCAP 16\n+#endif  // HAVE_STRONG_GETAUXVAL || HAVE_WEAK_GETAUXVAL\n+\n+namespace crc32c {\n+\n+inline bool CanUseArm64Linux() {\n+#if HAVE_STRONG_GETAUXVAL || HAVE_WEAK_GETAUXVAL\n+  // From 'arch/arm64/include/uapi/asm/hwcap.h' in Linux kernel source code.\n+  constexpr unsigned long kHWCAP_PMULL = 1 << 4;\n+  constexpr unsigned long kHWCAP_CRC32 = 1 << 7;\n+  unsigned long hwcap = (&getauxval != nullptr) ? getauxval(AT_HWCAP) : 0;\n+  return (hwcap & (kHWCAP_PMULL | kHWCAP_CRC32)) ==\n+         (kHWCAP_PMULL | kHWCAP_CRC32);\n+#else\n+  return false;\n+#endif  // HAVE_STRONG_GETAUXVAL || HAVE_WEAK_GETAUXVAL\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // HAVE_ARM64_CRC32C\n+\n+#endif  // CRC32C_CRC32C_ARM_LINUX_CHECK_H_"
      },
      {
        "sha": "6f917d9c0ce790178a75941489ee9c68aff313dd",
        "filename": "src/crc32c_arm64_unittest.cc",
        "status": "added",
        "additions": 24,
        "deletions": 0,
        "changes": 24,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_arm64_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_arm64_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_arm64_unittest.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,24 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"gtest/gtest.h\"\n+\n+#include \"./crc32c_arm64.h\"\n+#include \"./crc32c_extend_unittests.h\"\n+\n+namespace crc32c {\n+\n+#if HAVE_ARM64_CRC32C\n+\n+struct Arm64TestTraits {\n+  static uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count) {\n+    return ExtendArm64(crc, data, count);\n+  }\n+};\n+\n+INSTANTIATE_TYPED_TEST_SUITE_P(Arm64, ExtendTest, Arm64TestTraits);\n+\n+#endif  // HAVE_ARM64_CRC32C\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "c464304b3f2879da5e352432b78c6ac507c78367",
        "filename": "src/crc32c_benchmark.cc",
        "status": "added",
        "additions": 106,
        "deletions": 0,
        "changes": 106,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_benchmark.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_benchmark.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_benchmark.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,106 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#if CRC32C_TESTS_BUILT_WITH_GLOG\n+#include \"glog/logging.h\"\n+#endif  // CRC32C_TESTS_BUILT_WITH_GLOG\n+\n+#include \"./crc32c_arm64.h\"\n+#include \"./crc32c_arm64_linux_check.h\"\n+#include \"./crc32c_internal.h\"\n+#include \"./crc32c_sse42.h\"\n+#include \"./crc32c_sse42_check.h\"\n+#include \"crc32c/crc32c.h\"\n+\n+class CRC32CBenchmark : public benchmark::Fixture {\n+ public:\n+  void SetUp(const benchmark::State& state) override {\n+    block_size_ = static_cast<size_t>(state.range(0));\n+    block_data_ = std::string(block_size_, 'x');\n+    block_buffer_ = reinterpret_cast<const uint8_t*>(block_data_.data());\n+  }\n+\n+ protected:\n+  std::string block_data_;\n+  const uint8_t* block_buffer_;\n+  size_t block_size_;\n+};\n+\n+BENCHMARK_DEFINE_F(CRC32CBenchmark, Public)(benchmark::State& state) {\n+  uint32_t crc = 0;\n+  for (auto _ : state)\n+    crc = crc32c::Extend(crc, block_buffer_, block_size_);\n+  state.SetBytesProcessed(state.iterations() * block_size_);\n+}\n+BENCHMARK_REGISTER_F(CRC32CBenchmark, Public)\n+    ->RangeMultiplier(16)\n+    ->Range(256, 16777216);  // Block size.\n+\n+BENCHMARK_DEFINE_F(CRC32CBenchmark, Portable)(benchmark::State& state) {\n+  uint32_t crc = 0;\n+  for (auto _ : state)\n+    crc = crc32c::ExtendPortable(crc, block_buffer_, block_size_);\n+  state.SetBytesProcessed(state.iterations() * block_size_);\n+}\n+BENCHMARK_REGISTER_F(CRC32CBenchmark, Portable)\n+    ->RangeMultiplier(16)\n+    ->Range(256, 16777216);  // Block size.\n+\n+#if HAVE_ARM64_CRC32C\n+\n+BENCHMARK_DEFINE_F(CRC32CBenchmark, ArmLinux)(benchmark::State& state) {\n+  if (!crc32c::CanUseArm64Linux()) {\n+    state.SkipWithError(\"ARM CRC32C instructions not available or not enabled\");\n+    return;\n+  }\n+\n+  uint32_t crc = 0;\n+  for (auto _ : state)\n+    crc = crc32c::ExtendArm64(crc, block_buffer_, block_size_);\n+  state.SetBytesProcessed(state.iterations() * block_size_);\n+}\n+BENCHMARK_REGISTER_F(CRC32CBenchmark, ArmLinux)\n+    ->RangeMultiplier(16)\n+    ->Range(256, 16777216);  // Block size.\n+\n+#endif  // HAVE_ARM64_CRC32C\n+\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+BENCHMARK_DEFINE_F(CRC32CBenchmark, Sse42)(benchmark::State& state) {\n+  if (!crc32c::CanUseSse42()) {\n+    state.SkipWithError(\"SSE4.2 instructions not available or not enabled\");\n+    return;\n+  }\n+\n+  uint32_t crc = 0;\n+  for (auto _ : state)\n+    crc = crc32c::ExtendSse42(crc, block_buffer_, block_size_);\n+  state.SetBytesProcessed(state.iterations() * block_size_);\n+}\n+BENCHMARK_REGISTER_F(CRC32CBenchmark, Sse42)\n+    ->RangeMultiplier(16)\n+    ->Range(256, 16777216);  // Block size.\n+\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+int main(int argc, char** argv) {\n+#if CRC32C_TESTS_BUILT_WITH_GLOG\n+  google::InitGoogleLogging(argv[0]);\n+  google::InstallFailureSignalHandler();\n+#endif  // CRC32C_TESTS_BUILT_WITH_GLOG\n+\n+  benchmark::Initialize(&argc, argv);\n+  benchmark::RunSpecifiedBenchmarks();\n+  return 0;\n+}"
      },
      {
        "sha": "c8993a0959900ae072f4d29b243865d8deee4ff4",
        "filename": "src/crc32c_capi_unittest.c",
        "status": "added",
        "additions": 66,
        "deletions": 0,
        "changes": 66,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_capi_unittest.c",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_capi_unittest.c",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_capi_unittest.c?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,66 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"crc32c/crc32c.h\"\n+\n+#include <stddef.h>\n+#include <stdint.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+\n+int main() {\n+  /* From rfc3720 section B.4. */\n+  uint8_t buf[32];\n+\n+  memset(buf, 0, sizeof(buf));\n+  if ((uint32_t)0x8a9136aa != crc32c_value(buf, sizeof(buf))) {\n+    printf(\"crc32c_value(zeros) test failed\\n\");\n+    return 1;\n+  }\n+\n+  memset(buf, 0xff, sizeof(buf));\n+  if ((uint32_t)0x62a8ab43 != crc32c_value(buf, sizeof(buf))) {\n+    printf(\"crc32c_value(0xff) test failed\\n\");\n+    return 1;\n+  }\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = (uint8_t)i;\n+  if ((uint32_t)0x46dd794e != crc32c_value(buf, sizeof(buf))) {\n+    printf(\"crc32c_value(0..31) test failed\\n\");\n+    return 1;\n+  }\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = (uint8_t)(31 - i);\n+  if ((uint32_t)0x113fdb5c != crc32c_value(buf, sizeof(buf))) {\n+    printf(\"crc32c_value(31..0) test failed\\n\");\n+    return 1;\n+  }\n+\n+  uint8_t data[48] = {\n+      0x01, 0xc0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00,\n+      0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x28, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+  };\n+  if ((uint32_t)0xd9963a56 != crc32c_value(data, sizeof(data))) {\n+    printf(\"crc32c_value(31..0) test failed\\n\");\n+    return 1;\n+  }\n+\n+  const uint8_t* hello_space_world = (const uint8_t*)\"hello world\";\n+  const uint8_t* hello_space = (const uint8_t*)\"hello \";\n+  const uint8_t* world = (const uint8_t*)\"world\";\n+\n+  if (crc32c_value(hello_space_world, 11) !=\n+      crc32c_extend(crc32c_value(hello_space, 6), world, 5)) {\n+    printf(\"crc32c_extend test failed\\n\");\n+    return 1;\n+  }\n+\n+  printf(\"All tests passed\\n\");\n+  return 0;\n+}"
      },
      {
        "sha": "4034fa5644461eb20118906ac0935282a05a1bcd",
        "filename": "src/crc32c_config.h.in",
        "status": "added",
        "additions": 36,
        "deletions": 0,
        "changes": 36,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_config.h.in",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_config.h.in",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_config.h.in?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,36 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_CONFIG_H_\n+#define CRC32C_CRC32C_CONFIG_H_\n+\n+// Define to 1 if building for a big-endian platform.\n+#cmakedefine01 BYTE_ORDER_BIG_ENDIAN\n+\n+// Define to 1 if the compiler has the __builtin_prefetch intrinsic.\n+#cmakedefine01 HAVE_BUILTIN_PREFETCH\n+\n+// Define to 1 if targeting X86 and the compiler has the _mm_prefetch intrinsic.\n+#cmakedefine01 HAVE_MM_PREFETCH\n+\n+// Define to 1 if targeting X86 and the compiler has the _mm_crc32_u{8,32,64}\n+// intrinsics.\n+#cmakedefine01 HAVE_SSE42\n+\n+// Define to 1 if targeting ARM and the compiler has the __crc32c{b,h,w,d} and\n+// the vmull_p64 intrinsics.\n+#cmakedefine01 HAVE_ARM64_CRC32C\n+\n+// Define to 1 if the system libraries have the getauxval function in the\n+// <sys/auxv.h> header. Should be true on Linux and Android API level 20+.\n+#cmakedefine01 HAVE_STRONG_GETAUXVAL\n+\n+// Define to 1 if the compiler supports defining getauxval as a weak symbol.\n+// Should be true for any compiler that supports __attribute__((weak)).\n+#cmakedefine01 HAVE_WEAK_GETAUXVAL\n+\n+// Define to 1 if CRC32C tests have been built with Google Logging.\n+#cmakedefine01 CRC32C_TESTS_BUILT_WITH_GLOG\n+\n+#endif  // CRC32C_CRC32C_CONFIG_H_"
      },
      {
        "sha": "0732973737d5a408e6443b7e8b23bfd6b999ad2b",
        "filename": "src/crc32c_extend_unittests.h",
        "status": "added",
        "additions": 112,
        "deletions": 0,
        "changes": 112,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_extend_unittests.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_extend_unittests.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_extend_unittests.h?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,112 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_EXTEND_UNITTESTS_H_\n+#define CRC32C_CRC32C_EXTEND_UNITTESTS_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <cstring>\n+\n+#include \"gtest/gtest.h\"\n+\n+// Common test cases for all implementations of CRC32C_Extend().\n+\n+namespace crc32c {\n+\n+template<typename TestTraits>\n+class ExtendTest : public testing::Test {};\n+\n+TYPED_TEST_SUITE_P(ExtendTest);\n+\n+TYPED_TEST_P(ExtendTest, StandardResults) {\n+  // From rfc3720 section B.4.\n+  uint8_t buf[32];\n+\n+  std::memset(buf, 0, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x8a9136aa),\n+            TypeParam::Extend(0, buf, sizeof(buf)));\n+\n+  std::memset(buf, 0xff, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x62a8ab43),\n+            TypeParam::Extend(0, buf, sizeof(buf)));\n+\n+  for (int i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x46dd794e),\n+            TypeParam::Extend(0, buf, sizeof(buf)));\n+\n+  for (int i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(31 - i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x113fdb5c),\n+            TypeParam::Extend(0, buf, sizeof(buf)));\n+\n+  uint8_t data[48] = {\n+      0x01, 0xc0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00,\n+      0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x28, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+  };\n+  EXPECT_EQ(static_cast<uint32_t>(0xd9963a56),\n+            TypeParam::Extend(0, data, sizeof(data)));\n+}\n+\n+TYPED_TEST_P(ExtendTest, HelloWorld) {\n+  const uint8_t* hello_space_world =\n+      reinterpret_cast<const uint8_t*>(\"hello world\");\n+  const uint8_t* hello_space = reinterpret_cast<const uint8_t*>(\"hello \");\n+  const uint8_t* world = reinterpret_cast<const uint8_t*>(\"world\");\n+\n+  EXPECT_EQ(TypeParam::Extend(0, hello_space_world, 11),\n+            TypeParam::Extend(TypeParam::Extend(0, hello_space, 6), world, 5));\n+}\n+\n+TYPED_TEST_P(ExtendTest, BufferSlicing) {\n+  uint8_t buffer[48] = {\n+      0x01, 0xc0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00,\n+      0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x28, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+  };\n+\n+  for (size_t i = 0; i < 48; ++i) {\n+    for (size_t j = i + 1; j <= 48; ++j) {\n+      uint32_t crc = 0;\n+\n+      if (i > 0) crc = TypeParam::Extend(crc, buffer, i);\n+      crc = TypeParam::Extend(crc, buffer + i, j - i);\n+      if (j < 48) crc = TypeParam::Extend(crc, buffer + j, 48 - j);\n+\n+      EXPECT_EQ(static_cast<uint32_t>(0xd9963a56), crc);\n+    }\n+  }\n+}\n+\n+TYPED_TEST_P(ExtendTest, LargeBufferSlicing) {\n+  uint8_t buffer[2048];\n+  for (size_t i = 0; i < 2048; i++)\n+    buffer[i] = static_cast<uint8_t>(3 * i * i + 7 * i + 11);\n+\n+  for (size_t i = 0; i < 2048; ++i) {\n+    for (size_t j = i + 1; j <= 2048; ++j) {\n+      uint32_t crc = 0;\n+\n+      if (i > 0) crc = TypeParam::Extend(crc, buffer, i);\n+      crc = TypeParam::Extend(crc, buffer + i, j - i);\n+      if (j < 2048) crc = TypeParam::Extend(crc, buffer + j, 2048 - j);\n+\n+      EXPECT_EQ(static_cast<uint32_t>(0x36dcc753), crc);\n+    }\n+  }\n+}\n+\n+REGISTER_TYPED_TEST_SUITE_P(ExtendTest,\n+    StandardResults,\n+    HelloWorld,\n+    BufferSlicing,\n+    LargeBufferSlicing);\n+\n+}  // namespace crc32c\n+\n+#endif  // CRC32C_CRC32C_EXTEND_UNITTESTS_H_"
      },
      {
        "sha": "2bd23dea43e84ed0d226fe9ce0f2b1e9f4a25e7e",
        "filename": "src/crc32c_internal.h",
        "status": "added",
        "additions": 23,
        "deletions": 0,
        "changes": 23,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_internal.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_internal.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_internal.h?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,23 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_INTERNAL_H_\n+#define CRC32C_CRC32C_INTERNAL_H_\n+\n+// Internal functions that may change between releases.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+namespace crc32c {\n+\n+// Un-accelerated implementation that works on all CPUs.\n+uint32_t ExtendPortable(uint32_t crc, const uint8_t* data, size_t count);\n+\n+// CRCs are pre- and post- conditioned by xoring with all ones.\n+static constexpr const uint32_t kCRC32Xor = static_cast<uint32_t>(0xffffffffU);\n+\n+}  // namespace crc32c\n+\n+#endif  // CRC32C_CRC32C_INTERNAL_H_"
      },
      {
        "sha": "31ec6eac5373dc2acf912015bf269bb6f93cd8bf",
        "filename": "src/crc32c_portable.cc",
        "status": "added",
        "additions": 351,
        "deletions": 0,
        "changes": 351,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_portable.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_portable.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_portable.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,351 @@\n+// Copyright 2008 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_internal.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"./crc32c_prefetch.h\"\n+#include \"./crc32c_read_le.h\"\n+#include \"./crc32c_round_up.h\"\n+\n+namespace {\n+\n+const uint32_t kByteExtensionTable[256] = {\n+    0x00000000, 0xf26b8303, 0xe13b70f7, 0x1350f3f4, 0xc79a971f, 0x35f1141c,\n+    0x26a1e7e8, 0xd4ca64eb, 0x8ad958cf, 0x78b2dbcc, 0x6be22838, 0x9989ab3b,\n+    0x4d43cfd0, 0xbf284cd3, 0xac78bf27, 0x5e133c24, 0x105ec76f, 0xe235446c,\n+    0xf165b798, 0x030e349b, 0xd7c45070, 0x25afd373, 0x36ff2087, 0xc494a384,\n+    0x9a879fa0, 0x68ec1ca3, 0x7bbcef57, 0x89d76c54, 0x5d1d08bf, 0xaf768bbc,\n+    0xbc267848, 0x4e4dfb4b, 0x20bd8ede, 0xd2d60ddd, 0xc186fe29, 0x33ed7d2a,\n+    0xe72719c1, 0x154c9ac2, 0x061c6936, 0xf477ea35, 0xaa64d611, 0x580f5512,\n+    0x4b5fa6e6, 0xb93425e5, 0x6dfe410e, 0x9f95c20d, 0x8cc531f9, 0x7eaeb2fa,\n+    0x30e349b1, 0xc288cab2, 0xd1d83946, 0x23b3ba45, 0xf779deae, 0x05125dad,\n+    0x1642ae59, 0xe4292d5a, 0xba3a117e, 0x4851927d, 0x5b016189, 0xa96ae28a,\n+    0x7da08661, 0x8fcb0562, 0x9c9bf696, 0x6ef07595, 0x417b1dbc, 0xb3109ebf,\n+    0xa0406d4b, 0x522bee48, 0x86e18aa3, 0x748a09a0, 0x67dafa54, 0x95b17957,\n+    0xcba24573, 0x39c9c670, 0x2a993584, 0xd8f2b687, 0x0c38d26c, 0xfe53516f,\n+    0xed03a29b, 0x1f682198, 0x5125dad3, 0xa34e59d0, 0xb01eaa24, 0x42752927,\n+    0x96bf4dcc, 0x64d4cecf, 0x77843d3b, 0x85efbe38, 0xdbfc821c, 0x2997011f,\n+    0x3ac7f2eb, 0xc8ac71e8, 0x1c661503, 0xee0d9600, 0xfd5d65f4, 0x0f36e6f7,\n+    0x61c69362, 0x93ad1061, 0x80fde395, 0x72966096, 0xa65c047d, 0x5437877e,\n+    0x4767748a, 0xb50cf789, 0xeb1fcbad, 0x197448ae, 0x0a24bb5a, 0xf84f3859,\n+    0x2c855cb2, 0xdeeedfb1, 0xcdbe2c45, 0x3fd5af46, 0x7198540d, 0x83f3d70e,\n+    0x90a324fa, 0x62c8a7f9, 0xb602c312, 0x44694011, 0x5739b3e5, 0xa55230e6,\n+    0xfb410cc2, 0x092a8fc1, 0x1a7a7c35, 0xe811ff36, 0x3cdb9bdd, 0xceb018de,\n+    0xdde0eb2a, 0x2f8b6829, 0x82f63b78, 0x709db87b, 0x63cd4b8f, 0x91a6c88c,\n+    0x456cac67, 0xb7072f64, 0xa457dc90, 0x563c5f93, 0x082f63b7, 0xfa44e0b4,\n+    0xe9141340, 0x1b7f9043, 0xcfb5f4a8, 0x3dde77ab, 0x2e8e845f, 0xdce5075c,\n+    0x92a8fc17, 0x60c37f14, 0x73938ce0, 0x81f80fe3, 0x55326b08, 0xa759e80b,\n+    0xb4091bff, 0x466298fc, 0x1871a4d8, 0xea1a27db, 0xf94ad42f, 0x0b21572c,\n+    0xdfeb33c7, 0x2d80b0c4, 0x3ed04330, 0xccbbc033, 0xa24bb5a6, 0x502036a5,\n+    0x4370c551, 0xb11b4652, 0x65d122b9, 0x97baa1ba, 0x84ea524e, 0x7681d14d,\n+    0x2892ed69, 0xdaf96e6a, 0xc9a99d9e, 0x3bc21e9d, 0xef087a76, 0x1d63f975,\n+    0x0e330a81, 0xfc588982, 0xb21572c9, 0x407ef1ca, 0x532e023e, 0xa145813d,\n+    0x758fe5d6, 0x87e466d5, 0x94b49521, 0x66df1622, 0x38cc2a06, 0xcaa7a905,\n+    0xd9f75af1, 0x2b9cd9f2, 0xff56bd19, 0x0d3d3e1a, 0x1e6dcdee, 0xec064eed,\n+    0xc38d26c4, 0x31e6a5c7, 0x22b65633, 0xd0ddd530, 0x0417b1db, 0xf67c32d8,\n+    0xe52cc12c, 0x1747422f, 0x49547e0b, 0xbb3ffd08, 0xa86f0efc, 0x5a048dff,\n+    0x8ecee914, 0x7ca56a17, 0x6ff599e3, 0x9d9e1ae0, 0xd3d3e1ab, 0x21b862a8,\n+    0x32e8915c, 0xc083125f, 0x144976b4, 0xe622f5b7, 0xf5720643, 0x07198540,\n+    0x590ab964, 0xab613a67, 0xb831c993, 0x4a5a4a90, 0x9e902e7b, 0x6cfbad78,\n+    0x7fab5e8c, 0x8dc0dd8f, 0xe330a81a, 0x115b2b19, 0x020bd8ed, 0xf0605bee,\n+    0x24aa3f05, 0xd6c1bc06, 0xc5914ff2, 0x37faccf1, 0x69e9f0d5, 0x9b8273d6,\n+    0x88d28022, 0x7ab90321, 0xae7367ca, 0x5c18e4c9, 0x4f48173d, 0xbd23943e,\n+    0xf36e6f75, 0x0105ec76, 0x12551f82, 0xe03e9c81, 0x34f4f86a, 0xc69f7b69,\n+    0xd5cf889d, 0x27a40b9e, 0x79b737ba, 0x8bdcb4b9, 0x988c474d, 0x6ae7c44e,\n+    0xbe2da0a5, 0x4c4623a6, 0x5f16d052, 0xad7d5351};\n+\n+const uint32_t kStrideExtensionTable0[256] = {\n+    0x00000000, 0x30d23865, 0x61a470ca, 0x517648af, 0xc348e194, 0xf39ad9f1,\n+    0xa2ec915e, 0x923ea93b, 0x837db5d9, 0xb3af8dbc, 0xe2d9c513, 0xd20bfd76,\n+    0x4035544d, 0x70e76c28, 0x21912487, 0x11431ce2, 0x03171d43, 0x33c52526,\n+    0x62b36d89, 0x526155ec, 0xc05ffcd7, 0xf08dc4b2, 0xa1fb8c1d, 0x9129b478,\n+    0x806aa89a, 0xb0b890ff, 0xe1ced850, 0xd11ce035, 0x4322490e, 0x73f0716b,\n+    0x228639c4, 0x125401a1, 0x062e3a86, 0x36fc02e3, 0x678a4a4c, 0x57587229,\n+    0xc566db12, 0xf5b4e377, 0xa4c2abd8, 0x941093bd, 0x85538f5f, 0xb581b73a,\n+    0xe4f7ff95, 0xd425c7f0, 0x461b6ecb, 0x76c956ae, 0x27bf1e01, 0x176d2664,\n+    0x053927c5, 0x35eb1fa0, 0x649d570f, 0x544f6f6a, 0xc671c651, 0xf6a3fe34,\n+    0xa7d5b69b, 0x97078efe, 0x8644921c, 0xb696aa79, 0xe7e0e2d6, 0xd732dab3,\n+    0x450c7388, 0x75de4bed, 0x24a80342, 0x147a3b27, 0x0c5c750c, 0x3c8e4d69,\n+    0x6df805c6, 0x5d2a3da3, 0xcf149498, 0xffc6acfd, 0xaeb0e452, 0x9e62dc37,\n+    0x8f21c0d5, 0xbff3f8b0, 0xee85b01f, 0xde57887a, 0x4c692141, 0x7cbb1924,\n+    0x2dcd518b, 0x1d1f69ee, 0x0f4b684f, 0x3f99502a, 0x6eef1885, 0x5e3d20e0,\n+    0xcc0389db, 0xfcd1b1be, 0xada7f911, 0x9d75c174, 0x8c36dd96, 0xbce4e5f3,\n+    0xed92ad5c, 0xdd409539, 0x4f7e3c02, 0x7fac0467, 0x2eda4cc8, 0x1e0874ad,\n+    0x0a724f8a, 0x3aa077ef, 0x6bd63f40, 0x5b040725, 0xc93aae1e, 0xf9e8967b,\n+    0xa89eded4, 0x984ce6b1, 0x890ffa53, 0xb9ddc236, 0xe8ab8a99, 0xd879b2fc,\n+    0x4a471bc7, 0x7a9523a2, 0x2be36b0d, 0x1b315368, 0x096552c9, 0x39b76aac,\n+    0x68c12203, 0x58131a66, 0xca2db35d, 0xfaff8b38, 0xab89c397, 0x9b5bfbf2,\n+    0x8a18e710, 0xbacadf75, 0xebbc97da, 0xdb6eafbf, 0x49500684, 0x79823ee1,\n+    0x28f4764e, 0x18264e2b, 0x18b8ea18, 0x286ad27d, 0x791c9ad2, 0x49cea2b7,\n+    0xdbf00b8c, 0xeb2233e9, 0xba547b46, 0x8a864323, 0x9bc55fc1, 0xab1767a4,\n+    0xfa612f0b, 0xcab3176e, 0x588dbe55, 0x685f8630, 0x3929ce9f, 0x09fbf6fa,\n+    0x1baff75b, 0x2b7dcf3e, 0x7a0b8791, 0x4ad9bff4, 0xd8e716cf, 0xe8352eaa,\n+    0xb9436605, 0x89915e60, 0x98d24282, 0xa8007ae7, 0xf9763248, 0xc9a40a2d,\n+    0x5b9aa316, 0x6b489b73, 0x3a3ed3dc, 0x0aecebb9, 0x1e96d09e, 0x2e44e8fb,\n+    0x7f32a054, 0x4fe09831, 0xddde310a, 0xed0c096f, 0xbc7a41c0, 0x8ca879a5,\n+    0x9deb6547, 0xad395d22, 0xfc4f158d, 0xcc9d2de8, 0x5ea384d3, 0x6e71bcb6,\n+    0x3f07f419, 0x0fd5cc7c, 0x1d81cddd, 0x2d53f5b8, 0x7c25bd17, 0x4cf78572,\n+    0xdec92c49, 0xee1b142c, 0xbf6d5c83, 0x8fbf64e6, 0x9efc7804, 0xae2e4061,\n+    0xff5808ce, 0xcf8a30ab, 0x5db49990, 0x6d66a1f5, 0x3c10e95a, 0x0cc2d13f,\n+    0x14e49f14, 0x2436a771, 0x7540efde, 0x4592d7bb, 0xd7ac7e80, 0xe77e46e5,\n+    0xb6080e4a, 0x86da362f, 0x97992acd, 0xa74b12a8, 0xf63d5a07, 0xc6ef6262,\n+    0x54d1cb59, 0x6403f33c, 0x3575bb93, 0x05a783f6, 0x17f38257, 0x2721ba32,\n+    0x7657f29d, 0x4685caf8, 0xd4bb63c3, 0xe4695ba6, 0xb51f1309, 0x85cd2b6c,\n+    0x948e378e, 0xa45c0feb, 0xf52a4744, 0xc5f87f21, 0x57c6d61a, 0x6714ee7f,\n+    0x3662a6d0, 0x06b09eb5, 0x12caa592, 0x22189df7, 0x736ed558, 0x43bced3d,\n+    0xd1824406, 0xe1507c63, 0xb02634cc, 0x80f40ca9, 0x91b7104b, 0xa165282e,\n+    0xf0136081, 0xc0c158e4, 0x52fff1df, 0x622dc9ba, 0x335b8115, 0x0389b970,\n+    0x11ddb8d1, 0x210f80b4, 0x7079c81b, 0x40abf07e, 0xd2955945, 0xe2476120,\n+    0xb331298f, 0x83e311ea, 0x92a00d08, 0xa272356d, 0xf3047dc2, 0xc3d645a7,\n+    0x51e8ec9c, 0x613ad4f9, 0x304c9c56, 0x009ea433};\n+\n+const uint32_t kStrideExtensionTable1[256] = {\n+    0x00000000, 0x54075546, 0xa80eaa8c, 0xfc09ffca, 0x55f123e9, 0x01f676af,\n+    0xfdff8965, 0xa9f8dc23, 0xabe247d2, 0xffe51294, 0x03eced5e, 0x57ebb818,\n+    0xfe13643b, 0xaa14317d, 0x561dceb7, 0x021a9bf1, 0x5228f955, 0x062fac13,\n+    0xfa2653d9, 0xae21069f, 0x07d9dabc, 0x53de8ffa, 0xafd77030, 0xfbd02576,\n+    0xf9cabe87, 0xadcdebc1, 0x51c4140b, 0x05c3414d, 0xac3b9d6e, 0xf83cc828,\n+    0x043537e2, 0x503262a4, 0xa451f2aa, 0xf056a7ec, 0x0c5f5826, 0x58580d60,\n+    0xf1a0d143, 0xa5a78405, 0x59ae7bcf, 0x0da92e89, 0x0fb3b578, 0x5bb4e03e,\n+    0xa7bd1ff4, 0xf3ba4ab2, 0x5a429691, 0x0e45c3d7, 0xf24c3c1d, 0xa64b695b,\n+    0xf6790bff, 0xa27e5eb9, 0x5e77a173, 0x0a70f435, 0xa3882816, 0xf78f7d50,\n+    0x0b86829a, 0x5f81d7dc, 0x5d9b4c2d, 0x099c196b, 0xf595e6a1, 0xa192b3e7,\n+    0x086a6fc4, 0x5c6d3a82, 0xa064c548, 0xf463900e, 0x4d4f93a5, 0x1948c6e3,\n+    0xe5413929, 0xb1466c6f, 0x18beb04c, 0x4cb9e50a, 0xb0b01ac0, 0xe4b74f86,\n+    0xe6add477, 0xb2aa8131, 0x4ea37efb, 0x1aa42bbd, 0xb35cf79e, 0xe75ba2d8,\n+    0x1b525d12, 0x4f550854, 0x1f676af0, 0x4b603fb6, 0xb769c07c, 0xe36e953a,\n+    0x4a964919, 0x1e911c5f, 0xe298e395, 0xb69fb6d3, 0xb4852d22, 0xe0827864,\n+    0x1c8b87ae, 0x488cd2e8, 0xe1740ecb, 0xb5735b8d, 0x497aa447, 0x1d7df101,\n+    0xe91e610f, 0xbd193449, 0x4110cb83, 0x15179ec5, 0xbcef42e6, 0xe8e817a0,\n+    0x14e1e86a, 0x40e6bd2c, 0x42fc26dd, 0x16fb739b, 0xeaf28c51, 0xbef5d917,\n+    0x170d0534, 0x430a5072, 0xbf03afb8, 0xeb04fafe, 0xbb36985a, 0xef31cd1c,\n+    0x133832d6, 0x473f6790, 0xeec7bbb3, 0xbac0eef5, 0x46c9113f, 0x12ce4479,\n+    0x10d4df88, 0x44d38ace, 0xb8da7504, 0xecdd2042, 0x4525fc61, 0x1122a927,\n+    0xed2b56ed, 0xb92c03ab, 0x9a9f274a, 0xce98720c, 0x32918dc6, 0x6696d880,\n+    0xcf6e04a3, 0x9b6951e5, 0x6760ae2f, 0x3367fb69, 0x317d6098, 0x657a35de,\n+    0x9973ca14, 0xcd749f52, 0x648c4371, 0x308b1637, 0xcc82e9fd, 0x9885bcbb,\n+    0xc8b7de1f, 0x9cb08b59, 0x60b97493, 0x34be21d5, 0x9d46fdf6, 0xc941a8b0,\n+    0x3548577a, 0x614f023c, 0x635599cd, 0x3752cc8b, 0xcb5b3341, 0x9f5c6607,\n+    0x36a4ba24, 0x62a3ef62, 0x9eaa10a8, 0xcaad45ee, 0x3eced5e0, 0x6ac980a6,\n+    0x96c07f6c, 0xc2c72a2a, 0x6b3ff609, 0x3f38a34f, 0xc3315c85, 0x973609c3,\n+    0x952c9232, 0xc12bc774, 0x3d2238be, 0x69256df8, 0xc0ddb1db, 0x94dae49d,\n+    0x68d31b57, 0x3cd44e11, 0x6ce62cb5, 0x38e179f3, 0xc4e88639, 0x90efd37f,\n+    0x39170f5c, 0x6d105a1a, 0x9119a5d0, 0xc51ef096, 0xc7046b67, 0x93033e21,\n+    0x6f0ac1eb, 0x3b0d94ad, 0x92f5488e, 0xc6f21dc8, 0x3afbe202, 0x6efcb744,\n+    0xd7d0b4ef, 0x83d7e1a9, 0x7fde1e63, 0x2bd94b25, 0x82219706, 0xd626c240,\n+    0x2a2f3d8a, 0x7e2868cc, 0x7c32f33d, 0x2835a67b, 0xd43c59b1, 0x803b0cf7,\n+    0x29c3d0d4, 0x7dc48592, 0x81cd7a58, 0xd5ca2f1e, 0x85f84dba, 0xd1ff18fc,\n+    0x2df6e736, 0x79f1b270, 0xd0096e53, 0x840e3b15, 0x7807c4df, 0x2c009199,\n+    0x2e1a0a68, 0x7a1d5f2e, 0x8614a0e4, 0xd213f5a2, 0x7beb2981, 0x2fec7cc7,\n+    0xd3e5830d, 0x87e2d64b, 0x73814645, 0x27861303, 0xdb8fecc9, 0x8f88b98f,\n+    0x267065ac, 0x727730ea, 0x8e7ecf20, 0xda799a66, 0xd8630197, 0x8c6454d1,\n+    0x706dab1b, 0x246afe5d, 0x8d92227e, 0xd9957738, 0x259c88f2, 0x719bddb4,\n+    0x21a9bf10, 0x75aeea56, 0x89a7159c, 0xdda040da, 0x74589cf9, 0x205fc9bf,\n+    0xdc563675, 0x88516333, 0x8a4bf8c2, 0xde4cad84, 0x2245524e, 0x76420708,\n+    0xdfbadb2b, 0x8bbd8e6d, 0x77b471a7, 0x23b324e1};\n+\n+const uint32_t kStrideExtensionTable2[256] = {\n+    0x00000000, 0x678efd01, 0xcf1dfa02, 0xa8930703, 0x9bd782f5, 0xfc597ff4,\n+    0x54ca78f7, 0x334485f6, 0x3243731b, 0x55cd8e1a, 0xfd5e8919, 0x9ad07418,\n+    0xa994f1ee, 0xce1a0cef, 0x66890bec, 0x0107f6ed, 0x6486e636, 0x03081b37,\n+    0xab9b1c34, 0xcc15e135, 0xff5164c3, 0x98df99c2, 0x304c9ec1, 0x57c263c0,\n+    0x56c5952d, 0x314b682c, 0x99d86f2f, 0xfe56922e, 0xcd1217d8, 0xaa9cead9,\n+    0x020fedda, 0x658110db, 0xc90dcc6c, 0xae83316d, 0x0610366e, 0x619ecb6f,\n+    0x52da4e99, 0x3554b398, 0x9dc7b49b, 0xfa49499a, 0xfb4ebf77, 0x9cc04276,\n+    0x34534575, 0x53ddb874, 0x60993d82, 0x0717c083, 0xaf84c780, 0xc80a3a81,\n+    0xad8b2a5a, 0xca05d75b, 0x6296d058, 0x05182d59, 0x365ca8af, 0x51d255ae,\n+    0xf94152ad, 0x9ecfafac, 0x9fc85941, 0xf846a440, 0x50d5a343, 0x375b5e42,\n+    0x041fdbb4, 0x639126b5, 0xcb0221b6, 0xac8cdcb7, 0x97f7ee29, 0xf0791328,\n+    0x58ea142b, 0x3f64e92a, 0x0c206cdc, 0x6bae91dd, 0xc33d96de, 0xa4b36bdf,\n+    0xa5b49d32, 0xc23a6033, 0x6aa96730, 0x0d279a31, 0x3e631fc7, 0x59ede2c6,\n+    0xf17ee5c5, 0x96f018c4, 0xf371081f, 0x94fff51e, 0x3c6cf21d, 0x5be20f1c,\n+    0x68a68aea, 0x0f2877eb, 0xa7bb70e8, 0xc0358de9, 0xc1327b04, 0xa6bc8605,\n+    0x0e2f8106, 0x69a17c07, 0x5ae5f9f1, 0x3d6b04f0, 0x95f803f3, 0xf276fef2,\n+    0x5efa2245, 0x3974df44, 0x91e7d847, 0xf6692546, 0xc52da0b0, 0xa2a35db1,\n+    0x0a305ab2, 0x6dbea7b3, 0x6cb9515e, 0x0b37ac5f, 0xa3a4ab5c, 0xc42a565d,\n+    0xf76ed3ab, 0x90e02eaa, 0x387329a9, 0x5ffdd4a8, 0x3a7cc473, 0x5df23972,\n+    0xf5613e71, 0x92efc370, 0xa1ab4686, 0xc625bb87, 0x6eb6bc84, 0x09384185,\n+    0x083fb768, 0x6fb14a69, 0xc7224d6a, 0xa0acb06b, 0x93e8359d, 0xf466c89c,\n+    0x5cf5cf9f, 0x3b7b329e, 0x2a03aaa3, 0x4d8d57a2, 0xe51e50a1, 0x8290ada0,\n+    0xb1d42856, 0xd65ad557, 0x7ec9d254, 0x19472f55, 0x1840d9b8, 0x7fce24b9,\n+    0xd75d23ba, 0xb0d3debb, 0x83975b4d, 0xe419a64c, 0x4c8aa14f, 0x2b045c4e,\n+    0x4e854c95, 0x290bb194, 0x8198b697, 0xe6164b96, 0xd552ce60, 0xb2dc3361,\n+    0x1a4f3462, 0x7dc1c963, 0x7cc63f8e, 0x1b48c28f, 0xb3dbc58c, 0xd455388d,\n+    0xe711bd7b, 0x809f407a, 0x280c4779, 0x4f82ba78, 0xe30e66cf, 0x84809bce,\n+    0x2c139ccd, 0x4b9d61cc, 0x78d9e43a, 0x1f57193b, 0xb7c41e38, 0xd04ae339,\n+    0xd14d15d4, 0xb6c3e8d5, 0x1e50efd6, 0x79de12d7, 0x4a9a9721, 0x2d146a20,\n+    0x85876d23, 0xe2099022, 0x878880f9, 0xe0067df8, 0x48957afb, 0x2f1b87fa,\n+    0x1c5f020c, 0x7bd1ff0d, 0xd342f80e, 0xb4cc050f, 0xb5cbf3e2, 0xd2450ee3,\n+    0x7ad609e0, 0x1d58f4e1, 0x2e1c7117, 0x49928c16, 0xe1018b15, 0x868f7614,\n+    0xbdf4448a, 0xda7ab98b, 0x72e9be88, 0x15674389, 0x2623c67f, 0x41ad3b7e,\n+    0xe93e3c7d, 0x8eb0c17c, 0x8fb73791, 0xe839ca90, 0x40aacd93, 0x27243092,\n+    0x1460b564, 0x73ee4865, 0xdb7d4f66, 0xbcf3b267, 0xd972a2bc, 0xbefc5fbd,\n+    0x166f58be, 0x71e1a5bf, 0x42a52049, 0x252bdd48, 0x8db8da4b, 0xea36274a,\n+    0xeb31d1a7, 0x8cbf2ca6, 0x242c2ba5, 0x43a2d6a4, 0x70e65352, 0x1768ae53,\n+    0xbffba950, 0xd8755451, 0x74f988e6, 0x137775e7, 0xbbe472e4, 0xdc6a8fe5,\n+    0xef2e0a13, 0x88a0f712, 0x2033f011, 0x47bd0d10, 0x46bafbfd, 0x213406fc,\n+    0x89a701ff, 0xee29fcfe, 0xdd6d7908, 0xbae38409, 0x1270830a, 0x75fe7e0b,\n+    0x107f6ed0, 0x77f193d1, 0xdf6294d2, 0xb8ec69d3, 0x8ba8ec25, 0xec261124,\n+    0x44b51627, 0x233beb26, 0x223c1dcb, 0x45b2e0ca, 0xed21e7c9, 0x8aaf1ac8,\n+    0xb9eb9f3e, 0xde65623f, 0x76f6653c, 0x1178983d};\n+\n+const uint32_t kStrideExtensionTable3[256] = {\n+    0x00000000, 0xf20c0dfe, 0xe1f46d0d, 0x13f860f3, 0xc604aceb, 0x3408a115,\n+    0x27f0c1e6, 0xd5fccc18, 0x89e52f27, 0x7be922d9, 0x6811422a, 0x9a1d4fd4,\n+    0x4fe183cc, 0xbded8e32, 0xae15eec1, 0x5c19e33f, 0x162628bf, 0xe42a2541,\n+    0xf7d245b2, 0x05de484c, 0xd0228454, 0x222e89aa, 0x31d6e959, 0xc3dae4a7,\n+    0x9fc30798, 0x6dcf0a66, 0x7e376a95, 0x8c3b676b, 0x59c7ab73, 0xabcba68d,\n+    0xb833c67e, 0x4a3fcb80, 0x2c4c517e, 0xde405c80, 0xcdb83c73, 0x3fb4318d,\n+    0xea48fd95, 0x1844f06b, 0x0bbc9098, 0xf9b09d66, 0xa5a97e59, 0x57a573a7,\n+    0x445d1354, 0xb6511eaa, 0x63add2b2, 0x91a1df4c, 0x8259bfbf, 0x7055b241,\n+    0x3a6a79c1, 0xc866743f, 0xdb9e14cc, 0x29921932, 0xfc6ed52a, 0x0e62d8d4,\n+    0x1d9ab827, 0xef96b5d9, 0xb38f56e6, 0x41835b18, 0x527b3beb, 0xa0773615,\n+    0x758bfa0d, 0x8787f7f3, 0x947f9700, 0x66739afe, 0x5898a2fc, 0xaa94af02,\n+    0xb96ccff1, 0x4b60c20f, 0x9e9c0e17, 0x6c9003e9, 0x7f68631a, 0x8d646ee4,\n+    0xd17d8ddb, 0x23718025, 0x3089e0d6, 0xc285ed28, 0x17792130, 0xe5752cce,\n+    0xf68d4c3d, 0x048141c3, 0x4ebe8a43, 0xbcb287bd, 0xaf4ae74e, 0x5d46eab0,\n+    0x88ba26a8, 0x7ab62b56, 0x694e4ba5, 0x9b42465b, 0xc75ba564, 0x3557a89a,\n+    0x26afc869, 0xd4a3c597, 0x015f098f, 0xf3530471, 0xe0ab6482, 0x12a7697c,\n+    0x74d4f382, 0x86d8fe7c, 0x95209e8f, 0x672c9371, 0xb2d05f69, 0x40dc5297,\n+    0x53243264, 0xa1283f9a, 0xfd31dca5, 0x0f3dd15b, 0x1cc5b1a8, 0xeec9bc56,\n+    0x3b35704e, 0xc9397db0, 0xdac11d43, 0x28cd10bd, 0x62f2db3d, 0x90fed6c3,\n+    0x8306b630, 0x710abbce, 0xa4f677d6, 0x56fa7a28, 0x45021adb, 0xb70e1725,\n+    0xeb17f41a, 0x191bf9e4, 0x0ae39917, 0xf8ef94e9, 0x2d1358f1, 0xdf1f550f,\n+    0xcce735fc, 0x3eeb3802, 0xb13145f8, 0x433d4806, 0x50c528f5, 0xa2c9250b,\n+    0x7735e913, 0x8539e4ed, 0x96c1841e, 0x64cd89e0, 0x38d46adf, 0xcad86721,\n+    0xd92007d2, 0x2b2c0a2c, 0xfed0c634, 0x0cdccbca, 0x1f24ab39, 0xed28a6c7,\n+    0xa7176d47, 0x551b60b9, 0x46e3004a, 0xb4ef0db4, 0x6113c1ac, 0x931fcc52,\n+    0x80e7aca1, 0x72eba15f, 0x2ef24260, 0xdcfe4f9e, 0xcf062f6d, 0x3d0a2293,\n+    0xe8f6ee8b, 0x1afae375, 0x09028386, 0xfb0e8e78, 0x9d7d1486, 0x6f711978,\n+    0x7c89798b, 0x8e857475, 0x5b79b86d, 0xa975b593, 0xba8dd560, 0x4881d89e,\n+    0x14983ba1, 0xe694365f, 0xf56c56ac, 0x07605b52, 0xd29c974a, 0x20909ab4,\n+    0x3368fa47, 0xc164f7b9, 0x8b5b3c39, 0x795731c7, 0x6aaf5134, 0x98a35cca,\n+    0x4d5f90d2, 0xbf539d2c, 0xacabfddf, 0x5ea7f021, 0x02be131e, 0xf0b21ee0,\n+    0xe34a7e13, 0x114673ed, 0xc4babff5, 0x36b6b20b, 0x254ed2f8, 0xd742df06,\n+    0xe9a9e704, 0x1ba5eafa, 0x085d8a09, 0xfa5187f7, 0x2fad4bef, 0xdda14611,\n+    0xce5926e2, 0x3c552b1c, 0x604cc823, 0x9240c5dd, 0x81b8a52e, 0x73b4a8d0,\n+    0xa64864c8, 0x54446936, 0x47bc09c5, 0xb5b0043b, 0xff8fcfbb, 0x0d83c245,\n+    0x1e7ba2b6, 0xec77af48, 0x398b6350, 0xcb876eae, 0xd87f0e5d, 0x2a7303a3,\n+    0x766ae09c, 0x8466ed62, 0x979e8d91, 0x6592806f, 0xb06e4c77, 0x42624189,\n+    0x519a217a, 0xa3962c84, 0xc5e5b67a, 0x37e9bb84, 0x2411db77, 0xd61dd689,\n+    0x03e11a91, 0xf1ed176f, 0xe215779c, 0x10197a62, 0x4c00995d, 0xbe0c94a3,\n+    0xadf4f450, 0x5ff8f9ae, 0x8a0435b6, 0x78083848, 0x6bf058bb, 0x99fc5545,\n+    0xd3c39ec5, 0x21cf933b, 0x3237f3c8, 0xc03bfe36, 0x15c7322e, 0xe7cb3fd0,\n+    0xf4335f23, 0x063f52dd, 0x5a26b1e2, 0xa82abc1c, 0xbbd2dcef, 0x49ded111,\n+    0x9c221d09, 0x6e2e10f7, 0x7dd67004, 0x8fda7dfa};\n+\n+constexpr const ptrdiff_t kPrefetchHorizon = 256;\n+\n+}  // namespace\n+\n+namespace crc32c {\n+\n+uint32_t ExtendPortable(uint32_t crc, const uint8_t* data, size_t size) {\n+  const uint8_t* p = data;\n+  const uint8_t* e = p + size;\n+  uint32_t l = crc ^ kCRC32Xor;\n+\n+// Process one byte at a time.\n+#define STEP1                              \\\n+  do {                                     \\\n+    int c = (l & 0xff) ^ *p++;             \\\n+    l = kByteExtensionTable[c] ^ (l >> 8); \\\n+  } while (0)\n+\n+// Process one of the 4 strides of 4-byte data.\n+#define STEP4(s)                                                               \\\n+  do {                                                                         \\\n+    crc##s = ReadUint32LE(p + s * 4) ^ kStrideExtensionTable3[crc##s & 0xff] ^ \\\n+             kStrideExtensionTable2[(crc##s >> 8) & 0xff] ^                    \\\n+             kStrideExtensionTable1[(crc##s >> 16) & 0xff] ^                   \\\n+             kStrideExtensionTable0[crc##s >> 24];                             \\\n+  } while (0)\n+\n+// Process a 16-byte swath of 4 strides, each of which has 4 bytes of data.\n+#define STEP16 \\\n+  do {         \\\n+    STEP4(0);  \\\n+    STEP4(1);  \\\n+    STEP4(2);  \\\n+    STEP4(3);  \\\n+    p += 16;   \\\n+  } while (0)\n+\n+// Process 4 bytes that were already loaded into a word.\n+#define STEP4W(w)                                   \\\n+  do {                                              \\\n+    w ^= l;                                         \\\n+    for (size_t i = 0; i < 4; ++i) {                \\\n+      w = (w >> 8) ^ kByteExtensionTable[w & 0xff]; \\\n+    }                                               \\\n+    l = w;                                          \\\n+  } while (0)\n+\n+  // Point x at first 4-byte aligned byte in the buffer. This might be past the\n+  // end of the buffer.\n+  const uint8_t* x = RoundUp<4>(p);\n+  if (x <= e) {\n+    // Process bytes p is 4-byte aligned.\n+    while (p != x) {\n+      STEP1;\n+    }\n+  }\n+\n+  if ((e - p) >= 16) {\n+    // Load a 16-byte swath into the stride partial results.\n+    uint32_t crc0 = ReadUint32LE(p + 0 * 4) ^ l;\n+    uint32_t crc1 = ReadUint32LE(p + 1 * 4);\n+    uint32_t crc2 = ReadUint32LE(p + 2 * 4);\n+    uint32_t crc3 = ReadUint32LE(p + 3 * 4);\n+    p += 16;\n+\n+    while ((e - p) > kPrefetchHorizon) {\n+      RequestPrefetch(p + kPrefetchHorizon);\n+\n+      // Process 64 bytes at a time.\n+      STEP16;\n+      STEP16;\n+      STEP16;\n+      STEP16;\n+    }\n+\n+    // Process one 16-byte swath at a time.\n+    while ((e - p) >= 16) {\n+      STEP16;\n+    }\n+\n+    // Advance one word at a time as far as possible.\n+    while ((e - p) >= 4) {\n+      STEP4(0);\n+      uint32_t tmp = crc0;\n+      crc0 = crc1;\n+      crc1 = crc2;\n+      crc2 = crc3;\n+      crc3 = tmp;\n+      p += 4;\n+    }\n+\n+    // Combine the 4 partial stride results.\n+    l = 0;\n+    STEP4W(crc0);\n+    STEP4W(crc1);\n+    STEP4W(crc2);\n+    STEP4W(crc3);\n+  }\n+\n+  // Process the last few bytes.\n+  while (p != e) {\n+    STEP1;\n+  }\n+#undef STEP4W\n+#undef STEP16\n+#undef STEP4\n+#undef STEP1\n+  return l ^ kCRC32Xor;\n+}\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "5098e2c373ff3fd66a06446c6afc1d7ba6e95a6e",
        "filename": "src/crc32c_portable_unittest.cc",
        "status": "added",
        "additions": 20,
        "deletions": 0,
        "changes": 20,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_portable_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_portable_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_portable_unittest.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,20 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"gtest/gtest.h\"\n+\n+#include \"./crc32c_extend_unittests.h\"\n+#include \"./crc32c_internal.h\"\n+\n+namespace crc32c {\n+\n+struct PortableTestTraits {\n+  static uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count) {\n+    return ExtendPortable(crc, data, count);\n+  }\n+};\n+\n+INSTANTIATE_TYPED_TEST_SUITE_P(Portable, ExtendTest, PortableTestTraits);\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "aec7d54e84e571c4d7ae489d2177623204c549a7",
        "filename": "src/crc32c_prefetch.h",
        "status": "added",
        "additions": 46,
        "deletions": 0,
        "changes": 46,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_prefetch.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_prefetch.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_prefetch.h?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,46 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_PREFETCH_H_\n+#define CRC32C_CRC32C_PREFETCH_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_MM_PREFETCH\n+\n+#if defined(_MSC_VER)\n+#include <intrin.h>\n+#else  // !defined(_MSC_VER)\n+#include <xmmintrin.h>\n+#endif  // defined(_MSC_VER)\n+\n+#endif  // HAVE_MM_PREFETCH\n+\n+namespace crc32c {\n+\n+// Ask the hardware to prefetch the data at the given address into the L1 cache.\n+inline void RequestPrefetch(const uint8_t* address) {\n+#if HAVE_BUILTIN_PREFETCH\n+  // Clang and GCC implement the __builtin_prefetch non-standard extension,\n+  // which maps to the best instruction on the target architecture.\n+  __builtin_prefetch(reinterpret_cast<const char*>(address), 0 /* Read only. */,\n+                     0 /* No temporal locality. */);\n+#elif HAVE_MM_PREFETCH\n+  // Visual Studio doesn't implement __builtin_prefetch, but exposes the\n+  // PREFETCHNTA instruction via the _mm_prefetch intrinsic.\n+  _mm_prefetch(reinterpret_cast<const char*>(address), _MM_HINT_NTA);\n+#else\n+  // No prefetch support. Silence compiler warnings.\n+  (void)address;\n+#endif  // HAVE_BUILTIN_PREFETCH\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // CRC32C_CRC32C_ROUND_UP_H_"
      },
      {
        "sha": "b34ed2d5fec67cd4e351c04a63aeb5c62f779357",
        "filename": "src/crc32c_prefetch_unittest.cc",
        "status": "added",
        "additions": 9,
        "deletions": 0,
        "changes": 9,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_prefetch_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_prefetch_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_prefetch_unittest.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,9 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_prefetch.h\"\n+\n+// There is no easy way to test cache prefetching. We can only test that the\n+// crc32c_prefetch.h header compiles on its own, so it doesn't have any unstated\n+// dependencies."
      },
      {
        "sha": "3bd45fe3aa9e2e13cbe019823db1898ea4616a82",
        "filename": "src/crc32c_read_le.h",
        "status": "added",
        "additions": 53,
        "deletions": 0,
        "changes": 53,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_read_le.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_read_le.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_read_le.h?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,53 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_READ_LE_H_\n+#define CRC32C_CRC32C_READ_LE_H_\n+\n+#include <cstdint>\n+#include <cstring>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+namespace crc32c {\n+\n+// Reads a little-endian 32-bit integer from a 32-bit-aligned buffer.\n+inline uint32_t ReadUint32LE(const uint8_t* buffer) {\n+#if BYTE_ORDER_BIG_ENDIAN\n+  return ((static_cast<uint32_t>(static_cast<uint8_t>(buffer[0]))) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[1])) << 8) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[2])) << 16) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[3])) << 24));\n+#else   // !BYTE_ORDER_BIG_ENDIAN\n+  uint32_t result;\n+  // This should be optimized to a single instruction.\n+  std::memcpy(&result, buffer, sizeof(result));\n+  return result;\n+#endif  // BYTE_ORDER_BIG_ENDIAN\n+}\n+\n+// Reads a little-endian 64-bit integer from a 64-bit-aligned buffer.\n+inline uint64_t ReadUint64LE(const uint8_t* buffer) {\n+#if BYTE_ORDER_BIG_ENDIAN\n+  return ((static_cast<uint32_t>(static_cast<uint8_t>(buffer[0]))) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[1])) << 8) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[2])) << 16) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[3])) << 24) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[4])) << 32) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[5])) << 40) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[6])) << 48) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[7])) << 56));\n+#else   // !BYTE_ORDER_BIG_ENDIAN\n+  uint64_t result;\n+  // This should be optimized to a single instruction.\n+  std::memcpy(&result, buffer, sizeof(result));\n+  return result;\n+#endif  // BYTE_ORDER_BIG_ENDIAN\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // CRC32C_CRC32C_READ_LE_H_"
      },
      {
        "sha": "2a30302adf5f8654055a3e6e4c80bd0f96fc44ea",
        "filename": "src/crc32c_read_le_unittest.cc",
        "status": "added",
        "additions": 32,
        "deletions": 0,
        "changes": 32,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_read_le_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_read_le_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_read_le_unittest.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,32 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_read_le.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"gtest/gtest.h\"\n+\n+#include \"./crc32c_round_up.h\"\n+\n+namespace crc32c {\n+\n+TEST(Crc32CReadLETest, ReadUint32LE) {\n+  // little-endian 0x12345678\n+  alignas(4) uint8_t bytes[] = {0x78, 0x56, 0x34, 0x12};\n+\n+  ASSERT_EQ(RoundUp<4>(bytes), bytes) << \"Stack array is not aligned\";\n+  EXPECT_EQ(static_cast<uint32_t>(0x12345678), ReadUint32LE(bytes));\n+}\n+\n+TEST(Crc32CReadLETest, ReadUint64LE) {\n+  // little-endian 0x123456789ABCDEF0\n+  alignas(8) uint8_t bytes[] = {0xF0, 0xDE, 0xBC, 0x9A, 0x78, 0x56, 0x34, 0x12};\n+\n+  ASSERT_EQ(RoundUp<8>(bytes), bytes) << \"Stack array is not aligned\";\n+  EXPECT_EQ(static_cast<uint64_t>(0x123456789ABCDEF0), ReadUint64LE(bytes));\n+}\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "d3b922beb95dc783acf107953872ae3bc00087a0",
        "filename": "src/crc32c_round_up.h",
        "status": "added",
        "additions": 34,
        "deletions": 0,
        "changes": 34,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_round_up.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_round_up.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_round_up.h?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,34 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_ROUND_UP_H_\n+#define CRC32C_CRC32C_ROUND_UP_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+namespace crc32c {\n+\n+// Returns the smallest number >= the given number that is evenly divided by N.\n+//\n+// N must be a power of two.\n+template <int N>\n+constexpr inline uintptr_t RoundUp(uintptr_t pointer) {\n+  static_assert((N & (N - 1)) == 0, \"N must be a power of two\");\n+  return (pointer + (N - 1)) & ~(N - 1);\n+}\n+\n+// Returns the smallest address >= the given address that is aligned to N bytes.\n+//\n+// N must be a power of two.\n+template <int N>\n+constexpr inline const uint8_t* RoundUp(const uint8_t* pointer) {\n+  static_assert((N & (N - 1)) == 0, \"N must be a power of two\");\n+  return reinterpret_cast<uint8_t*>(\n+      RoundUp<N>(reinterpret_cast<uintptr_t>(pointer)));\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // CRC32C_CRC32C_ROUND_UP_H_"
      },
      {
        "sha": "5ff657bb5c749d06ca119bd815d43b0f444857b2",
        "filename": "src/crc32c_round_up_unittest.cc",
        "status": "added",
        "additions": 84,
        "deletions": 0,
        "changes": 84,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_round_up_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_round_up_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_round_up_unittest.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,84 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_round_up.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"gtest/gtest.h\"\n+\n+namespace crc32c {\n+\n+TEST(CRC32CRoundUpTest, RoundUpUintptr) {\n+  uintptr_t zero = 0;\n+\n+  ASSERT_EQ(zero, RoundUp<1>(zero));\n+  ASSERT_EQ(1U, RoundUp<1>(1U));\n+  ASSERT_EQ(2U, RoundUp<1>(2U));\n+  ASSERT_EQ(3U, RoundUp<1>(3U));\n+  ASSERT_EQ(~static_cast<uintptr_t>(0), RoundUp<1>(~static_cast<uintptr_t>(0)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(1), RoundUp<1>(~static_cast<uintptr_t>(1)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(2), RoundUp<1>(~static_cast<uintptr_t>(2)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<1>(~static_cast<uintptr_t>(3)));\n+\n+  ASSERT_EQ(zero, RoundUp<2>(zero));\n+  ASSERT_EQ(2U, RoundUp<2>(1U));\n+  ASSERT_EQ(2U, RoundUp<2>(2U));\n+  ASSERT_EQ(4U, RoundUp<2>(3U));\n+  ASSERT_EQ(4U, RoundUp<2>(4U));\n+  ASSERT_EQ(6U, RoundUp<2>(5U));\n+  ASSERT_EQ(6U, RoundUp<2>(6U));\n+  ASSERT_EQ(8U, RoundUp<2>(7U));\n+  ASSERT_EQ(8U, RoundUp<2>(8U));\n+  ASSERT_EQ(~static_cast<uintptr_t>(1), RoundUp<2>(~static_cast<uintptr_t>(1)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(1), RoundUp<2>(~static_cast<uintptr_t>(2)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<2>(~static_cast<uintptr_t>(3)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<2>(~static_cast<uintptr_t>(4)));\n+\n+  ASSERT_EQ(zero, RoundUp<4>(zero));\n+  ASSERT_EQ(4U, RoundUp<4>(1U));\n+  ASSERT_EQ(4U, RoundUp<4>(2U));\n+  ASSERT_EQ(4U, RoundUp<4>(3U));\n+  ASSERT_EQ(4U, RoundUp<4>(4U));\n+  ASSERT_EQ(8U, RoundUp<4>(5U));\n+  ASSERT_EQ(8U, RoundUp<4>(6U));\n+  ASSERT_EQ(8U, RoundUp<4>(7U));\n+  ASSERT_EQ(8U, RoundUp<4>(8U));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<4>(~static_cast<uintptr_t>(3)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<4>(~static_cast<uintptr_t>(4)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<4>(~static_cast<uintptr_t>(5)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<4>(~static_cast<uintptr_t>(6)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(7), RoundUp<4>(~static_cast<uintptr_t>(7)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(7), RoundUp<4>(~static_cast<uintptr_t>(8)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(7), RoundUp<4>(~static_cast<uintptr_t>(9)));\n+}\n+\n+TEST(CRC32CRoundUpTest, RoundUpPointer) {\n+  uintptr_t zero = 0, three = 3, four = 4, seven = 7, eight = 8;\n+\n+  const uint8_t* zero_ptr = reinterpret_cast<const uint8_t*>(zero);\n+  const uint8_t* three_ptr = reinterpret_cast<const uint8_t*>(three);\n+  const uint8_t* four_ptr = reinterpret_cast<const uint8_t*>(four);\n+  const uint8_t* seven_ptr = reinterpret_cast<const uint8_t*>(seven);\n+  const uint8_t* eight_ptr = reinterpret_cast<uint8_t*>(eight);\n+\n+  ASSERT_EQ(zero_ptr, RoundUp<1>(zero_ptr));\n+  ASSERT_EQ(zero_ptr, RoundUp<4>(zero_ptr));\n+  ASSERT_EQ(zero_ptr, RoundUp<8>(zero_ptr));\n+\n+  ASSERT_EQ(three_ptr, RoundUp<1>(three_ptr));\n+  ASSERT_EQ(four_ptr, RoundUp<4>(three_ptr));\n+  ASSERT_EQ(eight_ptr, RoundUp<8>(three_ptr));\n+\n+  ASSERT_EQ(four_ptr, RoundUp<1>(four_ptr));\n+  ASSERT_EQ(four_ptr, RoundUp<4>(four_ptr));\n+  ASSERT_EQ(eight_ptr, RoundUp<8>(four_ptr));\n+\n+  ASSERT_EQ(seven_ptr, RoundUp<1>(seven_ptr));\n+  ASSERT_EQ(eight_ptr, RoundUp<4>(seven_ptr));\n+  ASSERT_EQ(eight_ptr, RoundUp<8>(four_ptr));\n+}\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "139520428e08dd3e1738791e6227dbfd67564d52",
        "filename": "src/crc32c_sse42.cc",
        "status": "added",
        "additions": 258,
        "deletions": 0,
        "changes": 258,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_sse42.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_sse42.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_sse42.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,258 @@\n+// Copyright 2008 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_sse42.h\"\n+\n+// In a separate source file to allow this accelerated CRC32C function to be\n+// compiled with the appropriate compiler flags to enable SSE4.2 instructions.\n+\n+// This implementation is loosely based on Intel Pub 323405 from April 2011,\n+// \"Fast CRC Computation for iSCSI Polynomial Using CRC32 Instruction\".\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"./crc32c_internal.h\"\n+#include \"./crc32c_prefetch.h\"\n+#include \"./crc32c_read_le.h\"\n+#include \"./crc32c_round_up.h\"\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+#if defined(_MSC_VER)\n+#include <intrin.h>\n+#else  // !defined(_MSC_VER)\n+#include <nmmintrin.h>\n+#endif  // defined(_MSC_VER)\n+\n+namespace crc32c {\n+\n+namespace {\n+\n+constexpr const ptrdiff_t kGroups = 3;\n+constexpr const ptrdiff_t kBlock0Size = 16 * 1024 / kGroups / 64 * 64;\n+constexpr const ptrdiff_t kBlock1Size = 4 * 1024 / kGroups / 8 * 8;\n+constexpr const ptrdiff_t kBlock2Size = 1024 / kGroups / 8 * 8;\n+\n+const uint32_t kBlock0SkipTable[8][16] = {\n+    {0x00000000, 0xff770459, 0xfb027e43, 0x04757a1a, 0xf3e88a77, 0x0c9f8e2e,\n+     0x08eaf434, 0xf79df06d, 0xe23d621f, 0x1d4a6646, 0x193f1c5c, 0xe6481805,\n+     0x11d5e868, 0xeea2ec31, 0xead7962b, 0x15a09272},\n+    {0x00000000, 0xc196b2cf, 0x86c1136f, 0x4757a1a0, 0x086e502f, 0xc9f8e2e0,\n+     0x8eaf4340, 0x4f39f18f, 0x10dca05e, 0xd14a1291, 0x961db331, 0x578b01fe,\n+     0x18b2f071, 0xd92442be, 0x9e73e31e, 0x5fe551d1},\n+    {0x00000000, 0x21b940bc, 0x43728178, 0x62cbc1c4, 0x86e502f0, 0xa75c424c,\n+     0xc5978388, 0xe42ec334, 0x08267311, 0x299f33ad, 0x4b54f269, 0x6aedb2d5,\n+     0x8ec371e1, 0xaf7a315d, 0xcdb1f099, 0xec08b025},\n+    {0x00000000, 0x104ce622, 0x2099cc44, 0x30d52a66, 0x41339888, 0x517f7eaa,\n+     0x61aa54cc, 0x71e6b2ee, 0x82673110, 0x922bd732, 0xa2fefd54, 0xb2b21b76,\n+     0xc354a998, 0xd3184fba, 0xe3cd65dc, 0xf38183fe},\n+    {0x00000000, 0x012214d1, 0x024429a2, 0x03663d73, 0x04885344, 0x05aa4795,\n+     0x06cc7ae6, 0x07ee6e37, 0x0910a688, 0x0832b259, 0x0b548f2a, 0x0a769bfb,\n+     0x0d98f5cc, 0x0cbae11d, 0x0fdcdc6e, 0x0efec8bf},\n+    {0x00000000, 0x12214d10, 0x24429a20, 0x3663d730, 0x48853440, 0x5aa47950,\n+     0x6cc7ae60, 0x7ee6e370, 0x910a6880, 0x832b2590, 0xb548f2a0, 0xa769bfb0,\n+     0xd98f5cc0, 0xcbae11d0, 0xfdcdc6e0, 0xefec8bf0},\n+    {0x00000000, 0x27f8a7f1, 0x4ff14fe2, 0x6809e813, 0x9fe29fc4, 0xb81a3835,\n+     0xd013d026, 0xf7eb77d7, 0x3a294979, 0x1dd1ee88, 0x75d8069b, 0x5220a16a,\n+     0xa5cbd6bd, 0x8233714c, 0xea3a995f, 0xcdc23eae},\n+    {0x00000000, 0x745292f2, 0xe8a525e4, 0x9cf7b716, 0xd4a63d39, 0xa0f4afcb,\n+     0x3c0318dd, 0x48518a2f, 0xaca00c83, 0xd8f29e71, 0x44052967, 0x3057bb95,\n+     0x780631ba, 0x0c54a348, 0x90a3145e, 0xe4f186ac},\n+};\n+const uint32_t kBlock1SkipTable[8][16] = {\n+    {0x00000000, 0x79113270, 0xf22264e0, 0x8b335690, 0xe1a8bf31, 0x98b98d41,\n+     0x138adbd1, 0x6a9be9a1, 0xc6bd0893, 0xbfac3ae3, 0x349f6c73, 0x4d8e5e03,\n+     0x2715b7a2, 0x5e0485d2, 0xd537d342, 0xac26e132},\n+    {0x00000000, 0x889667d7, 0x14c0b95f, 0x9c56de88, 0x298172be, 0xa1171569,\n+     0x3d41cbe1, 0xb5d7ac36, 0x5302e57c, 0xdb9482ab, 0x47c25c23, 0xcf543bf4,\n+     0x7a8397c2, 0xf215f015, 0x6e432e9d, 0xe6d5494a},\n+    {0x00000000, 0xa605caf8, 0x49e7e301, 0xefe229f9, 0x93cfc602, 0x35ca0cfa,\n+     0xda282503, 0x7c2deffb, 0x2273faf5, 0x8476300d, 0x6b9419f4, 0xcd91d30c,\n+     0xb1bc3cf7, 0x17b9f60f, 0xf85bdff6, 0x5e5e150e},\n+    {0x00000000, 0x44e7f5ea, 0x89cfebd4, 0xcd281e3e, 0x1673a159, 0x529454b3,\n+     0x9fbc4a8d, 0xdb5bbf67, 0x2ce742b2, 0x6800b758, 0xa528a966, 0xe1cf5c8c,\n+     0x3a94e3eb, 0x7e731601, 0xb35b083f, 0xf7bcfdd5},\n+    {0x00000000, 0x59ce8564, 0xb39d0ac8, 0xea538fac, 0x62d66361, 0x3b18e605,\n+     0xd14b69a9, 0x8885eccd, 0xc5acc6c2, 0x9c6243a6, 0x7631cc0a, 0x2fff496e,\n+     0xa77aa5a3, 0xfeb420c7, 0x14e7af6b, 0x4d292a0f},\n+    {0x00000000, 0x8eb5fb75, 0x1887801b, 0x96327b6e, 0x310f0036, 0xbfbafb43,\n+     0x2988802d, 0xa73d7b58, 0x621e006c, 0xecabfb19, 0x7a998077, 0xf42c7b02,\n+     0x5311005a, 0xdda4fb2f, 0x4b968041, 0xc5237b34},\n+    {0x00000000, 0xc43c00d8, 0x8d947741, 0x49a87799, 0x1ec49873, 0xdaf898ab,\n+     0x9350ef32, 0x576cefea, 0x3d8930e6, 0xf9b5303e, 0xb01d47a7, 0x7421477f,\n+     0x234da895, 0xe771a84d, 0xaed9dfd4, 0x6ae5df0c},\n+    {0x00000000, 0x7b1261cc, 0xf624c398, 0x8d36a254, 0xe9a5f1c1, 0x92b7900d,\n+     0x1f813259, 0x64935395, 0xd6a79573, 0xadb5f4bf, 0x208356eb, 0x5b913727,\n+     0x3f0264b2, 0x4410057e, 0xc926a72a, 0xb234c6e6},\n+};\n+const uint32_t kBlock2SkipTable[8][16] = {\n+    {0x00000000, 0x8f158014, 0x1bc776d9, 0x94d2f6cd, 0x378eedb2, 0xb89b6da6,\n+     0x2c499b6b, 0xa35c1b7f, 0x6f1ddb64, 0xe0085b70, 0x74daadbd, 0xfbcf2da9,\n+     0x589336d6, 0xd786b6c2, 0x4354400f, 0xcc41c01b},\n+    {0x00000000, 0xde3bb6c8, 0xb99b1b61, 0x67a0ada9, 0x76da4033, 0xa8e1f6fb,\n+     0xcf415b52, 0x117aed9a, 0xedb48066, 0x338f36ae, 0x542f9b07, 0x8a142dcf,\n+     0x9b6ec055, 0x4555769d, 0x22f5db34, 0xfcce6dfc},\n+    {0x00000000, 0xde85763d, 0xb8e69a8b, 0x6663ecb6, 0x742143e7, 0xaaa435da,\n+     0xccc7d96c, 0x1242af51, 0xe84287ce, 0x36c7f1f3, 0x50a41d45, 0x8e216b78,\n+     0x9c63c429, 0x42e6b214, 0x24855ea2, 0xfa00289f},\n+    {0x00000000, 0xd569796d, 0xaf3e842b, 0x7a57fd46, 0x5b917ea7, 0x8ef807ca,\n+     0xf4affa8c, 0x21c683e1, 0xb722fd4e, 0x624b8423, 0x181c7965, 0xcd750008,\n+     0xecb383e9, 0x39dafa84, 0x438d07c2, 0x96e47eaf},\n+    {0x00000000, 0x6ba98c6d, 0xd75318da, 0xbcfa94b7, 0xab4a4745, 0xc0e3cb28,\n+     0x7c195f9f, 0x17b0d3f2, 0x5378f87b, 0x38d17416, 0x842be0a1, 0xef826ccc,\n+     0xf832bf3e, 0x939b3353, 0x2f61a7e4, 0x44c82b89},\n+    {0x00000000, 0xa6f1f0f6, 0x480f971d, 0xeefe67eb, 0x901f2e3a, 0x36eedecc,\n+     0xd810b927, 0x7ee149d1, 0x25d22a85, 0x8323da73, 0x6dddbd98, 0xcb2c4d6e,\n+     0xb5cd04bf, 0x133cf449, 0xfdc293a2, 0x5b336354},\n+    {0x00000000, 0x4ba4550a, 0x9748aa14, 0xdcecff1e, 0x2b7d22d9, 0x60d977d3,\n+     0xbc3588cd, 0xf791ddc7, 0x56fa45b2, 0x1d5e10b8, 0xc1b2efa6, 0x8a16baac,\n+     0x7d87676b, 0x36233261, 0xeacfcd7f, 0xa16b9875},\n+    {0x00000000, 0xadf48b64, 0x5e056039, 0xf3f1eb5d, 0xbc0ac072, 0x11fe4b16,\n+     0xe20fa04b, 0x4ffb2b2f, 0x7df9f615, 0xd00d7d71, 0x23fc962c, 0x8e081d48,\n+     0xc1f33667, 0x6c07bd03, 0x9ff6565e, 0x3202dd3a},\n+};\n+\n+constexpr const ptrdiff_t kPrefetchHorizon = 256;\n+\n+}  // namespace\n+\n+uint32_t ExtendSse42(uint32_t crc, const uint8_t* data, size_t size) {\n+  const uint8_t* p = data;\n+  const uint8_t* e = data + size;\n+  uint32_t l = crc ^ kCRC32Xor;\n+\n+#define STEP1                  \\\n+  do {                         \\\n+    l = _mm_crc32_u8(l, *p++); \\\n+  } while (0)\n+\n+#define STEP4(crc)                             \\\n+  do {                                         \\\n+    crc = _mm_crc32_u32(crc, ReadUint32LE(p)); \\\n+    p += 4;                                    \\\n+  } while (0)\n+\n+#define STEP8(crc, data)                          \\\n+  do {                                            \\\n+    crc = _mm_crc32_u64(crc, ReadUint64LE(data)); \\\n+    data += 8;                                    \\\n+  } while (0)\n+\n+#define STEP8BY3(crc0, crc1, crc2, p0, p1, p2) \\\n+  do {                                         \\\n+    STEP8(crc0, p0);                           \\\n+    STEP8(crc1, p1);                           \\\n+    STEP8(crc2, p2);                           \\\n+  } while (0)\n+\n+#define STEP8X3(crc0, crc1, crc2, bs)                     \\\n+  do {                                                    \\\n+    crc0 = _mm_crc32_u64(crc0, ReadUint64LE(p));          \\\n+    crc1 = _mm_crc32_u64(crc1, ReadUint64LE(p + bs));     \\\n+    crc2 = _mm_crc32_u64(crc2, ReadUint64LE(p + 2 * bs)); \\\n+    p += 8;                                               \\\n+  } while (0)\n+\n+#define SKIP_BLOCK(crc, tab)                                      \\\n+  do {                                                            \\\n+    crc = tab[0][crc & 0xf] ^ tab[1][(crc >> 4) & 0xf] ^          \\\n+          tab[2][(crc >> 8) & 0xf] ^ tab[3][(crc >> 12) & 0xf] ^  \\\n+          tab[4][(crc >> 16) & 0xf] ^ tab[5][(crc >> 20) & 0xf] ^ \\\n+          tab[6][(crc >> 24) & 0xf] ^ tab[7][(crc >> 28) & 0xf];  \\\n+  } while (0)\n+\n+  // Point x at first 8-byte aligned byte in the buffer. This might be past the\n+  // end of the buffer.\n+  const uint8_t* x = RoundUp<8>(p);\n+  if (x <= e) {\n+    // Process bytes p is 8-byte aligned.\n+    while (p != x) {\n+      STEP1;\n+    }\n+  }\n+\n+  // Proccess the data in predetermined block sizes with tables for quickly\n+  // combining the checksum. Experimentally it's better to use larger block\n+  // sizes where possible so use a hierarchy of decreasing block sizes.\n+  uint64_t l64 = l;\n+  while ((e - p) >= kGroups * kBlock0Size) {\n+    uint64_t l641 = 0;\n+    uint64_t l642 = 0;\n+    for (int i = 0; i < kBlock0Size; i += 8 * 8) {\n+      // Prefetch ahead to hide latency.\n+      RequestPrefetch(p + kPrefetchHorizon);\n+      RequestPrefetch(p + kBlock0Size + kPrefetchHorizon);\n+      RequestPrefetch(p + 2 * kBlock0Size + kPrefetchHorizon);\n+\n+      // Process 64 bytes at a time.\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+    }\n+\n+    // Combine results.\n+    SKIP_BLOCK(l64, kBlock0SkipTable);\n+    l64 ^= l641;\n+    SKIP_BLOCK(l64, kBlock0SkipTable);\n+    l64 ^= l642;\n+    p += (kGroups - 1) * kBlock0Size;\n+  }\n+  while ((e - p) >= kGroups * kBlock1Size) {\n+    uint64_t l641 = 0;\n+    uint64_t l642 = 0;\n+    for (int i = 0; i < kBlock1Size; i += 8) {\n+      STEP8X3(l64, l641, l642, kBlock1Size);\n+    }\n+    SKIP_BLOCK(l64, kBlock1SkipTable);\n+    l64 ^= l641;\n+    SKIP_BLOCK(l64, kBlock1SkipTable);\n+    l64 ^= l642;\n+    p += (kGroups - 1) * kBlock1Size;\n+  }\n+  while ((e - p) >= kGroups * kBlock2Size) {\n+    uint64_t l641 = 0;\n+    uint64_t l642 = 0;\n+    for (int i = 0; i < kBlock2Size; i += 8) {\n+      STEP8X3(l64, l641, l642, kBlock2Size);\n+    }\n+    SKIP_BLOCK(l64, kBlock2SkipTable);\n+    l64 ^= l641;\n+    SKIP_BLOCK(l64, kBlock2SkipTable);\n+    l64 ^= l642;\n+    p += (kGroups - 1) * kBlock2Size;\n+  }\n+\n+  // Process bytes 16 at a time\n+  while ((e - p) >= 16) {\n+    STEP8(l64, p);\n+    STEP8(l64, p);\n+  }\n+\n+  l = static_cast<uint32_t>(l64);\n+  // Process the last few bytes.\n+  while (p != e) {\n+    STEP1;\n+  }\n+#undef SKIP_BLOCK\n+#undef STEP8X3\n+#undef STEP8BY3\n+#undef STEP8\n+#undef STEP4\n+#undef STEP1\n+\n+  return l ^ kCRC32Xor;\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))"
      },
      {
        "sha": "95da9266325310e7866ff1910f862a15a110fd4a",
        "filename": "src/crc32c_sse42.h",
        "status": "added",
        "additions": 33,
        "deletions": 0,
        "changes": 33,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_sse42.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_sse42.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_sse42.h?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,33 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_SSE42_H_\n+#define CRC32C_CRC32C_SSE42_H_\n+\n+// X86-specific code.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+// The hardware-accelerated implementation is only enabled for 64-bit builds,\n+// because a straightforward 32-bit implementation actually runs slower than the\n+// portable version. Most X86 machines are 64-bit nowadays, so it doesn't make\n+// much sense to spend time building an optimized hardware-accelerated\n+// implementation.\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+namespace crc32c {\n+\n+// SSE4.2-accelerated implementation in crc32c_sse42.cc\n+uint32_t ExtendSse42(uint32_t crc, const uint8_t* data, size_t count);\n+\n+}  // namespace crc32c\n+\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+#endif  // CRC32C_CRC32C_SSE42_H_"
      },
      {
        "sha": "e7528912a6dbf1f2f5e3209df795d46535730c2e",
        "filename": "src/crc32c_sse42_check.h",
        "status": "added",
        "additions": 50,
        "deletions": 0,
        "changes": 50,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_sse42_check.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_sse42_check.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_sse42_check.h?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,50 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_SSE42_CHECK_H_\n+#define CRC32C_CRC32C_SSE42_CHECK_H_\n+\n+// X86-specific code checking the availability of SSE4.2 instructions.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+// If the compiler supports SSE4.2, it definitely supports X86.\n+\n+#if defined(_MSC_VER)\n+#include <intrin.h>\n+\n+namespace crc32c {\n+\n+inline bool CanUseSse42() {\n+  int cpu_info[4];\n+  __cpuid(cpu_info, 1);\n+  return (cpu_info[2] & (1 << 20)) != 0;\n+}\n+\n+}  // namespace crc32c\n+\n+#else  // !defined(_MSC_VER)\n+#include <cpuid.h>\n+\n+namespace crc32c {\n+\n+inline bool CanUseSse42() {\n+  unsigned int eax, ebx, ecx, edx;\n+  return __get_cpuid(1, &eax, &ebx, &ecx, &edx) && ((ecx & (1 << 20)) != 0);\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // defined(_MSC_VER)\n+\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+#endif  // CRC32C_CRC32C_SSE42_CHECK_H_"
      },
      {
        "sha": "c73ad8ddd162383f217474489deb699738b856ae",
        "filename": "src/crc32c_sse42_unittest.cc",
        "status": "added",
        "additions": 24,
        "deletions": 0,
        "changes": 24,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_sse42_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_sse42_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_sse42_unittest.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,24 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"gtest/gtest.h\"\n+\n+#include \"./crc32c_extend_unittests.h\"\n+#include \"./crc32c_sse42.h\"\n+\n+namespace crc32c {\n+\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+struct Sse42TestTraits {\n+  static uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count) {\n+    return ExtendSse42(crc, data, count);\n+  }\n+};\n+\n+INSTANTIATE_TYPED_TEST_SUITE_P(Sse42, ExtendTest, Sse42TestTraits);\n+\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "275ee380c6a81f1275ac1495486c6727236129fc",
        "filename": "src/crc32c_test_main.cc",
        "status": "added",
        "additions": 22,
        "deletions": 0,
        "changes": 22,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_test_main.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_test_main.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_test_main.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,22 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#include \"gtest/gtest.h\"\n+\n+#if CRC32C_TESTS_BUILT_WITH_GLOG\n+#include \"glog/logging.h\"\n+#endif  // CRC32C_TESTS_BUILT_WITH_GLOG\n+\n+int main(int argc, char** argv) {\n+#if CRC32C_TESTS_BUILT_WITH_GLOG\n+  google::InitGoogleLogging(argv[0]);\n+  google::InstallFailureSignalHandler();\n+#endif  // CRC32C_TESTS_BUILT_WITH_GLOG\n+  testing::InitGoogleTest(&argc, argv);\n+  return RUN_ALL_TESTS();\n+}"
      },
      {
        "sha": "d6c6af680c655847d217afd9ac012610d977088c",
        "filename": "src/crc32c_unittest.cc",
        "status": "added",
        "additions": 129,
        "deletions": 0,
        "changes": 129,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/2e1819311a59fb5cb26e3ca50a510bfe01358350/src/crc32c_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c_unittest.cc?ref=2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "patch": "@@ -0,0 +1,129 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"crc32c/crc32c.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <cstring>\n+\n+#include \"gtest/gtest.h\"\n+\n+#include \"./crc32c_extend_unittests.h\"\n+\n+TEST(Crc32CTest, Crc32c) {\n+  // From rfc3720 section B.4.\n+  uint8_t buf[32];\n+\n+  std::memset(buf, 0, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x8a9136aa),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  std::memset(buf, 0xff, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x62a8ab43),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x46dd794e),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(31 - i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x113fdb5c),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  uint8_t data[48] = {\n+      0x01, 0xc0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00,\n+      0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x28, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+  };\n+  EXPECT_EQ(static_cast<uint32_t>(0xd9963a56),\n+            crc32c::Crc32c(data, sizeof(data)));\n+}\n+\n+namespace crc32c {\n+\n+struct ApiTestTraits {\n+  static uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count) {\n+    return ::crc32c::Extend(crc, data, count);\n+  }\n+};\n+\n+INSTANTIATE_TYPED_TEST_SUITE_P(Api, ExtendTest, ApiTestTraits);\n+\n+}  // namespace crc32c\n+\n+TEST(CRC32CTest, Crc32cCharPointer) {\n+  char buf[32];\n+\n+  std::memset(buf, 0, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x8a9136aa),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  std::memset(buf, 0xff, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x62a8ab43),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<char>(i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x46dd794e),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<char>(31 - i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x113fdb5c),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+}\n+\n+TEST(CRC32CTest, Crc32cStdString) {\n+  std::string buf;\n+  buf.resize(32);\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<char>(0x00);\n+  EXPECT_EQ(static_cast<uint32_t>(0x8a9136aa), crc32c::Crc32c(buf));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = '\\xff';\n+  EXPECT_EQ(static_cast<uint32_t>(0x62a8ab43), crc32c::Crc32c(buf));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<char>(i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x46dd794e), crc32c::Crc32c(buf));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<char>(31 - i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x113fdb5c), crc32c::Crc32c(buf));\n+}\n+\n+#if __cplusplus > 201402L\n+#if __has_include(<string_view>)\n+\n+TEST(CRC32CTest, Crc32cStdStringView) {\n+  uint8_t buf[32];\n+  std::string_view view(reinterpret_cast<const char*>(buf), sizeof(buf));\n+\n+  std::memset(buf, 0, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x8a9136aa), crc32c::Crc32c(view));\n+\n+  std::memset(buf, 0xff, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x62a8ab43), crc32c::Crc32c(view));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x46dd794e), crc32c::Crc32c(view));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(31 - i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x113fdb5c), crc32c::Crc32c(view));\n+}\n+\n+#endif  // __has_include(<string_view>)\n+#endif  // __cplusplus > 201402L\n+\n+#define TESTED_EXTEND Extend\n+#include \"./crc32c_extend_unittests.h\"\n+#undef TESTED_EXTEND"
      }
    ]
  },
  {
    "sha": "3acaa13b157509e81f0eba6c1e16938816439e7b",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzozYWNhYTEzYjE1NzUwOWU4MWYwZWJhNmMxZTE2OTM4ODE2NDM5ZTdi",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T15:59:58Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T16:00:01Z"
      },
      "message": "Import crc32c using subtree merge as as 'src/crc32c'",
      "tree": {
        "sha": "ec0fc55dc63d16c4fae135abfe580cd646a7f9c0",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/ec0fc55dc63d16c4fae135abfe580cd646a7f9c0"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/3acaa13b157509e81f0eba6c1e16938816439e7b",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3acaa13b157509e81f0eba6c1e16938816439e7b",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/3acaa13b157509e81f0eba6c1e16938816439e7b",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3acaa13b157509e81f0eba6c1e16938816439e7b/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "20a6babfa9a66f5432ef19c6c433b4357560f853",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/20a6babfa9a66f5432ef19c6c433b4357560f853",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/20a6babfa9a66f5432ef19c6c433b4357560f853"
      },
      {
        "sha": "2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/2e1819311a59fb5cb26e3ca50a510bfe01358350",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/2e1819311a59fb5cb26e3ca50a510bfe01358350"
      }
    ],
    "stats": {
      "total": 2730,
      "additions": 2730,
      "deletions": 0
    },
    "files": [
      {
        "sha": "7345746750a77a35c971d26329b8b404c3c4493f",
        "filename": "src/crc32c/.appveyor.yml",
        "status": "added",
        "additions": 37,
        "deletions": 0,
        "changes": 37,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.appveyor.yml",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.appveyor.yml",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/.appveyor.yml?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,37 @@\n+# Build matrix / environment variables are explained on:\n+# https://www.appveyor.com/docs/appveyor-yml/\n+# This file can be validated on: https://ci.appveyor.com/tools/validate-yaml\n+\n+version: \"{build}\"\n+\n+environment:\n+  matrix:\n+    # AppVeyor currently has no custom job name feature.\n+    # http://help.appveyor.com/discussions/questions/1623-can-i-provide-a-friendly-name-for-jobs\n+    - JOB: Visual Studio 2017\n+      APPVEYOR_BUILD_WORKER_IMAGE: Visual Studio 2017\n+      CMAKE_GENERATOR: Visual Studio 15 2017\n+\n+platform:\n+  - x86\n+  - x64\n+\n+configuration:\n+  - RelWithDebInfo\n+  - Debug\n+\n+build_script:\n+  - git submodule update --init --recursive\n+  - mkdir build\n+  - cd build\n+  - if \"%platform%\"==\"x64\" set CMAKE_GENERATOR=%CMAKE_GENERATOR% Win64\n+  - cmake --version\n+  - cmake .. -G \"%CMAKE_GENERATOR%\" -DCRC32C_USE_GLOG=0\n+      -DCMAKE_CONFIGURATION_TYPES=\"%CONFIGURATION%\"\n+  - cmake --build . --config \"%CONFIGURATION%\"\n+  - cd ..\n+\n+test_script:\n+  - build\\%CONFIGURATION%\\crc32c_tests.exe\n+  - build\\%CONFIGURATION%\\crc32c_capi_tests.exe\n+  - build\\%CONFIGURATION%\\crc32c_bench.exe"
      },
      {
        "sha": "be9b80799fa0244e283f8e0a072498dc373a43de",
        "filename": "src/crc32c/.clang-format",
        "status": "added",
        "additions": 3,
        "deletions": 0,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.clang-format",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.clang-format",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/.clang-format?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,3 @@\n+---\n+Language:      Cpp\n+BasedOnStyle:  Google"
      },
      {
        "sha": "fa6757c6f36413b987db6af737b140e0360030c1",
        "filename": "src/crc32c/.clang_complete",
        "status": "added",
        "additions": 8,
        "deletions": 0,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.clang_complete",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.clang_complete",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/.clang_complete?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,8 @@\n+-Ibuild/include/\n+-Ibuild/third_party/glog/\n+-Iinclude/\n+-Ithird_party/benchmark/include/\n+-Ithird_party/googletest/googletest/include/\n+-Ithird_party/googletest/googlemock/include/\n+-Ithird_party/glog/src/\n+-std=c++11"
      },
      {
        "sha": "61769727e318e7f0d867f549309e4345b5c183f1",
        "filename": "src/crc32c/.gitignore",
        "status": "added",
        "additions": 8,
        "deletions": 0,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.gitignore",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.gitignore",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/.gitignore?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,8 @@\n+# Editors.\n+*.sw*\n+.DS_Store\n+/.vscode\n+\n+# Build directory.\n+build/\n+out/"
      },
      {
        "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
        "filename": "src/crc32c/.gitmodules",
        "status": "added",
        "additions": 0,
        "deletions": 0,
        "changes": 0,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.gitmodules",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.gitmodules",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/.gitmodules?ref=3acaa13b157509e81f0eba6c1e16938816439e7b"
      },
      {
        "sha": "d990a89f0750d283e59de4f045a07422d677ea48",
        "filename": "src/crc32c/.travis.yml",
        "status": "added",
        "additions": 76,
        "deletions": 0,
        "changes": 76,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.travis.yml",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.travis.yml",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/.travis.yml?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,76 @@\n+# Build matrix / environment variables are explained on:\n+# http://about.travis-ci.org/docs/user/build-configuration/\n+# This file can be validated on: http://lint.travis-ci.org/\n+\n+language: cpp\n+dist: bionic\n+osx_image: xcode10.3\n+\n+compiler:\n+- gcc\n+- clang\n+os:\n+- linux\n+- osx\n+\n+env:\n+- GLOG=1 SHARED_LIB=0 BUILD_TYPE=Debug\n+- GLOG=1 SHARED_LIB=0 BUILD_TYPE=RelWithDebInfo\n+- GLOG=0 SHARED_LIB=0 BUILD_TYPE=Debug\n+- GLOG=0 SHARED_LIB=0 BUILD_TYPE=RelWithDebInfo\n+- GLOG=0 SHARED_LIB=1 BUILD_TYPE=Debug\n+- GLOG=0 SHARED_LIB=1 BUILD_TYPE=RelWithDebInfo\n+\n+addons:\n+  apt:\n+    sources:\n+    - sourceline: 'deb http://apt.llvm.org/bionic/ llvm-toolchain-bionic-9 main'\n+      key_url: 'https://apt.llvm.org/llvm-snapshot.gpg.key'\n+    - sourceline: 'ppa:ubuntu-toolchain-r/test'\n+    packages:\n+    - clang-9\n+    - cmake\n+    - gcc-9\n+    - g++-9\n+    - ninja-build\n+  homebrew:\n+    packages:\n+    - cmake\n+    - gcc@9\n+    - llvm@9\n+    - ninja\n+    update: true\n+\n+install:\n+# The following Homebrew packages aren't linked by default, and need to be\n+# prepended to the path explicitly.\n+- if [ \"$TRAVIS_OS_NAME\" = \"osx\" ]; then\n+    export PATH=\"$(brew --prefix llvm)/bin:$PATH\";\n+  fi\n+# /usr/bin/gcc points to an older compiler on both Linux and macOS.\n+- if [ \"$CXX\" = \"g++\" ]; then export CXX=\"g++-9\" CC=\"gcc-9\"; fi\n+# /usr/bin/clang points to an older compiler on both Linux and macOS.\n+#\n+# Homebrew's llvm package doesn't ship a versioned clang++ binary, so the values\n+# below don't work on macOS. Fortunately, the path change above makes the\n+# default values (clang and clang++) resolve to the correct compiler on macOS.\n+- if [ \"$TRAVIS_OS_NAME\" = \"linux\" ]; then\n+    if [ \"$CXX\" = \"clang++\" ]; then export CXX=\"clang++-9\" CC=\"clang-9\"; fi;\n+  fi\n+- echo ${CC}\n+- echo ${CXX}\n+- ${CXX} --version\n+- cmake --version\n+\n+before_script:\n+- mkdir -p build && cd build\n+- cmake .. -G Ninja -DCRC32C_USE_GLOG=$GLOG -DCMAKE_BUILD_TYPE=$BUILD_TYPE\n+           -DBUILD_SHARED_LIBS=$SHARED_LIB -DCMAKE_INSTALL_PREFIX=$HOME/.local\n+- cmake --build .\n+- cd ..\n+\n+script:\n+- build/crc32c_tests\n+- build/crc32c_capi_tests\n+- build/crc32c_bench\n+- cd build && cmake --build . --target install"
      },
      {
        "sha": "536aadcec8cf65894e66701180e3cd45b95157a3",
        "filename": "src/crc32c/.ycm_extra_conf.py",
        "status": "added",
        "additions": 142,
        "deletions": 0,
        "changes": 142,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.ycm_extra_conf.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/.ycm_extra_conf.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/.ycm_extra_conf.py?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,142 @@\n+# Copyright 2017 The CRC32C Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file.\n+\"\"\"YouCompleteMe configuration that interprets a .clang_complete file.\n+\n+This module implementes the YouCompleteMe configuration API documented at:\n+https://github.com/Valloric/ycmd#ycm_extra_confpy-specification\n+\n+The implementation loads and processes a .clang_complete file, documented at:\n+https://github.com/Rip-Rip/clang_complete/blob/master/README.md\n+\"\"\"\n+\n+import os\n+\n+# Flags added to the list in .clang_complete.\n+BASE_FLAGS = [\n+    '-Werror',  # Unlike clang_complete, YCM can also be used as a linter.\n+    '-DUSE_CLANG_COMPLETER',  # YCM needs this.\n+    '-xc++',  # YCM needs this to avoid compiling headers as C code.\n+]\n+\n+# Clang flags that take in paths.\n+# See https://clang.llvm.org/docs/ClangCommandLineReference.html\n+PATH_FLAGS = [\n+    '-isystem',\n+    '-I',\n+    '-iquote',\n+    '--sysroot='\n+]\n+\n+\n+def DirectoryOfThisScript():\n+  \"\"\"Returns the absolute path to the directory containing this script.\"\"\"\n+  return os.path.dirname(os.path.abspath(__file__))\n+\n+\n+def MakeRelativePathsInFlagsAbsolute(flags, build_root):\n+  \"\"\"Expands relative paths in a list of Clang command-line flags.\n+\n+  Args:\n+    flags: The list of flags passed to Clang.\n+    build_root: The current directory when running the Clang compiler. Should be\n+        an absolute path.\n+\n+  Returns:\n+    A list of flags with relative paths replaced by absolute paths.\n+  \"\"\"\n+  new_flags = []\n+  make_next_absolute = False\n+  for flag in flags:\n+    new_flag = flag\n+\n+    if make_next_absolute:\n+      make_next_absolute = False\n+      if not flag.startswith('/'):\n+        new_flag = os.path.join(build_root, flag)\n+\n+    for path_flag in PATH_FLAGS:\n+      if flag == path_flag:\n+        make_next_absolute = True\n+        break\n+\n+      if flag.startswith(path_flag):\n+        path = flag[len(path_flag):]\n+        new_flag = path_flag + os.path.join(build_root, path)\n+        break\n+\n+    if new_flag:\n+      new_flags.append(new_flag)\n+  return new_flags\n+\n+\n+def FindNearest(target, path, build_root):\n+  \"\"\"Looks for a file with a specific name closest to a project path.\n+\n+  This is similar to the logic used by a version-control system (like git) to\n+  find its configuration directory (.git) based on the current directory when a\n+  command is invoked.\n+\n+  Args:\n+    target: The file name to search for.\n+    path: The directory where the search starts. The search will explore the\n+        given directory's ascendants using the parent relationship. Should be an\n+        absolute path.\n+    build_root: A directory that acts as a fence for the search. If the search\n+        reaches this directory, it will not advance to its parent. Should be an\n+        absolute path.\n+\n+  Returns:\n+    The path to a file with the desired name. None if the search failed.\n+  \"\"\"\n+  candidate = os.path.join(path, target)\n+  if os.path.isfile(candidate):\n+    return candidate\n+\n+  if path == build_root:\n+    return None\n+\n+  parent = os.path.dirname(path)\n+  if parent == path:\n+    return None\n+\n+  return FindNearest(target, parent, build_root)\n+\n+\n+def FlagsForClangComplete(file_path, build_root):\n+  \"\"\"Reads the .clang_complete flags for a source file.\n+\n+  Args:\n+    file_path: The path to the source file. Should be inside the project. Used\n+      to locate the relevant .clang_complete file.\n+    build_root: The current directory when running the Clang compiler for this\n+        file. Should be an absolute path.\n+\n+  Returns:\n+    A list of strings, where each element is a Clang command-line flag.\n+  \"\"\"\n+  clang_complete_path = FindNearest('.clang_complete', file_path, build_root)\n+  if clang_complete_path is None:\n+    return None\n+  clang_complete_flags = open(clang_complete_path, 'r').read().splitlines()\n+  return clang_complete_flags\n+\n+\n+def FlagsForFile(filename, **kwargs):\n+  \"\"\"Implements the YouCompleteMe API.\"\"\"\n+\n+  # kwargs can be used to pass 'client_data' to the YCM configuration. This\n+  # configuration script does not need any extra information, so\n+  # pylint: disable=unused-argument\n+\n+  build_root = DirectoryOfThisScript()\n+  file_path = os.path.realpath(filename)\n+\n+  flags = BASE_FLAGS\n+  clang_flags = FlagsForClangComplete(file_path, build_root)\n+  if clang_flags:\n+    flags += clang_flags\n+\n+  final_flags = MakeRelativePathsInFlagsAbsolute(flags, build_root)\n+\n+  return {'flags': final_flags}"
      },
      {
        "sha": "6f1f6871a6b665e5b28db7154a629b5a620d2e63",
        "filename": "src/crc32c/AUTHORS",
        "status": "added",
        "additions": 9,
        "deletions": 0,
        "changes": 9,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/AUTHORS",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/AUTHORS",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/AUTHORS?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,9 @@\n+# This is the list of CRC32C authors for copyright purposes.\n+#\n+# This does not necessarily list everyone who has contributed code, since in\n+# some cases, their employer may be the copyright holder.  To see the full list\n+# of contributors, see the revision history in source control.\n+Google Inc.\n+\n+Fangming Fang <Fangming.Fang@arm.com>\n+Vadim Skipin <vadim.skipin@gmail.com>"
      },
      {
        "sha": "111a3e36144b916e99077440c24c769a8feed59e",
        "filename": "src/crc32c/CMakeLists.txt",
        "status": "added",
        "additions": 423,
        "deletions": 0,
        "changes": 423,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/CMakeLists.txt",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/CMakeLists.txt",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/CMakeLists.txt?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,423 @@\n+# Copyright 2017 The CRC32C Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+cmake_minimum_required(VERSION 3.1)\n+project(Crc32c VERSION 1.1.0 LANGUAGES C CXX)\n+\n+# This project can use C11, but will gracefully decay down to C89.\n+set(CMAKE_C_STANDARD 11)\n+set(CMAKE_C_STANDARD_REQUIRED OFF)\n+set(CMAKE_C_EXTENSIONS OFF)\n+\n+# This project requires C++11.\n+set(CMAKE_CXX_STANDARD 11)\n+set(CMAKE_CXX_STANDARD_REQUIRED ON)\n+set(CMAKE_CXX_EXTENSIONS OFF)\n+\n+# https://github.com/izenecloud/cmake/blob/master/SetCompilerWarningAll.cmake\n+if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  # Use the highest warning level for Visual Studio.\n+  set(CMAKE_CXX_WARNING_LEVEL 4)\n+  if(CMAKE_CXX_FLAGS MATCHES \"/W[0-4]\")\n+    string(REGEX REPLACE \"/W[0-4]\" \"/W4\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  else(CMAKE_CXX_FLAGS MATCHES \"/W[0-4]\")\n+    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /W4\")\n+  endif(CMAKE_CXX_FLAGS MATCHES \"/W[0-4]\")\n+\n+  # Disable C++ exceptions.\n+  string(REGEX REPLACE \"/EH[a-z]+\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /EHs-c-\")\n+  add_definitions(-D_HAS_EXCEPTIONS=0)\n+\n+  # Disable RTTI.\n+  string(REGEX REPLACE \"/GR\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} /GR-\")\n+else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  # Use -Wall for clang and gcc.\n+  if(NOT CMAKE_CXX_FLAGS MATCHES \"-Wall\")\n+    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wall\")\n+  endif(NOT CMAKE_CXX_FLAGS MATCHES \"-Wall\")\n+\n+  # Use -Wextra for clang and gcc.\n+  if(NOT CMAKE_CXX_FLAGS MATCHES \"-Wextra\")\n+    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Wextra\")\n+  endif(NOT CMAKE_CXX_FLAGS MATCHES \"-Wextra\")\n+\n+  # Use -Werror for clang and gcc.\n+  if(NOT CMAKE_CXX_FLAGS MATCHES \"-Werror\")\n+    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -Werror\")\n+  endif(NOT CMAKE_CXX_FLAGS MATCHES \"-Werror\")\n+\n+  # Disable C++ exceptions.\n+  string(REGEX REPLACE \"-fexceptions\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fno-exceptions\")\n+\n+  # Disable RTTI.\n+  string(REGEX REPLACE \"-frtti\" \"\" CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS}\")\n+  set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -fno-rtti\")\n+endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+\n+option(CRC32C_BUILD_TESTS \"Build CRC32C's unit tests\" ON)\n+option(CRC32C_BUILD_BENCHMARKS \"Build CRC32C's benchmarks\" ON)\n+option(CRC32C_USE_GLOG \"Build CRC32C's tests with Google Logging\" ON)\n+option(CRC32C_INSTALL \"Install CRC32C's header and library\" ON)\n+\n+include(TestBigEndian)\n+test_big_endian(BYTE_ORDER_BIG_ENDIAN)\n+\n+include(CheckCXXCompilerFlag)\n+# Used by glog.\n+check_cxx_compiler_flag(-Wno-deprecated CRC32C_HAVE_NO_DEPRECATED)\n+# Used by glog.\n+check_cxx_compiler_flag(-Wno-sign-compare CRC32C_HAVE_NO_SIGN_COMPARE)\n+# Used by glog.\n+check_cxx_compiler_flag(-Wno-unused-parameter CRC32C_HAVE_NO_UNUSED_PARAMETER)\n+# Used by googletest.\n+check_cxx_compiler_flag(-Wno-missing-field-initializers\n+                        CRC32C_HAVE_NO_MISSING_FIELD_INITIALIZERS)\n+\n+# Check for __builtin_prefetch support in the compiler.\n+include(CheckCXXSourceCompiles)\n+check_cxx_source_compiles(\"\n+int main() {\n+  char data = 0;\n+  const char* address = &data;\n+  __builtin_prefetch(address, 0, 0);\n+  return 0;\n+}\n+\"  HAVE_BUILTIN_PREFETCH)\n+\n+# Check for _mm_prefetch support in the compiler.\n+include(CheckCXXSourceCompiles)\n+check_cxx_source_compiles(\"\n+#if defined(_MSC_VER)\n+#include <intrin.h>\n+#else  // !defined(_MSC_VER)\n+#include <xmmintrin.h>\n+#endif  // defined(_MSC_VER)\n+\n+int main() {\n+  char data = 0;\n+  const char* address = &data;\n+  _mm_prefetch(address, _MM_HINT_NTA);\n+  return 0;\n+}\n+\"  HAVE_MM_PREFETCH)\n+\n+# Check for SSE4.2 support in the compiler.\n+set(OLD_CMAKE_REQURED_FLAGS ${CMAKE_REQUIRED_FLAGS})\n+if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  set(CMAKE_REQUIRED_FLAGS \"${CMAKE_REQUIRED_FLAGS} /arch:AVX\")\n+else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  set(CMAKE_REQUIRED_FLAGS \"${CMAKE_REQUIRED_FLAGS} -msse4.2\")\n+endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+check_cxx_source_compiles(\"\n+#if defined(_MSC_VER)\n+#include <intrin.h>\n+#else  // !defined(_MSC_VER)\n+#include <cpuid.h>\n+#include <nmmintrin.h>\n+#endif  // defined(_MSC_VER)\n+\n+int main() {\n+  _mm_crc32_u8(0, 0); _mm_crc32_u32(0, 0);\n+#if defined(_M_X64) || defined(__x86_64__)\n+   _mm_crc32_u64(0, 0);\n+#endif // defined(_M_X64) || defined(__x86_64__)\n+  return 0;\n+}\n+\"  HAVE_SSE42)\n+set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQURED_FLAGS})\n+\n+# Check for ARMv8 w/ CRC and CRYPTO extensions support in the compiler.\n+set(OLD_CMAKE_REQURED_FLAGS ${CMAKE_REQUIRED_FLAGS})\n+if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  # TODO(pwnall): Insert correct flag when VS gets ARM CRC32C support.\n+  set(CMAKE_REQUIRED_FLAGS \"${CMAKE_REQUIRED_FLAGS} /arch:NOTYET\")\n+else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  set(CMAKE_REQUIRED_FLAGS \"${CMAKE_REQUIRED_FLAGS} -march=armv8-a+crc+crypto\")\n+endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+check_cxx_source_compiles(\"\n+#include <arm_acle.h>\n+#include <arm_neon.h>\n+\n+int main() {\n+  __crc32cb(0, 0); __crc32ch(0, 0); __crc32cw(0, 0); __crc32cd(0, 0);\n+  vmull_p64(0, 0);\n+  return 0;\n+}\n+\" HAVE_ARM64_CRC32C)\n+set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQURED_FLAGS})\n+\n+# Check for strong getauxval() support in the system headers.\n+check_cxx_source_compiles(\"\n+#include <arm_acle.h>\n+#include <arm_neon.h>\n+#include <sys/auxv.h>\n+\n+int main() {\n+  getauxval(AT_HWCAP);\n+  return 0;\n+}\n+\" HAVE_STRONG_GETAUXVAL)\n+\n+# Check for weak getauxval() support in the compiler.\n+check_cxx_source_compiles(\"\n+unsigned long getauxval(unsigned long type) __attribute__((weak));\n+#define AT_HWCAP 16\n+\n+int main() {\n+  getauxval(AT_HWCAP);\n+  return 0;\n+}\n+\" HAVE_WEAK_GETAUXVAL)\n+\n+if(CRC32C_USE_GLOG)\n+  # glog requires this setting to avoid using dynamic_cast.\n+  set(DISABLE_RTTI ON CACHE BOOL \"\" FORCE)\n+\n+  # glog's test targets trigger deprecation warnings, and compiling them burns\n+  # CPU cycles on the CI.\n+  set(BUILD_TESTING_SAVED \"${BUILD_TESTING}\")\n+  set(BUILD_TESTING OFF CACHE BOOL \"\" FORCE)\n+  add_subdirectory(\"third_party/glog\" EXCLUDE_FROM_ALL)\n+  set(BUILD_TESTING \"${BUILD_TESTING_SAVED}\" CACHE BOOL \"\" FORCE)\n+\n+  # glog triggers deprecation warnings on OSX.\n+  # https://github.com/google/glog/issues/185\n+  if(CRC32C_HAVE_NO_DEPRECATED)\n+    set_property(TARGET glog APPEND PROPERTY COMPILE_OPTIONS -Wno-deprecated)\n+  endif(CRC32C_HAVE_NO_DEPRECATED)\n+\n+  # glog triggers sign comparison warnings on gcc.\n+  if(CRC32C_HAVE_NO_SIGN_COMPARE)\n+    set_property(TARGET glog APPEND PROPERTY COMPILE_OPTIONS -Wno-sign-compare)\n+  endif(CRC32C_HAVE_NO_SIGN_COMPARE)\n+\n+  # glog triggers unused parameter warnings on clang.\n+  if(CRC32C_HAVE_NO_UNUSED_PARAMETER)\n+    set_property(TARGET glog\n+                 APPEND PROPERTY COMPILE_OPTIONS -Wno-unused-parameter)\n+  endif(CRC32C_HAVE_NO_UNUSED_PARAMETER)\n+\n+  set(CRC32C_TESTS_BUILT_WITH_GLOG 1)\n+endif(CRC32C_USE_GLOG)\n+\n+configure_file(\n+  \"src/crc32c_config.h.in\"\n+  \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+)\n+\n+include_directories(\"${PROJECT_BINARY_DIR}/include\")\n+\n+# ARM64 CRC32C code is built separately, so we don't accidentally compile\n+# unsupported instructions into code that gets run without ARM32 support.\n+add_library(crc32c_arm64 OBJECT \"\")\n+target_sources(crc32c_arm64\n+  PRIVATE\n+    \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+    \"src/crc32c_arm64.cc\"\n+    \"src/crc32c_arm64.h\"\n+)\n+if(HAVE_ARM64_CRC32C)\n+  if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    # TODO(pwnall): Insert correct flag when VS gets ARM64 CRC32C support.\n+    target_compile_options(crc32c_arm64 PRIVATE \"/arch:NOTYET\")\n+  else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    target_compile_options(crc32c_arm64 PRIVATE \"-march=armv8-a+crc+crypto\")\n+  endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+endif(HAVE_ARM64_CRC32C)\n+\n+# CMake only enables PIC by default in SHARED and MODULE targets.\n+if(BUILD_SHARED_LIBS)\n+  set_property(TARGET crc32c_arm64 PROPERTY POSITION_INDEPENDENT_CODE TRUE)\n+endif(BUILD_SHARED_LIBS)\n+\n+# SSE4.2 code is built separately, so we don't accidentally compile unsupported\n+# instructions into code that gets run without SSE4.2 support.\n+add_library(crc32c_sse42 OBJECT \"\")\n+target_sources(crc32c_sse42\n+  PRIVATE\n+    \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+    \"src/crc32c_sse42.cc\"\n+    \"src/crc32c_sse42.h\"\n+)\n+if(HAVE_SSE42)\n+  if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    target_compile_options(crc32c_sse42 PRIVATE \"/arch:AVX\")\n+  else(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    target_compile_options(crc32c_sse42 PRIVATE \"-msse4.2\")\n+  endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+endif(HAVE_SSE42)\n+\n+# CMake only enables PIC by default in SHARED and MODULE targets.\n+if(BUILD_SHARED_LIBS)\n+  set_property(TARGET crc32c_sse42 PROPERTY POSITION_INDEPENDENT_CODE TRUE)\n+endif(BUILD_SHARED_LIBS)\n+\n+# Must be included before CMAKE_INSTALL_INCLUDEDIR is used.\n+include(GNUInstallDirs)\n+\n+add_library(crc32c \"\"\n+  # TODO(pwnall): Move the TARGET_OBJECTS generator expressions to the PRIVATE\n+  # section of target_sources when cmake_minimum_required becomes 3.9 or above.\n+  $<TARGET_OBJECTS:crc32c_arm64>\n+  $<TARGET_OBJECTS:crc32c_sse42>\n+)\n+target_sources(crc32c\n+  PRIVATE\n+    \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+    \"src/crc32c_arm64.h\"\n+    \"src/crc32c_arm64_linux_check.h\"\n+    \"src/crc32c_internal.h\"\n+    \"src/crc32c_portable.cc\"\n+    \"src/crc32c_prefetch.h\"\n+    \"src/crc32c_read_le.h\"\n+    \"src/crc32c_round_up.h\"\n+    \"src/crc32c_sse42.h\"\n+    \"src/crc32c_sse42_check.h\"\n+    \"src/crc32c.cc\"\n+\n+  # Only CMake 3.3+ supports PUBLIC sources in targets exported by \"install\".\n+  $<$<VERSION_GREATER:CMAKE_VERSION,3.2>:PUBLIC>\n+    \"include/crc32c/crc32c.h\"\n+)\n+\n+target_include_directories(crc32c\n+  PUBLIC\n+    $<BUILD_INTERFACE:${PROJECT_SOURCE_DIR}/include>\n+    $<INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}>\n+)\n+\n+target_compile_definitions(crc32c\n+PRIVATE\n+  CRC32C_HAVE_CONFIG_H=1\n+)\n+\n+set_target_properties(crc32c\n+  PROPERTIES VERSION ${PROJECT_VERSION} SOVERSION ${PROJECT_VERSION_MAJOR})\n+\n+# Warnings as errors in Visual Studio for this project's targets.\n+if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+  set_property(TARGET crc32c APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+  set_property(TARGET crc32c_arm64 APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+  set_property(TARGET crc32c_sse42 APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+\n+if(CRC32C_BUILD_TESTS)\n+  enable_testing()\n+\n+  # Prevent overriding the parent project's compiler/linker settings on Windows.\n+  set(gtest_force_shared_crt ON CACHE BOOL \"\" FORCE)\n+  set(install_gtest OFF)\n+  set(install_gmock OFF)\n+\n+  # This project is tested using GoogleTest.\n+  add_subdirectory(\"third_party/googletest\")\n+\n+  # GoogleTest triggers a missing field initializers warning.\n+  if(CRC32C_HAVE_NO_MISSING_FIELD_INITIALIZERS)\n+    set_property(TARGET gtest\n+        APPEND PROPERTY COMPILE_OPTIONS -Wno-missing-field-initializers)\n+    set_property(TARGET gmock\n+        APPEND PROPERTY COMPILE_OPTIONS -Wno-missing-field-initializers)\n+  endif(CRC32C_HAVE_NO_MISSING_FIELD_INITIALIZERS)\n+\n+  add_executable(crc32c_tests \"\")\n+  target_sources(crc32c_tests\n+    PRIVATE\n+      \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+      \"src/crc32c_arm64_unittest.cc\"\n+      \"src/crc32c_extend_unittests.h\"\n+      \"src/crc32c_portable_unittest.cc\"\n+      \"src/crc32c_prefetch_unittest.cc\"\n+      \"src/crc32c_read_le_unittest.cc\"\n+      \"src/crc32c_round_up_unittest.cc\"\n+      \"src/crc32c_sse42_unittest.cc\"\n+      \"src/crc32c_unittest.cc\"\n+      \"src/crc32c_test_main.cc\"\n+  )\n+  target_link_libraries(crc32c_tests crc32c gtest)\n+\n+  # Warnings as errors in Visual Studio for this project's targets.\n+  if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    set_property(TARGET crc32c_tests APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+  endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+\n+  if(CRC32C_USE_GLOG)\n+    target_link_libraries(crc32c_tests glog)\n+  endif(CRC32C_USE_GLOG)\n+\n+  add_test(NAME crc32c_tests COMMAND crc32c_tests)\n+\n+  add_executable(crc32c_capi_tests \"\")\n+  target_sources(crc32c_capi_tests\n+    PRIVATE\n+      \"src/crc32c_capi_unittest.c\"\n+  )\n+  target_link_libraries(crc32c_capi_tests crc32c)\n+\n+  # Warnings as errors in Visual Studio for this project's targets.\n+  if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    set_property(TARGET crc32c_capi_tests APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+  endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+\n+  add_test(NAME crc32c_capi_tests COMMAND crc32c_capi_tests)\n+endif(CRC32C_BUILD_TESTS)\n+\n+if(CRC32C_BUILD_BENCHMARKS)\n+  add_executable(crc32c_bench \"\")\n+  target_sources(crc32c_bench\n+    PRIVATE\n+      \"${PROJECT_BINARY_DIR}/include/crc32c/crc32c_config.h\"\n+      \"src/crc32c_benchmark.cc\"\n+  )\n+  target_link_libraries(crc32c_bench crc32c)\n+\n+  # This project uses Google benchmark for benchmarking.\n+  set(BENCHMARK_ENABLE_TESTING OFF CACHE BOOL \"\" FORCE)\n+  set(BENCHMARK_ENABLE_EXCEPTIONS OFF CACHE BOOL \"\" FORCE)\n+  add_subdirectory(\"third_party/benchmark\")\n+  target_link_libraries(crc32c_bench benchmark)\n+\n+  if(CRC32C_USE_GLOG)\n+    target_link_libraries(crc32c_bench glog)\n+  endif(CRC32C_USE_GLOG)\n+\n+  # Warnings as errors in Visual Studio for this project's targets.\n+  if(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+    set_property(TARGET crc32c_bench APPEND PROPERTY COMPILE_OPTIONS \"/WX\")\n+  endif(CMAKE_CXX_COMPILER_ID STREQUAL \"MSVC\")\n+endif(CRC32C_BUILD_BENCHMARKS)\n+\n+if(CRC32C_INSTALL)\n+  install(TARGETS crc32c\n+    EXPORT Crc32cTargets\n+    RUNTIME DESTINATION ${CMAKE_INSTALL_BINDIR}\n+    LIBRARY DESTINATION ${CMAKE_INSTALL_LIBDIR}\n+    ARCHIVE DESTINATION ${CMAKE_INSTALL_LIBDIR}\n+  )\n+  install(\n+    FILES\n+      \"include/crc32c/crc32c.h\"\n+    DESTINATION \"${CMAKE_INSTALL_INCLUDEDIR}/crc32c\"\n+  )\n+\n+  include(CMakePackageConfigHelpers)\n+  write_basic_package_version_file(\n+      \"${PROJECT_BINARY_DIR}/Crc32cConfigVersion.cmake\"\n+      COMPATIBILITY SameMajorVersion\n+  )\n+  install(\n+    EXPORT Crc32cTargets\n+    NAMESPACE Crc32c::\n+    DESTINATION \"${CMAKE_INSTALL_LIBDIR}/cmake/Crc32c\"\n+  )\n+  install(\n+    FILES\n+      \"Crc32cConfig.cmake\"\n+      \"${PROJECT_BINARY_DIR}/Crc32cConfigVersion.cmake\"\n+    DESTINATION \"${CMAKE_INSTALL_LIBDIR}/cmake/Crc32c\"\n+  )\n+endif(CRC32C_INSTALL)"
      },
      {
        "sha": "ae319c70aca8c8b148045aa1fd0c3ecfae85cb8a",
        "filename": "src/crc32c/CONTRIBUTING.md",
        "status": "added",
        "additions": 23,
        "deletions": 0,
        "changes": 23,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/CONTRIBUTING.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/CONTRIBUTING.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/CONTRIBUTING.md?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,23 @@\n+# How to Contribute\n+\n+We'd love to accept your patches and contributions to this project. There are\n+just a few small guidelines you need to follow.\n+\n+## Contributor License Agreement\n+\n+Contributions to this project must be accompanied by a Contributor License\n+Agreement. You (or your employer) retain the copyright to your contribution,\n+this simply gives us permission to use and redistribute your contributions as\n+part of the project. Head over to <https://cla.developers.google.com/> to see\n+your current agreements on file or to sign a new one.\n+\n+You generally only need to submit a CLA once, so if you've already submitted one\n+(even if it was for a different project), you probably don't need to do it\n+again.\n+\n+## Code reviews\n+\n+All submissions, including submissions by project members, require review. We\n+use GitHub pull requests for this purpose. Consult\n+[GitHub Help](https://help.github.com/articles/about-pull-requests/) for more\n+information on using pull requests."
      },
      {
        "sha": "4d6057ec26f3bc04c5eb9df97d51cd8e5d90ae40",
        "filename": "src/crc32c/Crc32cConfig.cmake",
        "status": "added",
        "additions": 5,
        "deletions": 0,
        "changes": 5,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/Crc32cConfig.cmake",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/Crc32cConfig.cmake",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/Crc32cConfig.cmake?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,5 @@\n+# Copyright 2017 The CRC32C Authors. All rights reserved.\n+# Use of this source code is governed by a BSD-style license that can be\n+# found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+include(\"${CMAKE_CURRENT_LIST_DIR}/Crc32cTargets.cmake\")"
      },
      {
        "sha": "8c8735cf123cee0e410583fe9af785cb424b835b",
        "filename": "src/crc32c/LICENSE",
        "status": "added",
        "additions": 28,
        "deletions": 0,
        "changes": 28,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/LICENSE",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/LICENSE",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/LICENSE?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,28 @@\n+Copyright 2017, The CRC32C Authors.\n+\n+Redistribution and use in source and binary forms, with or without\n+modification, are permitted provided that the following conditions are\n+met:\n+\n+   * Redistributions of source code must retain the above copyright\n+notice, this list of conditions and the following disclaimer.\n+   * Redistributions in binary form must reproduce the above\n+copyright notice, this list of conditions and the following disclaimer\n+in the documentation and/or other materials provided with the\n+distribution.\n+\n+   * Neither the name of Google Inc. nor the names of its\n+contributors may be used to endorse or promote products derived from\n+this software without specific prior written permission.\n+\n+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n+\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n+OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
      },
      {
        "sha": "0bd69f7f097e2f6be002809b9097fe210af60fac",
        "filename": "src/crc32c/README.md",
        "status": "added",
        "additions": 125,
        "deletions": 0,
        "changes": 125,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/README.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/README.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/README.md?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,125 @@\n+# CRC32C\n+\n+[![Build Status](https://travis-ci.org/google/crc32c.svg?branch=master)](https://travis-ci.org/google/crc32c)\n+[![Build Status](https://ci.appveyor.com/api/projects/status/moiq7331pett4xuj/branch/master?svg=true)](https://ci.appveyor.com/project/pwnall/crc32c)\n+\n+New file format authors should consider\n+[HighwayHash](https://github.com/google/highwayhash). The initial version of\n+this code was extracted from [LevelDB](https://github.com/google/leveldb), which\n+is a stable key-value store that is widely used at Google.\n+\n+This project collects a few CRC32C implementations under an umbrella that\n+dispatches to a suitable implementation based on the host computer's hardware\n+capabilities.\n+\n+CRC32C is specified as the CRC that uses the iSCSI polynomial in\n+[RFC 3720](https://tools.ietf.org/html/rfc3720#section-12.1). The polynomial was\n+introduced by G. Castagnoli, S. Braeuer and M. Herrmann. CRC32C is used in\n+software such as Btrfs, ext4, Ceph and leveldb.\n+\n+\n+## Usage\n+\n+```cpp\n+#include \"crc32c/crc32c.h\"\n+\n+int main() {\n+  const std::uint8_t buffer[] = {0, 0, 0, 0};\n+  std::uint32_t result;\n+\n+  // Process a raw buffer.\n+  result = crc32c::Crc32c(buffer, 4);\n+\n+  // Process a std::string.\n+  std::string string;\n+  string.resize(4);\n+  result = crc32c::Crc32c(string);\n+\n+  // If you have C++17 support, process a std::string_view.\n+  std::string_view string_view(string);\n+  result = crc32c::Crc32c(string_view);\n+\n+  return 0;\n+}\n+```\n+\n+\n+## Prerequisites\n+\n+This project uses [CMake](https://cmake.org/) for building and testing. CMake is\n+available in all popular Linux distributions, as well as in\n+[Homebrew](https://brew.sh/).\n+\n+This project uses submodules for dependency management.\n+\n+```bash\n+git submodule update --init --recursive\n+```\n+\n+If you're using [Atom](https://atom.io/), the following packages can help.\n+\n+```bash\n+apm install autocomplete-clang build build-cmake clang-format language-cmake \\\n+    linter linter-clang\n+```\n+\n+If you don't mind more setup in return for more speed, replace\n+`autocomplete-clang` and `linter-clang` with `you-complete-me`. This requires\n+[setting up ycmd](https://github.com/Valloric/ycmd#building).\n+\n+```bash\n+apm install autocomplete-plus build build-cmake clang-format language-cmake \\\n+    linter you-complete-me\n+```\n+\n+## Building\n+\n+The following commands build and install the project.\n+\n+```bash\n+mkdir build\n+cd build\n+cmake -DCRC32C_BUILD_TESTS=0 -DCRC32C_BUILD_BENCHMARKS=0 .. && make all install\n+```\n+\n+\n+## Development\n+\n+The following command (when executed from `build/`) (re)builds the project and\n+runs the tests.\n+\n+```bash\n+cmake .. && cmake --build . && ctest --output-on-failure\n+```\n+\n+\n+### Android testing\n+\n+The following command builds the project against the Android NDK, which is\n+useful for benchmarking against ARM processors.\n+\n+```bash\n+cmake .. -DCMAKE_SYSTEM_NAME=Android -DCMAKE_ANDROID_ARCH_ABI=arm64-v8a \\\n+    -DCMAKE_ANDROID_NDK=$HOME/Library/Android/sdk/ndk-bundle \\\n+    -DCMAKE_ANDROID_NDK_TOOLCHAIN_VERSION=clang \\\n+    -DCMAKE_ANDROID_STL_TYPE=c++_static -DCRC32C_USE_GLOG=0 \\\n+    -DCMAKE_BUILD_TYPE=Release && cmake --build .\n+```\n+\n+The following commands install and run the benchmarks.\n+\n+```bash\n+adb push crc32c_bench /data/local/tmp\n+adb shell chmod +x /data/local/tmp/crc32c_bench\n+adb shell 'cd /data/local/tmp && ./crc32c_bench'\n+adb shell rm /data/local/tmp/crc32c_bench\n+```\n+\n+The following commands install and run the tests.\n+\n+```bash\n+adb push crc32c_tests /data/local/tmp\n+adb shell chmod +x /data/local/tmp/crc32c_tests\n+adb shell 'cd /data/local/tmp && ./crc32c_tests'\n+adb shell rm /data/local/tmp/crc32c_tests\n+```"
      },
      {
        "sha": "e8a78170a91cb69b5b00ae97fa398a373188c716",
        "filename": "src/crc32c/include/crc32c/crc32c.h",
        "status": "added",
        "additions": 89,
        "deletions": 0,
        "changes": 89,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/include/crc32c/crc32c.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/include/crc32c/crc32c.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/include/crc32c/crc32c.h?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,89 @@\n+/* Copyright 2017 The CRC32C Authors. All rights reserved.\n+   Use of this source code is governed by a BSD-style license that can be\n+   found in the LICENSE file. See the AUTHORS file for names of contributors. */\n+\n+#ifndef CRC32C_CRC32C_H_\n+#define CRC32C_CRC32C_H_\n+\n+/* The API exported by the CRC32C project. */\n+\n+#if defined(__cplusplus)\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <string>\n+\n+#else  /* !defined(__cplusplus) */\n+\n+#include <stddef.h>\n+#include <stdint.h>\n+\n+#endif  /* !defined(__cplusplus) */\n+\n+\n+/* The C API. */\n+\n+#if defined(__cplusplus)\n+extern \"C\" {\n+#endif  /* defined(__cplusplus) */\n+\n+/* Extends \"crc\" with the CRC32C of \"count\" bytes in the buffer pointed by\n+   \"data\" */\n+uint32_t crc32c_extend(uint32_t crc, const uint8_t* data, size_t count);\n+\n+/* Computes the CRC32C of \"count\" bytes in the buffer pointed by \"data\". */\n+uint32_t crc32c_value(const uint8_t* data, size_t count);\n+\n+#ifdef __cplusplus\n+}  /* end extern \"C\" */\n+#endif  /* defined(__cplusplus) */\n+\n+\n+/* The C++ API. */\n+\n+#if defined(__cplusplus)\n+\n+namespace crc32c {\n+\n+// Extends \"crc\" with the CRC32C of \"count\" bytes in the buffer pointed by\n+// \"data\".\n+uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count);\n+\n+// Computes the CRC32C of \"count\" bytes in the buffer pointed by \"data\".\n+inline uint32_t Crc32c(const uint8_t* data, size_t count) {\n+  return Extend(0, data, count);\n+}\n+\n+// Computes the CRC32C of \"count\" bytes in the buffer pointed by \"data\".\n+inline uint32_t Crc32c(const char* data, size_t count) {\n+  return Extend(0, reinterpret_cast<const uint8_t*>(data), count);\n+}\n+\n+// Computes the CRC32C of the string's content.\n+inline uint32_t Crc32c(const std::string& string) {\n+  return Crc32c(reinterpret_cast<const uint8_t*>(string.data()),\n+                string.size());\n+}\n+\n+}  // namespace crc32c\n+\n+#if __cplusplus > 201402L\n+#if __has_include(<string_view>)\n+#include <string_view>\n+\n+namespace crc32c {\n+\n+// Computes the CRC32C of the bytes in the string_view.\n+inline uint32_t Crc32c(const std::string_view& string_view) {\n+  return Crc32c(reinterpret_cast<const uint8_t*>(string_view.data()),\n+                string_view.size());\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // __has_include(<string_view>)\n+#endif  // __cplusplus > 201402L\n+\n+#endif  /* defined(__cplusplus) */\n+\n+#endif  // CRC32C_CRC32C_H_"
      },
      {
        "sha": "4d3018af477d9281b872e1251f9650d8a89fd33c",
        "filename": "src/crc32c/src/crc32c.cc",
        "status": "added",
        "additions": 39,
        "deletions": 0,
        "changes": 39,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,39 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"crc32c/crc32c.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"./crc32c_arm64.h\"\n+#include \"./crc32c_arm64_linux_check.h\"\n+#include \"./crc32c_internal.h\"\n+#include \"./crc32c_sse42.h\"\n+#include \"./crc32c_sse42_check.h\"\n+\n+namespace crc32c {\n+\n+uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count) {\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+  static bool can_use_sse42 = CanUseSse42();\n+  if (can_use_sse42) return ExtendSse42(crc, data, count);\n+#elif HAVE_ARM64_CRC32C\n+  static bool can_use_arm_linux = CanUseArm64Linux();\n+  if (can_use_arm_linux) return ExtendArm64(crc, data, count);\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+  return ExtendPortable(crc, data, count);\n+}\n+\n+extern \"C\" uint32_t crc32c_extend(uint32_t crc, const uint8_t* data,\n+                                  size_t count) {\n+  return crc32c::Extend(crc, data, count);\n+}\n+\n+extern \"C\" uint32_t crc32c_value(const uint8_t* data, size_t count) {\n+  return crc32c::Crc32c(data, count);\n+}\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "b872245f95b052f84e0c49fcc40ee1ca34e36e8e",
        "filename": "src/crc32c/src/crc32c_arm64.cc",
        "status": "added",
        "additions": 126,
        "deletions": 0,
        "changes": 126,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_arm64.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_arm64.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_arm64.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,126 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_arm64.h\"\n+\n+// In a separate source file to allow this accelerated CRC32C function to be\n+// compiled with the appropriate compiler flags to enable ARM NEON CRC32C\n+// instructions.\n+\n+// This implementation is based on https://github.com/google/leveldb/pull/490.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"./crc32c_internal.h\"\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_ARM64_CRC32C\n+\n+#include <arm_acle.h>\n+#include <arm_neon.h>\n+\n+#define KBYTES 1032\n+#define SEGMENTBYTES 256\n+\n+// compute 8bytes for each segment parallelly\n+#define CRC32C32BYTES(P, IND)                                             \\\n+  do {                                                                    \\\n+    crc1 = __crc32cd(                                                     \\\n+        crc1, *((const uint64_t *)(P) + (SEGMENTBYTES / 8) * 1 + (IND))); \\\n+    crc2 = __crc32cd(                                                     \\\n+        crc2, *((const uint64_t *)(P) + (SEGMENTBYTES / 8) * 2 + (IND))); \\\n+    crc3 = __crc32cd(                                                     \\\n+        crc3, *((const uint64_t *)(P) + (SEGMENTBYTES / 8) * 3 + (IND))); \\\n+    crc0 = __crc32cd(                                                     \\\n+        crc0, *((const uint64_t *)(P) + (SEGMENTBYTES / 8) * 0 + (IND))); \\\n+  } while (0);\n+\n+// compute 8*8 bytes for each segment parallelly\n+#define CRC32C256BYTES(P, IND)      \\\n+  do {                              \\\n+    CRC32C32BYTES((P), (IND)*8 + 0) \\\n+    CRC32C32BYTES((P), (IND)*8 + 1) \\\n+    CRC32C32BYTES((P), (IND)*8 + 2) \\\n+    CRC32C32BYTES((P), (IND)*8 + 3) \\\n+    CRC32C32BYTES((P), (IND)*8 + 4) \\\n+    CRC32C32BYTES((P), (IND)*8 + 5) \\\n+    CRC32C32BYTES((P), (IND)*8 + 6) \\\n+    CRC32C32BYTES((P), (IND)*8 + 7) \\\n+  } while (0);\n+\n+// compute 4*8*8 bytes for each segment parallelly\n+#define CRC32C1024BYTES(P)   \\\n+  do {                       \\\n+    CRC32C256BYTES((P), 0)   \\\n+    CRC32C256BYTES((P), 1)   \\\n+    CRC32C256BYTES((P), 2)   \\\n+    CRC32C256BYTES((P), 3)   \\\n+    (P) += 4 * SEGMENTBYTES; \\\n+  } while (0)\n+\n+namespace crc32c {\n+\n+uint32_t ExtendArm64(uint32_t crc, const uint8_t *buf, size_t size) {\n+  int64_t length = size;\n+  uint32_t crc0, crc1, crc2, crc3;\n+  uint64_t t0, t1, t2;\n+\n+  // k0=CRC(x^(3*SEGMENTBYTES*8)), k1=CRC(x^(2*SEGMENTBYTES*8)),\n+  // k2=CRC(x^(SEGMENTBYTES*8))\n+  const poly64_t k0 = 0x8d96551c, k1 = 0xbd6f81f8, k2 = 0xdcb17aa4;\n+\n+  crc = crc ^ kCRC32Xor;\n+  const uint8_t *p = reinterpret_cast<const uint8_t *>(buf);\n+\n+  while (length >= KBYTES) {\n+    crc0 = crc;\n+    crc1 = 0;\n+    crc2 = 0;\n+    crc3 = 0;\n+\n+    // Process 1024 bytes in parallel.\n+    CRC32C1024BYTES(p);\n+\n+    // Merge the 4 partial CRC32C values.\n+    t2 = (uint64_t)vmull_p64(crc2, k2);\n+    t1 = (uint64_t)vmull_p64(crc1, k1);\n+    t0 = (uint64_t)vmull_p64(crc0, k0);\n+    crc = __crc32cd(crc3, *(uint64_t *)p);\n+    p += sizeof(uint64_t);\n+    crc ^= __crc32cd(0, t2);\n+    crc ^= __crc32cd(0, t1);\n+    crc ^= __crc32cd(0, t0);\n+\n+    length -= KBYTES;\n+  }\n+\n+  while (length >= 8) {\n+    crc = __crc32cd(crc, *(uint64_t *)p);\n+    p += 8;\n+    length -= 8;\n+  }\n+\n+  if (length & 4) {\n+    crc = __crc32cw(crc, *(uint32_t *)p);\n+    p += 4;\n+  }\n+\n+  if (length & 2) {\n+    crc = __crc32ch(crc, *(uint16_t *)p);\n+    p += 2;\n+  }\n+\n+  if (length & 1) {\n+    crc = __crc32cb(crc, *p);\n+  }\n+\n+  return crc ^ kCRC32Xor;\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // HAVE_ARM64_CRC32C"
      },
      {
        "sha": "100cd56ec84cc1c18219503c7fc942e05155f5ec",
        "filename": "src/crc32c/src/crc32c_arm64.h",
        "status": "added",
        "additions": 27,
        "deletions": 0,
        "changes": 27,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_arm64.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_arm64.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_arm64.h?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,27 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+// Linux-specific code checking the availability for ARM CRC32C instructions.\n+\n+#ifndef CRC32C_CRC32C_ARM_LINUX_H_\n+#define CRC32C_CRC32C_ARM_LINUX_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_ARM64_CRC32C\n+\n+namespace crc32c {\n+\n+uint32_t ExtendArm64(uint32_t crc, const uint8_t* data, size_t count);\n+\n+}  // namespace crc32c\n+\n+#endif  // HAVE_ARM64_CRC32C\n+\n+#endif  // CRC32C_CRC32C_ARM_LINUX_H_"
      },
      {
        "sha": "1a20a757bb0fb1578da7a6c17505496f286d4ec1",
        "filename": "src/crc32c/src/crc32c_arm64_linux_check.h",
        "status": "added",
        "additions": 50,
        "deletions": 0,
        "changes": 50,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_arm64_linux_check.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_arm64_linux_check.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_arm64_linux_check.h?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,50 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+// ARM Linux-specific code checking for the availability of CRC32C instructions.\n+\n+#ifndef CRC32C_CRC32C_ARM_LINUX_CHECK_H_\n+#define CRC32C_CRC32C_ARM_LINUX_CHECK_H_\n+\n+// X86-specific code checking for the availability of SSE4.2 instructions.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_ARM64_CRC32C\n+\n+#if HAVE_STRONG_GETAUXVAL\n+#include <sys/auxv.h>\n+#elif HAVE_WEAK_GETAUXVAL\n+// getauxval() is not available on Android until API level 20. Link it as a weak\n+// symbol.\n+extern \"C\" unsigned long getauxval(unsigned long type) __attribute__((weak));\n+\n+#define AT_HWCAP 16\n+#endif  // HAVE_STRONG_GETAUXVAL || HAVE_WEAK_GETAUXVAL\n+\n+namespace crc32c {\n+\n+inline bool CanUseArm64Linux() {\n+#if HAVE_STRONG_GETAUXVAL || HAVE_WEAK_GETAUXVAL\n+  // From 'arch/arm64/include/uapi/asm/hwcap.h' in Linux kernel source code.\n+  constexpr unsigned long kHWCAP_PMULL = 1 << 4;\n+  constexpr unsigned long kHWCAP_CRC32 = 1 << 7;\n+  unsigned long hwcap = (&getauxval != nullptr) ? getauxval(AT_HWCAP) : 0;\n+  return (hwcap & (kHWCAP_PMULL | kHWCAP_CRC32)) ==\n+         (kHWCAP_PMULL | kHWCAP_CRC32);\n+#else\n+  return false;\n+#endif  // HAVE_STRONG_GETAUXVAL || HAVE_WEAK_GETAUXVAL\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // HAVE_ARM64_CRC32C\n+\n+#endif  // CRC32C_CRC32C_ARM_LINUX_CHECK_H_"
      },
      {
        "sha": "6f917d9c0ce790178a75941489ee9c68aff313dd",
        "filename": "src/crc32c/src/crc32c_arm64_unittest.cc",
        "status": "added",
        "additions": 24,
        "deletions": 0,
        "changes": 24,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_arm64_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_arm64_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_arm64_unittest.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,24 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"gtest/gtest.h\"\n+\n+#include \"./crc32c_arm64.h\"\n+#include \"./crc32c_extend_unittests.h\"\n+\n+namespace crc32c {\n+\n+#if HAVE_ARM64_CRC32C\n+\n+struct Arm64TestTraits {\n+  static uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count) {\n+    return ExtendArm64(crc, data, count);\n+  }\n+};\n+\n+INSTANTIATE_TYPED_TEST_SUITE_P(Arm64, ExtendTest, Arm64TestTraits);\n+\n+#endif  // HAVE_ARM64_CRC32C\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "c464304b3f2879da5e352432b78c6ac507c78367",
        "filename": "src/crc32c/src/crc32c_benchmark.cc",
        "status": "added",
        "additions": 106,
        "deletions": 0,
        "changes": 106,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_benchmark.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_benchmark.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_benchmark.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,106 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#include \"benchmark/benchmark.h\"\n+\n+#if CRC32C_TESTS_BUILT_WITH_GLOG\n+#include \"glog/logging.h\"\n+#endif  // CRC32C_TESTS_BUILT_WITH_GLOG\n+\n+#include \"./crc32c_arm64.h\"\n+#include \"./crc32c_arm64_linux_check.h\"\n+#include \"./crc32c_internal.h\"\n+#include \"./crc32c_sse42.h\"\n+#include \"./crc32c_sse42_check.h\"\n+#include \"crc32c/crc32c.h\"\n+\n+class CRC32CBenchmark : public benchmark::Fixture {\n+ public:\n+  void SetUp(const benchmark::State& state) override {\n+    block_size_ = static_cast<size_t>(state.range(0));\n+    block_data_ = std::string(block_size_, 'x');\n+    block_buffer_ = reinterpret_cast<const uint8_t*>(block_data_.data());\n+  }\n+\n+ protected:\n+  std::string block_data_;\n+  const uint8_t* block_buffer_;\n+  size_t block_size_;\n+};\n+\n+BENCHMARK_DEFINE_F(CRC32CBenchmark, Public)(benchmark::State& state) {\n+  uint32_t crc = 0;\n+  for (auto _ : state)\n+    crc = crc32c::Extend(crc, block_buffer_, block_size_);\n+  state.SetBytesProcessed(state.iterations() * block_size_);\n+}\n+BENCHMARK_REGISTER_F(CRC32CBenchmark, Public)\n+    ->RangeMultiplier(16)\n+    ->Range(256, 16777216);  // Block size.\n+\n+BENCHMARK_DEFINE_F(CRC32CBenchmark, Portable)(benchmark::State& state) {\n+  uint32_t crc = 0;\n+  for (auto _ : state)\n+    crc = crc32c::ExtendPortable(crc, block_buffer_, block_size_);\n+  state.SetBytesProcessed(state.iterations() * block_size_);\n+}\n+BENCHMARK_REGISTER_F(CRC32CBenchmark, Portable)\n+    ->RangeMultiplier(16)\n+    ->Range(256, 16777216);  // Block size.\n+\n+#if HAVE_ARM64_CRC32C\n+\n+BENCHMARK_DEFINE_F(CRC32CBenchmark, ArmLinux)(benchmark::State& state) {\n+  if (!crc32c::CanUseArm64Linux()) {\n+    state.SkipWithError(\"ARM CRC32C instructions not available or not enabled\");\n+    return;\n+  }\n+\n+  uint32_t crc = 0;\n+  for (auto _ : state)\n+    crc = crc32c::ExtendArm64(crc, block_buffer_, block_size_);\n+  state.SetBytesProcessed(state.iterations() * block_size_);\n+}\n+BENCHMARK_REGISTER_F(CRC32CBenchmark, ArmLinux)\n+    ->RangeMultiplier(16)\n+    ->Range(256, 16777216);  // Block size.\n+\n+#endif  // HAVE_ARM64_CRC32C\n+\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+BENCHMARK_DEFINE_F(CRC32CBenchmark, Sse42)(benchmark::State& state) {\n+  if (!crc32c::CanUseSse42()) {\n+    state.SkipWithError(\"SSE4.2 instructions not available or not enabled\");\n+    return;\n+  }\n+\n+  uint32_t crc = 0;\n+  for (auto _ : state)\n+    crc = crc32c::ExtendSse42(crc, block_buffer_, block_size_);\n+  state.SetBytesProcessed(state.iterations() * block_size_);\n+}\n+BENCHMARK_REGISTER_F(CRC32CBenchmark, Sse42)\n+    ->RangeMultiplier(16)\n+    ->Range(256, 16777216);  // Block size.\n+\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+int main(int argc, char** argv) {\n+#if CRC32C_TESTS_BUILT_WITH_GLOG\n+  google::InitGoogleLogging(argv[0]);\n+  google::InstallFailureSignalHandler();\n+#endif  // CRC32C_TESTS_BUILT_WITH_GLOG\n+\n+  benchmark::Initialize(&argc, argv);\n+  benchmark::RunSpecifiedBenchmarks();\n+  return 0;\n+}"
      },
      {
        "sha": "c8993a0959900ae072f4d29b243865d8deee4ff4",
        "filename": "src/crc32c/src/crc32c_capi_unittest.c",
        "status": "added",
        "additions": 66,
        "deletions": 0,
        "changes": 66,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_capi_unittest.c",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_capi_unittest.c",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_capi_unittest.c?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,66 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"crc32c/crc32c.h\"\n+\n+#include <stddef.h>\n+#include <stdint.h>\n+#include <stdio.h>\n+#include <stdlib.h>\n+#include <string.h>\n+\n+int main() {\n+  /* From rfc3720 section B.4. */\n+  uint8_t buf[32];\n+\n+  memset(buf, 0, sizeof(buf));\n+  if ((uint32_t)0x8a9136aa != crc32c_value(buf, sizeof(buf))) {\n+    printf(\"crc32c_value(zeros) test failed\\n\");\n+    return 1;\n+  }\n+\n+  memset(buf, 0xff, sizeof(buf));\n+  if ((uint32_t)0x62a8ab43 != crc32c_value(buf, sizeof(buf))) {\n+    printf(\"crc32c_value(0xff) test failed\\n\");\n+    return 1;\n+  }\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = (uint8_t)i;\n+  if ((uint32_t)0x46dd794e != crc32c_value(buf, sizeof(buf))) {\n+    printf(\"crc32c_value(0..31) test failed\\n\");\n+    return 1;\n+  }\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = (uint8_t)(31 - i);\n+  if ((uint32_t)0x113fdb5c != crc32c_value(buf, sizeof(buf))) {\n+    printf(\"crc32c_value(31..0) test failed\\n\");\n+    return 1;\n+  }\n+\n+  uint8_t data[48] = {\n+      0x01, 0xc0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00,\n+      0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x28, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+  };\n+  if ((uint32_t)0xd9963a56 != crc32c_value(data, sizeof(data))) {\n+    printf(\"crc32c_value(31..0) test failed\\n\");\n+    return 1;\n+  }\n+\n+  const uint8_t* hello_space_world = (const uint8_t*)\"hello world\";\n+  const uint8_t* hello_space = (const uint8_t*)\"hello \";\n+  const uint8_t* world = (const uint8_t*)\"world\";\n+\n+  if (crc32c_value(hello_space_world, 11) !=\n+      crc32c_extend(crc32c_value(hello_space, 6), world, 5)) {\n+    printf(\"crc32c_extend test failed\\n\");\n+    return 1;\n+  }\n+\n+  printf(\"All tests passed\\n\");\n+  return 0;\n+}"
      },
      {
        "sha": "4034fa5644461eb20118906ac0935282a05a1bcd",
        "filename": "src/crc32c/src/crc32c_config.h.in",
        "status": "added",
        "additions": 36,
        "deletions": 0,
        "changes": 36,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_config.h.in",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_config.h.in",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_config.h.in?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,36 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_CONFIG_H_\n+#define CRC32C_CRC32C_CONFIG_H_\n+\n+// Define to 1 if building for a big-endian platform.\n+#cmakedefine01 BYTE_ORDER_BIG_ENDIAN\n+\n+// Define to 1 if the compiler has the __builtin_prefetch intrinsic.\n+#cmakedefine01 HAVE_BUILTIN_PREFETCH\n+\n+// Define to 1 if targeting X86 and the compiler has the _mm_prefetch intrinsic.\n+#cmakedefine01 HAVE_MM_PREFETCH\n+\n+// Define to 1 if targeting X86 and the compiler has the _mm_crc32_u{8,32,64}\n+// intrinsics.\n+#cmakedefine01 HAVE_SSE42\n+\n+// Define to 1 if targeting ARM and the compiler has the __crc32c{b,h,w,d} and\n+// the vmull_p64 intrinsics.\n+#cmakedefine01 HAVE_ARM64_CRC32C\n+\n+// Define to 1 if the system libraries have the getauxval function in the\n+// <sys/auxv.h> header. Should be true on Linux and Android API level 20+.\n+#cmakedefine01 HAVE_STRONG_GETAUXVAL\n+\n+// Define to 1 if the compiler supports defining getauxval as a weak symbol.\n+// Should be true for any compiler that supports __attribute__((weak)).\n+#cmakedefine01 HAVE_WEAK_GETAUXVAL\n+\n+// Define to 1 if CRC32C tests have been built with Google Logging.\n+#cmakedefine01 CRC32C_TESTS_BUILT_WITH_GLOG\n+\n+#endif  // CRC32C_CRC32C_CONFIG_H_"
      },
      {
        "sha": "0732973737d5a408e6443b7e8b23bfd6b999ad2b",
        "filename": "src/crc32c/src/crc32c_extend_unittests.h",
        "status": "added",
        "additions": 112,
        "deletions": 0,
        "changes": 112,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_extend_unittests.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_extend_unittests.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_extend_unittests.h?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,112 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_EXTEND_UNITTESTS_H_\n+#define CRC32C_CRC32C_EXTEND_UNITTESTS_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <cstring>\n+\n+#include \"gtest/gtest.h\"\n+\n+// Common test cases for all implementations of CRC32C_Extend().\n+\n+namespace crc32c {\n+\n+template<typename TestTraits>\n+class ExtendTest : public testing::Test {};\n+\n+TYPED_TEST_SUITE_P(ExtendTest);\n+\n+TYPED_TEST_P(ExtendTest, StandardResults) {\n+  // From rfc3720 section B.4.\n+  uint8_t buf[32];\n+\n+  std::memset(buf, 0, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x8a9136aa),\n+            TypeParam::Extend(0, buf, sizeof(buf)));\n+\n+  std::memset(buf, 0xff, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x62a8ab43),\n+            TypeParam::Extend(0, buf, sizeof(buf)));\n+\n+  for (int i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x46dd794e),\n+            TypeParam::Extend(0, buf, sizeof(buf)));\n+\n+  for (int i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(31 - i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x113fdb5c),\n+            TypeParam::Extend(0, buf, sizeof(buf)));\n+\n+  uint8_t data[48] = {\n+      0x01, 0xc0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00,\n+      0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x28, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+  };\n+  EXPECT_EQ(static_cast<uint32_t>(0xd9963a56),\n+            TypeParam::Extend(0, data, sizeof(data)));\n+}\n+\n+TYPED_TEST_P(ExtendTest, HelloWorld) {\n+  const uint8_t* hello_space_world =\n+      reinterpret_cast<const uint8_t*>(\"hello world\");\n+  const uint8_t* hello_space = reinterpret_cast<const uint8_t*>(\"hello \");\n+  const uint8_t* world = reinterpret_cast<const uint8_t*>(\"world\");\n+\n+  EXPECT_EQ(TypeParam::Extend(0, hello_space_world, 11),\n+            TypeParam::Extend(TypeParam::Extend(0, hello_space, 6), world, 5));\n+}\n+\n+TYPED_TEST_P(ExtendTest, BufferSlicing) {\n+  uint8_t buffer[48] = {\n+      0x01, 0xc0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00,\n+      0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x28, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+  };\n+\n+  for (size_t i = 0; i < 48; ++i) {\n+    for (size_t j = i + 1; j <= 48; ++j) {\n+      uint32_t crc = 0;\n+\n+      if (i > 0) crc = TypeParam::Extend(crc, buffer, i);\n+      crc = TypeParam::Extend(crc, buffer + i, j - i);\n+      if (j < 48) crc = TypeParam::Extend(crc, buffer + j, 48 - j);\n+\n+      EXPECT_EQ(static_cast<uint32_t>(0xd9963a56), crc);\n+    }\n+  }\n+}\n+\n+TYPED_TEST_P(ExtendTest, LargeBufferSlicing) {\n+  uint8_t buffer[2048];\n+  for (size_t i = 0; i < 2048; i++)\n+    buffer[i] = static_cast<uint8_t>(3 * i * i + 7 * i + 11);\n+\n+  for (size_t i = 0; i < 2048; ++i) {\n+    for (size_t j = i + 1; j <= 2048; ++j) {\n+      uint32_t crc = 0;\n+\n+      if (i > 0) crc = TypeParam::Extend(crc, buffer, i);\n+      crc = TypeParam::Extend(crc, buffer + i, j - i);\n+      if (j < 2048) crc = TypeParam::Extend(crc, buffer + j, 2048 - j);\n+\n+      EXPECT_EQ(static_cast<uint32_t>(0x36dcc753), crc);\n+    }\n+  }\n+}\n+\n+REGISTER_TYPED_TEST_SUITE_P(ExtendTest,\n+    StandardResults,\n+    HelloWorld,\n+    BufferSlicing,\n+    LargeBufferSlicing);\n+\n+}  // namespace crc32c\n+\n+#endif  // CRC32C_CRC32C_EXTEND_UNITTESTS_H_"
      },
      {
        "sha": "2bd23dea43e84ed0d226fe9ce0f2b1e9f4a25e7e",
        "filename": "src/crc32c/src/crc32c_internal.h",
        "status": "added",
        "additions": 23,
        "deletions": 0,
        "changes": 23,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_internal.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_internal.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_internal.h?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,23 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_INTERNAL_H_\n+#define CRC32C_CRC32C_INTERNAL_H_\n+\n+// Internal functions that may change between releases.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+namespace crc32c {\n+\n+// Un-accelerated implementation that works on all CPUs.\n+uint32_t ExtendPortable(uint32_t crc, const uint8_t* data, size_t count);\n+\n+// CRCs are pre- and post- conditioned by xoring with all ones.\n+static constexpr const uint32_t kCRC32Xor = static_cast<uint32_t>(0xffffffffU);\n+\n+}  // namespace crc32c\n+\n+#endif  // CRC32C_CRC32C_INTERNAL_H_"
      },
      {
        "sha": "31ec6eac5373dc2acf912015bf269bb6f93cd8bf",
        "filename": "src/crc32c/src/crc32c_portable.cc",
        "status": "added",
        "additions": 351,
        "deletions": 0,
        "changes": 351,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_portable.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_portable.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_portable.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,351 @@\n+// Copyright 2008 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_internal.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"./crc32c_prefetch.h\"\n+#include \"./crc32c_read_le.h\"\n+#include \"./crc32c_round_up.h\"\n+\n+namespace {\n+\n+const uint32_t kByteExtensionTable[256] = {\n+    0x00000000, 0xf26b8303, 0xe13b70f7, 0x1350f3f4, 0xc79a971f, 0x35f1141c,\n+    0x26a1e7e8, 0xd4ca64eb, 0x8ad958cf, 0x78b2dbcc, 0x6be22838, 0x9989ab3b,\n+    0x4d43cfd0, 0xbf284cd3, 0xac78bf27, 0x5e133c24, 0x105ec76f, 0xe235446c,\n+    0xf165b798, 0x030e349b, 0xd7c45070, 0x25afd373, 0x36ff2087, 0xc494a384,\n+    0x9a879fa0, 0x68ec1ca3, 0x7bbcef57, 0x89d76c54, 0x5d1d08bf, 0xaf768bbc,\n+    0xbc267848, 0x4e4dfb4b, 0x20bd8ede, 0xd2d60ddd, 0xc186fe29, 0x33ed7d2a,\n+    0xe72719c1, 0x154c9ac2, 0x061c6936, 0xf477ea35, 0xaa64d611, 0x580f5512,\n+    0x4b5fa6e6, 0xb93425e5, 0x6dfe410e, 0x9f95c20d, 0x8cc531f9, 0x7eaeb2fa,\n+    0x30e349b1, 0xc288cab2, 0xd1d83946, 0x23b3ba45, 0xf779deae, 0x05125dad,\n+    0x1642ae59, 0xe4292d5a, 0xba3a117e, 0x4851927d, 0x5b016189, 0xa96ae28a,\n+    0x7da08661, 0x8fcb0562, 0x9c9bf696, 0x6ef07595, 0x417b1dbc, 0xb3109ebf,\n+    0xa0406d4b, 0x522bee48, 0x86e18aa3, 0x748a09a0, 0x67dafa54, 0x95b17957,\n+    0xcba24573, 0x39c9c670, 0x2a993584, 0xd8f2b687, 0x0c38d26c, 0xfe53516f,\n+    0xed03a29b, 0x1f682198, 0x5125dad3, 0xa34e59d0, 0xb01eaa24, 0x42752927,\n+    0x96bf4dcc, 0x64d4cecf, 0x77843d3b, 0x85efbe38, 0xdbfc821c, 0x2997011f,\n+    0x3ac7f2eb, 0xc8ac71e8, 0x1c661503, 0xee0d9600, 0xfd5d65f4, 0x0f36e6f7,\n+    0x61c69362, 0x93ad1061, 0x80fde395, 0x72966096, 0xa65c047d, 0x5437877e,\n+    0x4767748a, 0xb50cf789, 0xeb1fcbad, 0x197448ae, 0x0a24bb5a, 0xf84f3859,\n+    0x2c855cb2, 0xdeeedfb1, 0xcdbe2c45, 0x3fd5af46, 0x7198540d, 0x83f3d70e,\n+    0x90a324fa, 0x62c8a7f9, 0xb602c312, 0x44694011, 0x5739b3e5, 0xa55230e6,\n+    0xfb410cc2, 0x092a8fc1, 0x1a7a7c35, 0xe811ff36, 0x3cdb9bdd, 0xceb018de,\n+    0xdde0eb2a, 0x2f8b6829, 0x82f63b78, 0x709db87b, 0x63cd4b8f, 0x91a6c88c,\n+    0x456cac67, 0xb7072f64, 0xa457dc90, 0x563c5f93, 0x082f63b7, 0xfa44e0b4,\n+    0xe9141340, 0x1b7f9043, 0xcfb5f4a8, 0x3dde77ab, 0x2e8e845f, 0xdce5075c,\n+    0x92a8fc17, 0x60c37f14, 0x73938ce0, 0x81f80fe3, 0x55326b08, 0xa759e80b,\n+    0xb4091bff, 0x466298fc, 0x1871a4d8, 0xea1a27db, 0xf94ad42f, 0x0b21572c,\n+    0xdfeb33c7, 0x2d80b0c4, 0x3ed04330, 0xccbbc033, 0xa24bb5a6, 0x502036a5,\n+    0x4370c551, 0xb11b4652, 0x65d122b9, 0x97baa1ba, 0x84ea524e, 0x7681d14d,\n+    0x2892ed69, 0xdaf96e6a, 0xc9a99d9e, 0x3bc21e9d, 0xef087a76, 0x1d63f975,\n+    0x0e330a81, 0xfc588982, 0xb21572c9, 0x407ef1ca, 0x532e023e, 0xa145813d,\n+    0x758fe5d6, 0x87e466d5, 0x94b49521, 0x66df1622, 0x38cc2a06, 0xcaa7a905,\n+    0xd9f75af1, 0x2b9cd9f2, 0xff56bd19, 0x0d3d3e1a, 0x1e6dcdee, 0xec064eed,\n+    0xc38d26c4, 0x31e6a5c7, 0x22b65633, 0xd0ddd530, 0x0417b1db, 0xf67c32d8,\n+    0xe52cc12c, 0x1747422f, 0x49547e0b, 0xbb3ffd08, 0xa86f0efc, 0x5a048dff,\n+    0x8ecee914, 0x7ca56a17, 0x6ff599e3, 0x9d9e1ae0, 0xd3d3e1ab, 0x21b862a8,\n+    0x32e8915c, 0xc083125f, 0x144976b4, 0xe622f5b7, 0xf5720643, 0x07198540,\n+    0x590ab964, 0xab613a67, 0xb831c993, 0x4a5a4a90, 0x9e902e7b, 0x6cfbad78,\n+    0x7fab5e8c, 0x8dc0dd8f, 0xe330a81a, 0x115b2b19, 0x020bd8ed, 0xf0605bee,\n+    0x24aa3f05, 0xd6c1bc06, 0xc5914ff2, 0x37faccf1, 0x69e9f0d5, 0x9b8273d6,\n+    0x88d28022, 0x7ab90321, 0xae7367ca, 0x5c18e4c9, 0x4f48173d, 0xbd23943e,\n+    0xf36e6f75, 0x0105ec76, 0x12551f82, 0xe03e9c81, 0x34f4f86a, 0xc69f7b69,\n+    0xd5cf889d, 0x27a40b9e, 0x79b737ba, 0x8bdcb4b9, 0x988c474d, 0x6ae7c44e,\n+    0xbe2da0a5, 0x4c4623a6, 0x5f16d052, 0xad7d5351};\n+\n+const uint32_t kStrideExtensionTable0[256] = {\n+    0x00000000, 0x30d23865, 0x61a470ca, 0x517648af, 0xc348e194, 0xf39ad9f1,\n+    0xa2ec915e, 0x923ea93b, 0x837db5d9, 0xb3af8dbc, 0xe2d9c513, 0xd20bfd76,\n+    0x4035544d, 0x70e76c28, 0x21912487, 0x11431ce2, 0x03171d43, 0x33c52526,\n+    0x62b36d89, 0x526155ec, 0xc05ffcd7, 0xf08dc4b2, 0xa1fb8c1d, 0x9129b478,\n+    0x806aa89a, 0xb0b890ff, 0xe1ced850, 0xd11ce035, 0x4322490e, 0x73f0716b,\n+    0x228639c4, 0x125401a1, 0x062e3a86, 0x36fc02e3, 0x678a4a4c, 0x57587229,\n+    0xc566db12, 0xf5b4e377, 0xa4c2abd8, 0x941093bd, 0x85538f5f, 0xb581b73a,\n+    0xe4f7ff95, 0xd425c7f0, 0x461b6ecb, 0x76c956ae, 0x27bf1e01, 0x176d2664,\n+    0x053927c5, 0x35eb1fa0, 0x649d570f, 0x544f6f6a, 0xc671c651, 0xf6a3fe34,\n+    0xa7d5b69b, 0x97078efe, 0x8644921c, 0xb696aa79, 0xe7e0e2d6, 0xd732dab3,\n+    0x450c7388, 0x75de4bed, 0x24a80342, 0x147a3b27, 0x0c5c750c, 0x3c8e4d69,\n+    0x6df805c6, 0x5d2a3da3, 0xcf149498, 0xffc6acfd, 0xaeb0e452, 0x9e62dc37,\n+    0x8f21c0d5, 0xbff3f8b0, 0xee85b01f, 0xde57887a, 0x4c692141, 0x7cbb1924,\n+    0x2dcd518b, 0x1d1f69ee, 0x0f4b684f, 0x3f99502a, 0x6eef1885, 0x5e3d20e0,\n+    0xcc0389db, 0xfcd1b1be, 0xada7f911, 0x9d75c174, 0x8c36dd96, 0xbce4e5f3,\n+    0xed92ad5c, 0xdd409539, 0x4f7e3c02, 0x7fac0467, 0x2eda4cc8, 0x1e0874ad,\n+    0x0a724f8a, 0x3aa077ef, 0x6bd63f40, 0x5b040725, 0xc93aae1e, 0xf9e8967b,\n+    0xa89eded4, 0x984ce6b1, 0x890ffa53, 0xb9ddc236, 0xe8ab8a99, 0xd879b2fc,\n+    0x4a471bc7, 0x7a9523a2, 0x2be36b0d, 0x1b315368, 0x096552c9, 0x39b76aac,\n+    0x68c12203, 0x58131a66, 0xca2db35d, 0xfaff8b38, 0xab89c397, 0x9b5bfbf2,\n+    0x8a18e710, 0xbacadf75, 0xebbc97da, 0xdb6eafbf, 0x49500684, 0x79823ee1,\n+    0x28f4764e, 0x18264e2b, 0x18b8ea18, 0x286ad27d, 0x791c9ad2, 0x49cea2b7,\n+    0xdbf00b8c, 0xeb2233e9, 0xba547b46, 0x8a864323, 0x9bc55fc1, 0xab1767a4,\n+    0xfa612f0b, 0xcab3176e, 0x588dbe55, 0x685f8630, 0x3929ce9f, 0x09fbf6fa,\n+    0x1baff75b, 0x2b7dcf3e, 0x7a0b8791, 0x4ad9bff4, 0xd8e716cf, 0xe8352eaa,\n+    0xb9436605, 0x89915e60, 0x98d24282, 0xa8007ae7, 0xf9763248, 0xc9a40a2d,\n+    0x5b9aa316, 0x6b489b73, 0x3a3ed3dc, 0x0aecebb9, 0x1e96d09e, 0x2e44e8fb,\n+    0x7f32a054, 0x4fe09831, 0xddde310a, 0xed0c096f, 0xbc7a41c0, 0x8ca879a5,\n+    0x9deb6547, 0xad395d22, 0xfc4f158d, 0xcc9d2de8, 0x5ea384d3, 0x6e71bcb6,\n+    0x3f07f419, 0x0fd5cc7c, 0x1d81cddd, 0x2d53f5b8, 0x7c25bd17, 0x4cf78572,\n+    0xdec92c49, 0xee1b142c, 0xbf6d5c83, 0x8fbf64e6, 0x9efc7804, 0xae2e4061,\n+    0xff5808ce, 0xcf8a30ab, 0x5db49990, 0x6d66a1f5, 0x3c10e95a, 0x0cc2d13f,\n+    0x14e49f14, 0x2436a771, 0x7540efde, 0x4592d7bb, 0xd7ac7e80, 0xe77e46e5,\n+    0xb6080e4a, 0x86da362f, 0x97992acd, 0xa74b12a8, 0xf63d5a07, 0xc6ef6262,\n+    0x54d1cb59, 0x6403f33c, 0x3575bb93, 0x05a783f6, 0x17f38257, 0x2721ba32,\n+    0x7657f29d, 0x4685caf8, 0xd4bb63c3, 0xe4695ba6, 0xb51f1309, 0x85cd2b6c,\n+    0x948e378e, 0xa45c0feb, 0xf52a4744, 0xc5f87f21, 0x57c6d61a, 0x6714ee7f,\n+    0x3662a6d0, 0x06b09eb5, 0x12caa592, 0x22189df7, 0x736ed558, 0x43bced3d,\n+    0xd1824406, 0xe1507c63, 0xb02634cc, 0x80f40ca9, 0x91b7104b, 0xa165282e,\n+    0xf0136081, 0xc0c158e4, 0x52fff1df, 0x622dc9ba, 0x335b8115, 0x0389b970,\n+    0x11ddb8d1, 0x210f80b4, 0x7079c81b, 0x40abf07e, 0xd2955945, 0xe2476120,\n+    0xb331298f, 0x83e311ea, 0x92a00d08, 0xa272356d, 0xf3047dc2, 0xc3d645a7,\n+    0x51e8ec9c, 0x613ad4f9, 0x304c9c56, 0x009ea433};\n+\n+const uint32_t kStrideExtensionTable1[256] = {\n+    0x00000000, 0x54075546, 0xa80eaa8c, 0xfc09ffca, 0x55f123e9, 0x01f676af,\n+    0xfdff8965, 0xa9f8dc23, 0xabe247d2, 0xffe51294, 0x03eced5e, 0x57ebb818,\n+    0xfe13643b, 0xaa14317d, 0x561dceb7, 0x021a9bf1, 0x5228f955, 0x062fac13,\n+    0xfa2653d9, 0xae21069f, 0x07d9dabc, 0x53de8ffa, 0xafd77030, 0xfbd02576,\n+    0xf9cabe87, 0xadcdebc1, 0x51c4140b, 0x05c3414d, 0xac3b9d6e, 0xf83cc828,\n+    0x043537e2, 0x503262a4, 0xa451f2aa, 0xf056a7ec, 0x0c5f5826, 0x58580d60,\n+    0xf1a0d143, 0xa5a78405, 0x59ae7bcf, 0x0da92e89, 0x0fb3b578, 0x5bb4e03e,\n+    0xa7bd1ff4, 0xf3ba4ab2, 0x5a429691, 0x0e45c3d7, 0xf24c3c1d, 0xa64b695b,\n+    0xf6790bff, 0xa27e5eb9, 0x5e77a173, 0x0a70f435, 0xa3882816, 0xf78f7d50,\n+    0x0b86829a, 0x5f81d7dc, 0x5d9b4c2d, 0x099c196b, 0xf595e6a1, 0xa192b3e7,\n+    0x086a6fc4, 0x5c6d3a82, 0xa064c548, 0xf463900e, 0x4d4f93a5, 0x1948c6e3,\n+    0xe5413929, 0xb1466c6f, 0x18beb04c, 0x4cb9e50a, 0xb0b01ac0, 0xe4b74f86,\n+    0xe6add477, 0xb2aa8131, 0x4ea37efb, 0x1aa42bbd, 0xb35cf79e, 0xe75ba2d8,\n+    0x1b525d12, 0x4f550854, 0x1f676af0, 0x4b603fb6, 0xb769c07c, 0xe36e953a,\n+    0x4a964919, 0x1e911c5f, 0xe298e395, 0xb69fb6d3, 0xb4852d22, 0xe0827864,\n+    0x1c8b87ae, 0x488cd2e8, 0xe1740ecb, 0xb5735b8d, 0x497aa447, 0x1d7df101,\n+    0xe91e610f, 0xbd193449, 0x4110cb83, 0x15179ec5, 0xbcef42e6, 0xe8e817a0,\n+    0x14e1e86a, 0x40e6bd2c, 0x42fc26dd, 0x16fb739b, 0xeaf28c51, 0xbef5d917,\n+    0x170d0534, 0x430a5072, 0xbf03afb8, 0xeb04fafe, 0xbb36985a, 0xef31cd1c,\n+    0x133832d6, 0x473f6790, 0xeec7bbb3, 0xbac0eef5, 0x46c9113f, 0x12ce4479,\n+    0x10d4df88, 0x44d38ace, 0xb8da7504, 0xecdd2042, 0x4525fc61, 0x1122a927,\n+    0xed2b56ed, 0xb92c03ab, 0x9a9f274a, 0xce98720c, 0x32918dc6, 0x6696d880,\n+    0xcf6e04a3, 0x9b6951e5, 0x6760ae2f, 0x3367fb69, 0x317d6098, 0x657a35de,\n+    0x9973ca14, 0xcd749f52, 0x648c4371, 0x308b1637, 0xcc82e9fd, 0x9885bcbb,\n+    0xc8b7de1f, 0x9cb08b59, 0x60b97493, 0x34be21d5, 0x9d46fdf6, 0xc941a8b0,\n+    0x3548577a, 0x614f023c, 0x635599cd, 0x3752cc8b, 0xcb5b3341, 0x9f5c6607,\n+    0x36a4ba24, 0x62a3ef62, 0x9eaa10a8, 0xcaad45ee, 0x3eced5e0, 0x6ac980a6,\n+    0x96c07f6c, 0xc2c72a2a, 0x6b3ff609, 0x3f38a34f, 0xc3315c85, 0x973609c3,\n+    0x952c9232, 0xc12bc774, 0x3d2238be, 0x69256df8, 0xc0ddb1db, 0x94dae49d,\n+    0x68d31b57, 0x3cd44e11, 0x6ce62cb5, 0x38e179f3, 0xc4e88639, 0x90efd37f,\n+    0x39170f5c, 0x6d105a1a, 0x9119a5d0, 0xc51ef096, 0xc7046b67, 0x93033e21,\n+    0x6f0ac1eb, 0x3b0d94ad, 0x92f5488e, 0xc6f21dc8, 0x3afbe202, 0x6efcb744,\n+    0xd7d0b4ef, 0x83d7e1a9, 0x7fde1e63, 0x2bd94b25, 0x82219706, 0xd626c240,\n+    0x2a2f3d8a, 0x7e2868cc, 0x7c32f33d, 0x2835a67b, 0xd43c59b1, 0x803b0cf7,\n+    0x29c3d0d4, 0x7dc48592, 0x81cd7a58, 0xd5ca2f1e, 0x85f84dba, 0xd1ff18fc,\n+    0x2df6e736, 0x79f1b270, 0xd0096e53, 0x840e3b15, 0x7807c4df, 0x2c009199,\n+    0x2e1a0a68, 0x7a1d5f2e, 0x8614a0e4, 0xd213f5a2, 0x7beb2981, 0x2fec7cc7,\n+    0xd3e5830d, 0x87e2d64b, 0x73814645, 0x27861303, 0xdb8fecc9, 0x8f88b98f,\n+    0x267065ac, 0x727730ea, 0x8e7ecf20, 0xda799a66, 0xd8630197, 0x8c6454d1,\n+    0x706dab1b, 0x246afe5d, 0x8d92227e, 0xd9957738, 0x259c88f2, 0x719bddb4,\n+    0x21a9bf10, 0x75aeea56, 0x89a7159c, 0xdda040da, 0x74589cf9, 0x205fc9bf,\n+    0xdc563675, 0x88516333, 0x8a4bf8c2, 0xde4cad84, 0x2245524e, 0x76420708,\n+    0xdfbadb2b, 0x8bbd8e6d, 0x77b471a7, 0x23b324e1};\n+\n+const uint32_t kStrideExtensionTable2[256] = {\n+    0x00000000, 0x678efd01, 0xcf1dfa02, 0xa8930703, 0x9bd782f5, 0xfc597ff4,\n+    0x54ca78f7, 0x334485f6, 0x3243731b, 0x55cd8e1a, 0xfd5e8919, 0x9ad07418,\n+    0xa994f1ee, 0xce1a0cef, 0x66890bec, 0x0107f6ed, 0x6486e636, 0x03081b37,\n+    0xab9b1c34, 0xcc15e135, 0xff5164c3, 0x98df99c2, 0x304c9ec1, 0x57c263c0,\n+    0x56c5952d, 0x314b682c, 0x99d86f2f, 0xfe56922e, 0xcd1217d8, 0xaa9cead9,\n+    0x020fedda, 0x658110db, 0xc90dcc6c, 0xae83316d, 0x0610366e, 0x619ecb6f,\n+    0x52da4e99, 0x3554b398, 0x9dc7b49b, 0xfa49499a, 0xfb4ebf77, 0x9cc04276,\n+    0x34534575, 0x53ddb874, 0x60993d82, 0x0717c083, 0xaf84c780, 0xc80a3a81,\n+    0xad8b2a5a, 0xca05d75b, 0x6296d058, 0x05182d59, 0x365ca8af, 0x51d255ae,\n+    0xf94152ad, 0x9ecfafac, 0x9fc85941, 0xf846a440, 0x50d5a343, 0x375b5e42,\n+    0x041fdbb4, 0x639126b5, 0xcb0221b6, 0xac8cdcb7, 0x97f7ee29, 0xf0791328,\n+    0x58ea142b, 0x3f64e92a, 0x0c206cdc, 0x6bae91dd, 0xc33d96de, 0xa4b36bdf,\n+    0xa5b49d32, 0xc23a6033, 0x6aa96730, 0x0d279a31, 0x3e631fc7, 0x59ede2c6,\n+    0xf17ee5c5, 0x96f018c4, 0xf371081f, 0x94fff51e, 0x3c6cf21d, 0x5be20f1c,\n+    0x68a68aea, 0x0f2877eb, 0xa7bb70e8, 0xc0358de9, 0xc1327b04, 0xa6bc8605,\n+    0x0e2f8106, 0x69a17c07, 0x5ae5f9f1, 0x3d6b04f0, 0x95f803f3, 0xf276fef2,\n+    0x5efa2245, 0x3974df44, 0x91e7d847, 0xf6692546, 0xc52da0b0, 0xa2a35db1,\n+    0x0a305ab2, 0x6dbea7b3, 0x6cb9515e, 0x0b37ac5f, 0xa3a4ab5c, 0xc42a565d,\n+    0xf76ed3ab, 0x90e02eaa, 0x387329a9, 0x5ffdd4a8, 0x3a7cc473, 0x5df23972,\n+    0xf5613e71, 0x92efc370, 0xa1ab4686, 0xc625bb87, 0x6eb6bc84, 0x09384185,\n+    0x083fb768, 0x6fb14a69, 0xc7224d6a, 0xa0acb06b, 0x93e8359d, 0xf466c89c,\n+    0x5cf5cf9f, 0x3b7b329e, 0x2a03aaa3, 0x4d8d57a2, 0xe51e50a1, 0x8290ada0,\n+    0xb1d42856, 0xd65ad557, 0x7ec9d254, 0x19472f55, 0x1840d9b8, 0x7fce24b9,\n+    0xd75d23ba, 0xb0d3debb, 0x83975b4d, 0xe419a64c, 0x4c8aa14f, 0x2b045c4e,\n+    0x4e854c95, 0x290bb194, 0x8198b697, 0xe6164b96, 0xd552ce60, 0xb2dc3361,\n+    0x1a4f3462, 0x7dc1c963, 0x7cc63f8e, 0x1b48c28f, 0xb3dbc58c, 0xd455388d,\n+    0xe711bd7b, 0x809f407a, 0x280c4779, 0x4f82ba78, 0xe30e66cf, 0x84809bce,\n+    0x2c139ccd, 0x4b9d61cc, 0x78d9e43a, 0x1f57193b, 0xb7c41e38, 0xd04ae339,\n+    0xd14d15d4, 0xb6c3e8d5, 0x1e50efd6, 0x79de12d7, 0x4a9a9721, 0x2d146a20,\n+    0x85876d23, 0xe2099022, 0x878880f9, 0xe0067df8, 0x48957afb, 0x2f1b87fa,\n+    0x1c5f020c, 0x7bd1ff0d, 0xd342f80e, 0xb4cc050f, 0xb5cbf3e2, 0xd2450ee3,\n+    0x7ad609e0, 0x1d58f4e1, 0x2e1c7117, 0x49928c16, 0xe1018b15, 0x868f7614,\n+    0xbdf4448a, 0xda7ab98b, 0x72e9be88, 0x15674389, 0x2623c67f, 0x41ad3b7e,\n+    0xe93e3c7d, 0x8eb0c17c, 0x8fb73791, 0xe839ca90, 0x40aacd93, 0x27243092,\n+    0x1460b564, 0x73ee4865, 0xdb7d4f66, 0xbcf3b267, 0xd972a2bc, 0xbefc5fbd,\n+    0x166f58be, 0x71e1a5bf, 0x42a52049, 0x252bdd48, 0x8db8da4b, 0xea36274a,\n+    0xeb31d1a7, 0x8cbf2ca6, 0x242c2ba5, 0x43a2d6a4, 0x70e65352, 0x1768ae53,\n+    0xbffba950, 0xd8755451, 0x74f988e6, 0x137775e7, 0xbbe472e4, 0xdc6a8fe5,\n+    0xef2e0a13, 0x88a0f712, 0x2033f011, 0x47bd0d10, 0x46bafbfd, 0x213406fc,\n+    0x89a701ff, 0xee29fcfe, 0xdd6d7908, 0xbae38409, 0x1270830a, 0x75fe7e0b,\n+    0x107f6ed0, 0x77f193d1, 0xdf6294d2, 0xb8ec69d3, 0x8ba8ec25, 0xec261124,\n+    0x44b51627, 0x233beb26, 0x223c1dcb, 0x45b2e0ca, 0xed21e7c9, 0x8aaf1ac8,\n+    0xb9eb9f3e, 0xde65623f, 0x76f6653c, 0x1178983d};\n+\n+const uint32_t kStrideExtensionTable3[256] = {\n+    0x00000000, 0xf20c0dfe, 0xe1f46d0d, 0x13f860f3, 0xc604aceb, 0x3408a115,\n+    0x27f0c1e6, 0xd5fccc18, 0x89e52f27, 0x7be922d9, 0x6811422a, 0x9a1d4fd4,\n+    0x4fe183cc, 0xbded8e32, 0xae15eec1, 0x5c19e33f, 0x162628bf, 0xe42a2541,\n+    0xf7d245b2, 0x05de484c, 0xd0228454, 0x222e89aa, 0x31d6e959, 0xc3dae4a7,\n+    0x9fc30798, 0x6dcf0a66, 0x7e376a95, 0x8c3b676b, 0x59c7ab73, 0xabcba68d,\n+    0xb833c67e, 0x4a3fcb80, 0x2c4c517e, 0xde405c80, 0xcdb83c73, 0x3fb4318d,\n+    0xea48fd95, 0x1844f06b, 0x0bbc9098, 0xf9b09d66, 0xa5a97e59, 0x57a573a7,\n+    0x445d1354, 0xb6511eaa, 0x63add2b2, 0x91a1df4c, 0x8259bfbf, 0x7055b241,\n+    0x3a6a79c1, 0xc866743f, 0xdb9e14cc, 0x29921932, 0xfc6ed52a, 0x0e62d8d4,\n+    0x1d9ab827, 0xef96b5d9, 0xb38f56e6, 0x41835b18, 0x527b3beb, 0xa0773615,\n+    0x758bfa0d, 0x8787f7f3, 0x947f9700, 0x66739afe, 0x5898a2fc, 0xaa94af02,\n+    0xb96ccff1, 0x4b60c20f, 0x9e9c0e17, 0x6c9003e9, 0x7f68631a, 0x8d646ee4,\n+    0xd17d8ddb, 0x23718025, 0x3089e0d6, 0xc285ed28, 0x17792130, 0xe5752cce,\n+    0xf68d4c3d, 0x048141c3, 0x4ebe8a43, 0xbcb287bd, 0xaf4ae74e, 0x5d46eab0,\n+    0x88ba26a8, 0x7ab62b56, 0x694e4ba5, 0x9b42465b, 0xc75ba564, 0x3557a89a,\n+    0x26afc869, 0xd4a3c597, 0x015f098f, 0xf3530471, 0xe0ab6482, 0x12a7697c,\n+    0x74d4f382, 0x86d8fe7c, 0x95209e8f, 0x672c9371, 0xb2d05f69, 0x40dc5297,\n+    0x53243264, 0xa1283f9a, 0xfd31dca5, 0x0f3dd15b, 0x1cc5b1a8, 0xeec9bc56,\n+    0x3b35704e, 0xc9397db0, 0xdac11d43, 0x28cd10bd, 0x62f2db3d, 0x90fed6c3,\n+    0x8306b630, 0x710abbce, 0xa4f677d6, 0x56fa7a28, 0x45021adb, 0xb70e1725,\n+    0xeb17f41a, 0x191bf9e4, 0x0ae39917, 0xf8ef94e9, 0x2d1358f1, 0xdf1f550f,\n+    0xcce735fc, 0x3eeb3802, 0xb13145f8, 0x433d4806, 0x50c528f5, 0xa2c9250b,\n+    0x7735e913, 0x8539e4ed, 0x96c1841e, 0x64cd89e0, 0x38d46adf, 0xcad86721,\n+    0xd92007d2, 0x2b2c0a2c, 0xfed0c634, 0x0cdccbca, 0x1f24ab39, 0xed28a6c7,\n+    0xa7176d47, 0x551b60b9, 0x46e3004a, 0xb4ef0db4, 0x6113c1ac, 0x931fcc52,\n+    0x80e7aca1, 0x72eba15f, 0x2ef24260, 0xdcfe4f9e, 0xcf062f6d, 0x3d0a2293,\n+    0xe8f6ee8b, 0x1afae375, 0x09028386, 0xfb0e8e78, 0x9d7d1486, 0x6f711978,\n+    0x7c89798b, 0x8e857475, 0x5b79b86d, 0xa975b593, 0xba8dd560, 0x4881d89e,\n+    0x14983ba1, 0xe694365f, 0xf56c56ac, 0x07605b52, 0xd29c974a, 0x20909ab4,\n+    0x3368fa47, 0xc164f7b9, 0x8b5b3c39, 0x795731c7, 0x6aaf5134, 0x98a35cca,\n+    0x4d5f90d2, 0xbf539d2c, 0xacabfddf, 0x5ea7f021, 0x02be131e, 0xf0b21ee0,\n+    0xe34a7e13, 0x114673ed, 0xc4babff5, 0x36b6b20b, 0x254ed2f8, 0xd742df06,\n+    0xe9a9e704, 0x1ba5eafa, 0x085d8a09, 0xfa5187f7, 0x2fad4bef, 0xdda14611,\n+    0xce5926e2, 0x3c552b1c, 0x604cc823, 0x9240c5dd, 0x81b8a52e, 0x73b4a8d0,\n+    0xa64864c8, 0x54446936, 0x47bc09c5, 0xb5b0043b, 0xff8fcfbb, 0x0d83c245,\n+    0x1e7ba2b6, 0xec77af48, 0x398b6350, 0xcb876eae, 0xd87f0e5d, 0x2a7303a3,\n+    0x766ae09c, 0x8466ed62, 0x979e8d91, 0x6592806f, 0xb06e4c77, 0x42624189,\n+    0x519a217a, 0xa3962c84, 0xc5e5b67a, 0x37e9bb84, 0x2411db77, 0xd61dd689,\n+    0x03e11a91, 0xf1ed176f, 0xe215779c, 0x10197a62, 0x4c00995d, 0xbe0c94a3,\n+    0xadf4f450, 0x5ff8f9ae, 0x8a0435b6, 0x78083848, 0x6bf058bb, 0x99fc5545,\n+    0xd3c39ec5, 0x21cf933b, 0x3237f3c8, 0xc03bfe36, 0x15c7322e, 0xe7cb3fd0,\n+    0xf4335f23, 0x063f52dd, 0x5a26b1e2, 0xa82abc1c, 0xbbd2dcef, 0x49ded111,\n+    0x9c221d09, 0x6e2e10f7, 0x7dd67004, 0x8fda7dfa};\n+\n+constexpr const ptrdiff_t kPrefetchHorizon = 256;\n+\n+}  // namespace\n+\n+namespace crc32c {\n+\n+uint32_t ExtendPortable(uint32_t crc, const uint8_t* data, size_t size) {\n+  const uint8_t* p = data;\n+  const uint8_t* e = p + size;\n+  uint32_t l = crc ^ kCRC32Xor;\n+\n+// Process one byte at a time.\n+#define STEP1                              \\\n+  do {                                     \\\n+    int c = (l & 0xff) ^ *p++;             \\\n+    l = kByteExtensionTable[c] ^ (l >> 8); \\\n+  } while (0)\n+\n+// Process one of the 4 strides of 4-byte data.\n+#define STEP4(s)                                                               \\\n+  do {                                                                         \\\n+    crc##s = ReadUint32LE(p + s * 4) ^ kStrideExtensionTable3[crc##s & 0xff] ^ \\\n+             kStrideExtensionTable2[(crc##s >> 8) & 0xff] ^                    \\\n+             kStrideExtensionTable1[(crc##s >> 16) & 0xff] ^                   \\\n+             kStrideExtensionTable0[crc##s >> 24];                             \\\n+  } while (0)\n+\n+// Process a 16-byte swath of 4 strides, each of which has 4 bytes of data.\n+#define STEP16 \\\n+  do {         \\\n+    STEP4(0);  \\\n+    STEP4(1);  \\\n+    STEP4(2);  \\\n+    STEP4(3);  \\\n+    p += 16;   \\\n+  } while (0)\n+\n+// Process 4 bytes that were already loaded into a word.\n+#define STEP4W(w)                                   \\\n+  do {                                              \\\n+    w ^= l;                                         \\\n+    for (size_t i = 0; i < 4; ++i) {                \\\n+      w = (w >> 8) ^ kByteExtensionTable[w & 0xff]; \\\n+    }                                               \\\n+    l = w;                                          \\\n+  } while (0)\n+\n+  // Point x at first 4-byte aligned byte in the buffer. This might be past the\n+  // end of the buffer.\n+  const uint8_t* x = RoundUp<4>(p);\n+  if (x <= e) {\n+    // Process bytes p is 4-byte aligned.\n+    while (p != x) {\n+      STEP1;\n+    }\n+  }\n+\n+  if ((e - p) >= 16) {\n+    // Load a 16-byte swath into the stride partial results.\n+    uint32_t crc0 = ReadUint32LE(p + 0 * 4) ^ l;\n+    uint32_t crc1 = ReadUint32LE(p + 1 * 4);\n+    uint32_t crc2 = ReadUint32LE(p + 2 * 4);\n+    uint32_t crc3 = ReadUint32LE(p + 3 * 4);\n+    p += 16;\n+\n+    while ((e - p) > kPrefetchHorizon) {\n+      RequestPrefetch(p + kPrefetchHorizon);\n+\n+      // Process 64 bytes at a time.\n+      STEP16;\n+      STEP16;\n+      STEP16;\n+      STEP16;\n+    }\n+\n+    // Process one 16-byte swath at a time.\n+    while ((e - p) >= 16) {\n+      STEP16;\n+    }\n+\n+    // Advance one word at a time as far as possible.\n+    while ((e - p) >= 4) {\n+      STEP4(0);\n+      uint32_t tmp = crc0;\n+      crc0 = crc1;\n+      crc1 = crc2;\n+      crc2 = crc3;\n+      crc3 = tmp;\n+      p += 4;\n+    }\n+\n+    // Combine the 4 partial stride results.\n+    l = 0;\n+    STEP4W(crc0);\n+    STEP4W(crc1);\n+    STEP4W(crc2);\n+    STEP4W(crc3);\n+  }\n+\n+  // Process the last few bytes.\n+  while (p != e) {\n+    STEP1;\n+  }\n+#undef STEP4W\n+#undef STEP16\n+#undef STEP4\n+#undef STEP1\n+  return l ^ kCRC32Xor;\n+}\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "5098e2c373ff3fd66a06446c6afc1d7ba6e95a6e",
        "filename": "src/crc32c/src/crc32c_portable_unittest.cc",
        "status": "added",
        "additions": 20,
        "deletions": 0,
        "changes": 20,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_portable_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_portable_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_portable_unittest.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,20 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"gtest/gtest.h\"\n+\n+#include \"./crc32c_extend_unittests.h\"\n+#include \"./crc32c_internal.h\"\n+\n+namespace crc32c {\n+\n+struct PortableTestTraits {\n+  static uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count) {\n+    return ExtendPortable(crc, data, count);\n+  }\n+};\n+\n+INSTANTIATE_TYPED_TEST_SUITE_P(Portable, ExtendTest, PortableTestTraits);\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "aec7d54e84e571c4d7ae489d2177623204c549a7",
        "filename": "src/crc32c/src/crc32c_prefetch.h",
        "status": "added",
        "additions": 46,
        "deletions": 0,
        "changes": 46,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_prefetch.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_prefetch.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_prefetch.h?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,46 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_PREFETCH_H_\n+#define CRC32C_CRC32C_PREFETCH_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_MM_PREFETCH\n+\n+#if defined(_MSC_VER)\n+#include <intrin.h>\n+#else  // !defined(_MSC_VER)\n+#include <xmmintrin.h>\n+#endif  // defined(_MSC_VER)\n+\n+#endif  // HAVE_MM_PREFETCH\n+\n+namespace crc32c {\n+\n+// Ask the hardware to prefetch the data at the given address into the L1 cache.\n+inline void RequestPrefetch(const uint8_t* address) {\n+#if HAVE_BUILTIN_PREFETCH\n+  // Clang and GCC implement the __builtin_prefetch non-standard extension,\n+  // which maps to the best instruction on the target architecture.\n+  __builtin_prefetch(reinterpret_cast<const char*>(address), 0 /* Read only. */,\n+                     0 /* No temporal locality. */);\n+#elif HAVE_MM_PREFETCH\n+  // Visual Studio doesn't implement __builtin_prefetch, but exposes the\n+  // PREFETCHNTA instruction via the _mm_prefetch intrinsic.\n+  _mm_prefetch(reinterpret_cast<const char*>(address), _MM_HINT_NTA);\n+#else\n+  // No prefetch support. Silence compiler warnings.\n+  (void)address;\n+#endif  // HAVE_BUILTIN_PREFETCH\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // CRC32C_CRC32C_ROUND_UP_H_"
      },
      {
        "sha": "b34ed2d5fec67cd4e351c04a63aeb5c62f779357",
        "filename": "src/crc32c/src/crc32c_prefetch_unittest.cc",
        "status": "added",
        "additions": 9,
        "deletions": 0,
        "changes": 9,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_prefetch_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_prefetch_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_prefetch_unittest.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,9 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_prefetch.h\"\n+\n+// There is no easy way to test cache prefetching. We can only test that the\n+// crc32c_prefetch.h header compiles on its own, so it doesn't have any unstated\n+// dependencies."
      },
      {
        "sha": "3bd45fe3aa9e2e13cbe019823db1898ea4616a82",
        "filename": "src/crc32c/src/crc32c_read_le.h",
        "status": "added",
        "additions": 53,
        "deletions": 0,
        "changes": 53,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_read_le.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_read_le.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_read_le.h?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,53 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_READ_LE_H_\n+#define CRC32C_CRC32C_READ_LE_H_\n+\n+#include <cstdint>\n+#include <cstring>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+namespace crc32c {\n+\n+// Reads a little-endian 32-bit integer from a 32-bit-aligned buffer.\n+inline uint32_t ReadUint32LE(const uint8_t* buffer) {\n+#if BYTE_ORDER_BIG_ENDIAN\n+  return ((static_cast<uint32_t>(static_cast<uint8_t>(buffer[0]))) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[1])) << 8) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[2])) << 16) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[3])) << 24));\n+#else   // !BYTE_ORDER_BIG_ENDIAN\n+  uint32_t result;\n+  // This should be optimized to a single instruction.\n+  std::memcpy(&result, buffer, sizeof(result));\n+  return result;\n+#endif  // BYTE_ORDER_BIG_ENDIAN\n+}\n+\n+// Reads a little-endian 64-bit integer from a 64-bit-aligned buffer.\n+inline uint64_t ReadUint64LE(const uint8_t* buffer) {\n+#if BYTE_ORDER_BIG_ENDIAN\n+  return ((static_cast<uint32_t>(static_cast<uint8_t>(buffer[0]))) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[1])) << 8) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[2])) << 16) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[3])) << 24) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[4])) << 32) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[5])) << 40) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[6])) << 48) |\n+          (static_cast<uint32_t>(static_cast<uint8_t>(buffer[7])) << 56));\n+#else   // !BYTE_ORDER_BIG_ENDIAN\n+  uint64_t result;\n+  // This should be optimized to a single instruction.\n+  std::memcpy(&result, buffer, sizeof(result));\n+  return result;\n+#endif  // BYTE_ORDER_BIG_ENDIAN\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // CRC32C_CRC32C_READ_LE_H_"
      },
      {
        "sha": "2a30302adf5f8654055a3e6e4c80bd0f96fc44ea",
        "filename": "src/crc32c/src/crc32c_read_le_unittest.cc",
        "status": "added",
        "additions": 32,
        "deletions": 0,
        "changes": 32,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_read_le_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_read_le_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_read_le_unittest.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,32 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_read_le.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"gtest/gtest.h\"\n+\n+#include \"./crc32c_round_up.h\"\n+\n+namespace crc32c {\n+\n+TEST(Crc32CReadLETest, ReadUint32LE) {\n+  // little-endian 0x12345678\n+  alignas(4) uint8_t bytes[] = {0x78, 0x56, 0x34, 0x12};\n+\n+  ASSERT_EQ(RoundUp<4>(bytes), bytes) << \"Stack array is not aligned\";\n+  EXPECT_EQ(static_cast<uint32_t>(0x12345678), ReadUint32LE(bytes));\n+}\n+\n+TEST(Crc32CReadLETest, ReadUint64LE) {\n+  // little-endian 0x123456789ABCDEF0\n+  alignas(8) uint8_t bytes[] = {0xF0, 0xDE, 0xBC, 0x9A, 0x78, 0x56, 0x34, 0x12};\n+\n+  ASSERT_EQ(RoundUp<8>(bytes), bytes) << \"Stack array is not aligned\";\n+  EXPECT_EQ(static_cast<uint64_t>(0x123456789ABCDEF0), ReadUint64LE(bytes));\n+}\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "d3b922beb95dc783acf107953872ae3bc00087a0",
        "filename": "src/crc32c/src/crc32c_round_up.h",
        "status": "added",
        "additions": 34,
        "deletions": 0,
        "changes": 34,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_round_up.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_round_up.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_round_up.h?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,34 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_ROUND_UP_H_\n+#define CRC32C_CRC32C_ROUND_UP_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+namespace crc32c {\n+\n+// Returns the smallest number >= the given number that is evenly divided by N.\n+//\n+// N must be a power of two.\n+template <int N>\n+constexpr inline uintptr_t RoundUp(uintptr_t pointer) {\n+  static_assert((N & (N - 1)) == 0, \"N must be a power of two\");\n+  return (pointer + (N - 1)) & ~(N - 1);\n+}\n+\n+// Returns the smallest address >= the given address that is aligned to N bytes.\n+//\n+// N must be a power of two.\n+template <int N>\n+constexpr inline const uint8_t* RoundUp(const uint8_t* pointer) {\n+  static_assert((N & (N - 1)) == 0, \"N must be a power of two\");\n+  return reinterpret_cast<uint8_t*>(\n+      RoundUp<N>(reinterpret_cast<uintptr_t>(pointer)));\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // CRC32C_CRC32C_ROUND_UP_H_"
      },
      {
        "sha": "5ff657bb5c749d06ca119bd815d43b0f444857b2",
        "filename": "src/crc32c/src/crc32c_round_up_unittest.cc",
        "status": "added",
        "additions": 84,
        "deletions": 0,
        "changes": 84,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_round_up_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_round_up_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_round_up_unittest.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,84 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_round_up.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"gtest/gtest.h\"\n+\n+namespace crc32c {\n+\n+TEST(CRC32CRoundUpTest, RoundUpUintptr) {\n+  uintptr_t zero = 0;\n+\n+  ASSERT_EQ(zero, RoundUp<1>(zero));\n+  ASSERT_EQ(1U, RoundUp<1>(1U));\n+  ASSERT_EQ(2U, RoundUp<1>(2U));\n+  ASSERT_EQ(3U, RoundUp<1>(3U));\n+  ASSERT_EQ(~static_cast<uintptr_t>(0), RoundUp<1>(~static_cast<uintptr_t>(0)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(1), RoundUp<1>(~static_cast<uintptr_t>(1)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(2), RoundUp<1>(~static_cast<uintptr_t>(2)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<1>(~static_cast<uintptr_t>(3)));\n+\n+  ASSERT_EQ(zero, RoundUp<2>(zero));\n+  ASSERT_EQ(2U, RoundUp<2>(1U));\n+  ASSERT_EQ(2U, RoundUp<2>(2U));\n+  ASSERT_EQ(4U, RoundUp<2>(3U));\n+  ASSERT_EQ(4U, RoundUp<2>(4U));\n+  ASSERT_EQ(6U, RoundUp<2>(5U));\n+  ASSERT_EQ(6U, RoundUp<2>(6U));\n+  ASSERT_EQ(8U, RoundUp<2>(7U));\n+  ASSERT_EQ(8U, RoundUp<2>(8U));\n+  ASSERT_EQ(~static_cast<uintptr_t>(1), RoundUp<2>(~static_cast<uintptr_t>(1)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(1), RoundUp<2>(~static_cast<uintptr_t>(2)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<2>(~static_cast<uintptr_t>(3)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<2>(~static_cast<uintptr_t>(4)));\n+\n+  ASSERT_EQ(zero, RoundUp<4>(zero));\n+  ASSERT_EQ(4U, RoundUp<4>(1U));\n+  ASSERT_EQ(4U, RoundUp<4>(2U));\n+  ASSERT_EQ(4U, RoundUp<4>(3U));\n+  ASSERT_EQ(4U, RoundUp<4>(4U));\n+  ASSERT_EQ(8U, RoundUp<4>(5U));\n+  ASSERT_EQ(8U, RoundUp<4>(6U));\n+  ASSERT_EQ(8U, RoundUp<4>(7U));\n+  ASSERT_EQ(8U, RoundUp<4>(8U));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<4>(~static_cast<uintptr_t>(3)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<4>(~static_cast<uintptr_t>(4)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<4>(~static_cast<uintptr_t>(5)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(3), RoundUp<4>(~static_cast<uintptr_t>(6)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(7), RoundUp<4>(~static_cast<uintptr_t>(7)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(7), RoundUp<4>(~static_cast<uintptr_t>(8)));\n+  ASSERT_EQ(~static_cast<uintptr_t>(7), RoundUp<4>(~static_cast<uintptr_t>(9)));\n+}\n+\n+TEST(CRC32CRoundUpTest, RoundUpPointer) {\n+  uintptr_t zero = 0, three = 3, four = 4, seven = 7, eight = 8;\n+\n+  const uint8_t* zero_ptr = reinterpret_cast<const uint8_t*>(zero);\n+  const uint8_t* three_ptr = reinterpret_cast<const uint8_t*>(three);\n+  const uint8_t* four_ptr = reinterpret_cast<const uint8_t*>(four);\n+  const uint8_t* seven_ptr = reinterpret_cast<const uint8_t*>(seven);\n+  const uint8_t* eight_ptr = reinterpret_cast<uint8_t*>(eight);\n+\n+  ASSERT_EQ(zero_ptr, RoundUp<1>(zero_ptr));\n+  ASSERT_EQ(zero_ptr, RoundUp<4>(zero_ptr));\n+  ASSERT_EQ(zero_ptr, RoundUp<8>(zero_ptr));\n+\n+  ASSERT_EQ(three_ptr, RoundUp<1>(three_ptr));\n+  ASSERT_EQ(four_ptr, RoundUp<4>(three_ptr));\n+  ASSERT_EQ(eight_ptr, RoundUp<8>(three_ptr));\n+\n+  ASSERT_EQ(four_ptr, RoundUp<1>(four_ptr));\n+  ASSERT_EQ(four_ptr, RoundUp<4>(four_ptr));\n+  ASSERT_EQ(eight_ptr, RoundUp<8>(four_ptr));\n+\n+  ASSERT_EQ(seven_ptr, RoundUp<1>(seven_ptr));\n+  ASSERT_EQ(eight_ptr, RoundUp<4>(seven_ptr));\n+  ASSERT_EQ(eight_ptr, RoundUp<8>(four_ptr));\n+}\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "139520428e08dd3e1738791e6227dbfd67564d52",
        "filename": "src/crc32c/src/crc32c_sse42.cc",
        "status": "added",
        "additions": 258,
        "deletions": 0,
        "changes": 258,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_sse42.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_sse42.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_sse42.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,258 @@\n+// Copyright 2008 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"./crc32c_sse42.h\"\n+\n+// In a separate source file to allow this accelerated CRC32C function to be\n+// compiled with the appropriate compiler flags to enable SSE4.2 instructions.\n+\n+// This implementation is loosely based on Intel Pub 323405 from April 2011,\n+// \"Fast CRC Computation for iSCSI Polynomial Using CRC32 Instruction\".\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"./crc32c_internal.h\"\n+#include \"./crc32c_prefetch.h\"\n+#include \"./crc32c_read_le.h\"\n+#include \"./crc32c_round_up.h\"\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+#if defined(_MSC_VER)\n+#include <intrin.h>\n+#else  // !defined(_MSC_VER)\n+#include <nmmintrin.h>\n+#endif  // defined(_MSC_VER)\n+\n+namespace crc32c {\n+\n+namespace {\n+\n+constexpr const ptrdiff_t kGroups = 3;\n+constexpr const ptrdiff_t kBlock0Size = 16 * 1024 / kGroups / 64 * 64;\n+constexpr const ptrdiff_t kBlock1Size = 4 * 1024 / kGroups / 8 * 8;\n+constexpr const ptrdiff_t kBlock2Size = 1024 / kGroups / 8 * 8;\n+\n+const uint32_t kBlock0SkipTable[8][16] = {\n+    {0x00000000, 0xff770459, 0xfb027e43, 0x04757a1a, 0xf3e88a77, 0x0c9f8e2e,\n+     0x08eaf434, 0xf79df06d, 0xe23d621f, 0x1d4a6646, 0x193f1c5c, 0xe6481805,\n+     0x11d5e868, 0xeea2ec31, 0xead7962b, 0x15a09272},\n+    {0x00000000, 0xc196b2cf, 0x86c1136f, 0x4757a1a0, 0x086e502f, 0xc9f8e2e0,\n+     0x8eaf4340, 0x4f39f18f, 0x10dca05e, 0xd14a1291, 0x961db331, 0x578b01fe,\n+     0x18b2f071, 0xd92442be, 0x9e73e31e, 0x5fe551d1},\n+    {0x00000000, 0x21b940bc, 0x43728178, 0x62cbc1c4, 0x86e502f0, 0xa75c424c,\n+     0xc5978388, 0xe42ec334, 0x08267311, 0x299f33ad, 0x4b54f269, 0x6aedb2d5,\n+     0x8ec371e1, 0xaf7a315d, 0xcdb1f099, 0xec08b025},\n+    {0x00000000, 0x104ce622, 0x2099cc44, 0x30d52a66, 0x41339888, 0x517f7eaa,\n+     0x61aa54cc, 0x71e6b2ee, 0x82673110, 0x922bd732, 0xa2fefd54, 0xb2b21b76,\n+     0xc354a998, 0xd3184fba, 0xe3cd65dc, 0xf38183fe},\n+    {0x00000000, 0x012214d1, 0x024429a2, 0x03663d73, 0x04885344, 0x05aa4795,\n+     0x06cc7ae6, 0x07ee6e37, 0x0910a688, 0x0832b259, 0x0b548f2a, 0x0a769bfb,\n+     0x0d98f5cc, 0x0cbae11d, 0x0fdcdc6e, 0x0efec8bf},\n+    {0x00000000, 0x12214d10, 0x24429a20, 0x3663d730, 0x48853440, 0x5aa47950,\n+     0x6cc7ae60, 0x7ee6e370, 0x910a6880, 0x832b2590, 0xb548f2a0, 0xa769bfb0,\n+     0xd98f5cc0, 0xcbae11d0, 0xfdcdc6e0, 0xefec8bf0},\n+    {0x00000000, 0x27f8a7f1, 0x4ff14fe2, 0x6809e813, 0x9fe29fc4, 0xb81a3835,\n+     0xd013d026, 0xf7eb77d7, 0x3a294979, 0x1dd1ee88, 0x75d8069b, 0x5220a16a,\n+     0xa5cbd6bd, 0x8233714c, 0xea3a995f, 0xcdc23eae},\n+    {0x00000000, 0x745292f2, 0xe8a525e4, 0x9cf7b716, 0xd4a63d39, 0xa0f4afcb,\n+     0x3c0318dd, 0x48518a2f, 0xaca00c83, 0xd8f29e71, 0x44052967, 0x3057bb95,\n+     0x780631ba, 0x0c54a348, 0x90a3145e, 0xe4f186ac},\n+};\n+const uint32_t kBlock1SkipTable[8][16] = {\n+    {0x00000000, 0x79113270, 0xf22264e0, 0x8b335690, 0xe1a8bf31, 0x98b98d41,\n+     0x138adbd1, 0x6a9be9a1, 0xc6bd0893, 0xbfac3ae3, 0x349f6c73, 0x4d8e5e03,\n+     0x2715b7a2, 0x5e0485d2, 0xd537d342, 0xac26e132},\n+    {0x00000000, 0x889667d7, 0x14c0b95f, 0x9c56de88, 0x298172be, 0xa1171569,\n+     0x3d41cbe1, 0xb5d7ac36, 0x5302e57c, 0xdb9482ab, 0x47c25c23, 0xcf543bf4,\n+     0x7a8397c2, 0xf215f015, 0x6e432e9d, 0xe6d5494a},\n+    {0x00000000, 0xa605caf8, 0x49e7e301, 0xefe229f9, 0x93cfc602, 0x35ca0cfa,\n+     0xda282503, 0x7c2deffb, 0x2273faf5, 0x8476300d, 0x6b9419f4, 0xcd91d30c,\n+     0xb1bc3cf7, 0x17b9f60f, 0xf85bdff6, 0x5e5e150e},\n+    {0x00000000, 0x44e7f5ea, 0x89cfebd4, 0xcd281e3e, 0x1673a159, 0x529454b3,\n+     0x9fbc4a8d, 0xdb5bbf67, 0x2ce742b2, 0x6800b758, 0xa528a966, 0xe1cf5c8c,\n+     0x3a94e3eb, 0x7e731601, 0xb35b083f, 0xf7bcfdd5},\n+    {0x00000000, 0x59ce8564, 0xb39d0ac8, 0xea538fac, 0x62d66361, 0x3b18e605,\n+     0xd14b69a9, 0x8885eccd, 0xc5acc6c2, 0x9c6243a6, 0x7631cc0a, 0x2fff496e,\n+     0xa77aa5a3, 0xfeb420c7, 0x14e7af6b, 0x4d292a0f},\n+    {0x00000000, 0x8eb5fb75, 0x1887801b, 0x96327b6e, 0x310f0036, 0xbfbafb43,\n+     0x2988802d, 0xa73d7b58, 0x621e006c, 0xecabfb19, 0x7a998077, 0xf42c7b02,\n+     0x5311005a, 0xdda4fb2f, 0x4b968041, 0xc5237b34},\n+    {0x00000000, 0xc43c00d8, 0x8d947741, 0x49a87799, 0x1ec49873, 0xdaf898ab,\n+     0x9350ef32, 0x576cefea, 0x3d8930e6, 0xf9b5303e, 0xb01d47a7, 0x7421477f,\n+     0x234da895, 0xe771a84d, 0xaed9dfd4, 0x6ae5df0c},\n+    {0x00000000, 0x7b1261cc, 0xf624c398, 0x8d36a254, 0xe9a5f1c1, 0x92b7900d,\n+     0x1f813259, 0x64935395, 0xd6a79573, 0xadb5f4bf, 0x208356eb, 0x5b913727,\n+     0x3f0264b2, 0x4410057e, 0xc926a72a, 0xb234c6e6},\n+};\n+const uint32_t kBlock2SkipTable[8][16] = {\n+    {0x00000000, 0x8f158014, 0x1bc776d9, 0x94d2f6cd, 0x378eedb2, 0xb89b6da6,\n+     0x2c499b6b, 0xa35c1b7f, 0x6f1ddb64, 0xe0085b70, 0x74daadbd, 0xfbcf2da9,\n+     0x589336d6, 0xd786b6c2, 0x4354400f, 0xcc41c01b},\n+    {0x00000000, 0xde3bb6c8, 0xb99b1b61, 0x67a0ada9, 0x76da4033, 0xa8e1f6fb,\n+     0xcf415b52, 0x117aed9a, 0xedb48066, 0x338f36ae, 0x542f9b07, 0x8a142dcf,\n+     0x9b6ec055, 0x4555769d, 0x22f5db34, 0xfcce6dfc},\n+    {0x00000000, 0xde85763d, 0xb8e69a8b, 0x6663ecb6, 0x742143e7, 0xaaa435da,\n+     0xccc7d96c, 0x1242af51, 0xe84287ce, 0x36c7f1f3, 0x50a41d45, 0x8e216b78,\n+     0x9c63c429, 0x42e6b214, 0x24855ea2, 0xfa00289f},\n+    {0x00000000, 0xd569796d, 0xaf3e842b, 0x7a57fd46, 0x5b917ea7, 0x8ef807ca,\n+     0xf4affa8c, 0x21c683e1, 0xb722fd4e, 0x624b8423, 0x181c7965, 0xcd750008,\n+     0xecb383e9, 0x39dafa84, 0x438d07c2, 0x96e47eaf},\n+    {0x00000000, 0x6ba98c6d, 0xd75318da, 0xbcfa94b7, 0xab4a4745, 0xc0e3cb28,\n+     0x7c195f9f, 0x17b0d3f2, 0x5378f87b, 0x38d17416, 0x842be0a1, 0xef826ccc,\n+     0xf832bf3e, 0x939b3353, 0x2f61a7e4, 0x44c82b89},\n+    {0x00000000, 0xa6f1f0f6, 0x480f971d, 0xeefe67eb, 0x901f2e3a, 0x36eedecc,\n+     0xd810b927, 0x7ee149d1, 0x25d22a85, 0x8323da73, 0x6dddbd98, 0xcb2c4d6e,\n+     0xb5cd04bf, 0x133cf449, 0xfdc293a2, 0x5b336354},\n+    {0x00000000, 0x4ba4550a, 0x9748aa14, 0xdcecff1e, 0x2b7d22d9, 0x60d977d3,\n+     0xbc3588cd, 0xf791ddc7, 0x56fa45b2, 0x1d5e10b8, 0xc1b2efa6, 0x8a16baac,\n+     0x7d87676b, 0x36233261, 0xeacfcd7f, 0xa16b9875},\n+    {0x00000000, 0xadf48b64, 0x5e056039, 0xf3f1eb5d, 0xbc0ac072, 0x11fe4b16,\n+     0xe20fa04b, 0x4ffb2b2f, 0x7df9f615, 0xd00d7d71, 0x23fc962c, 0x8e081d48,\n+     0xc1f33667, 0x6c07bd03, 0x9ff6565e, 0x3202dd3a},\n+};\n+\n+constexpr const ptrdiff_t kPrefetchHorizon = 256;\n+\n+}  // namespace\n+\n+uint32_t ExtendSse42(uint32_t crc, const uint8_t* data, size_t size) {\n+  const uint8_t* p = data;\n+  const uint8_t* e = data + size;\n+  uint32_t l = crc ^ kCRC32Xor;\n+\n+#define STEP1                  \\\n+  do {                         \\\n+    l = _mm_crc32_u8(l, *p++); \\\n+  } while (0)\n+\n+#define STEP4(crc)                             \\\n+  do {                                         \\\n+    crc = _mm_crc32_u32(crc, ReadUint32LE(p)); \\\n+    p += 4;                                    \\\n+  } while (0)\n+\n+#define STEP8(crc, data)                          \\\n+  do {                                            \\\n+    crc = _mm_crc32_u64(crc, ReadUint64LE(data)); \\\n+    data += 8;                                    \\\n+  } while (0)\n+\n+#define STEP8BY3(crc0, crc1, crc2, p0, p1, p2) \\\n+  do {                                         \\\n+    STEP8(crc0, p0);                           \\\n+    STEP8(crc1, p1);                           \\\n+    STEP8(crc2, p2);                           \\\n+  } while (0)\n+\n+#define STEP8X3(crc0, crc1, crc2, bs)                     \\\n+  do {                                                    \\\n+    crc0 = _mm_crc32_u64(crc0, ReadUint64LE(p));          \\\n+    crc1 = _mm_crc32_u64(crc1, ReadUint64LE(p + bs));     \\\n+    crc2 = _mm_crc32_u64(crc2, ReadUint64LE(p + 2 * bs)); \\\n+    p += 8;                                               \\\n+  } while (0)\n+\n+#define SKIP_BLOCK(crc, tab)                                      \\\n+  do {                                                            \\\n+    crc = tab[0][crc & 0xf] ^ tab[1][(crc >> 4) & 0xf] ^          \\\n+          tab[2][(crc >> 8) & 0xf] ^ tab[3][(crc >> 12) & 0xf] ^  \\\n+          tab[4][(crc >> 16) & 0xf] ^ tab[5][(crc >> 20) & 0xf] ^ \\\n+          tab[6][(crc >> 24) & 0xf] ^ tab[7][(crc >> 28) & 0xf];  \\\n+  } while (0)\n+\n+  // Point x at first 8-byte aligned byte in the buffer. This might be past the\n+  // end of the buffer.\n+  const uint8_t* x = RoundUp<8>(p);\n+  if (x <= e) {\n+    // Process bytes p is 8-byte aligned.\n+    while (p != x) {\n+      STEP1;\n+    }\n+  }\n+\n+  // Proccess the data in predetermined block sizes with tables for quickly\n+  // combining the checksum. Experimentally it's better to use larger block\n+  // sizes where possible so use a hierarchy of decreasing block sizes.\n+  uint64_t l64 = l;\n+  while ((e - p) >= kGroups * kBlock0Size) {\n+    uint64_t l641 = 0;\n+    uint64_t l642 = 0;\n+    for (int i = 0; i < kBlock0Size; i += 8 * 8) {\n+      // Prefetch ahead to hide latency.\n+      RequestPrefetch(p + kPrefetchHorizon);\n+      RequestPrefetch(p + kBlock0Size + kPrefetchHorizon);\n+      RequestPrefetch(p + 2 * kBlock0Size + kPrefetchHorizon);\n+\n+      // Process 64 bytes at a time.\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+      STEP8X3(l64, l641, l642, kBlock0Size);\n+    }\n+\n+    // Combine results.\n+    SKIP_BLOCK(l64, kBlock0SkipTable);\n+    l64 ^= l641;\n+    SKIP_BLOCK(l64, kBlock0SkipTable);\n+    l64 ^= l642;\n+    p += (kGroups - 1) * kBlock0Size;\n+  }\n+  while ((e - p) >= kGroups * kBlock1Size) {\n+    uint64_t l641 = 0;\n+    uint64_t l642 = 0;\n+    for (int i = 0; i < kBlock1Size; i += 8) {\n+      STEP8X3(l64, l641, l642, kBlock1Size);\n+    }\n+    SKIP_BLOCK(l64, kBlock1SkipTable);\n+    l64 ^= l641;\n+    SKIP_BLOCK(l64, kBlock1SkipTable);\n+    l64 ^= l642;\n+    p += (kGroups - 1) * kBlock1Size;\n+  }\n+  while ((e - p) >= kGroups * kBlock2Size) {\n+    uint64_t l641 = 0;\n+    uint64_t l642 = 0;\n+    for (int i = 0; i < kBlock2Size; i += 8) {\n+      STEP8X3(l64, l641, l642, kBlock2Size);\n+    }\n+    SKIP_BLOCK(l64, kBlock2SkipTable);\n+    l64 ^= l641;\n+    SKIP_BLOCK(l64, kBlock2SkipTable);\n+    l64 ^= l642;\n+    p += (kGroups - 1) * kBlock2Size;\n+  }\n+\n+  // Process bytes 16 at a time\n+  while ((e - p) >= 16) {\n+    STEP8(l64, p);\n+    STEP8(l64, p);\n+  }\n+\n+  l = static_cast<uint32_t>(l64);\n+  // Process the last few bytes.\n+  while (p != e) {\n+    STEP1;\n+  }\n+#undef SKIP_BLOCK\n+#undef STEP8X3\n+#undef STEP8BY3\n+#undef STEP8\n+#undef STEP4\n+#undef STEP1\n+\n+  return l ^ kCRC32Xor;\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))"
      },
      {
        "sha": "95da9266325310e7866ff1910f862a15a110fd4a",
        "filename": "src/crc32c/src/crc32c_sse42.h",
        "status": "added",
        "additions": 33,
        "deletions": 0,
        "changes": 33,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_sse42.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_sse42.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_sse42.h?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,33 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_SSE42_H_\n+#define CRC32C_CRC32C_SSE42_H_\n+\n+// X86-specific code.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+// The hardware-accelerated implementation is only enabled for 64-bit builds,\n+// because a straightforward 32-bit implementation actually runs slower than the\n+// portable version. Most X86 machines are 64-bit nowadays, so it doesn't make\n+// much sense to spend time building an optimized hardware-accelerated\n+// implementation.\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+namespace crc32c {\n+\n+// SSE4.2-accelerated implementation in crc32c_sse42.cc\n+uint32_t ExtendSse42(uint32_t crc, const uint8_t* data, size_t count);\n+\n+}  // namespace crc32c\n+\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+#endif  // CRC32C_CRC32C_SSE42_H_"
      },
      {
        "sha": "e7528912a6dbf1f2f5e3209df795d46535730c2e",
        "filename": "src/crc32c/src/crc32c_sse42_check.h",
        "status": "added",
        "additions": 50,
        "deletions": 0,
        "changes": 50,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_sse42_check.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_sse42_check.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_sse42_check.h?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,50 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#ifndef CRC32C_CRC32C_SSE42_CHECK_H_\n+#define CRC32C_CRC32C_SSE42_CHECK_H_\n+\n+// X86-specific code checking the availability of SSE4.2 instructions.\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+// If the compiler supports SSE4.2, it definitely supports X86.\n+\n+#if defined(_MSC_VER)\n+#include <intrin.h>\n+\n+namespace crc32c {\n+\n+inline bool CanUseSse42() {\n+  int cpu_info[4];\n+  __cpuid(cpu_info, 1);\n+  return (cpu_info[2] & (1 << 20)) != 0;\n+}\n+\n+}  // namespace crc32c\n+\n+#else  // !defined(_MSC_VER)\n+#include <cpuid.h>\n+\n+namespace crc32c {\n+\n+inline bool CanUseSse42() {\n+  unsigned int eax, ebx, ecx, edx;\n+  return __get_cpuid(1, &eax, &ebx, &ecx, &edx) && ((ecx & (1 << 20)) != 0);\n+}\n+\n+}  // namespace crc32c\n+\n+#endif  // defined(_MSC_VER)\n+\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+#endif  // CRC32C_CRC32C_SSE42_CHECK_H_"
      },
      {
        "sha": "c73ad8ddd162383f217474489deb699738b856ae",
        "filename": "src/crc32c/src/crc32c_sse42_unittest.cc",
        "status": "added",
        "additions": 24,
        "deletions": 0,
        "changes": 24,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_sse42_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_sse42_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_sse42_unittest.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,24 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"gtest/gtest.h\"\n+\n+#include \"./crc32c_extend_unittests.h\"\n+#include \"./crc32c_sse42.h\"\n+\n+namespace crc32c {\n+\n+#if HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+struct Sse42TestTraits {\n+  static uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count) {\n+    return ExtendSse42(crc, data, count);\n+  }\n+};\n+\n+INSTANTIATE_TYPED_TEST_SUITE_P(Sse42, ExtendTest, Sse42TestTraits);\n+\n+#endif  // HAVE_SSE42 && (defined(_M_X64) || defined(__x86_64__))\n+\n+}  // namespace crc32c"
      },
      {
        "sha": "275ee380c6a81f1275ac1495486c6727236129fc",
        "filename": "src/crc32c/src/crc32c_test_main.cc",
        "status": "added",
        "additions": 22,
        "deletions": 0,
        "changes": 22,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_test_main.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_test_main.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_test_main.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,22 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file.\n+\n+#ifdef CRC32C_HAVE_CONFIG_H\n+#include \"crc32c/crc32c_config.h\"\n+#endif\n+\n+#include \"gtest/gtest.h\"\n+\n+#if CRC32C_TESTS_BUILT_WITH_GLOG\n+#include \"glog/logging.h\"\n+#endif  // CRC32C_TESTS_BUILT_WITH_GLOG\n+\n+int main(int argc, char** argv) {\n+#if CRC32C_TESTS_BUILT_WITH_GLOG\n+  google::InitGoogleLogging(argv[0]);\n+  google::InstallFailureSignalHandler();\n+#endif  // CRC32C_TESTS_BUILT_WITH_GLOG\n+  testing::InitGoogleTest(&argc, argv);\n+  return RUN_ALL_TESTS();\n+}"
      },
      {
        "sha": "d6c6af680c655847d217afd9ac012610d977088c",
        "filename": "src/crc32c/src/crc32c_unittest.cc",
        "status": "added",
        "additions": 129,
        "deletions": 0,
        "changes": 129,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_unittest.cc",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3acaa13b157509e81f0eba6c1e16938816439e7b/src/crc32c/src/crc32c_unittest.cc",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/crc32c/src/crc32c_unittest.cc?ref=3acaa13b157509e81f0eba6c1e16938816439e7b",
        "patch": "@@ -0,0 +1,129 @@\n+// Copyright 2017 The CRC32C Authors. All rights reserved.\n+// Use of this source code is governed by a BSD-style license that can be\n+// found in the LICENSE file. See the AUTHORS file for names of contributors.\n+\n+#include \"crc32c/crc32c.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <cstring>\n+\n+#include \"gtest/gtest.h\"\n+\n+#include \"./crc32c_extend_unittests.h\"\n+\n+TEST(Crc32CTest, Crc32c) {\n+  // From rfc3720 section B.4.\n+  uint8_t buf[32];\n+\n+  std::memset(buf, 0, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x8a9136aa),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  std::memset(buf, 0xff, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x62a8ab43),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x46dd794e),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(31 - i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x113fdb5c),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  uint8_t data[48] = {\n+      0x01, 0xc0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00,\n+      0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x18, 0x28, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+  };\n+  EXPECT_EQ(static_cast<uint32_t>(0xd9963a56),\n+            crc32c::Crc32c(data, sizeof(data)));\n+}\n+\n+namespace crc32c {\n+\n+struct ApiTestTraits {\n+  static uint32_t Extend(uint32_t crc, const uint8_t* data, size_t count) {\n+    return ::crc32c::Extend(crc, data, count);\n+  }\n+};\n+\n+INSTANTIATE_TYPED_TEST_SUITE_P(Api, ExtendTest, ApiTestTraits);\n+\n+}  // namespace crc32c\n+\n+TEST(CRC32CTest, Crc32cCharPointer) {\n+  char buf[32];\n+\n+  std::memset(buf, 0, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x8a9136aa),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  std::memset(buf, 0xff, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x62a8ab43),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<char>(i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x46dd794e),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<char>(31 - i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x113fdb5c),\n+            crc32c::Crc32c(buf, sizeof(buf)));\n+}\n+\n+TEST(CRC32CTest, Crc32cStdString) {\n+  std::string buf;\n+  buf.resize(32);\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<char>(0x00);\n+  EXPECT_EQ(static_cast<uint32_t>(0x8a9136aa), crc32c::Crc32c(buf));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = '\\xff';\n+  EXPECT_EQ(static_cast<uint32_t>(0x62a8ab43), crc32c::Crc32c(buf));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<char>(i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x46dd794e), crc32c::Crc32c(buf));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<char>(31 - i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x113fdb5c), crc32c::Crc32c(buf));\n+}\n+\n+#if __cplusplus > 201402L\n+#if __has_include(<string_view>)\n+\n+TEST(CRC32CTest, Crc32cStdStringView) {\n+  uint8_t buf[32];\n+  std::string_view view(reinterpret_cast<const char*>(buf), sizeof(buf));\n+\n+  std::memset(buf, 0, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x8a9136aa), crc32c::Crc32c(view));\n+\n+  std::memset(buf, 0xff, sizeof(buf));\n+  EXPECT_EQ(static_cast<uint32_t>(0x62a8ab43), crc32c::Crc32c(view));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x46dd794e), crc32c::Crc32c(view));\n+\n+  for (size_t i = 0; i < 32; ++i)\n+    buf[i] = static_cast<uint8_t>(31 - i);\n+  EXPECT_EQ(static_cast<uint32_t>(0x113fdb5c), crc32c::Crc32c(view));\n+}\n+\n+#endif  // __has_include(<string_view>)\n+#endif  // __cplusplus > 201402L\n+\n+#define TESTED_EXTEND Extend\n+#include \"./crc32c_extend_unittests.h\"\n+#undef TESTED_EXTEND"
      }
    ]
  },
  {
    "sha": "24d02a9ac00a82d172b171f73554a882df264c80",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzoyNGQwMmE5YWMwMGE4MmQxNzJiMTcxZjczNTU0YTg4MmRmMjY0Yzgw",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2019-11-06T21:26:28Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T16:01:48Z"
      },
      "message": "build: Update build system for new leveldb\n\nUpstream leveldb switched build systems, which means we need to define\na few different values.",
      "tree": {
        "sha": "c7107e2ab734fda8c150f7783a7614de819dfa02",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/c7107e2ab734fda8c150f7783a7614de819dfa02"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/24d02a9ac00a82d172b171f73554a882df264c80",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/24d02a9ac00a82d172b171f73554a882df264c80",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/24d02a9ac00a82d172b171f73554a882df264c80",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/24d02a9ac00a82d172b171f73554a882df264c80/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "3acaa13b157509e81f0eba6c1e16938816439e7b",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3acaa13b157509e81f0eba6c1e16938816439e7b",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/3acaa13b157509e81f0eba6c1e16938816439e7b"
      }
    ],
    "stats": {
      "total": 96,
      "additions": 44,
      "deletions": 52
    },
    "files": [
      {
        "sha": "6fe5abfa06ef74417331688df6f9620492f9492b",
        "filename": "configure.ac",
        "status": "modified",
        "additions": 26,
        "deletions": 29,
        "changes": 55,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/24d02a9ac00a82d172b171f73554a882df264c80/configure.ac",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/24d02a9ac00a82d172b171f73554a882df264c80/configure.ac",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/configure.ac?ref=24d02a9ac00a82d172b171f73554a882df264c80",
        "patch": "@@ -517,7 +517,6 @@ case $host in\n      fi\n \n      CPPFLAGS=\"$CPPFLAGS -D_MT -DWIN32 -D_WINDOWS -DBOOST_THREAD_USE_LIB -D_WIN32_WINNT=0x0601\"\n-     LEVELDB_TARGET_FLAGS=\"-DOS_WINDOWS\"\n      if test \"x$CXXFLAGS_overridden\" = \"xno\"; then\n        CXXFLAGS=\"$CXXFLAGS -w\"\n      fi\n@@ -533,7 +532,6 @@ case $host in\n      ;;\n   *darwin*)\n      TARGET_OS=darwin\n-     LEVELDB_TARGET_FLAGS=\"-DOS_MACOSX\"\n      if  test x$cross_compiling != xyes; then\n        BUILD_OS=darwin\n        AC_PATH_PROGS([RSVG_CONVERT], [rsvg-convert rsvg],rsvg-convert)\n@@ -585,35 +583,9 @@ case $host in\n    *android*)\n      dnl make sure android stays above linux for hosts like *linux-android*\n      TARGET_OS=android\n-     LEVELDB_TARGET_FLAGS=\"-DOS_ANDROID\"\n      ;;\n    *linux*)\n      TARGET_OS=linux\n-     LEVELDB_TARGET_FLAGS=\"-DOS_LINUX\"\n-     ;;\n-   *kfreebsd*)\n-     LEVELDB_TARGET_FLAGS=\"-DOS_KFREEBSD\"\n-     ;;\n-   *freebsd*)\n-     LEVELDB_TARGET_FLAGS=\"-DOS_FREEBSD\"\n-     ;;\n-   *openbsd*)\n-     LEVELDB_TARGET_FLAGS=\"-DOS_OPENBSD\"\n-     ;;\n-   *netbsd*)\n-     LEVELDB_TARGET_FLAGS=\"-DOS_NETBSD\"\n-     ;;\n-   *dragonfly*)\n-     LEVELDB_TARGET_FLAGS=\"-DOS_DRAGONFLYBSD\"\n-     ;;\n-   *solaris*)\n-     LEVELDB_TARGET_FLAGS=\"-DOS_SOLARIS\"\n-     ;;\n-   *hpux*)\n-     LEVELDB_TARGET_FLAGS=\"-DOS_HPUX\"\n-     ;;\n-   *)\n-     AC_MSG_ERROR(Cannot build leveldb for $host. Please file a bug report.)\n      ;;\n esac\n \n@@ -962,6 +934,28 @@ AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[#include <stdint.h>\n  [ AC_MSG_RESULT(no)]\n )\n \n+dnl LevelDB platform checks\n+AC_MSG_CHECKING(for fdatasync)\n+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[#include <unistd.h>]],\n+ [[ fdatasync(0); ]])],\n+ [ AC_MSG_RESULT(yes); HAVE_FDATASYNC=1 ],\n+ [ AC_MSG_RESULT(no); HAVE_FDATASYNC=0 ]\n+)\n+\n+AC_MSG_CHECKING(for F_FULLFSYNC)\n+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[#include <fcntl.h>]],\n+ [[ fcntl(0, F_FULLFSYNC, 0); ]])],\n+ [ AC_MSG_RESULT(yes); HAVE_FULLFSYNC=1 ],\n+ [ AC_MSG_RESULT(no); HAVE_FULLFSYNC=0 ]\n+)\n+\n+AC_MSG_CHECKING(for O_CLOEXEC)\n+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[#include <fcntl.h>]],\n+ [[ open(\"\", O_CLOEXEC); ]])],\n+ [ AC_MSG_RESULT(yes); HAVE_O_CLOEXEC=1 ],\n+ [ AC_MSG_RESULT(no); HAVE_O_CLOEXEC=0 ]\n+)\n+\n dnl Check for reduced exports\n if test x$use_reduce_exports = xyes; then\n   AX_CHECK_COMPILE_FLAG([-fvisibility=hidden],[RE_CXXFLAGS=\"-fvisibility=hidden\"],\n@@ -1522,6 +1516,7 @@ AM_CONDITIONAL([ENABLE_SSE41],[test x$enable_sse41 = xyes])\n AM_CONDITIONAL([ENABLE_AVX2],[test x$enable_avx2 = xyes])\n AM_CONDITIONAL([ENABLE_SHANI],[test x$enable_shani = xyes])\n AM_CONDITIONAL([USE_ASM],[test x$use_asm = xyes])\n+AM_CONDITIONAL([WORDS_BIGENDIAN],[test x$ac_cv_c_bigendian = xyes])\n \n AC_DEFINE(CLIENT_VERSION_MAJOR, _CLIENT_VERSION_MAJOR, [Major version])\n AC_DEFINE(CLIENT_VERSION_MINOR, _CLIENT_VERSION_MINOR, [Minor version])\n@@ -1573,13 +1568,15 @@ AC_SUBST(USE_UPNP)\n AC_SUBST(USE_QRCODE)\n AC_SUBST(BOOST_LIBS)\n AC_SUBST(TESTDEFS)\n-AC_SUBST(LEVELDB_TARGET_FLAGS)\n AC_SUBST(MINIUPNPC_CPPFLAGS)\n AC_SUBST(MINIUPNPC_LIBS)\n AC_SUBST(EVENT_LIBS)\n AC_SUBST(EVENT_PTHREADS_LIBS)\n AC_SUBST(ZMQ_LIBS)\n AC_SUBST(QR_LIBS)\n+AC_SUBST(HAVE_FDATASYNC)\n+AC_SUBST(HAVE_FULLFSYNC)\n+AC_SUBST(HAVE_O_CLOEXEC)\n AC_CONFIG_FILES([Makefile src/Makefile doc/man/Makefile share/setup.nsi share/qt/Info.plist test/config.ini])\n AC_CONFIG_FILES([contrib/devtools/split-debug.sh],[chmod +x contrib/devtools/split-debug.sh])\n AM_COND_IF([HAVE_DOXYGEN], [AC_CONFIG_FILES([doc/Doxyfile])])"
      },
      {
        "sha": "72bcb00e85854d188aa6e25867478dd7c1e05a32",
        "filename": "src/Makefile.leveldb.include",
        "status": "modified",
        "additions": 18,
        "deletions": 23,
        "changes": 41,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/24d02a9ac00a82d172b171f73554a882df264c80/src/Makefile.leveldb.include",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/24d02a9ac00a82d172b171f73554a882df264c80/src/Makefile.leveldb.include",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/Makefile.leveldb.include?ref=24d02a9ac00a82d172b171f73554a882df264c80",
        "patch": "@@ -4,27 +4,32 @@\n \n LIBLEVELDB_INT = leveldb/libleveldb.a\n LIBMEMENV_INT  = leveldb/libmemenv.a\n-LIBLEVELDB_SSE42_INT  = leveldb/libleveldb_sse42.a\n \n EXTRA_LIBRARIES += $(LIBLEVELDB_INT)\n EXTRA_LIBRARIES += $(LIBMEMENV_INT)\n-EXTRA_LIBRARIES += $(LIBLEVELDB_SSE42_INT)\n \n LIBLEVELDB += $(LIBLEVELDB_INT)\n LIBMEMENV += $(LIBMEMENV_INT)\n-LIBLEVELDB_SSE42 = $(LIBLEVELDB_SSE42_INT)\n \n LEVELDB_CPPFLAGS += -I$(srcdir)/leveldb/include\n LEVELDB_CPPFLAGS += -I$(srcdir)/leveldb/helpers/memenv\n \n LEVELDB_CPPFLAGS_INT =\n LEVELDB_CPPFLAGS_INT += -I$(srcdir)/leveldb\n-LEVELDB_CPPFLAGS_INT += $(LEVELDB_TARGET_FLAGS)\n-LEVELDB_CPPFLAGS_INT += -DLEVELDB_ATOMIC_PRESENT\n LEVELDB_CPPFLAGS_INT += -D__STDC_LIMIT_MACROS\n+LEVELDB_CPPFLAGS_INT += -DHAVE_SNAPPY=0 -DHAVE_CRC32C=0\n+LEVELDB_CPPFLAGS_INT += -DHAVE_FDATASYNC=@HAVE_FDATASYNC@\n+LEVELDB_CPPFLAGS_INT += -DHAVE_FULLFSYNC=@HAVE_FULLFSYNC@\n+LEVELDB_CPPFLAGS_INT += -DHAVE_O_CLOEXEC=@HAVE_O_CLOEXEC@\n+\n+if WORDS_BIGENDIAN\n+LEVELDB_CPPFLAGS_INT += -DLEVELDB_IS_BIG_ENDIAN=1\n+else\n+LEVELDB_CPPFLAGS_INT += -DLEVELDB_IS_BIG_ENDIAN=0\n+endif\n \n if TARGET_WINDOWS\n-LEVELDB_CPPFLAGS_INT += -DLEVELDB_PLATFORM_WINDOWS -D__USE_MINGW_ANSI_STDIO=1\n+LEVELDB_CPPFLAGS_INT += -DLEVELDB_PLATFORM_WINDOWS -D_UNICODE -DUNICODE -D__USE_MINGW_ANSI_STDIO=1\n else\n LEVELDB_CPPFLAGS_INT += -DLEVELDB_PLATFORM_POSIX\n endif\n@@ -33,12 +38,8 @@ leveldb_libleveldb_a_CPPFLAGS = $(AM_CPPFLAGS) $(LEVELDB_CPPFLAGS_INT) $(LEVELDB\n leveldb_libleveldb_a_CXXFLAGS = $(AM_CXXFLAGS) $(PIE_FLAGS)\n \n leveldb_libleveldb_a_SOURCES=\n-leveldb_libleveldb_a_SOURCES += leveldb/port/atomic_pointer.h\n-leveldb_libleveldb_a_SOURCES += leveldb/port/port_example.h\n-leveldb_libleveldb_a_SOURCES += leveldb/port/port_posix.h\n-leveldb_libleveldb_a_SOURCES += leveldb/port/win/stdint.h\n+leveldb_libleveldb_a_SOURCES += leveldb/port/port_stdcxx.h\n leveldb_libleveldb_a_SOURCES += leveldb/port/port.h\n-leveldb_libleveldb_a_SOURCES += leveldb/port/port_win.h\n leveldb_libleveldb_a_SOURCES += leveldb/port/thread_annotations.h\n leveldb_libleveldb_a_SOURCES += leveldb/include/leveldb/db.h\n leveldb_libleveldb_a_SOURCES += leveldb/include/leveldb/options.h\n@@ -47,6 +48,7 @@ leveldb_libleveldb_a_SOURCES += leveldb/include/leveldb/filter_policy.h\n leveldb_libleveldb_a_SOURCES += leveldb/include/leveldb/slice.h\n leveldb_libleveldb_a_SOURCES += leveldb/include/leveldb/table_builder.h\n leveldb_libleveldb_a_SOURCES += leveldb/include/leveldb/env.h\n+leveldb_libleveldb_a_SOURCES += leveldb/include/leveldb/export.h\n leveldb_libleveldb_a_SOURCES += leveldb/include/leveldb/c.h\n leveldb_libleveldb_a_SOURCES += leveldb/include/leveldb/iterator.h\n leveldb_libleveldb_a_SOURCES += leveldb/include/leveldb/cache.h\n@@ -78,6 +80,7 @@ leveldb_libleveldb_a_SOURCES += leveldb/table/format.h\n leveldb_libleveldb_a_SOURCES += leveldb/table/iterator_wrapper.h\n leveldb_libleveldb_a_SOURCES += leveldb/util/crc32c.h\n leveldb_libleveldb_a_SOURCES += leveldb/util/env_posix_test_helper.h\n+leveldb_libleveldb_a_SOURCES += leveldb/util/env_windows_test_helper.h\n leveldb_libleveldb_a_SOURCES += leveldb/util/arena.h\n leveldb_libleveldb_a_SOURCES += leveldb/util/random.h\n leveldb_libleveldb_a_SOURCES += leveldb/util/posix_logger.h\n@@ -87,7 +90,9 @@ leveldb_libleveldb_a_SOURCES += leveldb/util/coding.h\n leveldb_libleveldb_a_SOURCES += leveldb/util/testutil.h\n leveldb_libleveldb_a_SOURCES += leveldb/util/mutexlock.h\n leveldb_libleveldb_a_SOURCES += leveldb/util/logging.h\n+leveldb_libleveldb_a_SOURCES += leveldb/util/no_destructor.h\n leveldb_libleveldb_a_SOURCES += leveldb/util/testharness.h\n+leveldb_libleveldb_a_SOURCES += leveldb/util/windows_logger.h\n \n leveldb_libleveldb_a_SOURCES += leveldb/db/builder.cc\n leveldb_libleveldb_a_SOURCES += leveldb/db/c.cc\n@@ -120,7 +125,6 @@ leveldb_libleveldb_a_SOURCES += leveldb/util/coding.cc\n leveldb_libleveldb_a_SOURCES += leveldb/util/comparator.cc\n leveldb_libleveldb_a_SOURCES += leveldb/util/crc32c.cc\n leveldb_libleveldb_a_SOURCES += leveldb/util/env.cc\n-leveldb_libleveldb_a_SOURCES += leveldb/util/env_posix.cc\n leveldb_libleveldb_a_SOURCES += leveldb/util/filter_policy.cc\n leveldb_libleveldb_a_SOURCES += leveldb/util/hash.cc\n leveldb_libleveldb_a_SOURCES += leveldb/util/histogram.cc\n@@ -129,21 +133,12 @@ leveldb_libleveldb_a_SOURCES += leveldb/util/options.cc\n leveldb_libleveldb_a_SOURCES += leveldb/util/status.cc\n \n if TARGET_WINDOWS\n-leveldb_libleveldb_a_SOURCES += leveldb/util/env_win.cc\n-leveldb_libleveldb_a_SOURCES += leveldb/port/port_win.cc\n+leveldb_libleveldb_a_SOURCES += leveldb/util/env_windows.cc\n else\n-leveldb_libleveldb_a_SOURCES += leveldb/port/port_posix.cc\n+leveldb_libleveldb_a_SOURCES += leveldb/util/env_posix.cc\n endif\n \n leveldb_libmemenv_a_CPPFLAGS = $(leveldb_libleveldb_a_CPPFLAGS)\n leveldb_libmemenv_a_CXXFLAGS = $(leveldb_libleveldb_a_CXXFLAGS)\n leveldb_libmemenv_a_SOURCES =  leveldb/helpers/memenv/memenv.cc\n leveldb_libmemenv_a_SOURCES += leveldb/helpers/memenv/memenv.h\n-\n-leveldb_libleveldb_sse42_a_CPPFLAGS = $(leveldb_libleveldb_a_CPPFLAGS)\n-leveldb_libleveldb_sse42_a_CXXFLAGS = $(leveldb_libleveldb_a_CXXFLAGS)\n-if ENABLE_HWCRC32\n-leveldb_libleveldb_sse42_a_CPPFLAGS += -DLEVELDB_PLATFORM_POSIX_SSE\n-leveldb_libleveldb_sse42_a_CXXFLAGS += $(SSE42_CXXFLAGS)\n-endif\n-leveldb_libleveldb_sse42_a_SOURCES =  leveldb/port/port_posix_sse.cc"
      }
    ]
  },
  {
    "sha": "7cf13a513409c18d18dff2f6203b3630937b487d",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo3Y2YxM2E1MTM0MDljMThkMThkZmYyZjYyMDNiMzYzMDkzN2I0ODdk",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2019-11-07T12:42:44Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T16:01:48Z"
      },
      "message": "doc: Add crc32c subtree to developer notes",
      "tree": {
        "sha": "a43002eca2120a650950e704335a9cbe92d7610a",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/a43002eca2120a650950e704335a9cbe92d7610a"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/7cf13a513409c18d18dff2f6203b3630937b487d",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/7cf13a513409c18d18dff2f6203b3630937b487d",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/7cf13a513409c18d18dff2f6203b3630937b487d",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/7cf13a513409c18d18dff2f6203b3630937b487d/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "24d02a9ac00a82d172b171f73554a882df264c80",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/24d02a9ac00a82d172b171f73554a882df264c80",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/24d02a9ac00a82d172b171f73554a882df264c80"
      }
    ],
    "stats": {
      "total": 4,
      "additions": 4,
      "deletions": 0
    },
    "files": [
      {
        "sha": "a82ecee7d8c7af28dc1b4a254fd3bf4bd8c3b54a",
        "filename": "doc/developer-notes.md",
        "status": "modified",
        "additions": 4,
        "deletions": 0,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/7cf13a513409c18d18dff2f6203b3630937b487d/doc/developer-notes.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/7cf13a513409c18d18dff2f6203b3630937b487d/doc/developer-notes.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/developer-notes.md?ref=7cf13a513409c18d18dff2f6203b3630937b487d",
        "patch": "@@ -858,6 +858,10 @@ Current subtrees include:\n   - **Note**: Follow the instructions in [Upgrading LevelDB](#upgrading-leveldb) when\n     merging upstream changes to the LevelDB subtree.\n \n+- src/crc32c\n+  - Used by leveldb for hardware acceleration of CRC32C checksums for data integrity.\n+  - Upstream at https://github.com/google/crc32c ; Maintained by Google.\n+\n - src/secp256k1\n   - Upstream at https://github.com/bitcoin-core/secp256k1/ ; actively maintained by Core contributors.\n "
      }
    ]
  },
  {
    "sha": "84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo4NGZmMWIyMDc2ZWY5MWNlNjg4OTMwZDBhYTBhN2Y0MDc4ZWYzZTFk",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2019-11-07T12:43:55Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T16:01:48Z"
      },
      "message": "test: Add crc32c to subtree check linter",
      "tree": {
        "sha": "9b2f47742c75c2e51544edbc357a9211ec15cf77",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/9b2f47742c75c2e51544edbc357a9211ec15cf77"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "7cf13a513409c18d18dff2f6203b3630937b487d",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/7cf13a513409c18d18dff2f6203b3630937b487d",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/7cf13a513409c18d18dff2f6203b3630937b487d"
      }
    ],
    "stats": {
      "total": 2,
      "additions": 2,
      "deletions": 0
    },
    "files": [
      {
        "sha": "003bdf3c29268ac3ce589aeacf2cb7f6e3277be5",
        "filename": "ci/lint/06_script.sh",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d/ci/lint/06_script.sh",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d/ci/lint/06_script.sh",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/ci/lint/06_script.sh?ref=84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d",
        "patch": "@@ -14,6 +14,7 @@ test/lint/git-subtree-check.sh src/crypto/ctaes\n test/lint/git-subtree-check.sh src/secp256k1\n test/lint/git-subtree-check.sh src/univalue\n test/lint/git-subtree-check.sh src/leveldb\n+test/lint/git-subtree-check.sh src/crc32c\n test/lint/check-doc.py\n test/lint/check-rpc-mappings.py .\n test/lint/lint-all.sh"
      },
      {
        "sha": "6b95cc3540b99d4cea1cde0942325e16e04acfe0",
        "filename": "test/lint/README.md",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d/test/lint/README.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d/test/lint/README.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/lint/README.md?ref=84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d",
        "patch": "@@ -21,6 +21,7 @@ maintained:\n * for `src/leveldb`: https://github.com/bitcoin-core/leveldb.git (branch bitcoin-fork)\n * for `src/univalue`: https://github.com/bitcoin-core/univalue.git (branch master)\n * for `src/crypto/ctaes`: https://github.com/bitcoin-core/ctaes.git (branch master)\n+* for `src/crc32c`: https://github.com/google/crc32c.git (branch master)\n \n Usage: `git-subtree-check.sh DIR (COMMIT)`\n "
      }
    ]
  },
  {
    "sha": "3a037d0067c2c12a1c2c800fb85613a0a2911253",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzozYTAzN2QwMDY3YzJjMTJhMWMyYzgwMGZiODU2MTNhMGEyOTExMjUz",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2019-11-07T12:56:31Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T16:01:48Z"
      },
      "message": "test: Add crc32c exception to various linters and generation scripts",
      "tree": {
        "sha": "7dcef1021a627851efeae14927cfd1fc46ac2888",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/7dcef1021a627851efeae14927cfd1fc46ac2888"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/3a037d0067c2c12a1c2c800fb85613a0a2911253",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3a037d0067c2c12a1c2c800fb85613a0a2911253",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/3a037d0067c2c12a1c2c800fb85613a0a2911253",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3a037d0067c2c12a1c2c800fb85613a0a2911253/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/84ff1b2076ef91ce688930d0aa0a7f4078ef3e1d"
      }
    ],
    "stats": {
      "total": 20,
      "additions": 11,
      "deletions": 9
    },
    "files": [
      {
        "sha": "92120eaff7f9a6470827568fe9d9018711088343",
        "filename": "contrib/devtools/copyright_header.py",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3a037d0067c2c12a1c2c800fb85613a0a2911253/contrib/devtools/copyright_header.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3a037d0067c2c12a1c2c800fb85613a0a2911253/contrib/devtools/copyright_header.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/contrib/devtools/copyright_header.py?ref=3a037d0067c2c12a1c2c800fb85613a0a2911253",
        "patch": "@@ -34,6 +34,7 @@\n     \"src/leveldb/\",\n     \"src/secp256k1/\",\n     \"src/univalue/\",\n+    \"src/crc32c/\",\n ]\n \n INCLUDE = ['*.h', '*.cpp', '*.cc', '*.c', '*.mm', '*.py', '*.sh', '*.bash-completion']"
      },
      {
        "sha": "7e307ab7c84b00f43d75c514e86a334f0f9aa241",
        "filename": "doc/Doxyfile.in",
        "status": "modified",
        "additions": 2,
        "deletions": 1,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3a037d0067c2c12a1c2c800fb85613a0a2911253/doc/Doxyfile.in",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3a037d0067c2c12a1c2c800fb85613a0a2911253/doc/Doxyfile.in",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/Doxyfile.in?ref=3a037d0067c2c12a1c2c800fb85613a0a2911253",
        "patch": "@@ -861,7 +861,8 @@ RECURSIVE              = YES\n # Note that relative paths are relative to the directory from which doxygen is\n # run.\n \n-EXCLUDE                = src/leveldb \\\n+EXCLUDE                = src/crc32c \\\n+                         src/leveldb \\\n                          src/json \\\n                          src/test \\\n                          src/qt/test"
      },
      {
        "sha": "4d6c70660fbbfa2ac6dc00c3653f428f7ea6537b",
        "filename": "test/lint/extended-lint-cppcheck.sh",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/extended-lint-cppcheck.sh",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/extended-lint-cppcheck.sh",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/lint/extended-lint-cppcheck.sh?ref=3a037d0067c2c12a1c2c800fb85613a0a2911253",
        "patch": "@@ -65,7 +65,7 @@ function join_array {\n \n ENABLED_CHECKS_REGEXP=$(join_array \"|\" \"${ENABLED_CHECKS[@]}\")\n IGNORED_WARNINGS_REGEXP=$(join_array \"|\" \"${IGNORED_WARNINGS[@]}\")\n-WARNINGS=$(git ls-files -- \"*.cpp\" \"*.h\" \":(exclude)src/leveldb/\" \":(exclude)src/secp256k1/\" \":(exclude)src/univalue/\" | \\\n+WARNINGS=$(git ls-files -- \"*.cpp\" \"*.h\" \":(exclude)src/leveldb/\" \":(exclude)src/crc32c/\" \":(exclude)src/secp256k1/\" \":(exclude)src/univalue/\" | \\\n     xargs cppcheck --enable=all -j \"$(getconf _NPROCESSORS_ONLN)\" --language=c++ --std=c++11 --template=gcc -D__cplusplus -DCLIENT_VERSION_BUILD -DCLIENT_VERSION_IS_RELEASE -DCLIENT_VERSION_MAJOR -DCLIENT_VERSION_MINOR -DCLIENT_VERSION_REVISION -DCOPYRIGHT_YEAR -DDEBUG -DHAVE_WORKING_BOOST_SLEEP_FOR -I src/ -q 2>&1 | sort -u | \\\n     grep -E \"${ENABLED_CHECKS_REGEXP}\" | \\\n     grep -vE \"${IGNORED_WARNINGS_REGEXP}\")"
      },
      {
        "sha": "3a0494c190dc675611db5a1c5fe42c0fb11233aa",
        "filename": "test/lint/lint-include-guards.sh",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/lint-include-guards.sh",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/lint-include-guards.sh",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/lint/lint-include-guards.sh?ref=3a037d0067c2c12a1c2c800fb85613a0a2911253",
        "patch": "@@ -10,7 +10,7 @@ export LC_ALL=C\n HEADER_ID_PREFIX=\"BITCOIN_\"\n HEADER_ID_SUFFIX=\"_H\"\n \n-REGEXP_EXCLUDE_FILES_WITH_PREFIX=\"src/(crypto/ctaes/|leveldb/|secp256k1/|test/fuzz/FuzzedDataProvider.h|tinyformat.h|univalue/)\"\n+REGEXP_EXCLUDE_FILES_WITH_PREFIX=\"src/(crypto/ctaes/|leveldb/|crc32c/|secp256k1/|test/fuzz/FuzzedDataProvider.h|tinyformat.h|univalue/)\"\n \n EXIT_CODE=0\n for HEADER_FILE in $(git ls-files -- \"*.h\" | grep -vE \"^${REGEXP_EXCLUDE_FILES_WITH_PREFIX}\")"
      },
      {
        "sha": "ced2fd2bb696d1e2195edd94f1c73b504b94595d",
        "filename": "test/lint/lint-includes.sh",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/lint-includes.sh",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/lint-includes.sh",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/lint/lint-includes.sh?ref=3a037d0067c2c12a1c2c800fb85613a0a2911253",
        "patch": "@@ -9,7 +9,7 @@\n # Check includes: Check for duplicate includes. Enforce bracket syntax includes.\n \n export LC_ALL=C\n-IGNORE_REGEXP=\"/(leveldb|secp256k1|univalue)/\"\n+IGNORE_REGEXP=\"/(leveldb|secp256k1|univalue|crc32c)/\"\n \n # cd to root folder of git repo for git ls-files to work properly\n cd \"$(dirname $0)/../..\" || exit 1"
      },
      {
        "sha": "773855bed19d28547f2d768fd66cd25a25ea4321",
        "filename": "test/lint/lint-python-utf8-encoding.sh",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/lint-python-utf8-encoding.sh",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/lint-python-utf8-encoding.sh",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/lint/lint-python-utf8-encoding.sh?ref=3a037d0067c2c12a1c2c800fb85613a0a2911253",
        "patch": "@@ -9,15 +9,15 @@\n \n export LC_ALL=C\n EXIT_CODE=0\n-OUTPUT=$(git grep \" open(\" -- \"*.py\" | grep -vE \"encoding=.(ascii|utf8|utf-8).\" | grep -vE \"open\\([^,]*, ['\\\"][^'\\\"]*b[^'\\\"]*['\\\"]\")\n+OUTPUT=$(git grep \" open(\" -- \"*.py\" \":(exclude)src/crc32c/\" | grep -vE \"encoding=.(ascii|utf8|utf-8).\" | grep -vE \"open\\([^,]*, ['\\\"][^'\\\"]*b[^'\\\"]*['\\\"]\")\n if [[ ${OUTPUT} != \"\" ]]; then\n     echo \"Python's open(...) seems to be used to open text files without explicitly\"\n     echo \"specifying encoding=\\\"utf8\\\":\"\n     echo\n     echo \"${OUTPUT}\"\n     EXIT_CODE=1\n fi\n-OUTPUT=$(git grep \"check_output(\" -- \"*.py\" | grep \"universal_newlines=True\" | grep -vE \"encoding=.(ascii|utf8|utf-8).\")\n+OUTPUT=$(git grep \"check_output(\" -- \"*.py\" \":(exclude)src/crc32c/\"| grep \"universal_newlines=True\" | grep -vE \"encoding=.(ascii|utf8|utf-8).\")\n if [[ ${OUTPUT} != \"\" ]]; then\n     echo \"Python's check_output(...) seems to be used to get program outputs without explicitly\"\n     echo \"specifying encoding=\\\"utf8\\\":\""
      },
      {
        "sha": "cb84727ba5a39fb48f5dc6db1f1476a817cd2b82",
        "filename": "test/lint/lint-spelling.sh",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/lint-spelling.sh",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/lint-spelling.sh",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/lint/lint-spelling.sh?ref=3a037d0067c2c12a1c2c800fb85613a0a2911253",
        "patch": "@@ -15,6 +15,6 @@ if ! command -v codespell > /dev/null; then\n fi\n \n IGNORE_WORDS_FILE=test/lint/lint-spelling.ignore-words.txt\n-if ! codespell --check-filenames --disable-colors --quiet-level=7 --ignore-words=${IGNORE_WORDS_FILE} $(git ls-files -- \":(exclude)build-aux/m4/\" \":(exclude)contrib/seeds/*.txt\" \":(exclude)depends/\" \":(exclude)doc/release-notes/\" \":(exclude)src/leveldb/\" \":(exclude)src/qt/locale/\" \":(exclude)src/qt/*.qrc\" \":(exclude)src/secp256k1/\" \":(exclude)src/univalue/\"); then\n+if ! codespell --check-filenames --disable-colors --quiet-level=7 --ignore-words=${IGNORE_WORDS_FILE} $(git ls-files -- \":(exclude)build-aux/m4/\" \":(exclude)contrib/seeds/*.txt\" \":(exclude)depends/\" \":(exclude)doc/release-notes/\" \":(exclude)src/leveldb/\" \":(exclude)src/crc32c/\" \":(exclude)src/qt/locale/\" \":(exclude)src/qt/*.qrc\" \":(exclude)src/secp256k1/\" \":(exclude)src/univalue/\"); then\n     echo \"^ Warning: codespell identified likely spelling errors. Any false positives? Add them to the list of ignored words in ${IGNORE_WORDS_FILE}\"\n fi"
      },
      {
        "sha": "d8bdb0a8d700a6f80f970f5e2d3fbf5d80b2775b",
        "filename": "test/lint/lint-whitespace.sh",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/lint-whitespace.sh",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3a037d0067c2c12a1c2c800fb85613a0a2911253/test/lint/lint-whitespace.sh",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/lint/lint-whitespace.sh?ref=3a037d0067c2c12a1c2c800fb85613a0a2911253",
        "patch": "@@ -31,14 +31,14 @@ if [ -z \"${TRAVIS_COMMIT_RANGE}\" ]; then\n fi\n \n showdiff() {\n-  if ! git diff -U0 \"${TRAVIS_COMMIT_RANGE}\" -- \".\" \":(exclude)depends/patches/\" \":(exclude)src/leveldb/\" \":(exclude)src/secp256k1/\" \":(exclude)src/univalue/\" \":(exclude)doc/release-notes/\" \":(exclude)src/qt/locale/\"; then\n+  if ! git diff -U0 \"${TRAVIS_COMMIT_RANGE}\" -- \".\" \":(exclude)depends/patches/\" \":(exclude)src/leveldb/\" \":(exclude)src/crc32c/\" \":(exclude)src/secp256k1/\" \":(exclude)src/univalue/\" \":(exclude)doc/release-notes/\" \":(exclude)src/qt/locale/\"; then\n     echo \"Failed to get a diff\"\n     exit 1\n   fi\n }\n \n showcodediff() {\n-  if ! git diff -U0 \"${TRAVIS_COMMIT_RANGE}\" -- *.cpp *.h *.md *.py *.sh \":(exclude)src/leveldb/\" \":(exclude)src/secp256k1/\" \":(exclude)src/univalue/\" \":(exclude)doc/release-notes/\" \":(exclude)src/qt/locale/\"; then\n+  if ! git diff -U0 \"${TRAVIS_COMMIT_RANGE}\" -- *.cpp *.h *.md *.py *.sh \":(exclude)src/leveldb/\" \":(exclude)src/crc32c/\" \":(exclude)src/secp256k1/\" \":(exclude)src/univalue/\" \":(exclude)doc/release-notes/\" \":(exclude)src/qt/locale/\"; then\n     echo \"Failed to get a diff\"\n     exit 1\n   fi"
      }
    ]
  },
  {
    "sha": "402252a8081e25f22aa1a5c60708714cf1d84ec4",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo0MDIyNTJhODA4MWUyNWYyMmFhMWE1YzYwNzA4NzE0Y2YxZDg0ZWM0",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2019-11-07T13:03:04Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T16:01:48Z"
      },
      "message": "build: Add LCOV exception for crc32c",
      "tree": {
        "sha": "01a44ae7f97465e56e31a0f83ec967ec784e1937",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/01a44ae7f97465e56e31a0f83ec967ec784e1937"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/402252a8081e25f22aa1a5c60708714cf1d84ec4",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/402252a8081e25f22aa1a5c60708714cf1d84ec4",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/402252a8081e25f22aa1a5c60708714cf1d84ec4",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/402252a8081e25f22aa1a5c60708714cf1d84ec4/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "3a037d0067c2c12a1c2c800fb85613a0a2911253",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3a037d0067c2c12a1c2c800fb85613a0a2911253",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/3a037d0067c2c12a1c2c800fb85613a0a2911253"
      }
    ],
    "stats": {
      "total": 1,
      "additions": 1,
      "deletions": 0
    },
    "files": [
      {
        "sha": "bd41c5ae27196d699d0328481201f7eba3e8002f",
        "filename": "Makefile.am",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/402252a8081e25f22aa1a5c60708714cf1d84ec4/Makefile.am",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/402252a8081e25f22aa1a5c60708714cf1d84ec4/Makefile.am",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/Makefile.am?ref=402252a8081e25f22aa1a5c60708714cf1d84ec4",
        "patch": "@@ -194,6 +194,7 @@ LCOV_FILTER_PATTERN = \\\n \t-p \"/usr/lib/\" \\\n \t-p \"/usr/lib64/\" \\\n \t-p \"src/leveldb/\" \\\n+\t-p \"src/crc32c/\" \\\n \t-p \"src/bench/\" \\\n \t-p \"src/univalue\" \\\n \t-p \"src/crypto/ctaes\" \\"
      }
    ]
  },
  {
    "sha": "9ebdf047578f0da7e6578d0c51c32f55e84ac157",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo5ZWJkZjA0NzU3OGYwZGE3ZTY1NzhkMGM1MWMzMmY1NWU4NGFjMTU3",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2019-11-07T14:52:44Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T16:01:48Z"
      },
      "message": "build: CRC32C build system integration",
      "tree": {
        "sha": "7cd64e5ced186f46aa40f9a14e24b04081105cea",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/7cd64e5ced186f46aa40f9a14e24b04081105cea"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/9ebdf047578f0da7e6578d0c51c32f55e84ac157",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/9ebdf047578f0da7e6578d0c51c32f55e84ac157",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/9ebdf047578f0da7e6578d0c51c32f55e84ac157",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/9ebdf047578f0da7e6578d0c51c32f55e84ac157/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "402252a8081e25f22aa1a5c60708714cf1d84ec4",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/402252a8081e25f22aa1a5c60708714cf1d84ec4",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/402252a8081e25f22aa1a5c60708714cf1d84ec4"
      }
    ],
    "stats": {
      "total": 159,
      "additions": 153,
      "deletions": 6
    },
    "files": [
      {
        "sha": "cd9167e14c7d592e7153a0e5503a2a50b1cf9163",
        "filename": "configure.ac",
        "status": "modified",
        "additions": 74,
        "deletions": 4,
        "changes": 78,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/9ebdf047578f0da7e6578d0c51c32f55e84ac157/configure.ac",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/9ebdf047578f0da7e6578d0c51c32f55e84ac157/configure.ac",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/configure.ac?ref=9ebdf047578f0da7e6578d0c51c32f55e84ac157",
        "patch": "@@ -355,7 +355,7 @@ if test \"x$CXXFLAGS_overridden\" = \"xno\"; then\n   AX_CHECK_COMPILE_FLAG([-Wimplicit-fallthrough],[NOWARN_CXXFLAGS=\"$NOWARN_CXXFLAGS -Wno-implicit-fallthrough\"],,[[$CXXFLAG_WERROR]])\n fi\n \n-enable_hwcrc32=no\n+enable_sse42=no\n enable_sse41=no\n enable_avx2=no\n enable_shani=no\n@@ -365,14 +365,16 @@ if test \"x$use_asm\" = \"xyes\"; then\n dnl Check for optional instruction set support. Enabling these does _not_ imply that all code will\n dnl be compiled with them, rather that specific objects/libs may use them after checking for runtime\n dnl compatibility.\n+\n+dnl x86\n AX_CHECK_COMPILE_FLAG([-msse4.2],[[SSE42_CXXFLAGS=\"-msse4.2\"]],,[[$CXXFLAG_WERROR]])\n AX_CHECK_COMPILE_FLAG([-msse4.1],[[SSE41_CXXFLAGS=\"-msse4.1\"]],,[[$CXXFLAG_WERROR]])\n AX_CHECK_COMPILE_FLAG([-mavx -mavx2],[[AVX2_CXXFLAGS=\"-mavx -mavx2\"]],,[[$CXXFLAG_WERROR]])\n AX_CHECK_COMPILE_FLAG([-msse4 -msha],[[SHANI_CXXFLAGS=\"-msse4 -msha\"]],,[[$CXXFLAG_WERROR]])\n \n TEMP_CXXFLAGS=\"$CXXFLAGS\"\n CXXFLAGS=\"$CXXFLAGS $SSE42_CXXFLAGS\"\n-AC_MSG_CHECKING(for assembler crc32 support)\n+AC_MSG_CHECKING(for SSE4.2 intrinsics)\n AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[\n     #include <stdint.h>\n     #if defined(_MSC_VER)\n@@ -387,7 +389,7 @@ AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[\n     l = _mm_crc32_u64(l, 0);\n     return l;\n   ]])],\n- [ AC_MSG_RESULT(yes); enable_hwcrc32=yes],\n+ [ AC_MSG_RESULT(yes); enable_sse42=yes],\n  [ AC_MSG_RESULT(no)]\n )\n CXXFLAGS=\"$TEMP_CXXFLAGS\"\n@@ -439,6 +441,24 @@ AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[\n )\n CXXFLAGS=\"$TEMP_CXXFLAGS\"\n \n+# ARM\n+AX_CHECK_COMPILE_FLAG([-march=armv8-a+crc+crypto],[[ARM_CRC_CXXFLAGS=\"-march=armv8-a+crc+crypto\"]],,[[$CXXFLAG_WERROR]])\n+\n+TEMP_CXXFLAGS=\"$CXXFLAGS\"\n+CXXFLAGS=\"$CXXFLAGS $ARM_CRC_CXXFLAGS\"\n+AC_MSG_CHECKING(for ARM CRC32 intrinsics)\n+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[\n+    #include <arm_acle.h>\n+    #include <arm_neon.h>\n+  ]],[[\n+    __crc32cb(0, 0); __crc32ch(0, 0); __crc32cw(0, 0); __crc32cd(0, 0);\n+    vmull_p64(0, 0);\n+  ]])],\n+ [ AC_MSG_RESULT(yes); enable_arm_crc=yes; ],\n+ [ AC_MSG_RESULT(no)]\n+)\n+CXXFLAGS=\"$TEMP_CXXFLAGS\"\n+\n fi\n \n CPPFLAGS=\"$CPPFLAGS -DHAVE_BUILD_INFO -D__STDC_FORMAT_MACROS\"\n@@ -956,6 +976,50 @@ AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[#include <fcntl.h>]],\n  [ AC_MSG_RESULT(no); HAVE_O_CLOEXEC=0 ]\n )\n \n+dnl crc32c platform checks\n+AC_MSG_CHECKING(for __builtin_prefetch)\n+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[ ]], [[\n+  char data = 0;\n+  const char* address = &data;\n+  __builtin_prefetch(address, 0, 0);\n+  ]])],\n+ [ AC_MSG_RESULT(yes); HAVE_BUILTIN_PREFETCH=1 ],\n+ [ AC_MSG_RESULT(no); HAVE_BUILTIN_PREFETCH=0 ]\n+)\n+\n+AC_MSG_CHECKING(for _mm_prefetch)\n+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[#include <xmmintrin.h>]], [[\n+  char data = 0;\n+  const char* address = &data;\n+  _mm_prefetch(address, _MM_HINT_NTA);\n+  ]])],\n+ [ AC_MSG_RESULT(yes); HAVE_MM_PREFETCH=1 ],\n+ [ AC_MSG_RESULT(no); HAVE_MM_PREFETCH=0 ]\n+)\n+\n+AC_MSG_CHECKING(for strong getauxval support in the system headers)\n+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[\n+    #include <arm_acle.h>\n+    #include <arm_neon.h>\n+    #include <sys/auxv.h>\n+  ]], [[\n+    getauxval(AT_HWCAP);\n+  ]])],\n+ [ AC_MSG_RESULT(yes); HAVE_STRONG_GETAUXVAL=1 ],\n+ [ AC_MSG_RESULT(no); HAVE_STRONG_GETAUXVAL=0 ]\n+)\n+\n+AC_MSG_CHECKING(for weak getauxval support in the compiler)\n+AC_COMPILE_IFELSE([AC_LANG_PROGRAM([[\n+    unsigned long getauxval(unsigned long type) __attribute__((weak));\n+    #define AT_HWCAP 16\n+  ]], [[\n+    getauxval(AT_HWCAP);\n+  ]])],\n+ [ AC_MSG_RESULT(yes); HAVE_WEAK_GETAUXVAL=1 ],\n+ [ AC_MSG_RESULT(no); HAVE_WEAK_GETAUXVAL=0 ]\n+)\n+\n dnl Check for reduced exports\n if test x$use_reduce_exports = xyes; then\n   AX_CHECK_COMPILE_FLAG([-fvisibility=hidden],[RE_CXXFLAGS=\"-fvisibility=hidden\"],\n@@ -1511,10 +1575,11 @@ AM_CONDITIONAL([USE_QRCODE], [test x$use_qr = xyes])\n AM_CONDITIONAL([USE_LCOV],[test x$use_lcov = xyes])\n AM_CONDITIONAL([GLIBC_BACK_COMPAT],[test x$use_glibc_compat = xyes])\n AM_CONDITIONAL([HARDEN],[test x$use_hardening = xyes])\n-AM_CONDITIONAL([ENABLE_HWCRC32],[test x$enable_hwcrc32 = xyes])\n+AM_CONDITIONAL([ENABLE_SSE42],[test x$enable_sse42 = xyes])\n AM_CONDITIONAL([ENABLE_SSE41],[test x$enable_sse41 = xyes])\n AM_CONDITIONAL([ENABLE_AVX2],[test x$enable_avx2 = xyes])\n AM_CONDITIONAL([ENABLE_SHANI],[test x$enable_shani = xyes])\n+AM_CONDITIONAL([ENABLE_ARM_CRC],[test x$enable_arm_crc = xyes])\n AM_CONDITIONAL([USE_ASM],[test x$use_asm = xyes])\n AM_CONDITIONAL([WORDS_BIGENDIAN],[test x$ac_cv_c_bigendian = xyes])\n \n@@ -1563,6 +1628,7 @@ AC_SUBST(SSE42_CXXFLAGS)\n AC_SUBST(SSE41_CXXFLAGS)\n AC_SUBST(AVX2_CXXFLAGS)\n AC_SUBST(SHANI_CXXFLAGS)\n+AC_SUBST(ARM_CRC_CXXFLAGS)\n AC_SUBST(LIBTOOL_APP_LDFLAGS)\n AC_SUBST(USE_UPNP)\n AC_SUBST(USE_QRCODE)\n@@ -1577,6 +1643,10 @@ AC_SUBST(QR_LIBS)\n AC_SUBST(HAVE_FDATASYNC)\n AC_SUBST(HAVE_FULLFSYNC)\n AC_SUBST(HAVE_O_CLOEXEC)\n+AC_SUBST(HAVE_BUILTIN_PREFETCH)\n+AC_SUBST(HAVE_MM_PREFETCH)\n+AC_SUBST(HAVE_STRONG_GETAUXVAL)\n+AC_SUBST(HAVE_WEAK_GETAUXVAL)\n AC_CONFIG_FILES([Makefile src/Makefile doc/man/Makefile share/setup.nsi share/qt/Info.plist test/config.ini])\n AC_CONFIG_FILES([contrib/devtools/split-debug.sh],[chmod +x contrib/devtools/split-debug.sh])\n AM_COND_IF([HAVE_DOXYGEN], [AC_CONFIG_FILES([doc/Doxyfile])])"
      },
      {
        "sha": "367e006d734efb64558feeffdd7fea4b3b6958b6",
        "filename": "src/Makefile.am",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/9ebdf047578f0da7e6578d0c51c32f55e84ac157/src/Makefile.am",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/9ebdf047578f0da7e6578d0c51c32f55e84ac157/src/Makefile.am",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/Makefile.am?ref=9ebdf047578f0da7e6578d0c51c32f55e84ac157",
        "patch": "@@ -716,6 +716,7 @@ if HARDEN\n endif\n \n if EMBEDDED_LEVELDB\n+include Makefile.crc32c.include\n include Makefile.leveldb.include\n endif\n "
      },
      {
        "sha": "802b3a2e4b8450d74215c7dd08cd079a9eb49adc",
        "filename": "src/Makefile.crc32c.include",
        "status": "added",
        "additions": 75,
        "deletions": 0,
        "changes": 75,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/9ebdf047578f0da7e6578d0c51c32f55e84ac157/src/Makefile.crc32c.include",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/9ebdf047578f0da7e6578d0c51c32f55e84ac157/src/Makefile.crc32c.include",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/Makefile.crc32c.include?ref=9ebdf047578f0da7e6578d0c51c32f55e84ac157",
        "patch": "@@ -0,0 +1,75 @@\n+# Copyright (c) 2019 The Bitcoin Core developers\n+# Distributed under the MIT software license, see the accompanying\n+# file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+LIBCRC32C_INT = crc32c/libcrc32c.a\n+LIBLEVELDB_SSE42_INT  = leveldb/libleveldb_sse42.a\n+\n+EXTRA_LIBRARIES += $(LIBCRC32C_INT)\n+\n+LIBCRC32C = $(LIBCRC32C_INT)\n+\n+CRC32C_CPPFLAGS_INT =\n+CRC32C_CPPFLAGS_INT += -I$(srcdir)/crc32c/include\n+CRC32C_CPPFLAGS_INT += -DHAVE_BUILTIN_PREFETCH=@HAVE_BUILTIN_PREFETCH@\n+CRC32C_CPPFLAGS_INT += -DHAVE_MM_PREFETCH=@HAVE_MM_PREFETCH@\n+CRC32C_CPPFLAGS_INT += -DHAVE_STRONG_GETAUXVAL=@HAVE_STRONG_GETAUXVAL@\n+CRC32C_CPPFLAGS_INT += -DHAVE_WEAK_GETAUXVAL=@HAVE_WEAK_GETAUXVAL@\n+CRC32C_CPPFLAGS_INT += -DCRC32C_TESTS_BUILT_WITH_GLOG=0\n+\n+if ENABLE_SSE42\n+CRC32C_CPPFLAGS_INT += -DHAVE_SSE42=1\n+else\n+CRC32C_CPPFLAGS_INT += -DHAVE_SSE42=0\n+endif\n+\n+if ENABLE_ARM_CRC\n+CRC32C_CPPFLAGS_INT += -DHAVE_ARM64_CRC32C=1\n+else\n+CRC32C_CPPFLAGS_INT += -DHAVE_ARM64_CRC32C=0\n+endif\n+\n+if WORDS_BIGENDIAN\n+CRC32C_CPPFLAGS_INT += -DBYTE_ORDER_BIG_ENDIAN=1\n+else\n+CRC32C_CPPFLAGS_INT += -DBYTE_ORDER_BIG_ENDIAN=0\n+endif\n+\n+crc32c_libcrc32c_a_CPPFLAGS = $(AM_CPPFLAGS) $(CRC32C_CPPFLAGS_INT) $(CRC32C_CPPFLAGS)\n+crc32c_libcrc32c_a_CXXFLAGS = $(AM_CXXFLAGS) $(PIE_FLAGS)\n+\n+crc32c_libcrc32c_a_SOURCES =\n+crc32c_libcrc32c_a_SOURCES += crc32c/include/crc32c/crc32c.h\n+crc32c_libcrc32c_a_SOURCES += crc32c/src/crc32c_arm64.h\n+crc32c_libcrc32c_a_SOURCES += crc32c/src/crc32c_arm64_linux_check.h\n+crc32c_libcrc32c_a_SOURCES += crc32c/src/crc32c_internal.h\n+crc32c_libcrc32c_a_SOURCES += crc32c/src/crc32c_prefetch.h\n+crc32c_libcrc32c_a_SOURCES += crc32c/src/crc32c_read_le.h\n+crc32c_libcrc32c_a_SOURCES += crc32c/src/crc32c_round_up.h\n+crc32c_libcrc32c_a_SOURCES += crc32c/src/crc32c_sse42_check.h\n+crc32c_libcrc32c_a_SOURCES += crc32c/src/crc32c_sse42.h\n+\n+crc32c_libcrc32c_a_SOURCES += crc32c/src/crc32c.cc\n+crc32c_libcrc32c_a_SOURCES += crc32c/src/crc32c_portable.cc\n+\n+if ENABLE_SSE42\n+LIBCRC32C_SSE42_INT = crc32c/libcrc32c_sse42.a\n+EXTRA_LIBRARIES += $(LIBCRC32C_SSE42_INT)\n+LIBCRC32C += $(LIBCRC32C_SSE42_INT)\n+\n+crc32c_libcrc32c_sse42_a_CPPFLAGS = $(crc32c_libcrc32c_a_CPPFLAGS)\n+crc32c_libcrc32c_sse42_a_CXXFLAGS = $(crc32c_libcrc32c_a_CXXFLAGS) $(SSE42_CXXFLAGS)\n+\n+crc32c_libcrc32c_sse42_a_SOURCES = crc32c/src/crc32c_sse42.cc\n+endif\n+\n+if ENABLE_ARM_CRC\n+LIBCRC32C_ARM_CRC_INT = crc32c/libcrc32c_arm_crc.a\n+EXTRA_LIBRARIES += $(LIBCRC32C_ARM_CRC_INT)\n+LIBCRC32C += $(LIBCRC32C_ARM_CRC_INT)\n+\n+crc32c_libcrc32c_arm_crc_a_CPPFLAGS = $(crc32c_libcrc32c_a_CPPFLAGS)\n+crc32c_libcrc32c_arm_crc_a_CXXFLAGS = $(crc32c_libcrc32c_a_CXXFLAGS) $(ARM_CRC_CXXFLAGS)\n+\n+crc32c_libcrc32c_arm_crc_a_SOURCES = crc32c/src/crc32c_arm64.cc\n+endif"
      },
      {
        "sha": "04b53471e43ea67e9c57b9617a85b25a968e0268",
        "filename": "src/Makefile.leveldb.include",
        "status": "modified",
        "additions": 3,
        "deletions": 2,
        "changes": 5,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/9ebdf047578f0da7e6578d0c51c32f55e84ac157/src/Makefile.leveldb.include",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/9ebdf047578f0da7e6578d0c51c32f55e84ac157/src/Makefile.leveldb.include",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/Makefile.leveldb.include?ref=9ebdf047578f0da7e6578d0c51c32f55e84ac157",
        "patch": "@@ -8,16 +8,17 @@ LIBMEMENV_INT  = leveldb/libmemenv.a\n EXTRA_LIBRARIES += $(LIBLEVELDB_INT)\n EXTRA_LIBRARIES += $(LIBMEMENV_INT)\n \n-LIBLEVELDB += $(LIBLEVELDB_INT)\n+LIBLEVELDB += $(LIBLEVELDB_INT) $(LIBCRC32C)\n LIBMEMENV += $(LIBMEMENV_INT)\n \n LEVELDB_CPPFLAGS += -I$(srcdir)/leveldb/include\n LEVELDB_CPPFLAGS += -I$(srcdir)/leveldb/helpers/memenv\n \n LEVELDB_CPPFLAGS_INT =\n LEVELDB_CPPFLAGS_INT += -I$(srcdir)/leveldb\n+LEVELDB_CPPFLAGS_INT += -I$(srcdir)/crc32c/include\n LEVELDB_CPPFLAGS_INT += -D__STDC_LIMIT_MACROS\n-LEVELDB_CPPFLAGS_INT += -DHAVE_SNAPPY=0 -DHAVE_CRC32C=0\n+LEVELDB_CPPFLAGS_INT += -DHAVE_SNAPPY=0 -DHAVE_CRC32C=1\n LEVELDB_CPPFLAGS_INT += -DHAVE_FDATASYNC=@HAVE_FDATASYNC@\n LEVELDB_CPPFLAGS_INT += -DHAVE_FULLFSYNC=@HAVE_FULLFSYNC@\n LEVELDB_CPPFLAGS_INT += -DHAVE_O_CLOEXEC=@HAVE_O_CLOEXEC@"
      }
    ]
  },
  {
    "sha": "be23949765e1b2e050574c6c2a136658a89dee5d",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzpiZTIzOTQ5NzY1ZTFiMmUwNTA1NzRjNmMyYTEzNjY1OGE4OWRlZTVk",
    "commit": {
      "author": {
        "name": "Aaron Clauson",
        "email": "aaron@sipsorcery.com",
        "date": "2019-11-07T21:03:45Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T16:01:48Z"
      },
      "message": "build: MSVC changes for leveldb update",
      "tree": {
        "sha": "9a1d9f9518fe612b9f2ab4c672ab19eeb17727e5",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/9a1d9f9518fe612b9f2ab4c672ab19eeb17727e5"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/be23949765e1b2e050574c6c2a136658a89dee5d",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/be23949765e1b2e050574c6c2a136658a89dee5d",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/be23949765e1b2e050574c6c2a136658a89dee5d",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/be23949765e1b2e050574c6c2a136658a89dee5d/comments",
    "author": {
      "login": "sipsorcery",
      "id": 197660,
      "node_id": "MDQ6VXNlcjE5NzY2MA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/197660?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipsorcery",
      "html_url": "https://github.com/sipsorcery",
      "followers_url": "https://api.github.com/users/sipsorcery/followers",
      "following_url": "https://api.github.com/users/sipsorcery/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipsorcery/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipsorcery/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipsorcery/subscriptions",
      "organizations_url": "https://api.github.com/users/sipsorcery/orgs",
      "repos_url": "https://api.github.com/users/sipsorcery/repos",
      "events_url": "https://api.github.com/users/sipsorcery/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipsorcery/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "9ebdf047578f0da7e6578d0c51c32f55e84ac157",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/9ebdf047578f0da7e6578d0c51c32f55e84ac157",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/9ebdf047578f0da7e6578d0c51c32f55e84ac157"
      }
    ],
    "stats": {
      "total": 6,
      "additions": 2,
      "deletions": 4
    },
    "files": [
      {
        "sha": "cabc177557c9704f7fc25c055a150f97f4e811bc",
        "filename": "build_msvc/libleveldb/libleveldb.vcxproj",
        "status": "modified",
        "additions": 2,
        "deletions": 4,
        "changes": 6,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/be23949765e1b2e050574c6c2a136658a89dee5d/build_msvc/libleveldb/libleveldb.vcxproj",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/be23949765e1b2e050574c6c2a136658a89dee5d/build_msvc/libleveldb/libleveldb.vcxproj",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/build_msvc/libleveldb/libleveldb.vcxproj?ref=be23949765e1b2e050574c6c2a136658a89dee5d",
        "patch": "@@ -24,8 +24,6 @@\n     <ClCompile Include=\"..\\..\\src\\leveldb\\db\\version_set.cc\" />\n     <ClCompile Include=\"..\\..\\src\\leveldb\\db\\write_batch.cc\" />\n     <ClCompile Include=\"..\\..\\src\\leveldb\\helpers\\memenv\\memenv.cc\" />\n-    <ClCompile Include=\"..\\..\\src\\leveldb\\port\\port_posix_sse.cc\" />\n-    <ClCompile Include=\"..\\..\\src\\leveldb\\port\\port_win.cc\" />\n     <ClCompile Include=\"..\\..\\src\\leveldb\\table\\block.cc\" />\n     <ClCompile Include=\"..\\..\\src\\leveldb\\table\\block_builder.cc\" />\n     <ClCompile Include=\"..\\..\\src\\leveldb\\table\\filter_block.cc\" />\n@@ -42,7 +40,7 @@\n     <ClCompile Include=\"..\\..\\src\\leveldb\\util\\comparator.cc\" />\n     <ClCompile Include=\"..\\..\\src\\leveldb\\util\\crc32c.cc\" />\n     <ClCompile Include=\"..\\..\\src\\leveldb\\util\\env.cc\" />\n-    <ClCompile Include=\"..\\..\\src\\leveldb\\util\\env_win.cc\" />\n+    <ClCompile Include=\"..\\..\\src\\leveldb\\util\\env_windows.cc\" />\n     <ClCompile Include=\"..\\..\\src\\leveldb\\util\\filter_policy.cc\" />\n     <ClCompile Include=\"..\\..\\src\\leveldb\\util\\hash.cc\" />\n     <ClCompile Include=\"..\\..\\src\\leveldb\\util\\histogram.cc\" />\n@@ -52,7 +50,7 @@\n   </ItemGroup>\n   <ItemDefinitionGroup>\n     <ClCompile>\n-\t <PreprocessorDefinitions>_CRT_NONSTDC_NO_DEPRECATE;LEVELDB_PLATFORM_WINDOWS;LEVELDB_ATOMIC_PRESENT;%(PreprocessorDefinitions)</PreprocessorDefinitions>\n+\t <PreprocessorDefinitions>HAVE_CRC32C=0;HAVE_SNAPPY=0;__STDC_LIMIT_MACROS;LEVELDB_IS_BIG_ENDIAN=0;_UNICODE;UNICODE;_CRT_NONSTDC_NO_DEPRECATE;LEVELDB_PLATFORM_WINDOWS;LEVELDB_ATOMIC_PRESENT;%(PreprocessorDefinitions)</PreprocessorDefinitions>\n \t <DisableSpecificWarnings>4244;4267;4312;</DisableSpecificWarnings>\n \t <AdditionalIncludeDirectories>..\\..\\src\\leveldb;..\\..\\src\\leveldb\\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>\n \t</ClCompile>"
      }
    ]
  },
  {
    "sha": "8e68bb1ddeca504bedd40aee8492b5478a88c1e5",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo4ZTY4YmIxZGRlY2E1MDRiZWRkNDBhZWU4NDkyYjU0NzhhODhjMWU1",
    "commit": {
      "author": {
        "name": "Aaron Clauson",
        "email": "aaron@sipsorcery.com",
        "date": "2019-11-18T13:47:16Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T16:01:48Z"
      },
      "message": "build: Disable msvc warning 4722 for leveldb build\n\nThis prevents AppVeyor from failing on a warning in leveldb's new\nWindows environment.",
      "tree": {
        "sha": "f0d9b3b222200d20d9b58311a961834cc6fcdf2e",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/f0d9b3b222200d20d9b58311a961834cc6fcdf2e"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/8e68bb1ddeca504bedd40aee8492b5478a88c1e5",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/8e68bb1ddeca504bedd40aee8492b5478a88c1e5",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/8e68bb1ddeca504bedd40aee8492b5478a88c1e5",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/8e68bb1ddeca504bedd40aee8492b5478a88c1e5/comments",
    "author": {
      "login": "sipsorcery",
      "id": 197660,
      "node_id": "MDQ6VXNlcjE5NzY2MA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/197660?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipsorcery",
      "html_url": "https://github.com/sipsorcery",
      "followers_url": "https://api.github.com/users/sipsorcery/followers",
      "following_url": "https://api.github.com/users/sipsorcery/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipsorcery/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipsorcery/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipsorcery/subscriptions",
      "organizations_url": "https://api.github.com/users/sipsorcery/orgs",
      "repos_url": "https://api.github.com/users/sipsorcery/repos",
      "events_url": "https://api.github.com/users/sipsorcery/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipsorcery/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "be23949765e1b2e050574c6c2a136658a89dee5d",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/be23949765e1b2e050574c6c2a136658a89dee5d",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/be23949765e1b2e050574c6c2a136658a89dee5d"
      }
    ],
    "stats": {
      "total": 10,
      "additions": 5,
      "deletions": 5
    },
    "files": [
      {
        "sha": "1610ae7d8661f421df97c103ae57bf80e9399371",
        "filename": "build_msvc/libleveldb/libleveldb.vcxproj",
        "status": "modified",
        "additions": 5,
        "deletions": 5,
        "changes": 10,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/8e68bb1ddeca504bedd40aee8492b5478a88c1e5/build_msvc/libleveldb/libleveldb.vcxproj",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/8e68bb1ddeca504bedd40aee8492b5478a88c1e5/build_msvc/libleveldb/libleveldb.vcxproj",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/build_msvc/libleveldb/libleveldb.vcxproj?ref=8e68bb1ddeca504bedd40aee8492b5478a88c1e5",
        "patch": "@@ -49,11 +49,11 @@\n     <ClCompile Include=\"..\\..\\src\\leveldb\\util\\status.cc\" />\n   </ItemGroup>\n   <ItemDefinitionGroup>\n-    <ClCompile>\n-\t <PreprocessorDefinitions>HAVE_CRC32C=0;HAVE_SNAPPY=0;__STDC_LIMIT_MACROS;LEVELDB_IS_BIG_ENDIAN=0;_UNICODE;UNICODE;_CRT_NONSTDC_NO_DEPRECATE;LEVELDB_PLATFORM_WINDOWS;LEVELDB_ATOMIC_PRESENT;%(PreprocessorDefinitions)</PreprocessorDefinitions>\n-\t <DisableSpecificWarnings>4244;4267;4312;</DisableSpecificWarnings>\n-\t <AdditionalIncludeDirectories>..\\..\\src\\leveldb;..\\..\\src\\leveldb\\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>\n-\t</ClCompile>\n+     <ClCompile>\n+       <PreprocessorDefinitions>HAVE_CRC32C=0;HAVE_SNAPPY=0;__STDC_LIMIT_MACROS;LEVELDB_IS_BIG_ENDIAN=0;_UNICODE;UNICODE;_CRT_NONSTDC_NO_DEPRECATE;LEVELDB_PLATFORM_WINDOWS;LEVELDB_ATOMIC_PRESENT;%(PreprocessorDefinitions)</PreprocessorDefinitions>\n+       <DisableSpecificWarnings>4244;4267;4312;4722;</DisableSpecificWarnings>\n+       <AdditionalIncludeDirectories>..\\..\\src\\leveldb;..\\..\\src\\leveldb\\include;%(AdditionalIncludeDirectories)</AdditionalIncludeDirectories>\n+     </ClCompile>\n   </ItemDefinitionGroup>\n   <Import Project=\"$(VCTargetsPath)\\Microsoft.Cpp.props\" />\n   <Import Project=\"$(VCTargetsPath)\\Microsoft.Cpp.targets\" />"
      }
    ]
  },
  {
    "sha": "677fb8e92380d4deb6a3753047c01f7cf7b5af91",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo2NzdmYjhlOTIzODBkNGRlYjZhMzc1MzA0N2MwMWY3Y2Y3YjVhZjkx",
    "commit": {
      "author": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2019-12-10T03:56:45Z"
      },
      "committer": {
        "name": "Wladimir J. van der Laan",
        "email": "laanwj@protonmail.com",
        "date": "2020-01-28T16:01:48Z"
      },
      "message": "test: Add ubsan surpression for crc32c",
      "tree": {
        "sha": "0a46986ef3c438b37c25e22ead72ca4426c12d28",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/0a46986ef3c438b37c25e22ead72ca4426c12d28"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/677fb8e92380d4deb6a3753047c01f7cf7b5af91",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/677fb8e92380d4deb6a3753047c01f7cf7b5af91",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/677fb8e92380d4deb6a3753047c01f7cf7b5af91",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/677fb8e92380d4deb6a3753047c01f7cf7b5af91/comments",
    "author": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "laanwj",
      "id": 126646,
      "node_id": "MDQ6VXNlcjEyNjY0Ng==",
      "avatar_url": "https://avatars.githubusercontent.com/u/126646?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/laanwj",
      "html_url": "https://github.com/laanwj",
      "followers_url": "https://api.github.com/users/laanwj/followers",
      "following_url": "https://api.github.com/users/laanwj/following{/other_user}",
      "gists_url": "https://api.github.com/users/laanwj/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/laanwj/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/laanwj/subscriptions",
      "organizations_url": "https://api.github.com/users/laanwj/orgs",
      "repos_url": "https://api.github.com/users/laanwj/repos",
      "events_url": "https://api.github.com/users/laanwj/events{/privacy}",
      "received_events_url": "https://api.github.com/users/laanwj/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "8e68bb1ddeca504bedd40aee8492b5478a88c1e5",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/8e68bb1ddeca504bedd40aee8492b5478a88c1e5",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/8e68bb1ddeca504bedd40aee8492b5478a88c1e5"
      }
    ],
    "stats": {
      "total": 1,
      "additions": 1,
      "deletions": 0
    },
    "files": [
      {
        "sha": "098dd292606f671c5c532c8e5d958455a98eab4c",
        "filename": "test/sanitizer_suppressions/ubsan",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/677fb8e92380d4deb6a3753047c01f7cf7b5af91/test/sanitizer_suppressions/ubsan",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/677fb8e92380d4deb6a3753047c01f7cf7b5af91/test/sanitizer_suppressions/ubsan",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/sanitizer_suppressions/ubsan?ref=677fb8e92380d4deb6a3753047c01f7cf7b5af91",
        "patch": "@@ -84,3 +84,4 @@ implicit-signed-integer-truncation:test/skiplist_tests.cpp\n implicit-signed-integer-truncation:torcontrol.cpp\n implicit-unsigned-integer-truncation:crypto/*\n implicit-unsigned-integer-truncation:leveldb/*\n+implicit-integer-sign-change:crc32c/*"
      }
    ]
  }
]