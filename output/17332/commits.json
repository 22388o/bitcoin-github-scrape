[
  {
    "sha": "f862a4c692691f9c73b77233b1a7b8c1615fb1c6",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzpmODYyYTRjNjkyNjkxZjljNzNiNzcyMzNiMWE3YjhjMTYxNWZiMWM2",
    "commit": {
      "author": {
        "name": "Suhas Daftuar",
        "email": "sdaftuar@gmail.com",
        "date": "2019-10-07T19:22:56Z"
      },
      "committer": {
        "name": "Suhas Daftuar",
        "email": "sdaftuar@gmail.com",
        "date": "2019-10-30T16:46:23Z"
      },
      "message": "[refactor] Break up ProcessHeadersMessage() into smaller pieces",
      "tree": {
        "sha": "9240994e1c41e83aab615f290422342851f4fcb8",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/9240994e1c41e83aab615f290422342851f4fcb8"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/f862a4c692691f9c73b77233b1a7b8c1615fb1c6",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/f862a4c692691f9c73b77233b1a7b8c1615fb1c6",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/f862a4c692691f9c73b77233b1a7b8c1615fb1c6",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/f862a4c692691f9c73b77233b1a7b8c1615fb1c6/comments",
    "author": {
      "login": "sdaftuar",
      "id": 7463573,
      "node_id": "MDQ6VXNlcjc0NjM1NzM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sdaftuar",
      "html_url": "https://github.com/sdaftuar",
      "followers_url": "https://api.github.com/users/sdaftuar/followers",
      "following_url": "https://api.github.com/users/sdaftuar/following{/other_user}",
      "gists_url": "https://api.github.com/users/sdaftuar/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
      "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
      "repos_url": "https://api.github.com/users/sdaftuar/repos",
      "events_url": "https://api.github.com/users/sdaftuar/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sdaftuar",
      "id": 7463573,
      "node_id": "MDQ6VXNlcjc0NjM1NzM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sdaftuar",
      "html_url": "https://github.com/sdaftuar",
      "followers_url": "https://api.github.com/users/sdaftuar/followers",
      "following_url": "https://api.github.com/users/sdaftuar/following{/other_user}",
      "gists_url": "https://api.github.com/users/sdaftuar/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
      "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
      "repos_url": "https://api.github.com/users/sdaftuar/repos",
      "events_url": "https://api.github.com/users/sdaftuar/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "3c40bc6726b6dc639c4ca2c00c720bccd4cd4dc7",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3c40bc6726b6dc639c4ca2c00c720bccd4cd4dc7",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/3c40bc6726b6dc639c4ca2c00c720bccd4cd4dc7"
      }
    ],
    "stats": {
      "total": 254,
      "additions": 152,
      "deletions": 102
    },
    "files": [
      {
        "sha": "6d33ad313f09b7de2095079175fbbb48d5902d4d",
        "filename": "src/net_processing.cpp",
        "status": "modified",
        "additions": 152,
        "deletions": 102,
        "changes": 254,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/f862a4c692691f9c73b77233b1a7b8c1615fb1c6/src/net_processing.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/f862a4c692691f9c73b77233b1a7b8c1615fb1c6/src/net_processing.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.cpp?ref=f862a4c692691f9c73b77233b1a7b8c1615fb1c6",
        "patch": "@@ -1638,18 +1638,37 @@ inline void static SendBlockTransactions(const CBlock& block, const BlockTransac\n     connman->PushMessage(pfrom, msgMaker.Make(nSendFlags, NetMsgType::BLOCKTXN, resp));\n }\n \n-bool static ProcessHeadersMessage(CNode *pfrom, CConnman *connman, const std::vector<CBlockHeader>& headers, const CChainParams& chainparams, bool via_compact_block)\n+/**\n+ * Check to make sure that a given headers message should be validated:\n+ *\n+ * - empty messages are discarded\n+ * - unconnecting headers that appear to be block announcements are handled with a GETHEADERS\n+ * - non-continuous headers are rejected\n+ *\n+ * @param[in]  pfrom The peer sending us the headers\n+ * @param[in] connman Network handler, for sending messages back to the peer\n+ * @param[in]  headers The headers that were sent in the network message\n+ * @param[in]  chainparams The params for the chain we want to connect to\n+ * @param[in]  via_compact_block Whether the given header was sent via the compact blocks protocol\n+ * @param[out] received_new_header Whether the headers message contains a previously unknown block header\n+ * @param[out] should_validate Set to false if further processing (validation) should be aborted\n+ *\n+ * Returns false if the peer's headers are non-continuous.\n+ */\n+\n+bool static InspectHeaders(CNode *pfrom, CConnman *connman, const std::vector<CBlockHeader>& headers, const CChainParams& chainparams, bool via_compact_block, bool *received_new_header, bool *should_validate)\n {\n     const CNetMsgMaker msgMaker(pfrom->GetSendVersion());\n+    *should_validate = false;\n+    *received_new_header = false;\n+\n     size_t nCount = headers.size();\n \n     if (nCount == 0) {\n         // Nothing interesting. Stop asking this peers for more headers.\n         return true;\n     }\n \n-    bool received_new_header = false;\n-    const CBlockIndex *pindexLast = nullptr;\n     {\n         LOCK(cs_main);\n         CNodeState *nodestate = State(pfrom->GetId());\n@@ -1693,130 +1712,161 @@ bool static ProcessHeadersMessage(CNode *pfrom, CConnman *connman, const std::ve\n         // If we don't have the last header, then they'll have given us\n         // something new (if these headers are valid).\n         if (!LookupBlockIndex(hashLastBlock)) {\n-            received_new_header = true;\n+            *received_new_header = true;\n         }\n     }\n \n+    *should_validate = true;\n+    return true;\n+}\n+\n+/**\n+ * Validate a given set of headers from a given peer.\n+ *\n+ * Returns false if any fail validation.\n+ *\n+ * @param[out] pindexLast Pointer to the last CBlockIndex added.\n+ */\n+static bool ValidateHeaders(CNode *pfrom, const std::vector<CBlockHeader>& headers, const CChainParams& chainparams, bool via_compact_block, const CBlockIndex **pindexLast)\n+{\n     BlockValidationState state;\n-    if (!ProcessNewBlockHeaders(headers, state, chainparams, &pindexLast)) {\n+    if (!ProcessNewBlockHeaders(headers, state, chainparams, pindexLast)) {\n         if (state.IsInvalid()) {\n             MaybePunishNodeForBlock(pfrom->GetId(), state, via_compact_block, \"invalid header received\");\n             return false;\n         }\n     }\n+    return true;\n+}\n \n-    {\n-        LOCK(cs_main);\n-        CNodeState *nodestate = State(pfrom->GetId());\n-        if (nodestate->nUnconnectingHeaders > 0) {\n-            LogPrint(BCLog::NET, \"peer=%d: resetting nUnconnectingHeaders (%d -> 0)\\n\", pfrom->GetId(), nodestate->nUnconnectingHeaders);\n-        }\n-        nodestate->nUnconnectingHeaders = 0;\n+// Update peer's state after validly processing headers from that peer, and\n+// potentially fetch more headers or blocks from the peer.\n+static bool UpdateHeadersAndMaybeFetch(CNode *pfrom, CConnman *connman, const CBlockIndex *pindexLast, const CChainParams& chainparams, bool request_more_headers, bool received_new_header)\n+{\n+    const CNetMsgMaker msgMaker(pfrom->GetSendVersion());\n \n-        assert(pindexLast);\n-        UpdateBlockAvailability(pfrom->GetId(), pindexLast->GetBlockHash());\n+    LOCK(cs_main);\n+    CNodeState *nodestate = State(pfrom->GetId());\n+    if (nodestate->nUnconnectingHeaders > 0) {\n+        LogPrint(BCLog::NET, \"peer=%d: resetting nUnconnectingHeaders (%d -> 0)\\n\", pfrom->GetId(), nodestate->nUnconnectingHeaders);\n+    }\n+    nodestate->nUnconnectingHeaders = 0;\n \n-        // From here, pindexBestKnownBlock should be guaranteed to be non-null,\n-        // because it is set in UpdateBlockAvailability. Some nullptr checks\n-        // are still present, however, as belt-and-suspenders.\n+    assert(pindexLast);\n+    UpdateBlockAvailability(pfrom->GetId(), pindexLast->GetBlockHash());\n \n-        if (received_new_header && pindexLast->nChainWork > ::ChainActive().Tip()->nChainWork) {\n-            nodestate->m_last_block_announcement = GetTime();\n-        }\n+    // From here, pindexBestKnownBlock should be guaranteed to be non-null,\n+    // because it is set in UpdateBlockAvailability. Some nullptr checks\n+    // are still present, however, as belt-and-suspenders.\n \n-        if (nCount == MAX_HEADERS_RESULTS) {\n-            // Headers message had its maximum size; the peer may have more headers.\n-            // TODO: optimize: if pindexLast is an ancestor of ::ChainActive().Tip or pindexBestHeader, continue\n-            // from there instead.\n-            LogPrint(BCLog::NET, \"more getheaders (%d) to end to peer=%d (startheight:%d)\\n\", pindexLast->nHeight, pfrom->GetId(), pfrom->nStartingHeight);\n-            connman->PushMessage(pfrom, msgMaker.Make(NetMsgType::GETHEADERS, ::ChainActive().GetLocator(pindexLast), uint256()));\n-        }\n-\n-        bool fCanDirectFetch = CanDirectFetch(chainparams.GetConsensus());\n-        // If this set of headers is valid and ends in a block with at least as\n-        // much work as our tip, download as much as possible.\n-        if (fCanDirectFetch && pindexLast->IsValid(BLOCK_VALID_TREE) && ::ChainActive().Tip()->nChainWork <= pindexLast->nChainWork) {\n-            std::vector<const CBlockIndex*> vToFetch;\n-            const CBlockIndex *pindexWalk = pindexLast;\n-            // Calculate all the blocks we'd need to switch to pindexLast, up to a limit.\n-            while (pindexWalk && !::ChainActive().Contains(pindexWalk) && vToFetch.size() <= MAX_BLOCKS_IN_TRANSIT_PER_PEER) {\n-                if (!(pindexWalk->nStatus & BLOCK_HAVE_DATA) &&\n-                        !mapBlocksInFlight.count(pindexWalk->GetBlockHash()) &&\n-                        (!IsWitnessEnabled(pindexWalk->pprev, chainparams.GetConsensus()) || State(pfrom->GetId())->fHaveWitness)) {\n-                    // We don't have this block, and it's not yet in flight.\n-                    vToFetch.push_back(pindexWalk);\n-                }\n-                pindexWalk = pindexWalk->pprev;\n+    if (received_new_header && pindexLast->nChainWork > ::ChainActive().Tip()->nChainWork) {\n+        nodestate->m_last_block_announcement = GetTime();\n+    }\n+\n+    if (request_more_headers) {\n+        // Presumably the headers message had its maximum size, and the peer may have more headers.\n+        // TODO: optimize: if pindexLast is an ancestor of ::ChainActive().Tip or pindexBestHeader, continue\n+        // from there instead.\n+        LogPrint(BCLog::NET, \"more getheaders (%d) to end to peer=%d (startheight:%d)\\n\", pindexLast->nHeight, pfrom->GetId(), pfrom->nStartingHeight);\n+        connman->PushMessage(pfrom, msgMaker.Make(NetMsgType::GETHEADERS, ::ChainActive().GetLocator(pindexLast), uint256()));\n+    }\n+\n+    bool fCanDirectFetch = CanDirectFetch(chainparams.GetConsensus());\n+    // If this set of headers is valid and ends in a block with at least as\n+    // much work as our tip, download as much as possible.\n+    if (fCanDirectFetch && pindexLast->IsValid(BLOCK_VALID_TREE) && ::ChainActive().Tip()->nChainWork <= pindexLast->nChainWork) {\n+        std::vector<const CBlockIndex*> vToFetch;\n+        const CBlockIndex *pindexWalk = pindexLast;\n+        // Calculate all the blocks we'd need to switch to pindexLast, up to a limit.\n+        while (pindexWalk && !::ChainActive().Contains(pindexWalk) && vToFetch.size() <= MAX_BLOCKS_IN_TRANSIT_PER_PEER) {\n+            if (!(pindexWalk->nStatus & BLOCK_HAVE_DATA) &&\n+                    !mapBlocksInFlight.count(pindexWalk->GetBlockHash()) &&\n+                    (!IsWitnessEnabled(pindexWalk->pprev, chainparams.GetConsensus()) || State(pfrom->GetId())->fHaveWitness)) {\n+                // We don't have this block, and it's not yet in flight.\n+                vToFetch.push_back(pindexWalk);\n             }\n-            // If pindexWalk still isn't on our main chain, we're looking at a\n-            // very large reorg at a time we think we're close to caught up to\n-            // the main chain -- this shouldn't really happen.  Bail out on the\n-            // direct fetch and rely on parallel download instead.\n-            if (!::ChainActive().Contains(pindexWalk)) {\n-                LogPrint(BCLog::NET, \"Large reorg, won't direct fetch to %s (%d)\\n\",\n-                        pindexLast->GetBlockHash().ToString(),\n-                        pindexLast->nHeight);\n-            } else {\n-                std::vector<CInv> vGetData;\n-                // Download as much as possible, from earliest to latest.\n-                for (const CBlockIndex *pindex : reverse_iterate(vToFetch)) {\n-                    if (nodestate->nBlocksInFlight >= MAX_BLOCKS_IN_TRANSIT_PER_PEER) {\n-                        // Can't download any more from this peer\n-                        break;\n-                    }\n-                    uint32_t nFetchFlags = GetFetchFlags(pfrom);\n-                    vGetData.push_back(CInv(MSG_BLOCK | nFetchFlags, pindex->GetBlockHash()));\n-                    MarkBlockAsInFlight(pfrom->GetId(), pindex->GetBlockHash(), pindex);\n-                    LogPrint(BCLog::NET, \"Requesting block %s from  peer=%d\\n\",\n-                            pindex->GetBlockHash().ToString(), pfrom->GetId());\n-                }\n-                if (vGetData.size() > 1) {\n-                    LogPrint(BCLog::NET, \"Downloading blocks toward %s (%d) via headers direct fetch\\n\",\n-                            pindexLast->GetBlockHash().ToString(), pindexLast->nHeight);\n+            pindexWalk = pindexWalk->pprev;\n+        }\n+        // If pindexWalk still isn't on our main chain, we're looking at a\n+        // very large reorg at a time we think we're close to caught up to\n+        // the main chain -- this shouldn't really happen.  Bail out on the\n+        // direct fetch and rely on parallel download instead.\n+        if (!::ChainActive().Contains(pindexWalk)) {\n+            LogPrint(BCLog::NET, \"Large reorg, won't direct fetch to %s (%d)\\n\",\n+                    pindexLast->GetBlockHash().ToString(),\n+                    pindexLast->nHeight);\n+        } else {\n+            std::vector<CInv> vGetData;\n+            // Download as much as possible, from earliest to latest.\n+            for (const CBlockIndex *pindex : reverse_iterate(vToFetch)) {\n+                if (nodestate->nBlocksInFlight >= MAX_BLOCKS_IN_TRANSIT_PER_PEER) {\n+                    // Can't download any more from this peer\n+                    break;\n                 }\n-                if (vGetData.size() > 0) {\n-                    if (nodestate->fSupportsDesiredCmpctVersion && vGetData.size() == 1 && mapBlocksInFlight.size() == 1 && pindexLast->pprev->IsValid(BLOCK_VALID_CHAIN)) {\n-                        // In any case, we want to download using a compact block, not a regular one\n-                        vGetData[0] = CInv(MSG_CMPCT_BLOCK, vGetData[0].hash);\n-                    }\n-                    connman->PushMessage(pfrom, msgMaker.Make(NetMsgType::GETDATA, vGetData));\n+                uint32_t nFetchFlags = GetFetchFlags(pfrom);\n+                vGetData.push_back(CInv(MSG_BLOCK | nFetchFlags, pindex->GetBlockHash()));\n+                MarkBlockAsInFlight(pfrom->GetId(), pindex->GetBlockHash(), pindex);\n+                LogPrint(BCLog::NET, \"Requesting block %s from  peer=%d\\n\",\n+                        pindex->GetBlockHash().ToString(), pfrom->GetId());\n+            }\n+            if (vGetData.size() > 1) {\n+                LogPrint(BCLog::NET, \"Downloading blocks toward %s (%d) via headers direct fetch\\n\",\n+                        pindexLast->GetBlockHash().ToString(), pindexLast->nHeight);\n+            }\n+            if (vGetData.size() > 0) {\n+                if (nodestate->fSupportsDesiredCmpctVersion && vGetData.size() == 1 && mapBlocksInFlight.size() == 1 && pindexLast->pprev->IsValid(BLOCK_VALID_CHAIN)) {\n+                    // In any case, we want to download using a compact block, not a regular one\n+                    vGetData[0] = CInv(MSG_CMPCT_BLOCK, vGetData[0].hash);\n                 }\n+                connman->PushMessage(pfrom, msgMaker.Make(NetMsgType::GETDATA, vGetData));\n             }\n         }\n-        // If we're in IBD, we want outbound peers that will serve us a useful\n-        // chain. Disconnect peers that are on chains with insufficient work.\n-        if (::ChainstateActive().IsInitialBlockDownload() && nCount != MAX_HEADERS_RESULTS) {\n-            // When nCount < MAX_HEADERS_RESULTS, we know we have no more\n-            // headers to fetch from this peer.\n-            if (nodestate->pindexBestKnownBlock && nodestate->pindexBestKnownBlock->nChainWork < nMinimumChainWork) {\n-                // This peer has too little work on their headers chain to help\n-                // us sync -- disconnect if using an outbound slot (unless\n-                // whitelisted or addnode).\n-                // Note: We compare their tip to nMinimumChainWork (rather than\n-                // ::ChainActive().Tip()) because we won't start block download\n-                // until we have a headers chain that has at least\n-                // nMinimumChainWork, even if a peer has a chain past our tip,\n-                // as an anti-DoS measure.\n-                if (IsOutboundDisconnectionCandidate(pfrom)) {\n-                    LogPrintf(\"Disconnecting outbound peer %d -- headers chain has insufficient work\\n\", pfrom->GetId());\n-                    pfrom->fDisconnect = true;\n-                }\n+    }\n+    // If we're in IBD, we want outbound peers that will serve us a useful\n+    // chain. Disconnect peers that are on chains with insufficient work.\n+    if (::ChainstateActive().IsInitialBlockDownload() && !request_more_headers) {\n+        // We know we have no more headers to fetch from this peer.\n+        if (nodestate->pindexBestKnownBlock && nodestate->pindexBestKnownBlock->nChainWork < nMinimumChainWork) {\n+            // This peer has too little work on their headers chain to help\n+            // us sync -- disconnect if using an outbound slot (unless\n+            // whitelisted or addnode).\n+            // Note: We compare their tip to nMinimumChainWork (rather than\n+            // ::ChainActive().Tip()) because we won't start block download\n+            // until we have a headers chain that has at least\n+            // nMinimumChainWork, even if a peer has a chain past our tip,\n+            // as an anti-DoS measure.\n+            if (IsOutboundDisconnectionCandidate(pfrom)) {\n+                LogPrintf(\"Disconnecting outbound peer %d -- headers chain has insufficient work\\n\", pfrom->GetId());\n+                pfrom->fDisconnect = true;\n             }\n         }\n+    }\n \n-        if (!pfrom->fDisconnect && IsOutboundDisconnectionCandidate(pfrom) && nodestate->pindexBestKnownBlock != nullptr && pfrom->m_tx_relay != nullptr) {\n-            // If this is an outbound full-relay peer, check to see if we should protect\n-            // it from the bad/lagging chain logic.\n-            // Note that block-relay-only peers are already implicitly protected, so we\n-            // only consider setting m_protect for the full-relay peers.\n-            if (g_outbound_peers_with_protect_from_disconnect < MAX_OUTBOUND_PEERS_TO_PROTECT_FROM_DISCONNECT && nodestate->pindexBestKnownBlock->nChainWork >= ::ChainActive().Tip()->nChainWork && !nodestate->m_chain_sync.m_protect) {\n-                LogPrint(BCLog::NET, \"Protecting outbound peer=%d from eviction\\n\", pfrom->GetId());\n-                nodestate->m_chain_sync.m_protect = true;\n-                ++g_outbound_peers_with_protect_from_disconnect;\n-            }\n+    if (!pfrom->fDisconnect && IsOutboundDisconnectionCandidate(pfrom) && nodestate->pindexBestKnownBlock != nullptr && pfrom->m_tx_relay != nullptr) {\n+        // If this is an outbound full-relay peer, check to see if we should protect\n+        // it from the bad/lagging chain logic.\n+        // Note that block-relay-only peers are already implicitly protected, so we\n+        // only consider setting m_protect for the full-relay peers.\n+        if (g_outbound_peers_with_protect_from_disconnect < MAX_OUTBOUND_PEERS_TO_PROTECT_FROM_DISCONNECT && nodestate->pindexBestKnownBlock->nChainWork >= ::ChainActive().Tip()->nChainWork && !nodestate->m_chain_sync.m_protect) {\n+            LogPrint(BCLog::NET, \"Protecting outbound peer=%d from eviction\\n\", pfrom->GetId());\n+            nodestate->m_chain_sync.m_protect = true;\n+            ++g_outbound_peers_with_protect_from_disconnect;\n         }\n     }\n+    return true;\n+}\n \n+// Handler for receiving a HEADERS message from a peer\n+bool static ProcessHeadersMessage(CNode *pfrom, CConnman *connman, const std::vector<CBlockHeader>& headers, const CChainParams& chainparams, bool via_compact_block)\n+{\n+    bool should_validate = false;\n+    bool received_new_header = false;\n+    if (!InspectHeaders(pfrom, connman, headers, chainparams, via_compact_block, &received_new_header, &should_validate)) return false;\n+    if (should_validate) {\n+        const CBlockIndex *pindexLast = nullptr;\n+        if (!ValidateHeaders(pfrom, headers, chainparams, via_compact_block, &pindexLast)) return false;\n+        if (!UpdateHeadersAndMaybeFetch(pfrom, connman, pindexLast, chainparams, headers.size() == MAX_HEADERS_RESULTS, received_new_header)) return false;\n+    }\n     return true;\n }\n "
      }
    ]
  },
  {
    "sha": "06da4d62a888dc63d7ed0685471d501d80efa817",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzowNmRhNGQ2MmE4ODhkYzYzZDdlZDA2ODU0NzFkNTAxZDgwZWZhODE3",
    "commit": {
      "author": {
        "name": "Suhas Daftuar",
        "email": "sdaftuar@gmail.com",
        "date": "2019-10-02T15:32:17Z"
      },
      "committer": {
        "name": "Suhas Daftuar",
        "email": "sdaftuar@gmail.com",
        "date": "2019-10-31T18:05:50Z"
      },
      "message": "Improve DoS-resistance to low-work headers chains\n\nA low-work headers chain might be valid according to consensus rules, yet\nuninteresting for reaching consensus, because of the little work on the chain.\nCurrently, a low-work headers chain that is received by bitcoind is\nnevertheless stored in memory (permanently), because the headers download logic\nstores valid headers as it goes, and we only look at the total work on the\nchain at a later point.\n\nBy definition, a low-work headers chain can be cheap to produce, so the cost to\nan adversary for performing a memory DoS (on the entire network of reachable\nnodes) is not very high.\n\nIdeally, the cost to making a node store a headers chain should be related to\nthe total work on the best chain, as we're only ever interested in the most\nwork chain for consensus purposes. (If an adversary is able to perform a memory\nDoS by producing a headers chain with work comparable to the work on the best\nchain, there's not much we could do about it, as a node must be aware of all\nheaders chains that potentially have the most work in order to remain in\nconsensus. So requiring that a headers chain have work comparable to the\nmost-work chain before we store it is essentially the best we can do.)\n\nThis patch introduces a headers download scheme that attempts to verify that a\npeer's headers chain has sufficient work (namely, within a week of our current\ntip and at least as much work as nMinimumChainWork) before committing to\npermanent storage.\n\nIf a peer gives us a headers message whose last header has less work than our\nanti-DoS threshold, then we store those headers in memory that is allocated to\njust that peer, until we've seen a chain tip building on those headers that has\nsufficient work. At that point, the headers will be processed and stored\nglobally.\n\nBecause of the time-warp problem, where a chain producing blocks at a rate of 6\nblocks/second can theoretically be valid even while being low-work, we have to\nconsider the possibility of being fed a very long, low-work chain. If we stored\nall of a peer's headers even in temporary memory, this could be enough to be a\nmemory DoS by itself. To address this, this patch uses a heuristic to cache\njust the last header in each message if the time on the chain is progressing\nslower than expected. If the chain ends up having sufficient work, then we\ncan redownload the chain, verifying that we get the same headers back by using\nthese cached headers as intermediate markers that must match the redownloaded\nchain.\n\nUsing this scheme, we can bound the memory used for headers download by a\nsingle peer to roughly the amount of memory we'd expect an \"honest\" chain to\nuse (1 block header per 10 minutes starting at the genesis block).  To prevent\nan adversary from using many inbound peers to flood a node's memory due to\nsimultaneous headers sync, this patch also includes logic to restrict using the\nper-peer headers sync memory by more than one peer at a time, along with timeout\nlogic to prevent a single peer from starving headers sync from other peers.",
      "tree": {
        "sha": "ea369c9c0098945d97e0108758bacaf4d2984af5",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/ea369c9c0098945d97e0108758bacaf4d2984af5"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/06da4d62a888dc63d7ed0685471d501d80efa817",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/06da4d62a888dc63d7ed0685471d501d80efa817",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/06da4d62a888dc63d7ed0685471d501d80efa817",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/06da4d62a888dc63d7ed0685471d501d80efa817/comments",
    "author": {
      "login": "sdaftuar",
      "id": 7463573,
      "node_id": "MDQ6VXNlcjc0NjM1NzM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sdaftuar",
      "html_url": "https://github.com/sdaftuar",
      "followers_url": "https://api.github.com/users/sdaftuar/followers",
      "following_url": "https://api.github.com/users/sdaftuar/following{/other_user}",
      "gists_url": "https://api.github.com/users/sdaftuar/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
      "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
      "repos_url": "https://api.github.com/users/sdaftuar/repos",
      "events_url": "https://api.github.com/users/sdaftuar/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sdaftuar",
      "id": 7463573,
      "node_id": "MDQ6VXNlcjc0NjM1NzM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/7463573?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sdaftuar",
      "html_url": "https://github.com/sdaftuar",
      "followers_url": "https://api.github.com/users/sdaftuar/followers",
      "following_url": "https://api.github.com/users/sdaftuar/following{/other_user}",
      "gists_url": "https://api.github.com/users/sdaftuar/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sdaftuar/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sdaftuar/subscriptions",
      "organizations_url": "https://api.github.com/users/sdaftuar/orgs",
      "repos_url": "https://api.github.com/users/sdaftuar/repos",
      "events_url": "https://api.github.com/users/sdaftuar/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sdaftuar/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "f862a4c692691f9c73b77233b1a7b8c1615fb1c6",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/f862a4c692691f9c73b77233b1a7b8c1615fb1c6",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/f862a4c692691f9c73b77233b1a7b8c1615fb1c6"
      }
    ],
    "stats": {
      "total": 553,
      "additions": 541,
      "deletions": 12
    },
    "files": [
      {
        "sha": "54325265a054a70e3ba9bdb33d513b3d5a87060e",
        "filename": "src/net_processing.cpp",
        "status": "modified",
        "additions": 494,
        "deletions": 11,
        "changes": 505,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/06da4d62a888dc63d7ed0685471d501d80efa817/src/net_processing.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/06da4d62a888dc63d7ed0685471d501d80efa817/src/net_processing.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.cpp?ref=06da4d62a888dc63d7ed0685471d501d80efa817",
        "patch": "@@ -78,8 +78,12 @@ static constexpr std::chrono::microseconds MAX_GETDATA_RANDOM_DELAY{std::chrono:\n static constexpr std::chrono::microseconds TX_EXPIRY_INTERVAL{GETDATA_TX_INTERVAL * 10};\n static_assert(INBOUND_PEER_TX_DELAY >= MAX_GETDATA_RANDOM_DELAY,\n \"To preserve security, MAX_GETDATA_RANDOM_DELAY should not exceed INBOUND_PEER_DELAY\");\n+/* How much MTP (in seconds) must elapse in a full headers message to store the set of headers, rather than just the hash of the last block header */\n+static const int64_t MIN_MTP_INCREASE_FOR_STORAGE = 24*3600*10;\n /** Limit to avoid sending big packets. Not used in processing incoming GETDATA for compatibility */\n static const unsigned int MAX_GETDATA_SZ = 1000;\n+/** Implied consensus limit on the minimum time on the 2000th header of headers message, relative to the MTP of the last header in the prior header message */\n+static const int64_t MIN_MTP_INCREASE_PER_HEADERS_BATCH = 333; // 2000/6; MTP rule implies at most 6 blocks per second\n \n \n struct COrphanTx {\n@@ -191,6 +195,10 @@ namespace {\n \n     static size_t vExtraTxnForCompactIt GUARDED_BY(g_cs_orphans) = 0;\n     static std::vector<std::pair<uint256, CTransactionRef>> vExtraTxnForCompact GUARDED_BY(g_cs_orphans);\n+\n+    /** The peer that is permitted to continue adding headers to its\n+     * m_headers_sync_state (see below) */\n+    NodeId g_headers_sync_peer GUARDED_BY(cs_main) = -1;\n } // namespace\n \n namespace {\n@@ -353,6 +361,173 @@ struct CNodeState {\n     //! Whether this peer is a manual connection\n     bool m_is_manual_connection;\n \n+    /* Per-peer state associated with headers download of low-work headers\n+     *\n+     * Header with low cumulative work should not be stored in our block index,\n+     * to prevent memory DoS. We avoid this by only committing a header to the\n+     * block index if it has some descendant with sufficient work (at least as\n+     * much work as nMinimumChainWork and within some recent window of our\n+     * current tip).\n+     *\n+     * For headers with nChainWork greater than the bound, we will validate and\n+     * store as long as they are well-formed (the headers connect to each other\n+     * and build off a known header).\n+     *\n+     * For headers with nChainWork below the bound, we only commit the headers\n+     * to per-peer storage, which will be deleted if:\n+     * - the headers don't result in a sufficient-work chain, as defined above\n+     * - the peer disconnects\n+     * - something goes wrong with the headers download process (eg we receive\n+     *   headers that don't build off prior headers; this would reset the\n+     *   process)\n+     *\n+     * Ideally we would store all headers from a given peer until the headers\n+     * chain has sufficient work, and at that point we would process. However,\n+     * because of the time-warp problem, it's possible to cheaply produce\n+     * extremely long headers chains (using many gigabytes of memory). To avoid\n+     * such memory DoS, if a headers chain isn't advancing time quickly enough\n+     * (calculated by looking at average MTP elapsed time on each headers\n+     * message (2000 headers) and comparing against\n+     * MIN_MTP_INCREASE_FOR_STORAGE (10 days)), then instead of storing all the\n+     * headers from that peer as we go, we will instead just store the final\n+     * block hash from each headers message. This drastically reduces the\n+     * memory used in evaluating the headers chain, and is sufficient\n+     * information to allow us to redownload the chain and verify that we're\n+     * getting the same chain again, and thus can go ahead and fully validate\n+     * and store those headers permanently.\n+     *\n+     * In the case of what we think of as the honest mainnet chain, these\n+     * parameters result in us downloading the headers once, and once we cross\n+     * the nMinimumChainWork threshold, we process all and continue downloading\n+     * the rest.\n+     *\n+     * In the case of an adversary giving us a headers chain mined at the\n+     * fastest possible rate possible under consensus rules (eg by using\n+     * time-warp as well to ensure the difficulty remains at 1), storing 1\n+     * block hash every 2000 results in using approximately the same amount of\n+     * memory as the honest chain would require us to use, anyway.\n+     *\n+     * To bound memory across peers, we only allow one peer at a time to use\n+     * more than a small, bounded amount of CNodeState memory. A peer using its\n+     * per-peer memory for headers will have its nodeid put in\n+     * g_headers_sync_peers, which permits it to make subsequent headers\n+     * requests and continue to use more memory, while peers that are waiting\n+     * to be able to use their per-peer memory set m_try_continue_sync, which\n+     * is checked from time to time across all peers to determine which peer\n+     * syncs next.\n+     *\n+     * To prevent the designated HeadersSyncPeer from stalling headers download\n+     * from other peers, we use two strategies:\n+     * - once we have a headers chain that is more than nMinimumChainWork and\n+     *   within 24 hours of the tip, we'll send a getheaders to all our peers.\n+     *   Those responses may be processed without using any peer-local state,\n+     *   eg because their headers build off something with more than\n+     *   nMinimumChainWork and within a week of our tip.\n+     * - If we detect that we have more than one peer that needs to use its\n+     *   peer-storage in order to sync headers, then we enable a timeout on the\n+     *   peer holding the HeadersSyncPeer position, so that after the timeout\n+     *   if there's a peer waiting, the sync will be abandoned to give the\n+     *   other peer a chance to sync.\n+     */\n+\n+    struct HeadersSyncState {\n+        arith_uint256 m_cumulative_chain_work; // work on the chain we're processing, so far\n+\n+        // We use a list of hashes to store a fingerprint of a peer's chain as\n+        // we go, if it looks like their chain is longer than we expect (more\n+        // than a block every 10 minutes)\n+        std::list<uint256> m_header_cache;\n+\n+        // Otherwise, We directly store all our peer's headers if their\n+        // timestamps seem reasonable.\n+        // Note: we'll only store headers in one place; either all of them are\n+        // in m_stored_headers, or 1 hash every 2000 in m_header_cache.\n+        std::vector<CBlockHeader> m_stored_headers;\n+\n+        uint256 m_sufficient_work_hash; // hash of the block that has enough work to justify permanent storage of these headers\n+\n+        // These are used for the heuristic regarding whether the peer's chain\n+        // looks longer than expected. We store the MTP of the last block in\n+        // each headers message (m_mtp_last_block). We calculate the MTP for\n+        // the last block in each headers message, and if the average increase\n+        // of MTP from one message to the next is below\n+        // MIN_MTP_INCREASE_FOR_STORAGE, we will stop using m_stored_headers\n+        // and only use m_header_cache to track the peer's headers chain.\n+        int64_t m_mtp_advanced{0};\n+        int64_t m_intervals_seen{0};\n+        int64_t m_mtp_last_block{0};\n+\n+        // We only permit one peer at a time to use more than 1 \"entry\" (either\n+        // a set of 2000 headers from one headers message, or a single block\n+        // hash stored in m_header_cache) in this sync state object.\n+        // If another peer is already assigned to be the sync peer, we will\n+        // pause headers sync for other peers that would need to use additional\n+        // memory by setting m_try_continue_sync and waiting for the sync peer\n+        // to finish.\n+        // The next sync peer will be the one who started waiting first.\n+        std::chrono::microseconds m_try_continue_sync{0}; // the time at which we realized we want to sync further\n+\n+        // To prevent the sync peer from starving other peers from being able\n+        // to sync, we set a timeout at the time the sync peer is assigned,\n+        // which is based on how long we expect their blockchain to be (using\n+        // consensus pow-target-spacing and the time between now and the\n+        // genesis block). If at the end of that time the peer is still syncing\n+        // and some other peer is waiting to sync, we'll abort, clearing all\n+        // memory for that peer and allowing a new sync peer to be assigned.\n+        std::chrono::microseconds m_headers_sync_peer_timeout{0};\n+\n+        // Return the last block hash in the last headers message received from\n+        // this peer\n+        uint256 GetLastBlockHash() {\n+            if (!m_stored_headers.empty()) return m_stored_headers.back().GetHash();\n+            if (!m_header_cache.empty()) return m_header_cache.back();\n+            return uint256();\n+        }\n+\n+        // Add a set of headers to our stored state for this peer. Once we\n+        // start using the header cache, we never switch back to using\n+        // m_stored_headers. Otherwise, as long as the chain continues to pass\n+        // the threshold for time passage with each headers message (on\n+        // average), we'll continue storing all the headers received.\n+        void AddHeaders(const std::vector<CBlockHeader> &headers, int64_t min_average_time_passed, int64_t last_block_mtp) {\n+            if (m_mtp_advanced / m_intervals_seen > min_average_time_passed && m_header_cache.empty()) {\n+                m_stored_headers.insert(m_stored_headers.end(), headers.begin(), headers.end());\n+            } else {\n+                // Only use the header cache; empty out the stored headers if necessary.\n+                size_t headers_stored = m_stored_headers.size();\n+                if (headers_stored > 0) {\n+                    for (auto i=MAX_HEADERS_RESULTS-1; i<headers_stored; i += MAX_HEADERS_RESULTS) {\n+                        m_header_cache.emplace_back(m_stored_headers[i].GetHash());\n+                    }\n+                    m_stored_headers.clear();\n+                }\n+                m_header_cache.emplace_back(headers.back().GetHash());\n+            }\n+            // Update last block mtp\n+            m_mtp_last_block = last_block_mtp;\n+        }\n+\n+        // Whether we're using any storage for this peer\n+        bool IsEmpty() const {\n+            return m_header_cache.empty() && m_stored_headers.empty();\n+        }\n+\n+        // Reset all state\n+        void Clear() {\n+            m_header_cache.clear();\n+            std::vector<CBlockHeader>().swap(m_stored_headers);\n+            m_cumulative_chain_work = arith_uint256();\n+            m_sufficient_work_hash = uint256();\n+            m_mtp_advanced = 0;\n+            m_intervals_seen = 0;\n+            m_mtp_last_block = 0;\n+            m_try_continue_sync = std::chrono::microseconds(0);\n+            m_headers_sync_peer_timeout = std::chrono::microseconds(0);\n+        }\n+    };\n+\n+    HeadersSyncState m_headers_sync_state;\n+\n     CNodeState(CAddress addrIn, std::string addrNameIn, bool is_inbound, bool is_manual) :\n         address(addrIn), name(std::move(addrNameIn)), m_is_inbound(is_inbound),\n         m_is_manual_connection (is_manual)\n@@ -406,6 +581,58 @@ static void UpdatePreferredDownload(CNode* node, CNodeState* state) EXCLUSIVE_LO\n     nPreferredDownload += state->fPreferredDownload;\n }\n \n+// Calculate a timeout for headers sync from a given peer, based on the\n+// expected download time of a chain that has 1 block per nPowTargetSpacing\n+// from the known block header being built from.\n+static std::chrono::microseconds GetTimeout(const Consensus::Params &consensusParams, int64_t block_time_start)\n+{\n+    return GetTime<std::chrono::microseconds>() + std::chrono::microseconds(HEADERS_DOWNLOAD_TIMEOUT_BASE + HEADERS_DOWNLOAD_TIMEOUT_PER_HEADER * (GetAdjustedTime() - block_time_start)/consensusParams.nPowTargetSpacing);\n+}\n+\n+static void SetHeadersSyncPeer(NodeId nodeid, std::chrono::microseconds timeout) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n+{\n+    assert(g_headers_sync_peer == -1);\n+    State(nodeid)->m_headers_sync_state.m_headers_sync_peer_timeout = timeout;\n+    g_headers_sync_peer = nodeid;\n+}\n+\n+static void RemoveHeadersSyncPeer(NodeId nodeid) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n+{\n+    if (g_headers_sync_peer == nodeid) g_headers_sync_peer = -1;\n+}\n+\n+static bool IsHeadersSyncPeer(NodeId nodeid) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n+{\n+    return g_headers_sync_peer == nodeid;\n+}\n+\n+static bool HaveHeadersSyncPeer() EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n+{\n+    return g_headers_sync_peer != -1;\n+}\n+\n+static void ClearHeadersSyncState(CNodeState *nodestate, NodeId nodeid) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n+{\n+    nodestate->m_headers_sync_state.Clear();\n+    nodestate->m_headers_sync_state.m_try_continue_sync = std::chrono::microseconds(0);\n+    RemoveHeadersSyncPeer(nodeid);\n+}\n+\n+// Find the peer who has been waiting longest to continue syncing\n+static NodeId GetNextHeadersSyncPeer() EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n+{\n+    NodeId node_waiting_for_sync = -1;\n+    std::chrono::microseconds wait_start_time(0);\n+    for (auto it = mapNodeState.begin(); it != mapNodeState.end(); ++it) {\n+        const auto& peer_wait_time = it->second.m_headers_sync_state.m_try_continue_sync;\n+        if (peer_wait_time > std::chrono::microseconds(0) && peer_wait_time < wait_start_time) {\n+            wait_start_time = peer_wait_time;\n+            node_waiting_for_sync = it->first;\n+        }\n+    }\n+    return node_waiting_for_sync;\n+}\n+\n static void PushNodeVersion(CNode *pnode, CConnman* connman, int64_t nTime)\n {\n     // Note that pnode->GetLocalServices() is a reflection of the local\n@@ -794,6 +1021,8 @@ void PeerLogicValidation::FinalizeNode(NodeId nodeid, bool& fUpdateConnectionTim\n     g_outbound_peers_with_protect_from_disconnect -= state->m_chain_sync.m_protect;\n     assert(g_outbound_peers_with_protect_from_disconnect >= 0);\n \n+    RemoveHeadersSyncPeer(nodeid);\n+\n     mapNodeState.erase(nodeid);\n \n     if (mapNodeState.empty()) {\n@@ -1644,6 +1873,8 @@ inline void static SendBlockTransactions(const CBlock& block, const BlockTransac\n  * - empty messages are discarded\n  * - unconnecting headers that appear to be block announcements are handled with a GETHEADERS\n  * - non-continuous headers are rejected\n+ * - if cumulative work on the chain is below our work threshold, anti-DoS\n+ *   behavior is invoked - see comments in CNodeState above.\n  *\n  * @param[in]  pfrom The peer sending us the headers\n  * @param[in] connman Network handler, for sending messages back to the peer\n@@ -1664,24 +1895,32 @@ bool static InspectHeaders(CNode *pfrom, CConnman *connman, const std::vector<CB\n \n     size_t nCount = headers.size();\n \n-    if (nCount == 0) {\n-        // Nothing interesting. Stop asking this peers for more headers.\n-        return true;\n-    }\n-\n     {\n         LOCK(cs_main);\n         CNodeState *nodestate = State(pfrom->GetId());\n \n+        if (nCount == 0) {\n+            if (!nodestate->m_headers_sync_state.IsEmpty()) {\n+                // If we get an empty headers message before we have crossed\n+                // the minchainwork threshold for considering whatever headers\n+                // we've been caching, throw it all away.\n+                ClearHeadersSyncState(nodestate, pfrom->GetId());\n+            }\n+            // Nothing interesting. Stop asking this peers for more headers.\n+            return true;\n+        }\n+\n         // If this looks like it could be a block announcement (nCount <\n-        // MAX_BLOCKS_TO_ANNOUNCE), use special logic for handling headers that\n-        // don't connect:\n+        // MAX_BLOCKS_TO_ANNOUNCE, with no headers cached in CNodeState), use\n+        // special logic for handling headers that don't connect:\n         // - Send a getheaders message in response to try to connect the chain.\n         // - The peer can send up to MAX_UNCONNECTING_HEADERS in a row that\n         //   don't connect before giving DoS points\n         // - Once a headers message is received that is valid and does connect,\n         //   nUnconnectingHeaders gets reset back to 0.\n-        if (!LookupBlockIndex(headers[0].hashPrevBlock) && nCount < MAX_BLOCKS_TO_ANNOUNCE) {\n+        const CBlockIndex* chain_start_header  = LookupBlockIndex(headers[0].hashPrevBlock);\n+        bool first_header_connects_to_block_index = chain_start_header != nullptr;\n+        if (!first_header_connects_to_block_index && nCount < MAX_BLOCKS_TO_ANNOUNCE && nodestate->m_headers_sync_state.IsEmpty()) {\n             nodestate->nUnconnectingHeaders++;\n             connman->PushMessage(pfrom, msgMaker.Make(NetMsgType::GETHEADERS, ::ChainActive().GetLocator(pindexBestHeader), uint256()));\n             LogPrint(BCLog::NET, \"received header %s: missing prev block %s, sending getheaders (%d) to end (peer=%d, nUnconnectingHeaders=%d)\\n\",\n@@ -1714,8 +1953,180 @@ bool static InspectHeaders(CNode *pfrom, CConnman *connman, const std::vector<CB\n         if (!LookupBlockIndex(hashLastBlock)) {\n             *received_new_header = true;\n         }\n-    }\n \n+        // Anti-DoS thresholds\n+        arith_uint256 minimum_chain_work = ::ChainActive().Tip()->nChainWork;\n+        if (minimum_chain_work >= 1008*GetBlockProof(*::ChainActive().Tip())) {\n+            minimum_chain_work -= 1008*GetBlockProof(*::ChainActive().Tip());\n+        } else {\n+            minimum_chain_work = 0;\n+        }\n+        if (minimum_chain_work < nMinimumChainWork) minimum_chain_work = nMinimumChainWork;\n+\n+        // Don't accept headers unless the last one has enough work\n+        if (first_header_connects_to_block_index) {\n+            if (!nodestate->m_headers_sync_state.m_sufficient_work_hash.IsNull()) {\n+                // If we have previously validated a headers chain as having\n+                // sufficient work, then this might be us re-downloading.\n+                // Ensure that this chain matches what we previously cached.\n+                if (!nodestate->m_headers_sync_state.m_stored_headers.empty()) {\n+                    // This should be impossible.\n+                    // Clear sync state and continue processing these headers\n+                    // as though there were no sync in progress.\n+                    ClearHeadersSyncState(nodestate, pfrom->GetId());\n+                } else if (nodestate->m_headers_sync_state.m_header_cache.empty()) {\n+                    // This should also be impossible!\n+                    ClearHeadersSyncState(nodestate, pfrom->GetId());\n+                } else if (nodestate->m_headers_sync_state.m_header_cache.front() == headers.back().GetHash()) {\n+                    // This is the block hash we expected.\n+                    *should_validate = true;\n+                    return true;\n+                } else {\n+                    // This is an unexpected block hash!\n+                    ClearHeadersSyncState(nodestate, pfrom->GetId());\n+                }\n+            } else if (!nodestate->m_headers_sync_state.IsEmpty()) {\n+                // If we're not redownloading towards a sufficient-work header,\n+                // and this connects to something in our block index, then we\n+                // should not have a download in progress.\n+                ClearHeadersSyncState(nodestate, pfrom->GetId());\n+            }\n+            arith_uint256 total_work = chain_start_header->nChainWork;\n+            if (total_work < minimum_chain_work) total_work += CalculateHeadersWork(headers);\n+            if (total_work < minimum_chain_work) {\n+                // Our peer is giving us a chain that is below our anti-DoS\n+                // work threshold\n+                if (nCount < MAX_HEADERS_RESULTS) {\n+                    // Discard this message and don't try to sync headers, as\n+                    // the peer is on a too-little-work chain.\n+                    ClearHeadersSyncState(nodestate, pfrom->GetId());\n+                    return true;\n+                } else {\n+                    // This chain might end up having sufficient work. Cache\n+                    // the headers if possible and try to keep downloading.\n+                    // Start by verifying the proof of work on each block\n+                    // matches the claimed amount:\n+                    if (!HasValidProofOfWork(headers, chainparams.GetConsensus())) {\n+                        // This is a DoS-er\n+                        Misbehaving(pfrom->GetId(), 100, \"invalid proof of work\");\n+                        ClearHeadersSyncState(nodestate, pfrom->GetId());\n+                        return true;\n+                    }\n+                    // Ensure that MTP is sufficiently progressing on this chain.\n+                    int64_t last_block_mtp = GetMTPLastHeader(headers);\n+                    if (last_block_mtp - chain_start_header->GetMedianTimePast() < MIN_MTP_INCREASE_PER_HEADERS_BATCH) {\n+                        Misbehaving(pfrom->GetId(), 100, \"invalid header timestamps\");\n+                        ClearHeadersSyncState(nodestate, pfrom->GetId());\n+                        return true;\n+                    }\n+                    if (headers.back().GetBlockTime() > GetAdjustedTime() + MAX_FUTURE_BLOCK_TIME) {\n+                        // This won't validate -- give up for now.\n+                        ClearHeadersSyncState(nodestate, pfrom->GetId());\n+                        return true;\n+                    }\n+                    // We'll cache our progress.\n+                    // Update total work for this peer's chain.\n+                    nodestate->m_headers_sync_state.m_cumulative_chain_work = total_work;\n+                    // If the MTP of this chain is advancing enough, cache\n+                    // these headers in CNodeState\n+                    nodestate->m_headers_sync_state.m_mtp_advanced += last_block_mtp - chain_start_header->GetMedianTimePast();\n+                    nodestate->m_headers_sync_state.m_intervals_seen++;\n+                    nodestate->m_headers_sync_state.AddHeaders(headers, MIN_MTP_INCREASE_FOR_STORAGE, last_block_mtp);\n+                    // For now, only allow one peer at a time to have\n+                    // concurrent downloads, to bound memory usage as tightly\n+                    // as possible.\n+                    if (!HaveHeadersSyncPeer() && nodestate->fSyncStarted && GetNextHeadersSyncPeer() == -1) {\n+                        SetHeadersSyncPeer(pfrom->GetId(), GetTimeout(chainparams.GetConsensus(), headers.back().GetBlockTime()));\n+                    }\n+                    if (IsHeadersSyncPeer(pfrom->GetId())) {\n+                        // Keep downloading from this peer. We set our locator to\n+                        // just be the hash of the last block -- this would only be\n+                        // problematic if our peer somehow reorged away from this\n+                        // chain in-between requests, which should be unlikely for\n+                        // portions of the chain below nMinimumChainWork(!)\n+                        connman->PushMessage(pfrom, msgMaker.Make(NetMsgType::GETHEADERS, CBlockLocator({headers.back().GetHash()}), uint256()));\n+                    } else {\n+                        nodestate->m_headers_sync_state.m_try_continue_sync = GetTime<std::chrono::microseconds>();\n+                    }\n+                    return true;\n+                }\n+            } else {\n+                // Our peer's chain has legitimate work and builds off a known\n+                // block header; set the validation flag for processing/storage.\n+                *should_validate = true;\n+            }\n+        } else {\n+            // This headers message does not build off something stored in our\n+            // block index. This is either a misbehaving peer sending us a\n+            // non-connecting header, or we may be in the middle of initial\n+            // headers sync with this peer and not yet permanently stored their\n+            // headers chain.\n+            // If this is normal headers sync, then this should build off\n+            // something in our peer's cache.\n+            if (nodestate->m_headers_sync_state.GetLastBlockHash() != headers[0].hashPrevBlock) {\n+                // This does not connect to the last header our peer sent us.\n+                // It's possible they've reorged away from their chain in\n+                // between headers requests, but that is very unlikely.\n+                // Clear any download state and give up on headers sync with\n+                // this peer for now. (We can try again later if they announce a\n+                // new block.)\n+                ClearHeadersSyncState(nodestate, pfrom->GetId());\n+                return true;\n+            } else {\n+                // Ensure that we have headers sync going from this peer\n+                // -- if not that would imply an unrequested headers\n+                // message from this peer, which we should drop to avoid memory\n+                // DoS.\n+                if (!IsHeadersSyncPeer(pfrom->GetId()) && HaveHeadersSyncPeer()) {\n+                    // Don't process/store these headers; we have a sync going\n+                    // from some other peer.\n+                    // Set a flag to try this peer again later.\n+                    nodestate->m_headers_sync_state.m_try_continue_sync = GetTime<std::chrono::microseconds>();\n+                    return true;\n+                }\n+                // We are in the middle of downloading our peer's headers chain.\n+                // Once it has sufficient work, we'll permanently store the\n+                // headers in our block index.\n+                // Check that each header has valid proof-of-work.\n+                if (!HasValidProofOfWork(headers, chainparams.GetConsensus())) {\n+                    // This is a DoS-er\n+                    Misbehaving(pfrom->GetId(), 100, \"invalid proof of work\");\n+                    ClearHeadersSyncState(nodestate, pfrom->GetId());\n+                    return false;\n+                }\n+                // Ensure that MTP is sufficiently progressing on this chain.\n+                int64_t last_block_mtp = GetMTPLastHeader(headers);\n+                if (last_block_mtp - nodestate->m_headers_sync_state.m_mtp_last_block < MIN_MTP_INCREASE_PER_HEADERS_BATCH) {\n+                    Misbehaving(pfrom->GetId(), 100, \"invalid header timestamps\");\n+                    ClearHeadersSyncState(nodestate, pfrom->GetId());\n+                    return true;\n+                }\n+                // Check whether the accumulated proof-of-work is now in excess of nMinimumChainWork.\n+                nodestate->m_headers_sync_state.m_cumulative_chain_work += CalculateHeadersWork(headers);\n+                if (nodestate->m_headers_sync_state.m_cumulative_chain_work >= minimum_chain_work) {\n+                    nodestate->m_headers_sync_state.m_sufficient_work_hash = headers.back().GetHash();\n+                    nodestate->m_headers_sync_state.AddHeaders(headers, true, last_block_mtp);\n+                    *should_validate = true;\n+                    return true;\n+                } else {\n+                    // We're still below the anti-DoS threshold; try caching.\n+                    if (!IsHeadersSyncPeer(pfrom->GetId())) {\n+                        // We already checked that either this is the header\n+                        // sync peer, or that we have none -- we only want to\n+                        // set the timeout once, so we check to make sure that\n+                        // we're not already the headers sync peer to avoid\n+                        // bumping it accidentally.\n+                        SetHeadersSyncPeer(pfrom->GetId(), GetTimeout(chainparams.GetConsensus(), headers.back().GetBlockTime()));\n+                    }\n+                    nodestate->m_headers_sync_state.m_mtp_advanced += last_block_mtp - nodestate->m_headers_sync_state.m_mtp_last_block;\n+                    nodestate->m_headers_sync_state.m_intervals_seen++;\n+                    nodestate->m_headers_sync_state.AddHeaders(headers, MIN_MTP_INCREASE_FOR_STORAGE, last_block_mtp);\n+                    connman->PushMessage(pfrom, msgMaker.Make(NetMsgType::GETHEADERS, CBlockLocator({headers.back().GetHash()}), uint256()));\n+                    return true;\n+                }\n+            }\n+        }\n+    }\n     *should_validate = true;\n     return true;\n }\n@@ -1863,8 +2274,38 @@ bool static ProcessHeadersMessage(CNode *pfrom, CConnman *connman, const std::ve\n     bool received_new_header = false;\n     if (!InspectHeaders(pfrom, connman, headers, chainparams, via_compact_block, &received_new_header, &should_validate)) return false;\n     if (should_validate) {\n+        LOCK(cs_main);\n+        CNodeState *nodestate = State(pfrom->GetId());\n         const CBlockIndex *pindexLast = nullptr;\n-        if (!ValidateHeaders(pfrom, headers, chainparams, via_compact_block, &pindexLast)) return false;\n+        bool ret = false;\n+        if (!nodestate->m_headers_sync_state.IsEmpty()) {\n+            if (!nodestate->m_headers_sync_state.m_stored_headers.empty()) {\n+                // In this case we're validating a LOT of headers at once (will get us up to nMinimumChainWork).\n+                ret = ValidateHeaders(pfrom, nodestate->m_headers_sync_state.m_stored_headers, chainparams, /*via_compact_block=*/ false, &pindexLast);\n+                ClearHeadersSyncState(nodestate, pfrom->GetId());\n+            } else if (LookupBlockIndex(headers[0].hashPrevBlock) != nullptr) {\n+                // In this case, we're re-receiving headers that we previously\n+                // downloaded, but this time we're ready to store them.\n+                ret = ValidateHeaders(pfrom, headers, chainparams, /*via_compact_block=*/ false, &pindexLast);\n+                if (!ret) {\n+                    // Clear the sync state for this peer and give up syncing.\n+                    ClearHeadersSyncState(nodestate, pfrom->GetId());\n+                    return false;\n+                }\n+                // Clear the top entry from our list\n+                nodestate->m_headers_sync_state.m_header_cache.pop_front();\n+                // If we have no more cached headers left, clear the whole data structure.\n+                if (nodestate->m_headers_sync_state.IsEmpty()) ClearHeadersSyncState(nodestate, pfrom->GetId());\n+            } else {\n+                // We need to request the headers again, and process them as they come in.\n+                const CNetMsgMaker msgMaker(pfrom->GetSendVersion());\n+                connman->PushMessage(pfrom, msgMaker.Make(NetMsgType::GETHEADERS, ::ChainActive().GetLocator(pindexBestHeader), uint256()));\n+                return true;\n+            }\n+        } else {\n+            ret = ValidateHeaders(pfrom, headers, chainparams, via_compact_block, &pindexLast);\n+        }\n+        if (!ret) return false;\n         if (!UpdateHeadersAndMaybeFetch(pfrom, connman, pindexLast, chainparams, headers.size() == MAX_HEADERS_RESULTS, received_new_header)) return false;\n     }\n     return true;\n@@ -2291,7 +2732,7 @@ bool static ProcessMessage(CNode* pfrom, const std::string& strCommand, CDataStr\n \n             if (inv.type == MSG_BLOCK) {\n                 UpdateBlockAvailability(pfrom->GetId(), inv.hash);\n-                if (!fAlreadyHave && !fImporting && !fReindex && !mapBlocksInFlight.count(inv.hash)) {\n+                if (!fAlreadyHave && !fImporting && !fReindex && !mapBlocksInFlight.count(inv.hash) && !IsHeadersSyncPeer(pfrom->GetId())) {\n                     // We used to request the full block here, but since headers-announcements are now the\n                     // primary method of announcement on the network, and since, in the case that a node\n                     // fell back to inv we probably have a reorg which we should get the headers for first,\n@@ -3682,6 +4123,40 @@ bool PeerLogicValidation::SendMessages(CNode* pto)\n                 LogPrint(BCLog::NET, \"initial getheaders (%d) to peer=%d (startheight:%d)\\n\", pindexStart->nHeight, pto->GetId(), pto->nStartingHeight);\n                 connman->PushMessage(pto, msgMaker.Make(NetMsgType::GETHEADERS, ::ChainActive().GetLocator(pindexStart), uint256()));\n             }\n+        } else if (state.fSyncStarted && state.m_headers_sync_state.m_try_continue_sync > std::chrono::microseconds(0)) {\n+            // We previously started syncing headers with this peer, but we had\n+            // in-flight headers that were being stored from another peer as\n+            // well. Resume syncing from this peer if possible.\n+            if (state.m_headers_sync_state.IsEmpty()) {\n+                // If we somehow have nowhere to continue from, give up.\n+                ClearHeadersSyncState(&state, pto->GetId());\n+            } else if (!HaveHeadersSyncPeer()) {\n+                // We will choose the smallest nodeid to sync from next, among\n+                // all peers that have m_try_continue_sync set.\n+                if (GetNextHeadersSyncPeer() == pto->GetId()) {\n+                    // Estimate the block time of their last block from the mtp\n+                    // of that last block, for calculating the timeout.\n+                    int64_t start_time = state.m_headers_sync_state.m_mtp_last_block;\n+                    state.m_headers_sync_state.m_try_continue_sync = std::chrono::microseconds(0);\n+                    // It's this peer's turn to sync from next; continue with a\n+                    // getheaders from where we left off.\n+                    if (LookupBlockIndex(state.m_headers_sync_state.GetLastBlockHash()) != nullptr) {\n+                        // We now have the header that we last cached for this\n+                        // peer, so we can construct a full locator from there.\n+                        const CBlockIndex *pindexStart = LookupBlockIndex(state.m_headers_sync_state.GetLastBlockHash());\n+                        connman->PushMessage(pto, msgMaker.Make(NetMsgType::GETHEADERS, ::ChainActive().GetLocator(pindexStart), uint256()));\n+                        // If the peer's last given block is now known, clear\n+                        // the sync state -- we expect the next header to now\n+                        // build off a known block.\n+                        ClearHeadersSyncState(&state, pto->GetId());\n+                    } else {\n+                        // Continue from where we left off with this peer.\n+                        connman->PushMessage(pto, msgMaker.Make(NetMsgType::GETHEADERS, CBlockLocator({state.m_headers_sync_state.GetLastBlockHash()}), uint256()));\n+                    }\n+                    // We set this after potentially clearing the sync state above.\n+                    SetHeadersSyncPeer(pto->GetId(), GetTimeout(consensusParams, start_time));\n+                }\n+            }\n         }\n \n         //\n@@ -4023,6 +4498,14 @@ bool PeerLogicValidation::SendMessages(CNode* pto)\n                 // disconnect later.\n                 state.nHeadersSyncTimeout = std::numeric_limits<int64_t>::max();\n             }\n+        } else if (IsHeadersSyncPeer(pto->GetId()) && state.m_headers_sync_state.m_headers_sync_peer_timeout < GetTime<std::chrono::microseconds>()) {\n+            // Check to see if we're holding on to being the sync peer for too long\n+            NodeId next_peer = GetNextHeadersSyncPeer();\n+            if (next_peer != -1) {\n+                LogPrint(BCLog::NET, \"Timeout syncing headers from peer=%d (stalling peer=%d), will try again later\\n\", pto->GetId(), next_peer);\n+                ClearHeadersSyncState(&state, pto->GetId());\n+                state.m_headers_sync_state.m_try_continue_sync = GetTime<std::chrono::microseconds>();\n+            }\n         }\n \n         // Check that outbound peers have reasonable chains"
      },
      {
        "sha": "79f8154423d603a6cab8044b105c2fea6616344c",
        "filename": "src/validation.cpp",
        "status": "modified",
        "additions": 36,
        "deletions": 0,
        "changes": 36,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/06da4d62a888dc63d7ed0685471d501d80efa817/src/validation.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/06da4d62a888dc63d7ed0685471d501d80efa817/src/validation.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/validation.cpp?ref=06da4d62a888dc63d7ed0685471d501d80efa817",
        "patch": "@@ -5069,6 +5069,42 @@ double GuessVerificationProgress(const ChainTxData& data, const CBlockIndex *pin\n     return pindex->nChainTx / fTxTotal;\n }\n \n+bool HasValidProofOfWork(const std::vector<CBlockHeader>& headers, const Consensus::Params& params)\n+{\n+    bool proof_of_work_valid = true;\n+    for (const CBlockHeader& header : headers) {\n+        proof_of_work_valid = proof_of_work_valid && CheckProofOfWork(header.GetHash(), header.nBits, params);\n+    }\n+    return proof_of_work_valid;\n+}\n+\n+arith_uint256 CalculateHeadersWork(const std::vector<CBlockHeader>& headers)\n+{\n+    arith_uint256 total_work{0};\n+    for (const CBlockHeader& header : headers) {\n+        CBlockIndex dummy(header);\n+        total_work += GetBlockProof(dummy);\n+    }\n+    return total_work;\n+}\n+\n+int64_t GetMTPLastHeader(const std::vector<CBlockHeader>& headers)\n+{\n+    if (headers.size() == 0) return 0;\n+\n+    std::vector<CBlockIndex> dummy_chain;\n+    dummy_chain.reserve(headers.size());\n+    CBlockIndex* last_block = nullptr;\n+\n+    for (const CBlockHeader& header : headers) {\n+        dummy_chain.emplace_back(CBlockIndex(header));\n+        dummy_chain.back().pprev = last_block;\n+        last_block = &dummy_chain.back();\n+    }\n+    return dummy_chain.back().GetMedianTimePast();\n+\n+}\n+\n class CMainCleanup\n {\n public:"
      },
      {
        "sha": "ca905d76dbd3dbe4f7e37256f3946dd9cd436c0e",
        "filename": "src/validation.h",
        "status": "modified",
        "additions": 9,
        "deletions": 0,
        "changes": 9,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/06da4d62a888dc63d7ed0685471d501d80efa817/src/validation.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/06da4d62a888dc63d7ed0685471d501d80efa817/src/validation.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/validation.h?ref=06da4d62a888dc63d7ed0685471d501d80efa817",
        "patch": "@@ -792,4 +792,13 @@ inline bool IsBlockPruned(const CBlockIndex* pblockindex)\n     return (fHavePruned && !(pblockindex->nStatus & BLOCK_HAVE_DATA) && pblockindex->nTx > 0);\n }\n \n+//! Return true if the headers given have valid proof of work.\n+bool HasValidProofOfWork(const std::vector<CBlockHeader>& headers, const Consensus::Params& params);\n+\n+//! Calculate the sum of the work on the given block headers, based on nBits values\n+arith_uint256 CalculateHeadersWork(const std::vector<CBlockHeader>& headers);\n+\n+//! Calculate the MedianTimePast of the last block in a set of headers.\n+int64_t GetMTPLastHeader(const std::vector<CBlockHeader>& headers);\n+\n #endif // BITCOIN_VALIDATION_H"
      },
      {
        "sha": "5e60f701bf708a0899a011deab55caa514f3dc9a",
        "filename": "test/functional/p2p_dos_header_tree.py",
        "status": "modified",
        "additions": 2,
        "deletions": 1,
        "changes": 3,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/06da4d62a888dc63d7ed0685471d501d80efa817/test/functional/p2p_dos_header_tree.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/06da4d62a888dc63d7ed0685471d501d80efa817/test/functional/p2p_dos_header_tree.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_dos_header_tree.py?ref=06da4d62a888dc63d7ed0685471d501d80efa817",
        "patch": "@@ -22,6 +22,7 @@ def set_test_params(self):\n         self.setup_clean_chain = True\n         self.chain = 'testnet3'  # Use testnet chain because it has an early checkpoint\n         self.num_nodes = 2\n+        self.extra_args = [[\"-minimumchainwork=0x00\"], [\"-minimumchainwork=0x00\"]]\n \n     def add_options(self, parser):\n         parser.add_argument(\n@@ -63,7 +64,7 @@ def run_test(self):\n \n         self.log.info(\"Feed all fork headers (succeeds without checkpoint)\")\n         # On node 0 it succeeds because checkpoints are disabled\n-        self.restart_node(0, extra_args=['-nocheckpoints'])\n+        self.restart_node(0, extra_args=['-nocheckpoints', \"-minimumchainwork=0x00\"])\n         self.nodes[0].add_p2p_connection(P2PInterface())\n         self.nodes[0].p2p.send_message(msg_headers(self.headers_fork))\n         self.nodes[0].p2p.sync_with_ping()"
      }
    ]
  }
]