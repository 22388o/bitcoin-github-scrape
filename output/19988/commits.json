[
  {
    "sha": "da3b8fde03f2e8060bb7ff3bff17175dab85f0cd",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzpkYTNiOGZkZTAzZjJlODA2MGJiN2ZmM2JmZjE3MTc1ZGFiODVmMGNk",
    "commit": {
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-09-21T04:17:29Z"
      },
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-10-12T18:01:16Z"
      },
      "message": "Add txrequest module\n\nThis adds a new module (unused for now) which defines TxRequestTracker, a data\nstructure that maintains all information about transaction requests, and coordinates\nrequests.",
      "tree": {
        "sha": "288a1e596a2e026b06a117d2a62db6c314df65e4",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/288a1e596a2e026b06a117d2a62db6c314df65e4"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd/comments",
    "author": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "0b2abaa666d6f3331e3246ffd64dd47946e9dcdf",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/0b2abaa666d6f3331e3246ffd64dd47946e9dcdf",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/0b2abaa666d6f3331e3246ffd64dd47946e9dcdf"
      }
    ],
    "stats": {
      "total": 807,
      "additions": 807,
      "deletions": 0
    },
    "files": [
      {
        "sha": "e29063889b375b20ef90080a92c894460bf2abb3",
        "filename": "src/Makefile.am",
        "status": "modified",
        "additions": 2,
        "deletions": 0,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd/src/Makefile.am",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd/src/Makefile.am",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/Makefile.am?ref=da3b8fde03f2e8060bb7ff3bff17175dab85f0cd",
        "patch": "@@ -215,6 +215,7 @@ BITCOIN_CORE_H = \\\n   timedata.h \\\n   torcontrol.h \\\n   txdb.h \\\n+  txrequest.h \\\n   txmempool.h \\\n   undo.h \\\n   util/asmap.h \\\n@@ -327,6 +328,7 @@ libbitcoin_server_a_SOURCES = \\\n   timedata.cpp \\\n   torcontrol.cpp \\\n   txdb.cpp \\\n+  txrequest.cpp \\\n   txmempool.cpp \\\n   validation.cpp \\\n   validationinterface.cpp \\"
      },
      {
        "sha": "bb64a00847d5789498a37da2711df883e0fd950c",
        "filename": "src/txrequest.cpp",
        "status": "added",
        "additions": 606,
        "deletions": 0,
        "changes": 606,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd/src/txrequest.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd/src/txrequest.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/txrequest.cpp?ref=da3b8fde03f2e8060bb7ff3bff17175dab85f0cd",
        "patch": "@@ -0,0 +1,606 @@\n+// Copyright (c) 2020 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <txrequest.h>\n+\n+#include <crypto/siphash.h>\n+#include <net.h>\n+#include <primitives/transaction.h>\n+#include <random.h>\n+#include <uint256.h>\n+#include <util/memory.h>\n+\n+#include <boost/multi_index_container.hpp>\n+#include <boost/multi_index/ordered_index.hpp>\n+\n+#include <chrono>\n+#include <unordered_map>\n+#include <utility>\n+\n+#include <assert.h>\n+\n+namespace {\n+\n+/** The various states a (txhash,peer) pair can be in.\n+ *\n+ * Note that CANDIDATE is split up into 3 substates (DELAYED, BEST, READY), allowing more efficient implementation.\n+ * Also note that the sorting order of ByTxHashView relies on the specific order of values in this enum.\n+ *\n+ * Expected behaviour is:\n+ *   - When first announced by a peer, the state is CANDIDATE_DELAYED until reqtime is reached.\n+ *   - Announcements that have reached their reqtime but not been requested will be either CANDIDATE_READY or\n+ *     CANDIDATE_BEST. Neither of those has an expiration time; they remain in that state until they're requested or\n+ *     no longer needed. CANDIDATE_READY announcements are promoted to CANDIDATE_BEST when they're the best one left.\n+ *   - When requested, an announcement will be in state REQUESTED until expiry is reached.\n+ *   - If expiry is reached, or the peer replies to the request (either with NOTFOUND or the tx), the state becomes\n+ *     COMPLETED.\n+ */\n+enum class State : uint8_t {\n+    /** A CANDIDATE announcement whose reqtime is in the future. */\n+    CANDIDATE_DELAYED,\n+    /** A CANDIDATE announcement that's not CANDIDATE_DELAYED or CANDIDATE_BEST. */\n+    CANDIDATE_READY,\n+    /** The best CANDIDATE for a given txhash; only if there is no REQUESTED announcement already for that txhash.\n+     *  The CANDIDATE_BEST is the highest-priority announcement among all CANDIDATE_READY (and _BEST) ones for that\n+     *  txhash. */\n+    CANDIDATE_BEST,\n+    /** A REQUESTED announcement. */\n+    REQUESTED,\n+    /** A COMPLETED announcement. */\n+    COMPLETED,\n+};\n+\n+//! Type alias for sequence numbers.\n+using SequenceNumber = uint64_t;\n+\n+/** An announcement. This is the data we track for each txid or wtxid that is announced to us by each peer. */\n+struct Announcement {\n+    /** Txid or wtxid that was announced. */\n+    const uint256 m_txhash;\n+    /** For CANDIDATE_{DELAYED,BEST,READY} the reqtime; for REQUESTED the expiry. */\n+    std::chrono::microseconds m_time;\n+    /** What peer the request was from. */\n+    const NodeId m_peer;\n+    /** What sequence number this announcement has. */\n+    const SequenceNumber m_sequence : 59;\n+    /** Whether the request is preferred. */\n+    const bool m_preferred : 1;\n+    /** Whether this is a wtxid request. */\n+    const bool m_is_wtxid : 1;\n+\n+    /** What state this announcement is in. */\n+    State m_state : 3;\n+\n+    /** Whether this announcement is selected. There can be at most 1 selected peer per txhash. */\n+    bool IsSelected() const\n+    {\n+        return m_state == State::CANDIDATE_BEST || m_state == State::REQUESTED;\n+    }\n+\n+    /** Whether this announcement is waiting for a certain time to pass. */\n+    bool IsWaiting() const\n+    {\n+        return m_state == State::REQUESTED || m_state == State::CANDIDATE_DELAYED;\n+    }\n+\n+    /** Whether this announcement can feasibly be selected if the current IsSelected() one disappears. */\n+    bool IsSelectable() const\n+    {\n+        return m_state == State::CANDIDATE_READY || m_state == State::CANDIDATE_BEST;\n+    }\n+\n+    /** Construct a new announcement from scratch, initially in CANDIDATE_DELAYED state. */\n+    Announcement(const GenTxid& gtxid, NodeId peer, bool preferred, std::chrono::microseconds reqtime,\n+        SequenceNumber sequence) :\n+        m_txhash(gtxid.GetHash()), m_time(reqtime), m_peer(peer), m_sequence(sequence), m_preferred(preferred),\n+        m_is_wtxid(gtxid.IsWtxid()), m_state(State::CANDIDATE_DELAYED) {}\n+};\n+\n+//! Type alias for priorities.\n+using Priority = uint64_t;\n+\n+/** A functor with embedded salt that computes priority of an announcement.\n+ *\n+ * Higher priorities are selected first.\n+ */\n+class PriorityComputer {\n+    const uint64_t m_k0, m_k1;\n+public:\n+    explicit PriorityComputer(bool deterministic) :\n+        m_k0{deterministic ? 0 : GetRand(0xFFFFFFFFFFFFFFFF)},\n+        m_k1{deterministic ? 0 : GetRand(0xFFFFFFFFFFFFFFFF)} {}\n+\n+    Priority operator()(const uint256& txhash, NodeId peer, bool preferred) const\n+    {\n+        uint64_t low_bits = CSipHasher(m_k0, m_k1).Write(txhash.begin(), txhash.size()).Write(peer).Finalize() >> 1;\n+        return low_bits | uint64_t{preferred} << 63;\n+    }\n+\n+    Priority operator()(const Announcement& ann) const\n+    {\n+        return operator()(ann.m_txhash, ann.m_peer, ann.m_preferred);\n+    }\n+};\n+\n+// Definitions for the 3 indexes used in the main data structure.\n+//\n+// Each index has a By* type to identify it, a By*View data type to represent the view of announcement it is sorted\n+// by, and an By*ViewExtractor type to convert an announcement into the By*View type.\n+// See https://www.boost.org/doc/libs/1_58_0/libs/multi_index/doc/reference/key_extraction.html#key_extractors\n+// for more information about the key extraction concept.\n+\n+// The ByPeer index is sorted by (peer, state == CANDIDATE_BEST, txhash)\n+//\n+// Uses:\n+// * Looking up existing announcements by peer/txhash, by checking both (peer, false, txhash) and\n+//   (peer, true, txhash).\n+// * Finding all CANDIDATE_BEST announcements for a given peer in GetRequestable.\n+struct ByPeer {};\n+using ByPeerView = std::tuple<NodeId, bool, const uint256&>;\n+struct ByPeerViewExtractor\n+{\n+    using result_type = ByPeerView;\n+    result_type operator()(const Announcement& ann) const\n+    {\n+        return ByPeerView{ann.m_peer, ann.m_state == State::CANDIDATE_BEST, ann.m_txhash};\n+    }\n+};\n+\n+// The ByTxHash index is sorted by (txhash, state, priority).\n+//\n+// Note: priority == 0 whenever state != CANDIDATE_READY.\n+//\n+// Uses:\n+// * Deleting all announcements with a given txhash in ForgetTxHash.\n+// * Finding the best CANDIDATE_READY to convert to CANDIDATE_BEST, when no other CANDIDATE_READY or REQUESTED\n+//   announcement exists for that txhash.\n+// * Determining when no more non-COMPLETED announcements for a given txhash exist, so the COMPLETED ones can be\n+//   deleted.\n+struct ByTxHash {};\n+using ByTxHashView = std::tuple<const uint256&, State, Priority>;\n+class ByTxHashViewExtractor {\n+    const PriorityComputer& m_computer;\n+public:\n+    ByTxHashViewExtractor(const PriorityComputer& computer) : m_computer(computer) {}\n+    using result_type = ByTxHashView;\n+    result_type operator()(const Announcement& ann) const\n+    {\n+        const Priority prio = (ann.m_state == State::CANDIDATE_READY) ? m_computer(ann) : 0;\n+        return ByTxHashView{ann.m_txhash, ann.m_state, prio};\n+    }\n+};\n+\n+enum class WaitState {\n+    //! Used for announcements that need efficient testing of \"is their timestamp in the future?\".\n+    FUTURE_EVENT,\n+    //! Used for announcements whose timestamp is not relevant.\n+    NO_EVENT,\n+    //! Used for announcements that need efficient testing of \"is their timestamp in the past?\".\n+    PAST_EVENT,\n+};\n+\n+WaitState GetWaitState(const Announcement& ann)\n+{\n+    if (ann.IsWaiting()) return WaitState::FUTURE_EVENT;\n+    if (ann.IsSelectable()) return WaitState::PAST_EVENT;\n+    return WaitState::NO_EVENT;\n+}\n+\n+// The ByTime index is sorted by (wait_state, time).\n+//\n+// All announcements with a timestamp in the future can be found by iterating the index forward from the beginning.\n+// All announcements with a timestamp in the past can be found by iterating the index backwards from the end.\n+//\n+// Uses:\n+// * Finding CANDIDATE_DELAYED announcements whose reqtime has passed, and REQUESTED announcements whose expiry has\n+//   passed.\n+// * Finding CANDIDATE_READY/BEST announcements whose reqtime is in the future (when the clock time went backwards).\n+struct ByTime {};\n+using ByTimeView = std::pair<WaitState, std::chrono::microseconds>;\n+struct ByTimeViewExtractor\n+{\n+    using result_type = ByTimeView;\n+    result_type operator()(const Announcement& ann) const\n+    {\n+        return ByTimeView{GetWaitState(ann), ann.m_time};\n+    }\n+};\n+\n+/** Data type for the main data structure (Announcement objects with ByPeer/ByTxHash/ByTime indexes). */\n+using Index = boost::multi_index_container<\n+    Announcement,\n+    boost::multi_index::indexed_by<\n+        boost::multi_index::ordered_unique<boost::multi_index::tag<ByPeer>, ByPeerViewExtractor>,\n+        boost::multi_index::ordered_non_unique<boost::multi_index::tag<ByTxHash>, ByTxHashViewExtractor>,\n+        boost::multi_index::ordered_non_unique<boost::multi_index::tag<ByTime>, ByTimeViewExtractor>\n+    >\n+>;\n+\n+/** Helper type to simplify syntax of iterator types. */\n+template<typename Tag>\n+using Iter = typename Index::index<Tag>::type::iterator;\n+\n+/** Per-peer statistics object. */\n+struct PeerInfo {\n+    size_t m_total = 0; //!< Total number of announcements for this peer.\n+    size_t m_completed = 0; //!< Number of COMPLETED announcements for this peer.\n+    size_t m_requested = 0; //!< Number of REQUESTED announcements for this peer.\n+};\n+\n+}  // namespace\n+\n+/** Actual implementation for TxRequestTracker's data structure. */\n+class TxRequestTracker::Impl {\n+    //! The current sequence number. Increases for every announcement. This is used to sort txhashes returned by\n+    //! GetRequestable in announcement order.\n+    SequenceNumber m_current_sequence{0};\n+\n+    //! This tracker's priority computer.\n+    const PriorityComputer m_computer;\n+\n+    //! This tracker's main data structure.\n+    Index m_index;\n+\n+    //! Map with this tracker's per-peer statistics.\n+    std::unordered_map<NodeId, PeerInfo> m_peerinfo;\n+\n+    //! Wrapper around Index::...::erase that keeps m_peerinfo up to date.\n+    template<typename Tag>\n+    Iter<Tag> Erase(Iter<Tag> it)\n+    {\n+        auto peerit = m_peerinfo.find(it->m_peer);\n+        peerit->second.m_completed -= it->m_state == State::COMPLETED;\n+        peerit->second.m_requested -= it->m_state == State::REQUESTED;\n+        if (--peerit->second.m_total == 0) m_peerinfo.erase(peerit);\n+        return m_index.get<Tag>().erase(it);\n+    }\n+\n+    //! Wrapper around Index::...::modify that keeps m_peerinfo up to date.\n+    template<typename Tag, typename Modifier>\n+    void Modify(Iter<Tag> it, Modifier modifier)\n+    {\n+        auto peerit = m_peerinfo.find(it->m_peer);\n+        peerit->second.m_completed -= it->m_state == State::COMPLETED;\n+        peerit->second.m_requested -= it->m_state == State::REQUESTED;\n+        m_index.get<Tag>().modify(it, std::move(modifier));\n+        peerit->second.m_completed += it->m_state == State::COMPLETED;\n+        peerit->second.m_requested += it->m_state == State::REQUESTED;\n+    }\n+\n+    //! Convert a CANDIDATE_DELAYED announcement into a CANDIDATE_READY. If this makes it the new best\n+    //! CANDIDATE_READY (and no REQUESTED exists) and better than the CANDIDATE_BEST (if any), it becomes the new\n+    //! CANDIDATE_BEST.\n+    void PromoteCandidateReady(Iter<ByTxHash> it)\n+    {\n+        assert(it != m_index.get<ByTxHash>().end());\n+        assert(it->m_state == State::CANDIDATE_DELAYED);\n+        // Convert CANDIDATE_DELAYED to CANDIDATE_READY first.\n+        Modify<ByTxHash>(it, [](Announcement& ann){ ann.m_state = State::CANDIDATE_READY; });\n+        // The following code relies on the fact that the ByTxHash is sorted by txhash, and then by state (first\n+        // _DELAYED, then _READY, then _BEST/REQUESTED). Within the _READY announcements, the best one (highest\n+        // priority) comes last. Thus, if an existing _BEST exists for the same txhash that this announcement may\n+        // be preferred over, it must immediately follow the newly created _READY.\n+        auto it_next = std::next(it);\n+        if (it_next == m_index.get<ByTxHash>().end() || it_next->m_txhash != it->m_txhash ||\n+            it_next->m_state == State::COMPLETED) {\n+            // This is the new best CANDIDATE_READY, and there is no IsSelected() announcement for this txhash\n+            // already.\n+            Modify<ByTxHash>(it, [](Announcement& ann){ ann.m_state = State::CANDIDATE_BEST; });\n+        } else if (it_next->m_state == State::CANDIDATE_BEST) {\n+            Priority priority_old = m_computer(*it_next);\n+            Priority priority_new = m_computer(*it);\n+            if (priority_new > priority_old) {\n+                // There is a CANDIDATE_BEST announcement already, but this one is better.\n+                Modify<ByTxHash>(it_next, [](Announcement& ann){ ann.m_state = State::CANDIDATE_READY; });\n+                Modify<ByTxHash>(it, [](Announcement& ann){ ann.m_state = State::CANDIDATE_BEST; });\n+            }\n+        }\n+    }\n+\n+    //! Change the state of an announcement to something non-IsSelected(). If it was IsSelected(), the next best\n+    //! announcement will be marked CANDIDATE_BEST.\n+    void ChangeAndReselect(Iter<ByTxHash> it, State new_state)\n+    {\n+        assert(new_state == State::COMPLETED || new_state == State::CANDIDATE_DELAYED);\n+        assert(it != m_index.get<ByTxHash>().end());\n+        if (it->IsSelected() && it != m_index.get<ByTxHash>().begin()) {\n+            auto it_prev = std::prev(it);\n+            // The next best CANDIDATE_READY, if any, immediately precedes the REQUESTED or CANDIDATE_BEST\n+            // announcement in the ByTxHash index.\n+            if (it_prev->m_txhash == it->m_txhash && it_prev->m_state == State::CANDIDATE_READY) {\n+                // If one such CANDIDATE_READY exists (for this txhash), convert it to CANDIDATE_BEST.\n+                Modify<ByTxHash>(it_prev, [](Announcement& ann){ ann.m_state = State::CANDIDATE_BEST; });\n+            }\n+        }\n+        Modify<ByTxHash>(it, [new_state](Announcement& ann){ ann.m_state = new_state; });\n+    }\n+\n+    //! Check if 'it' is the only announcement for a given txhash that isn't COMPLETED.\n+    bool IsOnlyNonCompleted(Iter<ByTxHash> it)\n+    {\n+        assert(it != m_index.get<ByTxHash>().end());\n+        assert(it->m_state != State::COMPLETED); // Not allowed to call this on COMPLETED announcements.\n+\n+        // This announcement has a predecessor that belongs to the same txhash. Due to ordering, and the\n+        // fact that 'it' is not COMPLETED, its predecessor cannot be COMPLETED here.\n+        if (it != m_index.get<ByTxHash>().begin() && std::prev(it)->m_txhash == it->m_txhash) return false;\n+\n+        // This announcement has a successor that belongs to the same txhash, and is not COMPLETED.\n+        if (std::next(it) != m_index.get<ByTxHash>().end() && std::next(it)->m_txhash == it->m_txhash &&\n+            std::next(it)->m_state != State::COMPLETED) return false;\n+\n+        return true;\n+    }\n+\n+    /** Convert any announcement to a COMPLETED one. If there are no non-COMPLETED announcements left for this\n+     *  txhash, they are deleted. If this was a REQUESTED announcement, and there are other CANDIDATEs left, the\n+     *  best one is made CANDIDATE_BEST. Returns whether the announcement still exists. */\n+    bool MakeCompleted(Iter<ByTxHash> it)\n+    {\n+        assert(it != m_index.get<ByTxHash>().end());\n+\n+        // Nothing to be done if it's already COMPLETED.\n+        if (it->m_state == State::COMPLETED) return true;\n+\n+        if (IsOnlyNonCompleted(it)) {\n+            // This is the last non-COMPLETED announcement for this txhash. Delete all.\n+            uint256 txhash = it->m_txhash;\n+            do {\n+                it = Erase<ByTxHash>(it);\n+            } while (it != m_index.get<ByTxHash>().end() && it->m_txhash == txhash);\n+            return false;\n+        }\n+\n+        // Mark the announcement COMPLETED, and select the next best announcement (the first CANDIDATE_READY) if\n+        // needed.\n+        ChangeAndReselect(it, State::COMPLETED);\n+\n+        return true;\n+    }\n+\n+    //! Make the data structure consistent with a given point in time:\n+    //! - REQUESTED annoucements with expiry <= now are turned into COMPLETED.\n+    //! - CANDIDATE_DELAYED announcements with reqtime <= now are turned into CANDIDATE_{READY,BEST}.\n+    //! - CANDIDATE_{READY,BEST} announcements with reqtime > now are turned into CANDIDATE_DELAYED.\n+    void SetTimePoint(std::chrono::microseconds now)\n+    {\n+        // Iterate over all CANDIDATE_DELAYED and REQUESTED from old to new, as long as they're in the past,\n+        // and convert them to CANDIDATE_READY and COMPLETED respectively.\n+        while (!m_index.empty()) {\n+            auto it = m_index.get<ByTime>().begin();\n+            if (it->m_state == State::CANDIDATE_DELAYED && it->m_time <= now) {\n+                PromoteCandidateReady(m_index.project<ByTxHash>(it));\n+            } else if (it->m_state == State::REQUESTED && it->m_time <= now) {\n+                MakeCompleted(m_index.project<ByTxHash>(it));\n+            } else {\n+                break;\n+            }\n+        }\n+\n+        while (!m_index.empty()) {\n+            // If time went backwards, we may need to demote CANDIDATE_BEST and CANDIDATE_READY announcements back\n+            // to CANDIDATE_DELAYED. This is an unusual edge case, and unlikely to matter in production. However,\n+            // it makes it much easier to specify and test TxRequestTracker::Impl's behaviour.\n+            auto it = std::prev(m_index.get<ByTime>().end());\n+            if (it->IsSelectable() && it->m_time > now) {\n+                ChangeAndReselect(m_index.project<ByTxHash>(it), State::CANDIDATE_DELAYED);\n+            } else {\n+                break;\n+            }\n+        }\n+    }\n+\n+public:\n+    Impl(bool deterministic) :\n+        m_computer(deterministic),\n+        // Explicitly initialize m_index as we need to pass a reference to m_computer to ByTxHashViewExtractor.\n+        m_index(boost::make_tuple(\n+            boost::make_tuple(ByPeerViewExtractor(), std::less<ByPeerView>()),\n+            boost::make_tuple(ByTxHashViewExtractor(m_computer), std::less<ByTxHashView>()),\n+            boost::make_tuple(ByTimeViewExtractor(), std::less<ByTimeView>())\n+        )) {}\n+\n+    // Disable copying and assigning (a default copy won't work due the stateful ByTxHashViewExtractor).\n+    Impl(const Impl&) = delete;\n+    Impl& operator=(const Impl&) = delete;\n+\n+    void DisconnectedPeer(NodeId peer)\n+    {\n+        auto& index = m_index.get<ByPeer>();\n+        auto it = index.lower_bound(ByPeerView{peer, false, uint256::ZERO});\n+        while (it != index.end() && it->m_peer == peer) {\n+            // Check what to continue with after this iteration. 'it' will be deleted in what follows, so we need to\n+            // decide what to continue with afterwards. There are a number of cases to consider:\n+            // - std::next(it) is end() or belongs to a different peer. In that case, this is the last iteration\n+            //   of the loop (denote this by setting it_next to end()).\n+            // - 'it' is not the only non-COMPLETED announcement for its txhash. This means it will be deleted, but\n+            //   no other Announcement objects will be modified. Continue with std::next(it) if it belongs to the\n+            //   same peer, but decide this ahead of time (as 'it' may change position in what follows).\n+            // - 'it' is the only non-COMPLETED announcement for its txhash. This means it will be deleted along\n+            //   with all other announcements for the same txhash - which may include std::next(it). However, other\n+            //   than 'it', no announcements for the same peer can be affected (due to (peer, txhash) uniqueness).\n+            //   In other words, the situation where std::next(it) is deleted can only occur if std::next(it)\n+            //   belongs to a different peer but the same txhash as 'it'. This is covered by the first bulletpoint\n+            //   already, and we'll have set it_next to end().\n+            auto it_next = (std::next(it) == index.end() || std::next(it)->m_peer != peer) ? index.end() :\n+                std::next(it);\n+            // If the announcement isn't already COMPLETED, first make it COMPLETED (which will mark other\n+            // CANDIDATEs as CANDIDATE_BEST, or delete all of a txhash's announcements if no non-COMPLETED ones are\n+            // left).\n+            if (MakeCompleted(m_index.project<ByTxHash>(it))) {\n+                // Then actually delete the announcement (unless it was already deleted by MakeCompleted).\n+                Erase<ByPeer>(it);\n+            }\n+            it = it_next;\n+        }\n+    }\n+\n+    void ForgetTxHash(const uint256& txhash)\n+    {\n+        auto it = m_index.get<ByTxHash>().lower_bound(ByTxHashView{txhash, State::CANDIDATE_DELAYED, 0});\n+        while (it != m_index.get<ByTxHash>().end() && it->m_txhash == txhash) {\n+            it = Erase<ByTxHash>(it);\n+        }\n+    }\n+\n+    void ReceivedInv(NodeId peer, const GenTxid& gtxid, bool preferred,\n+        std::chrono::microseconds reqtime)\n+    {\n+        // Bail out if we already have a CANDIDATE_BEST announcement for this (txhash, peer) combination. The case\n+        // where there is a non-CANDIDATE_BEST announcement already will be caught by the uniqueness property of the\n+        // ByPeer index when we try to emplace the new object below.\n+        if (m_index.get<ByPeer>().count(ByPeerView{peer, true, gtxid.GetHash()})) return;\n+\n+        // Try creating the announcement with CANDIDATE_DELAYED state (which will fail due to the uniqueness\n+        // of the ByPeer index if a non-CANDIDATE_BEST announcement already exists with the same txhash and peer).\n+        // Bail out in that case.\n+        auto ret = m_index.get<ByPeer>().emplace(gtxid, peer, preferred, reqtime, m_current_sequence);\n+        if (!ret.second) return;\n+\n+        // Update accounting metadata.\n+        ++m_peerinfo[peer].m_total;\n+        ++m_current_sequence;\n+    }\n+\n+    //! Find the GenTxids to request now from peer.\n+    std::vector<GenTxid> GetRequestable(NodeId peer, std::chrono::microseconds now)\n+    {\n+        // Move time.\n+        SetTimePoint(now);\n+\n+        // Find all CANDIDATE_BEST announcements for this peer.\n+        std::vector<const Announcement*> selected;\n+        auto it_peer = m_index.get<ByPeer>().lower_bound(ByPeerView{peer, true, uint256::ZERO});\n+        while (it_peer != m_index.get<ByPeer>().end() && it_peer->m_peer == peer &&\n+            it_peer->m_state == State::CANDIDATE_BEST) {\n+            selected.emplace_back(&*it_peer);\n+            ++it_peer;\n+        }\n+\n+        // Sort by sequence number.\n+        std::sort(selected.begin(), selected.end(), [](const Announcement* a, const Announcement* b) {\n+            return a->m_sequence < b->m_sequence;\n+        });\n+\n+        // Convert to GenTxid and return.\n+        std::vector<GenTxid> ret;\n+        ret.reserve(selected.size());\n+        std::transform(selected.begin(), selected.end(), std::back_inserter(ret), [](const Announcement* ann) {\n+            return GenTxid{ann->m_is_wtxid, ann->m_txhash};\n+        });\n+        return ret;\n+    }\n+\n+    void RequestedTx(NodeId peer, const uint256& txhash, std::chrono::microseconds expiry)\n+    {\n+        auto it = m_index.get<ByPeer>().find(ByPeerView{peer, true, txhash});\n+        if (it == m_index.get<ByPeer>().end()) {\n+            // There is no CANDIDATE_BEST announcement, look for a _READY or _DELAYED instead. If the caller only\n+            // ever invokes RequestedTx with the values returned by GetRequestable, and no other non-const functions\n+            // other than ForgetTxHash and GetRequestable in between, this branch will never execute (as txhashes\n+            // returned by GetRequestable always correspond to CANDIDATE_BEST announcements).\n+\n+            it = m_index.get<ByPeer>().find(ByPeerView{peer, false, txhash});\n+            if (it == m_index.get<ByPeer>().end() || (it->m_state != State::CANDIDATE_DELAYED &&\n+                it->m_state != State::CANDIDATE_READY)) {\n+                // There is no CANDIDATE announcement tracked for this peer, so we have nothing to do. Either this\n+                // txhash wasn't tracked at all (and the caller should have called ReceivedInv), or it was already\n+                // requested and/or completed for other reasons and this is just a superfluous RequestedTx call.\n+                return;\n+            }\n+\n+            // Look for an existing CANDIDATE_BEST or REQUESTED with the same txhash. We only need to do this if the\n+            // found announcement had a different state than CANDIDATE_BEST. If it did, invariants guarantee that no\n+            // other CANDIDATE_BEST or REQUESTED can exist.\n+            auto it_old = m_index.get<ByTxHash>().lower_bound(ByTxHashView{txhash, State::CANDIDATE_BEST, 0});\n+            if (it_old != m_index.get<ByTxHash>().end() && it_old->m_txhash == txhash) {\n+                if (it_old->m_state == State::CANDIDATE_BEST) {\n+                    // The data structure's invariants require that there can be at most one CANDIDATE_BEST or one\n+                    // REQUESTED announcement per txhash (but not both simultaneously), so we have to convert any\n+                    // existing CANDIDATE_BEST to another CANDIDATE_* when constructing another REQUESTED.\n+                    // It doesn't matter whether we pick CANDIDATE_READY or _DELAYED here, as SetTimePoint()\n+                    // will correct it at GetRequestable() time. If time only goes forward, it will always be\n+                    // _READY, so pick that to avoid extra work in SetTimePoint().\n+                    Modify<ByTxHash>(it_old, [](Announcement& ann) { ann.m_state = State::CANDIDATE_READY; });\n+                } else if (it_old->m_state == State::REQUESTED) {\n+                    // As we're no longer waiting for a response to the previous REQUESTED announcement, convert it\n+                    // to COMPLETED. This also helps guaranteeing progress.\n+                    Modify<ByTxHash>(it_old, [](Announcement& ann) { ann.m_state = State::COMPLETED; });\n+                }\n+            }\n+        }\n+\n+        Modify<ByPeer>(it, [expiry](Announcement& ann) {\n+            ann.m_state = State::REQUESTED;\n+            ann.m_time = expiry;\n+        });\n+    }\n+\n+    void ReceivedResponse(NodeId peer, const uint256& txhash)\n+    {\n+        // We need to search the ByPeer index for both (peer, false, txhash) and (peer, true, txhash).\n+        auto it = m_index.get<ByPeer>().find(ByPeerView{peer, false, txhash});\n+        if (it == m_index.get<ByPeer>().end()) {\n+            it = m_index.get<ByPeer>().find(ByPeerView{peer, true, txhash});\n+        }\n+        if (it != m_index.get<ByPeer>().end()) MakeCompleted(m_index.project<ByTxHash>(it));\n+    }\n+\n+    size_t CountInFlight(NodeId peer) const\n+    {\n+        auto it = m_peerinfo.find(peer);\n+        if (it != m_peerinfo.end()) return it->second.m_requested;\n+        return 0;\n+    }\n+\n+    size_t CountCandidates(NodeId peer) const\n+    {\n+        auto it = m_peerinfo.find(peer);\n+        if (it != m_peerinfo.end()) return it->second.m_total - it->second.m_requested - it->second.m_completed;\n+        return 0;\n+    }\n+\n+    size_t Count(NodeId peer) const\n+    {\n+        auto it = m_peerinfo.find(peer);\n+        if (it != m_peerinfo.end()) return it->second.m_total;\n+        return 0;\n+    }\n+\n+    //! Count how many announcements are being tracked in total across all peers and transactions.\n+    size_t Size() const { return m_index.size(); }\n+};\n+\n+TxRequestTracker::TxRequestTracker(bool deterministic) :\n+    m_impl{MakeUnique<TxRequestTracker::Impl>(deterministic)} {}\n+\n+TxRequestTracker::~TxRequestTracker() = default;\n+\n+void TxRequestTracker::ForgetTxHash(const uint256& txhash) { m_impl->ForgetTxHash(txhash); }\n+void TxRequestTracker::DisconnectedPeer(NodeId peer) { m_impl->DisconnectedPeer(peer); }\n+size_t TxRequestTracker::CountInFlight(NodeId peer) const { return m_impl->CountInFlight(peer); }\n+size_t TxRequestTracker::CountCandidates(NodeId peer) const { return m_impl->CountCandidates(peer); }\n+size_t TxRequestTracker::Count(NodeId peer) const { return m_impl->Count(peer); }\n+size_t TxRequestTracker::Size() const { return m_impl->Size(); }\n+\n+void TxRequestTracker::ReceivedInv(NodeId peer, const GenTxid& gtxid, bool preferred,\n+    std::chrono::microseconds reqtime)\n+{\n+    m_impl->ReceivedInv(peer, gtxid, preferred, reqtime);\n+}\n+\n+void TxRequestTracker::RequestedTx(NodeId peer, const uint256& txhash, std::chrono::microseconds expiry)\n+{\n+    m_impl->RequestedTx(peer, txhash, expiry);\n+}\n+\n+void TxRequestTracker::ReceivedResponse(NodeId peer, const uint256& txhash)\n+{\n+    m_impl->ReceivedResponse(peer, txhash);\n+}\n+\n+std::vector<GenTxid> TxRequestTracker::GetRequestable(NodeId peer, std::chrono::microseconds now)\n+{\n+    return m_impl->GetRequestable(peer, now);\n+}"
      },
      {
        "sha": "e24390b6aae3797b501717ffda5173f41fc228fb",
        "filename": "src/txrequest.h",
        "status": "added",
        "additions": 197,
        "deletions": 0,
        "changes": 197,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd/src/txrequest.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd/src/txrequest.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/txrequest.h?ref=da3b8fde03f2e8060bb7ff3bff17175dab85f0cd",
        "patch": "@@ -0,0 +1,197 @@\n+// Copyright (c) 2020 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#ifndef BITCOIN_TXREQUEST_H\n+#define BITCOIN_TXREQUEST_H\n+\n+#include <primitives/transaction.h>\n+#include <net.h> // For NodeId\n+#include <uint256.h>\n+\n+#include <chrono>\n+#include <vector>\n+\n+#include <stdint.h>\n+\n+/** Data structure to keep track of, and schedule, transaction downloads from peers.\n+ *\n+ * === Specification ===\n+ *\n+ * We keep track of which peers have announced which transactions, and use that to determine which requests\n+ * should go to which peer, when, and in what order.\n+ *\n+ * The following information is tracked per peer/tx combination (\"announcement\"):\n+ * - Which peer announced it (through their NodeId)\n+ * - The txid or wtxid of the transaction (collectively called \"txhash\" in what follows)\n+ * - Whether it was a tx or wtx announcement (see BIP339).\n+ * - What the earliest permitted time is that that transaction can be requested from that peer (called \"reqtime\").\n+ * - Whether it's from a \"preferred\" peer or not. Which announcements get this flag is determined by the caller, but\n+ *   this is designed for outbound peers, or other peers that we have a higher level of trust in. Even when the\n+ *   peers' preferredness changes, the preferred flag of existing announcements from that peer won't change.\n+ * - Whether or not the transaction was requested already, and if so, when it times out (called \"expiry\").\n+ * - Whether or not the transaction request failed already (timed out, or invalid transaction or NOTFOUND was\n+ *   received).\n+ *\n+ * Transaction requests are then assigned to peers, following these rules:\n+ *\n+ * - No transaction is requested as long as another request for the same txhash is outstanding (it needs to fail\n+ *   first by passing expiry, or a NOTFOUND or invalid transaction has to be received for it).\n+ *\n+ *   Rationale: to avoid wasting bandwidth on multiple copies of the same transaction. Note that this only works\n+ *              per txhash, so if the same transaction is announced both through txid and wtxid, we have no means\n+ *              to prevent fetching both (the caller can however mitigate this by delaying one, see further).\n+ *\n+ * - The same transaction is never requested twice from the same peer, unless the announcement was forgotten in\n+ *   between, and re-announced. Announcements are forgotten only:\n+ *   - If a peer goes offline, all its announcements are forgotten.\n+ *   - If a transaction has been successfully received, or is otherwise no longer needed, the caller can call\n+ *     ForgetTxHash, which removes all announcements across all peers with the specified txhash.\n+ *   - If for a given txhash only already-failed announcements remain, they are all forgotten.\n+ *\n+ *   Rationale: giving a peer multiple chances to announce a transaction would allow them to bias requests in their\n+ *              favor, worsening transaction censoring attacks. The flip side is that as long as an attacker manages\n+ *              to prevent us from receiving a transaction, failed announcements (including those from honest peers)\n+ *              will linger longer, increasing memory usage somewhat. The impact of this is limited by imposing a\n+ *              cap on the number of tracked announcements per peer. As failed requests in response to announcements\n+ *              from honest peers should be rare, this almost solely hinders attackers.\n+ *              Transaction censoring attacks can be done by announcing transactions quickly while not answering\n+ *              requests for them. See https://allquantor.at/blockchainbib/pdf/miller2015topology.pdf for more\n+ *              information.\n+ *\n+ * - Transactions are not requested from a peer until its reqtime has passed.\n+ *\n+ *   Rationale: enable the calling code to define a delay for less-than-ideal peers, so that (presumed) better\n+ *              peers have a chance to give their announcement first.\n+ *\n+ * - If multiple viable candidate peers exist according to the above rules, pick a peer as follows:\n+ *\n+ *   - If any preferred peers are available, non-preferred peers are not considered for what follows.\n+ *\n+ *     Rationale: preferred peers are more trusted by us, so are less likely to be under attacker control.\n+ *\n+ *   - Pick a uniformly random peer among the candidates.\n+ *\n+ *     Rationale: random assignments are hard to influence for attackers.\n+ *\n+ * Together these rules strike a balance between being fast in non-adverserial conditions and minimizing\n+ * susceptibility to censorship attacks. An attacker that races the network:\n+ * - Will be unsuccessful if all preferred connections are honest (and there is at least one preferred connection).\n+ * - If there are P preferred connections of which Ph>=1 are honest, the attacker can delay us from learning\n+ *   about a transaction by k expiration periods, where k ~ 1 + NHG(N=P-1,K=P-Ph-1,r=1), which has mean\n+ *   P/(Ph+1) (where NHG stands for Negative Hypergeometric distribution). The \"1 +\" is due to the fact that the\n+ *   attacker can be the first to announce through a preferred connection in this scenario, which very likely means\n+ *   they get the first request.\n+ * - If all P preferred connections are to the attacker, and there are NP non-preferred connections of which NPh>=1\n+ *   are honest, where we assume that the attacker can disconnect and reconnect those connections, the distribution\n+ *   becomes k ~ P + NB(p=1-NPh/NP,r=1) (where NB stands for Negative Binomial distribution), which has mean\n+ *   P-1+NP/NPh.\n+ *\n+ * Complexity:\n+ * - Memory usage is proportional to the total number of tracked announcements (Size()) plus the number of\n+ *   peers with a nonzero number of tracked announcements.\n+ * - CPU usage is generally logarithmic in the total number of tracked announcements, plus the number of\n+ *   announcements affected by an operation (amortized O(1) per announcement).\n+ */\n+class TxRequestTracker {\n+    // Avoid littering this header file with implementation details.\n+    class Impl;\n+    const std::unique_ptr<Impl> m_impl;\n+\n+public:\n+    //! Construct a TxRequestTracker.\n+    explicit TxRequestTracker(bool deterministic = false);\n+    ~TxRequestTracker();\n+\n+    // Conceptually, the data structure consists of a collection of \"announcements\", one for each peer/txhash\n+    // combination:\n+    //\n+    // - CANDIDATE announcements represent transactions that were announced by a peer, and that become available for\n+    //   download after their reqtime has passed.\n+    //\n+    // - REQUESTED announcements represent transactions that have been requested, and which we're awaiting a\n+    //   response for from that peer. Their expiry value determines when the request times out.\n+    //\n+    // - COMPLETED announcements represent transactions that have been requested from a peer, and a NOTFOUND or a\n+    //   transaction was received in response (valid or not), or they timed out. They're only kept around to\n+    //   prevent requesting them again. If only COMPLETED announcements for a given txhash remain (so no CANDIDATE\n+    //   or REQUESTED ones), all of them are deleted (this is an invariant, and maintained by all operations below).\n+    //\n+    // The operations below manipulate the data structure.\n+\n+    /** Adds a new CANDIDATE announcement.\n+     *\n+     * Does nothing if one already exists for that (txhash, peer) combination (whether it's CANDIDATE, REQUESTED, or\n+     * COMPLETED). Note that the txid/wtxid property is ignored for determining uniqueness, so if an announcement\n+     * is added for a wtxid H, while one for txid H from the same peer already exists, it will be ignored. This is\n+     * harmless as the txhashes being equal implies it is a non-segwit transaction, so it doesn't matter how it is\n+     * fetched. The new announcement is given the specified preferred and reqtime values, and takes its is_wtxid\n+     * from the specified gtxid.\n+     */\n+    void ReceivedInv(NodeId peer, const GenTxid& gtxid, bool preferred,\n+        std::chrono::microseconds reqtime);\n+\n+    /** Deletes all announcements for a given peer.\n+     *\n+     * It should be called when a peer goes offline.\n+     */\n+    void DisconnectedPeer(NodeId peer);\n+\n+    /** Deletes all announcements for a given txhash (both txid and wtxid ones).\n+     *\n+     * This should be called when a transaction is no longer needed. The caller should ensure that new announcements\n+     * for the same txhash will not trigger new ReceivedInv calls, at least in the short term after this call.\n+     */\n+    void ForgetTxHash(const uint256& txhash);\n+\n+    /** Find the txids to request now from peer.\n+     *\n+     * It does the following:\n+     *  - Convert all REQUESTED announcements (for all txhashes/peers) with (expiry <= now) to COMPLETED ones.\n+     *  - Requestable announcements are selected: CANDIDATE announcements from the specified peer with\n+     *    (reqtime <= now) for which no existing REQUESTED announcement with the same txhash from a different peer\n+     *    exists, and for which the specified peer is the best choice among all (reqtime <= now) CANDIDATE\n+     *    announcements with the same txhash (subject to preferredness rules, and tiebreaking using a deterministic\n+     *    salted hash of peer and txhash).\n+     *  - The selected announcements are converted to GenTxids using their is_wtxid flag, and returned in\n+     *    announcement order (even if multiple were added at the same time, or when the clock went backwards while\n+     *    they were being added). This is done to minimize disruption from dependent transactions being requested\n+     *    out of order: if multiple dependent transactions are announced simultaneously by one peer, and end up\n+     *    being requested from them, the requests will happen in announcement order.\n+     */\n+    std::vector<GenTxid> GetRequestable(NodeId peer, std::chrono::microseconds now);\n+\n+    /** Marks a transaction as requested, with a specified expiry.\n+     *\n+     * If no CANDIDATE announcement for the provided peer and txhash exists, this call has no effect. Otherwise:\n+     *  - That announcement is converted to REQUESTED.\n+     *  - If any other REQUESTED announcement for the same txhash already existed, it means an unexpected request\n+     *    was made (GetRequestable will never advise doing so). In this case it is converted to COMPLETED, as we're\n+     *    no longer waiting for a response to it.\n+     */\n+    void RequestedTx(NodeId peer, const uint256& txhash, std::chrono::microseconds expiry);\n+\n+    /** Converts a CANDIDATE or REQUESTED announcement to a COMPLETED one. If no such announcement exists for the\n+     *  provided peer and txhash, nothing happens.\n+     *\n+     * It should be called whenever a transaction or NOTFOUND was received from a peer. When the transaction is\n+     * not needed entirely anymore, ForgetTxhash should be called instead of, or in addition to, this call.\n+     */\n+    void ReceivedResponse(NodeId peer, const uint256& txhash);\n+\n+    // The operations below inspect the data structure.\n+\n+    /** Count how many REQUESTED announcements a peer has. */\n+    size_t CountInFlight(NodeId peer) const;\n+\n+    /** Count how many CANDIDATE announcements a peer has. */\n+    size_t CountCandidates(NodeId peer) const;\n+\n+    /** Count how many announcements a peer has (REQUESTED, CANDIDATE, and COMPLETED combined). */\n+    size_t Count(NodeId peer) const;\n+\n+    /** Count how many announcements are being tracked in total across all peers and transaction hashes. */\n+    size_t Size() const;\n+};\n+\n+#endif // BITCOIN_TXREQUEST_H"
      },
      {
        "sha": "f358b62903745c60dc52fe3425b993b95a93952c",
        "filename": "src/uint256.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd/src/uint256.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd/src/uint256.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/uint256.cpp?ref=da3b8fde03f2e8060bb7ff3bff17175dab85f0cd",
        "patch": "@@ -80,4 +80,5 @@ template std::string base_blob<256>::ToString() const;\n template void base_blob<256>::SetHex(const char*);\n template void base_blob<256>::SetHex(const std::string&);\n \n+const uint256 uint256::ZERO(0);\n const uint256 uint256::ONE(1);"
      },
      {
        "sha": "ceae70707ebc0df7c17a6649a464cf79ce4f099d",
        "filename": "src/uint256.h",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd/src/uint256.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd/src/uint256.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/uint256.h?ref=da3b8fde03f2e8060bb7ff3bff17175dab85f0cd",
        "patch": "@@ -126,6 +126,7 @@ class uint256 : public base_blob<256> {\n     constexpr uint256() {}\n     constexpr explicit uint256(uint8_t v) : base_blob<256>(v) {}\n     explicit uint256(const std::vector<unsigned char>& vch) : base_blob<256>(vch) {}\n+    static const uint256 ZERO;\n     static const uint256 ONE;\n };\n "
      }
    ]
  },
  {
    "sha": "3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzozYzdmZTBlNWEwZWUxYWJmNGRjMjYzYWU1MzEwZTY4MjUzYzg2NmUx",
    "commit": {
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-09-29T23:10:16Z"
      },
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-10-12T19:08:43Z"
      },
      "message": "Add txrequest unit tests\n\nAdd unit tests for TxRequestTracker. Several scenarios are tested,\nrandomly interleaved with eachother.\n\nIncludes a test by Antoine Riard (ariard).",
      "tree": {
        "sha": "5dfc0534e5f8f7d5600e448f901ef72f78dbd32c",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/5dfc0534e5f8f7d5600e448f901ef72f78dbd32c"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1/comments",
    "author": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "da3b8fde03f2e8060bb7ff3bff17175dab85f0cd",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/da3b8fde03f2e8060bb7ff3bff17175dab85f0cd"
      }
    ],
    "stats": {
      "total": 858,
      "additions": 857,
      "deletions": 1
    },
    "files": [
      {
        "sha": "368ca638b09c3d6b02da5af28f3a569cf00864df",
        "filename": "src/Makefile.test.include",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1/src/Makefile.test.include",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1/src/Makefile.test.include",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/Makefile.test.include?ref=3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1",
        "patch": "@@ -275,6 +275,7 @@ BITCOIN_TESTS =\\\n   test/torcontrol_tests.cpp \\\n   test/transaction_tests.cpp \\\n   test/txindex_tests.cpp \\\n+  test/txrequest_tests.cpp \\\n   test/txvalidation_tests.cpp \\\n   test/txvalidationcache_tests.cpp \\\n   test/uint256_tests.cpp \\"
      },
      {
        "sha": "46927059aeaeb39677101a92e332476f468beaac",
        "filename": "src/test/txrequest_tests.cpp",
        "status": "added",
        "additions": 711,
        "deletions": 0,
        "changes": 711,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1/src/test/txrequest_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1/src/test/txrequest_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/txrequest_tests.cpp?ref=3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1",
        "patch": "@@ -0,0 +1,711 @@\n+// Copyright (c) 2020 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+\n+#include <txrequest.h>\n+#include <uint256.h>\n+\n+#include <test/util/setup_common.h>\n+\n+#include <algorithm>\n+#include <functional>\n+#include <vector>\n+\n+#include <boost/test/unit_test.hpp>\n+\n+BOOST_FIXTURE_TEST_SUITE(txrequest_tests, BasicTestingSetup)\n+\n+namespace {\n+\n+constexpr std::chrono::microseconds MIN_TIME = std::chrono::microseconds::min();\n+constexpr std::chrono::microseconds MAX_TIME = std::chrono::microseconds::max();\n+constexpr std::chrono::microseconds MICROSECOND = std::chrono::microseconds{1};\n+constexpr std::chrono::microseconds NO_TIME = std::chrono::microseconds{0};\n+\n+/** An Action is a function to call at a particular (simulated) timestamp. */\n+using Action = std::pair<std::chrono::microseconds, std::function<void()>>;\n+\n+/** Object that stores actions from multiple interleaved scenarios, and data shared across them.\n+ *\n+ * The Scenario below is used to fill this.\n+ */\n+struct Runner\n+{\n+    /** The TxRequestTracker being tested. */\n+    TxRequestTracker txrequest;\n+\n+    /** List of actions to be executed (in order of increasing timestamp). */\n+    std::vector<Action> actions;\n+\n+    /** Which node ids have been assigned already (to prevent reuse). */\n+    std::set<NodeId> peerset;\n+\n+    /** Which txhashes have been assigned already (to prevent reuse). */\n+    std::set<uint256> txhashset;\n+};\n+\n+std::chrono::microseconds RandomTime8s() { return std::chrono::microseconds{1 + InsecureRandBits(23)}; }\n+std::chrono::microseconds RandomTime1y() { return std::chrono::microseconds{1 + InsecureRandBits(45)}; }\n+\n+/** A proxy for a Runner that helps build a sequence of consecutive test actions on a TxRequestTracker.\n+ *\n+ * Each Scenario is a proxy through which actions for the (sequential) execution of various tests are added to a\n+ * Runner. The actions from multiple scenarios are then run concurrently, resulting in these tests being performed\n+ * against a TxRequestTracker in parallel. Every test has its own unique txhashes and NodeIds which are not\n+ * reused in other tests, and thus they should be independent from each other. Running them in parallel however\n+ * means that we verify the behavior (w.r.t. one test's txhashes and NodeIds) even when the state of the data\n+ * structure is more complicated due to the presence of other tests.\n+ */\n+class Scenario\n+{\n+    Runner& m_runner;\n+    std::chrono::microseconds m_now;\n+    std::string m_testname;\n+\n+public:\n+    Scenario(Runner& runner, std::chrono::microseconds starttime) : m_runner(runner), m_now(starttime) {}\n+\n+    /** Set a name for the current test, to give more clear error messages. */\n+    void SetTestName(std::string testname)\n+    {\n+        m_testname = std::move(testname);\n+    }\n+\n+    /** Advance this Scenario's time; this affects the timestamps newly scheduled events get. */\n+    void AdvanceTime(std::chrono::microseconds amount)\n+    {\n+        assert(amount.count() >= 0);\n+        m_now += amount;\n+    }\n+\n+    /** Schedule a ForgetTxHash call at the Scheduler's current time. */\n+    void ForgetTxHash(const uint256& txhash)\n+    {\n+        auto& runner = m_runner;\n+        runner.actions.emplace_back(m_now, [=,&runner]() {\n+            runner.txrequest.ForgetTxHash(txhash);\n+            runner.txrequest.SanityCheck();\n+        });\n+    }\n+\n+    /** Schedule a ReceivedInv call at the Scheduler's current time. */\n+    void ReceivedInv(NodeId peer, const GenTxid& gtxid, bool pref, std::chrono::microseconds reqtime)\n+    {\n+        auto& runner = m_runner;\n+        runner.actions.emplace_back(m_now, [=,&runner]() {\n+            runner.txrequest.ReceivedInv(peer, gtxid, pref, reqtime);\n+            runner.txrequest.SanityCheck();\n+        });\n+    }\n+\n+    /** Schedule a DisconnectedPeer call at the Scheduler's current time. */\n+    void DisconnectedPeer(NodeId peer)\n+    {\n+        auto& runner = m_runner;\n+        runner.actions.emplace_back(m_now, [=,&runner]() {\n+            runner.txrequest.DisconnectedPeer(peer);\n+            runner.txrequest.SanityCheck();\n+        });\n+    }\n+\n+    /** Schedule a RequestedTx call at the Scheduler's current time. */\n+    void RequestedTx(NodeId peer, const uint256& txhash, std::chrono::microseconds exptime)\n+    {\n+        auto& runner = m_runner;\n+        runner.actions.emplace_back(m_now, [=,&runner]() {\n+            runner.txrequest.RequestedTx(peer, txhash, exptime);\n+            runner.txrequest.SanityCheck();\n+        });\n+    }\n+\n+    /** Schedule a ReceivedResponse call at the Scheduler's current time. */\n+    void ReceivedResponse(NodeId peer, const uint256& txhash)\n+    {\n+        auto& runner = m_runner;\n+        runner.actions.emplace_back(m_now, [=,&runner]() {\n+            runner.txrequest.ReceivedResponse(peer, txhash);\n+            runner.txrequest.SanityCheck();\n+        });\n+    }\n+\n+    /** Schedule calls to verify the TxRequestTracker's state at the Scheduler's current time.\n+     *\n+     * @param peer       The peer whose state will be inspected.\n+     * @param expected   The expected return value for GetRequestable(peer)\n+     * @param candidates The expected return value CountCandidates(peer)\n+     * @param inflight   The expected return value CountInFlight(peer)\n+     * @param completed  The expected return value of Count(peer), minus candidates and inflight.\n+     * @param checkname  An arbitrary string to include in error messages, for test identificatrion.\n+     * @param offset     Offset with the current time to use (must be <= 0). This allows simulations of time going\n+     *                   backwards (but note that the ordering of this event only follows the scenario's m_now.\n+     */\n+    void Check(NodeId peer, const std::vector<GenTxid>& expected, size_t candidates, size_t inflight,\n+        size_t completed, const std::string& checkname,\n+        std::chrono::microseconds offset = std::chrono::microseconds{0})\n+    {\n+        const auto comment = m_testname + \" \" + checkname;\n+        auto& runner = m_runner;\n+        const auto now = m_now;\n+        assert(offset.count() <= 0);\n+        runner.actions.emplace_back(m_now, [=,&runner]() {\n+            auto ret = runner.txrequest.GetRequestable(peer, now + offset);\n+            runner.txrequest.SanityCheck();\n+            runner.txrequest.PostGetRequestableSanityCheck(now + offset);\n+            size_t total = candidates + inflight + completed;\n+            size_t real_total = runner.txrequest.Count(peer);\n+            size_t real_candidates = runner.txrequest.CountCandidates(peer);\n+            size_t real_inflight = runner.txrequest.CountInFlight(peer);\n+            BOOST_CHECK_MESSAGE(real_total == total, strprintf(\"[\" + comment + \"] total %i (%i expected)\", real_total, total));\n+            BOOST_CHECK_MESSAGE(real_inflight == inflight, strprintf(\"[\" + comment + \"] inflight %i (%i expected)\", real_inflight, inflight));\n+            BOOST_CHECK_MESSAGE(real_candidates == candidates, strprintf(\"[\" + comment + \"] candidates %i (%i expected)\", real_candidates, candidates));\n+            BOOST_CHECK_MESSAGE(ret == expected, \"[\" + comment + \"] mismatching requestables\");\n+        });\n+    }\n+\n+    /** Generate a random txhash, whose priorities for certain peers are constrained.\n+     *\n+     * For example, NewTxHash({{p1,p2,p3},{p2,p4,p5}}) will generate a txhash T such that both:\n+     *  - priority(p1,T) > priority(p2,T) > priority(p3,T)\n+     *  - priority(p2,T) > priority(p4,T) > priority(p5,T)\n+     * where priority is the predicted internal TxRequestTracker's priority, assuming all announcements\n+     * are within the same preferredness class.\n+     */\n+    uint256 NewTxHash(const std::vector<std::vector<NodeId>>& orders = {})\n+    {\n+        uint256 ret;\n+        bool ok;\n+        do {\n+            ret = InsecureRand256();\n+            ok = true;\n+            for (const auto& order : orders) {\n+                for (size_t pos = 1; pos < order.size(); ++pos) {\n+                    uint64_t prio_prev = m_runner.txrequest.ComputePriority(ret, order[pos - 1], true);\n+                    uint64_t prio_cur = m_runner.txrequest.ComputePriority(ret, order[pos], true);\n+                    if (prio_prev <= prio_cur) {\n+                        ok = false;\n+                        break;\n+                    }\n+                }\n+                if (!ok) break;\n+            }\n+            if (ok) {\n+                ok = m_runner.txhashset.insert(ret).second;\n+            }\n+        } while(!ok);\n+        return ret;\n+    }\n+\n+    /** Generate a random GenTxid; the txhash follows NewTxHash; the is_wtxid flag is random. */\n+    GenTxid NewGTxid(const std::vector<std::vector<NodeId>>& orders = {})\n+    {\n+        return {InsecureRandBool(), NewTxHash(orders)};\n+    }\n+\n+    /** Generate a new random NodeId to use as peer. The same NodeId is never returned twice\n+     *  (across all Scenarios combined). */\n+    NodeId NewPeer()\n+    {\n+        bool ok;\n+        NodeId ret;\n+        do {\n+            ret = InsecureRandBits(63);\n+            ok = m_runner.peerset.insert(ret).second;\n+        } while(!ok);\n+        return ret;\n+    }\n+\n+    std::chrono::microseconds Now() const { return m_now; }\n+};\n+\n+/** Add to scenario a test with a single tx announced by a single peer.\n+ *\n+ * config is an integer in [0, 32), which controls which variant of the test is used.\n+ */\n+void BuildSingleTest(Scenario& scenario, int config)\n+{\n+    auto peer = scenario.NewPeer();\n+    auto gtxid = scenario.NewGTxid();\n+    bool immediate = config & 1;\n+    bool preferred = config & 2;\n+    auto delay = immediate ? NO_TIME : RandomTime8s();\n+\n+    scenario.SetTestName(strprintf(\"Single(config=%i)\", config));\n+\n+    // Receive an announcement, either immediately requestable or delayed.\n+    scenario.ReceivedInv(peer, gtxid, preferred, immediate ? MIN_TIME : scenario.Now() + delay);\n+    if (immediate) {\n+        scenario.Check(peer, {gtxid}, 1, 0, 0, \"s1\");\n+    } else {\n+        scenario.Check(peer, {}, 1, 0, 0, \"s2\");\n+        scenario.AdvanceTime(delay - MICROSECOND);\n+        scenario.Check(peer, {}, 1, 0, 0, \"s3\");\n+        scenario.AdvanceTime(MICROSECOND);\n+        scenario.Check(peer, {gtxid}, 1, 0, 0, \"s4\");\n+    }\n+\n+    if (config >> 3) { // We'll request the transaction\n+        scenario.AdvanceTime(RandomTime8s());\n+        auto expiry = RandomTime8s();\n+        scenario.Check(peer, {gtxid}, 1, 0, 0, \"s5\");\n+        scenario.RequestedTx(peer, gtxid.GetHash(), scenario.Now() + expiry);\n+        scenario.Check(peer, {}, 0, 1, 0, \"s6\");\n+\n+        if ((config >> 3) == 1) { // The request will time out\n+            scenario.AdvanceTime(expiry - MICROSECOND);\n+            scenario.Check(peer, {}, 0, 1, 0, \"s7\");\n+            scenario.AdvanceTime(MICROSECOND);\n+            scenario.Check(peer, {}, 0, 0, 0, \"s8\");\n+            return;\n+        } else {\n+            scenario.AdvanceTime(std::chrono::microseconds{InsecureRandRange(expiry.count())});\n+            scenario.Check(peer, {}, 0, 1, 0, \"s9\");\n+            if ((config >> 3) == 3) { // A response will arrive for the transaction\n+                scenario.ReceivedResponse(peer, gtxid.GetHash());\n+                scenario.Check(peer, {}, 0, 0, 0, \"s10\");\n+                return;\n+            }\n+        }\n+    }\n+\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    if (config & 4) { // The peer will go offline\n+        scenario.DisconnectedPeer(peer);\n+    } else { // The transaction is no longer needed\n+        scenario.ForgetTxHash(gtxid.GetHash());\n+    }\n+    scenario.Check(peer, {}, 0, 0, 0, \"s11\");\n+}\n+\n+/** Add to scenario a test with a single tx announced by two peers, to verify the\n+ *  right peer is selected for requests.\n+ *\n+ * config is an integer in [0, 32), which controls which variant of the test is used.\n+ */\n+void BuildPriorityTest(Scenario& scenario, int config)\n+{\n+    scenario.SetTestName(strprintf(\"Priority(config=%i)\", config));\n+\n+    // Two peers. They will announce in order {peer1, peer2}.\n+    auto peer1 = scenario.NewPeer(), peer2 = scenario.NewPeer();\n+    // Construct a transaction that under random rules would be preferred by peer2 or peer1,\n+    // depending on configuration.\n+    bool prio1 = config & 1;\n+    auto gtxid = prio1 ? scenario.NewGTxid({{peer1, peer2}}) : scenario.NewGTxid({{peer2, peer1}});\n+    bool pref1 = config & 2, pref2 = config & 4;\n+\n+    scenario.ReceivedInv(peer1, gtxid, pref1, MIN_TIME);\n+    scenario.Check(peer1, {gtxid}, 1, 0, 0, \"p1\");\n+    if (InsecureRandBool()) {\n+        scenario.AdvanceTime(RandomTime8s());\n+        scenario.Check(peer1, {gtxid}, 1, 0, 0, \"p2\");\n+    }\n+\n+    scenario.ReceivedInv(peer2, gtxid, pref2, MIN_TIME);\n+    bool stage2_prio =\n+        // At this point, peer2 will be given priority if:\n+        // - It is preferred and peer1 is not\n+        (pref2 && !pref1) ||\n+        // - They're in the same preference class,\n+        //   and the randomized priority favors peer2 over peer1.\n+        (pref1 == pref2 && !prio1);\n+    NodeId priopeer = stage2_prio ? peer2 : peer1, otherpeer = stage2_prio ? peer1 : peer2;\n+    scenario.Check(otherpeer, {}, 1, 0, 0, \"p3\");\n+    scenario.Check(priopeer, {gtxid}, 1, 0, 0, \"p4\");\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.Check(otherpeer, {}, 1, 0, 0, \"p5\");\n+    scenario.Check(priopeer, {gtxid}, 1, 0, 0, \"p6\");\n+\n+    // We possibly request from the selected peer.\n+    if (config & 8) {\n+        scenario.RequestedTx(priopeer, gtxid.GetHash(), MAX_TIME);\n+        scenario.Check(priopeer, {}, 0, 1, 0, \"p7\");\n+        scenario.Check(otherpeer, {}, 1, 0, 0, \"p8\");\n+        if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    }\n+\n+    // The peer which was selected (or requested from) now goes offline, or a NOTFOUND is received from them.\n+    if (config & 16) {\n+        scenario.DisconnectedPeer(priopeer);\n+    } else {\n+        scenario.ReceivedResponse(priopeer, gtxid.GetHash());\n+    }\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.Check(priopeer, {}, 0, 0, !(config & 16), \"p8\");\n+    scenario.Check(otherpeer, {gtxid}, 1, 0, 0, \"p9\");\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+\n+    // Now the other peer goes offline.\n+    scenario.DisconnectedPeer(otherpeer);\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.Check(peer1, {}, 0, 0, 0, \"p10\");\n+    scenario.Check(peer2, {}, 0, 0, 0, \"p11\");\n+}\n+\n+/** Add to scenario a randomized test in which N peers announce the same transaction, to verify\n+ *  the order in which they are requested. */\n+void BuildBigPriorityTest(Scenario& scenario, int peers)\n+{\n+    scenario.SetTestName(strprintf(\"BigPriority(peers=%i)\", peers));\n+\n+    // We will have N peers announce the same transaction.\n+    std::map<NodeId, bool> preferred;\n+    std::vector<NodeId> pref_peers, npref_peers;\n+    int num_pref = InsecureRandRange(peers + 1) ; // Some preferred, ...\n+    int num_npref = peers - num_pref; // some not preferred.\n+    for (int i = 0; i < num_pref; ++i) {\n+        pref_peers.push_back(scenario.NewPeer());\n+        preferred[pref_peers.back()] = true;\n+    }\n+    for (int i = 0; i < num_npref; ++i) {\n+        npref_peers.push_back(scenario.NewPeer());\n+        preferred[npref_peers.back()] = false;\n+    }\n+    // Make a list of all peers, in order of intended request order (concatenation of pref_peers and npref_peers).\n+    std::vector<NodeId> request_order;\n+    for (int i = 0; i < num_pref; ++i) request_order.push_back(pref_peers[i]);\n+    for (int i = 0; i < num_npref; ++i) request_order.push_back(npref_peers[i]);\n+\n+    // Determine the announcement order randomly.\n+    std::vector<NodeId> announce_order = request_order;\n+    Shuffle(announce_order.begin(), announce_order.end(), g_insecure_rand_ctx);\n+\n+    // Find a gtxid whose txhash prioritization is consistent with the required ordering within pref_peers and\n+    // within npref_peers.\n+    auto gtxid = scenario.NewGTxid({pref_peers, npref_peers});\n+\n+    // Decide reqtimes in opposite order of the expected request order. This means that as time passes we expect the\n+    // to-be-requested-from-peer will change every time a subsequent reqtime is passed.\n+    std::map<NodeId, std::chrono::microseconds> reqtimes;\n+    auto reqtime = scenario.Now();\n+    for (int i = peers - 1; i >= 0; --i) {\n+        reqtime += RandomTime8s();\n+        reqtimes[request_order[i]] = reqtime;\n+    }\n+\n+    // Actually announce from all peers simultaneously (but in announce_order).\n+    for (const auto peer : announce_order) {\n+        scenario.ReceivedInv(peer, gtxid, preferred[peer], reqtimes[peer]);\n+    }\n+    for (const auto peer : announce_order) {\n+        scenario.Check(peer, {}, 1, 0, 0, \"b1\");\n+    }\n+\n+    // Let time pass and observe the to-be-requested-from peer change, from nonpreferred to preferred, and from\n+    // high priority to low priority within each class.\n+    for (int i = peers - 1; i >= 0; --i) {\n+        scenario.AdvanceTime(reqtimes[request_order[i]] - scenario.Now() - MICROSECOND);\n+        scenario.Check(request_order[i], {}, 1, 0, 0, \"b2\");\n+        scenario.AdvanceTime(MICROSECOND);\n+        scenario.Check(request_order[i], {gtxid}, 1, 0, 0, \"b3\");\n+    }\n+\n+    // Peers now in random order go offline, or send NOTFOUNDs. At every point in time the new to-be-requested-from\n+    // peer should be the best remaining one, so verify this after every response.\n+    for (int i = 0; i < peers; ++i) {\n+        if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+        const int pos = InsecureRandRange(request_order.size());\n+        const auto peer = request_order[pos];\n+        request_order.erase(request_order.begin() + pos);\n+        if (InsecureRandBool()) {\n+            scenario.DisconnectedPeer(peer);\n+            scenario.Check(peer, {}, 0, 0, 0, \"b4\");\n+        } else {\n+            scenario.ReceivedResponse(peer, gtxid.GetHash());\n+            scenario.Check(peer, {}, 0, 0, request_order.size() > 0, \"b5\");\n+        }\n+        if (request_order.size()) {\n+            scenario.Check(request_order[0], {gtxid}, 1, 0, 0, \"b6\");\n+        }\n+    }\n+\n+    // Everything is gone in the end.\n+    for (const auto peer : announce_order) {\n+        scenario.Check(peer, {}, 0, 0, 0, \"b7\");\n+    }\n+}\n+\n+/** Add to scenario a test with one peer announcing two transactions, to verify they are\n+ *  fetched in announcement order.\n+ *\n+ *  config is an integer in [0, 4) inclusive, and selects the variant of the test.\n+ */\n+void BuildRequestOrderTest(Scenario& scenario, int config)\n+{\n+    scenario.SetTestName(strprintf(\"RequestOrder(config=%i)\", config));\n+\n+    auto peer = scenario.NewPeer();\n+    auto gtxid1 = scenario.NewGTxid();\n+    auto gtxid2 = scenario.NewGTxid();\n+\n+    auto reqtime2 = scenario.Now() + RandomTime8s();\n+    auto reqtime1 = reqtime2 + RandomTime8s();\n+\n+    scenario.ReceivedInv(peer, gtxid1, config & 1, reqtime1);\n+    // Simulate time going backwards by giving the second announcement an earlier reqtime.\n+    scenario.ReceivedInv(peer, gtxid2, config & 2, reqtime2);\n+\n+    scenario.AdvanceTime(reqtime2 - MICROSECOND - scenario.Now());\n+    scenario.Check(peer, {}, 2, 0, 0, \"o1\");\n+    scenario.AdvanceTime(MICROSECOND);\n+    scenario.Check(peer, {gtxid2}, 2, 0, 0, \"o2\");\n+    scenario.AdvanceTime(reqtime1 - MICROSECOND - scenario.Now());\n+    scenario.Check(peer, {gtxid2}, 2, 0, 0, \"o3\");\n+    scenario.AdvanceTime(MICROSECOND);\n+    // Even with time going backwards in between announcements, the return value of GetRequestable is in\n+    // announcement order.\n+    scenario.Check(peer, {gtxid1, gtxid2}, 2, 0, 0, \"o4\");\n+\n+    scenario.DisconnectedPeer(peer);\n+    scenario.Check(peer, {}, 0, 0, 0, \"o5\");\n+}\n+\n+/** Add to scenario a test that verifies behavior related to both txid and wtxid with the same\n+ *  hash being announced.\n+ *\n+ *  config is an integer in [0, 4) inclusive, and selects the variant of the test used.\n+*/\n+void BuildWtxidTest(Scenario& scenario, int config)\n+{\n+    scenario.SetTestName(strprintf(\"Wtxid(config=%i)\", config));\n+\n+    auto peerT = scenario.NewPeer();\n+    auto peerW = scenario.NewPeer();\n+    auto txhash = scenario.NewTxHash();\n+    GenTxid txid{false, txhash};\n+    GenTxid wtxid{true, txhash};\n+\n+    auto reqtimeT = InsecureRandBool() ? MIN_TIME : scenario.Now() + RandomTime8s();\n+    auto reqtimeW = InsecureRandBool() ? MIN_TIME : scenario.Now() + RandomTime8s();\n+\n+    // Announce txid first or wtxid first.\n+    if (config & 1) {\n+        scenario.ReceivedInv(peerT, txid, config & 2, reqtimeT);\n+        if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+        scenario.ReceivedInv(peerW, wtxid, !(config & 2), reqtimeW);\n+    } else {\n+        scenario.ReceivedInv(peerW, wtxid, !(config & 2), reqtimeW);\n+        if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+        scenario.ReceivedInv(peerT, txid, config & 2, reqtimeT);\n+    }\n+\n+    // Let time pass if needed, and check that the preferred announcement (txid or wtxid)\n+    // is correctly to-be-requested (and with the correct wtxidness).\n+    auto max_reqtime = std::max(reqtimeT, reqtimeW);\n+    if (max_reqtime > scenario.Now()) scenario.AdvanceTime(max_reqtime - scenario.Now());\n+    if (config & 2) {\n+        scenario.Check(peerT, {txid}, 1, 0, 0, \"w1\");\n+        scenario.Check(peerW, {}, 1, 0, 0, \"w2\");\n+    } else {\n+        scenario.Check(peerT, {}, 1, 0, 0, \"w3\");\n+        scenario.Check(peerW, {wtxid}, 1, 0, 0, \"w4\");\n+    }\n+\n+    // Let the preferred announcement be requested. It's not going to be delivered.\n+    auto expiry = RandomTime8s();\n+    if (config & 2) {\n+        scenario.RequestedTx(peerT, txid.GetHash(), scenario.Now() + expiry);\n+        scenario.Check(peerT, {}, 0, 1, 0, \"w5\");\n+        scenario.Check(peerW, {}, 1, 0, 0, \"w6\");\n+    } else {\n+        scenario.RequestedTx(peerW, wtxid.GetHash(), scenario.Now() + expiry);\n+        scenario.Check(peerT, {}, 1, 0, 0, \"w7\");\n+        scenario.Check(peerW, {}, 0, 1, 0, \"w8\");\n+    }\n+\n+    // After reaching expiration time of the preferred announcement, verify that the\n+    // remaining one is requestable\n+    scenario.AdvanceTime(expiry);\n+    if (config & 2) {\n+        scenario.Check(peerT, {}, 0, 0, 1, \"w9\");\n+        scenario.Check(peerW, {wtxid}, 1, 0, 0, \"w10\");\n+    } else {\n+        scenario.Check(peerT, {txid}, 1, 0, 0, \"w11\");\n+        scenario.Check(peerW, {}, 0, 0, 1, \"w12\");\n+    }\n+\n+    // If a good transaction with either that hash as wtxid or txid arrives, both\n+    // announcements are gone.\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.ForgetTxHash(txhash);\n+    scenario.Check(peerT, {}, 0, 0, 0, \"w13\");\n+    scenario.Check(peerW, {}, 0, 0, 0, \"w14\");\n+}\n+\n+/** Add to scenario a test that exercises clocks that go backwards. */\n+void BuildTimeBackwardsTest(Scenario& scenario)\n+{\n+    auto peer1 = scenario.NewPeer();\n+    auto peer2 = scenario.NewPeer();\n+    auto gtxid = scenario.NewGTxid({{peer1, peer2}});\n+\n+    // Announce from peer2.\n+    auto reqtime = scenario.Now() + RandomTime8s();\n+    scenario.ReceivedInv(peer2, gtxid, true, reqtime);\n+    scenario.Check(peer2, {}, 1, 0, 0, \"r1\");\n+    scenario.AdvanceTime(reqtime - scenario.Now());\n+    scenario.Check(peer2, {gtxid}, 1, 0, 0, \"r2\");\n+    // Check that if the clock goes backwards by 1us, the transaction would stop being requested.\n+    scenario.Check(peer2, {}, 1, 0, 0, \"r3\", -MICROSECOND);\n+    // But it reverts to being requested if time goes forward again.\n+    scenario.Check(peer2, {gtxid}, 1, 0, 0, \"r4\");\n+\n+    // Announce from peer1.\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.ReceivedInv(peer1, gtxid, true, MAX_TIME);\n+    scenario.Check(peer2, {gtxid}, 1, 0, 0, \"r5\");\n+    scenario.Check(peer1, {}, 1, 0, 0, \"r6\");\n+\n+    // Request from peer1.\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    auto expiry = scenario.Now() + RandomTime8s();\n+    scenario.RequestedTx(peer1, gtxid.GetHash(), expiry);\n+    scenario.Check(peer1, {}, 0, 1, 0, \"r7\");\n+    scenario.Check(peer2, {}, 1, 0, 0, \"r8\");\n+\n+    // Expiration passes.\n+    scenario.AdvanceTime(expiry - scenario.Now());\n+    scenario.Check(peer1, {}, 0, 0, 1, \"r9\");\n+    scenario.Check(peer2, {gtxid}, 1, 0, 0, \"r10\"); // Request goes back to peer2.\n+    scenario.Check(peer1, {}, 0, 0, 1, \"r11\", -MICROSECOND); // Going back does not unexpire.\n+    scenario.Check(peer2, {gtxid}, 1, 0, 0, \"r12\", -MICROSECOND);\n+\n+    // Peer2 goes offline, meaning no viable announcements remain.\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.DisconnectedPeer(peer2);\n+    scenario.Check(peer1, {}, 0, 0, 0, \"r13\");\n+    scenario.Check(peer2, {}, 0, 0, 0, \"r14\");\n+}\n+\n+/** Add to scenario a test that involves RequestedTx() calls for txhashes not returned by GetRequestable. */\n+void BuildWeirdRequestsTest(Scenario& scenario)\n+{\n+    auto peer1 = scenario.NewPeer();\n+    auto peer2 = scenario.NewPeer();\n+    auto gtxid1 = scenario.NewGTxid({{peer1, peer2}});\n+    auto gtxid2 = scenario.NewGTxid({{peer2, peer1}});\n+\n+    // Announce gtxid1 by peer1.\n+    scenario.ReceivedInv(peer1, gtxid1, true, MIN_TIME);\n+    scenario.Check(peer1, {gtxid1}, 1, 0, 0, \"q1\");\n+\n+    // Announce gtxid2 by peer2.\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.ReceivedInv(peer2, gtxid2, true, MIN_TIME);\n+    scenario.Check(peer1, {gtxid1}, 1, 0, 0, \"q2\");\n+    scenario.Check(peer2, {gtxid2}, 1, 0, 0, \"q3\");\n+\n+    // We request gtxid2 from *peer1* - no effect.\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.RequestedTx(peer1, gtxid2.GetHash(), MAX_TIME);\n+    scenario.Check(peer1, {gtxid1}, 1, 0, 0, \"q4\");\n+    scenario.Check(peer2, {gtxid2}, 1, 0, 0, \"q5\");\n+\n+    // Now request gtxid1 from peer1 - marks it as REQUESTED.\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    auto expiryA = scenario.Now() + RandomTime8s();\n+    scenario.RequestedTx(peer1, gtxid1.GetHash(), expiryA);\n+    scenario.Check(peer1, {}, 0, 1, 0, \"q6\");\n+    scenario.Check(peer2, {gtxid2}, 1, 0, 0, \"q7\");\n+\n+    // Request it a second time - nothing happens, as it's already REQUESTED.\n+    auto expiryB = expiryA + RandomTime8s();\n+    scenario.RequestedTx(peer1, gtxid1.GetHash(), expiryB);\n+    scenario.Check(peer1, {}, 0, 1, 0, \"q8\");\n+    scenario.Check(peer2, {gtxid2}, 1, 0, 0, \"q9\");\n+\n+    // Also announce gtxid1 from peer2 now, so that the txhash isn't forgotten when the peer1 request expires.\n+    scenario.ReceivedInv(peer2, gtxid1, true, MIN_TIME);\n+    scenario.Check(peer1, {}, 0, 1, 0, \"q10\");\n+    scenario.Check(peer2, {gtxid2}, 2, 0, 0, \"q11\");\n+\n+    // When reaching expiryA, it expires (not expiryB, which is later).\n+    scenario.AdvanceTime(expiryA - scenario.Now());\n+    scenario.Check(peer1, {}, 0, 0, 1, \"q12\");\n+    scenario.Check(peer2, {gtxid2, gtxid1}, 2, 0, 0, \"q13\");\n+\n+    // Requesting it yet again from peer1 doesn't do anything, as it's already COMPLETED.\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.RequestedTx(peer1, gtxid1.GetHash(), MAX_TIME);\n+    scenario.Check(peer1, {}, 0, 0, 1, \"q14\");\n+    scenario.Check(peer2, {gtxid2, gtxid1}, 2, 0, 0, \"q15\");\n+\n+    // Now announce gtxid2 from peer1.\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.ReceivedInv(peer1, gtxid2, true, MIN_TIME);\n+    scenario.Check(peer1, {}, 1, 0, 1, \"q16\");\n+    scenario.Check(peer2, {gtxid2, gtxid1}, 2, 0, 0, \"q17\");\n+\n+    // And request it from peer1 (weird as peer2 has the preference).\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.RequestedTx(peer1, gtxid2.GetHash(), MAX_TIME);\n+    scenario.Check(peer1, {}, 0, 1, 1, \"q18\");\n+    scenario.Check(peer2, {gtxid1}, 2, 0, 0, \"q19\");\n+\n+    // If peer2 now (normally) requests gtxid2, the existing request by peer1 becomes COMPLETED.\n+    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n+    scenario.RequestedTx(peer2, gtxid2.GetHash(), MAX_TIME);\n+    scenario.Check(peer1, {}, 0, 0, 2, \"q20\");\n+    scenario.Check(peer2, {gtxid1}, 1, 1, 0, \"q21\");\n+\n+    // If peer2 goes offline, no viable announcements remain.\n+    scenario.DisconnectedPeer(peer2);\n+    scenario.Check(peer1, {}, 0, 0, 0, \"q22\");\n+    scenario.Check(peer2, {}, 0, 0, 0, \"q23\");\n+}\n+\n+void TestInterleavedScenarios()\n+{\n+    // Create a list of functions which add tests to scenarios.\n+    std::vector<std::function<void(Scenario&)>> builders;\n+    // Add instances of every test, for every configuration.\n+    for (int n = 0; n < 64; ++n) {\n+        builders.emplace_back([n](Scenario& scenario){ BuildWtxidTest(scenario, n); });\n+        builders.emplace_back([n](Scenario& scenario){ BuildRequestOrderTest(scenario, n & 3); });\n+        builders.emplace_back([n](Scenario& scenario){ BuildSingleTest(scenario, n & 31); });\n+        builders.emplace_back([n](Scenario& scenario){ BuildPriorityTest(scenario, n & 31); });\n+        builders.emplace_back([n](Scenario& scenario){ BuildBigPriorityTest(scenario, (n & 7) + 1); });\n+        builders.emplace_back([](Scenario& scenario){ BuildTimeBackwardsTest(scenario); });\n+        builders.emplace_back([](Scenario& scenario){ BuildWeirdRequestsTest(scenario); });\n+    }\n+    // Randomly shuffle all those functions.\n+    Shuffle(builders.begin(), builders.end(), g_insecure_rand_ctx);\n+\n+    Runner runner;\n+    auto starttime = RandomTime1y();\n+    // Construct many scenarios, and run (up to) 10 randomly-chosen tests consecutively in each.\n+    while (builders.size()) {\n+        // Introduce some variation in the start time of each scenario, so they don't all start off\n+        // concurrently, but get a more random interleaving.\n+        auto scenario_start = starttime + RandomTime8s() + RandomTime8s() + RandomTime8s();\n+        Scenario scenario(runner, scenario_start);\n+        for (int j = 0; builders.size() && j < 10; ++j) {\n+            builders.back()(scenario);\n+            builders.pop_back();\n+        }\n+    }\n+    // Sort all the actions from all those scenarios chronologically, resulting in the actions from\n+    // distinct scenarios to become interleaved. Use stable_sort so that actions from one scenario\n+    // aren't reordered w.r.t. each other.\n+    std::stable_sort(runner.actions.begin(), runner.actions.end(), [](const Action& a1, const Action& a2) {\n+        return a1.first < a2.first;\n+    });\n+\n+    // Run all actions from all scenarios, in order.\n+    for (auto& action : runner.actions) {\n+        action.second();\n+    }\n+\n+    BOOST_CHECK_EQUAL(runner.txrequest.Size(), 0U);\n+}\n+\n+}  // namespace\n+\n+BOOST_AUTO_TEST_CASE(TxRequestTest)\n+{\n+    for (int i = 0; i < 5; ++i) {\n+        TestInterleavedScenarios();\n+    }\n+}\n+\n+BOOST_AUTO_TEST_SUITE_END()"
      },
      {
        "sha": "cabdc6395717fccec6605cc84c3e1c0d536cc1a5",
        "filename": "src/txrequest.cpp",
        "status": "modified",
        "additions": 133,
        "deletions": 1,
        "changes": 134,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1/src/txrequest.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1/src/txrequest.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/txrequest.cpp?ref=3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1",
        "patch": "@@ -228,6 +228,69 @@ struct PeerInfo {\n     size_t m_requested = 0; //!< Number of REQUESTED announcements for this peer.\n };\n \n+/** Per-txhash statistics object. Only used for sanity checking. */\n+struct TxHashInfo\n+{\n+    //! Number of CANDIDATE_DELAYED announcements for this txhash.\n+    size_t m_candidate_delayed = 0;\n+    //! Number of CANDIDATE_READY announcements for this txhash.\n+    size_t m_candidate_ready = 0;\n+    //! Number of CANDIDATE_BEST announcements for this txhash (at most one).\n+    size_t m_candidate_best = 0;\n+    //! Number of REQUESTED announcements for this txhash (at most one; mutually exclusive with CANDIDATE_BEST).\n+    size_t m_requested = 0;\n+    //! The priority of the CANDIDATE_BEST announcement if one exists, or max() otherwise.\n+    Priority m_priority_candidate_best = std::numeric_limits<Priority>::max();\n+    //! The highest priority of all CANDIDATE_READY announcements (or min() if none exist).\n+    Priority m_priority_best_candidate_ready = std::numeric_limits<Priority>::min();\n+    //! All peers we have an announcement for this txhash for.\n+    std::vector<NodeId> m_peers;\n+};\n+\n+/** Compare two PeerInfo objects. Only used for sanity checking. */\n+bool operator==(const PeerInfo& a, const PeerInfo& b)\n+{\n+    return std::tie(a.m_total, a.m_completed, a.m_requested) ==\n+           std::tie(b.m_total, b.m_completed, b.m_requested);\n+};\n+\n+/** (Re)compute the PeerInfo map from the index. Only used for sanity checking. */\n+std::unordered_map<NodeId, PeerInfo> RecomputePeerInfo(const Index& index)\n+{\n+    std::unordered_map<NodeId, PeerInfo> ret;\n+    for (const Announcement& ann : index) {\n+        PeerInfo& info = ret[ann.m_peer];\n+        ++info.m_total;\n+        info.m_requested += (ann.m_state == State::REQUESTED);\n+        info.m_completed += (ann.m_state == State::COMPLETED);\n+    }\n+    return ret;\n+}\n+\n+/** Compute the TxHashInfo map. Only used for sanity checking. */\n+std::map<uint256, TxHashInfo> ComputeTxHashInfo(const Index& index, const PriorityComputer& computer)\n+{\n+    std::map<uint256, TxHashInfo> ret;\n+    for (const Announcement& ann : index) {\n+        TxHashInfo& info = ret[ann.m_txhash];\n+        // Classify how many announcements of each state we have for this txhash.\n+        info.m_candidate_delayed += (ann.m_state == State::CANDIDATE_DELAYED);\n+        info.m_candidate_ready += (ann.m_state == State::CANDIDATE_READY);\n+        info.m_candidate_best += (ann.m_state == State::CANDIDATE_BEST);\n+        info.m_requested += (ann.m_state == State::REQUESTED);\n+        // And track the priority of the best CANDIDATE_READY/CANDIDATE_BEST announcements.\n+        if (ann.m_state == State::CANDIDATE_BEST) {\n+            info.m_priority_candidate_best = computer(ann);\n+        }\n+        if (ann.m_state == State::CANDIDATE_READY) {\n+            info.m_priority_best_candidate_ready = std::max(info.m_priority_best_candidate_ready, computer(ann));\n+        }\n+        // Also keep track of which peers this txhash has an announcement for (so we can detect duplicates).\n+        info.m_peers.push_back(ann.m_peer);\n+    }\n+    return ret;\n+}\n+\n }  // namespace\n \n /** Actual implementation for TxRequestTracker's data structure. */\n@@ -239,12 +302,63 @@ class TxRequestTracker::Impl {\n     //! This tracker's priority computer.\n     const PriorityComputer m_computer;\n \n-    //! This tracker's main data structure.\n+    //! This tracker's main data structure. See SanityCheck() for the invariants that apply to it.\n     Index m_index;\n \n     //! Map with this tracker's per-peer statistics.\n     std::unordered_map<NodeId, PeerInfo> m_peerinfo;\n \n+public:\n+    void SanityCheck() const\n+    {\n+        // Recompute m_peerdata from m_index. This verifies the data in it as it should just be caching statistics\n+        // on m_index. It also verifies the invariant that no PeerInfo announcements with m_total==0 exist.\n+        assert(m_peerinfo == RecomputePeerInfo(m_index));\n+\n+        // Calculate per-txhash statistics from m_index, and validate invariants.\n+        for (auto& item : ComputeTxHashInfo(m_index, m_computer)) {\n+            TxHashInfo& info = item.second;\n+\n+            // Cannot have only COMPLETED peer (txhash should have been forgotten already)\n+            assert(info.m_candidate_delayed + info.m_candidate_ready + info.m_candidate_best + info.m_requested > 0);\n+\n+            // Can have at most 1 CANDIDATE_BEST/REQUESTED peer\n+            assert(info.m_candidate_best + info.m_requested <= 1);\n+\n+            // If there are any CANDIDATE_READY announcements, there must be exactly one CANDIDATE_BEST or REQUESTED\n+            // announcement.\n+            if (info.m_candidate_ready > 0) {\n+                assert(info.m_candidate_best + info.m_requested == 1);\n+            }\n+\n+            // If there is both a CANDIDATE_READY and a CANDIDATE_BEST announcement, the CANDIDATE_BEST one must be\n+            // at least as good (equal or higher priority) as the best CANDIDATE_READY.\n+            if (info.m_candidate_ready && info.m_candidate_best) {\n+                assert(info.m_priority_candidate_best >= info.m_priority_best_candidate_ready);\n+            }\n+\n+            // No txhash can have been announced by the same peer twice.\n+            std::sort(info.m_peers.begin(), info.m_peers.end());\n+            assert(std::adjacent_find(info.m_peers.begin(), info.m_peers.end()) == info.m_peers.end());\n+        }\n+    }\n+\n+    void PostGetRequestableSanityCheck(std::chrono::microseconds now) const\n+    {\n+        for (const Announcement& ann : m_index) {\n+            if (ann.IsWaiting()) {\n+                // REQUESTED and CANDIDATE_DELAYED must have a time in the future (they should have been converted\n+                // to COMPLETED/CANDIDATE_READY respectively).\n+                assert(ann.m_time > now);\n+            } else if (ann.IsSelectable()) {\n+                // CANDIDATE_READY and CANDIDATE_BEST cannot have a time in the future (they should have remained\n+                // CANDIDATE_DELAYED, or should have been converted back to it if time went backwards).\n+                assert(ann.m_time <= now);\n+            }\n+        }\n+    }\n+\n+private:\n     //! Wrapper around Index::...::erase that keeps m_peerinfo up to date.\n     template<typename Tag>\n     Iter<Tag> Erase(Iter<Tag> it)\n@@ -570,6 +684,13 @@ class TxRequestTracker::Impl {\n \n     //! Count how many announcements are being tracked in total across all peers and transactions.\n     size_t Size() const { return m_index.size(); }\n+\n+    uint64_t ComputePriority(const uint256& txhash, NodeId peer, bool preferred) const\n+    {\n+        // Return Priority as a uint64_t as Priority is internal.\n+        return uint64_t{m_computer(txhash, peer, preferred)};\n+    }\n+\n };\n \n TxRequestTracker::TxRequestTracker(bool deterministic) :\n@@ -583,6 +704,12 @@ size_t TxRequestTracker::CountInFlight(NodeId peer) const { return m_impl->Count\n size_t TxRequestTracker::CountCandidates(NodeId peer) const { return m_impl->CountCandidates(peer); }\n size_t TxRequestTracker::Count(NodeId peer) const { return m_impl->Count(peer); }\n size_t TxRequestTracker::Size() const { return m_impl->Size(); }\n+void TxRequestTracker::SanityCheck() const { m_impl->SanityCheck(); }\n+\n+void TxRequestTracker::PostGetRequestableSanityCheck(std::chrono::microseconds now) const\n+{\n+    m_impl->PostGetRequestableSanityCheck(now);\n+}\n \n void TxRequestTracker::ReceivedInv(NodeId peer, const GenTxid& gtxid, bool preferred,\n     std::chrono::microseconds reqtime)\n@@ -604,3 +731,8 @@ std::vector<GenTxid> TxRequestTracker::GetRequestable(NodeId peer, std::chrono::\n {\n     return m_impl->GetRequestable(peer, now);\n }\n+\n+uint64_t TxRequestTracker::ComputePriority(const uint256& txhash, NodeId peer, bool preferred) const\n+{\n+    return m_impl->ComputePriority(txhash, peer, preferred);\n+}"
      },
      {
        "sha": "a434901a5282d4c8994eb1834b0f850ce14df598",
        "filename": "src/txrequest.h",
        "status": "modified",
        "additions": 12,
        "deletions": 0,
        "changes": 12,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1/src/txrequest.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1/src/txrequest.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/txrequest.h?ref=3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1",
        "patch": "@@ -192,6 +192,18 @@ class TxRequestTracker {\n \n     /** Count how many announcements are being tracked in total across all peers and transaction hashes. */\n     size_t Size() const;\n+\n+    /** Access to the internal priority computation (testing only) */\n+    uint64_t ComputePriority(const uint256& txhash, NodeId peer, bool preferred) const;\n+\n+    /** Run internal consistency check (testing only). */\n+    void SanityCheck() const;\n+\n+    /** Run a time-dependent internal consistency check (testing only).\n+     *\n+     * This can only be called immediately after GetRequestable, with the same 'now' parameter.\n+     */\n+    void PostGetRequestableSanityCheck(std::chrono::microseconds now) const;\n };\n \n #endif // BITCOIN_TXREQUEST_H"
      }
    ]
  },
  {
    "sha": "5b03121d60527a193a84c339151481f9c9c1962b",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo1YjAzMTIxZDYwNTI3YTE5M2E4NGMzMzkxNTE0ODFmOWM5YzE5NjJi",
    "commit": {
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-09-21T04:18:59Z"
      },
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-10-12T19:08:47Z"
      },
      "message": "Add txrequest fuzz tests\n\nThis adds a fuzz test that reimplements a naive reimplementation of\nTxRequestTracker (with up to 16 fixed peers and 16 fixed txhashes),\nand compares the real implementation against it.",
      "tree": {
        "sha": "38886e07454cb0d6c14ddbf78d82d1da9cda465a",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/38886e07454cb0d6c14ddbf78d82d1da9cda465a"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/5b03121d60527a193a84c339151481f9c9c1962b",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/5b03121d60527a193a84c339151481f9c9c1962b",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/5b03121d60527a193a84c339151481f9c9c1962b",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/5b03121d60527a193a84c339151481f9c9c1962b/comments",
    "author": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/3c7fe0e5a0ee1abf4dc263ae5310e68253c866e1"
      }
    ],
    "stats": {
      "total": 375,
      "additions": 375,
      "deletions": 0
    },
    "files": [
      {
        "sha": "44a1f0c914d7ce4225c51bd712e8bf5f5dca150c",
        "filename": "src/Makefile.test.include",
        "status": "modified",
        "additions": 7,
        "deletions": 0,
        "changes": 7,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/5b03121d60527a193a84c339151481f9c9c1962b/src/Makefile.test.include",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/5b03121d60527a193a84c339151481f9c9c1962b/src/Makefile.test.include",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/Makefile.test.include?ref=5b03121d60527a193a84c339151481f9c9c1962b",
        "patch": "@@ -151,6 +151,7 @@ FUZZ_TARGETS = \\\n   test/fuzz/tx_in_deserialize \\\n   test/fuzz/tx_out \\\n   test/fuzz/txoutcompressor_deserialize \\\n+  test/fuzz/txrequest \\\n   test/fuzz/txundo_deserialize \\\n   test/fuzz/uint160_deserialize \\\n   test/fuzz/uint256_deserialize\n@@ -1215,6 +1216,12 @@ test_fuzz_txoutcompressor_deserialize_LDADD = $(FUZZ_SUITE_LD_COMMON)\n test_fuzz_txoutcompressor_deserialize_LDFLAGS = $(FUZZ_SUITE_LDFLAGS_COMMON)\n test_fuzz_txoutcompressor_deserialize_SOURCES = test/fuzz/deserialize.cpp\n \n+test_fuzz_txrequest_CPPFLAGS = $(AM_CPPFLAGS) $(BITCOIN_INCLUDES)\n+test_fuzz_txrequest_CXXFLAGS = $(AM_CXXFLAGS) $(PIE_FLAGS)\n+test_fuzz_txrequest_LDADD = $(FUZZ_SUITE_LD_COMMON)\n+test_fuzz_txrequest_LDFLAGS = $(FUZZ_SUITE_LDFLAGS_COMMON)\n+test_fuzz_txrequest_SOURCES = test/fuzz/txrequest.cpp\n+\n test_fuzz_txundo_deserialize_CPPFLAGS = $(AM_CPPFLAGS) $(BITCOIN_INCLUDES) -DTXUNDO_DESERIALIZE=1\n test_fuzz_txundo_deserialize_CXXFLAGS = $(AM_CXXFLAGS) $(PIE_FLAGS)\n test_fuzz_txundo_deserialize_LDADD = $(FUZZ_SUITE_LD_COMMON)"
      },
      {
        "sha": "4a8e32d105d492fa303ad4bc129b896e20ff7c49",
        "filename": "src/test/fuzz/txrequest.cpp",
        "status": "added",
        "additions": 368,
        "deletions": 0,
        "changes": 368,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/5b03121d60527a193a84c339151481f9c9c1962b/src/test/fuzz/txrequest.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/5b03121d60527a193a84c339151481f9c9c1962b/src/test/fuzz/txrequest.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/fuzz/txrequest.cpp?ref=5b03121d60527a193a84c339151481f9c9c1962b",
        "patch": "@@ -0,0 +1,368 @@\n+// Copyright (c) 2020 The Bitcoin Core developers\n+// Distributed under the MIT software license, see the accompanying\n+// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n+\n+#include <crypto/common.h>\n+#include <crypto/sha256.h>\n+#include <crypto/siphash.h>\n+#include <primitives/transaction.h>\n+#include <test/fuzz/fuzz.h>\n+#include <txrequest.h>\n+\n+#include <bitset>\n+#include <cstdint>\n+#include <queue>\n+#include <vector>\n+\n+namespace {\n+\n+constexpr int MAX_TXHASHES = 16;\n+constexpr int MAX_PEERS = 16;\n+\n+//! Randomly generated GenTxids used in this test (length is MAX_TXHASHES).\n+uint256 TXHASHES[MAX_TXHASHES];\n+\n+//! Precomputed random durations (positive and negative, each ~exponentially distributed).\n+std::chrono::microseconds DELAYS[256];\n+\n+struct Initializer\n+{\n+    Initializer()\n+    {\n+        for (uint8_t txhash = 0; txhash < MAX_TXHASHES; txhash += 1) {\n+            CSHA256().Write(&txhash, 1).Finalize(TXHASHES[txhash].begin());\n+        }\n+        int i = 0;\n+        // DELAYS[N] for N=0..15 is just N microseconds.\n+        for (; i < 16; ++i) {\n+            DELAYS[i] = std::chrono::microseconds{i};\n+        }\n+        // DELAYS[N] for N=16..127 has randomly-looking but roughly exponentially increasing values up to\n+        // 198.416453 seconds.\n+        for (; i < 128; ++i) {\n+            int diff_bits = ((i - 10) * 2) / 9;\n+            uint64_t diff = 1 + (CSipHasher(0, 0).Write(i).Finalize() >> (64 - diff_bits));\n+            DELAYS[i] = DELAYS[i - 1] + std::chrono::microseconds{diff};\n+        }\n+        // DELAYS[N] for N=128..255 are negative delays with the same magnitude as N=0..127.\n+        for (; i < 256; ++i) {\n+            DELAYS[i] = -DELAYS[255 - i];\n+        }\n+    }\n+} g_initializer;\n+\n+/** Tester class for TxRequestTracker\n+ *\n+ * It includes a naive reimplementation of its behavior, for a limited set\n+ * of MAX_TXHASHES distinct txids, and MAX_PEERS peer identifiers.\n+ *\n+ * All of the public member functions perform the same operation on\n+ * an actual TxRequestTracker and on the state of the reimplementation.\n+ * The output of GetRequestable is compared with the expected value\n+ * as well.\n+ *\n+ * Check() calls the TxRequestTracker's sanity check, plus compares the\n+ * output of the constant accessors (Size(), CountLoad(), CountTracked())\n+ * with expected values.\n+ */\n+class Tester\n+{\n+    //! TxRequestTracker object being tested.\n+    TxRequestTracker m_tracker;\n+\n+    //! States for txid/peer combinations in the naive data structure.\n+    enum class State {\n+        NOTHING, //!< Absence of this txid/peer combination\n+\n+        // Note that this implementation does not distinguish between DELAYED/READY/BEST variants of CANDIDATE.\n+        CANDIDATE,\n+        REQUESTED,\n+        COMPLETED,\n+    };\n+\n+    //! Sequence numbers, incremented whenever a new CANDIDATE is added.\n+    uint64_t m_current_sequence{0};\n+\n+    //! List of future 'events' (all inserted reqtimes/exptimes). This is used to implement AdvanceToEvent.\n+    std::priority_queue<std::chrono::microseconds, std::vector<std::chrono::microseconds>,\n+        std::greater<std::chrono::microseconds>> m_events;\n+\n+    //! Information about a txhash/peer combination.\n+    struct Announcement\n+    {\n+        std::chrono::microseconds m_time;\n+        uint64_t m_sequence;\n+        State m_state{State::NOTHING};\n+        bool m_preferred;\n+        bool m_is_wtxid;\n+        uint64_t m_priority; //!< Precomputed priority.\n+    };\n+\n+    //! Information about all txhash/peer combination.\n+    Announcement m_announcements[MAX_TXHASHES][MAX_PEERS];\n+\n+    //! The current time; can move forward and backward.\n+    std::chrono::microseconds m_now{244466666};\n+\n+    //! Delete txhashes whose only announcements are COMPLETED.\n+    void Cleanup(int txhash)\n+    {\n+        bool all_nothing = true;\n+        for (int peer = 0; peer < MAX_PEERS; ++peer) {\n+            const Announcement& ann = m_announcements[txhash][peer];\n+            if (ann.m_state != State::NOTHING) {\n+                if (ann.m_state != State::COMPLETED) return;\n+                all_nothing = false;\n+            }\n+        }\n+        if (all_nothing) return;\n+        for (int peer = 0; peer < MAX_PEERS; ++peer) {\n+            m_announcements[txhash][peer].m_state = State::NOTHING;\n+        }\n+    }\n+\n+    //! Find the current best peer to request from for a txhash (or -1 if none).\n+    int GetSelected(int txhash) const\n+    {\n+        int ret = -1;\n+        uint64_t ret_priority = 0;\n+        for (int peer = 0; peer < MAX_PEERS; ++peer) {\n+            const Announcement& ann = m_announcements[txhash][peer];\n+            // Return -1 if there already is a (non-expired) in-flight request.\n+            if (ann.m_state == State::REQUESTED) return -1;\n+            // If it's a viable candidate, see if it has lower priority than the best one so far.\n+            if (ann.m_state == State::CANDIDATE && ann.m_time <= m_now) {\n+                if (ret == -1 || ann.m_priority > ret_priority) {\n+                    std::tie(ret, ret_priority) = std::tie(peer, ann.m_priority);\n+                }\n+            }\n+        }\n+        return ret;\n+    }\n+\n+public:\n+    Tester() : m_tracker(true) {}\n+\n+    std::chrono::microseconds Now() const { return m_now; }\n+\n+    void AdvanceTime(std::chrono::microseconds offset)\n+    {\n+        m_now += offset;\n+        while (!m_events.empty() && m_events.top() <= m_now) m_events.pop();\n+    }\n+\n+    void AdvanceToEvent()\n+    {\n+        while (!m_events.empty() && m_events.top() <= m_now) m_events.pop();\n+        if (!m_events.empty()) {\n+            m_now = m_events.top();\n+            m_events.pop();\n+        }\n+    }\n+\n+    void DisconnectedPeer(int peer)\n+    {\n+        // Apply to naive structure: all announcements for that peer are wiped.\n+        for (int txhash = 0; txhash < MAX_TXHASHES; ++txhash) {\n+            if (m_announcements[txhash][peer].m_state != State::NOTHING) {\n+                m_announcements[txhash][peer].m_state = State::NOTHING;\n+                Cleanup(txhash);\n+            }\n+        }\n+\n+        // Call TxRequestTracker's implementation.\n+        m_tracker.DisconnectedPeer(peer);\n+    }\n+\n+    void ForgetTxHash(int txhash)\n+    {\n+        // Apply to naive structure: all announcements for that txhash are wiped.\n+        for (int peer = 0; peer < MAX_PEERS; ++peer) {\n+            m_announcements[txhash][peer].m_state = State::NOTHING;\n+        }\n+        Cleanup(txhash);\n+\n+        // Call TxRequestTracker's implementation.\n+        m_tracker.ForgetTxHash(TXHASHES[txhash]);\n+    }\n+\n+    void ReceivedInv(int peer, int txhash, bool is_wtxid, bool preferred, std::chrono::microseconds reqtime)\n+    {\n+        // Apply to naive structure: if no announcement for txidnum/peer combination\n+        // already, create a new CANDIDATE; otherwise do nothing.\n+        Announcement& ann = m_announcements[txhash][peer];\n+        if (ann.m_state == State::NOTHING) {\n+            ann.m_preferred = preferred;\n+            ann.m_state = State::CANDIDATE;\n+            ann.m_time = reqtime;\n+            ann.m_is_wtxid = is_wtxid;\n+            ann.m_sequence = m_current_sequence++;\n+            ann.m_priority = m_tracker.ComputePriority(TXHASHES[txhash], peer, ann.m_preferred);\n+\n+            // Add event so that AdvanceToEvent can quickly jump to the point where its reqtime passes.\n+            if (reqtime > m_now) m_events.push(reqtime);\n+        }\n+\n+        // Call TxRequestTracker's implementation.\n+        m_tracker.ReceivedInv(peer, GenTxid{is_wtxid, TXHASHES[txhash]}, preferred, reqtime);\n+    }\n+\n+    void RequestedTx(int peer, int txhash, std::chrono::microseconds exptime)\n+    {\n+        // Apply to naive structure: if a CANDIDATE announcement exists for peer/txhash,\n+        // convert it to REQUESTED, and change any existing REQUESTED announcement for the same txhash to COMPLETED.\n+        if (m_announcements[txhash][peer].m_state == State::CANDIDATE) {\n+            for (int peer2 = 0; peer2 < MAX_PEERS; ++peer2) {\n+                if (m_announcements[txhash][peer2].m_state == State::REQUESTED) {\n+                    m_announcements[txhash][peer2].m_state = State::COMPLETED;\n+                }\n+            }\n+            m_announcements[txhash][peer].m_state = State::REQUESTED;\n+            m_announcements[txhash][peer].m_time = exptime;\n+        }\n+\n+        // Add event so that AdvanceToEvent can quickly jump to the point where its exptime passes.\n+        if (exptime > m_now) m_events.push(exptime);\n+\n+        // Call TxRequestTracker's implementation.\n+        m_tracker.RequestedTx(peer, TXHASHES[txhash], exptime);\n+    }\n+\n+    void ReceivedResponse(int peer, int txhash)\n+    {\n+        // Apply to naive structure: convert anything to COMPLETED.\n+        if (m_announcements[txhash][peer].m_state != State::NOTHING) {\n+            m_announcements[txhash][peer].m_state = State::COMPLETED;\n+            Cleanup(txhash);\n+        }\n+\n+        // Call TxRequestTracker's implementation.\n+        m_tracker.ReceivedResponse(peer, TXHASHES[txhash]);\n+    }\n+\n+    void GetRequestable(int peer)\n+    {\n+        // Implement using naive structure:\n+\n+        //! list of (sequence number, txhash, is_wtxid) tuples.\n+        std::vector<std::tuple<uint64_t, int, bool>> result;\n+        for (int txhash = 0; txhash < MAX_TXHASHES; ++txhash) {\n+            // Mark any expired REQUESTED announcements as COMPLETED.\n+            for (int peer2 = 0; peer2 < MAX_PEERS; ++peer2) {\n+                Announcement& ann2 = m_announcements[txhash][peer2];\n+                if (ann2.m_state == State::REQUESTED && ann2.m_time <= m_now) {\n+                    ann2.m_state = State::COMPLETED;\n+                    break;\n+                }\n+            }\n+            // And delete txids with only COMPLETED announcements left.\n+            Cleanup(txhash);\n+            // CANDIDATEs for which this announcement has the highest priority get returned.\n+            const Announcement& ann = m_announcements[txhash][peer];\n+            if (ann.m_state == State::CANDIDATE && GetSelected(txhash) == peer) {\n+                result.emplace_back(ann.m_sequence, txhash, ann.m_is_wtxid);\n+            }\n+        }\n+        // Sort the results by sequence number.\n+        std::sort(result.begin(), result.end());\n+\n+        // Compare with TxRequestTracker's implementation.\n+        const auto actual = m_tracker.GetRequestable(peer, m_now);\n+\n+        m_tracker.PostGetRequestableSanityCheck(m_now);\n+        assert(result.size() == actual.size());\n+        for (size_t pos = 0; pos < actual.size(); ++pos) {\n+            assert(TXHASHES[std::get<1>(result[pos])] == actual[pos].GetHash());\n+            assert(std::get<2>(result[pos]) == actual[pos].IsWtxid());\n+        }\n+    }\n+\n+    void Check()\n+    {\n+        // Compare CountTracked and CountLoad with naive structure.\n+        size_t total = 0;\n+        for (int peer = 0; peer < MAX_PEERS; ++peer) {\n+            size_t tracked = 0;\n+            size_t inflight = 0;\n+            size_t candidates = 0;\n+            for (int txhash = 0; txhash < MAX_TXHASHES; ++txhash) {\n+                tracked += m_announcements[txhash][peer].m_state != State::NOTHING;\n+                inflight += m_announcements[txhash][peer].m_state == State::REQUESTED;\n+                candidates += m_announcements[txhash][peer].m_state == State::CANDIDATE;\n+            }\n+            assert(m_tracker.Count(peer) == tracked);\n+            assert(m_tracker.CountInFlight(peer) == inflight);\n+            assert(m_tracker.CountCandidates(peer) == candidates);\n+            total += tracked;\n+        }\n+        // Compare Size.\n+        assert(m_tracker.Size() == total);\n+\n+        // Invoke internal consistency check of TxRequestTracker object.\n+        m_tracker.SanityCheck();\n+    }\n+};\n+} // namespace\n+\n+void test_one_input(const std::vector<uint8_t>& buffer)\n+{\n+    // Tester object (which encapsulates a TxRequestTracker).\n+    Tester tester;\n+\n+    // Decode the input as a sequence of instructions with parameters\n+    auto it = buffer.begin();\n+    while (it != buffer.end()) {\n+        int cmd = *(it++) % 11;\n+        int peer, txidnum, delaynum;\n+        switch (cmd) {\n+        case 0: // Make time jump to the next event (m_time of CANDIDATE or REQUESTED)\n+            tester.AdvanceToEvent();\n+            break;\n+        case 1: // Change time\n+            delaynum = it == buffer.end() ? 0 : *(it++);\n+            tester.AdvanceTime(DELAYS[delaynum]);\n+            break;\n+        case 2: // Query for requestable txs\n+            peer = it == buffer.end() ? 0 : *(it++) % MAX_PEERS;\n+            tester.GetRequestable(peer);\n+            break;\n+        case 3: // Peer went offline\n+            peer = it == buffer.end() ? 0 : *(it++) % MAX_PEERS;\n+            tester.DisconnectedPeer(peer);\n+            break;\n+        case 4: // No longer need tx\n+            txidnum = it == buffer.end() ? 0 : *(it++);\n+            tester.ForgetTxHash(txidnum % MAX_TXHASHES);\n+            break;\n+        case 5: // Received immediate preferred inv\n+        case 6: // Same, but non-preferred.\n+            peer = it == buffer.end() ? 0 : *(it++) % MAX_PEERS;\n+            txidnum = it == buffer.end() ? 0 : *(it++);\n+            tester.ReceivedInv(peer, txidnum % MAX_TXHASHES, (txidnum / MAX_TXHASHES) & 1, cmd & 1,\n+                std::chrono::microseconds::min());\n+            break;\n+        case 7: // Received delayed preferred inv\n+        case 8: // Same, but non-preferred.\n+            peer = it == buffer.end() ? 0 : *(it++) % MAX_PEERS;\n+            txidnum = it == buffer.end() ? 0 : *(it++);\n+            delaynum = it == buffer.end() ? 0 : *(it++);\n+            tester.ReceivedInv(peer, txidnum % MAX_TXHASHES, (txidnum / MAX_TXHASHES) & 1, cmd & 1,\n+                tester.Now() + DELAYS[delaynum]);\n+            break;\n+        case 9: // Requested tx from peer\n+            peer = it == buffer.end() ? 0 : *(it++) % MAX_PEERS;\n+            txidnum = it == buffer.end() ? 0 : *(it++);\n+            delaynum = it == buffer.end() ? 0 : *(it++);\n+            tester.RequestedTx(peer, txidnum % MAX_TXHASHES, tester.Now() + DELAYS[delaynum]);\n+            break;\n+        case 10: // Received response\n+            peer = it == buffer.end() ? 0 : *(it++) % MAX_PEERS;\n+            txidnum = it == buffer.end() ? 0 : *(it++);\n+            tester.ReceivedResponse(peer, txidnum % MAX_TXHASHES);\n+            break;\n+        default:\n+            assert(false);\n+        }\n+    }\n+    tester.Check();\n+}"
      }
    ]
  },
  {
    "sha": "242d16477df1a024c7126bad23dde39cad217eca",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzoyNDJkMTY0NzdkZjFhMDI0YzcxMjZiYWQyM2RkZTM5Y2FkMjE3ZWNh",
    "commit": {
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-09-21T04:20:06Z"
      },
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-10-12T19:14:11Z"
      },
      "message": "Change transaction request logic to use txrequest\n\nThis removes most transaction request logic from net_processing, and\nreplaces it with calls to a global TxRequestTracker object.\n\nThe major changes are:\n\n* Announcements from outbound (and whitelisted) peers are now always\n  preferred over those from inbound peers. This used to be the case for the\n  first request (by delaying the first request from inbound peers), and\n  a bias afters. The 2s delay for requests from inbound peers still exists,\n  but after that, if viable outbound peers remain for any given transaction,\n  they will always be tried first.\n\n* No more hard cap of 100 in flight transactions per peer, as there is less\n  need for it (memory usage is linear in the number of announcements, but\n  independent from the number in flight, and CPU usage isn't affected by it).\n  Furthermore, if only one peer announces a transaction, and it has over 100\n  in flight and requestable already, we still want to request it from them.\n  The cap is replaced with an additional 2s delay (possibly combined with the\n  existing 2s delays for inbound connections, and for txid peers when wtxid\n  peers are available).\n\nIncludes functional tests written by Marco Falke and Antoine Riard.",
      "tree": {
        "sha": "9d45cbec120f94649f67c00e59b8c7b27aa70286",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/9d45cbec120f94649f67c00e59b8c7b27aa70286"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/242d16477df1a024c7126bad23dde39cad217eca",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/242d16477df1a024c7126bad23dde39cad217eca",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/242d16477df1a024c7126bad23dde39cad217eca",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/242d16477df1a024c7126bad23dde39cad217eca/comments",
    "author": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "5b03121d60527a193a84c339151481f9c9c1962b",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/5b03121d60527a193a84c339151481f9c9c1962b",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/5b03121d60527a193a84c339151481f9c9c1962b"
      }
    ],
    "stats": {
      "total": 388,
      "additions": 150,
      "deletions": 238
    },
    "files": [
      {
        "sha": "163c9c1f7288351f6edd5c5e02672b6fe357a731",
        "filename": "src/net_processing.cpp",
        "status": "modified",
        "additions": 53,
        "deletions": 218,
        "changes": 271,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/242d16477df1a024c7126bad23dde39cad217eca/src/net_processing.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/242d16477df1a024c7126bad23dde39cad217eca/src/net_processing.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.cpp?ref=242d16477df1a024c7126bad23dde39cad217eca",
        "patch": "@@ -72,22 +72,19 @@ static constexpr std::chrono::minutes PING_INTERVAL{2};\n static const unsigned int MAX_LOCATOR_SZ = 101;\n /** The maximum number of entries in an 'inv' protocol message */\n static const unsigned int MAX_INV_SZ = 50000;\n-/** Maximum number of in-flight transactions from a peer */\n-static constexpr int32_t MAX_PEER_TX_IN_FLIGHT = 100;\n+/** Maximum number of in-flight transaction requests from a peer. It is not a hard limit, but the threshold at which\n+ *  point the OVERLOADED_PEER_TX_DELAY kicks in. */\n+static constexpr int32_t MAX_PEER_TX_REQUEST_IN_FLIGHT = 100;\n /** Maximum number of announced transactions from a peer */\n static constexpr int32_t MAX_PEER_TX_ANNOUNCEMENTS = 2 * MAX_INV_SZ;\n-/** How many microseconds to delay requesting transactions via txids, if we have wtxid-relaying peers */\n-static constexpr std::chrono::microseconds TXID_RELAY_DELAY{std::chrono::seconds{2}};\n-/** How many microseconds to delay requesting transactions from inbound peers */\n-static constexpr std::chrono::microseconds INBOUND_PEER_TX_DELAY{std::chrono::seconds{2}};\n+/** How long to delay requesting transactions via txids, if we have wtxid-relaying peers */\n+static constexpr auto TXID_RELAY_DELAY = std::chrono::seconds{2};\n+/** How long to delay requesting transactions from non-preferred peers */\n+static constexpr auto NONPREF_PEER_TX_DELAY = std::chrono::seconds{2};\n+/** How long to delay requesting transactions from overloaded peers (see MAX_PEER_TX_REQUEST_IN_FLIGHT). */\n+static constexpr auto OVERLOADED_PEER_TX_DELAY = std::chrono::seconds{2};\n /** How long to wait (in microseconds) before downloading a transaction from an additional peer */\n static constexpr std::chrono::microseconds GETDATA_TX_INTERVAL{std::chrono::seconds{60}};\n-/** Maximum delay (in microseconds) for transaction requests to avoid biasing some peers over others. */\n-static constexpr std::chrono::microseconds MAX_GETDATA_RANDOM_DELAY{std::chrono::seconds{2}};\n-/** How long to wait (in microseconds) before expiring an in-flight getdata request to a peer */\n-static constexpr std::chrono::microseconds TX_EXPIRY_INTERVAL{GETDATA_TX_INTERVAL * 10};\n-static_assert(INBOUND_PEER_TX_DELAY >= MAX_GETDATA_RANDOM_DELAY,\n-\"To preserve security, MAX_GETDATA_RANDOM_DELAY should not exceed INBOUND_PEER_DELAY\");\n /** Limit to avoid sending big packets. Not used in processing incoming GETDATA for compatibility */\n static const unsigned int MAX_GETDATA_SZ = 1000;\n /** Number of blocks that can be requested at any given time from a single peer. */\n@@ -375,69 +372,6 @@ struct CNodeState {\n     //! Time of last new block announcement\n     int64_t m_last_block_announcement;\n \n-    /*\n-     * State associated with transaction download.\n-     *\n-     * Tx download algorithm:\n-     *\n-     *   When inv comes in, queue up (process_time, txid) inside the peer's\n-     *   CNodeState (m_tx_process_time) as long as m_tx_announced for the peer\n-     *   isn't too big (MAX_PEER_TX_ANNOUNCEMENTS).\n-     *\n-     *   The process_time for a transaction is set to nNow for outbound peers,\n-     *   nNow + 2 seconds for inbound peers. This is the time at which we'll\n-     *   consider trying to request the transaction from the peer in\n-     *   SendMessages(). The delay for inbound peers is to allow outbound peers\n-     *   a chance to announce before we request from inbound peers, to prevent\n-     *   an adversary from using inbound connections to blind us to a\n-     *   transaction (InvBlock).\n-     *\n-     *   When we call SendMessages() for a given peer,\n-     *   we will loop over the transactions in m_tx_process_time, looking\n-     *   at the transactions whose process_time <= nNow. We'll request each\n-     *   such transaction that we don't have already and that hasn't been\n-     *   requested from another peer recently, up until we hit the\n-     *   MAX_PEER_TX_IN_FLIGHT limit for the peer. Then we'll update\n-     *   g_already_asked_for for each requested txid, storing the time of the\n-     *   GETDATA request. We use g_already_asked_for to coordinate transaction\n-     *   requests amongst our peers.\n-     *\n-     *   For transactions that we still need but we have already recently\n-     *   requested from some other peer, we'll reinsert (process_time, txid)\n-     *   back into the peer's m_tx_process_time at the point in the future at\n-     *   which the most recent GETDATA request would time out (ie\n-     *   GETDATA_TX_INTERVAL + the request time stored in g_already_asked_for).\n-     *   We add an additional delay for inbound peers, again to prefer\n-     *   attempting download from outbound peers first.\n-     *   We also add an extra small random delay up to 2 seconds\n-     *   to avoid biasing some peers over others. (e.g., due to fixed ordering\n-     *   of peer processing in ThreadMessageHandler).\n-     *\n-     *   When we receive a transaction from a peer, we remove the txid from the\n-     *   peer's m_tx_in_flight set and from their recently announced set\n-     *   (m_tx_announced).  We also clear g_already_asked_for for that entry, so\n-     *   that if somehow the transaction is not accepted but also not added to\n-     *   the reject filter, then we will eventually redownload from other\n-     *   peers.\n-     */\n-    struct TxDownloadState {\n-        /* Track when to attempt download of announced transactions (process\n-         * time in micros -> txid)\n-         */\n-        std::multimap<std::chrono::microseconds, GenTxid> m_tx_process_time;\n-\n-        //! Store all the transactions a peer has recently announced\n-        std::set<uint256> m_tx_announced;\n-\n-        //! Store transactions which were requested by us, with timestamp\n-        std::map<uint256, std::chrono::microseconds> m_tx_in_flight;\n-\n-        //! Periodically check for stuck getdata requests\n-        std::chrono::microseconds m_check_expiry_timer{0};\n-    };\n-\n-    TxDownloadState m_tx_download;\n-\n     //! Whether this peer is an inbound connection\n     bool m_is_inbound;\n \n@@ -478,9 +412,6 @@ struct CNodeState {\n     }\n };\n \n-// Keeps track of the time (in microseconds) when transactions were requested last time\n-limitedmap<uint256, std::chrono::microseconds> g_already_asked_for GUARDED_BY(cs_main)(MAX_INV_SZ);\n-\n /** Map maintaining per-node state. */\n static std::map<NodeId, CNodeState> mapNodeState GUARDED_BY(cs_main);\n \n@@ -817,73 +748,34 @@ static void FindNextBlocksToDownload(NodeId nodeid, unsigned int count, std::vec\n     }\n }\n \n-void EraseTxRequest(const GenTxid& gtxid) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n-{\n-    g_already_asked_for.erase(gtxid.GetHash());\n-}\n-\n-std::chrono::microseconds GetTxRequestTime(const GenTxid& gtxid) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n-{\n-    auto it = g_already_asked_for.find(gtxid.GetHash());\n-    if (it != g_already_asked_for.end()) {\n-        return it->second;\n-    }\n-    return {};\n-}\n-\n-void UpdateTxRequestTime(const GenTxid& gtxid, std::chrono::microseconds request_time) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n-{\n-    auto it = g_already_asked_for.find(gtxid.GetHash());\n-    if (it == g_already_asked_for.end()) {\n-        g_already_asked_for.insert(std::make_pair(gtxid.GetHash(), request_time));\n-    } else {\n-        g_already_asked_for.update(it, request_time);\n-    }\n-}\n-\n-std::chrono::microseconds CalculateTxGetDataTime(const GenTxid& gtxid, std::chrono::microseconds current_time, bool use_inbound_delay, bool use_txid_delay) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n-{\n-    std::chrono::microseconds process_time;\n-    const auto last_request_time = GetTxRequestTime(gtxid);\n-    // First time requesting this tx\n-    if (last_request_time.count() == 0) {\n-        process_time = current_time;\n-    } else {\n-        // Randomize the delay to avoid biasing some peers over others (such as due to\n-        // fixed ordering of peer processing in ThreadMessageHandler)\n-        process_time = last_request_time + GETDATA_TX_INTERVAL + GetRandMicros(MAX_GETDATA_RANDOM_DELAY);\n-    }\n-\n-    // We delay processing announcements from inbound peers\n-    if (use_inbound_delay) process_time += INBOUND_PEER_TX_DELAY;\n-\n-    // We delay processing announcements from peers that use txid-relay (instead of wtxid)\n-    if (use_txid_delay) process_time += TXID_RELAY_DELAY;\n-\n-    return process_time;\n-}\n+} // namespace\n \n-void RequestTx(CNodeState* state, const GenTxid& gtxid, std::chrono::microseconds current_time) EXCLUSIVE_LOCKS_REQUIRED(cs_main)\n+void PeerManager::AddTxAnnouncement(const CNode& node, const GenTxid& gtxid, std::chrono::microseconds current_time)\n {\n-    CNodeState::TxDownloadState& peer_download_state = state->m_tx_download;\n-    if (peer_download_state.m_tx_announced.size() >= MAX_PEER_TX_ANNOUNCEMENTS ||\n-            peer_download_state.m_tx_process_time.size() >= MAX_PEER_TX_ANNOUNCEMENTS ||\n-            peer_download_state.m_tx_announced.count(gtxid.GetHash())) {\n-        // Too many queued announcements from this peer, or we already have\n-        // this announcement\n+    AssertLockHeld(::cs_main); // For m_txrequest\n+    NodeId nodeid = node.GetId();\n+    if (m_txrequest.Count(nodeid) >= MAX_PEER_TX_ANNOUNCEMENTS) {\n+        // Too many queued announcements from this peer\n         return;\n     }\n-    peer_download_state.m_tx_announced.insert(gtxid.GetHash());\n-\n-    // Calculate the time to try requesting this transaction. Use\n-    // fPreferredDownload as a proxy for outbound peers.\n-    const auto process_time = CalculateTxGetDataTime(gtxid, current_time, !state->fPreferredDownload, !state->m_wtxid_relay && g_wtxid_relay_peers > 0);\n-\n-    peer_download_state.m_tx_process_time.emplace(process_time, gtxid);\n+    const CNodeState* state = State(nodeid);\n+\n+    // Decide the TxRequestTracker parameters for this announcement:\n+    // - \"preferred\": if fPreferredDownload is set (= outbound, or PF_NOBAN permission)\n+    // - \"reqtime\": current time plus delays for:\n+    //   - NONPREF_PEER_TX_DELAY for announcements from non-preferred connections\n+    //   - TXID_RELAY_DELAY for announcements from txid peers while wtxid peers are available\n+    //   - OVERLOADED_PEER_TX_DELAY for announcements from peers which have at least\n+    //     MAX_PEER_TX_REQUEST_IN_FLIGHT requests in flight.\n+    auto delay = std::chrono::microseconds{0};\n+    const bool preferred = state->fPreferredDownload;\n+    if (!preferred) delay += NONPREF_PEER_TX_DELAY;\n+    if (!state->m_wtxid_relay && g_wtxid_relay_peers > 0) delay += TXID_RELAY_DELAY;\n+    const bool overloaded = m_txrequest.CountInFlight(nodeid) >= MAX_PEER_TX_REQUEST_IN_FLIGHT;\n+    if (overloaded) delay += OVERLOADED_PEER_TX_DELAY;\n+    m_txrequest.ReceivedInv(nodeid, gtxid, preferred, current_time + delay);\n }\n \n-} // namespace\n-\n // This function is used for testing the stale tip eviction logic, see\n // denialofservice_tests.cpp\n void UpdateLastBlockAnnounceTime(NodeId node, int64_t time_in_seconds)\n@@ -900,6 +792,7 @@ void PeerManager::InitializeNode(CNode *pnode) {\n     {\n         LOCK(cs_main);\n         mapNodeState.emplace_hint(mapNodeState.end(), std::piecewise_construct, std::forward_as_tuple(nodeid), std::forward_as_tuple(addr, pnode->IsInboundConn(), pnode->IsManualConn()));\n+        assert(m_txrequest.Count(nodeid) == 0);\n     }\n     {\n         PeerRef peer = std::make_shared<Peer>(nodeid);\n@@ -957,6 +850,7 @@ void PeerManager::FinalizeNode(NodeId nodeid, bool& fUpdateConnectionTime) {\n         mapBlocksInFlight.erase(entry.hash);\n     }\n     EraseOrphansFor(nodeid);\n+    m_txrequest.DisconnectedPeer(nodeid);\n     nPreferredDownload -= state->fPreferredDownload;\n     nPeersWithValidatedDownloads -= (state->nBlocksInFlightValidHeaders != 0);\n     assert(nPeersWithValidatedDownloads >= 0);\n@@ -974,6 +868,7 @@ void PeerManager::FinalizeNode(NodeId nodeid, bool& fUpdateConnectionTime) {\n         assert(nPeersWithValidatedDownloads == 0);\n         assert(g_outbound_peers_with_protect_from_disconnect == 0);\n         assert(g_wtxid_relay_peers == 0);\n+        assert(m_txrequest.Size() == 0);\n     }\n     LogPrint(BCLog::NET, \"Cleared nodestate for peer=%d\\n\", nodeid);\n }\n@@ -2769,7 +2664,7 @@ void PeerManager::ProcessMessage(CNode& pfrom, const std::string& msg_type, CDat\n                     pfrom.fDisconnect = true;\n                     return;\n                 } else if (!fAlreadyHave && !m_chainman.ActiveChainstate().IsInitialBlockDownload()) {\n-                    RequestTx(State(pfrom.GetId()), gtxid, current_time);\n+                    AddTxAnnouncement(pfrom, gtxid, current_time);\n                 }\n             } else {\n                 LogPrint(BCLog::NET, \"Unknown inv type \\\"%s\\\" received from peer=%d\\n\", inv.ToString(), pfrom.GetId());\n@@ -3023,11 +2918,8 @@ void PeerManager::ProcessMessage(CNode& pfrom, const std::string& msg_type, CDat\n \n         TxValidationState state;\n \n-        for (const GenTxid& gtxid : {GenTxid(false, txid), GenTxid(true, wtxid)}) {\n-            nodestate->m_tx_download.m_tx_announced.erase(gtxid.GetHash());\n-            nodestate->m_tx_download.m_tx_in_flight.erase(gtxid.GetHash());\n-            EraseTxRequest(gtxid);\n-        }\n+        m_txrequest.ReceivedResponse(pfrom.GetId(), txid);\n+        if (tx.HasWitness()) m_txrequest.ReceivedResponse(pfrom.GetId(), wtxid);\n \n         std::list<CTransactionRef> lRemovedTxn;\n \n@@ -3101,7 +2993,7 @@ void PeerManager::ProcessMessage(CNode& pfrom, const std::string& msg_type, CDat\n                     // protocol for getting all unconfirmed parents.\n                     const GenTxid gtxid{/* is_wtxid=*/false, parent_txid};\n                     pfrom.AddKnownTx(parent_txid);\n-                    if (!AlreadyHaveTx(gtxid, m_mempool)) RequestTx(State(pfrom.GetId()), gtxid, current_time);\n+                    if (!AlreadyHaveTx(gtxid, m_mempool)) AddTxAnnouncement(pfrom, gtxid, current_time);\n                 }\n                 AddOrphanTx(ptx, pfrom.GetId());\n \n@@ -3789,24 +3681,15 @@ void PeerManager::ProcessMessage(CNode& pfrom, const std::string& msg_type, CDat\n     }\n \n     if (msg_type == NetMsgType::NOTFOUND) {\n-        // Remove the NOTFOUND transactions from the peer\n-        LOCK(cs_main);\n-        CNodeState *state = State(pfrom.GetId());\n         std::vector<CInv> vInv;\n         vRecv >> vInv;\n-        if (vInv.size() <= MAX_PEER_TX_IN_FLIGHT + MAX_BLOCKS_IN_TRANSIT_PER_PEER) {\n+        if (vInv.size() <= MAX_PEER_TX_ANNOUNCEMENTS + MAX_BLOCKS_IN_TRANSIT_PER_PEER) {\n+            LOCK(::cs_main);\n             for (CInv &inv : vInv) {\n                 if (inv.IsGenTxMsg()) {\n-                    // If we receive a NOTFOUND message for a txid we requested, erase\n-                    // it from our data structures for this peer.\n-                    auto in_flight_it = state->m_tx_download.m_tx_in_flight.find(inv.hash);\n-                    if (in_flight_it == state->m_tx_download.m_tx_in_flight.end()) {\n-                        // Skip any further work if this is a spurious NOTFOUND\n-                        // message.\n-                        continue;\n-                    }\n-                    state->m_tx_download.m_tx_in_flight.erase(in_flight_it);\n-                    state->m_tx_download.m_tx_announced.erase(inv.hash);\n+                    // If we receive a NOTFOUND message for a tx we requested, mark the announcement for it as\n+                    // completed in TxRequestTracker.\n+                    m_txrequest.ReceivedResponse(pfrom.GetId(), inv.hash);\n                 }\n             }\n         }\n@@ -4581,67 +4464,19 @@ bool PeerManager::SendMessages(CNode* pto)\n         //\n         // Message: getdata (non-blocks)\n         //\n-\n-        // For robustness, expire old requests after a long timeout, so that\n-        // we can resume downloading transactions from a peer even if they\n-        // were unresponsive in the past.\n-        // Eventually we should consider disconnecting peers, but this is\n-        // conservative.\n-        if (state.m_tx_download.m_check_expiry_timer <= current_time) {\n-            for (auto it=state.m_tx_download.m_tx_in_flight.begin(); it != state.m_tx_download.m_tx_in_flight.end();) {\n-                if (it->second <= current_time - TX_EXPIRY_INTERVAL) {\n-                    LogPrint(BCLog::NET, \"timeout of inflight tx %s from peer=%d\\n\", it->first.ToString(), pto->GetId());\n-                    state.m_tx_download.m_tx_announced.erase(it->first);\n-                    state.m_tx_download.m_tx_in_flight.erase(it++);\n-                } else {\n-                    ++it;\n-                }\n-            }\n-            // On average, we do this check every TX_EXPIRY_INTERVAL. Randomize\n-            // so that we're not doing this for all peers at the same time.\n-            state.m_tx_download.m_check_expiry_timer = current_time + TX_EXPIRY_INTERVAL / 2 + GetRandMicros(TX_EXPIRY_INTERVAL);\n-        }\n-\n-        auto& tx_process_time = state.m_tx_download.m_tx_process_time;\n-        while (!tx_process_time.empty() && tx_process_time.begin()->first <= current_time && state.m_tx_download.m_tx_in_flight.size() < MAX_PEER_TX_IN_FLIGHT) {\n-            const GenTxid gtxid = tx_process_time.begin()->second;\n-            // Erase this entry from tx_process_time (it may be added back for\n-            // processing at a later time, see below)\n-            tx_process_time.erase(tx_process_time.begin());\n-            CInv inv(gtxid.IsWtxid() ? MSG_WTX : (MSG_TX | GetFetchFlags(*pto)), gtxid.GetHash());\n-            if (!AlreadyHaveTx(ToGenTxid(inv), m_mempool)) {\n-                // If this transaction was last requested more than 1 minute ago,\n-                // then request.\n-                const auto last_request_time = GetTxRequestTime(gtxid);\n-                if (last_request_time <= current_time - GETDATA_TX_INTERVAL) {\n-                    LogPrint(BCLog::NET, \"Requesting %s peer=%d\\n\", inv.ToString(), pto->GetId());\n-                    vGetData.push_back(inv);\n-                    if (vGetData.size() >= MAX_GETDATA_SZ) {\n-                        m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::GETDATA, vGetData));\n-                        vGetData.clear();\n-                    }\n-                    UpdateTxRequestTime(gtxid, current_time);\n-                    state.m_tx_download.m_tx_in_flight.emplace(gtxid.GetHash(), current_time);\n-                } else {\n-                    // This transaction is in flight from someone else; queue\n-                    // up processing to happen after the download times out\n-                    // (with a slight delay for inbound peers, to prefer\n-                    // requests to outbound peers).\n-                    // Don't apply the txid-delay to re-requests of a\n-                    // transaction; the heuristic of delaying requests to\n-                    // txid-relay peers is to save bandwidth on initial\n-                    // announcement of a transaction, and doesn't make sense\n-                    // for a followup request if our first peer times out (and\n-                    // would open us up to an attacker using inbound\n-                    // wtxid-relay to prevent us from requesting transactions\n-                    // from outbound txid-relay peers).\n-                    const auto next_process_time = CalculateTxGetDataTime(gtxid, current_time, !state.fPreferredDownload, false);\n-                    tx_process_time.emplace(next_process_time, gtxid);\n+        for (const GenTxid& gtxid : m_txrequest.GetRequestable(pto->GetId(), current_time)) {\n+            if (!AlreadyHaveTx(gtxid, m_mempool)) {\n+                LogPrint(BCLog::NET, \"Requesting %s %s peer=%d\\n\", gtxid.IsWtxid() ? \"wtx\" : \"tx\",\n+                    gtxid.GetHash().ToString(), pto->GetId());\n+                vGetData.emplace_back(gtxid.IsWtxid() ? MSG_WTX : (MSG_TX | GetFetchFlags(*pto)), gtxid.GetHash());\n+                if (vGetData.size() >= MAX_GETDATA_SZ) {\n+                    m_connman.PushMessage(pto, msgMaker.Make(NetMsgType::GETDATA, vGetData));\n+                    vGetData.clear();\n                 }\n+                m_txrequest.RequestedTx(pto->GetId(), gtxid.GetHash(), current_time + GETDATA_TX_INTERVAL);\n             } else {\n                 // We have already seen this transaction, no need to download.\n-                state.m_tx_download.m_tx_announced.erase(gtxid.GetHash());\n-                state.m_tx_download.m_tx_in_flight.erase(gtxid.GetHash());\n+                m_txrequest.ForgetTxHash(gtxid.GetHash());\n             }\n         }\n "
      },
      {
        "sha": "578660355afe9f837c06aafebe3b5b410bb31fd8",
        "filename": "src/net_processing.h",
        "status": "modified",
        "additions": 8,
        "deletions": 0,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/242d16477df1a024c7126bad23dde39cad217eca/src/net_processing.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/242d16477df1a024c7126bad23dde39cad217eca/src/net_processing.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.h?ref=242d16477df1a024c7126bad23dde39cad217eca",
        "patch": "@@ -9,6 +9,7 @@\n #include <consensus/params.h>\n #include <net.h>\n #include <sync.h>\n+#include <txrequest.h>\n #include <validationinterface.h>\n \n class BlockTransactionsRequest;\n@@ -127,12 +128,19 @@ class PeerManager final : public CValidationInterface, public NetEventsInterface\n \n     void SendBlockTransactions(CNode& pfrom, const CBlock& block, const BlockTransactionsRequest& req);\n \n+    /** Register with TxRequestTracker that an INV has been received from a\n+     *  peer. The announcement parameters are decided in PeerManager and then\n+     *  passed to TxRequestTracker. */\n+    void AddTxAnnouncement(const CNode& node, const GenTxid& gtxid, std::chrono::microseconds current_time)\n+        EXCLUSIVE_LOCKS_REQUIRED(::cs_main);\n+\n     const CChainParams& m_chainparams;\n     CConnman& m_connman;\n     /** Pointer to this node's banman. May be nullptr - check existence before dereferencing. */\n     BanMan* const m_banman;\n     ChainstateManager& m_chainman;\n     CTxMemPool& m_mempool;\n+    TxRequestTracker m_txrequest GUARDED_BY(::cs_main);\n \n     int64_t m_stale_tip_check_time; //!< Next time to check for stale tip\n };"
      },
      {
        "sha": "a3f5f8892287b2a492993810dd5184e8c79efdf3",
        "filename": "test/functional/p2p_tx_download.py",
        "status": "modified",
        "additions": 89,
        "deletions": 20,
        "changes": 109,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/242d16477df1a024c7126bad23dde39cad217eca/test/functional/p2p_tx_download.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/242d16477df1a024c7126bad23dde39cad217eca/test/functional/p2p_tx_download.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_tx_download.py?ref=242d16477df1a024c7126bad23dde39cad217eca",
        "patch": "@@ -42,15 +42,14 @@ def on_getdata(self, message):\n \n # Constants from net_processing\n GETDATA_TX_INTERVAL = 60  # seconds\n-MAX_GETDATA_RANDOM_DELAY = 2  # seconds\n INBOUND_PEER_TX_DELAY = 2  # seconds\n TXID_RELAY_DELAY = 2 # seconds\n+OVERLOADED_PEER_DELAY = 2 # seconds\n MAX_GETDATA_IN_FLIGHT = 100\n-TX_EXPIRY_INTERVAL = GETDATA_TX_INTERVAL * 10\n \n # Python test constants\n NUM_INBOUND = 10\n-MAX_GETDATA_INBOUND_WAIT = GETDATA_TX_INTERVAL + MAX_GETDATA_RANDOM_DELAY + INBOUND_PEER_TX_DELAY + TXID_RELAY_DELAY\n+MAX_GETDATA_INBOUND_WAIT = GETDATA_TX_INTERVAL + INBOUND_PEER_TX_DELAY + TXID_RELAY_DELAY\n \n \n class TxDownloadTest(BitcoinTestFramework):\n@@ -121,46 +120,116 @@ def test_inv_block(self):\n         # * the first time it is re-requested from the outbound peer, plus\n         # * 2 seconds to avoid races\n         assert self.nodes[1].getpeerinfo()[0]['inbound'] == False\n-        timeout = 2 + (MAX_GETDATA_RANDOM_DELAY + INBOUND_PEER_TX_DELAY) + (\n-            GETDATA_TX_INTERVAL + MAX_GETDATA_RANDOM_DELAY)\n+        timeout = 2 + INBOUND_PEER_TX_DELAY + GETDATA_TX_INTERVAL\n         self.log.info(\"Tx should be received at node 1 after {} seconds\".format(timeout))\n         self.sync_mempools(timeout=timeout)\n \n     def test_in_flight_max(self):\n-        self.log.info(\"Test that we don't request more than {} transactions from any peer, every {} minutes\".format(\n-            MAX_GETDATA_IN_FLIGHT, TX_EXPIRY_INTERVAL / 60))\n+        self.log.info(\"Test that we don't load peers with more than {} transaction requests immediately\".format(MAX_GETDATA_IN_FLIGHT))\n         txids = [i for i in range(MAX_GETDATA_IN_FLIGHT + 2)]\n \n         p = self.nodes[0].p2ps[0]\n \n         with p2p_lock:\n             p.tx_getdata_count = 0\n \n-        p.send_message(msg_inv([CInv(t=MSG_WTX, h=i) for i in txids]))\n+        mock_time = int(time.time() + 1)\n+        self.nodes[0].setmocktime(mock_time)\n+        for i in range(MAX_GETDATA_IN_FLIGHT):\n+            p.send_message(msg_inv([CInv(t=MSG_WTX, h=txids[i])]))\n+        p.sync_with_ping()\n+        mock_time += INBOUND_PEER_TX_DELAY\n+        self.nodes[0].setmocktime(mock_time)\n         p.wait_until(lambda: p.tx_getdata_count >= MAX_GETDATA_IN_FLIGHT)\n+        for i in range(MAX_GETDATA_IN_FLIGHT, len(txids)):\n+            p.send_message(msg_inv([CInv(t=MSG_WTX, h=txids[i])]))\n+        p.sync_with_ping()\n+        self.log.info(\"No more than {} requests should be seen within {} seconds after announcement\".format(MAX_GETDATA_IN_FLIGHT, INBOUND_PEER_TX_DELAY + OVERLOADED_PEER_DELAY - 1))\n+        self.nodes[0].setmocktime(mock_time + INBOUND_PEER_TX_DELAY + OVERLOADED_PEER_DELAY - 1)\n+        p.sync_with_ping()\n         with p2p_lock:\n             assert_equal(p.tx_getdata_count, MAX_GETDATA_IN_FLIGHT)\n-\n-        self.log.info(\"Now check that if we send a NOTFOUND for a transaction, we'll get one more request\")\n-        p.send_message(msg_notfound(vec=[CInv(t=MSG_WTX, h=txids[0])]))\n-        p.wait_until(lambda: p.tx_getdata_count >= MAX_GETDATA_IN_FLIGHT + 1, timeout=10)\n+        self.log.info(\"If we wait {} seconds after announcement, we should eventually get more requests\".format(INBOUND_PEER_TX_DELAY + OVERLOADED_PEER_DELAY))\n+        self.nodes[0].setmocktime(mock_time + INBOUND_PEER_TX_DELAY + OVERLOADED_PEER_DELAY)\n+        p.wait_until(lambda: p.tx_getdata_count == len(txids))\n+\n+    def test_expiry_fallback(self):\n+        self.log.info('Check that expiry will select another peer for download')\n+        WTXID = 0xffaa\n+        peer1 = self.nodes[0].add_p2p_connection(TestP2PConn())\n+        peer2 = self.nodes[0].add_p2p_connection(TestP2PConn())\n+        for p in [peer1, peer2]:\n+            p.send_message(msg_inv([CInv(t=MSG_WTX, h=WTXID)]))\n+        # One of the peers is asked for the tx\n+        peer2.wait_until(lambda: sum(p.tx_getdata_count for p in [peer1, peer2]) == 1)\n         with p2p_lock:\n-            assert_equal(p.tx_getdata_count, MAX_GETDATA_IN_FLIGHT + 1)\n-\n-        WAIT_TIME = TX_EXPIRY_INTERVAL // 2 + TX_EXPIRY_INTERVAL\n-        self.log.info(\"if we wait about {} minutes, we should eventually get more requests\".format(WAIT_TIME / 60))\n-        self.nodes[0].setmocktime(int(time.time() + WAIT_TIME))\n-        p.wait_until(lambda: p.tx_getdata_count == MAX_GETDATA_IN_FLIGHT + 2)\n-        self.nodes[0].setmocktime(0)\n+            peer_expiry, peer_fallback = (peer1, peer2) if peer1.tx_getdata_count == 1 else (peer2, peer1)\n+            assert_equal(peer_fallback.tx_getdata_count, 0)\n+        self.nodes[0].setmocktime(int(time.time()) + GETDATA_TX_INTERVAL + 1)  # Wait for request to peer_expiry to expire\n+        peer_fallback.wait_until(lambda: peer_fallback.tx_getdata_count >= 1, timeout=1)\n+        with p2p_lock:\n+            assert_equal(peer_fallback.tx_getdata_count, 1)\n+        self.restart_node(0)  # reset mocktime\n+\n+    def test_disconnect_fallback(self):\n+        self.log.info('Check that disconnect will select another peer for download')\n+        WTXID = 0xffbb\n+        peer1 = self.nodes[0].add_p2p_connection(TestP2PConn())\n+        peer2 = self.nodes[0].add_p2p_connection(TestP2PConn())\n+        for p in [peer1, peer2]:\n+            p.send_message(msg_inv([CInv(t=MSG_WTX, h=WTXID)]))\n+        # One of the peers is asked for the tx\n+        peer2.wait_until(lambda: sum(p.tx_getdata_count for p in [peer1, peer2]) == 1)\n+        with p2p_lock:\n+            peer_disconnect, peer_fallback = (peer1, peer2) if peer1.tx_getdata_count == 1 else (peer2, peer1)\n+            assert_equal(peer_fallback.tx_getdata_count, 0)\n+        peer_disconnect.peer_disconnect()\n+        peer_disconnect.wait_for_disconnect()\n+        peer_fallback.wait_until(lambda: peer_fallback.tx_getdata_count >= 1, timeout=1)\n+        with p2p_lock:\n+            assert_equal(peer_fallback.tx_getdata_count, 1)\n+\n+    def test_notfound_fallback(self):\n+        self.log.info('Check that notfounds will select another peer for download immediately')\n+        WTXID = 0xffdd\n+        peer1 = self.nodes[0].add_p2p_connection(TestP2PConn())\n+        peer2 = self.nodes[0].add_p2p_connection(TestP2PConn())\n+        for p in [peer1, peer2]:\n+            p.send_message(msg_inv([CInv(t=MSG_WTX, h=WTXID)]))\n+        # One of the peers is asked for the tx\n+        peer2.wait_until(lambda: sum(p.tx_getdata_count for p in [peer1, peer2]) == 1)\n+        with p2p_lock:\n+            peer_notfound, peer_fallback = (peer1, peer2) if peer1.tx_getdata_count == 1 else (peer2, peer1)\n+            assert_equal(peer_fallback.tx_getdata_count, 0)\n+        peer_notfound.send_and_ping(msg_notfound(vec=[CInv(MSG_WTX, WTXID)]))  # Send notfound, so that fallback peer is selected\n+        peer_fallback.wait_until(lambda: peer_fallback.tx_getdata_count >= 1, timeout=1)\n+        with p2p_lock:\n+            assert_equal(peer_fallback.tx_getdata_count, 1)\n+\n+    def test_preferred_inv(self):\n+        self.log.info('Check that invs from preferred peers are downloaded immediately')\n+        self.restart_node(0, extra_args=['-whitelist=noban@127.0.0.1'])\n+        peer = self.nodes[0].add_p2p_connection(TestP2PConn())\n+        peer.send_message(msg_inv([CInv(t=MSG_WTX, h=0xff00ff00)]))\n+        peer.wait_until(lambda: peer.tx_getdata_count >= 1, timeout=1)\n+        with p2p_lock:\n+            assert_equal(peer.tx_getdata_count, 1)\n \n     def test_spurious_notfound(self):\n         self.log.info('Check that spurious notfound is ignored')\n         self.nodes[0].p2ps[0].send_message(msg_notfound(vec=[CInv(MSG_TX, 1)]))\n \n     def run_test(self):\n+        # Run tests without mocktime that only need one peer-connection first, to avoid restarting the nodes\n+        self.test_expiry_fallback()\n+        self.test_disconnect_fallback()\n+        self.test_notfound_fallback()\n+        self.test_preferred_inv()\n+        self.test_spurious_notfound()\n+\n         # Run each test against new bitcoind instances, as setting mocktimes has long-term effects on when\n         # the next trickle relay event happens.\n-        for test in [self.test_spurious_notfound, self.test_in_flight_max, self.test_inv_block, self.test_tx_requests]:\n+        for test in [self.test_in_flight_max, self.test_inv_block, self.test_tx_requests]:\n             self.stop_nodes()\n             self.start_nodes()\n             self.connect_nodes(1, 0)"
      }
    ]
  },
  {
    "sha": "de11b0a4eff20da3e3ca52dc90948b5253d329c5",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzpkZTExYjBhNGVmZjIwZGEzZTNjYTUyZGM5MDk0OGI1MjUzZDMyOWM1",
    "commit": {
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-09-24T00:00:46Z"
      },
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-10-12T19:14:53Z"
      },
      "message": "Reduce MAX_PEER_TX_ANNOUNCEMENTS for non-PF_RELAY peers\n\nMaintaining up to 100000 INVs per peer is excessive, as that is far more\nthan fits in a typical mempool.\n\nAlso disable the \"overload\" penalty for PF_RELAY peers.",
      "tree": {
        "sha": "62ffc21d451eab444a4635a110581d645902639b",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/62ffc21d451eab444a4635a110581d645902639b"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/de11b0a4eff20da3e3ca52dc90948b5253d329c5",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/de11b0a4eff20da3e3ca52dc90948b5253d329c5",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/de11b0a4eff20da3e3ca52dc90948b5253d329c5",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/de11b0a4eff20da3e3ca52dc90948b5253d329c5/comments",
    "author": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "242d16477df1a024c7126bad23dde39cad217eca",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/242d16477df1a024c7126bad23dde39cad217eca",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/242d16477df1a024c7126bad23dde39cad217eca"
      }
    ],
    "stats": {
      "total": 44,
      "additions": 38,
      "deletions": 6
    },
    "files": [
      {
        "sha": "ef26eb30320412014850e873d96e3224689b8e71",
        "filename": "doc/release-notes-19988.md",
        "status": "added",
        "additions": 9,
        "deletions": 0,
        "changes": 9,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/de11b0a4eff20da3e3ca52dc90948b5253d329c5/doc/release-notes-19988.md",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/de11b0a4eff20da3e3ca52dc90948b5253d329c5/doc/release-notes-19988.md",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/doc/release-notes-19988.md?ref=de11b0a4eff20da3e3ca52dc90948b5253d329c5",
        "patch": "@@ -0,0 +1,9 @@\n+P2P changes\n+-----------\n+\n+The size of the set of transactions that peers have announced and we consider\n+for requests has been reduced from 100000 to 5000 (per peer), and further\n+announcements will be ignored when that limit is reached. If you need to\n+dump (very) large batches of transactions, exceptions can be made for trusted\n+peers using the \"relay\" network permission. For localhost for example it can\n+be enabled using the command line option `-whitelist=relay@127.0.0.1`."
      },
      {
        "sha": "d40fdfb1139b5f3e3afc0d3f0c570439023295a0",
        "filename": "src/net_permissions.cpp",
        "status": "modified",
        "additions": 1,
        "deletions": 1,
        "changes": 2,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/de11b0a4eff20da3e3ca52dc90948b5253d329c5/src/net_permissions.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/de11b0a4eff20da3e3ca52dc90948b5253d329c5/src/net_permissions.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_permissions.cpp?ref=de11b0a4eff20da3e3ca52dc90948b5253d329c5",
        "patch": "@@ -12,7 +12,7 @@ const std::vector<std::string> NET_PERMISSIONS_DOC{\n     \"bloomfilter (allow requesting BIP37 filtered blocks and transactions)\",\n     \"noban (do not ban for misbehavior; implies download)\",\n     \"forcerelay (relay transactions that are already in the mempool; implies relay)\",\n-    \"relay (relay even in -blocksonly mode)\",\n+    \"relay (relay even in -blocksonly mode, and unlimited transaction announcements)\",\n     \"mempool (allow requesting BIP35 mempool contents)\",\n     \"download (allow getheaders during IBD, no disconnect after maxuploadtarget limit)\",\n     \"addr (responses to GETADDR avoid hitting the cache and contain random records with the most up-to-date info)\""
      },
      {
        "sha": "bba0ea16958820fccf49cd62a8775420b1405244",
        "filename": "src/net_permissions.h",
        "status": "modified",
        "additions": 1,
        "deletions": 0,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/de11b0a4eff20da3e3ca52dc90948b5253d329c5/src/net_permissions.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/de11b0a4eff20da3e3ca52dc90948b5253d329c5/src/net_permissions.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_permissions.h?ref=de11b0a4eff20da3e3ca52dc90948b5253d329c5",
        "patch": "@@ -19,6 +19,7 @@ enum NetPermissionFlags {\n     // Can query bloomfilter even if -peerbloomfilters is false\n     PF_BLOOMFILTER = (1U << 1),\n     // Relay and accept transactions from this peer, even if -blocksonly is true\n+    // This peer is also not subject to limits on how many transaction INVs are tracked\n     PF_RELAY = (1U << 3),\n     // Always relay transactions from this peer, even if already in mempool\n     // Keep parameter interaction: forcerelay implies relay"
      },
      {
        "sha": "ee50bc18052e03237e3ae20fe57b0d97e280ec74",
        "filename": "src/net_processing.cpp",
        "status": "modified",
        "additions": 9,
        "deletions": 5,
        "changes": 14,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/de11b0a4eff20da3e3ca52dc90948b5253d329c5/src/net_processing.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/de11b0a4eff20da3e3ca52dc90948b5253d329c5/src/net_processing.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.cpp?ref=de11b0a4eff20da3e3ca52dc90948b5253d329c5",
        "patch": "@@ -75,8 +75,11 @@ static const unsigned int MAX_INV_SZ = 50000;\n /** Maximum number of in-flight transaction requests from a peer. It is not a hard limit, but the threshold at which\n  *  point the OVERLOADED_PEER_TX_DELAY kicks in. */\n static constexpr int32_t MAX_PEER_TX_REQUEST_IN_FLIGHT = 100;\n-/** Maximum number of announced transactions from a peer */\n-static constexpr int32_t MAX_PEER_TX_ANNOUNCEMENTS = 2 * MAX_INV_SZ;\n+/** Maximum number of transactions to consider for requesting, per peer. It provides a reasonable DoS limit to\n+ *  per-peer memory usage spent on announcements, while covering peers continuously sending INVs at the maximum\n+ *  rate (by our own policy, see INVENTORY_BROADCAST_PER_SECOND) for several minutes, while not receiving\n+ *  the actual transaction (from any peer) in response to requests for them. */\n+static constexpr int32_t MAX_PEER_TX_ANNOUNCEMENTS = 5000;\n /** How long to delay requesting transactions via txids, if we have wtxid-relaying peers */\n static constexpr auto TXID_RELAY_DELAY = std::chrono::seconds{2};\n /** How long to delay requesting transactions from non-preferred peers */\n@@ -754,7 +757,7 @@ void PeerManager::AddTxAnnouncement(const CNode& node, const GenTxid& gtxid, std\n {\n     AssertLockHeld(::cs_main); // For m_txrequest\n     NodeId nodeid = node.GetId();\n-    if (m_txrequest.Count(nodeid) >= MAX_PEER_TX_ANNOUNCEMENTS) {\n+    if (!node.HasPermission(PF_RELAY) && m_txrequest.Count(nodeid) >= MAX_PEER_TX_ANNOUNCEMENTS) {\n         // Too many queued announcements from this peer\n         return;\n     }\n@@ -766,12 +769,13 @@ void PeerManager::AddTxAnnouncement(const CNode& node, const GenTxid& gtxid, std\n     //   - NONPREF_PEER_TX_DELAY for announcements from non-preferred connections\n     //   - TXID_RELAY_DELAY for announcements from txid peers while wtxid peers are available\n     //   - OVERLOADED_PEER_TX_DELAY for announcements from peers which have at least\n-    //     MAX_PEER_TX_REQUEST_IN_FLIGHT requests in flight.\n+    //     MAX_PEER_TX_REQUEST_IN_FLIGHT requests in flight (and don't have PF_RELAY).\n     auto delay = std::chrono::microseconds{0};\n     const bool preferred = state->fPreferredDownload;\n     if (!preferred) delay += NONPREF_PEER_TX_DELAY;\n     if (!state->m_wtxid_relay && g_wtxid_relay_peers > 0) delay += TXID_RELAY_DELAY;\n-    const bool overloaded = m_txrequest.CountInFlight(nodeid) >= MAX_PEER_TX_REQUEST_IN_FLIGHT;\n+    const bool overloaded = !node.HasPermission(PF_RELAY) &&\n+        m_txrequest.CountInFlight(nodeid) >= MAX_PEER_TX_REQUEST_IN_FLIGHT;\n     if (overloaded) delay += OVERLOADED_PEER_TX_DELAY;\n     m_txrequest.ReceivedInv(nodeid, gtxid, preferred, current_time + delay);\n }"
      },
      {
        "sha": "16d9302db8794c49ebe7c4caecfb88abb3a80e53",
        "filename": "test/functional/p2p_tx_download.py",
        "status": "modified",
        "additions": 18,
        "deletions": 0,
        "changes": 18,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/de11b0a4eff20da3e3ca52dc90948b5253d329c5/test/functional/p2p_tx_download.py",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/de11b0a4eff20da3e3ca52dc90948b5253d329c5/test/functional/p2p_tx_download.py",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/test/functional/p2p_tx_download.py?ref=de11b0a4eff20da3e3ca52dc90948b5253d329c5",
        "patch": "@@ -46,6 +46,7 @@ def on_getdata(self, message):\n TXID_RELAY_DELAY = 2 # seconds\n OVERLOADED_PEER_DELAY = 2 # seconds\n MAX_GETDATA_IN_FLIGHT = 100\n+MAX_PEER_TX_ANNOUNCEMENTS = 5000\n \n # Python test constants\n NUM_INBOUND = 10\n@@ -215,6 +216,22 @@ def test_preferred_inv(self):\n         with p2p_lock:\n             assert_equal(peer.tx_getdata_count, 1)\n \n+    def test_large_inv_batch(self):\n+        self.log.info('Test how large inv batches are handled with relay permission')\n+        self.restart_node(0, extra_args=['-whitelist=relay@127.0.0.1'])\n+        peer = self.nodes[0].add_p2p_connection(TestP2PConn())\n+        peer.send_message(msg_inv([CInv(t=MSG_WTX, h=wtxid) for wtxid in range(MAX_PEER_TX_ANNOUNCEMENTS + 1)]))\n+        peer.wait_until(lambda: peer.tx_getdata_count == MAX_PEER_TX_ANNOUNCEMENTS + 1)\n+\n+        self.log.info('Test how large inv batches are handled without relay permission')\n+        self.restart_node(0)\n+        peer = self.nodes[0].add_p2p_connection(TestP2PConn())\n+        peer.send_message(msg_inv([CInv(t=MSG_WTX, h=wtxid) for wtxid in range(MAX_PEER_TX_ANNOUNCEMENTS + 1)]))\n+        peer.wait_until(lambda: peer.tx_getdata_count == MAX_PEER_TX_ANNOUNCEMENTS)\n+        peer.sync_with_ping()\n+        with p2p_lock:\n+            assert_equal(peer.tx_getdata_count, MAX_PEER_TX_ANNOUNCEMENTS)\n+\n     def test_spurious_notfound(self):\n         self.log.info('Check that spurious notfound is ignored')\n         self.nodes[0].p2ps[0].send_message(msg_notfound(vec=[CInv(MSG_TX, 1)]))\n@@ -225,6 +242,7 @@ def run_test(self):\n         self.test_disconnect_fallback()\n         self.test_notfound_fallback()\n         self.test_preferred_inv()\n+        self.test_large_inv_batch()\n         self.test_spurious_notfound()\n \n         # Run each test against new bitcoind instances, as setting mocktimes has long-term effects on when"
      }
    ]
  },
  {
    "sha": "173a1d2d3f824b83777ac713e89bee69fd87692d",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzoxNzNhMWQyZDNmODI0YjgzNzc3YWM3MTNlODliZWU2OWZkODc2OTJk",
    "commit": {
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-09-23T23:39:33Z"
      },
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-10-12T19:14:53Z"
      },
      "message": "Expedite removal of tx requests that are no longer needed\n\nWhenever a transaction is added to the mempool or orphan pool, both\nits txid and wtxid are considered AlreadyHave, and thus will eventually\nbe removed from m_txrequest.\n\nThe same is true for hashes added to the reject filter, but note that sometimes\nonly the wtxid is added (in which case only the wtxid can be removed from\nm_txrequest).",
      "tree": {
        "sha": "06c0910d6a2b4435246c1d20d757c839df5991a6",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/06c0910d6a2b4435246c1d20d757c839df5991a6"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/173a1d2d3f824b83777ac713e89bee69fd87692d",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/173a1d2d3f824b83777ac713e89bee69fd87692d",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/173a1d2d3f824b83777ac713e89bee69fd87692d",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/173a1d2d3f824b83777ac713e89bee69fd87692d/comments",
    "author": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "de11b0a4eff20da3e3ca52dc90948b5253d329c5",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/de11b0a4eff20da3e3ca52dc90948b5253d329c5",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/de11b0a4eff20da3e3ca52dc90948b5253d329c5"
      }
    ],
    "stats": {
      "total": 25,
      "additions": 23,
      "deletions": 2
    },
    "files": [
      {
        "sha": "14507aa920540042c25f378bedfab3b5a882b249",
        "filename": "src/net_processing.cpp",
        "status": "modified",
        "additions": 23,
        "deletions": 2,
        "changes": 25,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/173a1d2d3f824b83777ac713e89bee69fd87692d/src/net_processing.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/173a1d2d3f824b83777ac713e89bee69fd87692d/src/net_processing.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.cpp?ref=173a1d2d3f824b83777ac713e89bee69fd87692d",
        "patch": "@@ -1185,7 +1185,8 @@ PeerManager::PeerManager(const CChainParams& chainparams, CConnman& connman, Ban\n \n /**\n  * Evict orphan txn pool entries (EraseOrphanTx) based on a newly connected\n- * block. Also save the time of the last tip update.\n+ * block, remember the recently confirmed transactions, and delete tracked\n+ * announcements for them. Also save the time of the last tip update.\n  */\n void PeerManager::BlockConnected(const std::shared_ptr<const CBlock>& pblock, const CBlockIndex* pindex)\n {\n@@ -1229,6 +1230,13 @@ void PeerManager::BlockConnected(const std::shared_ptr<const CBlock>& pblock, co\n             }\n         }\n     }\n+    {\n+        LOCK(cs_main);\n+        for (const auto& ptx : pblock->vtx) {\n+            m_txrequest.ForgetTxHash(ptx->GetHash());\n+            m_txrequest.ForgetTxHash(ptx->GetWitnessHash());\n+        }\n+    }\n }\n \n void PeerManager::BlockDisconnected(const std::shared_ptr<const CBlock> &block, const CBlockIndex* pindex)\n@@ -2942,6 +2950,10 @@ void PeerManager::ProcessMessage(CNode& pfrom, const std::string& msg_type, CDat\n         if (!AlreadyHaveTx(GenTxid(/* is_wtxid=*/true, wtxid), m_mempool) &&\n             AcceptToMemoryPool(m_mempool, state, ptx, &lRemovedTxn, false /* bypass_limits */)) {\n             m_mempool.check(&::ChainstateActive().CoinsTip());\n+            // As this version of the transaction was acceptable, we can forget about any\n+            // requests for it.\n+            m_txrequest.ForgetTxHash(tx.GetHash());\n+            m_txrequest.ForgetTxHash(tx.GetWitnessHash());\n             RelayTransaction(tx.GetHash(), tx.GetWitnessHash(), m_connman);\n             for (unsigned int i = 0; i < tx.vout.size(); i++) {\n                 auto it_by_prev = mapOrphanTransactionsByPrev.find(COutPoint(txid, i));\n@@ -3001,6 +3013,10 @@ void PeerManager::ProcessMessage(CNode& pfrom, const std::string& msg_type, CDat\n                 }\n                 AddOrphanTx(ptx, pfrom.GetId());\n \n+                // Once added to the orphan pool, a tx is considered AlreadyHave, and we shouldn't request it anymore.\n+                m_txrequest.ForgetTxHash(tx.GetHash());\n+                m_txrequest.ForgetTxHash(tx.GetWitnessHash());\n+\n                 // DoS prevention: do not allow mapOrphanTransactions to grow unbounded (see CVE-2012-3789)\n                 unsigned int nMaxOrphanTx = (unsigned int)std::max((int64_t)0, gArgs.GetArg(\"-maxorphantx\", DEFAULT_MAX_ORPHAN_TRANSACTIONS));\n                 unsigned int nEvicted = LimitOrphanTxSize(nMaxOrphanTx);\n@@ -3017,6 +3033,8 @@ void PeerManager::ProcessMessage(CNode& pfrom, const std::string& msg_type, CDat\n                 // from any of our non-wtxidrelay peers.\n                 recentRejects->insert(tx.GetHash());\n                 recentRejects->insert(tx.GetWitnessHash());\n+                m_txrequest.ForgetTxHash(tx.GetHash());\n+                m_txrequest.ForgetTxHash(tx.GetWitnessHash());\n             }\n         } else {\n             if (state.GetResult() != TxValidationResult::TX_WITNESS_STRIPPED) {\n@@ -3035,6 +3053,7 @@ void PeerManager::ProcessMessage(CNode& pfrom, const std::string& msg_type, CDat\n                 // if we start doing this too early.\n                 assert(recentRejects);\n                 recentRejects->insert(tx.GetWitnessHash());\n+                m_txrequest.ForgetTxHash(tx.GetWitnessHash());\n                 // If the transaction failed for TX_INPUTS_NOT_STANDARD,\n                 // then we know that the witness was irrelevant to the policy\n                 // failure, since this check depends only on the txid\n@@ -3045,6 +3064,7 @@ void PeerManager::ProcessMessage(CNode& pfrom, const std::string& msg_type, CDat\n                 // parent-fetching by txid via the orphan-handling logic).\n                 if (state.GetResult() == TxValidationResult::TX_INPUTS_NOT_STANDARD && tx.GetWitnessHash() != tx.GetHash()) {\n                     recentRejects->insert(tx.GetHash());\n+                    m_txrequest.ForgetTxHash(tx.GetHash());\n                 }\n                 if (RecursiveDynamicUsage(*ptx) < 100000) {\n                     AddToCompactExtraTransactions(ptx);\n@@ -4479,7 +4499,8 @@ bool PeerManager::SendMessages(CNode* pto)\n                 }\n                 m_txrequest.RequestedTx(pto->GetId(), gtxid.GetHash(), current_time + GETDATA_TX_INTERVAL);\n             } else {\n-                // We have already seen this transaction, no need to download.\n+                // We have already seen this transaction, no need to download. This is just a belt-and-suspenders, as\n+                // this should already be called whenever a transaction becomes AlreadyHaveTx().\n                 m_txrequest.ForgetTxHash(gtxid.GetHash());\n             }\n         }"
      }
    ]
  },
  {
    "sha": "cc16fff3e476a9378d2176b3c1b83ad12b1b052a",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzpjYzE2ZmZmM2U0NzZhOTM3OGQyMTc2YjNjMWI4M2FkMTJiMWIwNTJh",
    "commit": {
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-09-29T19:39:05Z"
      },
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-10-12T19:14:53Z"
      },
      "message": "Make txid delay penalty also apply to fetches of orphan's parents",
      "tree": {
        "sha": "1492eca5f021402661ec91c04360f4046cdc0b7d",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/1492eca5f021402661ec91c04360f4046cdc0b7d"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/cc16fff3e476a9378d2176b3c1b83ad12b1b052a",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/cc16fff3e476a9378d2176b3c1b83ad12b1b052a",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/cc16fff3e476a9378d2176b3c1b83ad12b1b052a",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/cc16fff3e476a9378d2176b3c1b83ad12b1b052a/comments",
    "author": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "173a1d2d3f824b83777ac713e89bee69fd87692d",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/173a1d2d3f824b83777ac713e89bee69fd87692d",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/173a1d2d3f824b83777ac713e89bee69fd87692d"
      }
    ],
    "stats": {
      "total": 4,
      "additions": 2,
      "deletions": 2
    },
    "files": [
      {
        "sha": "35c87127ae2f0947aa6957b5702df6f3474be217",
        "filename": "src/net_processing.cpp",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/cc16fff3e476a9378d2176b3c1b83ad12b1b052a/src/net_processing.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/cc16fff3e476a9378d2176b3c1b83ad12b1b052a/src/net_processing.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.cpp?ref=cc16fff3e476a9378d2176b3c1b83ad12b1b052a",
        "patch": "@@ -767,13 +767,13 @@ void PeerManager::AddTxAnnouncement(const CNode& node, const GenTxid& gtxid, std\n     // - \"preferred\": if fPreferredDownload is set (= outbound, or PF_NOBAN permission)\n     // - \"reqtime\": current time plus delays for:\n     //   - NONPREF_PEER_TX_DELAY for announcements from non-preferred connections\n-    //   - TXID_RELAY_DELAY for announcements from txid peers while wtxid peers are available\n+    //   - TXID_RELAY_DELAY for txid announcements while wtxid peers are available\n     //   - OVERLOADED_PEER_TX_DELAY for announcements from peers which have at least\n     //     MAX_PEER_TX_REQUEST_IN_FLIGHT requests in flight (and don't have PF_RELAY).\n     auto delay = std::chrono::microseconds{0};\n     const bool preferred = state->fPreferredDownload;\n     if (!preferred) delay += NONPREF_PEER_TX_DELAY;\n-    if (!state->m_wtxid_relay && g_wtxid_relay_peers > 0) delay += TXID_RELAY_DELAY;\n+    if (!gtxid.IsWtxid() && g_wtxid_relay_peers > 0) delay += TXID_RELAY_DELAY;\n     const bool overloaded = !node.HasPermission(PF_RELAY) &&\n         m_txrequest.CountInFlight(nodeid) >= MAX_PEER_TX_REQUEST_IN_FLIGHT;\n     if (overloaded) delay += OVERLOADED_PEER_TX_DELAY;"
      }
    ]
  },
  {
    "sha": "86f50ed10f66b5535f0162cf0026456a9e3f8963",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzo4NmY1MGVkMTBmNjZiNTUzNWYwMTYyY2YwMDI2NDU2YTllM2Y4OTYz",
    "commit": {
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-09-21T04:20:25Z"
      },
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-10-12T19:14:53Z"
      },
      "message": "Delete limitedmap as it is unused now",
      "tree": {
        "sha": "573f97b8ee8533d1b27fdebe59706d4ee964b318",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/573f97b8ee8533d1b27fdebe59706d4ee964b318"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/86f50ed10f66b5535f0162cf0026456a9e3f8963",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/86f50ed10f66b5535f0162cf0026456a9e3f8963",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/86f50ed10f66b5535f0162cf0026456a9e3f8963",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/86f50ed10f66b5535f0162cf0026456a9e3f8963/comments",
    "author": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "cc16fff3e476a9378d2176b3c1b83ad12b1b052a",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/cc16fff3e476a9378d2176b3c1b83ad12b1b052a",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/cc16fff3e476a9378d2176b3c1b83ad12b1b052a"
      }
    ],
    "stats": {
      "total": 204,
      "additions": 0,
      "deletions": 204
    },
    "files": [
      {
        "sha": "1dd821f968bf582dfa9a8bb986fe3959a4a36b44",
        "filename": "src/Makefile.am",
        "status": "modified",
        "additions": 0,
        "deletions": 1,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/86f50ed10f66b5535f0162cf0026456a9e3f8963/src/Makefile.am",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/86f50ed10f66b5535f0162cf0026456a9e3f8963/src/Makefile.am",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/Makefile.am?ref=86f50ed10f66b5535f0162cf0026456a9e3f8963",
        "patch": "@@ -151,7 +151,6 @@ BITCOIN_CORE_H = \\\n   interfaces/wallet.h \\\n   key.h \\\n   key_io.h \\\n-  limitedmap.h \\\n   logging.h \\\n   logging/timer.h \\\n   memusage.h \\"
      },
      {
        "sha": "3af30db4db1df9ee8cf23fae0d3ba767d0092adf",
        "filename": "src/Makefile.test.include",
        "status": "modified",
        "additions": 0,
        "deletions": 1,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/86f50ed10f66b5535f0162cf0026456a9e3f8963/src/Makefile.test.include",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/86f50ed10f66b5535f0162cf0026456a9e3f8963/src/Makefile.test.include",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/Makefile.test.include?ref=86f50ed10f66b5535f0162cf0026456a9e3f8963",
        "patch": "@@ -236,7 +236,6 @@ BITCOIN_TESTS =\\\n   test/interfaces_tests.cpp \\\n   test/key_io_tests.cpp \\\n   test/key_tests.cpp \\\n-  test/limitedmap_tests.cpp \\\n   test/logging_tests.cpp \\\n   test/dbwrapper_tests.cpp \\\n   test/validation_tests.cpp \\"
      },
      {
        "sha": "7d66964e36aa5119dbe41c9cf322e7ec1a94a094",
        "filename": "src/limitedmap.h",
        "status": "removed",
        "additions": 0,
        "deletions": 100,
        "changes": 100,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/cc16fff3e476a9378d2176b3c1b83ad12b1b052a/src/limitedmap.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/cc16fff3e476a9378d2176b3c1b83ad12b1b052a/src/limitedmap.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/limitedmap.h?ref=cc16fff3e476a9378d2176b3c1b83ad12b1b052a",
        "patch": "@@ -1,100 +0,0 @@\n-// Copyright (c) 2012-2018 The Bitcoin Core developers\n-// Distributed under the MIT software license, see the accompanying\n-// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n-\n-#ifndef BITCOIN_LIMITEDMAP_H\n-#define BITCOIN_LIMITEDMAP_H\n-\n-#include <assert.h>\n-#include <map>\n-\n-/** STL-like map container that only keeps the N elements with the highest value. */\n-template <typename K, typename V>\n-class limitedmap\n-{\n-public:\n-    typedef K key_type;\n-    typedef V mapped_type;\n-    typedef std::pair<const key_type, mapped_type> value_type;\n-    typedef typename std::map<K, V>::const_iterator const_iterator;\n-    typedef typename std::map<K, V>::size_type size_type;\n-\n-protected:\n-    std::map<K, V> map;\n-    typedef typename std::map<K, V>::iterator iterator;\n-    std::multimap<V, iterator> rmap;\n-    typedef typename std::multimap<V, iterator>::iterator rmap_iterator;\n-    size_type nMaxSize;\n-\n-public:\n-    explicit limitedmap(size_type nMaxSizeIn)\n-    {\n-        assert(nMaxSizeIn > 0);\n-        nMaxSize = nMaxSizeIn;\n-    }\n-    const_iterator begin() const { return map.begin(); }\n-    const_iterator end() const { return map.end(); }\n-    size_type size() const { return map.size(); }\n-    bool empty() const { return map.empty(); }\n-    const_iterator find(const key_type& k) const { return map.find(k); }\n-    size_type count(const key_type& k) const { return map.count(k); }\n-    void insert(const value_type& x)\n-    {\n-        std::pair<iterator, bool> ret = map.insert(x);\n-        if (ret.second) {\n-            if (map.size() > nMaxSize) {\n-                map.erase(rmap.begin()->second);\n-                rmap.erase(rmap.begin());\n-            }\n-            rmap.insert(make_pair(x.second, ret.first));\n-        }\n-    }\n-    void erase(const key_type& k)\n-    {\n-        iterator itTarget = map.find(k);\n-        if (itTarget == map.end())\n-            return;\n-        std::pair<rmap_iterator, rmap_iterator> itPair = rmap.equal_range(itTarget->second);\n-        for (rmap_iterator it = itPair.first; it != itPair.second; ++it)\n-            if (it->second == itTarget) {\n-                rmap.erase(it);\n-                map.erase(itTarget);\n-                return;\n-            }\n-        // Shouldn't ever get here\n-        assert(0);\n-    }\n-    void update(const_iterator itIn, const mapped_type& v)\n-    {\n-        // Using map::erase() with empty range instead of map::find() to get a non-const iterator,\n-        // since it is a constant time operation in C++11. For more details, see\n-        // https://stackoverflow.com/questions/765148/how-to-remove-constness-of-const-iterator\n-        iterator itTarget = map.erase(itIn, itIn);\n-\n-        if (itTarget == map.end())\n-            return;\n-        std::pair<rmap_iterator, rmap_iterator> itPair = rmap.equal_range(itTarget->second);\n-        for (rmap_iterator it = itPair.first; it != itPair.second; ++it)\n-            if (it->second == itTarget) {\n-                rmap.erase(it);\n-                itTarget->second = v;\n-                rmap.insert(make_pair(v, itTarget));\n-                return;\n-            }\n-        // Shouldn't ever get here\n-        assert(0);\n-    }\n-    size_type max_size() const { return nMaxSize; }\n-    size_type max_size(size_type s)\n-    {\n-        assert(s > 0);\n-        while (map.size() > s) {\n-            map.erase(rmap.begin()->second);\n-            rmap.erase(rmap.begin());\n-        }\n-        nMaxSize = s;\n-        return nMaxSize;\n-    }\n-};\n-\n-#endif // BITCOIN_LIMITEDMAP_H"
      },
      {
        "sha": "06bd4e8e2ade3cdfba54d720c4349fdea19dadb1",
        "filename": "src/net.h",
        "status": "modified",
        "additions": 0,
        "deletions": 1,
        "changes": 1,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/86f50ed10f66b5535f0162cf0026456a9e3f8963/src/net.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/86f50ed10f66b5535f0162cf0026456a9e3f8963/src/net.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net.h?ref=86f50ed10f66b5535f0162cf0026456a9e3f8963",
        "patch": "@@ -14,7 +14,6 @@\n #include <compat.h>\n #include <crypto/siphash.h>\n #include <hash.h>\n-#include <limitedmap.h>\n #include <net_permissions.h>\n #include <netaddress.h>\n #include <optional.h>"
      },
      {
        "sha": "ea18debbd3ec71db013df160d4377f7bc71c0ce1",
        "filename": "src/test/limitedmap_tests.cpp",
        "status": "removed",
        "additions": 0,
        "deletions": 101,
        "changes": 101,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/cc16fff3e476a9378d2176b3c1b83ad12b1b052a/src/test/limitedmap_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/cc16fff3e476a9378d2176b3c1b83ad12b1b052a/src/test/limitedmap_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/limitedmap_tests.cpp?ref=cc16fff3e476a9378d2176b3c1b83ad12b1b052a",
        "patch": "@@ -1,101 +0,0 @@\n-// Copyright (c) 2012-2019 The Bitcoin Core developers\n-// Distributed under the MIT software license, see the accompanying\n-// file COPYING or http://www.opensource.org/licenses/mit-license.php.\n-\n-#include <limitedmap.h>\n-\n-#include <test/util/setup_common.h>\n-\n-#include <boost/test/unit_test.hpp>\n-\n-BOOST_FIXTURE_TEST_SUITE(limitedmap_tests, BasicTestingSetup)\n-\n-BOOST_AUTO_TEST_CASE(limitedmap_test)\n-{\n-    // create a limitedmap capped at 10 items\n-    limitedmap<int, int> map(10);\n-\n-    // check that the max size is 10\n-    BOOST_CHECK(map.max_size() == 10);\n-\n-    // check that it's empty\n-    BOOST_CHECK(map.size() == 0);\n-\n-    // insert (-1, -1)\n-    map.insert(std::pair<int, int>(-1, -1));\n-\n-    // make sure that the size is updated\n-    BOOST_CHECK(map.size() == 1);\n-\n-    // make sure that the new item is in the map\n-    BOOST_CHECK(map.count(-1) == 1);\n-\n-    // insert 10 new items\n-    for (int i = 0; i < 10; i++) {\n-        map.insert(std::pair<int, int>(i, i + 1));\n-    }\n-\n-    // make sure that the map now contains 10 items...\n-    BOOST_CHECK(map.size() == 10);\n-\n-    // ...and that the first item has been discarded\n-    BOOST_CHECK(map.count(-1) == 0);\n-\n-    // iterate over the map, both with an index and an iterator\n-    limitedmap<int, int>::const_iterator it = map.begin();\n-    for (int i = 0; i < 10; i++) {\n-        // make sure the item is present\n-        BOOST_CHECK(map.count(i) == 1);\n-\n-        // use the iterator to check for the expected key and value\n-        BOOST_CHECK(it->first == i);\n-        BOOST_CHECK(it->second == i + 1);\n-\n-        // use find to check for the value\n-        BOOST_CHECK(map.find(i)->second == i + 1);\n-\n-        // update and recheck\n-        map.update(it, i + 2);\n-        BOOST_CHECK(map.find(i)->second == i + 2);\n-\n-        it++;\n-    }\n-\n-    // check that we've exhausted the iterator\n-    BOOST_CHECK(it == map.end());\n-\n-    // resize the map to 5 items\n-    map.max_size(5);\n-\n-    // check that the max size and size are now 5\n-    BOOST_CHECK(map.max_size() == 5);\n-    BOOST_CHECK(map.size() == 5);\n-\n-    // check that items less than 5 have been discarded\n-    // and items greater than 5 are retained\n-    for (int i = 0; i < 10; i++) {\n-        if (i < 5) {\n-            BOOST_CHECK(map.count(i) == 0);\n-        } else {\n-            BOOST_CHECK(map.count(i) == 1);\n-        }\n-    }\n-\n-    // erase some items not in the map\n-    for (int i = 100; i < 1000; i += 100) {\n-        map.erase(i);\n-    }\n-\n-    // check that the size is unaffected\n-    BOOST_CHECK(map.size() == 5);\n-\n-    // erase the remaining elements\n-    for (int i = 5; i < 10; i++) {\n-        map.erase(i);\n-    }\n-\n-    // check that the map is now empty\n-    BOOST_CHECK(map.empty());\n-}\n-\n-BOOST_AUTO_TEST_SUITE_END()"
      }
    ]
  },
  {
    "sha": "fd9a0060f028a4c01bd88f58777dea34bdcbafd1",
    "node_id": "MDY6Q29tbWl0MTE4MTkyNzpmZDlhMDA2MGYwMjhhNGMwMWJkODhmNTg3NzdkZWEzNGJkY2JhZmQx",
    "commit": {
      "author": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-10-09T18:44:06Z"
      },
      "committer": {
        "name": "Pieter Wuille",
        "email": "pieter@wuille.net",
        "date": "2020-10-12T19:14:53Z"
      },
      "message": "Report and verify expirations",
      "tree": {
        "sha": "6fc17dc1233aa9e4ab056b6a1d22046bf7ebd3a8",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/git/trees/6fc17dc1233aa9e4ab056b6a1d22046bf7ebd3a8"
      },
      "url": "https://api.github.com/repos/bitcoin/bitcoin/git/commits/fd9a0060f028a4c01bd88f58777dea34bdcbafd1",
      "comment_count": 0,
      "verification": {
        "verified": false,
        "reason": "unsigned",
        "signature": null,
        "payload": null
      }
    },
    "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/fd9a0060f028a4c01bd88f58777dea34bdcbafd1",
    "html_url": "https://github.com/bitcoin/bitcoin/commit/fd9a0060f028a4c01bd88f58777dea34bdcbafd1",
    "comments_url": "https://api.github.com/repos/bitcoin/bitcoin/commits/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/comments",
    "author": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "committer": {
      "login": "sipa",
      "id": 548488,
      "node_id": "MDQ6VXNlcjU0ODQ4OA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/548488?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sipa",
      "html_url": "https://github.com/sipa",
      "followers_url": "https://api.github.com/users/sipa/followers",
      "following_url": "https://api.github.com/users/sipa/following{/other_user}",
      "gists_url": "https://api.github.com/users/sipa/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sipa/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sipa/subscriptions",
      "organizations_url": "https://api.github.com/users/sipa/orgs",
      "repos_url": "https://api.github.com/users/sipa/repos",
      "events_url": "https://api.github.com/users/sipa/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sipa/received_events",
      "type": "User",
      "site_admin": false
    },
    "parents": [
      {
        "sha": "86f50ed10f66b5535f0162cf0026456a9e3f8963",
        "url": "https://api.github.com/repos/bitcoin/bitcoin/commits/86f50ed10f66b5535f0162cf0026456a9e3f8963",
        "html_url": "https://github.com/bitcoin/bitcoin/commit/86f50ed10f66b5535f0162cf0026456a9e3f8963"
      }
    ],
    "stats": {
      "total": 77,
      "additions": 64,
      "deletions": 13
    },
    "files": [
      {
        "sha": "6c8affe70d69264469e766a5ccfe2900cb6c2139",
        "filename": "src/net_processing.cpp",
        "status": "modified",
        "additions": 7,
        "deletions": 1,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/net_processing.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/net_processing.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/net_processing.cpp?ref=fd9a0060f028a4c01bd88f58777dea34bdcbafd1",
        "patch": "@@ -4488,7 +4488,13 @@ bool PeerManager::SendMessages(CNode* pto)\n         //\n         // Message: getdata (non-blocks)\n         //\n-        for (const GenTxid& gtxid : m_txrequest.GetRequestable(pto->GetId(), current_time)) {\n+        std::vector<std::pair<NodeId, GenTxid>> expired;\n+        auto requestable = m_txrequest.GetRequestable(pto->GetId(), current_time, &expired);\n+        for (const auto& entry : expired) {\n+            LogPrint(BCLog::NET, \"timeout of inflight %s %s from peer=%d\\n\", entry.second.IsWtxid() ? \"wtx\" : \"tx\",\n+                entry.second.GetHash().ToString(), entry.first);\n+        }\n+        for (const GenTxid& gtxid : requestable) {\n             if (!AlreadyHaveTx(gtxid, m_mempool)) {\n                 LogPrint(BCLog::NET, \"Requesting %s %s peer=%d\\n\", gtxid.IsWtxid() ? \"wtx\" : \"tx\",\n                     gtxid.GetHash().ToString(), pto->GetId());"
      },
      {
        "sha": "00544f64fea2dabf6bfaccc34aecfae3b645f99f",
        "filename": "src/primitives/transaction.h",
        "status": "modified",
        "additions": 2,
        "deletions": 2,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/primitives/transaction.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/primitives/transaction.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/primitives/transaction.h?ref=fd9a0060f028a4c01bd88f58777dea34bdcbafd1",
        "patch": "@@ -399,8 +399,8 @@ template <typename Tx> static inline CTransactionRef MakeTransactionRef(Tx&& txI\n /** A generic txid reference (txid or wtxid). */\n class GenTxid\n {\n-    const bool m_is_wtxid;\n-    const uint256 m_hash;\n+    bool m_is_wtxid;\n+    uint256 m_hash;\n public:\n     GenTxid(bool is_wtxid, const uint256& hash) : m_is_wtxid(is_wtxid), m_hash(hash) {}\n     bool IsWtxid() const { return m_is_wtxid; }"
      },
      {
        "sha": "9529ad32742250c171d65dd86e8c053b026aa6ef",
        "filename": "src/test/fuzz/txrequest.cpp",
        "status": "modified",
        "additions": 7,
        "deletions": 1,
        "changes": 8,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/test/fuzz/txrequest.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/test/fuzz/txrequest.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/fuzz/txrequest.cpp?ref=fd9a0060f028a4c01bd88f58777dea34bdcbafd1",
        "patch": "@@ -246,11 +246,13 @@ class Tester\n \n         //! list of (sequence number, txhash, is_wtxid) tuples.\n         std::vector<std::tuple<uint64_t, int, bool>> result;\n+        std::vector<std::pair<NodeId, GenTxid>> expected_expired;\n         for (int txhash = 0; txhash < MAX_TXHASHES; ++txhash) {\n             // Mark any expired REQUESTED announcements as COMPLETED.\n             for (int peer2 = 0; peer2 < MAX_PEERS; ++peer2) {\n                 Announcement& ann2 = m_announcements[txhash][peer2];\n                 if (ann2.m_state == State::REQUESTED && ann2.m_time <= m_now) {\n+                    expected_expired.emplace_back(peer2, GenTxid{ann2.m_is_wtxid, TXHASHES[txhash]});\n                     ann2.m_state = State::COMPLETED;\n                     break;\n                 }\n@@ -265,9 +267,13 @@ class Tester\n         }\n         // Sort the results by sequence number.\n         std::sort(result.begin(), result.end());\n+        std::sort(expected_expired.begin(), expected_expired.end());\n \n         // Compare with TxRequestTracker's implementation.\n-        const auto actual = m_tracker.GetRequestable(peer, m_now);\n+        std::vector<std::pair<NodeId, GenTxid>> expired;\n+        const auto actual = m_tracker.GetRequestable(peer, m_now, &expired);\n+        std::sort(expired.begin(), expired.end());\n+        assert(expired == expected_expired);\n \n         m_tracker.PostGetRequestableSanityCheck(m_now);\n         assert(result.size() == actual.size());"
      },
      {
        "sha": "1d137b03b1cc381206062037eea2cd4f57521fb9",
        "filename": "src/test/txrequest_tests.cpp",
        "status": "modified",
        "additions": 29,
        "deletions": 2,
        "changes": 31,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/test/txrequest_tests.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/test/txrequest_tests.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/test/txrequest_tests.cpp?ref=fd9a0060f028a4c01bd88f58777dea34bdcbafd1",
        "patch": "@@ -43,6 +43,11 @@ struct Runner\n \n     /** Which txhashes have been assigned already (to prevent reuse). */\n     std::set<uint256> txhashset;\n+\n+    /** Which (peer, gtxid) combinations are known to be expired. These need to be accumulated here instead of\n+     *  checked directly in the GetRequestable return value to avoid introducing a dependency between the various\n+     *  parallel tests. */\n+    std::multiset<std::pair<NodeId, GenTxid>> expired;\n };\n \n std::chrono::microseconds RandomTime8s() { return std::chrono::microseconds{1 + InsecureRandBits(23)}; }\n@@ -149,7 +154,9 @@ class Scenario\n         const auto now = m_now;\n         assert(offset.count() <= 0);\n         runner.actions.emplace_back(m_now, [=,&runner]() {\n-            auto ret = runner.txrequest.GetRequestable(peer, now + offset);\n+            std::vector<std::pair<NodeId, GenTxid>> expired_now;\n+            auto ret = runner.txrequest.GetRequestable(peer, now + offset, &expired_now);\n+            for (const auto& entry : expired_now) runner.expired.insert(entry);\n             runner.txrequest.SanityCheck();\n             runner.txrequest.PostGetRequestableSanityCheck(now + offset);\n             size_t total = candidates + inflight + completed;\n@@ -163,6 +170,21 @@ class Scenario\n         });\n     }\n \n+    /** Verify that an announcement for gtxid by peer has expired some time before this check is scheduled.\n+     *\n+     * Every expected expiration should be accounted for through exactly one call to this function.\n+     */\n+    void CheckExpired(NodeId peer, GenTxid gtxid)\n+    {\n+        const auto& testname = m_testname;\n+        auto& runner = m_runner;\n+        runner.actions.emplace_back(m_now, [=,&runner]() {\n+            auto it = runner.expired.find(std::pair<NodeId, GenTxid>{peer, gtxid});\n+            BOOST_CHECK_MESSAGE(it != runner.expired.end(), \"[\" + testname + \"] missing expiration\");\n+            if (it != runner.expired.end()) runner.expired.erase(it);\n+        });\n+    }\n+\n     /** Generate a random txhash, whose priorities for certain peers are constrained.\n      *\n      * For example, NewTxHash({{p1,p2,p3},{p2,p4,p5}}) will generate a txhash T such that both:\n@@ -256,6 +278,7 @@ void BuildSingleTest(Scenario& scenario, int config)\n             scenario.Check(peer, {}, 0, 1, 0, \"s7\");\n             scenario.AdvanceTime(MICROSECOND);\n             scenario.Check(peer, {}, 0, 0, 0, \"s8\");\n+            scenario.CheckExpired(peer, gtxid);\n             return;\n         } else {\n             scenario.AdvanceTime(std::chrono::microseconds{InsecureRandRange(expiry.count())});\n@@ -268,7 +291,6 @@ void BuildSingleTest(Scenario& scenario, int config)\n         }\n     }\n \n-    if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n     if (config & 4) { // The peer will go offline\n         scenario.DisconnectedPeer(peer);\n     } else { // The transaction is no longer needed\n@@ -519,9 +541,11 @@ void BuildWtxidTest(Scenario& scenario, int config)\n     if (config & 2) {\n         scenario.Check(peerT, {}, 0, 0, 1, \"w9\");\n         scenario.Check(peerW, {wtxid}, 1, 0, 0, \"w10\");\n+        scenario.CheckExpired(peerT, txid);\n     } else {\n         scenario.Check(peerT, {txid}, 1, 0, 0, \"w11\");\n         scenario.Check(peerW, {}, 0, 0, 1, \"w12\");\n+        scenario.CheckExpired(peerW, wtxid);\n     }\n \n     // If a good transaction with either that hash as wtxid or txid arrives, both\n@@ -567,6 +591,7 @@ void BuildTimeBackwardsTest(Scenario& scenario)\n     scenario.AdvanceTime(expiry - scenario.Now());\n     scenario.Check(peer1, {}, 0, 0, 1, \"r9\");\n     scenario.Check(peer2, {gtxid}, 1, 0, 0, \"r10\"); // Request goes back to peer2.\n+    scenario.CheckExpired(peer1, gtxid);\n     scenario.Check(peer1, {}, 0, 0, 1, \"r11\", -MICROSECOND); // Going back does not unexpire.\n     scenario.Check(peer2, {gtxid}, 1, 0, 0, \"r12\", -MICROSECOND);\n \n@@ -623,6 +648,7 @@ void BuildWeirdRequestsTest(Scenario& scenario)\n     scenario.AdvanceTime(expiryA - scenario.Now());\n     scenario.Check(peer1, {}, 0, 0, 1, \"q12\");\n     scenario.Check(peer2, {gtxid2, gtxid1}, 2, 0, 0, \"q13\");\n+    scenario.CheckExpired(peer1, gtxid1);\n \n     // Requesting it yet again from peer1 doesn't do anything, as it's already COMPLETED.\n     if (InsecureRandBool()) scenario.AdvanceTime(RandomTime8s());\n@@ -697,6 +723,7 @@ void TestInterleavedScenarios()\n     }\n \n     BOOST_CHECK_EQUAL(runner.txrequest.Size(), 0U);\n+    BOOST_CHECK(runner.expired.empty());\n }\n \n }  // namespace"
      },
      {
        "sha": "494786c201490aaa1208e3895e677d9ca956bf46",
        "filename": "src/txrequest.cpp",
        "status": "modified",
        "additions": 16,
        "deletions": 6,
        "changes": 22,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/txrequest.cpp",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/txrequest.cpp",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/txrequest.cpp?ref=fd9a0060f028a4c01bd88f58777dea34bdcbafd1",
        "patch": "@@ -291,6 +291,11 @@ std::map<uint256, TxHashInfo> ComputeTxHashInfo(const Index& index, const Priori\n     return ret;\n }\n \n+GenTxid ToGenTxid(const Announcement& ann)\n+{\n+    return {ann.m_is_wtxid, ann.m_txhash};\n+}\n+\n }  // namespace\n \n /** Actual implementation for TxRequestTracker's data structure. */\n@@ -477,15 +482,18 @@ class TxRequestTracker::Impl {\n     //! - REQUESTED annoucements with expiry <= now are turned into COMPLETED.\n     //! - CANDIDATE_DELAYED announcements with reqtime <= now are turned into CANDIDATE_{READY,BEST}.\n     //! - CANDIDATE_{READY,BEST} announcements with reqtime > now are turned into CANDIDATE_DELAYED.\n-    void SetTimePoint(std::chrono::microseconds now)\n+    void SetTimePoint(std::chrono::microseconds now, std::vector<std::pair<NodeId, GenTxid>>* expired)\n     {\n+        if (expired) expired->clear();\n+\n         // Iterate over all CANDIDATE_DELAYED and REQUESTED from old to new, as long as they're in the past,\n         // and convert them to CANDIDATE_READY and COMPLETED respectively.\n         while (!m_index.empty()) {\n             auto it = m_index.get<ByTime>().begin();\n             if (it->m_state == State::CANDIDATE_DELAYED && it->m_time <= now) {\n                 PromoteCandidateReady(m_index.project<ByTxHash>(it));\n             } else if (it->m_state == State::REQUESTED && it->m_time <= now) {\n+                if (expired) expired->emplace_back(it->m_peer, ToGenTxid(*it));\n                 MakeCompleted(m_index.project<ByTxHash>(it));\n             } else {\n                 break;\n@@ -578,10 +586,11 @@ class TxRequestTracker::Impl {\n     }\n \n     //! Find the GenTxids to request now from peer.\n-    std::vector<GenTxid> GetRequestable(NodeId peer, std::chrono::microseconds now)\n+    std::vector<GenTxid> GetRequestable(NodeId peer, std::chrono::microseconds now,\n+        std::vector<std::pair<NodeId, GenTxid>>* expired)\n     {\n         // Move time.\n-        SetTimePoint(now);\n+        SetTimePoint(now, expired);\n \n         // Find all CANDIDATE_BEST announcements for this peer.\n         std::vector<const Announcement*> selected;\n@@ -601,7 +610,7 @@ class TxRequestTracker::Impl {\n         std::vector<GenTxid> ret;\n         ret.reserve(selected.size());\n         std::transform(selected.begin(), selected.end(), std::back_inserter(ret), [](const Announcement* ann) {\n-            return GenTxid{ann->m_is_wtxid, ann->m_txhash};\n+            return ToGenTxid(*ann);\n         });\n         return ret;\n     }\n@@ -727,9 +736,10 @@ void TxRequestTracker::ReceivedResponse(NodeId peer, const uint256& txhash)\n     m_impl->ReceivedResponse(peer, txhash);\n }\n \n-std::vector<GenTxid> TxRequestTracker::GetRequestable(NodeId peer, std::chrono::microseconds now)\n+std::vector<GenTxid> TxRequestTracker::GetRequestable(NodeId peer, std::chrono::microseconds now,\n+    std::vector<std::pair<NodeId, GenTxid>>* expired)\n {\n-    return m_impl->GetRequestable(peer, now);\n+    return m_impl->GetRequestable(peer, now, expired);\n }\n \n uint64_t TxRequestTracker::ComputePriority(const uint256& txhash, NodeId peer, bool preferred) const"
      },
      {
        "sha": "cd3042c87e5f2c16efa98d886fa52a58374a060c",
        "filename": "src/txrequest.h",
        "status": "modified",
        "additions": 3,
        "deletions": 1,
        "changes": 4,
        "blob_url": "https://github.com/bitcoin/bitcoin/blob/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/txrequest.h",
        "raw_url": "https://github.com/bitcoin/bitcoin/raw/fd9a0060f028a4c01bd88f58777dea34bdcbafd1/src/txrequest.h",
        "contents_url": "https://api.github.com/repos/bitcoin/bitcoin/contents/src/txrequest.h?ref=fd9a0060f028a4c01bd88f58777dea34bdcbafd1",
        "patch": "@@ -148,6 +148,7 @@ class TxRequestTracker {\n      *\n      * It does the following:\n      *  - Convert all REQUESTED announcements (for all txhashes/peers) with (expiry <= now) to COMPLETED ones.\n+     *    These are returned in expired, if non-nullptr.\n      *  - Requestable announcements are selected: CANDIDATE announcements from the specified peer with\n      *    (reqtime <= now) for which no existing REQUESTED announcement with the same txhash from a different peer\n      *    exists, and for which the specified peer is the best choice among all (reqtime <= now) CANDIDATE\n@@ -159,7 +160,8 @@ class TxRequestTracker {\n      *    out of order: if multiple dependent transactions are announced simultaneously by one peer, and end up\n      *    being requested from them, the requests will happen in announcement order.\n      */\n-    std::vector<GenTxid> GetRequestable(NodeId peer, std::chrono::microseconds now);\n+    std::vector<GenTxid> GetRequestable(NodeId peer, std::chrono::microseconds now,\n+        std::vector<std::pair<NodeId, GenTxid>>* expired = nullptr);\n \n     /** Marks a transaction as requested, with a specified expiry.\n      *"
      }
    ]
  }
]